Searching between mysql-5.7.22 and mysql-8.0.12
Keywords: slow, fast, time, perf(ormance), optim(ize), regression
Additional keywords: delayedInnoDBflush,flush,binaryLog,dsync,delayedInnodbWrite,binarylog,buffer,bufferpoolsize
Keywords: slow fast time perf optim regression speed delayedInnoDBflush flush binaryLog dsync delayedInnodbWrite binarylog buffer bufferpoolsize
For keyword slow:
[33mcommit f63fbd324369fb981e64067cf84584363bc9664e[m
Author: Nuno Carvalho <nuno.carvalho@oracle.com>
Date:   Fri May 18 12:16:51 2018 +0200

    BUG#27652526: REJOIN OLD PRIMARY NODE MAY DUPLICATE KEY WHEN RECOVERY
    
    Group Replication does implement conflict detection on
    multi-primary to avoid write errors on parallel operations.
    The conflict detection is also engaged in single-primary mode on the
    particular case of primary change and the new primary still has a
    backlog to apply. Until the backlog is flushed, conflict detection
    is enabled to prevent write errors between the backlog and incoming
    transactions.
    
    The conflict detection data, which we name certification info, is
    also used to detected dependencies between accepted transactions,
    dependencies which will rule the transactions schedule on the
    parallel applier.
    
    In order to avoid that the certification info grows forever,
    periodically all members exchange their GTID_EXECUTED set, which
    full intersection will provide the set of transactions that are
    applied on all members. Future transactions cannot conflict with
    this set since all members are operating on top of it, so we can
    safely remove all write-sets from the certification info that do
    belong to those transactions.
    More details at WL#6833: Group Replication: Read-set free
    Certification Module (DBSM Snapshot Isolation).
    
    Though a corner case was found on which the garbage collection was
    purging more data than it should.
    The scenario is:
     1) Group with 2 members;
     2) Member1 executes:
          CREATE TABLE t1(a INT, b INT, PRIMARY KEY(a));
          INSERT INTO t1 VALUE(1, 1);
        Both members have a GTID_EXECUTED= UUID:1-4
        Both members certification info has:
           Hash of item in Writeset     snapshot version (Gtid_set)
           #1                           UUID1:1-4
     3) member1 executes TA
          UPDATE t1 SET b=10 WHERE a=1;
        and blocks immediately before send the transaction to the group.
        This transaction has snapshot_version: UUID:1-4
     4) member2 executes TB
          UPDATE t1 SET b=10 WHERE a=1;
        This transaction has snapshot_version: UUID:1-4
        It goes through the complete patch and it is committed.
        This transaction has GTID: UUID:1000002
        Both members have a GTID_EXECUTED= UUID:1-4:1000002
        Both members certification info has:
           Hash of item in Writeset     snapshot version (Gtid_set)
           #1                           UUID1:1-4:1000002
     5) member2 becomes extremely [1;31mslow[m in processing transactions, we
        simulate that by holding the transaction queue to the GR
        pipeline.
        Transaction delivery is still working, but the transaction will
        be block before certification.
     6) member1 is able to send its TA transaction, lets recall that
        this transaction has snapshot_version: UUID:1-4.
        On conflict detection on member1, it will conflict with #1,
        since this snapshot_version does not contain the snapshot_version
        of #1, that is TA was executed on a previous version than TB.
        On member2 the transaction will be delivered and will be put on
        hold before conflict detection.
     7) meanwhile the certification info garbage collection kicks in.
        Both members have a GTID_EXECUTED= UUID:1-4:1000002
        Its intersection is UUID:1-4:1000002
        Both members certification info has:
           Hash of item in Writeset     snapshot version (Gtid_set)
           #1                           UUID1:1-4:1000002
        The condition to purge write-sets is:
           snapshot_version.is_subset(intersection)
        We have
           "UUID:1-4:1000002".is_subset("UUID:1-4:1000002)
        which is true, so we remove #1.
        Both members certification info has:
           Hash of item in Writeset     snapshot version (Gtid_set)
           <empty>
     8) member2 gets back to normal, we release transaction TA, lets
        recall that this transaction has snapshot_version: UUID:1-4.
        On conflict detection, since the certification info is empty,
        the transaction will be allowed to proceed, which is incorrect,
        it must rollback (like on member1) since it conflicts with TB.
    
    The problem it is on certification garbage collection, more
    precisely on the condition used to purge data, we cannot leave the
    certification info empty otherwise this situation can happen.
    The condition must be changed to
           snapshot_version.is_subset_not_equals(intersection)
    which will always leave a placeholder to detect delayed conflicting
    transaction.
    
    So a trace of the solution is (starting on step 7):
     7) meanwhile the certification info garbage collection kicks in.
        Both members have a GTID_EXECUTED= UUID:1-4:1000002
        Its intersection is UUID:1-4:1000002
        Both members certification info has:
           Hash of item in Writeset     snapshot version (Gtid_set)
           #1                           UUID1:1-4:1000002
        The condition to purge write-sets is:
           snapshot_version.is_subset_not_equals(intersection)
        We have
           "UUID:1-4:1000002".is_subset_not_equals("UUID:1-4:1000002)
        which is false, so we do not remove #1.
        Both members certification info has:
           Hash of item in Writeset     snapshot version (Gtid_set)
           #1                           UUID1:1-4:1000002
     8) member2 gets back to normal, we release transaction TA, lets
        recall that this transaction has snapshot_version: UUID:1-4.
        On conflict detection on member2, it will conflict with #1,
        since this snapshot_version does not contain the snapshot_version
        of #1, that is TA was executed on a previous version than TB.
    
    This is the same scenario that we see on this bug, though here the
    pipeline is being blocked by the distributed recovery procedure,
    that is, while the joining member is applying the missing data
    through the recovery channel, the incoming data is being queued.
    Meanwhile the certification info garbage collection kicks in and
    purges more data that it should, the result it is that conflicts are
    not being detected.

[33mcommit 3f3136188f1bd383f77f97823cf6ebd72d5e4d7e[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Thu May 3 10:11:10 2018 -0600

    Bug #25540277 INNODB'S MVCC HAS O(N^2) BEHAVIORS
    
    This performance improvement was submitted by Domas Mituzas on 10-Feb-2017.
    Description: If there are multiple row versions in InnoDB, reading one row
    from PK may have O(N) complexity and reading from secondary keys may have
    O(N^2) complexity.
    
    The problem occurs when there are many pending versions of the same row,
    meaning that the primary key is the same, but a secondary key is different.
    The [1;31mslow[mdown occurs when the secondary index is traversed. This patch
    creates a helper class for the function row_sel_get_clust_rec_for_mysql()
    which can remember and re-use cached_clust_rec & cached_old_vers so that
    rec_get_offsets() does not need to be called over and over for the
    clustered record.
    
    The patch submitted was converted to v8.0 style and structure.  The test case
    was enhanced to use multiple concurrent clients to commit 100 new record
    versions followed by a final record version so that the test case will be consistent.
    A variable length column is added to the table and the final record is shown.

[33mcommit e20833e4d28168b9894f8d0a2944bb1f7cbe7f57[m
Author: Neha Kumari <neha.n.kumari@oracle.com>
Date:   Mon Apr 30 09:52:29 2018 +0530

    Bug#26450129:DEAD BRANCH IN SEARCH_KEY_IN_TABLE()
    
    Problem:
    
    if (key_type & UNIQUE_KEY_FLAG && table->s->uniques)
      {
        ...
      }
    The condition (table->s->uniques) is always 0 so the if block will never be
    executed. In cases where different primary key is used on master and slave
    and if there is an Unique key present on slave then that should be used for
    lookup created index. Before this bug in above cases a TABLE_SCAN was being
    performed which can be [1;31mslow[mer than INDEX_SCAN that will be performed after
    the bug fix.
    
    Fix:
    Remove the condition (table->s->uniques).

[33mcommit d70cf6b7605395f41ad86fbb8059cf83c52357b6[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Wed Apr 11 11:48:52 2018 +0200

    Bug #27523095: SET PERSIST MANDATORY_ROLES FAILS TO START THE SERVER
    
    Problem: During server startup when persisted variables are being set,
    error is reported as there is no enough privileges.
    
    Analysis: System variables like keyring_access, mandatory_roles need dynamic
    privileges only and not SUPER, this is with an intention to [1;31mslow[mly get rid of
    SUPER. When these variables are persisted and later during server restart, when
    these variables are applied back on server the privilege check happens in
    corresponding check() functions. Since there is no entry in
    g_dynamic_privileges_map we report error. g_dynamic_privileges_map has a
    mapping between user and its dynamic privilege which is a reflection of
    mysql.global_grants table, in this case since it was during server startup
    phase where in THD::Security_context::m_user is empty string, thus the lookup
    into g_dynamic_privileges_map fails.
    
    Fix: Fix is to introduce a new Security_context_factory class whose primary
    functionality is to return an immutable security_context based on passed in
    user profile. User profile is this case represents a bootstrap user with only
    needed dynamic privileges. This returned security_context is further set in
    current THD. Once all needed operations are performed, security_context is
    dropped.

[33mcommit 6be2fa0bdbbadc52cc8478b52b69db02b0eaff40[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Wed Feb 14 09:33:42 2018 +0100

    WL#10310 Redo log optimization: dedicated threads and concurrent log buffer.
    
    0. Log buffer became a ring buffer, data inside is no longer shifted.
    
    1. User threads are able to write concurrently to log buffer.
    
    2. Relaxed order of dirty pages in flush lists - no need to synchronize
       the order in which dirty pages are added to flush lists.
    
    3. Concurrent MTR commits can interleave on different stages of commits.
    
    4. Introduced dedicated log threads which keep writing log buffer:
        * log_writer: writes log buffer to system buffers,
        * log_flusher: flushes system buffers to disk.
       As soon as they finished writing (flushing) and there is new data to
       write (flush), they start next write (flush).
    
    5. User threads no longer write / flush log buffer to disk, they only
       wait by spinning or on event for notification. They do not have to
       compete for the responsibility of writing / flushing.
    
    6. Introduced a ring buffer of events (one per log-block) which are used
       by user threads to wait for written/flushed redo log to avoid:
        * contention on single event
        * false wake-ups of all waiting threads whenever some write/flush
          has finished (we can wake-up only those waiting in related blocks)
    
    7. Introduced dedicated notifier threads not to delay next writes/fsyncs:
        * log_write_notifier: notifies user threads about written redo,
        * log_flush_notifier: notifies user threads about flushed redo.
    
    8. Master thread no longer has to flush log buffer.
    
    9. Introduced dedicated log thread which is responsible for writing checkpoints.
       No longer concurrent user threads need to compete for this responsibility.
    
    10. Master thread no longer has to take care of periodical checkpoints.
        Log checkpointer thread writes checkpoint at least once per second
        (before it was once per 7 seconds).
    
    11. The following exposed system variables, can be changed in runtime now:
        * innodb_log_buffer_size,
        * innodb_log_write_ahead_size.
    
    12. Master thread measures average global cpu usage in OS.
    
    13. Introduced new exposed system variables:
        * innodb_log_wait_for_flush_spin_hwm,
        * innodb_log_spin_cpu_abs_lwm,
        * innodb_log_spin_cpu_pct_hwm.
        They control when we need to use spinning for the best performance,
        to reduce latency which would otherwise come from communication
        between log threads and user threads. The first one is based on
        average flush time, the two others are based on cpu usage.
    
    14. Introduced new CMake option: ENABLE_EXPERIMENT_SYSVARS=0/1. System variables
        can be marked as hidden unless the experiment mode is turned on.
    
    15. There is a list of hidden new system variables for experiments with redo log.
        We skip listing them here.
    
    16. Created dedicated tester for redo log alone (as gtest).
    
    17. Created doxygen documentation for the new redo log.
    
    18. The dict_persist margin is updated when number of dirty pages is
        changed, instead of calculations on demand.
    
    19. Mechanism used to copy last incomplete block for Clone has been changed,
        because log buffer is concurrent now.
    
    20. Added more useful MONITOR counters for redo, including average lsn rate.
    
    21. Introduced sharded rw-lock to have an option to stop the world in redo,
        because log_mutex is removed.
    
    22. Invented and implemented a concurrent data structure which tracks progress
        of concurrent operations and can answer up to which point they all have been
        finished (when there is some order defined but they are allowed to be executed
        out of the order). This structure is used for concurrent writes to log buffer
        and re-used for concurrent additions to flush lists.
    
    23. Introduced a universal mechanism to wait on event, which starts with
        provided number of spin delays, then fallbacks to waits on event,
        starting at small timeout, but increasing timeout every few waits.
        This mechanism is used in communication between user and log threads,
        and in communication between different log threads.
    
    24. We [1;31mslow[m-down redo log writer when there is no space in redo allowing
        checkpoints to progress and rescue the state of redo.
    
    25. Log buffer can be resize in runtime - the size can also be decreased.
    
    26. Simplified shutdown procedure to avoid a possible returns in logic
        to previous phases.
    
    27. Removed concept of multiple log groups.
    
    28. Relaxed conditions required for checkpoint_lsn. It can now point to
        any data byte within redo (does not need to point to a records group
        beginning).
    
    29. Windows: always use buffered IO for redo log.
    
    30. Mysql test runner received a new feature (thanks to Marcin):
        --exec_in_background.
    
    Review: RB#15134
    
    Reviewers:
        - Marcin Babij <marcin.babij@oracle.com>,
        - Debarun Banerjee <debarun.banerjee@oracle.com>.
    
    Performance tests:
        - Dimitri Kravtchuk <dimitri.kravtchuk@oracle.com>,
        - Daniel Blanchard <daniel.blanchard@oracle.com>,
        - Amrendra Kumar <amrendra.x.kumar@oracle.com>.
    
    QA and MTR tests:
        - Vinay Fisrekar <vinay.fisrekar@oracle.com>.

[33mcommit 68000078165c55faea5b1f5048450ccad2c36a99[m
Author: Maria Couceiro <maria.couceiro@oracle.com>
Date:   Thu Jan 11 17:00:56 2018 +0000

    BUG#27370035 RPL_DELAYED_SLAVE SHOULD USE REPLICATION TIMESTAMPS TO IMPROVE STABILITY
    
    Problem and analysis:
    The test rpl_delayed_slave is currently disabled due to its sporadic
    failures. It relies on a set of sleeps followed by thread state checks
    to verify whether events were correctly delayed before being applied in
    the slave. This approach is prone to produce unstable results as [1;31mslow[mer
    machines may not have reached the expected state after the timeout,
    causing the test to fail.
    
    Fix:
    Replace all sleep followed by thread state checks with asserts relying
    on the immediate_commit_timestamp reported in the binary log, which can
    be found in check_slave_delay.inc file.
    Move the Seconds_behind_master checks to the corresponding test case and
    reformulate the assertions so that they are more deterministic.
    Remove all time conditions that are prone to fail on [1;31mslow[mer machines.
    Most of these conditions are already tested in other sql delay tests.

[33mcommit 541f51122d05b993a9216a0dd46b3fce5a227c3a[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Tue Jan 16 16:19:25 2018 +0100

    Bug #27349579 SEVERE PERFORMANCE REGRESSION IN SERVER BOOTSRAP
    
    Problem: mysqld --initialize is significantly [1;31mslow[mer on some file
    systems after switching from several INSERT statements in one
    transaction to auto-committing CREATE SPATIAL REFERENCE SYSTEM
    statements to initialize the spatial reference system definition list.
    
    The root cause is that InnoDB transactions are [1;31mslow[m on some file
    systems. Since CREATE statements are auto-committing, the change in SQL
    statements during --initialize causes ~5000 new transactions to be
    executed, which is noticable on file systems where transactions are
    [1;31mslow[m.
    
    Solution: Set innodb_flush_log_at_trx_commit=0 before installing spatial
    reference systems during initialization. Since this is done during
    initialization of an empty data directory, no user data is lost if
    mysqld crashes.
    
    Change-Id: I6a23e408a4226b92d437a0181f7fb45f137a63b8

[33mcommit cb688d3bb0574989c98e60ca8fad60e314244b15[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Wed Jan 10 12:43:58 2018 +1100

    Bug#27265874 - TABLESPACE ID DISCOVERY ON STARTUP IS BROKEN
    
    Follow up fix.
    If the header page is all zeroes then the tablespace flags parsing
    will result in resetting the page size used to read the .ibd file
    to the default 16K.
    
    The fix is to use the [1;31mslow[mer check if a tablespace ID read from
    the header is 0.

[33mcommit fd2b8a43be884a3aa1c01856faa9d9f1645554e3[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Wed Jan 10 12:43:58 2018 +1100

    Bug#27265874 - TABLESPACE ID DISCOVERY ON STARTUP IS BROKEN
    
    Follow up fix.
    If the header page is all zeroes then the tablespace flags parsing
    will result in resetting the page size used to read the .ibd file
    to the default 16K.
    
    The fix is to use the [1;31mslow[mer check if a tablespace ID read from
    the header is 0.

[33mcommit 838871ffe5b464364bd6489b389b0c438a0b69ac[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Tue Jan 9 18:13:36 2018 +1100

    Bug#26399073 - MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS
    
    Fix a performance regression; InnoDB has a system where the performance
    schema key is decided by FILE, and the patch that extended the basename
    function to work with both / and \ made these allocations [1;31mslow[mer (as it
    uses std::string, which can allocate on the heap).
    
    However, there is no reason whatsoever that this lookup needs to be done
    runtime in a map. Change it to use a constexpr function; it goes through
    the array linearly, but it's small and it's compile-time. The end result
    is that the compiled code stores a PSI key directly, instead of taking
    FILE, removing its path runtime and looking it up in an std::map.
    
    Improves a data loading benchmark with ~3%, in addition to the ~7%
    regression it fixes
    
    rb#18379 Approved by Bin. Fixed by Steinar.

[33mcommit 1b0a0645a2803b4a5f3bd5ada356a3edf9d1624a[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Tue Jan 9 18:13:36 2018 +1100

    Bug#26399073 - MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS
    
    Fix a performance regression; InnoDB has a system where the performance
    schema key is decided by FILE, and the patch that extended the basename
    function to work with both / and \ made these allocations [1;31mslow[mer (as it
    uses std::string, which can allocate on the heap).
    
    However, there is no reason whatsoever that this lookup needs to be done
    runtime in a map. Change it to use a constexpr function; it goes through
    the array linearly, but it's small and it's compile-time. The end result
    is that the compiled code stores a PSI key directly, instead of taking
    FILE, removing its path runtime and looking it up in an std::map.
    
    Improves a data loading benchmark with ~3%, in addition to the ~7%
    regression it fixes
    
    rb#18379 Approved by Bin. Fixed by Steinar.

[33mcommit 4d3573e22b337db7c748f54f83d0b2eb040e50cd[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Fri Dec 15 18:10:33 2017 +1100

    Bug#27265874 - TABLESPACE ID DISCOVERY ON STARTUP IS BROKEN
    
    The compare with the previous value is broken. The fix is to read the
    the value into an array and then do a compare separately. If there is
    any mismatch then we fallback to the [1;31mslow[mer tablespace ID lookup.
    
    RB#18258 Approved by Bin Su.

[33mcommit 3afbb1bc30c773a93eeafd5648b79f18c3c1ed09[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Fri Dec 15 18:10:33 2017 +1100

    Bug#27265874 - TABLESPACE ID DISCOVERY ON STARTUP IS BROKEN
    
    The compare with the previous value is broken. The fix is to read the
    the value into an array and then do a compare separately. If there is
    any mismatch then we fallback to the [1;31mslow[mer tablespace ID lookup.
    
    RB#18258 Approved by Bin Su.

[33mcommit 37223f3a41940296e7b62a5fd3a83a079ee43161[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Fri Dec 15 18:10:33 2017 +1100

    Bug#27265874 - TABLESPACE ID DISCOVERY ON STARTUP IS BROKEN
    
    The compare with the previous value is broken. The fix is to read the
    the value into an array and then do a compare separately. If there is
    any mismatch then we fallback to the [1;31mslow[mer tablespace ID lookup.
    
    RB#18258 Approved by Bin Su.

[33mcommit 9c9bdf17e2159af46ef036910a1e33fa14a5261e[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Dec 1 11:18:12 2017 +0100

    Bug #26399073: MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS [noclose]
    
    Fix a performance regression; InnoDB has a system where the performance
    schema key is decided by __FILE__, and the patch that extended the
    basename function to work with both / and \ made these allocations
    [1;31mslow[mer (as it uses std::string, which can allocate on the heap).
    
    However, there is no reason whatsoever that this lookup needs to be done
    runtime in a map. Change it to use a constexpr function; it goes through
    the array linearly, but it's small and it's compile-time. The end result
    is that the compiled code stores a PSI key directly, instead of taking
    __FILE__, removing its path runtime and looking it up in an std::map.
    
    Improves a data loading benchmark with ~3%, in addition to the ~7% regression
    it fixes.
    
    Change-Id: Ia536f6342278fcd6cc990053c3d2b0978e781b29

[33mcommit 0675bd36b465784a045ff41f12ac1684f50b9613[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Thu Nov 16 22:23:59 2017 +0000

    Bug#25965370 NDB : LQH CAN EXCEED 4 CONCURRENTLY
      OPENED FILES PER PART DURING RESTARTS
    
    During restart, the LQH component in the data node loads redo
    log part metadata for each redo log part it manages, from one
    or more redo log files.
    
    Metadata is stored per megabyte, and each file has a limited
    metadata capacity, so the number of files which must be consulted
    depends on the size of the redo log part.
    
      (NoOfFragmentLogFiles * FragmentLogFileSize)
    
    Files are opened, read and closed sequentially, but the close
    of one file occurs concurrently with the open of the next.
    
    In cases where file close is [1;31mslow[m, this can result in more
    than 4 open files per redo log part.
    
    As the files are opened with the OM_WRITE_BUFFER option set,
    this can result in more than 4 chunks of write buffer being
    allocated per part.
    
    As the write buffer pool is finite, if all redo log parts
    are in a similar state, it may be exhausted, causing node
    shutdown.
    
    The solution chosen is to avoid using the OM_WRITE_BUFFER
    option during metadata reload, so that transiently opening
    more than 4 redo log files per part does not cause node
    failure.
    
    A new ERROR_INSERT is added to [1;31mslow[m file closure for metadata
    reload, allowing manual testing of the fix.  No automated
    testcase is added as there is a requirement for large redo
    logs.

[33mcommit 02c845e6cc5c2679bcb429b621164431d06914de[m
Author: Tatiana Azundris Nuernberg <tatjana.nuernberg@oracle.com>
Date:   Fri Nov 10 09:37:09 2017 +0000

    Bug#22591899: FILE HANDLE LEAK WHEN SETTING SLOW LOG IN MULTIPLE CONNECTIONS.
    
    log open function accessed the log-name system variables without
    holding a lock on sysvars. This could lead to a race condition
    between
    a) several threads trying to change the same logging sys-var
    b) several threads trying to change inter-related logging sys-vars
       (e.g. [1;31mslow[m log file name, and [1;31mslow[m log on/off state)
    c) a thread changing a logging sys-var, and another thread running
       FLUSH [ERROR] LOGS (which also read the log name sys vars while
       reopening the log; and without holding a lock on the sys vars)
    While this case seems somewhat artificial in that it requires SUPER
    and a lot of pointless waffling with the log settings, it's only
    proper that we guard against it all the same. New code factors out
    the part that reads the sys-var, so it is not run during FLUSH,
    and makes sure that that part of the code is run from sys-var setters
    while the sys var lock is still held.

[33mcommit 65bb451034ab20d0c35c62de568027bb7fd7f434[m
Author: Pedro Figueiredo <pedro.figueiredo@oracle.com>
Date:   Mon Nov 6 12:35:50 2017 +0000

    Bug#26926291 RPL.RPL_SPEC_VARIABLES FAILS ON PB2 SPORADICALLY
    
    Description
    -----------
    rpl.rpl_spec_variables is seen to be failing on pb2 sporadically
    Error output is:
    
        rpl.rpl_spec_variables 'mix'             w19 [ fail ]
            Test ended at 2017-09-29 21:39:59
    
        mysqltest: In included file ./include/sync_slave_sql.inc at line 151:
        included from ./include/sync_slave_sql_with_master.inc at line 79:
        included from ./mysql-commercial-9.0.0-dmr-linux-x86_64-valgrind/mysql-test/suite/rpl/t/
           rpl_spec_variables.test at line 204:
        At line 150: Error in sync_with_master.inc
    
        ERROR: sync_slave_sql.inc failed on connection 'slave'
        ERROR: use_gtids='0'
        ERROR: _saved_gtids=''
        ERROR: _saved_file='master-bin.000001'
        ERROR: _saved_pos='815297'
        ERROR: _saved_channel_name=
        ERROR: timeout='300'
        ERROR: result='-1'
        ERROR: error type: Timeout after 300 seconds.
    
    Analysis
    --------
    - Could not replicate the problem locally.
    - Tested several 'mtr' options to [1;31mslow[m down the process, etc, with no
    success in replicating the problem.
    - Tested some visible points of failure:
      . Heap max limit exceeded with ENGINE=MEMORY,
      . Inserting 2000 records and synchonize might take more than 300 secondsm
      . I/O thread stops,
      but would fail every time and not sporadically.
    - Test fails with the --repeat > 1, due to the usage of a --copy_file command
    without validation for the existance of such files in the destination dir. The
    --copy_file command does not allow file override and files if the destination
    files already exist.
    
    Fix
    ---
    - Reduce the amount of records inserted in order to ensure that the timeout interval
    isn't, in fact, being reached.
    - Add config variables, for:
      * record count, '$row_count'
      * heap size, '$heap_size'
      * record size, '$record_size'.
    - Making '$record_count' dependant of the division of the other two variables.
    - Replace --copy_file with --copy_files_wildcard, which allow file to be
    overwritten
    
    Notes
    -----
    - '$record_size' may hold any value, it all depends on the amount of records
    one whishes to insert in the tables.

[33mcommit 2985f120a0fe0e3c619d428f599134a828fd9605[m
Author: Jaideep Karande <jaideep.karande@oracle.com>
Date:   Wed Oct 25 12:20:40 2017 +0200

    BUG#25429322 : GROUP_REPLICATION.GR_PREPARED_STATEMENTS FAILS SPORADICALLY ON SLOW SYSTEMS
    
    Problem: Test case GR_PREPARED_STATEMENTS only checks count of records
    
    Description:
    Test case GR_PREPARED_STATEMENTS only checks count of records and does not
    wait for operations to replicate across group.
    Test case has series of inserts, delete and update statements.
    On [1;31mslow[m system its possible count of records may match in between operations
    causing later record matching checks to fail.
    
    e.g.
    1.  S-1 I(1) TABLE(1)
    2.  S-1 I(2) TABLE(1,2)
    3.  S-1 I(3) TABLE(1,2,3)
    
    4.  S-2 I(4) TABLE(1,2,3,4)
    5.  S-2 I(5) TABLE(1,2,3,4,5)
    6.  S-2 I(6) TABLE(1,2,3,4,5,6)
    
    7.  S-2 U(+10) TABLE(11,12,13,14,15,16)
    8.  S-2 D(11) TABLE(12,13,14,15,16)
    9.  S-2 D(12) TABLE(13,14,15,16)
    (S-1 mean server-1, I(1) mean insert 1 in table t1, and TABLE(1) means records
    in table t1)
    Count of records matches to 4 in step 4 and step 9.
    On [1;31mslow[m machines WAIT condition comes out in step 4 instead of step 9.
    This causes difference in records causing test to fail.
    
    Resolution:
    Added call to rpl_sync to make sure records are replicated.
    Replaced corresponding wait with assert.

[33mcommit d703c5b1884fa5b87cc154fb02375431a473ca74[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Oct 11 10:41:03 2017 +0200

    Bug#17840780 PERFORMANCE_SCHEMA.SETUP_INSTRUMENTS* TESTS UNSTABLE ON PB2
    
    Improved the test perfschema.setup_instruments_default robustness.
    
    Do not restart the server from within a mtr test script,
    it makes the test [1;31mslow[m and unstable under heavy load.

[33mcommit e9457df12eb961f0daf742eb916b33c243afadbc[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Mon Aug 28 14:06:16 2017 +0200

    Stabilize a few tests after the RC 1 cut-off.
    
    Stabilize output for some tests (--sorted_result).
    
    Added missing clean-up in binlog.binlog_rewrite and
    sys_vars.[1;31mslow[m_query_log_func
    
    Approved by Anitha Gopi <anitha.gopi@oracle.com>.

[33mcommit 7133c6e8e070f9f7238a251bded49acccdcd1606[m
Author: Xing Zhang <xing.z.zhang@oracle.com>
Date:   Thu Jun 29 17:56:12 2017 +0800

    Bug #25426632: STRNXFRM RUNS SLOWER WHEN TAILORING RULE CONTAINS CONTRACTION
    
    Strnxfrm function of uca collations needs to search for contraction's
    weight. Current implemenation of contraction uses array to store info of
    contraction, which is [1;31mslow[m.
    
    Fix:
    Build trie of contraction. Each node of the trie contains one character of
    contraction. It is faster to find a contraction in the trie and return its
    weight pointer.
    
    This patch also changed mysql-test/std_data/Index.xml, because one
    tailoring rule defined in this file is wrong. There will be no rule: "A
    <<<< A".
    
    BM_Hungarian_AS_CS         3750 -> 2405 ns/iter [+ 55.9%]
    BM_Japanese_AS_CS          4058 -> 2562 ns/iter [+ 58.4%]
    BM_Japanese_AS_CS_KS       5242 -> 3464 ns/iter [+ 51.3%]
    
    Change-Id: I611068aebed42168c93c1e94f874b3749ba3a531

[33mcommit 793e8e74ff6e34274a093638d5abe0c988f1394c[m
Author: Xing Zhang <xing.z.zhang@oracle.com>
Date:   Tue Jun 20 10:46:18 2017 +0800

    Bug #26286790: PERFORMANCE ISSUE OF EXPLICIT COLLATE CLAUSE
    
    Ordering by a varchar field with explicit collation is much [1;31mslow[mer than it
    with implicit collation, even if the explicit collation is same as the
    implicit one. A certain sorting with implicit collation needs 0.5 sec, but
    the sorting with explicit collation needs about 1 min.
    
    Cause:
    A item is created for the field with explict collation, and filesort treats
    its weight buffer length is fixed. But for the field with implicit
    collation, filesort treats its weight buffer length is variable. This
    causes there are much more chunks is created and needed to merge when doing
    filesort for the field with explicit collation. It consumes a lot of time.
    
    Fix:
    All new UCA collations we added don't need padding spaces anymore, so we
    let filesort know that the weight buffer length of the item is variable.
    
    Result:
    without this patch, time used to sorting reporter's data needs 0.51 sec and
    58.73 sec.
    With this patch, time used to sorting reporter's data needs 0.54 sec and
    0.76 sec.
    
    Change-Id: I5394faabf6325ff43f71ae6076dedebd3d75c105

[33mcommit 3ea6ece3105a0420fbe0e3fa86019505888bc392[m
Author: Thirunarayanan Balathandayuthapani <thirunarayanan.balathandayuth@oracle.com>
Date:   Fri Jun 23 10:15:07 2017 +0530

    Bug#26197113 SLOW DYNAMIC TABLE STATISTICS RETRIVAL FROM I_S AFTER MYSQL-TRUNK-META-SYNC PUSH
    
    Analysis:
    
    If the table is not present in the cache then opening the table
    takes lot of time and it leads to [1;31mslow[m performance in information
    schema queries.
    
    Following changes are done to fix the issue,
    
    InnoDB changes:
    
    - Instead of opening the table, InnoDB can fetch the stats
      information from innodb_table_stats and innodb_index_stats.
    
    - Fetch the record from innodb_table_stats using db_name, table name
      and it will give information about n_rows, clustered index_size and
      sum of other index size.
    
    - Fetch the space id from Tablespace SE private data for
      general/system tablespace (or) Fetch the space id using db_name,
      table_name from fil_space_t hash.
    
    - Use the space_id to calculate the available length in the
      tablespace.
    
    - Maximum value of autoincremnt fetched from innodb_dynamic_metadata
      using table id and autoincrement fetched from table_se_private data.
    
    - Cardinality can be fetched from innodb_index_stats table using
      db_name, table name, index name and column offset.
    
    - If the table doesn't have persistent stats then InnoDB loads
    the table from the disk.
    
    Server changes:
    
    - Supply mysql.tablespaces.se_private_data to internal functions
      INTERNAL_*(), which is used by SE to read the SE specific tablespace
      metadata when fetching table dynamic statistics. E.g., InnoDB would
      read the SE specific space_id from se_private_data column.
    
    - INFORMATION_SCHEMA.TABLES system view is now joined with
      mysql.tablespaces, to get the mysql.tablespaces.se_private_data for a
      table.
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Bin Su <bin.x.su@oracle.com>
    Reviewed-by: Praveenkumar Hulakund <praveenkumar.hulakund@oracle.com>
    RB: 16467

[33mcommit df5c7956bb106edd16304219faaf5e67099fe7a9[m
Author: Thirunarayanan Balathandayuthapani <thirunarayanan.balathandayuth@oracle.com>
Date:   Fri Jun 23 10:15:07 2017 +0530

    Bug#26197113 SLOW DYNAMIC TABLE STATISTICS RETRIVAL FROM I_S AFTER MYSQL-TRUNK-META-SYNC PUSH
    
    Analysis:
    
    If the table is not present in the cache then opening the table
    takes lot of time and it leads to [1;31mslow[m performance in information
    schema queries.
    
    Following changes are done to fix the issue,
    
    InnoDB changes:
    
    - Instead of opening the table, InnoDB can fetch the stats
      information from innodb_table_stats and innodb_index_stats.
    
    - Fetch the record from innodb_table_stats using db_name, table name
      and it will give information about n_rows, clustered index_size and
      sum of other index size.
    
    - Fetch the space id from Tablespace SE private data for
      general/system tablespace (or) Fetch the space id using db_name,
      table_name from fil_space_t hash.
    
    - Use the space_id to calculate the available length in the
      tablespace.
    
    - Maximum value of autoincremnt fetched from innodb_dynamic_metadata
      using table id and autoincrement fetched from table_se_private data.
    
    - Cardinality can be fetched from innodb_index_stats table using
      db_name, table name, index name and column offset.
    
    - If the table doesn't have persistent stats then InnoDB loads
    the table from the disk.
    
    Server changes:
    
    - Supply mysql.tablespaces.se_private_data to internal functions
      INTERNAL_*(), which is used by SE to read the SE specific tablespace
      metadata when fetching table dynamic statistics. E.g., InnoDB would
      read the SE specific space_id from se_private_data column.
    
    - INFORMATION_SCHEMA.TABLES system view is now joined with
      mysql.tablespaces, to get the mysql.tablespaces.se_private_data for a
      table.
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Bin Su <bin.x.su@oracle.com>
    Reviewed-by: Praveenkumar Hulakund <praveenkumar.hulakund@oracle.com>
    RB: 16467

[33mcommit f5b9c862610f06b78acb375349ddb10ac7ea18b3[m
Author: Xing Zhang <xing.z.zhang@oracle.com>
Date:   Thu Jun 1 23:32:00 2017 +0800

    WL #10818: Add utf8mb4 accent sensitive and case insensitive collation
    
    Added accent sensitive and case insensitive collation, utf8mb4_0900_as_ci.
    The implementation is simple and straightforward because all the logic of
    multi-level collation is ready when we added accent and case sensitive
    collations.
    
    The benchmark result of this collation is [1;31mslow[mer than accent and case
    insensitive collation but faster than accent and case sensitive collation,
    just as expected.
    
    BM_MixedUTF8MB4             161 ns/iter     0.77 GB/sec
    BM_MixedUTF8MB4_AS_CI       336 ns/iter   377.31 MB/sec
    BM_MixedUTF8MB4_AS_CS       486 ns/iter   261.13 MB/sec
    
    Change-Id: I1e44b7008c7746ee111dd8738d22591c7a36eec4

[33mcommit ebaff9fffc958030a57d8ea7f1f2d527cac1df64[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Fri Mar 31 10:43:38 2017 +0200

    WL#10353: Use utf8mb4 in libmysql and command tools
    
    This WL changes the compiled in default character set for all clients to
    utf8mb4. Client tools include following: mysql, mysqladmin, mysqldump,
    mysqlcheck, mysqlpump, mysqlimport, mysql_upgrade, mysqltest, mysql[1;31mslow[m,
    mysqlslap.

[33mcommit 7e114949f6a464df74b17d272e5cd644ca9893c8[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Wed Feb 8 10:37:17 2017 +0530

    BUG#24806741 : MTR: INTRODUCE "EXPR" COMMAND
    
    Description :
    =============
    MTR cannot do basic math operations like +, -, /, *, %, &&, || etc.
    Current way is to invoke SQL command to do these operations. But using
    mysqld server for these basic operations is [1;31mslow[m and not right.
    
    Fix :
    =====
    Introduced new MTR command 'expr' to perform basic mathematical
    operations.
    
    "--expr $<var_name>= <operand1> <operator> <operand2>"
    
    Both <operand1> and <operand2> should be valid MTR variables. 'expr'
    command supports only binary operators that operates on two operands
    and manipulates them to return a result.
    
    E.g:
    
    --let $val1= 10
    --let $var2= 20
    --expr $res= $var1 + $var2
    --echo $res
    
    Following mathemiatical operators are supported.
    
    1 Arithmetic Operators
      1.1 Addition
      1.2 Subtraction
      1.3 Multiplication
      1.4 Division
      1.5 Modulo
    
    2 Logical Operators
      2.1 Logical AND
      2.2 Logical OR
    
    3 Bitwise Operators
      3.1 Binary AND
      3.2 Binary OR
      3.3 Binary XOR
      3.4 Binary Left Shift
      3.5 Binary Right Shift
    
    NOTE
    1. Non-integer operand is truncated to integer value for operations
       that dont support non-integer operand.
    2. If the result is an infinite value, then expr command will return
       'inf' keyword to indicate the result is infinity.
    3. Division by 0 will result in an infinite value and expr command
       will return 'inf' keyword to indicate the result is infinity.
    
    Reviewed-by: Deepa Dixit <deepa.dixit@oracle.com>
    Reviewed-by: Srikanth B R <srikanth.b.r@oracle.com>
    RB: 14788

[33mcommit 9d3865ea6f13b357d1ecc09934516aa13b0be735[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Wed Feb 1 10:38:38 2017 +0100

    WL#6599 - New Data Dictionary and I_S integration.
    
    Post-push fix.
    
    When [1;31mslow[m query is run more than once with server option
    query_cache_type=1, the first execution of the query is
    logged as [1;31mslow[m query. As we skip parsing parsing and fetch
    results directly for subsequent execution of same query, the
    query is not written to [1;31mslow[m query. This is the reason
    main.show_check is failing when query cache is enabled.
    
    In order to get consistent results for main.show_check test
    with and without the query cache enabled, the test is
    modified to not use query cache by adding SQL_NO_CACHE in
    respective select.

[33mcommit a9e792f7175d0aff0de3c5b0c06a80ae6856f46e[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Sun Jan 29 07:15:11 2017 +0100

    WL#6599 - New Data Dictionary and I_S integration.
    
    Post-push fix: Sporadic failure of main.show_check test.
    
    The test case for Bug#28808 is written to test behavior of
    'log_queries_not_using_indexes' variable based on test that uses
    INFORMATION_SCHEMA.TABLES. The expectation is that it should not
    use index. But, after WL#6599, INFORMATION_SCHEMA.TABLES is a
    system view which a JOIN over several DD tables and there is
    possibility of optimizer opting to use a index. This leads
    optimizer to set or unset SERVER_QUERY_NO_INDEX_USED as
    thd->server_status sporadically. And this causes
    log_[1;31mslow[m_applicable() function to ignore logging the the query
    when SERVER_QUERY_NO_INDEX_USED is not set to thd->server_status.
    
    In order to fix the issue, the test case is modified to use a
    user table 'tab1' (as described in bug#28808) instead of
    INFORMATION_SCHEMA.TABLES. This avoid the sporadic failure.

[33mcommit 55f4f2c8c2bd846360caef96893b1ceefee54aa4[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon May 23 11:58:08 2016 +0200

    WL#7569 Split ha_ndbcluster_glue.h into the appropriate ndb_*.h files
    
     - Move thd_unmasked_server_id() to ndb_thd.h and ndb_thd.cc
     - It's no longer a static inline function but that's ok
       since it's in the "[1;31mslow[m path"

[33mcommit e18fafb71ef41ea8390da919d8fd712a2b9c6464[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Tue Jan 24 21:25:59 2017 +0100

    WL#10174
    When we see an IO lag on any of the log parts in an LDM we will
    decide that this is enough to [1;31mslow[m down the LCP writing since the
    disk is overloaded. Obviously this condition should be that if
    any log part in any LDM is overloaded then the disk is overloaded.
    So we ensure that this reporting is done for all LDMs and not only
    for one LDM.

[33mcommit ac567a9fd4c0615bda0114451b6355e487141f0e[m
Author: Tiago Jorge <tiago.jorge@oracle.com>
Date:   Tue Jan 10 18:45:13 2017 +0000

    BUG#25311164 - UPDATE XCOM ON GROUP REPLICATION
    
    This updates GR to the latest XCom on GCS. On this commit we have fixes for:
    
    BUG#22204121 - NODE THAT FAILS AND RE-ENTERS MIGHT BE EXPELLED WITH NO REASON
    Added the notion of reincarnation of a node.
    
    BUG#22812902 - ENABLE WERROR AS DEFAULT IN MYSQL-GCS BUILDS
    Several warning corrections
    
    BUG#22671683 - LIMIT MEMORY UTILIZATION IN XCOM
    Adding cache methods to avoid breaking examples code
    Added minimum delivered message number to xcom messages to avoid deallocating cache that is needed by [1;31mslow[m or joining nodes. Incread xcom protocol version to x_1_2
    Added functions to enforce an upper limit to the application data in the xcom cache
    
    Some changes towards this adaptation:
    - Corrected Copyright year
    - Corrected invalid declaration
    - Adapting to printing size_t on 32-bit platforms
    - Removing unecessary declarations
    - Corrected the fact that the patch was not self-sufficient
      in terms of not using UUIDs with XCom

[33mcommit d450ab5d679b68951c4ee2232cf785f63caab21f[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Wed Dec 14 11:45:01 2016 +0530

    WL#9711 : Remove *.require files
    
    Description :
    =============
    In MTR we have *.require files to perform checks. But these require
    files are not necessary to perform a check and adds an extra overhead.
    Instead of using require files, the check for the condition can be
    implemented in corresponding inc files.
    
    E.g:
    
    1) have_debug_sync.inc
    ----------------------
    require r/have_debug_sync.require;
    disable_query_log;
    let $value=query_get_value(SHOW VARIABLES LIKE 'debug_sync', Value, 1);
    eval SELECT ('$value' LIKE 'ON %') AS debug_sync;
    enable_query_log;
    
    2) have_debug_sync.require
    --------------------------
    debug_sync
    1
    
    The way this works is that '--require' causes the result of the next
    query to be written to a temporary file and then there is a file
    comparison of the temporary file and, in this case,
    have_debug_sync.require.
    
    This sounds much [1;31mslow[mer than it could be. And also there are issues on
    Windows where a test can fail simply because of line ending differences.
    
    This WL removes all these require files and implements the check in
    the corresponding inc file. If '--require' command is used in any of
    the test file/inc file, MTR will error out with a deprecation message.
    
    E.g:
    
    Modified have_debug_sync.inc
    ----------------------------
    let $have_debug_sync= query_get_value(SHOW VARIABLES LIKE 'debug_sync', Value, 1);
    if ($have_debug_sync == 'No such row')
    {
      skip Test requires 'have_debug_sync';
    }
    
    Reviewed-by: Anitha Gopi <anitha.gopi@oracle.com>
    Reviewed-by: Deepa Dixit <deepa.dixit@oracle.com>
    Reviewed-by: Magnus Blåudd <magnus.blaudd@oracle.com>
    RB: 14686

[33mcommit c5768818b32fdc65aec9118b1fe7e63205eefd45[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Nov 22 10:43:41 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Drop char_index for UCA 9.0.0 scanners, now that strnxfrm is no longer expected
    to truncate (and we don't need it for padding). Speeds up the [1;31mslow[m path
    significantly.
    
    Microbenchmarks (Skylake 3.4 GHz, optimized mode, GCC 6.2):
    
      BM_SimpleUTF8MB4                147 -> 142 ns/iter  [ +3.5%]
      BM_MixedUTF8MB4                 277 -> 212 ns/iter  [+30.7%]
      BM_MixedUTF8MB4_AS_CS           786 -> 657 ns/iter  [+19.6%]
      BM_NewlineFilledUTF8MB4         231 -> 200 ns/iter  [+15.5%]
      BM_HashSimpleUTF8MB4            306 -> 306 ns/iter  [  0.0%]
    
    Change-Id: Id9883ac4d73618e05b4663d7cb15310aa300cbcc

[33mcommit fe5d218e891374acaf5bdda9e956c3e46cebef89[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Thu Nov 24 10:19:03 2016 +0530

    BUG#20694384 : TEST TIMEOUT BUT NO STACK TRACE ON WINDOWS
    
    Description :
    =============
    When a test times out, MTR generates stack trace in order to
    debug the issue. We usually get this on Linux, but apparently
    not on Windows.
    
    Except when the test is too [1;31mslow[m, a timeout is most likely due
    to a deadlock. A stack trace would help to find out. With no
    stack trace it's impossible to analyze the bug.
    
    Issue :
    =======
    When a test times out, on linux kill() command with ABRT signal
    is issued to the server process which will cause it to generate
    memory dump.
    
    Due to the limitation of perl and signal handling in windows, no
    signal is sent to the server process and no dump file is generated.
    
    Fix :
    =====
    On windows, when a test times out 'cdb' tool is used to generate
    the dump file for server process, but there is a high risk of MTR
    hanging by calling external programs like 'cbd' in multi-threaded
    runs(i.e $parallel > 1). Currently patch is made to work with
    parallel value 1 only.
    
    Reviewed-by: Bjorn Munch <bjorn.munch@oracle.com>
    Reviewed-by: Srikanth B R <srikanth.b.r@oracle.com>
    RB: 14236

[33mcommit a8c341b66d15966013448a885b3d80bed50c7689[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Nov 14 16:42:55 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Refactoring: Clean up an ending condition in the [1;31mslow[m path of uca_scanner_900.
    
    Change-Id: Ie2708b664ca2794826474fc74797fd22b623f1be

[33mcommit eb4d8baf353258ec5eee88cd8d161e6f0b41d11a[m
Author: Ole John <ole.john.aske@oracle.com>
Date:   Mon Oct 3 10:52:20 2016 +0200

    Follow up of bug#24496910, intended to fix bug#24715897: Showstopper for 7.5 GA
    
    The patch for bug#24496910 also introduced locking of the injector_mutex
    when reading global variabled maintained by the binlog injector thread, and
    read by any client thread.
    
    As it turns out that the injector_mutex is held for intervals of 10ms,
    that could considderably [1;31mslow[m down operations as open'ing of tables
    to a non acceptable level.
    
    This locking of this mutex is reverted ndb_binlog_is_read_only().
    A big comment is added explaining why, and suggesting TODO actions
    for a later propper fix.

[33mcommit 012f21c4cbcc22830d1fc8044634b1d3366d2405[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Fri Sep 2 15:26:40 2016 +0200

    Bug#24586888: SELECT LENGTH(JSON)
    
    Conversion of JSON documents to string could be [1;31mslow[m if the document
    was big and contained many signed integers.
    
    The reason was that String::append_longlong(), which was used to add
    the integers to the result string, only allocated enough memory to
    append one more integer, so that memory had to be reallocated very
    frequently.
    
    The fix is to make String::append_longlong() reallocate memory more
    aggressively, so that it doesn't have to do it as often. This patch
    makes append_longlong() reallocate memory in the same way as its
    sibling function append_ulonglong().

[33mcommit 270fd3411e3d671a73ed9725940a30080f59ce6d[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Thu Aug 25 16:52:45 2016 +0530

    WL#6392 : Upgrade to Transactional Data Dictionary
    
    With the implementation of the new data dictionary, the metadata will
    be stored in the InnoDB tables. For the users to upgrade from the older
    MySQL version(5.7) to mysql-8.0, dictionary tables should be created and
    populated in old data directory from various metadata sources.
    
    When the Mysql-8.0 server comes up, it detects for the presence of
    dictionary tables.  If dictionary tables are not present,
    they will be created in old data directory and populated
    with the metadata. Then the server will proceed with normal start.
    
    If dictionary tables are present, server will proceed with normal startup.
    
    Upgrade Steps for Users
    ------------------------
    
    1. Do a pre requisite check on 5.7 data directory.
    2. Do a [1;31mslow[m shutdown of mysql-5.7 server. Slow shutdown involves setting
       global variable 'innodb_fast_shutdown' to zero before server shutdown.
    3. Start mysql-8.0 server on 5.7 data directory.
       mysql-8.0 server will detect if Dictionary tables are present or not.
       If dictionary tables are not present,  they will be created in old data
       directory. Metadata will be populated in dictionary tables.
       Then server will proceed with normal start.
    4. Execute mysql_upgrade client tool.
    5. Shutdown and start server again with normal configuration. (Recommended)
    
    Reviewed-by: Nisha Gopalakrishnan <nisha.gopalakrishnan@oracle.com>
    Reviewed-by: Thayumanavar Sachithanantham <thayumanavar.x.sachithanantha@oracle.com>
    Reviewed-by: Dmitry Lenev <dmitry.lenev@oracle.com>

[33mcommit 4f3823e76c3165fbe5abb898587feaaea97e343e[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Thu Aug 25 16:52:45 2016 +0530

    WL#6392 : Upgrade to Transactional Data Dictionary
    
    With the implementation of the new data dictionary, the metadata will
    be stored in the InnoDB tables. For the users to upgrade from the older
    MySQL version(5.7) to mysql-8.0, dictionary tables should be created and
    populated in old data directory from various metadata sources.
    
    When the Mysql-8.0 server comes up, it detects for the presence of
    dictionary tables.  If dictionary tables are not present,
    they will be created in old data directory and populated
    with the metadata. Then the server will proceed with normal start.
    
    If dictionary tables are present, server will proceed with normal startup.
    
    Upgrade Steps for Users
    ------------------------
    
    1. Do a pre requisite check on 5.7 data directory.
    2. Do a [1;31mslow[m shutdown of mysql-5.7 server. Slow shutdown involves setting
       global variable 'innodb_fast_shutdown' to zero before server shutdown.
    3. Start mysql-8.0 server on 5.7 data directory.
       mysql-8.0 server will detect if Dictionary tables are present or not.
       If dictionary tables are not present,  they will be created in old data
       directory. Metadata will be populated in dictionary tables.
       Then server will proceed with normal start.
    4. Execute mysql_upgrade client tool.
    5. Shutdown and start server again with normal configuration. (Recommended)
    
    Reviewed-by: Nisha Gopalakrishnan <nisha.gopalakrishnan@oracle.com>
    Reviewed-by: Thayumanavar Sachithanantham <thayumanavar.x.sachithanantha@oracle.com>
    Reviewed-by: Dmitry Lenev <dmitry.lenev@oracle.com>

[33mcommit 3c0da65188fff295809afd17e3ff188641327608[m
Author: Deepthi ES <deepthi.e.s@oracle.com>
Date:   Tue Aug 23 17:11:33 2016 +0530

    Bug#23297190 : RPL_GTID_SERVER_SIGHUP AND RPL_MASTER_POS_WAIT_AFTER_STARTUP FAILS IN VALGRIND
    
    In the testcases we are restarting the master server which is taking more time
    on [1;31mslow[m platforms like valgrind and slave fails to reconnect with
    "error reconnecting to master '$Master_Port'- retry-time: 1 retries:10".
    
    Fix :
    
    Changed master_connect_retry=30 and master-retry-count=30 on slave. Now the
    slave retries connecting after every 30 secs for 30 times which gives
    sufficient time to reconnect to the master.

[33mcommit 666756d01ccb55d2f023aeeaaa228b796690043f[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon Apr 11 12:05:30 2016 +0200

    Bug#23081045 RPL_SHOW_SLAVE_HOSTS USES TOO LOW SLAVE-NET-TIMEOUT VALUE
    
     - slave fails to connect to master due to too low slave-net-timeout
       value, occurs on [1;31mslow[mer hosts or when running mysqld in valgrind.
     - fix by removing the low slave-net-timeout value and instead force
       the master's dump thread to wake up and detect that slave
       disconnected by running some dummy DDL.

[33mcommit 8d5c4bc2eba3dc2eeee2822ae847c5559dbe6295[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon Apr 11 12:05:30 2016 +0200

    Bug#23081045 RPL_SHOW_SLAVE_HOSTS USES TOO LOW SLAVE-NET-TIMEOUT VALUE
    
     - slave fails to connect to master due to too low slave-net-timeout
       value, occurs on [1;31mslow[mer hosts or when running mysqld in valgrind.
     - fix by removing the low slave-net-timeout value and instead force
       the master's dump thread to wake up and detect that slave
       disconnected by running some dummy DDL.

[33mcommit 162e016044bae8942479e8bccdba3543f228e74b[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Tue Mar 15 14:32:39 2016 +0100

    Bug#22948828: REFACTOR USAGE OF MY_MICRO_TIME()
    
    Remove redundant calls to my_micro_time() to simplify code
    and reduce the usage of gettimeofdat(). Especially focused
    on code for handling new connections.
    
    sql/conn_handler/connection_handler_one_thread.cc
    - Removed my_micro_time() call. THD::start_utime has just been
      set by THD::THD() => THD::init(). THD::thr_create_utime is
      only needed by connection_handler_per_thread.cc
    
    sql/conn_handler/connection_handler_per_thread.cc
    - Removed my_micro_time() call. THD::start_utime has just been
      set by THD::THD() => THD::init(). Remove THD::thr_create_utime,
      we can use THD::start_utime instead.
    
    sql/event_queue.cc
    - Replaced usage of THD::set_current_time() with THD::set_time().
      THD::set_time() does the same as long as THD::user_time is NULL
      which it is for events. Allows the removal of THD::set_current_time()
    
    sql/events.cc
    - Removed THD::set_time() call. THD::set_time() has just been
      called by THD::THD() => THD::init().
    
    sql/log.cc
    - Removed default argument value for make_iso8601_timestamp()
      for clarity.
    - Reduced critical section of LOCK_logger.
    - Call my_micro_time() directly instead of the unnecessary
      THD::current_utime() wrapper.
    
    sql/log_event.cc
    - Use the existing THD::query_start() function instead of accessing
      THD::start_time directly.
    - Renamed THD::update_server_status() to THD::check_[1;31mslow[m_query()
      since the old name was somewhat misleading.
    
    sql/sql_class.h
    - Removed THD::thr_create_utime, no longer needed.
    - Removed redundant inline keyword, added const where possible.
    - Removed THD::query_start_usec(), not used.
    - Removed THD::query_start_timeval(), no longer needed.
    - Removed THD::set_current_time(), no longer needed.
    - Removed THD::is_valid_time(), code moved to sql_parse.cc
    - Renamed THD::update_server_status() to THD::check_[1;31mslow[m_query()
      since the old name was somewhat misleading.
    
    sql/sql_connect.cc
    - Use THD::start_utime instead of removed THD::thd_create_utime
      (had the same value)
    - Removed call to THD::set_time(). Called by THD::init_for_queries()
      right afterwards anyway.
    
    sql/sql_thd_internal_api.cc
    - Removed THD::set_time() call. THD::set_time() has just been
      called by THD::THD() => THD::init().
    - Removed call to my_micro_time(). Already done by THD::set_time().

[33mcommit 09c624b187aab895105e1256c69d7381f3a1b71b[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Wed Mar 2 09:17:35 2016 +0800

    BUG#22607584 INNODB.ANALYZE_TABLE HAS SOME TIMEOUTS
                 ON WEEKLY PB2 SOLARIS & VALGRIND RUNS
    
    The test is very [1;31mslow[m because we insert 1M rows into a table,
    so that the table size is bigger than innodb_buffer_pool_size.
    We just disable the test on Solaris, and skip the test when
    log bin is enabled.

[33mcommit d6d1e197f0014dd816494624a255af9a171a5e13[m
Author: Catalin Besleaga <catalin.besleaga@oracle.com>
Date:   Wed Jan 27 13:44:20 2016 +0100

    WL#8920: added uuid_to_bin, bin_to_uuid and is_uuid functions
    
    Problem
    =======
    1) The column type binary(16) is extensively used as a compact storage for
    UUID's. But in order to transform the text (human-readable) format into binary
    format, users must use some text manipulation functions like unhex() and
    replace().
    Example:
    unhex(replace('aab5d5fd-70c1-11e5-a4fb-b026b977eb28', '-', ''))
    
    2) in order to do the reverse transformation, from the binary(16) to
    human-readable format, users must use even more text manipulation functions.
    Example:
    insert(
        insert(
          insert(
            insert(hex(uuid_bin),9,0,'-'),
            14,0,'-'),
          19,0,'-'),
        24,0,'-')
    
    3) A valid UUID text must have a certain length and be made up of only certain
    characters. In MySQL there is no simple way to validate text UUIDs.
    
    4) UUIDs version 1 store the time-low at the
    beginning of the string making the index inserts very [1;31mslow[m (since the variations
    between two consecutive generated UUIDs are very high at the beginning of the
    string).
    
    Solution:
    =========
    Introducing three new functions defined like this:
    
    F-1.1: UUID_TO_BIN(arg1) should return valid VARBINARY(16) data for any
    valid UUID-string in <arg1>. All specified UUID-formats should be supported:
    - UUID without dashes, ex 12345678123456781234567812345678
    - UUID with braces, ex {12345678-1234-5678-1234-567812345678}
    - standard UUID, ex 12345678-1234-5678-1234-567812345678,
    uppercase/lowercase letters should be accepted. For all those examples, the
    result should be a string starting with a byte of hex ASCII code 0x12, then
    another byte of code 0x34, etc. The validation will be simple, the version
    number bit will not be check, neither the point in time of the timestamp will
    not be checked. The binary data stored should be in the same order as the text.
    
    F-1.2: UUID_TO_BIN(arg1,arg2) should behave as in F-1.1 if <arg2> is FALSE. If
    instead it is true, the binary data stored should be shuffled so that the time-
    low (first group) and  time-high parts (third group) are swapped. The rest of
    the bytes will remain  in the same order as the text version. This can give
    better indexing as the rapidly-varying part is moved to the right. The function
    assumes that the UUID is v1 without complaining if it's not.
    
    F-1.3: if the function UUID_TO_BIN is called with invalid UUIDs, an error will
    be thrown.
    
    F-1.4: if the function UUID_TO_BIN is called with NULL argument for the UUID
    string, the function should return NULL without any warning/error.
    
    F-2.1 BIN_TO_UUID should return a valid UUID string for the VARBINARY(16) UUID
    provided as argument. It should be in the standard format, with downcase
    letters. The validation will be simple, it will check that the binary data has
    the size 16: the version number bit will not be tested, nor the timestamp.
    The UUID string result should have the same byte-order. This is the inverse of
    UUID_TO_BIN.
    
    F-2.2 BIN_TO_UUID(arg1,arg2) should behave as in F-2.1 if <arg2> is FALSE. If
    instead it is true, the function should return a valid UUID string having the
    time-low and time-high parts swapped back to their original position.The
    function assumes that the UUID is v1 without complaining if it's not.
    
    F-2.3: if the function BIN_TO_UUID is called with invalid arguments, an error
    will be thrown.
    
    F-2.3: if the function BIN_TO_UUID is called with NULL argument, the NULL
    value will be returned without any warnings/errors.
    
    F-3.1: IS_UUID should return TRUE for valid UUIDs. The function will only
    validate that the string is correctly formatted: correct size, if it uses the
    format with dashes- all dashes are in the right place and all the groups have
    the right amount of characters per group, if it contains curly brackets- both
    exists and are in the right place. No other validation is done.
    
    F-3.2: IS_UUID should return FALSE if the argument is not a valid UUID, and NULL
    if the argument is NULL. No warnings/errors will be thrown.

[33mcommit 7cae9b6875e94a8110aacf92c8bcd4a19050699f[m
Author: Satya Bodapati <satya.bodapati@oracle.com>
Date:   Wed Feb 3 17:52:01 2016 +0530

    Bug#22561332 - ASSERT !TRX_COMMIT_DISALLOWED IN ROLLBACK AFTER RECOVERY
    
    Problem:
    --------
    On [1;31mslow[m shutdown, we did not wait for the background rollback thread to
    exit first. The purge thread already exited and the background rollback
    thread tries to do commit(adding undo to purge). This causes assert
    failure.
    
    Fix:
    ----
    On [1;31mslow[m shutdown, wait for background rollback thread to exit first
    and then initiate the purge threads shutdown.
    
    Reviewed-By: Marko Makela <marko.makela@oracle.com>
    RB: 11691

[33mcommit 47eda0636176a9ff1fc9900b45b10cd40045daa8[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Feb 3 09:38:27 2016 +0100

    Bug#22494024, addendum patch.
    
    Make added testcase deterministic by hiding output from
    'select * from ndb_schema'
    
    mysqld might not have connected to the datanodes yet at this time
    if it is '[1;31mslow[m'. Thus, the select may fail. (Whcih was already accepted)

[33mcommit 68d5bce13ab6edac83d168b5dcebfdd2c75436de[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Mon Jan 25 15:08:53 2016 +0100

    Bug#21657078: MYSQL DOES NOT COMPILE WITH VISUAL STUDIO 2015
    
    Post-push fix: The problem was that condition variable
    timeouts could in some cases ([1;31mslow[m machines and/or short
    timeouts) be infinite.
    
    When the number of milliseconds to wait is computed, the
    end time is computed before the now() time. This can result
    in the now() time being later than the end time, leading to
    negative timeout. Which after conversion to unsigned becomes
    ~infinite.
    
    This patch fixes the problem by explicitly checking if we
    get negative timeout and then using 0 if this is the case.

[33mcommit 023dd1e7ef5210548c263bd82b24a64532e33559[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Thu Jan 21 09:52:57 2016 +0100

    Bug#22551595: UPDATE WINDOWSCACHE.CMAKE FOR VS2015
    
    WindowsCache.cmake contains hardcoded results of various CMake
    checks we do during building. This is useful as running these
    tests on Windows is pretty [1;31mslow[m.
    
    This patch updates WindowsCache.cmake now that we have
    switched to VS2015 for 5.8. Since we now have timespec on
    all platforms, our own implementation which was used <VS2015
    is removed. Missing entries in WindowsCache.cmake are also added.

[33mcommit 6de35640d6ac2c6ce6854fb12ceedc6dbaec3693[m
Author: Satya Bodapati <satya.bodapati@oracle.com>
Date:   Mon Nov 30 19:32:27 2015 +0530

    Bug#22157724 - INNODB.MONITOR_RESTART FAILS WITH "UNEXPECTED COUNT"
    
    Problem:
    -------
    Test fails randomly with unexpected count. The unexpected count comes
    from
    
    1. Purge activity from mysql.collations tables (On every startup
       we do DELETE+INSERT into mysql.collations. This causes purge activity
       even after [1;31mslow[m shutdown
    
    2. Persisting AUTO-INC values on log_checkpoint by master thread.
       DDL Statement (CREAT TABLE) inserts into DD tables (mysql.columns
       etc). Since these tables have a AUTO-INC column, the checkpoint can
       can also cause searches into B-tree indexes (see
       dict_persist_to_dd_table_buffer())
    
    Fix:
    ----
    To solve 1), we will use debug way to stop purge and Bug#22284224 is
    raised to solve the un-necesary DELETE+INSERT on every startup.
    
    For 2), we create table before restart. This makes sure that there
    are no inserts in DD tables.
    
    Also a debug assert is added to find threads which access any other
    table than "t1".
    
    Reviewed-By: Marko Mäkelä <marko.makela@oracle.com>
    RB: 11190

[33mcommit f9227441e963f52752566b88860245f01313dd43[m
Author: Anitha Gopi <anitha.gopi@oracle.com>
Date:   Fri Nov 27 10:54:41 2015 +0100

    Bug#22102394     SYSSCHEMA.PR_STATEMENT_PERFORMANCE_ANALYZER TEST STILL FAIL
    ING ON PB2 ON WINDOWS
    
        Disabling the test on windows
    
     17979736    SYS_VARS.LOG_SLOW_ADMIN_STATEMENTS_FUNC HAS OCCASIONAL FAILURES
    ON WIN
    
        Made sys_vars.log_[1;31mslow[m_admin_statements_func experimental on windows
    
    Reviewed-by: erlend.dahl@oracle.com

[33mcommit 347d7ecec81a8d5b6b35e5dd3cbcd77ef9cc52a5[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Oct 29 13:53:14 2015 +0100

    Patch for bug#20957068
    
    NDB : EVENT API POLLEVENTS() MUST ACTUALLY CAUSE POLL OF TRANSPORTERS
    
    This patch lets the client thread do its own transporter polling
    if it has to wait in pollEvents() / pollEvents2(). Thus we are no
    longer dependent of other client threads or the ClusterMgr doing the
    poll for us. This removes a problem where pollEvents were [1;31mslow[m to
    receive events.
    
    Introduction of transporter polling also revealed a problem of
    missing mutex protection in ndbcluster_binlog, this has
    been added as part of this patch.
    
    The 'enum WaitSignalType' has been extended with the 'WAIT_EVENT'
    which is now used as 'tWaitState' when the client is waiting for
    completion of a new epoch. NdbImpl::trp_deliver_signal() has been
    enhanced to wake up a waiting client in this state whenever a
    new epoch is completed.
    
    Implementation of 'the wait' in pollEvent() was moved from
    NdbEventBuffer::pollEvent() to Ndb::pollEvent() where also
    the transport polling now happends a part of calling
    PollGuard::wait_n_unlock()
    
    The above changes made NdbEventBuffer::p_cond obsolete which
    is now removed.

[33mcommit 46ce01a5096f76e9e616d84e775e6a208cb29de4[m
Author: Venkatesh Duggirala <venkatesh.duggirala@oracle.com>
Date:   Mon Oct 26 14:15:10 2015 +0530

    BUG#16666407    BINLOG WRITE ERRORS SILENTLY IGNORED
    BUG#20938915 2PC SUCCEEDS EVEN THOUGH BINLOG FLUSH/SYNC FAILS
    
    Fixing a Pb2 test script failure (rpl_semi_sync_after_sync on
    [1;31mslow[mer machine)

[33mcommit ff13ed0df1039d68839f0a251a52aa963bb910cc[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Thu Aug 27 16:12:54 2015 +0300

    WL#7158 "Move privilege system tables from MyISAM to transactional storage".
    
    Privilege tables now use InnoDB SE instead of MyISAM.
    
    Note that even though we switched to transactional tables user-manipulation
    statements semantics is kept backward-compatible (i.e. MyISAM-compatible)
    when possible. Particularly this means that user-manipulation statements
    which fail due to logic errors after updating some privileges are still
    committed i.e. are partially executed as before. System errors like
    errors from storage engine/OOMs are handled by full rollback as it is
    impossible to handle them in any other way (e.g. think of deadlock error).
    Error handling in ACL code was improved to support this.
    
    We also try to avoid deadlock/lock-wait timeout errors which can occur
    for ordinary DML/InnoDB tables. This is achieved by user-manipulation
    statements/ACL code acquiring strong SNRW and SRO locks on privilege
    tables (i.e. by simulating table-level locking for them).
    
    This task opens path for further improvements in ACL code such as changing
    user-manipulation statements to be fully atomic.
    
    Note that we still allow creation and start up on MyISAM privilege tables
    to simplify upgrades/restoring backups from previous versions.
    
    However, we now require presence of mysql.procs_priv and proxies_priv
    privilege tables in case of upgrade (i.e. one should be upgrading at
    least from 5.5).
    
    In order to support switch to InnoDB privilege tables the following
    auxiliary changes were made:
    
    - Separate SQLCOM_SET_PASSWORD command to handle SET PASSWORD was
      introduced.
    - mtr_system_tables_data.sql was changed to create only 2 root
      accounts instead of 4. Extra accounts which were removed created
      ambiguity for host identification. This ambiguity, which surfaced
      thanks to InnoDB using different row ordering than MyISAM, caused
      many test failures.
    - Since removal of these two root accounts has created problem with
      connecting on Windows for some of the tests, mysqltest and MTR were
      changed to use named pipes as a default connection method on this
      platform (similarly to Unices).
    - Issues with Windows pipe support which were discovered after this
      switch were addressed (e.g. improved use of PFS instrumentation,
      fixed handling of connection termination).
    - Test cases were adjusted to take into account introduction of
      separate SQLCOM_SET_PASSWORD command, switch to pipes on Windows
      and extra account removal.
    - New test coverage for transactional privilege tables was added,
      specifically for handling of logic and system errors with them.
      Also some test cases were adjusted to take into account the fact
      that we now use transactional privilege tables.
    - wait_until_connected/disconnected/_again.inc were adjust to take
      into account switch to pipes and the fact that server start-up
      can now take longer on [1;31mslow[m machines due to InnoDB doing recovery
      on privilege tables.

[33mcommit cbb3f6c0c28ac7716e9c3824ae654b9f97fa1884[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Tue Jul 28 12:19:58 2015 +0100

    Bug#20204854       BACKUP FAILING UNDER HEAVY LOAD EXCEPT WHEN SNAPSHOTSTAR
    Bug#21362380       NDB : LOG MAXDISKWRITESPEEDCHANGES FROM ONE LDM INSTANCE
    
    Background
    
    During normal operation, data nodes attempt to maximise
    the disk write speed used for LCP and Backup while remaining
    within the bounds of the configured MinDiskWriteSpeed and
    MaxDiskWriteSpeed.
    
    In 7.4, the implementation of disk write throttling was
    changed to give each LDM thread an equal share of the total
    budget.  This allows parallel LCP to occur without exceeding
    the configured disk IO budget.
    
    However, Backup is executed by only one LDM thread, and so
    it effectively suffered a budget cut.  This results in
    [1;31mslow[mer time to backup completion, and, if the change
    rate is high enough, can result in failure to backup
    as the Backup log buffer fill rate is higher than the
    achievable write rate.
    
    Solution
    
    This patch adds a new cluster configuration parameter :
    
    BackupDiskWriteSpeedPct
    
    This parameter defaults to 50(%) and can be set between
    0(%) and 90(%).
    
    When a Backup starts, the configured percentage of the
    node's maximum write rate budget will be reserved prior
    to sharing out the remainder of the budget amongst LDM
    threads for LCP.
    
    The LDM thread running the backup will receive the whole
    write rate budget for the Backup, plus its (reduced) share
    of the write rate budget for LCP.
    
    This increased budget makes the disk write rate budget
    behave in a similar way to releases < 7.4.
    
    Additionally, a new node log message has been added which
    appears at the end of a Backup and indicates the high-water-mark
    usage of the Backup log buffer.  This can be an aid to efficiently
    configuring this parameter.
    
    Notes :
    The LDM thread with increased 'budget' is still free to
    assign the budget to LCP/Backup scan/Backup log on a
    first-come-first-served (FCFS) basis, so the bandwidth
    is not guaranteed.
    
    Reducing the budget available to LCP on the other LDM
    threads will [1;31mslow[m the LCP for the duration of the backup.
    This can affect the amount of Redo and Undo log space
    needed.
    
    A separate bug where each LDM thread reported max speed
    changes separately has also been fixed.
    
    Example :
    
    Max write rate = 20MB/s
    Num LDMs = 4
    
    Normal case (no backup):
    
    Each LDM has a Max write rate of 20/4 = 5MB/s
    
    Backup case
    
    Node backup budget = 50% of 20MB = 10MB/s
    Node LCP budget = 20 - 10 = 10MB/s
    Per-LDM LCP budget share = 10/4 = 2.5MB/s
    
    Backup LDM thread budget : 10 + 2.5 = 12.5MB/s
    Other LDM threads budget : 2.5MB/s
    
    Total budget = 12.5 + 2.5 + 2.5 + 2.5 = 20MB/s
    
    Notes :
    
    - 50% default gives similar behavior to previous releases
    - 0% gives current behaviour
    - Increased budget is not guaranteed for Backup log - similar
    to previous releases.

[33mcommit 87dbde022c53d393f24d181ff00e52eb5e30922c[m
Merge: 112025a48f8 5eef003ae44
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri May 15 10:46:34 2015 +0300

    Merge remote-tracking branch 'local/mysql-trunk' into mysql-trunk-wl7170
    
    * local/mysql-trunk:
      Fix Bug#20783098 INNODB_CHECKSUM_ALGORITHM=CRC32 IS NOT BYTE ORDER AGNOSTIC
      Bug#20819189: ASSERT IF .FRM EXISTS BUT NO PARTITIONED INNODB TABLE.
      Bug#20561087 : REPLACE_USER_TABLE() DOES NOT CHECK ERROR WHEN READING FROM MYSQL.USER
      Bug#20819189: ASSERT IF .FRM EXISTS BUT NO PARTITIONED INNODB TABLE.
      BUG#19706455: RESET MASTER SHOULD RESET GTID STATE AND NOT ERROR OUT WHEN BINLOG IS OFF
      Test suite cleanup
      Some cosmetic changes which had been suggested in the review of wl#2489 but had to wait for wl#5275 and wl#7870 to be pushed.
      Test cleanup
      Bug#21074643: SERVER SETS OPEN_FILES_LIMIT UNCONDITIONALLY
      Fix for build failure after pushing a767e483e9496e8427d50f59dfa4842d4895e08a
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Bug#20896539 - A QUERY DIGEST SOMETIMES CONTAIN BACKTICKS AND SOMETIMES NOT DEPENDING ON CS
      Post push cleanup
      WL#8216: Deprecate and remove the sync_frm sysvar
      PB2 failures (valgrind and result mismatch) fixes.
      Follow up patch of bug20734998 for fixing Werror failure.
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20762557, Bug#20697533 : Disabled following tests since they fail very often on PB2: main.explain_for_connection_rqg_json main.explain_for_connection_rqg_trad rpl.rpl_perfschema_applier_status
      Test commit
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      WL#8186: Deprecate conversion of pre MySQL 5.1 encoded database names
      Bug#20980885: ENSURE THAT START/STOP GROUP REPLICATION ALWAYS REQUIRE SUPER PRIVILEGE
      Partial backport from mysql-trunk to mysql.5.7 of Bug#21041451: ENABLE AND FIX ADDITONAL WARNINGS REPORTED BY CLANG in order to fix Clang 3.4 warnings in release build. No new warning options are added in the backport.
      Bug#21074358: SOME NEW 5.7 SOURCE FILES ARE D0S FORMATTED
      Bug #17818062       PERFORMANCE SCHEMA, ISSUE WITH UPPERCASE ROUTINES NAMES, PERFSCHEMA.MISC FAILS
      Bug #17818062         PERFORMANCE SCHEMA, ISSUE WITH UPPERCASE ROUTINES NAMES, PERFSCHEMA.MISC FAILS
      Bug#17832047: Crash in calculate_materialization_costs
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      Added openssl multithreading to client.
      Added openssl multithreading to client.
      Bug#20721087 UPGRADE TO BOOST 1.58.0
      Bug#20734998 FAILING ASSERTION: !CURSOR->INDEX->IS_COMMITTED()
      Bug #21047137 REMOVE -GCC FROM NAME OF SOLARIS PACKAGES/TARBALLS
      Bug#19316063: MAKE MTS WORK WITH RELAY_LOG_RECOVERY=1 WHEN GTID IS ENABLED
      Bug#21062842 : Made i_main.costmodel_plan change experimental.
      Bug# 19823076 : READ OF FREED MEMORY IN MY_MB_WC_SJIS WITH                 SOUNDS LIKE OPERATOR IN SUBQUERY
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      BUG#20743468: ASSERTION `OLD_VALUE >= 1' FAILED. | ABORT (SIG=6) IN GTID_STATE::END_ANONYMOUS_ BUG#20748502: ASSERTION `THD->VARIABLES.GTID_NEXT.TYPE== ANONYMOUS_GROUP' FAILED.
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      WL#7589: Updated the README file.
      Bug#21041451: ENABLE AND FIX ADDITONAL WARNINGS REPORTED BY CLANG
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20753620: DBUG: DICT_LOAD_FOREIGN, HA_INNOPART::CHECK, HA_INNOPART::CREATE_NEW_PARTITION
      Silence rpl.rpl_xa_survive_crash_debug in Valgrind
      Bug#21021894 : UNHELPFUL ERROR FOR MYSQL_SSL_RSA_SETUP WHEN DATADIR DOESN'T EXIST
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      Bug#21021754 - OPTION FOR MAX_STATEMENT_TIME IS MISSING
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      BUG #21063087 - MTR SHOULD PASS --INNODB_UNDO_TABLESPACES VARIABLE AT BOOTSTRAP
      BUG#20921940 DEBUG ONLY-CODE MAY HAVE SIDE EFFECTS IN HA_INNOBASE::
      - Bug#21046781: WHILE TRUNCATE UNDO-TABLESPACE FILE COULD BE CLOSED IN BACKGROUND
      BUG#21041449 ASSERT IN I_INNODB.INNODB_BUG16244691
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug #20445525 ADD A CONSISTENCY CHECK AGAINST DB_TRX_ID BEING IN THE FUTURE
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20835095 CRASH AT CREATE_REF_FOR_KEY IN SQL/SQL_SELECT.CC
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20980217 - TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE DOES NOT SHOW CORRECT INDEX NAMES
      Bug#20923066: SSL AND RSA KEY MATERIAL EXPIRATION SHOULD BE EXTENDED
      Corrected validate_password_strength and export_set functions
      Post push fix for BUG#18731252
      Bug#21046582 GEOMETRYCOLLECTION COLUMNS CAN'T STORE SUBTYPES
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      Fix for PB2 test failure.
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      - Bug#21053486: TRUNCATE_RECOVER FAILING IN MYSQL-TRUNK
      Bug#21021894 : UNHELPFUL ERROR FOR MYSQL_SSL_RSA_SETUP WHEN DATADIR DOESN'T EXIST
      Bug#20705648 - max_statement_time leaks memory on windows Bug#20705642 - max_statement_time: assertion failed: pending || thd_timer->thread_id
      Bug#20996273 ALTER USER REWRITE CAUSES DIFFERENCES ON SLAVE
      Fix to remove data dir reference
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Bug#20987568 - INCREASE STOP TIMEOUT OF COMMUNITY RPM SHUTDOWN SCRIPT /ETC/INIT.D/MYSQLD
      - Bug#21046968 : POSSIBLE RACE IN THE TRUNCATE CODE
      WL#7899: Add the tests that were accidentally omitted.
      WL#7899: InnoDB: Map compressed temporary tables to uncompressed
      Bug#20918881 CRASH WITH CENTROID - INVALID FREE
      Bug#20854952 SHOW GLOBAL VARIABLES RETURN WARNING ABOUT SQL_LOG_BIN BEING DEPRECATED
      Bug#21021670 - MISLEADING WARNING WHEN PER-QUERY STATEMENT TIME IS EXCEEDED
      Bug#20854952 SHOW GLOBAL VARIABLES RETURN WARNING ABOUT SQL_LOG_BIN BEING DEPRECATED
      Bug #20692556 : PREPARED STATEMENTS DO NOT TRACK STATUS LIKE STATISTICS
      - Bug#20023425: EMBEDDED SERVER FAILS TO BOOTSTRAP/START UP WITH   INNODB_UNDO_TABLESPACES=2
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Bug #20376498: MAX_ALLOWED_PACKET ERROR DESTROYS ORIGINAL               DATA
      BUG#20753463 HANDLE_FATAL_SIGNAL (SIG=11) IN __STRLEN_SSE2_PMINUB ON              CHANGE MASTER
      Bug#20507804 FAILING ASSERTION: TRX->READ_ONLY && TRX->AUTO_COMMIT && TRX->ISOLATION_LEVEL==1.
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      BUG#18731252 SLAVES WITH SAME SERVER_ID / SERVER_UUID COMPETE FOR              MASTER CONNECTION
      BUG#20768847 ASSERTION 0 IN HA_INNOBASE::COMMIT_INPLACE_ALTER_TABLE
      Post-push fix for BUG#20470724: SET GTID_PURGED SHOULD NOT ROTATE BINLOG
      Fixed Bug#20145024: WRONG RESULT FOR COUNT DISTINCT QUERY IN DERIVED TABLE
      Bug #20592961  'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381 - post fix
      BUG#20977779 CANNOT IMPORT TABLES CONTAINING PREFIX INDEXES
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Fix to avoid build break
      Bug#20814280 SEVERAL PERFORMANCE SCHEMA UNIT TESTS FAIL
      Bug#20814280 SEVERAL PERFORMANCE SCHEMA UNIT TESTS FAIL
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Test cleanup
      Test cleanup
      BUG#20470724: SET GTID_PURGED SHOULD NOT ROTATE BINLOG
      Bug#20748537 INNODB: FAILING ASSERTION: NODE->PCUR->REL_POS == BTR_PCUR_ON
      BUG#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bugi#20593257 FIREWALL PLUGIN LEAK PINS UNDER SPECIAL CIRCUMSTANCES
      BUG#20949314 PARTITION_HELPER::PH_RND_INIT(BOOL): ASSERTION `0' FAILED
      Fix firewall_qc broken test case when the FIREWALL_PLUGIN variable isn't set. This affected 32bit debian
      Fix firewall_qc broken test case when the FIREWALL_PLUGIN variable isn't set. This affected 32bit debian
      Bug#20963147 DECOUPLE DIGEST SIZE FROM SERVER AND PFS
      Bug #20926253 VALGRIND FAILURE IN INNODB.ALTER_MISSING_TABLESPACE
      - Bug#20023425: EMBEDDED SERVER FAILS TO BOOTSTRAP/START UP WITH   INNODB_UNDO_TABLESPACES=2
      Bug#20963147 DECOUPLE DIGEST SIZE FROM SERVER AND PFS
      Raise version number after cloning 5.6.25
      Raise version number after cloning 5.5.44
      BUG#21023683 FAILURE IN EMBEDDED I_INNODB.INNODB-ALTER
      Follow-up to BUG#20913616 - FIREWALL INTEGRATES BADLY WITH QUERY CACHE
      Bug #20914786 : MYSQL_UPGRADE FAILS WITH SHOW_COMPATIBILITY_56 = OFF
      Bug #20753378 ASSERTION `GTID_NEXT->TYPE != AUTOMATIC_GROUP || THD->OWNED_GTID.IS_EMPTY()'
      Bug #20592961  'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381
      Bug #20592961 'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381
      Bug #20753378 ASSERTION `GTID_NEXT->TYPE != AUTOMATIC_GROUP || THD->OWNED_GTID.IS_EMPTY()'
      Fix for missing test recording and test output differences on Windows.
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Bug#20913616 FIREWALL INTEGRATES BADLY WITH QUERY CACHE
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      BUG#19897405: CRASH WHILE ACCESSING VIEWS IN STORED ROUTINE               AND TABLES ARE FLUSHED
      Bug#20515155 Views: Assertion failed: is_view_or_derived() && is_merged()
      Bug #20987420 PB2 FAILURE OF TEST CASE INNODB_ZIP.INNODB_16K
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      BUG#20007583: THE EVENT_SCHEDULER USERNAME IS NOT RESERVERD.               ALLOWS PROCESSLIST VIEW.
      Windows installer in need of fixing to accommodate for WL#7307
      Bug#20768717: DEBUG BUILD FAILS WHEN USING GCC 5 DUE TO COMPILER WARNING
      post push minor test fix for bug:19887143
      BUG#20768847 ASSERTION 0 IN HA_INNOBASE::COMMIT_INPLACE_ALTER_TABLE
      - bug#20938115: innodb_undo_logs max limit should be downgraded from 126 to 94^
      Bug #20563332 : OPEN_FILES_LIMIT BINARY PUT INTO ./BIN DIRECTORY OF A BUILD?
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      Addendum to the fix for bug #20681412:
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug#20979020 - THE TRX IN DDL SHOULD ALWAYS NOT BE ROLLED BACK
      Bug#20709462: GENERATED COLUMNS NOT PRINTED CORRECTLY IN SHOW CREATE TABLE
      Bug#20583321: CRASH ON PS_THREAD_INFO / SYS USAGE
      Bug #18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Fixed failing test
      Bug#20583321: CRASH ON PS_THREAD_INFO / SYS USAGE
      Bug #19077239 mtr tests fixed.
      Bug#19077239 re-enabling disable tests mysql_secure_installation amd mysql_secure_installation_ssl
      Revert "WL#8462: test_services are plugins serving as examples for how plugin services can be tested with mtr."
      Bug #19887143 : THREAD/SQL/MAIN DOESN'T CHANGE STATE/INFO AFTER STARTUP
      WL#7895 - Add systemd support to server.
      Fixed Bug #20683741 UNZIP REQUIRED TO RUN MYSQL-TEST-RUN.PL BUT NOT CHECKED FOR BY CMAKE
      Bug#20865674-VALGRIND FAILURE IN INNODB.CREATE_TABLESPACE
      BUG#19821087 UPDATES TO INDEXED COLUMN MUCH SLOWER IN 5.7.5
      Fixed Bug #20949226: CAN ASSIGN NON-DEFAULT() VALUE TO GENERATED COLUMN
      rb8590 Fixes to sporadically failing on PB2 rpl_xa_survive_crash_debug
      WL#8462: test_services are plugins serving as examples for how plugin services can be tested with mtr.
      Bug #20681412 MYSQLD --INITIALIZE REFERS TO MYSQL_INSTALL_DB AND BOOTSTRAP
      Bug#20937654 CANNOT BUILD WITH "-DDISABLE_SHARED=ON" FOR CMAKE BECAUSE OF REWRITER PLUGIN
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      Fixed failing tests
      WL#6940 Server version token and check
      Bug #20181776 :- ACCESS CONTROL DOESN'T MATCH MOST SPECIFIC                  HOST WHEN IT CONTAINS WILDCARD
      Bug#20961660 RPL TESTS ARE FAILING WITH INNODB: UNDO TABLESPACES MUST BE READABLE!
      WL#4601: Remove fastmutex from the server sources
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      BUG#20955104: ADD UNIT TEST BINARIES AS OPTIONAL TARGETS WHEN MERGE_UNITTESTS=1
      Bug#19865673 DDL LIKE ADD INDEX IS VERY SLOW IN 5.7.5
      Bug #20294225 - INVALID MEMORY ACCESS
      Bug#20275612  MEMCACHED INNODB PLUGIN BREAKS MYSQL ENTERPRISE BACKUP
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug #18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Bug#19822257: WRONG VALUE PASSED TO --INIT-FILE OPTION CAUSES SERVER HANG
      BUG#20748570  BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      Bug#20515155 Views: Assertion failed: is_view_or_derived() && is_merged()
      Improved the way --print-defaults works.
      Bug#20615597 Assertion !thd->is_error() at st_select_lex::prepare()
      BUG#20960406  NO_PROTOCOL.INC SHOULD BE IN MYSQL-TEST/INCLUDE DIRECTORY
      WL#8165 Use new records per key interface in NDB
      Bug #20683237 BACKPORT 19817663 TO 5.1 and 5.5
      Bug #20275612 MEMCACHED INNODB PLUGIN BREAKS MYSQL ENTERPRISE BACKUP
      Bug#20895852 UNDERSIZED TMP_TABLE_SIZE - ASSERTION OR ERROR 2027 (HY000): MALFORMED PACKET
      Bug#20895852 UNDERSIZED TMP_TABLE_SIZE - ASSERTION OR ERROR 2027 (HY000): MALFORMED PACKET
      Revert "Bug#20683741 fixed."
      Revert "Updated file have_util_uz.inc under Bug Bug#20683741"
      Revert "Fixed Bug#20683741"
      WL#6940 Server version token and check
      Bug #20052580 MISSING MUTEX/LOCK IN ACL_AUTHENTICATION()
      Bug#20318154 : NEGATIVE ARRAY INDEX WRITE V2
      Bug#20952953 RPL.RPL_SLAVE_SKIP FAILS IN VALGRIND
      Bug#20952953 RPL.RPL_SLAVE_SKIP FAILS IN VALGRIND
      Fixed Bug#20683741
      Bug#20937173 CLEANUP GIS_DEBUG USELESS CODE
      WL#6940 Server version token and check
      Bug#20922238: REDUCE HEADER FILE DEPENDENCIES IN MY_SYS.H AND M_STRING.H
      BUG#20889900: UNITTESTS SHOULD START THE SERVER WITH APPROPRIATE OPTIONS
      Bug#20810627 ASSERTION: REC_PAGE_NO > 2 IN IBUF_GET_MERGE_PAGE_NOS_FUNC
      Bug#20748570 BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      WL#8017 Infrastructure for Optimizer Hints
      Fixing the query tipping points
      Modified the test to run only on 64 bit machine
      Revert accidental changes to collections/default.push
      Bug#20927239: MY_TIMER-T UNIT TEST DOES NOT WORK WITH MERGE_UNITTESTS=0
      Bug#20922238: REDUCE HEADER FILE DEPENDENCIES IN MY_SYS.H AND M_STRING.H
      Post push fix for BUG#20431860
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Bug#20748570 BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      Bug#20902791 MYSQLDUMP DUMPS SYS_SCHEMA
      Bug#20782142 PAM tests Fixed
      Updated file have_util_uz.inc under Bug Bug#20683741
      BUG#17259750 - STACK CORRUPTION IN VIO_IO_WAIT ON MAC OS X
      BUG# 20798617 - MYSQL CALLS  EXIT(MYSQLD_ABORT_EXIT) WITHOUT                 SHUTTING DOWN INNODB.
      BUG#20597821 INVALID READ OF BLOB MEMORY FREED IN ::CLEAR_BLOB_HEAP_PART
      Bug#20911624 THE SERVER CRASH WHEN TEST ST_INTERSECTS WITH ST_BUFFER
      Bug #20904893         INNODB: FIX RECENT WINDOWS 32 AND 63 BIT COMPILER WARNINGS
      Bug#20921370: NEW CLANG 3.6 WARNINGS - MUST ENABLE -WNO-UNUSED-LOCAL-TYPEDEF
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Clean up mysql-test/collections
      Enable run of default suites on daily valgrind
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Bug#20903701 FIX VALGRIND WARNINGS IN UNIT TESTS
      WL#8161: Locking service for read/write named locks
      Bug#20789078 innodb: assertion: index->id == btr_page_get_index_id(page)
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug#18486509 ASSERTION FAILED: TABLE->KEY_READ == 0 IN CLOSE_THREAD_TABLE
      WL#8161: Locking service for read/write named locks
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Fix Bug#20618309 ASSERT SLOT1->PAGE_LEVEL == SLOT2->PAGE_LEVEL, BTR_ESTIMATE_N_ROWS_IN_RANGE()
      Bug #20476395 DICT_LOAD_FOREIGNS() FAILED IN COMMIT_INPLACE_ALTER_TABLE
      Bug#20573701 DROP DATABASE ASSERT ON DEBUG WHEN OTHER FILES PRESENT IN DB FOLDER.
      Bug#20573701 DROP DATABASE ASSERT ON DEBUG WHEN OTHER FILES PRESENT IN DB FOLDER.
      Bug#20902600: REDUCE HEADER FILE DEPENDENCIES IN SP* AND EVENT* FILES
      Bug #20883256         INNODB: WARNINGS: NONNULL PARAMETER WILL EVALUATE TO 'TRUE' ON FIRST ENCOUNTER
      Bug#20888417: REMOVE FUNCTION DECLARATIONS WITHOUT DEFINITIONS
      Bug#20814396 PB2 IS SECRET ABOUT WHAT UNIT TESTS IT RUN
      WL#8161: Locking service for read/write named locks
      BUG #20414588 - REMOVE HARD-CODED AIO DISABLE FROM MTR
      Bug#20882432 INCORRECT MERGE_THRESHOLD LENGTH IN SYS_INDEXES AFTER UPGRADE, TRUNCATE, RESTART
      Clarify comment in my_global.h about where and why this header should be included.
      Dummy commit to keep the push hook happy.
      Bug#20856729: QUERY REWRITE: WRONG IFDEF SYMBOL IN SERVICE_PARSER.H
      Bug#20364862 : MYSQLADMIN PASSWORD AFFECTS EXTERNAL AUTH ACCOUNTS
      Bug#20364862 : MYSQLADMIN PASSWORD AFFECTS EXTERNAL AUTH ACCOUNTS
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Bug #19953365 MY_PRINT_DEFAULTS DOES NOT MASK PASSWORDS
      Bug#20752436: INNODB: FAILING ASSERTION: 0 IN FILE HANDLER0ALTER.CC LINE 6647
      BUG#17650326 MYSQLBINLOG PRINTS INVALID SQL FROM RELAY LOGS WHEN GTID IS ENABLED
      Bug#20350989: MYSQLBINLOG CAN'T DECODE EVENTS > ~1.6GB
      Bug#20609063 - STDOUT AND STDERR REDIRECTION ISSUES
      Bug#20752436: INNODB: FAILING ASSERTION: 0 IN FILE HANDLER0ALTER.CC LINE 6647
      Bug#20886222 MOVE THE DECLARATION OF FIL_NODE_T TO A HEADER FILE,              AND CLEAN UP COMMENTS Move the definition of the data structure fil_node_t from fil0fil.cc to fil0fil.h so that diagnostics code outside that module can access information about the files belonging to a tablespace. Also do other cleanup and formatting changes.
      Bug#20888417: REMOVE FUNCTION DECLARATIONS WITHOUT DEFINITIONS
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Test cleanup
      Convert a func comments to new the InnoDB style.
      Non-functional style fixups
      Bug#20872436 MAKE DIST BY MISTAKE COPIES FILES WITH VARIABLE EXPANSION
      Bug#20882345: MOVE CODE OUT OF HANDLER.H
      Post-merge fix for WL#7806: Remove bogus files.
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug#20615023 SIGNAL 11 IN ITEM_FIELD::RESULT_TYPE DURING 1ST EXECUTION OF PREPARED STMT
      Bug#20872436 MAKE DIST BY MISTAKE COPIES FILES WITH VARIABLE EXPANSION
      BUG 20459905 - DEADLOCK OF THREADS DETECTED! 5.7.5, 1 THREAD SQL TESTCASE, SPORADIC, IN IB_LOGF
      Bug#20863042 Stop filling mtr logs with InnoDB page dumps
      Remove a test from the experimental collection.
      Bug#20865407: DBUG_ASSERT(1) MAKES NO SENSE
      BUG#20857756: BUILD NT_SERVC.CC ONCE FOR ALL UNITTESTS ON WIN32
      Clean up the post-commit fix for Bug#20872655 debug instrumentation.
      Bug#20874411 INNODB SHUTDOWN HANGS IF INNODB_FORCE_RECOVERY>=3 SKIPPED ANY ROLLBACK
      Followup fix for BUG#20518099
      Post-commit fix or work-around for Bug#20872655 debug instrumentation.
      Post-merge fix for Bug#20872655 XA ROLLBACK IS NOT CRASH-SAFE
      Bug#20518099 - CLEANUP UNIV_INNOCHECKSUM in innodb code base
      Bug#19363615 : innodb.log_file fails very frequently on windows and solaris. Moved test from experimental to disabled state
      Raised version after tagging 5.1.74 (some commits skipped)
      Bug#20872655 XA ROLLBACK IS NOT CRASH-SAFE
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Bug#20788811 MAX_STATEMENT_TIME: ASSERTION `EXPLAIN_OTHER || UNIT->IS_OPTIMIZED()' FAILED.
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Test cleanup
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES            OF INNODB_CHECKSUM_ALGORITHM
      Bug#20104307 GTID_EXECUTED TABLE COMPRESSION THREAD MAY NOT WAKE UP
      sys_vars.innodb_compress_debug_basic requires P_S to run
      Bug#20859285: REDUCE HEADER FILE DEPENDENCIES OF SQL_CLASS.H AND TABLE.H
      Add daily and weekly collections of tests that shun --parallel.
      Bug#20578834 - INNODB READ ONLY MODE AND NON EXISTENT TMP DIR CRASHES SERVER
      Bug #20809045    BUFFER OVERFLOW IN MYSQL
      Silence rpl_xa_survive_crash_debug in Valgrind.
      Bug# 19573096: LOADING CORRUPTED GEOMETRY DATA INTO A                MYISAM TABLE CAUSES THE SERVER TO CRASH
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES                    OF INNODB_CHECKSUM_ALGORITHM
      Bug#20857979 REMOVE DEPENDENCY ON HANDLER.H FROM PFS_ENGINE_TABLE.H
      Bug#20768820 MAIN.BIGINT TEST FAILS WHEN BUILT WITH GCC 5 IN RELEASE BUILD
      Bug#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bug#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bug#20855853 MDL SUBSYSTEM ENCAPSULATION BROKEN
      Bug#20816223 test fix.
      Remove MCP_WIX
      Remove MCP_WIX
      WL#7806: Add a test case from Viswanatham Gudipati with some cleanup by me.
      Test cleanup
      WL#7806: Relax a test that started to fail due to WL#6205.
      WL#7795 PERFORMANCE SCHEMA, HISTORY PER THREAD
      WL#7795 PERFORMANCE SCHEMA, HISTORY PER THREAD
      Clean up a test case. Use [1;31mslow[m shutdown in order to avoid generating redo log after restart, for processing old undo logs or change buffer records.
      WL#7806: Re-enable a test and work around a problem in WL#6965.
      WL#7806: Add a temporary workaround until WL#7691.
      WL#7806: Temporarily remove the fil_sys_lookup[] for user tablespaces in order to ensure that we are not masking Bug#18645050.
      WL#7806: Add a flat fil_sys_lookup[] array so that fil_spaces_lookup() can avoid acquiring fil_system->mutex when looking up the system tablespace or the undo tablespaces. This is addressing a performance regression.
      WL#7806: Correct some comments.
      Test that no redo log gets generated unexpectedly.
      Rename some tests to comply with new policy:
      Try to get a test to work on Windows.

[33mcommit ca6ecd8229c53b0a139304bf6641cef6e529e61a[m
Merge: b840f9e9e35 2e91bec76f5
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Apr 8 12:35:31 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug #20590548 UNABLE TO LOGIN WITH USER WHOSE PWD CHANGED FROM 5.6.23 MYSQLADMIN IN 5.7.6
      Bug#20726413 : MYSQL_SSL_RSA_SETUP DOES NOT HAVE USER OPTION
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES                    OF INNODB_CHECKSUM_ALGORITHM
      WL#8244 Hints for subquery strategies. Part#2: Add support for SEMIJOIN/_SEMIJOIN and SUBQUERY hints
      WL#8244 Hints for subquery strategies. Part#1: Add optimizer_switch for DuplicateWeedout strategy.
      WL#7696 follow up fix, check return values.
      Fixed bug#20745142: GENERATED COLUMNS: ASSERTION FAILED: THD->CHANGE_LIST.IS_EMPTY()
      Fixed bug#20797941: WL8149:ASSERTION `!TABLE || (!TABLE->READ_SET ||                     BITMAP_IS_SET(TABLE->READ_SET
      BUG#20593808 - CRASH WITH PARTITIONED TABLES + MULTITABLE DELETE
      WL#7696 follow up fix.
      Bug#20788853 MUTEX ISSUE IN SQL/SQL_SHOW.CC RESULTING IN SIG6. SOURCE LIKELY FILL_VARIABLES
      WL#7696 followup - remove unused file
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, rerecord the test
      WL#7696 follow up fix, add INNODB_COMPRESS_DEBUG to the test.
      Bug#20840377 UNITILAISED BYTES REPORTED AT MY_WRITE.C:63
      Fixed failing tests after commit 335a53004313ab5a971cf17dea36f1dc4490db9f MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20755430 COST CONSTANT CACHE MUTEX NOT INSTRUMENTED BY PERFORMANCE SCHEMA
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      WL#7696 follow up fix.
      WL#7696 follow up fix - add INNODB_COMPRESS_DEBUG to the list
      Addendum to bug #20810928: fixed the test to reflect that COM_SHUTDOWN can be a zero-length RPC
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20678411 BROKEN MAKEFILE DEPENDENCY: SQL_YACC.YY AND LEX_TOKEN.H
      Bug #17299181    CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      BUG#20093172 LOG_STATE DECLARED VOLATILE, MISSING MEMORY BARRIERS
      BUG#20042205 RPL_GTID CHECKABLE_RWLOCK DEBUG CODE DOESN'T NEED VOLATILE              LOCK_STATE
      BUG#20042109 MYSQL_BIN_LOG::M_PREP_XIDS DOESN'T NEED TO BE VOLATILE
      BUG#20754369: BACKPORT BUG#20007583 TO 5.1
      Bug #17299181  CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      Bug#20411374:CAN NOT EXECUTE CHANGE MASTER AFTER ERROR OCCURED IN MTS MODE
      Bug#20683741 fixed.
      Bug #20814051 CREATE USER BINLOG EVENTS INCLUDE NEW ACCOUNT KEYWORD
      BUG#20510811 - RQG_ALTER_ONLINE_PART RUN INTO ASSERTION: NODE->ENTRY
      Bug#20279241 - ALTER TABLE XXX CHARACTER SET UTF8, CONVERT TO CHARACTER SET LATIN1 SHOULD FAIL
      Adapt new sql/ha_ndbcluster.cc code to use the new ER_THD() macro
      Remove MCP_GLOBAL_SCHEMA_LOCK patch
      Bug #20810928: CANNOT SHUTDOWN MYSQL USING JDBC DRIVER
      Fixed Bug #20683741.
      Test cleanup
      Bump version to 7.5.0
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20811494 SHOW_COMPATIBILITY_56 = OFF INCOMPATIBLE WITH CONNECTORS
      Bug#20531812: MEMORY CONSUMED QUICKLY WHILE EXECUTING LOOP IN PROCEDURE
      Bug#20683959 LOAD DATA INFILE IGNORES A SPECIFIC ROW SILENTLY UNDER DB CHARSET IS UTF8
      Remove MCP_BUG16021021
      Remove MCP_WIX
      Bug#20313067 CHECK TABLE REPORTS WRONG COUNT FOR SPATIAL INDEX AND OTHER GIS PROBLEMS
      Bug#20124342 MYSQL 5.6 SLAVE OUT OF MEMORY ERROR ? Problem: I/O thread on Slave with master_info_repository=TABLE settings, is leaking memory that leads to Out of memory (OOM) after some time.
      Fix merge error in mysql_system_tables_fix.sql
      Remove MCP tags for BUG16226274
      BUG#20811125 INNODB FTS: FTS_PRINT_DOC_ID PRINTS TOO MANY DEBUG INFORMATION
      Bug#20762059 - innodb_thread_concurrency=1 and queries using intrinsic temp tables, causes hang
      Create an .inc file which does [1;31mslow[m shutdown before restarting innodb in read-only mode.
      Bug#19811953 ENVELOPE() FUNCTION RETURNS INVALID POLYGON Bug#20196720 ENVELOPE(P) RETURNS NULL FOR A NON NULL POLYGON P
      Bug #20544581         ASSERTION: REC_PAGE_NO > (ULINT) 4 - (REC_SPACE_ID != 0)
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 - Fix a merge issue.
      WL#7696 - Fix a merge issue
      WL#7696 - Fix the column ordinatlity. Messed up in a previous merge.
      WL#7696 - Fix a compilation error
      move some compression tests elsewhere until using Win32::API module is approved. Improve error detection, if there is no module, the tests will succeed, not fail as before, but the testing power will be somewhat limited.
      Bumped rpm version for oel due to respin
      Bug#20756770 MYSQL SERVER DOESN'T COMPILE AGAINST OPENSSL 1.0.1M
      Patch for Bug#17162055: SSL.CMAKE SILENTLY CHOOSES BUNDLED YASSL INSTEAD OF ERRORING FOR OLD OPENSSL VER
      Bug#20755346 EXAMPLE SCRIPT IN FIREWALL MISSES WHERE CLAUSE
      Bug#20764521 REGRESSION: FIREWALL USE GENERAL_HOST TO RESOLVE HOST
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      Resurrect unintentionally remove disabled.def file
      Resurrect unintentionally remove disabled.def file
      Bug#20651661 NDBEVENTBUFFER LEAKS GCI_OP
      Remove three files which did not properly remain
      WL#7696 - Make LZ4 decompress safe during recovery
      Remove hack to allow large number of failing tests in mtr.pl
      WL#7696 - Reset the contents of the page to NUL.
      WL#7696 - Use the double write buffer pages for compressed pages.
      WL#7696 - Fix syntax error on Windows.
      WL#7696 - Fix debug assertion.
      mysql-test/include/innodb-compress-utils.inc:   add OSD support to get allocated file size for Windows
      add the result file missing in the previous commit
      Test update:   mysql-test/suite/innodb/t/table_compress.test:     fix one failing case for 32k   mysql-test/suite/innodb/r/table_compress_2.result: make use of new     include files   mysql-test/suite/innodb/t/table_compress_3.test: new test to cover     what was not covered yet, shared tablespaces in particular   mysql-test/include/innodb-compress-verify.inc: common sequence     for compression verification   mysql-test/include/innodb-compress-utils.inc: perl compression     related utilities.     Note: OSD Windows file allocated size is not implemented yet.     The test is still expected to pass on Windows because the allocated     size is forced to the expected value.
      Bug #20536590: BACKPORT BUG #12368204 AND BUG #16953758 TO MYSQL-5.6
      WL#7696 - Code clean up. Ignore table COMPRESSION setting if set to NONE.
      WL#7696 - Minor code cleanup
      WL#7696 - Fix the punch hole size calculation.
      Bug#20712432 AUTOTEST: TESTFK FAIL IN CLEARTABLE WITH 256 REFERENCED ROW EXISTS
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#17775772 POTENTIALLY UNINITIALIZED BUFFER IN NDBOUT::PRINT* PRINTOUT   - print nothing or just empty newline instead of uninitialized buffer   - catch error with an assert in debug compile
      Bug#17775607 POTENTIALLY UNINITIALIZED BUFFER IN VNDBOUT_C PRINTOUT  - print empty newline instead of uninitialized buffer  - catch error with an assert in debug compile  - Mark vndbout_c as static and thus local to implementation Conflicts in copyright:        storage/ndb/include/util/NdbOut.hpp     storage/ndb/src/common/util/NdbOut.cpp
      Remove unused parameter ndbcluster_drop_event()
      Bug#20032381 KILLED_STATE SAVE IN NDBCLUSTER_BINLOG RETRY AT SHUTDOWN DOESN'T NEED TO BE VOLA
      Bug#20014045 MONOTONIC SPELT INCORRECTLY IN NDB CODE
      Bug#20092754:  MYSQLD CRASH (FOUND UNCOMITTED AUTOCOMMIT+RBWR TRANSACTION, COMMIT STATUS 3)
      mysql-test/suite/innodb/t/table_compress_2.test:
      Raise version number after cloning 7.4.5
      Correct MTR command for 64k run. Adiing missing "k".
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      Tetss that use innodb_compress_debug should run against debug server
      Added runs with differnt combination and page size setting for Innodb suites
      mysql-test/suite/innodb/t/table_compress.test:   Fix failure when hole punching is not available.   Now the test will be skipped instead
      Revert accidental bump of server version back to 5.6.23
      Fix a compilation warning in non-debug mode
      BUG#18949230: Removed unneeded ndbassert and fixed printout, also recorded number of real periods
      Added some extra output to ndbapi tests utilities as an aid to hunt down the AutoTest failure 'testBasic -n Bug54986 D2'
      Added log printout about invalidation of REDO log and where log head was found
      WL#6815 Adapt MySQL Cluster to 5.7
      Added autotest files for Mikaels environment, added comments about how to get file system as part of results in autotest, added comment about how to handle older git versions with autotest
      BUG#20546157: Fix problems in START_PERMREQ and START_INFOREQ that hangs node restarts when invalidation of nodes is still ongoing at node restart
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20480035 REMOVE MCP_BUG44529
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disable ndb_rpl_circular_2ch* waiting for Bug20592110
      Disable ndb_addnode_witbinlog waiting for Bug17400320
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75720: Fix platform issues with ndb_dd_dump test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      WL#7696 - Don't print a warning on Windows if SPARSE FILE attribute can't be set
      BUG#20631645: Ensure that SYSFILE->latestLCP_ID is properly up-to-date in the pause LCP protocol
      Fix regression caused by wl#7674 in testBasic -n RefreshTuple T6 D1
      Fix regression caused by wl#7674 in testDict -n Bug13416603 I2.
      Fix for Bug#20408733:
      WL#7696 - Punch hole message is Linux specific.
      WL#7696 - Backport code from mysql-trunk to mysql-5.7
      Followup fix for "Bug20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK"
      WL#6815 Adapt MySQL Cluster to 5.7
      Another follow up fix for "BUG11748566 - MYSQL SHOWS WRONG DEFAULT VALUE FOR PK IF  NOT NULL NOT SPECIFIED"
      BUG#20568586: Fix ndb_cpcd to avoid reading a closed file
      BUG#20567730: Ensure that late arriving LCP_FRAG_ORD with lastFragmentFlag set from new master are handled correctly, correct is to ignore them if such a signal arrives in idle LCP state
      Fix for bug#20538179
      BUG#20546899: Faulty ndbrequire fixed
      BUG#20553247: Fix memcpy overlapping copy issue
      BUG#20553247: Use memmove for overlapping memory copy
      Commit this fix on behalf of Pekka N:
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      BUG#19811871 VERSION NUMBR NOT SHOWN IN LOG WHEN [RE]STARTING 5.6.21 SERVICE WITH SLES11 REPO
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      Updated copyright information
      Bug#20228839: MISSING DATABASE '-D' OPTIONS FOR FEW OF THE HUGO TOOLS
      Re-enable clusterj tests disabled during 7.4.4 release.
      Bug#20593065 MULTI UPDATE RETURNS DIFFERENT DATA WITH ENGINE NDB
      This commit is a followup to the fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_time calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop timeout to be configured).
      Add support for SLES12
      Merge 7.3->7.4
      Merge 7.2->7.3
      Overriding release() function from the DynamicObject class in its subclasses.
      This commit is a fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_time calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop timeout to be configured).
      Reverse order of libraries used when linking the ndbapi examples
      Add small MCP for problem with Partition_handler::get_default_num_partitions
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM: fix test regression
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7549: Fix test case for removed EMPTY_LCP protocol
      BUG#20444078: Removed unneeded log printout
      BUG#20444078: Fix master takeover of COPY_GCIREQ protocol
      WL#6815 Adapt MySQL Cluster to 5.7
      Revert accidental version number change
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20528878 : P_S UNIT TEST IS FAILING
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM
      Temporarily hack mtr.pl to allow a large number of failing tests
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disabling ndb.clusterj and ndb.clusterj_jpa tests for 7.4.4 release.
      WL#6815 Adapt MySQL Cluster to 5.7
      bump version to 7.4.5
      Bump version to 7.4.5
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20281479: Entered eternal loop when starting node in MGM server due to buggy bug fix
      Fix unintentional increase in testsize by a factor of 100 of 'testBasic -n Bug54986'
      BUG#20513571: Introduce MaxSendDelay for large clusters
      Fix failing AutoTest 'testIndex -n NFNR3*'
      BUG#20512063: Moved verbose logging to only be used in verbose mode
      Add missing failure detection for 'testBasic -n Bug54986'.
      BUG#20281479: Ensure that START_ORD is properly sent from management server
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20504971: Fixed restart_info table to provide its output
      WL#6815 Adapt MySQL Cluster to 5.7
      Proper error printouts after reaching NDBT_FAILED in test cases
      Backport fix for BUG#20276462
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Updated to newest version of flexAsynch
      Patch related to bug#18401543
      BUG20308276: Don't use same list for master and participant part of takeover processing
      Fix issue in AutoTest where test are being killed by WatchDog during memory allog in startphase 0.
      BUG20276462: Fixed spelling error in error code
      BUG#20276462: Error code ZNODE_FAILURE_ERROR has no treatment in NDB API, use NODE_SHUTDOWN_ERROR instead
      WL#8148 NDB: Add git support to Autotest
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT
      Bug#20234994 JOINS ARE NOT PUSHED AFTER WL6042
      Revert "Adapt pushed joins to WL#6042"
      Fix for Bug#19053226 AUTOTEST FAIL: TESTSRBANK -N MIX -L 300 -R 15 T1
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) PART III
      Bug#20410087 GCOV COVERAGE DATA FOR NDB KERNEL IS MISSING
      WL#8294 NDB: turn on signal checksum as default
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Disabling mtr tests on 7.1 which fail because SSL certificates have expired.
      Re-recording mtr test result after ssl certificate update
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT Generated new certificates with validity upto 2029.
      Fix test client failure for AutoTest 'testNodeRestart -n ClusterSplitLatency'
      Bug#19785977:  CRASH IN NDBINDEXSCANOPERATION::SCANINDEXIMPL
      Bug#20423898 BAD TEST TESTNODERESTART -N LCPTAKEOVER CAN NOT FAIL.
      Improve ndb_rpl_circular_2ch_rep_status reliability.
      Test was random failing due to matching random binlog junk. Make false matches less likely.
      A little brute force to understand the issues with ndb_rpl_circular_2ch_rep_status
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      Experimental experiment with experimental status.
      A more standard variant of !valgrind.
      BUG#19667566 : PARTITION BY WITH COMMENT LEADS TO MYSQL SERVER REBOOT IN MYSQL CLUSTER
      Sacrifice Valgrind run to improve ndb_rpl_slave_binlog_index reliability.
      Backport of fix for bug#16209645
      Bug#17579998 TEST 'TESTNODERESTART -N GCP -L 1 T1' FAILS DUE TO MYSQLD ABORTED
      ndb_rpl_slave_binlog_index.test
      ndb_types.test contained binary raw data from 'bit' and 'binary' columns.
      Bug #20372169         NDB : INCORRECT STATUS VARIABLES NDB_LAST_COMMIT_EPOCH_[SERVER|SESSION]
      Fix of uncorrect merge (7.2 -> 7.3) of regression fix for bug#19524096
      Fix regression introduced by fix for bug#19524096.
      Fix regression introduced by fix for bug#19524096.
      Fix regression introduced by fix for bug#bug#19524096.
      Improve ndb_rpl_slave_binlog_index.test behaviour under Valgrind.
      Bug#20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK INTEGRATION
      Add some improved debugging to help understand non locally reproducable problems with ndb_binlog_last_commit_epoch testcase.
      This commit is a fix for Bug#19880969 (CLUB FOR 7.1, LINUX-RELEASE, 345 WARNINGS IN BUILD). The fix suppresses these warnings, so that the corresponding square in club becomes green rather than red.
      Bug #19306793         CORE IN NDBAPI WHEN EXTENDED EXTENSION TABLE IS CREATED IN MYSQL 7.4
      Quick fix of corrupted special comment characters. No code change.
      Updated the copyright year in README and welcome message
      Improve garbage collection of clusterj artifacts
      Updating copyright year
      Some copyright fixes to files changed in 2014
      Fixing user visible copyright years
      Fix for 7.4.3 build failures
      Fix for copy right year
      Corrected copyright year by sreedhar
      Updated README and banners to 2015
      bump version to 7.1.35
      pgmanpe pe-dump.diff pgman: dump max page entries bug#18484117 bug#19915761 bug#19958804
      pgmanpe pe-config.diff pgman: configure max page entries bug#18484117 bug#19915761 bug#19958804
      BUG#19480197, BUG#73667, BUG#74945: Ensure Local object has transferred back object to real object before calling recursive function
      Cherrypick fix which removes MCP_WL1735 from 7.4
      Cherrypick fix for bug20009152 from 7.4
      Adapt pushed joins to WL#6042
      Follow up fix for bug#20112981
      Fix for bug#20112981
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - rewrite clean_away_stray_files() to use find_files() direct rather than going via make_db_list(). - The only difference between make_db_list() and find_files() is that the information_schema database is not   return in the list of databases. But it's currently not possible  to create a NDB table in information_schema   and thus there can not be any "stray" tables there either.  - testcase added to ndb_reconnect which shows access denied when trying to create table    in information_schema  - This avoids patching the MySQL Server to make the static make_db_list() function available    to use in ha_ndbcluster_binlog and thus the MCP for make_db_list() and LOOKUP_FIELD_VALUES   can be removed. - Also remove the NDB_WITHOUT_MAKE_DB_LIST which was used for compiling ndbcluster in MySQL Server
      Remove unused TNTO_NO_REMOVE_STRAY_FILES Thd_ndb option
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#19898269, BUG#74594: Fixed wrong order of sending bitmap of LCP participants to ensure that starting node can correctly calculate the lcpOngoing flag for each fragment
      Another addendum patch for bug#20112981, adressing comment from Mikael R.
      Incremental addendum patch for bug#20112981
      Fix for bug#20112981
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#75220: Added option to use 10 and 20 LDM threads (same for NoOfLogParts)
      BUG#20215395: Bug in cluster join protocol
      Added jams to place where data nodes freezes in startup
      BUG#19590336: Preparatory patch adding lots of jam:s to DD code, also a few more more comments added
      Additions to wl#7674
      Bug#18715165, BUG#17069285
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug#20193236 SOME COMPILER WARNINGS BECAME ERRORS AFTER MERGE OF MYSQL SERVER 5.5.41
      Cherrypick from 5.6 : Bug#20009154 - FIX REGRESSION AFTER HA_FLUSH_LOGS() HOOK FOR NDB IS REMOVED.
      Bug 19895502 -  BINARY LOG GROUP COMMIT CAUSES REGRESSION FOR NDB REPLICATION.
      This commit is a followup to WL#8145 (NdbInfo : Per-fragment operations info). That WL introduced an error causing 'testScan -n Bug54945 T1' to fail: short-signal scans crashes because the attrinfo section is not available at the point where the code tries to read it to find the size of the interpreted progam. This commit fixes that by not trying to count program size for short-signal scans and lookups. Since these only happen during online upgrade, they are not important for per-fragment statistics.
      Bug #19992856 MYSQL CLUSTER TRIGGER ON DELETE FALSE POSITIVE
      This commit is a followup to the fix for bug#19976428 ("reports failing with 'out of longmessagebuffer' error"). This commit updates a regression test (testIndex/FireTrigOverload) so that it will expect the right error code (293 "Inconsistent trigger state in TC block" instead of 218 "Out of LongMessageBuffer").
      autotest auto1.diff testBasic -n Bug16834333 : fix dict cache crash
      Bug #19858151         MAKING DATA NODE SELF-EXCLUDE MECHANISM MORE ROBUST
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Updated fix for bug#20113145:
      Follow up to fix for bug#bug#20166585:
      Follow up to fix for bug#bug#20166585:
      This commit fixes bug #19976428 ("reports failing with 'out of longmessagebuffer' error"), and a set of other issues related to the pool of "Fired Trigger" records.
      Bug#17069285 : SEGMENTATION FAULT IN NDB_PRINT_FILE
      Update to recent fix where we failed to close scan cursors at the end of their lifetime.
      WL#7514: Fitted into infoEvent max size and decreased some too wordy log printouts
      Update 'v3' fix for bug#20166585:
      WL#7514: Fixed an incorrect assert
      Fix for various AutoTest 'testIndex ...' crashing due to excessive memory usage.
      Bug#18715165, BUG#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for: - Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT - BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      The AutoTest testcase 'testScan -n Bug54945 T1' crashed as it failed to create a transaction object which was later referred without first checking that it was created.
      Fix for crashing AutoTest: 'testNdbApi -n RecordSpecificationBackwardCompatibility'
      WL#6815  Adapt MySQL Cluster to 5.7
      Fix flexAsynch also in 7.3, backport from 7.4
      WL#7508: Parallelize synchronization of starting nodes with live nodes
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - Test fails since the two new default sql_modes  ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES   are displayed by "show create procedure"  - Update .result file to include the two new default sql_modes(as has been done in similar   places)
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      Experimental fix for several AutoTest which crash with an unreadable stack dump very early in their lifecycle, like:
      Fixed crashing AutoTest testBitfield.
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Cherrypick fix for ndb_memcache out of source from 7.4
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20135403 NDB_MEMCACHE TEST DOES NOT WORK IN OUT OF SOURCE BUILD
      Fixed crashing AutoTest: './testLimits -n ExhaustSegmentedSectionPk WIDE_2COL'
      Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT
      BUG#74594: Fixed a hang in PAUSE LCP protocol when LCP was completed between PAUSE and UNPAUSE
      Removed lots of jam noise from QMGR preventing one from seeing the bugs
      WL#6815  Adapt MySQL Cluster to 5.7
      Revert some junk lines from pfs_upfgrade*.result files
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherry-picked from mysql-5.6.22-release
      Cherry-pick from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-pick from mysql-5.5.41-release
      Added tag mysql-5.6.22
      Added tag mysql-5.5.41
      BUG#74594: Fix missing state update that causes PAUSE LCP protocol to hang
      BUG#74594: Added some more DUMP printouts for PAUSE LCP protocol
      WL#7650: Make atrt work on Mac OS X
      Removed assert / require from NDBT_ResultRow c'tor and rewrote it such that it could be constructed even if the the object is not in 'Retrieved' state.
      BUG#75007: Ensure we wait until master takeover is completed before handle LCP_COMPLETE_REP from LQH and DIH participants in the LCP protocol
      Bug#20029843 7.4.2 REGRESSION: UPGRADE_TRAFFIC FAILURES FOR 7.4 -> 7.3: Fixed incorrect conditional expressions
      Cherrypick fix for ndb_dist_priv.sql from 7.4
      WL#6815  Adapt MySQL Cluster to 5.7
      Cherrypick fix for mysql_system_tables_fix.sql from 7.4
      WL#6815 Adapt MySQL Cluster to 5.7
      Encourage MySQL to treat numeric variables as numbers so that ndb_rpl_conflict_epoch2_extra does not return incorrect results from inequality tests.
      BUG#75007: More work on ensuring that we drop the right signals of the LCP_COMPLETE_REP and LCP_FRAG_REP, a bit tricky to decide, wrote up an analysis in a comment and a fairly simple code based on this analysis
      Cherrypick fixes for ndb_alter_table_online from 7.4
      Remove usage of DEFAULT 0 for TIMESTAMP
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fixed for ndb_update_no_read from 7.4
      Turn "info" off after each section in test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fix for ndb_dd_disk2memory from 7.4
      Add missing enable_query_log comman in ndb_dd_disk2memory.test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75007: Fixed interaction with early master takeover initialisation and handling of failed node in LCP, code in new master
      BUG#75007: Handle side effect of bug fix, there are signals generated by node failure handling that must be allowed to pass through the code as they are required for node fail handling to be done properly
      Apply patch for MCP_BUG19704825to 5.7.5
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#74594: Fix of variable length in message to management server to avoid printing garbage
      BUG#75007: Ensure that we drop LCP_FRAG_REP and LCP_COMPLETE_REP that originates from a dead node. The LCP could potentially be done before this arrives due to node failure handling, these signals are sometimes delayed and thus we need to take care that we can still receive them.
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Assumption that all alive nodes have participated in LCP at close down time caused havoc since we can now be alive and still not have participated in the LCP. So had to move the send of the last LCP_COMPLETE_REP backwards a bit to be able to reuse the m_participatingDIH bitmap to send to.
      remove last NDB_WITHOUT_COLUMN_FORMAT ifdef  - since all versions of MySQL Server which ndbcluster   compiles against now supports "field->column_format" and "field->storage_type" - one NDB_WITHOUT_COLUMN_FORMAT left behind(or reappeared)
      BUG#19795152: Missed essential ptrCheckGuard in upgrade/downgrade situations
      WL#7514: More printouts to log for system restart case
      BUG#18610698: New test case
      BUG19795152: Fix Software upgrade issue
      Add missing delete of Ndb instance created by testcase
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Minor tweak of jamming and of a loop
      BUG#19795217: Checked the LCP state a bit too early
      BUG#74594: Added one more cluster log event
      BUG#74594: Wrong check if LCP is idle when sending UnPause message
      bug#20045455 Improve error reporting for clusterj
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Fixed a compiler warning in new tool
      BUG#74594: Wrote an analysis tool for reading DIH Fraglist files to enable easier analysis of system restart bugs
      BUG#74594: Queued LCP_COMPLETE_REP comes from LQH, not from DIH
      BUG#74594: Fixed a typo bug in an important condition
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Added a new ndbrequire to find problem
      WL#7514: Added a bit more logging of the actual start order signal
      flexBench created its worker threads, flexBenchThread, with a stack of insufficent size. This later caused the threads to crash.
      WL#7509: Add undocumented interface to change Disk Write Speed in LCPs, change isn't persistent over restarts, useful to handle SRs where restarts are too [1;31mslow[m
      WL#7509: Tweaked the adaptive LCP speed parameters to be a bit [1;31mslow[mer in changing
      BUG#74594: Add DUMP_STATE_ORD variant to print pause state to cluster log
      BUG#19795108: Proper fix of node restart status using the new Node Recovery Status module
      BUG#19795152: Handle Partial System restarts
      BUG#74594: Used wrong variable in non-master to decide on pauseAction
      Attempt better "htonll" portability in NDB memcache code
      Fix for bug#19390895
      BUG#74594: Ensure that we drop PAUSE_LCP_REQ signals from master if it concerns a node that already has died
      BUG#74594: Node failure in inopportune time caused crash
      BUG#74594: Decrease amount of useless jam:ing to make bugs more visible
      Bug#19642978: NDB_RESTORE CORES ON BUILT-IN PRIMARY KEY + STAGING BLOB CONVERSIONS ON SPARC
      Fix for bug#20031313  AUTOTEST CASE 'TESTDICT -N GETTABINFOREF' NEVER WORKED FOR >= 4 DATA NODES
      BUG#74594: Turned ndbrequire condition the wrong way, caused obvious crash, added a few more ndbrequires while at it
      BUG#19795152: Also NODE_FAILURE_COMPLETED and ALLOCATED_NODE_ID can be states from where a node fails from DISCONNECT_REP although the node hasn't really started its start yet.
      BUG#74594: Removed buggy ndbrequire, not correct though to possibility of delaying arrival of LCP_FRAG_REP when copying table to disk
      BUG#19795152: NdbTick_Elapsed parameters in wrong order
      BUG#19795152: Added one more acceptable state transition, ALLOCATED_NODE_ID -> ALLOCATED_NODE_ID
      BUG#74594: Missed setting lcp id in COPY_TABREQ, added ints of LCP variables on replica and fragment records, removed init of lcpStatus in INCL_NODEREQ which depended on old fact that we included when LCP was idle, now this is no longer necessary, missed init of m_lcp_start_time in including node in LCP, added a number of log prints
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#19676350 NDB_RPL_CONFLICT_EPOCH SHOWS SCHEMA DIST TIME FAST FORWARD DUE TO EINVAL
      BUG#74594: missed init of c_queued_lcp_complete_rep
      BUG#74594: Handle fromTimeQueue issues with LCP_FRAG_REP
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed stopping of pause properly in master and in non-master
      BUG#74594: Wrong assumption in START_LCP_REQ removed, fix of ndbrequire of COPY_TABREQ counter improved
      BUG#74594: Added new parameters to allocStoredReplica
      BUG#74594: Missed init of fragId and tableId in replica record, wrong assumption about m_participatingDIH in START_LCP_REQ
      BUG#74594: Missed clear of own node in NodeReceiverGroup in sending FLUSH_LCP_REP_REQ
      BUG#74594: Fixed typo
      BUG#74594: Missing inserts into signal table
      BUG#74594: Fixes for wrong assert, missing state update and wrong condition
      BUG#74594, fix for sanity check
      BUG#19795152: Fix a placement new that overwrote the node recovery timers in debug mode, added a bit more debug code and arranged the parameters in some common functions a bit more logically
      BUG#74594: Added missing file CopyTab.hpp
      BUG#74594: Remove need for long wait for LCP to copy meta data to make restart times more predictable and faster
      BUG#74639: Preparatory patch to handle overload bugs that is likely to be caused by higher pressure on LCPs and restarts
      BUG#19795152: Added missing file: NodeRecoveryStatusRep.hpp
      BUG#19795152: Wait for LCP start at node restart, add node recovery status table as well
      BUG#19795217: Remove EMPTY_LCP protocol from master takeover
      BUG#74594: Part 2: Fix a potential LCP stoppage
      BUG#74594: Part 1: Remove a faulty ndbrequire
      BUG#19795029: Improve logging of restarts developed in WL#7514
      BUG#19795108: Fix of node restart status for adapting speed of LCP disk write speed
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug#20007248 NDB NOT FUNCTIONAL ON POWER
      Bug#20007216 FLEXASYNC USES 32BIT MATH, LEADING TO INCORRECT SUMMARY ON POWER8
      Fix regression in AutoTest -n DropWithTakeover T1 introduced by fix for bug#19874809:
      Add missing newline before end of file in AsyncNdbContext.cpp
      Fix build failure in MCP patch for BUG19553099
      bug#20017292 Clusterj logging levels too verbose
      Bug#20009152 FIELD NAME NOT INCLUDED IN WARNING WHEN CONVERTING TO FIXED
      WL#7640  Ndb Active Active Delete-Delete handling
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Fix Club test regressions after backport of bug#19524096:
      WL#7640  Ndb Active Active Delete-Delete handling
      Provide easy way to store documents with no mapping and no schema defined   define new method on session factory: db(database_name) returns db object   db object has properties corresponding to table names     if table does not exist, create the table       if user has not mapped the table, create default table mapping and table       if user has mapped the table, use table mapping to create the table   Operations on session using non-existing table name     will now create the table if it does not exist and user has mapped the table
      Fix bad #ifdef
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Bug #19817817 TFBUFFER::VALIDATE() CONST: ASSERTION `(P->M_BYTES & 3) == 0\' FAILED
      Backport of fix for bug#19524096
      Bug#19999242 DELETEING NDB_CLUSTER_CONNECTION WITH NDB INSTANCES
      bug#19913569
      Avoid segv when closing session factory with sessions still active
      Bug #17592990: DATA MISMATCH BETWEEN C NDB API AND MYSQL CLI.
      Backport of fix for Bug#19724313
      Fix for bug#19880747:
      Fix for bug#19875663
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Fix for bug#19881025:
      This commit is an update of WL#7375 (Ndbinfo: Per-fragment memory usage reporting). Column fixed_elem_free_rows in view ndbinfo.memory_per_fragment is renamed to fixed_elem_free_count to get a more consisten naming.
      Fix for bug#19874809 :
      Added sles11 repo packages
      This commit implements WL#8145 (NdbInfo : Per-fragment operations info).
      Follow up fix for bug#18352514 fixing a build failure.
      Addendum fix for bug#18352514:
      bump version to 7.4.3
      Bug #19875710         NDB : COMMIT ACK MARKERS LEAK @ LQH IN 7.4
      BUG#19815044: Part 4, remove usage of global block variable m_pgman_ptr, it is used for parameter passing, but can in some weird situation in DBTUP it can be reassigned to a value that can cause an inconsistent database.
      BUG#19815044: Part 3, fix such that an aborted insert after a committed delete doesn't lead to that triggers for delete isn't executed by ensuring that delete_insert_flag is properly maintained
      BUG#19815044: Part 1: Improve jamming support to make it easier to read what's going on bug situations
      BUG#19815044: Add test case for it used in autotest
      BUG#19815041: Crash on abort of delete after successful delete on a disk data table
      Add global.fail_connect to test utilities
      Fix ProjectionErrorTest
      Improve error reporting for multidb tests
      big lint-fixing patch
      Fix unified_debug issue with per-file levels for C++ files Remove workaround for this in executable programs
      Converter use in DBTableHandler (fixes freeform tests for ndb)
      Big deglobalization patch. Removes many global variables (but not all).
      Move SQL.create and SQL.drop from test harness into adapters. NDB depends on MySQL for this.
      Enhance closeAllOpenSessionFactories() so it takes a callback & returns a promise
      Fix for bug#19712569
      When using node --harmony and strict mode, DBIndexHandler cannot be forward declared   and still use the function DBIndexHandler(parent, dbIndex) syntax.
      jscrund: add support for B tests with varying size varchar. (Only supported by jscrund_mysqljs crund backend).
      lint globals cleanup
      Fixes restart race causing test timeout in AutoTest 'testDict -n schemaTrans'
      Return an error if writing non-Buffer data to binary columns
      Allow flexible mapping for node.js domain classes
      Fix for bug#18352514
      Fix for bug#19661543
      Remove warning introduced with patch for BUG#19236945
      Bug #19236945 ADDRESSSANITIZER BUG SHOW UP IN NDBRECATTR::RECEIVE_DATA CALLED FROM RESTORE.CPP
      bug#19793475 - NO WAIT FOR EPOCHS THAT HAVE NO DB CHANGES MADE BY THIS NDB THD TO BE IN BINLOG
      Removing the extra blank line from daily-basic-autotest-conf
      Fixed compilation error due to changed file name
      Bug#19267720:  NDB REPLICATION : DO NOT SETUP CONFLICT RESOLUTION FOR EXCEPTIONS TABLES
      formatting
      Docs work
      BUG#19795072: Fix problems related to ndbinfo tables for disk write speed
      BUG#19643174: Fix races in relation to sending TC_COMMIT_ACK and handling of complete of a transaction
      Removed compiler warnings
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000): GOT ERROR 4547 PART II
      Cherrypick from 7.4 (revno 4354): Implement status variables exposing last commit epochs for the server   and each session.
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      BUG#19724313: Handle multiple threads crashing at the same time properly
      Added missing include for previous patch Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Restore computeChecksum to computeXorChecksum that was reverted in patch for Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Merge of Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Refactoring of Packer::unpack in preparation of merging Bug#19582925
      Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      wl#7674-5 fixing errors
      wl#7674-5 fixing errors and compiler warnings
      wl#7674 Backward compatibility/new event api methods
      wl#7675 Introduce state machine for event buffering
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) : GOT ERROR 4547 : 'RecordSpecification has overlapping offsets'
      Applying the patch for regression bug#19582807 for 7.1.33 cluster release
      Improve Query documentation
      Cherrypicked
      Cherrypicked
      Bug #19582807 MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Wl#7639 Ndb Active Active Manageability improvements
      Removed compiler warnings
      WL#7642 Ndb Active Active Binlog Read Tracking: Removed uninitialized data to remove valgrind warnings
      Work on new README
      Bug #17257842     EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #19766167         NDB : VALGRIND REACHABLE MEMORY IN NDB_RPL_CONFLICT_EPOCH_TRANS
      Fix new log printouts - Use log functions of component in favour of sql_print_information - Break long lines
      In-Progress Packaging / Documentation improvements
      Iterate array rather than for/in
      Add mynode.closeAllOpenSessionFactories()
      Windows testcase fix attempt
      Follow up patch for WL#7953 Transporter handshake retry
      WL#7642 Ndb Active Active Binlog Read Tracking: Updated result for ndb_rpl_conflict_read_tracking test case to reflect new conflict counters
      WL#7640  Ndb Active Active Delete-Delete handling
      bump version to 7.3.8
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      bump version to 7.2.19
      bump version to 7.1.34
      Bug#19692387 PORT FIX FOR BUG 18770469 TO MYSQL CLUSTER 7.3
      Added ndb_print_file man pages
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug#18487960: SIG 11 on delete with index merge
      Follow up patch for WL#7953 Transporter handshake retry
      Follow up patch for WL#7953 Transporter handshake retry
      Patch 2 for WL#7953 Transporter handshake retry
      Patch 1 for WL#7953 Transporter handshake retry
      Patch 3 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 2 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 1 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      adding checksum to the cnf file
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19600834  late code review comment
      Bug #19600834 DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH)
      Bug #19600834         DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH) ...
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3
      Bug #19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3  - revert the reverted
      Bug#19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Change from mysql-5.6 to build Oracle Linux 7 RPMs
      WL#7640  Ndb Active Active Delete-Delete handling
      WL7640 Add delete-delete conflict count
      Adding ndb_print_file to spec file
      Repush of WL#7544 after 7.4.1 clone tag.
      bump version to 7.4.2
      Set version 7.4.1
      Revert WL#7544, not to be included in DMR 7.4.1
      Reorder member initializer list for thr_data to follow initialization order. This removes compiler warning introduced in fix of Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      WL#7544: Optimisations of the NDB API receiver thread in various manners. 1) Optimising method to unpack field data from TRANSID_AI signal, 2) optimised handling of trp_client locking check, 3) reorganised code in NDB API receiver thread for better performance and more readability, 4) Optimisation signal receive handler
      BUG#19451060: One more step on the way to understanding commit ack markers
      Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Fix for bug#19559313, call getPerformStateString() with a nodeId arg instead of a state argument
      Fix for Bug#19552283 :
      Update documentation to remove useProjection       Update Session.js to remove useProjection
      BUG#19552349: Avoid stack overrun by removing endless recursive call
      BUG#19451060: Further refinements of bug fix, previous ndbrequire revealed a race that could cause multiple REMOVE_MARKER_ORDs to appear for the same transaction, added long comment about this specific race variant. Left a part of the ndbrequire still to ensure that this only happens when receiving REMOVE_MARKER_ORD sent by API through TC_COMMIT_ACK and not through API failure handling
      Bug #18703922  DUMP-CODE ACTIVATED DEBUGGING ON WATCHDOG OVERLOAD ISSUES
      Bug #17730825  NDB API: POSSIBLE LEAK OF CONNECTION OBJECTS
      BUG#19524096: Converted many 4009 errors to temporary error 4035, ensured APIs can use new data nodes sooner, fixed some wrong error categories, removed no longer used errors, fixed some anomaly in communication towards the API, small improvement of restart printouts, should give autotest a much better chance to get rid of redness
      Bug #17893872         ER_DUP_ENTRY WHEN INSERTING TO AUTO-INC COLUMN ON SPARC MULTI-MASTER SETUP
      BUG#19451060: Added more descriptive information at crashes related to commit ack markers, changed name of noFired to numFired for clarity, added possibility to put last in free list to aid crash printouts
      Fix for spelling error in Win32 code
      WL#7509: Introduced more configurability of disk write speeds and added a number of new ndbinfo tables to track this new more adaptive behaviour
      WL7845: More and safer ways to print records in DBTC
      BUG#19451049: Missing call to prepareTUPKEYREQ from handle_lcp_keep, added comment about handle_lcp_keep
      bug#19124970 - PB WITH POLLEVENTS , NDBEVENTS
      Backport from 7.2
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      The Bug was due to m_out object used in NdbOut operator was not initialized/set to the output stream. Added an ndb_init() call to initialize it to output stream. Added an environmental variable $NDB_PRINT_FILE to give path to its binary in  mysql-test/mysql-test-run.pl file. Added a unit test and its result file.
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      bug#19031389 bugfix.diff bug fix
      bug#19031389 bugtest.diff bug test
      BUG#19513967: Fixed missing init of longer bitmask
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      BUG#17703874
      Bug#19202654: NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      Bug #18354165         16723708 CHANGED EVENT CATEGORY VALUES
      Clusterj windows CMakeList error
      Clusterj support for autoincrement columns http://wl.no.oracle.com/worklog/NDB-RawIdeaBin/index.pl?tid=8027
      Added missing logging.properties
      Clusterj improve maven handling for out-of-source builds
      Bug#18875137: NDB_RESTORE STILL MISSING SOME TYPE CONVERSIONS
      Fix for Bug#19414511:
      Bug #19236785  ADDRESSSANITIZER BUG IN ~NDB_MOVE_DATA Bug #73311      AddressSanitizer bug in ~Ndb_move_data
      Bug #19235428  ADDRESSSANITIZER BUG IN DATABUFFER2<SZ,POOL>::IMPORT (DBDICT::ALTERTABLE_PARSE) Bug #73310     AddressSanitizer bug in DataBuffer2<sz,Pool>::import (Dbdict::alterTable_parse)
      Bug #19235170  ADDRESSSANITIZER BUG IN DBUTIL::GET_SYSTAB_TABLEID Bug #73308  AddressSanitizer bug in DbUtil::get_systab_tableid
      Bug#11764704 : Exclude missing tables when restoring a backup  - added an option "--exclude-missing-tables" to ndb_restore tool  - when enabled, the missing tables will be added to the    exclude tables list before starting to restore.  - updated test cases accordingly.
      Revert fix merged in from 5.5.39 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert fix merged in from 5.6.20 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert quick fix for dtrace problems in release tree. New fix in CMake files will be merged in from 5.6.20.
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      This commit is a followup to the one below. It changes the fragment_num colum (in memory_per_fragment), such that it gives the global frgament id rather than a node-local sequence number. That way, it is possible to see where each fragment (or some replica of it) is located. This is consistent with the output from 'ndb_desc -pn -d <database> <table>.
      Bug 19028487 NPE when scanning rows with blob or text columns
      More fixes for bug#19053226
      Fixes for bug#19053226
      More fixes for bug#19053226
      bug#18410939 - MEMORY LEAK AT EVENT BUFFER ALLOCATING A DUMMY EVENT LIST WHEN INCONSISTENCY
      Bug #17184024         ERROR 4 IN LIBNDBCLIENT.SO.6.0.0 (3-7474573041)
      bug#19122346 fix3.diff FK use full name PP/CC/name + debug
      bug#19122346 fix2.diff fix test error from 7.3 r4203 FK_Bug18069680
      bug#19122346 fix1.diff FK use full name PP/CC/name
      ndb - RSS-DynArr256
      A new ndbapi test case: testNodeRestart -n DeleteRestart.
      Bug #18731008    NDB : AVOID MAPPING EMPTY PAGES DUE TO DELETES DURING NR Bug #18683398    MEMORY LEAK DURING ROLLING RESTART
      Bug #19193927         TC TAKEOVER TAKES TOO LONG CAUSING MANY PROBLEMS
      ndb
      Bug#19193756 MTR GENERATES TOO LONG SOCKET PATHS
      Merge from mysql-cluster-7.2.17-release
      ndb
      use primitive types
      Include stdlib.h for malloc() and free()
      Compiler issues on some Windows platforms
      Add debug to trace bug#18411034 - CRASH IN NDB-SHARE
      Updated the list of tables to be deleted after running ndb clusterj tests Added new test and the model to build specification
      Merge latest nodejs-adapter from 7.3 to 7.4
      Unconditionally disable dtrace for rpm, barfs on Oracle dtrace
      Remove superfluous -master.opt file for the removed test case ndb_mt_recv.
      Unconditionally disable dtrace for rpm-oel, barfs on Oracle dtrace
      correcting copyright headers
      Fix issues with Read/Modify/Update of NDB VO objects containing blobs.
      All NDB read results (including those containing BLOB and TEXT columns) are now ValueObjects.
      Fix bug of using Persistent<T>(x) rather than Persistent<T>::New(x)
      work on support for NdbRecord-backed ValueObjects which contain TEXT or BLOB columns.
      More TEXT tests for NDB
      less debugging output at end of test run
      Fix composition value checking
      Implement bufferForText and textFromBuffer in C++.
      rawNdbDefaultvalue does not require a full-fledged Node Buffer
      let compiler supply default destructors
      Another attempt to fix crashing bug in BlobHandler
      Expose the string encoder statistics in NdbTypeEncoder.cpp to JavaScript.
      Move v8 calls from worker thread to main JS thread
      Support TEXT columns with character set UTF-8 or ASCII. Other charsets (which require recoding) are not yet supported.
      A test file that does not export a test case now causes a warning rather than an error.  This should make it a little easier to develop new tests.
      Column Metadata API provides charsetName rather than charsetNumber
      Fix apparent bug in calculating size requirement of UTF-8 buffer
      Restore compatibility with node-mysql 2.0.0
      Fix crash on stub commit / stub rollback
      update cmake & gyp build lists
      Finish read & write BLOB implementation for NDB adapter
      Implement connection pooling for mysql adapter
      Fix tests that do not close session after running test
      Improve error reporting for connecting to database
      Add suggestion to user to maximize performance of updates
      Improve spi test error reporting
      Succesful insert into BLOB column
      Add BLOB column to stringtypes test suite & confirm that existing tests pass with a mapped (but unused) BLOB field.
      Test that storing a non-BLOB in a BINARY column gives error SQLState 22000
      Use Error SQLState 0F001 "Bad BLOB" (actually a "Locator Exception") if value intended for a BLOB column is not a Buffer.
      Initial implementation work on BLOB support for NDB adapter.
      Refactor connection handling to prepare for connection pooling
      WL#7626 Implement many-to-many relationships for Document Composition
      Don't try immediate startTransaction() unless using async api.
      Keep a single usedOperationSets array rather than one per DBSession. The array is at file scope in NdbTransactionHandler. It does not grow past 4000 elements (a literal constant). Underlying DBOperationSet native objects are freed when the wrapper is placed in the recycler array.
      Disable mysql tests for now
      Attempt to recycle DBOperationSet wrappers
      wrapPointerInObject and unwrapPointer take a v8::Handle<T> rather than a v8::Local<T>
      Improve error reporting for relationships that are null or undefined
      Test a slightly different approach to V8 wrapping
      Minor refactoring in NdbOperation
      Remove the use of "proto" in DBTableHandler
      Refactor DBTableHandler.getFields() into a simple case getFields() and a separate more complex getFieldsWithListener(). Removed the resolveDefaults option which was always set to false.
      Improve error reporting for ProjectionTest
      Improve error reporting for ProjectionTest
      Improve error reporting for test failures
      Compiler error
      Stub out NdbSession.buildReadProjectionOperation in hopes that test suite will run.
      WL#7626 Composition Implement support for one-one, one-many, and many-many relationships. Replace useProjection with implementation for find (projection, key).
      Rather than having a JavaScript wrapper for Record::setNotNull(), implicitly call setNotNull() when writing a data value in encoderWrite().
      Don't use a startTransaction() hint for unique key operations.
      In JsValueConverter for pointer types, if the JavaScript value is Null, represent it as a null pointer.
      Remove what little was left of NdbTransaction_wrapper.cpp
      move ENABLE_WRAPPER_TYPE_CHECKS define into adapter_global.h
      portability fix
      Update source file lists for gyp & CMake
      Add option free-percent
      New design for scans. This removes the previous wrapper for NdbScanOperation and ScanImpl.cpp file and consolidates all scan functions into ScanOperation. Expected: start 416 tests, pass 413, fail 2, skip 1.
      fix wrappers for boolean types
      In test driver allow --stats=query, e.g. --stats=spi/ndb/DBSession
      Add HandleScope to all toJS() template functions just to be safer from enigmatic V8 memory leaks. Provide toJS() and isWrappedPointer() specializations for type bool.
      Refactor NDB execute. This patch renames PendingOperationSet to DBOperationSet, and makes DBOperationSet the "point of contact" for JavaScript calls to begin and execute transactions. All t_basic tests now pass.
      New SPI test   begin transaction; delete (execute NoCommit) ; read deleted row ; commit.
      Minor bug fixes for passing SPI tests
      Major JavaScript logic changes in NDB adapter. NdbTransactionContext, NdbSession, NdbOperation, and NdbConnectionPool are adapted to use the call flow of DBSessionImpl and DBTransactionContext rather than the native call flow of the NDB API.
      This commit includes various small C++ fixes. The next commit includes major JavaScript logic changes. With these together, spi tests pass.
      Add new connection property ndb_sesion_concurrency Refactor initialization of NdbSession and connecting of the new NdbSession to its impl.
      Adapt DBDictionaryImpl to use DBSessionImpl rather than Ndb.
      Revise protocol for registering a transaction open / closed. Use only two calls, registerIntentToOpen() and registerTxClosed(). Always make these calls from JavaScript main thread.
      NdbTransaction is no longer wrapped for JavaScript
      Template class NativeCFunctionCall_4_
      DBSessionImpl
      Adapt AsyncNdbContext to be aware of DBTransactionContext
      executeAsync() on AsyncNdbContext is no longer wrapped for JavaScript; use executeAsync() on DBTransactionContext instead.
      Refactor DBOperationHelper:  it now takes a DBTransactionContext rather than an NdbTransaction.  it now defines operations, but does not prepare them.
      Rename addOperation() to getNextOperation()
      Add two new classes, DBTransactionContext and DBSessionImpl. These will free the JavaScript code from the start/prepare/execute cycle of Ndb and NdbTransaction, eventually allowing operations to be performed with fewer scheduled async calls and therefore less overhead.
      Adapt DBOperationHelper to the KeyOperation / ScanOperation change.
      Bug fix where the do_close flag must be associated with the transaction rather than its parent Ndb object.
      Refactor Operation and DBScanHelper into two classes called KeyOperation and ScanOperation.
      This change alllows Ndb::startTransaction() to run as a sync call in the main JS thread if we suspect that it will not block.  As a proof of concept, this allows you to measure the performance with this change; but it should not be used as-is, because the guess could be wrong, which would cause the main thread to block waiting for network I/O.
      In the common case where an async method call returns int zero, try to optimize away creating a new JavaScript value.
      Slight change to the compatibility strategy for some libuv changes.
      Combine NdbTransaction execute() and close() into a single scheduled call whenever execType is Commit or Rollback.  This saves the scheduling cost of running the close() call by itself.
      Various fixes for lint.
      Remove old stats API.
      Use new stats API in MySQL code.
      Use new stats API in NDB code.
      Revised statistics API. Now each module owns, at file scope, its own stats object. The module registers the stats object with the global statistics, which keeps a reference to it in the stats tree. This should reduce the cost of keeping statistics to practically zero.
      Delay after (rather than before) the first test iteration. This allows V8 to compile all the JavaScript code before dtrace starts running. High dtrace profiling rates caused the first iteration to run very [1;31mslow[mly and skewed the profile towards compile times rather than run times.
      Optional delays both before & after jscrund run
      jscrund: add option to delay start of test run
      Add useProjection to Session   this function specifies a projection to be used for find and query operations
      Minor work on DBDictionaryImpl Contain the code for handling NdbDictionary 3-part/slashed/names in DictionaryNameSplitter class. Reformat patch indent width from 4 spaces to 2 spaces. buildDBForeignKey() takes only the fk* and must use its own private name splitter.
      Error 23000 when attempting to set a non-nullable column to null.
      Restore table which should not have been removed from test suite
      Add support for foreign key metadata
      update literal mapping test for schema
      Fix errors in test case & misc. lint errors.
      Check in test case where one operation in a batch has a data type error. This test fails for both NDB and MySQL.
      Expose NdbRecordObject::prepare() to JavaScript. This is a step towards fixing handling of encoder errors for value objects.
      Write a negative value to an unsigned int field of an NDB Value Object. This test causes the test suite to hang forever.
      Run executeAsynch() in JS main thread rather than a UV worker thread. We had seen higher latency using async ndbapi vs. sync ndbapi, but this change eliminates most of that difference.
      unused table in test suite
      Fix for compiler warning in TimestampWriter validity check
      NDB encoding-related changes.  (1) distinguish between 22003 numeric value out of range and HY000 for "value is not numeric"  (2) provide a (hopefully) faster path to encoderWrite and encoderRead by wrapping them as methods of Record
      Refactor error handling
      Attempt to optimize encodeKeyBuffer() for single-column indexes
      Fix reporting of session factory if no mappings
      Remove JsValueAdapter in loader; it is no longer needed.
      This fixes the failing "timestamp 1969" test case for NDB. Test still fails with MySQL.
      Fixes for lint test failures
      Test & fix NDB handling of encoder errors for numeric types
      Tests for numeric types
      This renames the integraltypes suite to numerictypes and adds stub tests for float, double, and decimal columns
      Test for particular expected errors rather than simply for operation failure
      Add decimal support in NdbTypeEncoders Remove JS wrapper for decimal utilities from ndb_util
      Encoders for NDB integer values: if the fast integer conversion fails, try a [1;31mslow[m one, then test whether the result is legal.  This should allow writing valid JS string and float values to int columns.
      Improve handling of errors from NDB data type encoders
      Improve handling of data encoder errors in the ndb adapter
      fix sql_mode for mysql adapter
      Implemented test cases
      Stub out new test cases for data type casting
      If MySQLTime.valid is set to false, NdbTypeEncoder will reject the value.
      Allow user to set sql_mode in mysql adapter with a default of STRICT_ALL_TABLES
      Change console.log to udebug.log in issues/2014-03-18Test
      Add shell script to manage regular runs of jscrund
      Adapt loader to use new Batch.getOperationCount() api
      Batch: use getOperationCount()  rather than getSize()
      Add Batch.getSize() method
      Add test case for issue of bad data type for column
      Fix typo
      Add test case for issue where a TableMapping created from a literal mapping could not be used to perform operations (fixed in bzr 686).
      Changes to sample data loader after code review with Craig. This version still has lots of untested features (and combinations of features) but it can load CSV data and random data.
      Bug fix creating TableMapping from object literal
      WL#7578 Replace usage of ndb_schema_share->key with hardcoded text
      WL#7578 Move subscriber bitmaps to NDB binlog component
      WL#7578 Move the g_nodeid_map to Ndb binlog thread
      WL#7578 move clearing of subscribed to binlog thread
      WL#7578 Always expect everyone to ack the schema op
      WL#7578 Refactor schema distribution code
      WL#7578 Refactor schema distribution code
      ndb
      WL#7578 note about nodeid from global cluster connection
      WL#7578 Don't use ndb_schema_share from ack_schema_op
      Initial checkin of JavaScript data loader tool
      Remove windows line endings from ndb_schema_object.cc
      Try to reduce overhead of stats.incr() calls
      Remove the error handling in jscrund_mysqljs backend which duplicates work performed in the jscrund frontend.
      Add conditional guards around udebug log messages.
      Add conditional guards around udebug log statements.
      Improve error reporting while loading mysql node_module
      The node-mysql driver by default constructs an Error object in order to get a stack that includes the user's call to Query. This can be a performance bottleneck.

[33mcommit 018ee48617052b3806f4dd22d93242c2aa16ae3b[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Apr 8 11:52:14 2015 +0300

    Test the mysys's lockfree hash
    
    It is impossible to implement the ut_hash_interface_t using the mysys's
    lockfree hash because it requires the called to maintain a "pins" object
    on his own, in addition to the hash table itself. Thus, messup the neat
    implementation in the unit test.
    
    This commit is for historical reference and is going to be reverted.
    
    The mysys's lockfree is about 10 times [1;31mslow[mer than the implementation in
    ut0lock_free_hash.h for the workload in the ut0lock_free_hash-t unit
    test.
    
    WL#7170 InnoDB buffer estimates for tables and indexes

[33mcommit b39caef1b599cc51ac9457b2375efea6a22dba1f[m
Author: Satya Bodapati <satya.bodapati@oracle.com>
Date:   Tue Mar 31 16:59:26 2015 +0200

    Create an .inc file which does [1;31mslow[m shutdown before restarting innodb in
    read-only mode.
    
    Fix all tests to use "include/restart_innodb_read_only.inc"
    
    Reviewed-by: Marko Makela<marko.makela@oracle.com>
    RB: 8487

[33mcommit 664c40fc64a134a6125b5c7ecfbb4f9ae7f41236[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Mon Mar 23 11:33:44 2015 +0100

    Bug#20754445: REDUCE CURRENT_THD USAGE
    
    Getting a valid THD pointer from the current_thd thread local storage
    macro is [1;31mslow[m, it obscures dependencies and makes it harder to
    change the threading model.
    
    This patch reduces the usage of current_thd and replaces it with
    thd as an explicit function argument.

[33mcommit d64a0f110f1c7aeb181d823e2c6c4529c7a093fd[m
Author: Marko Makela <marko.makela@oracle.com>
Date:   Mon Nov 10 15:04:59 2014 +0200

    Clean up a test case.
    Use [1;31mslow[m shutdown in order to avoid generating redo log after restart,
    for processing old undo logs or change buffer records.
    
    Use common header files for killing the server.
For keyword fast:
[33mcommit 8f5ed27f8b0d85717c54d23fcca0e47cf9409b80[m
Author: Rahul Sisondia <rahul.sisondia@oracle.com>
Date:   Wed Feb 14 10:08:43 2018 +0100

    Bug#27400095 unable to access 8.0.4 server after starting on top of 5.7.20
    database
    
    Description
    -----------
    
    This problem was reported while starting the server after in-place upgrade from
    the mysql 5.7.20 to 8.0.4 version when --skip-grant-tables options is enabled.
    
    During the investigation it turned out that starting from 8.0.4 default
    authentication plugin has been changed to chaching_sha2_password due to that
    problem could also be seen if the 8.0.4 server is started with
    --skip-grant-tables options then 8.0.4 client is unable to connect to it.
    
    This happens because caching_sha2_password client/server plugins require more
    packets interchange after the client has sent the scrambled password to the
    server.
    If server after receiving the scrambled packet from the client detects that
    --skip-grant-tables option is specified then it simply returns the CR_OK packet
    while client is expecting either [1;31mfast[m_auth_success or
    perform_full_authentication packet.
    
    Fix:
    ---
    We now let the server continue the handshake process with the decoy user instead
    of returning the CR_OK packet to the client.  This required the following
    changes -
      1. Added a check in the find_mpvio_user method so that if acl_users are null
         then it can directly create the decoy user.
      2. In the parse_client_handshake_packet, let it set the user as decoy user
         and continue.
      3. We set the MPVIO as SUCCESS in case of --skip-grant-tables therefore if
         any error is encountered after this point will set in the diganotic_area
         as well. We must reset that in --skip-grant-tables is specified.
         This problem was discovered while testing the fix with PIPE protocol.
    
    Unrelated changes - Fixed typos in the doxygen comments.
    
    Testing :
    -------
    
    Added two new test files.
    skip_grant_protocols -
        Executes on non-windows platforms. Verifies the fix with socket protocol.
    skip_grant_protocols_windows -
        Execute on windows platform. Verifies the fix with the shared-memory
        and named-pipe protocols.
    
    Verified the scenario reported in the bug manually as it is not possible to
    write MTR test for it. Neither it is required.
    
    branch - mysql-8.0-itch  ( In progress)
    push id: 12544359
    Date - 2018-02-08 09:40:17 
    
    Report from loki-
    
    Unit tests: 100% tests passed, 0 tests failed out of 46
    --------------------------------------------------------------------------
    The servers were restarted 1458 times
    Spent 24259.968 of 1409 seconds executing testcases
    
    Completed: All 5828 tests were successful.
    
    1663 tests were skipped, 147 by the test itself.
    
    Review :
    --------
    RB#18698

[33mcommit 0b20dc85a796960fc0af94cd1e4394fdfd9be091[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Thu Nov 30 18:19:31 2017 +0100

    Bug#21616914: MAIN.JSON_CONVERSIONS TIMES OUT IN VALGRIND
    
    Strip down the time it takes to run the json_conversions test by
    making the following changes:
    
    1. Remove some redundant verification of the contents in the test
    tables. The contents of a big test table were dumped, and multiple
    regular expressions were used on the output to filter out
    non-deterministic data. The input data were validated in different and
    cheaper ways later in the test, so this partly redundant and very time
    consuming step was removed.
    
    2. A table that was populated by doing multiple INSERT INTO ... SELECT
    DISTINCT FROM statement that used subqueries to avoid inserting
    duplicates into the table, is now instead populated using a single
    INSERT INTO ... SELECT statement where the SELECT is a big UNION. This
    single statement is much [1;31mfast[mer than the original ones.
    
    3. Add an index on a column that is used for equality predicates in
    many of the queries in the test.
    
    4. Testing of the JSON comparator with the != operator is removed. The
    non-standard != operator is indistinguishable from the standard <>
    operator after the query has gone through the tokenizer, so it doesn't
    contribute to the code coverage.
    
    5. Some parts of the test, which use multiple SELECT statements to
    work through a table, are rewritten to use a single SELECT statement
    which goes through the entire table in a single pass.
    
    6. Remove some duplicated SELECT statements that tested conversions
    from the YEAR data type.
    
    Change-Id: I55bfbea5fad26cf0feba717ef32b43c4e88c1457

[33mcommit 81ac35c8e87557c4667b7527f22384c348612411[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Sun Jan 28 21:52:01 2018 +0800

    Bug #26003816   RPL.RPL_IPV4_AS_IPV6 AND RPL.RPL_IP_MIX FAILS SPORADICALLY ON PB2
    
    Problem
    =======
    When the mysql_socket_bind(...) call on the INET socket fails, mysqld
    reports an error like that:
    [ERROR] Can't start server: Bind on TCP/IP port: No such file or directory
    [ERROR] Do you already have another mysqld server running on port: 3310 ?
    [ERROR] Aborting
    
    Analyse
    =======
    Sometimes the port is not released [1;31mfast[m enough when stopping and
    restarting the server. This happens quite often with the test
    suite on busy systems. Retry to bind the address at some intervals
    during the port timeout. The value of port timeout is 0 in the
    test. So the above error happens if the first try of binding the
    address fails.
    
    Fix
    ===
    To fix the problem, set --port-open-timeout to 10000 to allow
    enough retries to bind the address.

[33mcommit b35783e8893098467034a2a86cfacb0ba601b812[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Thu Dec 7 16:47:29 2017 +0100

    Bug#24734971: PERFORMANCE REGRESSION IN DICTIONARY OPERATIONS DUE TO METADATA LOCKING
    
    Problem: Search in, and traversal of lists of MDL_tickets maintaned by
    MDL_context becomes time consuming when the number of tickets is
    large.
    
    Fix: 1) Add a hash index for the lists to get O(1) lookup based on MDL_key.
         2) Keep track of the subset of the tickets for which
            MDL_context::materialize_[1;31mfast[m_path_locks already have been
            called, and only iterate over tickets added since the last
            call.
    
    Change-Id: Ie4275d02ee310112ba36614a9c331da869d71d18
    (cherry picked from commit e531c8a23f8edeb4b845be98b5cfa29d46bc7af1)

[33mcommit 1543ad8f62d3f3287215c8a51cd4e600cf2faeca[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Thu Dec 7 16:47:29 2017 +0100

    Bug#24734971: PERFORMANCE REGRESSION IN DICTIONARY OPERATIONS DUE TO METADATA LOCKING
    
    Problem: Search in, and traversal of lists of MDL_tickets maintaned by
    MDL_context becomes time consuming when the number of tickets is
    large.
    
    Fix: 1) Add a hash index for the lists to get O(1) lookup based on MDL_key.
         2) Keep track of the subset of the tickets for which
            MDL_context::materialize_[1;31mfast[m_path_locks already have been
            called, and only iterate over tickets added since the last
            call.
    
    Change-Id: Ie4275d02ee310112ba36614a9c331da869d71d18

[33mcommit 1eaa5b14f8ffb340e4d03fc5c39d4008a4e3a48f[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:52:52 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    Refactor TransporterRegistry::prepareSendTemplate() to:
    
    - Use likely/unlikely to annotate the [1;31mfast[m path through this rather performance
      critical code.
    
    - Remove duplicated check for 't == NULL'
    
    - Remove extra check for 'insertPtr != NULL' when 'resend work'.
      Instead return SEND_OK where we already know that getWritePtr suceeded .
    
    No functional changes.

[33mcommit 9a11f17af92696bebd97f9914500aea55fcf6114[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:52:52 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    Refactor TransporterRegistry::prepareSendTemplate() to:
    
    - Use likely/unlikely to annotate the [1;31mfast[m path through this rather performance
      critical code.
    
    - Remove duplicated check for 't == NULL'
    
    - Remove extra check for 'insertPtr != NULL' when 'resend work'.
      Instead return SEND_OK where we already know that getWritePtr suceeded .
    
    No functional changes.

[33mcommit 0ecc3a1b6b61f2f39a5d23932e8e713d5e74f588[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:52:52 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    Refactor TransporterRegistry::prepareSendTemplate() to:
    
    - Use likely/unlikely to annotate the [1;31mfast[m path through this rather performance
      critical code.
    
    - Remove duplicated check for 't == NULL'
    
    - Remove extra check for 'insertPtr != NULL' when 'resend work'.
      Instead return SEND_OK where we already know that getWritePtr suceeded .
    
    No functional changes.

[33mcommit 490f74226dc225baa30c319e29783ad377b9865f[m
Author: Kristofer Älvring <kristofer.pettersson@oracle.com>
Date:   Mon Nov 27 13:58:38 2017 +0100

    Bug#27136346 SYSBENCH CONNECT TEST SHOWS -95% REGRESSION FOR NON-ROOT VS ROOT USER
    
    None root users experienced a 95% drop in CPU utilization due to a cache
    which is suppose to store database privileges based on user name and host
    for [1;31mfast[m acccess. The cache is protected be a rw lock that needs to be
    checked for success. The check was inveresed so it reported failure
    on success and vice versa which ultimately caused the performance issues
    as a write lock was taken 10 times for every connection attempt by
    internal system processes.

[33mcommit 7d2c3123537e8809a69fb9fe469d895aa32cd1fc[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Thu Nov 2 10:22:25 2017 +0530

    WL #10194: Read table and fragment id from extent in extra PGMAN worker in UNDO log applier
    
    Remove most of the need to query PGMAN from rep thread and instead
    use TSMAN data structures. This will remove the need to fetch the page
    in two different threads.
    There will be some extra interaction with TSMAN that requires mutex
    protection instead, but this should be much [1;31mfast[mer.

[33mcommit 244ee7e798e3416eccd1cf5d6f69b9c403f04eab[m
Author: Sunny Bains <sunny.bains@oracle.com>
Date:   Wed Nov 15 15:50:18 2017 +0000

    WL#8619 - Retry page header check if [1;31mfast[m path fails.

[33mcommit d0bfaf67997b48ac4e72e90630c0d49c15a66cc5[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Sep 28 12:57:22 2017 +0200

    Bug #26940369: REWRITE THE MEM_ROOT
    
    Streamline and optimize the MEM_ROOT.
    
    This totally rewrites the MEM_ROOT, though keeping mostly the same conceptual
    idea (arena allocation). Important changes:
    
     - The MEM_ROOT now keeps only one free block, greatly simplifying the logic.
       In particular, we no longer have to traverse a linked list of free blocks
       (with associated cache misses) for allocations that do not fit, and we don't
       need complex heuristics for when to give up a block.
     - Preallocation was hardly ever used and caused a fair amount of complexity,
       so it has been removed.
     - We now have a [1;31mfast[m path for Alloc() that can be inlined, so that the common
       case is simply an easily predictable branch and an add.
     - New blocks increase exponentially in size instead of linearly (similar to
       how std::vector and other STL classes operate), so that we can guarantee
       O(1) calls to malloc (assuming constant-sized allocations).
     - A lot of other complexity with questionable use has been removed.
     - The interface is now C++, with C wrappers being kept for compatibility.
     - Since the code is effectively all new, it now follows Google coding style.
    
    Note that this changes the meaning of the “query_prealloc_size” variable somewhat.
    It now sets (up to a constant factor, currently at 5) how much memory is
    allowed to be kept in the MEM_ROOT between queries, instead of actually
    preallocating memory at the start. However, the end-user effect should be
    pretty similar.
    
    sysbench tests show somewhere between 1% and 6% qps increase.
    
    Change-Id: Ia1b5c7b87833dac0d2ef51e0c00399c818f51eb0

[33mcommit 97dae79ac976bdf70c60670639db3f275ca80b3c[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Oct 12 14:09:31 2017 +0800

    Bug#26950659 - INITIALIZE FAILED:: NODE->N_PENDING == 0 FIL_CLOSE_ALL_FILES
    
    During shutdown, after confirming there is no IO from buffer pool,
    there is still some pending IO on DD tablespace found when closing all files.
    The cause is that after checking buffer pool, server still tries to
    write back dynamic metadata, which results in new IO for DD tablespace.
    This may happen when [1;31mfast[m shutdown.
    
    To fix this, write-back of dynamic metadata should be done first,
    before checking buffer pool, if it's a [1;31mfast[m shutdown.
    
    RB: 17616
    Reviewed by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit d034d7599c4b1da891fe7ae9510b14adb7ee49df[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Aug 11 12:45:49 2017 +0200

    WL #10343: Switch GCC optimization from -O3 to -O2
    
    Change from -O3 to -O2 everywhere, for smaller binaries, [1;31mfast[mer compile
    times and generally better performance. Mark some performance schema
    function as force-inline to avoid performance regressions, since they
    are important to inline despite being big.
    
    Change-Id: Ib7603f141e6974aeed7e4fde2ef7697864231ae3

[33mcommit 7133c6e8e070f9f7238a251bded49acccdcd1606[m
Author: Xing Zhang <xing.z.zhang@oracle.com>
Date:   Thu Jun 29 17:56:12 2017 +0800

    Bug #25426632: STRNXFRM RUNS SLOWER WHEN TAILORING RULE CONTAINS CONTRACTION
    
    Strnxfrm function of uca collations needs to search for contraction's
    weight. Current implemenation of contraction uses array to store info of
    contraction, which is slow.
    
    Fix:
    Build trie of contraction. Each node of the trie contains one character of
    contraction. It is [1;31mfast[mer to find a contraction in the trie and return its
    weight pointer.
    
    This patch also changed mysql-test/std_data/Index.xml, because one
    tailoring rule defined in this file is wrong. There will be no rule: "A
    <<<< A".
    
    BM_Hungarian_AS_CS         3750 -> 2405 ns/iter [+ 55.9%]
    BM_Japanese_AS_CS          4058 -> 2562 ns/iter [+ 58.4%]
    BM_Japanese_AS_CS_KS       5242 -> 3464 ns/iter [+ 51.3%]
    
    Change-Id: I611068aebed42168c93c1e94f874b3749ba3a531

[33mcommit d057432973264cae4d7b59760b3fbde857e55673[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Sat Jul 29 13:48:02 2017 +0200

    Follow-up to WL#10972 : stabilize test
    
    One machine is pb2 is [1;31mfast[m, and executes the 1000 iterations so [1;31mfast[m
    that we don't have time to switch to the other connection and kill.
    So, allow more iterations, like before wl#10972 was implemented.

[33mcommit 203fab8b238111df749a54e2c2087271a2aa2cba[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Thu Jun 8 07:57:38 2017 +0200

    Test main.information_schema-big runs [1;31mfast[mer after WL#6599, which
    implements I_S tables as a system view over DD. So, the test case
    does not suite for big-test. This patch moves the remaining
    single test case from information_schema-big.test to
    main.information_schema.
    
    Change requested by Erlend/Anitha.
    Reviewed by Praveen.

[33mcommit f5b9c862610f06b78acb375349ddb10ac7ea18b3[m
Author: Xing Zhang <xing.z.zhang@oracle.com>
Date:   Thu Jun 1 23:32:00 2017 +0800

    WL #10818: Add utf8mb4 accent sensitive and case insensitive collation
    
    Added accent sensitive and case insensitive collation, utf8mb4_0900_as_ci.
    The implementation is simple and straightforward because all the logic of
    multi-level collation is ready when we added accent and case sensitive
    collations.
    
    The benchmark result of this collation is slower than accent and case
    insensitive collation but [1;31mfast[mer than accent and case sensitive collation,
    just as expected.
    
    BM_MixedUTF8MB4             161 ns/iter     0.77 GB/sec
    BM_MixedUTF8MB4_AS_CI       336 ns/iter   377.31 MB/sec
    BM_MixedUTF8MB4_AS_CS       486 ns/iter   261.13 MB/sec
    
    Change-Id: I1e44b7008c7746ee111dd8738d22591c7a36eec4

[33mcommit e5ec2919f7917236adbb9e7d9778a7d817c2d677[m
Author: Lars Tangvald <lars.tangvald@oracle.com>
Date:   Wed May 24 14:05:24 2017 +0200

    Bug#25825833    MYSQL SERVICE IN UBUNTU 14.04 LACKS USER PRIVILEGE VALIDATION AND LOOPS
    
    If the user running the service script isn't allowed to read pidfile or datadir,
    fail [1;31mfast[m.

[33mcommit 2288193f49c99d7f4d9b691e0deecde390244a51[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon May 8 15:51:57 2017 +0200

    Bug #26023259: REMOVE RADIXSORT
    
    We have special-purpose radixsort code for sorting very short keys, but in
    practical testing, std::stable_sort is now [1;31mfast[mer. Thus, we can just remove the
    radixsort.
    
    Verified by sorting 50000 short records on an int field, which is supposed to
    be the poster child for radxisort; removing the code was 10–20% [1;31mfast[mer in
    single-threaded testing, and there should be yet more in multithreaded, due to
    less cache pressure.
    
    Change-Id: I4f17344e7a744ee56df42cabd9423d9ccd93ba9c

[33mcommit e9f46d9955790dd0515919a3d7af82e63609e63b[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Apr 6 13:26:54 2017 +0200

    WL #9554: Varlen keys for sorting multibyte String values
    
    Unicode collations are sorted by means of variable-length weight strings.
    In the worst case, these weight strings can become very long; for instance, for
    utf8mb4_0900_as_cs, we have a strnxfrm_multiply of 24, which is interpreted as
    every byte in the input string becoming potentially 24 bytes. In other words, a
    VARCHAR(100), which can be up to 400 bytes, gets 9600 bytes allocated for
    filesort, even if it just contains a simple 'a' (which is six bytes of weight
    plus some level separators). The default set max_sort_length=1024 masks this
    problem somewhat by truncating the weight strings, at the cost of incorrect and
    unpredictable sorting when sorting strings that actually need long weight
    strings.
    
    This worklog aims to introduce variable-length keys when sorting NO PAD collations.
    (PAD collations still need to be fixed length, because they are conceptually
    extended to infinity.) It builds on the existing semantics for sorting JSON using
    variable-length keys; it doesn't try to replace strnxfrm with strnncollsp,
    which would also be an interesting avenue, but can happen in a later worklog.
    
    Benchmark results are good: For the distinct_ranges sysbench test
    (using varchar keys), we win about 12% on a single core of Skylake 3.4 GHz.
    For a test of sorting 300000 first names in a VARCHAR(100) COLLATE utf8mb4_0900_as_cs,
    setting max_sort_length=65536 (so that both sides actually sort based on all
    their data, as opposed to truncating the key and sacrificing correctness),
    it is about five times as [1;31mfast[m, due to vastly less spilling to external storage
    (77 versus 11075 chunks). This is even though external storage in this case is
    RAM, not disk -- if it would be actually hitting the SSD, the difference would
    be even more dramatic.
    
    Change-Id: I4704ffe04e2b35db47e5c1b98160f6a4731157ad

[33mcommit 11d6946141358eecbe8b09856a14e99910f6bbca[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Fri Apr 21 09:52:09 2017 +0300

    Removed old partitioning DDL implementation which is no longer in use.
    
    After WL#8971 "Deprecate and remove partition engine" and WL#9559
    "InnoDB_New_DD: Support in-place ALTER PARTITION" code implementing
    "[1;31mfast[m" partitioning DDL ([1;31mfast[m_alter_partition_table() and related
    functions) became unused.
    
    This patch removes this dead code (including DDL_LOG implementation
    used by it) as a follow-up to the above WLs.

[33mcommit 03d9c51607d3ad9e53bf47c5b6faf1c883358523[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Feb 8 15:58:07 2017 +0100

    WL #10354: Make Unicode 9.0.0 and newer collations NO PAD (revert whitespace changes)
    
    Revert the changes that we did to whitespace weights as part of Bug #24823885;
    now that we are NO PAD, we don't need these changes to make pad behavior [1;31mfast[mer.
    This brings us back in line with default DUCET ordering.
    
    Change-Id: I44e4a87a7c87ef9a89aaf62272d879b85a15713e

[33mcommit b1f35740f886c6a87c047cd4b51c9ae64e4ae91f[m
Author: Craig L Russell <craig.russell@oracle.com>
Date:   Fri Mar 17 18:08:41 2017 -0700

    WL#9545 Clusterj automatic reconnect on cluster failure
    
    clusterj-api/pom.xml.in
      change Java version from 1.5 to 1.7
    
    clusterj-api/src/main/java/com/mysql/clusterj/Constants.java
      add property com.mysql.clusterj.connection.reconnect.timeout
      add default for com.mysql.clusterj.connection.reconnect.timeout
    
    clusterj-api/src/main/java/com/mysql/clusterj/Session.java
      make Session extend AutoCloseable for easier application error handling
    
    clusterj-api/src/main/java/com/mysql/clusterj/SessionFactory.java
      add method reconnect(int) to allow application to reconnect
      add method reconnect() to allow automatic reconnect
      add method currentState() to report state: Open, Closed, Reconnecting
    
    clusterj-core/pom.xml.in
      change Java version from 1.5 to 1.7
    
    clusterj-core/src/main/java/com/mysql/clusterj/core/SessionFactoryImpl.java
      implement new methods from SessionFactory
      add internal flag to getSession to allow reconnect to get a session when not open
      implement reconnect thread to asynchronously reconnect to cluster
        while reconnecting, getSession will throw a ClusterJUserException
    
    clusterj-core/src/main/java/com/mysql/clusterj/core/SessionImpl.java
      add multiple checks for session closing to fail [1;31mfast[m on cluster disconnect
    
    clusterj-core/src/main/java/com/mysql/clusterj/core/query/QueryImpl.java
      add multiple checks for session closing to fail [1;31mfast[m on cluster disconnect
    
    clusterj-core/src/main/java/com/mysql/clusterj/core/store/Db.java
      add method assertNotClosed(String)
    
    clusterj-core/src/main/resources/com/mysql/clusterj/core/Bundle.properties
      add new messages for reconnection
    
    clusterj-test/pom.xml.in
      change Java version from 1.5 to 1.7
    
    clusterj-test/src/main/java/testsuite/clusterj/AutoCloseableTest.java
      new test case for Session AutoCloseable semantics
    
    clusterj-test/src/main/java/testsuite/clusterj/ReconnectTest.java
      new test case for application-initiated reconnect
    
    clusterj-tie/pom.xml.in
      change Java version from 1.5 to 1.7
    
    clusterj-tie/src/main/java/com/mysql/clusterj/tie/ClusterConnectionImpl.java
      add a wait for Ndb objects to close after marking them closing
    
    clusterj-tie/src/main/java/com/mysql/clusterj/tie/ClusterTransactionImpl.java
      use new assertNotClosed method
    
    clusterj-tie/src/main/java/com/mysql/clusterj/tie/DbImpl.java
      implement new assertNotClosed method
      allow closing an ndb object even if a transaction is open
    
    clusterj-tie/src/main/java/com/mysql/clusterj/tie/DbImplForNdbRecord.java
      implement new assertNotClosed method
    
    clusterj-tie/src/main/java/com/mysql/clusterj/tie/NdbRecordImpl.java
      add multiple checks for session closing to fail [1;31mfast[m on cluster disconnect
    
    clusterj-tie/src/main/java/com/mysql/clusterj/tie/NdbRecordScanOperationImpl.java
      add multiple checks for session closing to fail [1;31mfast[m on cluster disconnect
    
    clusterj-tie/src/main/java/com/mysql/clusterj/tie/NdbRecordScanResultDataImpl.java
      add multiple checks for session closing to fail [1;31mfast[m on cluster disconnect
    
    clusterj-tie/src/main/resources/com/mysql/clusterj/tie/Bundle.properties
      add new messages
    clusterj-tie/src/test/resources/clusterj.properties
      add new default property connect timeout for running tests
    
    clusterj-tie/src/test/java/testsuite/clusterj/tie/AutoCloseableTest.java
      new test case for AutoCloseable
    
    clusterj-tie/src/test/java/testsuite/clusterj/tie/ReconnectTest.java
      new test case for application reconnect
    
    clusterj-unit/pom.xml.in
      change Java version from 1.5 to 1.7
    
    storage/ndb/config/type_JAVA.cmake
      change Java version from 1.5 to 1.7

[33mcommit 8406d69d57cb1dd13d7b525a94f1f8d964fd0544[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Feb 8 15:58:07 2017 +0100

    WL #10354: Make Unicode 9.0.0 and newer collations NO PAD (revert whitespace changes)
    
    Revert the changes that we did to whitespace weights as part of Bug #24823885;
    now that we are NO PAD, we don't need these changes to make pad behavior [1;31mfast[mer.
    This brings us back in line with default DUCET ordering.
    
    Change-Id: I44e4a87a7c87ef9a89aaf62272d879b85a15713e

[33mcommit dbd2ca2f6e14ce0ec19e743eb2f0cfdb20df6573[m
Author: Joao Gramacho <joao.gramacho@oracle.com>
Date:   Tue Nov 1 06:45:39 2016 +0000

    WL#8599: Reduce contention in IO and SQL threads
    
    (Step 1)
    
    This patch introduces the changes for the worklog related to making the
    slave applier to read from the relay log the same way the Binlog_sender
    does from the binary log (using a non-shared IO_CACHE, not relying on
    relay_log->LOCK_log even when reading from the "hot" relay log file).
    
    Made binlog_end_pos atomic
    --------------------------
    
    The MYSQL_BIN_LOG::binlog_end_pos was refactored to be atomic. From the
    Binlog_sender perspective, this would allow reducing the amount of
    acquirements of binary log LOCK_binlog_end_pos. With this change, both
    binary and relay log files readers don't need to acquire the
    LOCK_binlog_end_pos while checking if they reached the end of the "hot"
    log file. They only need to acquire the LOCK_binlog_end_pos if they are
    actually going to wait for updates.
    
    @ sql/binlog.h:
    
    Renamed binlog_end_pos to atomic_binlog_end_pos and made it atomic.
    
      At MYSQL_BIN_LOG::get_binlog_end_pos(), we removed the assertion of
      the ownership of the LOCK_binlog_end_pos, as it is not necessary since
      the binlog_end_pos variable become atomic.
    
    @ sql/rpl_binlog_sender.cc
    
      Refactored Binlog_sender::wait_new_events() to first check if the
      waiting is really needed (if the binary log was not updated before the
      acquirement of LOCK_binlog_end_pos), and then, only if the
      Binlog_sender really need to wait, to enter the
      stage_master_has_sent_all_binlog_to_slave stage and wait for updates
      on the binary log.
    
    Removed the relay_log->LOCK_log usage from next_event()
    -------------------------------------------------------
    
    The slave applier was refactored to not use the relay_log->LOCK_log when
    reading events from the "hot" relay log file.
    
    It was introduced a new PSI mutex key(MYSQL_RELAY_LOG::LOCK_log_end_pos)
    to instrument the LOCK_binlog_end_pos on relay log files.
    
    @ mysql-test/suite/perfschema/r/relaylog.test
    
      The test case had to be recorded again after the addition of the new
      PSI mutex key.
    
    @ sql/mysqld.(cc|.h)
    
    Introduced the new "MYSQL_RELAY_LOG::LOCK_log_end_pos" PSI mutex key.
    
    In order to make the slave applier to not need to acquire
    relay_log->LOCK_log when reading from the "hot" relay log, the slave
    receiver now opens the relay log with the same flags as the binary log
    files are opened: O_WRONLY. This lead to many changes in the slave code.
    
    The rli->ign_master_log_* that relied on relay_log->LOCK_log are now
    being protected by the relay_log->LOCK_binlog_end_pos. This change was
    needed in order to guarantee that the updated generated by events
    ignored by the receiver thread would be properly handled by the applier
    regardless relay_log->LOCK_log.
    
    @ sql/binlog.h
    
      The MYSQL_BIN_LOG::update_binlog_end_pos() function is now also used
      for the relay log. The function was refactored to remove the relay log
      specific code. It also has now a new parameter to tell the function
      that the LOCK_binlog_end_pos was acquired by the caller.
    
      MYSQL_BIN_LOG::after_append_to_relay_log(),
      MYSQL_BIN_LOG::append_event() and MYSQL_BIN_LOG::append_buffer()
      function were renamed to MYSQL_BIN_LOG::after_write_to_relay_log(),
      MYSQL_BIN_LOG::write_event() and MYSQL_BIN_LOG::write_buffer()
      respectively.
    
    @ sql/binlog.cc
    
      At MYSQL_BIN_LOG::open(), there is no distinction about binary or
      relay log with respect to the flags used to open the IO_CACHE.
    
      At MYSQL_BIN_LOG::open_binlog(), replaced a check for the relay log
      that were relying on the io_cache_type to actually check if it is a
      relay log or not.
    
      At MYSQL_BIN_LOG::after_write_to_relay_log(), replaced the function
      used to get the actual file position from my_b_append_tell() to
      my_b_tell(). Also, instead of just signaling the update of the log
      file, this function also cleanup the rli->ign_master_log_name_end.
    
      MYSQL_BIN_LOG::write_event() is now asserting that the log_file.type
      is WRITE_CACHE.
    
      MYSQL_BIN_LOG::write_buffer() is now asserting that the log_file.type
      is WRITE_CACHE. It is also calling my_b_write() to write the buffer
      into the relay log IO_CACHE.
    
      MYSQL_BIN_LOG::wait_for_update_relay_log() was refactored to rely on
      LOCK_binlog_end_pos instead of LOCK_log and was moved to
      sql/rpl_slave.cc as wait_new_relaylog_events().
    
      At MYSQL_BIN_LOG::close, replaced a check for the relay log that were
      relying on the io_cache_type to actually check if it is a relay log or
      not.
    
    @ sql/log_event.cc
    
      Log_event::write_header() now calculates the event
      common_header->log_pos by using my_b_tell() as there is no IO_CACHE
      with SEQ_READ_APPEND type anymore.
    
    @ sql/rpl_rli.h
    
      It was removed the IO_CACHE *cur_log as it is not needed anymore.
    
      It was also removed the cur_log_old_open_count variable.
    
    @ sql/rpl_rli.cc
    
      Relay_log_info::Relay_log_info() now initialize the relay_log using
      the WRITE_CACHE cache type. It was added the initialization of the
      key_RELAYLOG_LOCK_log_end_pos that now is used by the relay log.
    
      It was removed any reference to relay_log->LOCK_log at
      Relay_log_info::init_relay_log_pos() function.
    
    @ sql/rpl_slave.cc
    
      The write_ignored_events_info_to_relay_log() function now relies on
      LOCK_binlog_end_pos instead of LOCK_log.
    
      At queue_event(), there is a rli->relay_log.lock_binlog_end_pos() call
      every time the rli->ign_master_log_* variables are going to be
      handled.
    
      It was created the relay_log_space_verification() static function with
      all the code related to relay log space verification that was inside
      the next_event() function.
    
      The major changes in this step were done at the next_event() static
      function. It doesn't use the relay_log->LOCK_log anymore, and rely on
      relay_log->LOCK_binlog_end_pos when reaching the "hot" relay log file
      boundaries. The function now only reads and event from the relay log
      file if the log is not "hot" or if current reading position is less
      than the binlog_end_pos.
    
      Introduced the wait_new_relaylog_events() function.
    
    @ mysql-test/suite/rpl/t/rpl_relay_log_locking(.test|.result)
    
      It was created a test case that relies on debug instrumentation to
      block the receiver thread while queuing an event and ensure that the
      applier thread is capable of reading from the relay log up to the last
      queued event.
    
    Other references
    ----------------
    
    This patch also fixed:
    
    BUG#25321231: TUNING THE LOG_LOCK CONTENTION FOR IO_THREAD AND
                  SQL_THREAD IN RPL_SLAVE.CC
    
    (Step 2)
    
    This patch made channels retrieved_gtid_sets to use their own
    sid_map/sid_lock and created a class to avoid locking when checking the
    current server GTID_MODE to be used Master_info and Binlog_sender.
    
    Gtid_mode_copy class
    --------------------
    
    Any operation needing to check the current server GTID_MODE would
    acquire the global_sid_lock in order to read the GTID_MODE. This is a
    very [1;31mfast[m operation (just to access a server global variable), but while
    done by many concurrent threads it might generate impact, mostly on
    commit operations that acquire the global_sid_lock exclusively.
    
    Also, when the server is committing a group of transactions, as the
    global_sid_lock is acquired for writing, any operation trying to check
    the server GTID_MODE will have to be held.
    
    GTID_MODE is a global variable that should not be changed often, but
    the access to it is protected by any of the four locks described at
    enum_gtid_mode_lock.
    
    Every time a channel receiver thread connects to a master, every time
    a Gtid_log_event or an Anonymous_gtid_log_event is queued by a receiver
    thread, or is going to be sent by the Binlog_sender to a receiver, there
    must be checked if the current GTID_MODE is compatible with the
    operation.
    
    There are some places where the verification is performed while
    already holding one of the above mentioned locks, but there are other
    places that rely on no specific lock and, in this case, will rely on the
    global_sid_lock, blocking any other GTID operation relying on the
    global_sid_map for writing (like a group of transactions being
    committed).
    
    In order to avoid acquiring lock to check a variable that is not
    changed often, we introduced a global (atomic) counter of how many times
    the GTID_MODE was changed since the server startup.
    
    The Gtid_mode_copy class was implemented to hold a copy of the last
    GTID_MODE to be returned without the need of acquiring locks if the
    local GTID mode counter has the same value as the global atomic counter.
    
    @ sql/mysqld.cc
    
      Introduced the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/rpl_gtid_misc.cc
    
      Declared the global atomic _gtid_mode_counter.
    
    @ sql/rpl_gtid.h
    
      Declared the external atomic _gtid_mode_counter.
    
      Defined DEFAULT_GTID_MODE as GTID_MODE_OFF.
    
      Introduced the Gtid_mode_copy class.
    
    @ sql/rpl_binlog_sender.h
    
      Inherited from Gtid_mode_copy to the Binlog_sender class.
    
    @ sql/rpl_binlog_sender.cc
    
      Replaced the calls to get_gtid_mode() by get_gtid_mode_from_copy().
    
    @ sql/rpl_slave.cc
    
      At recover_relay_log(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At init_recovery(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At start_slave_threads(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At get_master_version_and_clock(), replaced the call to
      get_gtid_mode() by get_gtid_mode_from_copy().
    
      At queue_event(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
    @ sql/sys_vars.cc
    
      Incremented the _gtid_mode_counter when GTID_MODE is changed. Also,
      made the GTID_MODE global variable to have DEFAULT_GTID_MODE as its
      default value.
    
    Retrieve_gtid_sets with their own SID maps/SID locks
    ----------------------------------------------------
    
    Any GTID set operation relying on a given SID map (and its respective
    lock) will be blocked by any other operation (in any other GTID set)
    holding the SID lock for writing.
    
    All server GTID state sets (lost_gtids, executed_gtids,
    gtids_only_in_table, previous_gtids_logged and owned_gtids) rely on the
    global SID map (and on the global SID lock). So, when GTIDs are
    committed in the server, the updates on the GTID state lock the SID map
    for writing to prevent other threads to perform updates on the GTID
    state (or read from it while it is being updated). The side effect of
    this way of avoiding other threads to read from or update a GTID set is
    blocking any other GTID activity in other GTID sets relying on the same
    SID map/SID lock. So, before this patch, the replication receiver
    threads had their Retrieved_Gtid_Set relying on the global SID map/lock.
    In this way, when a group commit was updating the GTIDs of the committed
    transactions, any replication receiver trying to queue a Gtid_log_event
    or finishing queuing a Gtid transaction had to wait for the group commit
    to unlock the global SID lock. Also, a group commit trying to lock the
    global SID lock for writing was waiting to all receiver threads queuing
    GTIDs to finish before having being granted with the lock ownership.
    
    The global SID lock on the cases described above is taken for doing
    small operations, and there is no significant impact on server
    performance in a slave server replicating using a single replication
    channel with medium to large transactions and without using MTS. But
    when the slave is scaled to have many replication channels and/or
    replicating many small transactions and using MTS, the impact of the
    concurrency in the global SID lock becomes noticeable.
    
    This patch is making all receiver threads to rely on their own
    (individual) SID maps and locks.
    
    @ sql/binlog.cc
    
      The MYSQL_BIN_LOG::init_gtid_sets() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      The MYSQL_BIN_LOG::open_binlog() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      The MYSQL_BIN_LOG::reset_logs() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      MYSQL_BIN_LOG::after_write_to_relay_log() now uses only the relay log
      sid_lock.
    
    @ sql/log_event.cc
    
      Previous_log_event should assert that the SID map of the GTID set
      passed as parameter is locked (is it not the global_sid_lock for relay
      log events).
    
    @ sql/mysqld.h
    
      Declared the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/mysqld.cc
    
      At gtid_server_init(), initialized the global _gtid_mode_counter.
    
      Introduced the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/rpl_channel_service_interface.cc
    
      The channel_get_last_delivered_gno() function now uses the relay log
      sid_lock.
    
      The channel_wait_until_apply_queue_applied() was refactored to avoid
      blocking both the relay log sid_lock and the global_sid_lock while
      waiting for the condition.
    
    @ sql/rpl_gtid.h
    
      Enabled the declaration of Sid_map::clear() regardless of compiler
      directives.
    
      Declared a new static function Sid_map::get_new_sid_map() to
      retrieve a new empty SID map with its own SID lock.
    
      Declared the Gtid_set::clear_set_and_sid_map() function that takes
      care of cleaning the SID map after cleaning the GTID set.
    
    @ sql/rpl_gtid_set.cc
    
      Introduced the Gtid_set::clear_set_and_sid_map() function that takes
      care of cleaning the SID map after cleaning the GTID set.
    
    @ sql/rpl_gtid_sid_map.cc
    
      Removed the compiler directives preventing the compilation of
      Sid_map::clear().
    
    @ sql/rpl_rli.h
    
      Made the (retrieved) gtid_set a pointer.
    
      Added function to get the GTID set SID map (get_sid_map()) and SID
      lock (get_sid_lock()).
    
      Changed add_logged_gtid() function to use the relay log SID map and
      lock.
    
      Declared a new wait_for_gtid_set() function receiving a char*
      parameter instead of a String*.
    
    @ sql/rpl_rli.cc
    
      Refactored the gtid_set initialization on Relay_log_info constructor
      and cleaned up the GTID set, SID map and lock on destructor.
    
      Introduced the new wait_for_gtid_set() function receiving a char*
      parameter instead of a String* and refactored the wait_for_gtid_set()
      that receives a String* to call the new introduced one.
    
      Added some assertions at Relay_log_info::wait_for_gtid_set() to ensure
      that the GTID set to wait is relying on global_sid_map or has no SID
      map.
    
      Relay_log_info::purge_relay_logs() now uses the relay log SID lock and
      also clears the relay log SID map when cleaning the retrieved GTID
      set.
    
      Relay_log_info::rli_init_info now uses the relay log SID lock.
    
      Relay_log_info::add_gtid_set() now uses the relay log SID lock.
    
    @ sql/rpl_slave.cc
    
      The recover_relay_log() function now uses the relay log SID lock and
      also clears the relay log SID map when cleaning the retrieved GTID
      set.
    
      The show_slave_status() functions were refactored to use the relay log
      SID lock when dealing with the retrieved GTID sets.
    
      The request_dump() function now uses the relay log SID lock when
      dealing with the retrieved GTID set.
    
      The queue_event() function now uses the relay log SID lock when
      dealing with GTIDs of received Gtid_log_events.
    
    @ storage/perfschema/table_replication_connection_status.cc
    
      The table_replication_connection_status::make_row() function was
      refactored to use the relay log SID lock when dealing with the
      retrieved GTID sets.
    
    (Step 3)
    
    This patch moved the call to flush_master_info() that was done by the
    I/O thread after a successful call to queue_event() to inside the
    queue_event() function, in order to take a ride in the already locked
    mi->data_lock and relay_log->LOCK_log.
    
    This will avoid acquiring the above mentioned locks twice for every
    successful event queued.
    
    It also added a new parameter to flush_master_info() to opt the flush of
    the relay log. Previous approach was leading to flush the relay log
    twice per event.
    
    @ sql/rpl_channel_service_interface.cc
    
      Specified the new queue_event() parameter to not flush master info
      after queuing the event.
    
    @ sql/rpl_slave.h
    
      Changes flush_master_info() declaration by adding a new parameter
      telling the function if it needs to acquire the required locks or if
      the locks are already acquired and a new parameter telling the
      function if it needs to flush the relay log.
    
      Declared QUEUE_EVENT_RESULT enum with the possible results of the
      queue_event() function.
    
      Changes queue_event() declaration to return QUEUE_EVENT_RESULT and
      also to support a new parameter telling the function to also flush
      master info on after an event be successfully queued.
    
    @ sql/rpl_slave.cc
    
      The flush_master_info() function was changed to not acquire the
      relay_log->LOCK_log always, but rely on the need_lock parameter to do
      so. It was also changed to only flush the relay log based on the new
      flush_relay_log parameter. This will prevent flushing the relay log
      twice when queuing events.
    
      On handle_slave_io(), refactored the calls to queue_event() and
      flush_master_info() to use the new implemented parameters.
    
      Refactored queue_event() function to return QUEUE_EVENT_RESULT, and to
      flush master info without the need of flushing the relay log in the
      case of a successful event be queued.
    
    Added test cases to improve code coverage:
    
    - rpl_write_ignored_events: ensure the ignored events not yet consumed
      by the slave are taken into account by the SQL thread if the I/O
      thread is stopped before the SQL thread consumed the ignored events
      info.
    
    - rpl_write_ignored_events_fail_writing_rotate: ensure I/O behavior
      when failures happen while writing the ignored events info to the
      relay log.
    
    Also commented an unreachable code to make gcov happy.
    
    Added test cases to verify that receiver threads GTID sets do not rely on
    global SID anymore.
    
    rpl_multi_source_block_receiver: checks that receiver thread receiving GTIDs
    (and adding them to its retrieved GTID set) can apply GTIDs from a server UUID
    that doesn't belong to the global SID map yet.
    
    rpl_line_topology_receiver_block: checks that receiver thread on slave
    receiving GTIDs (and adding them to its retrieved GTID set) can have other
    servers replicating from it.

[33mcommit 4993b75e07de9e280fc3f22aa1717f114f41a93e[m
Author: Xing Zhang <xing.z.zhang@oracle.com>
Date:   Wed Feb 22 11:11:11 2017 +0800

    WL #9751: Add Japanese collation to utf8mb4
    
    Implement Japanese collation based on the rules defined by CLDR v30.
    1. Hiragana and Katakana
    DUCET has already organized weight for Hiragana and Katakana to sort them
    correctly. It uses level 2 weight to differentiate "voiced kana" from
    "voiceless kana", and uses level 3 weight to make sure Hiragana sort before
    Katakana. We use the weight defined in DUCET to sort Hiragana and Katakana.
    
    2. Length mark and iteration mark
    Length mark (U+30FC) is a Japanese symbol which indicates a long vowel of
    two mora (syllable timing) in length. It is usually used in Katakana and
    Hiragana writing. CLDR has a series of rules which define how the length
    mark should sort when it follows different Katakana / Hiragana character.
    We use these rules to tailor its weight.
    Iteration mark is a punctuation mark that represent a duplicated character.
    CLDR has rules which define how the iteration mark of Hiragana and Katakana
    should sort. We use these rules to tailor their weight.
    
    3. Kanji
    CLDR defines sort order of 6355 Kanji characters as defined by JIS X 0208,
    the most recent version of Japanese Industrial Standards.
    We give them tailored explicit weight according to the collating order
    defined in CLDR. The given weight will be greater than the maximum weight
    of Kana characters.
    For other non-Japanese Han characters, we keep their implicit weight as
    defined by UCA.
    
    4. Reorder
    CLDR defines reorder rule [Latin, Kana, Hani] for Japanese.
    For Latin and Kana group, the reorder implementation in WL#9108 can reorder
    them well.
    But for character groups between Latin and Kana, and character groups
    between Kana and Hani, we'll give them tailored weight which is greater than
    the maximum weight of Hani characters to make sure they sort after Hani.
    
    BM_Hungarian_AS_CS   4186 ns/iter    27.11 MB/sec
    BM_Japanese_AS_CS    3899 ns/iter    30.06 MB/sec
    
    BM_Japanese_AS_CS is a little [1;31mfast[mer than BM_Hungarian_AS_CS. This is
    because besides weight shift, tailoring rule of Japanese contains many
    prefix context, but tailoring rule of Hungarian contains many contractions.
    So in next_raw(), weight of Japanese character can be returned earlier than
    Hungarian character.
    
    Change-Id: I7786d4182c54bd6d588a255e28e440e40fd777a6

[33mcommit c0ee6138b3673b4548ae58db7029beb14d5b0842[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Fri Jan 27 05:38:05 2017 +0100

    WL#9494 Implement INFORMATION_SCHEMA system views for ROUTINES/TRIGGERS/EVENTS
    
    Post WL#9494 push fix:
    
    In a very busy machines the test main.events_scheduling seem
    to sporadically fail. The reason of failure is that querying
    INFORMATION_SCHEMA.EVENTS sees the status of a event as
    ENABLED instead of DISABLED. To make the test behave
    consistent, this patch changes the wait condition to wait
    until the status turn to DISABLED for events, instead of
    waiting for ENABLED. This seem to avoid sporadic test
    failure.
    
    Although this failure is seen after WL#9494 is pushed, there
    is no obvious reason to relate to. IMO, we uncovered this
    failure now, may be because WL#9494 makes I_S.EVENTS
    executes much [1;31mfast[mer than earlier.
    
    Note: The failure could be reproduced by following command
          without the patch.
    
             ./mtr --ps-protocol
                   --repeat=500
                   --parallel=15
                   main.events_scheduling{,,,}
                   events_1{,,,,,}

[33mcommit 71b2787edcf1cfb5225c26890e8dea8f2b6db43c[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Jan 16 16:08:51 2017 +0100

    Bug #25407857: SIMPLIFY FLOAT/DOUBLE SORT KEY GENERATION
    
    The current float/double sort key generation is unneccessarily complicated,
    and poorly documented. It can be made simpler (and [1;31mfast[mer) by noticing that
    positive floats already sort correctly as ints, and doing some minor tweaks
    for negative numbers.
    
    Change-Id: I5c51be7e1ba31e173ba67537c21381e98260bfc5

[33mcommit 8e257e76a8b5798729fb111bb78cd4cf26980e2b[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Nov 29 12:48:57 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Microoptimize and simplify utf8mb4 parsing:
    
     - Use regular AND masks and comparisons instead of xor-ing away
       the continuation bits. GCC rewrites the xor-and-comparison tests
       to wrapping adds, which are not as easy to mix with shifts as
       ANDs are. (See also below.)
     - Use adds instead of ors, since these are equivalent and can
       sometimes be rewritten as LEAs. (The compiler doesn't actually
       seem to do so in this case, though.)
     - When testing for multiple continuation bytes, read a larger
       chunk using memcpy and do all the comparisons at the same time.
       This would not be possible to do using the XOR trick.
     - When testing if we are outside the allowed range for a given number
       of UTF-8 bytes, simply test the resulting code point (after piecing
       it together) instead of doing complicated testing on each byte
       of the encoded form.
    
    In particular, this matters for three- and four-byte code points;
    one- and two-byte are generally unchanged, and ASCII is of course
    taken by the UCA scanner [1;31mfast[m path anyway. Add a new microbenchmark
    consisting exclusively of Japanese (which is represented mainly
    using three-byte code points) to highlight the differences.
    
    Also unify the many different UTF-8 parsing routines that we have.
    
    Microbenchmarks (Skylake 3.4 GHz, 64-bit, GCC 6.2):
    
      BM_SimpleUTF8                328 -> 334 ns/iter [ -1.8%]
      BM_UTF8MB4StringLength        47 ->  47 ns/iter [  0.0%]
      BM_SimpleUTF8MB4             142 -> 142 ns/iter [  0.0%]
      BM_MixedUTF8MB4              197 -> 188 ns/iter [ +4.8%]
      BM_MixedUTF8MB4_AS_CS        643 -> 576 ns/iter [+11.6%]
      BM_JapaneseUTF8MB4           663 -> 542 ns/iter [+22.3%]
      BM_NewlineFilledUTF8MB4      171 -> 172 ns/iter [ -0.6%]
      BM_HashSimpleUTF8MB4         306 -> 306 ns/iter [  0.0%]
    
    sysbench results are neutral, since they don't test anything
    but ASCII.
    
    Change-Id: I57a72abf69d1b636d2224a1f6e0ebb1aa196296e

[33mcommit cd8957803411dddaa8de2b25f6a51bd8ecef7853[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Nov 18 13:11:49 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Unroll the ASCII [1;31mfast[m path to check four bytes at a time. This is a tradeoff;
    we lose out on the cases where we have four-byte blocks with mixed ASCII/non-ASCII
    (e.g. in text with mostly ASCII but some accents) and on some relatively common
    ASCII code points outside the 0x20..0x7e range, such as newlines.
    
      BM_SimpleUTF8MB4          232 -> 146 ns/iter  [+58.9%]
      BM_MixedUTF8MB4           230 -> 276 ns/iter  [-16.7%]
      BM_MixedUTF8MB4_AS_CS     759 -> 828 ns/iter  [ -8.3%]
      BM_NewlineFilledUTF8MB4   123 -> 231 ns/iter  [-46.8%]
      BM_HashSimpleUTF8MB4      299 -> 306 ns/iter  [ -2.3%]
    
    Change-Id: I64dc2fa06482809cc2e530f2434e5c8890a4edb2

[33mcommit 616f1be47b5b43877079d80449f8f658e1643e21[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Nov 17 13:48:33 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Optimize the hash function; the old one was horrible both in speed and quality.
    The new one is significantly [1;31mfast[mer and slightly less horrible (verified with
    SMHasher). Note that we can do this only because the UCA 9.0.0 collations are
    not part of a GA release; we cannot go back and do this to other collations
    without breaking partitioning.
    
    Microbenchmarks (Skylake 3.4 GHz, optimized, GCC 6.2):
    
      BM_HashSimpleUTF8MB4   1140 -> 289 ns/iter  [+294.5%]
    
    sysbench goes from 11519 -> 12022 tps (+3.2%).
    
    Change-Id: I6c554110387d927ad1d139c19627c6c51a6aa10c

[33mcommit 2bd59f6e54cb152d539c46aa52a3b6507fb10bca[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Nov 17 13:48:33 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Optimize the hash function; the old one was horrible both in speed and quality.
    The new one is significantly [1;31mfast[mer and slightly less horrible (verified with
    SMHasher). Note that we can do this only because the UCA 9.0.0 collations are
    not part of a GA release; we cannot go back and do this to other collations
    without breaking partitioning.
    
    Microbenchmarks (Skylake 3.4 GHz, optimized, GCC 6.2):
    
      BM_HashSimpleUTF8MB4   1140 -> 289 ns/iter  [+294.5%]
    
    sysbench goes from 11519 -> 12022 tps (+3.2%).
    
    Change-Id: I6c554110387d927ad1d139c19627c6c51a6aa10c

[33mcommit d0688a9cc400e2fe30bddeba39754574d2ae9292[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Oct 26 14:48:05 2016 +0200

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    In UCA 9.0.0 collations, move SPACE to the lowest possible weight (previously,
    a select few code points, such as FORM FEED, would sort lower than it). This
    allows us to strip spaces from the right instead of actually adding spaces,
    which is much [1;31mfast[mer, and also makes for variable-length sort keys when filesort
    gets to that.
    
    There's some subtlety in that we still want to keep equality as before;
    in particular, code points such as NON-BREAKING SPACE should still keep
    equality with SPACE on primary and secondary level, but sort later on
    the tertiary level.
    
    Microbenchmarks (Skylake 3.4 GHz, opt, GCC 6.2):
    
      BM_SimpleUTF8MB4         396 ->  368 ns/iter  [ +7.6%]
      BM_MixedUTF8MB4          374 ->  312 ns/iter  [+19.9%]
      BM_MixedUTF8MB4_AS_CS   1105 -> 1017 ns/iter  [ +8.7%]
    
    Note that the microbenchmarks hardly stress padding at all.
    sysbench goes from 9078 -> 10825 tps (+19.2%).
    
    Change-Id: Iff12c8c885a810c9c7c68add1196fbf61c4269c5

[33mcommit 3154c713d32258ef0b02b9d44d903178d2d6ed9d[m
Author: Oystein Grovlen <oystein.grovlen@oracle.com>
Date:   Fri Oct 28 10:28:27 2016 +0200

    Bug#24364448: assert m_opr_handle != null in ha_innobase_inmem::keys_to_use_for_scanning
    
    It turns out calling this function from test_if_cheaper_ordering() is
    both unnecessary and does not give the desired behavior. Hence, this
    bug can be avoided by removing this call.
    
    handler::keys_to_use_for_scanning() returns the set of indexes that
    can be used to provide order.  In other words, it returns the set of
    B-tree indexes, while hash indexes is not included.  This should not
    be necessary to check since the indexes considered by
    test_if_cheaper_ordering() is based on Field::part_of_sortkey.  Hence,
    hash indexes have already been excluded at this point.
    
    Also, the code in test_if_cheaper_ordering() does not achieve what is
    intended.  The comment says: "If not used with LIMIT, only use keys if
    the whole query can be resolved with a key; This is because filesort()
    is usually [1;31mfast[mer than retrieving all rows through an index."  In
    other words, one only wants to switch to full index scan if the index
    is covering.  However, the set of indexes considered is the union of
    covering indexes and the indexes returned by keys_to_use_for_scanning(),
    which in InnoDB's case will be all indexes.   (While MyISAM's use the
    default implementation and returns no indexes.)
    
    Other comments in test_if_cheaper_ordering() are in conflict with the
    comment cited above.  For example: "Don't use an index scan with ORDER
    BY without limit.  For GROUP BY without limit always use index scan if
    there is a suitable index."  Due to the effect of the code discussed
    above, this has been the effect for InnoDB while for MyISAM full index
    scan for GROUP BY has only been used when the index has been covering.
    
    The fix is to remove the discussed code.  This will not make any
    difference for InnoDB tables since all indexes were already
    considered.  For MyISAM tables, full index scan may now be used
    instead of full table scan + filesort even when index is not covering.
    
    Details:
    
      sql/sql_select.cc
        Remove the code that limits the indexes that may be considered by
        test_if_cheaper_ordering()
        Remove local variable keys since parameter usable_keys may be used
    
      mysql-test/t/derived.test
      mysql-test/r/derived.result
        Reduced test case from bug report
        Note that this test case does not fail on trunk; only in WL#8117 branch
    
      mysql-test/t/heap_btree.test
      mysql-test/r/heap_btree.result
        Added a test case that verifies that btree index in heap engine may
        be used for ordering
    
      mysql-test/t/heap_hash.test
      mysql-test/r/heap_hash.result
        Added a test case that verifies that hash index is not used for ordering
    
      mysql-test/r/group_by.result
        Result of a query with not full group by changes since rows is
        accessed in different order when full index scan is used.
    
      mysql-test/r/group_min_max.result
        Switch from table scan with sorting to full index scan that avoids
        sorting
    
      mysql-test/r/key.result
        Switch from table scan with sorting to full index scan that avoids
        sorting
    
      mysql-test/r/select_found.result
        Switch from table scan with sorting to full index scan that avoids
        sorting
        Distinct query with limit gives different result since rows is
        accessed in different order when full index scan is used.
    
      mysql-test/r/subquery_mat.result
      mysql-test/r/subquery_mat_all.result
      mysql-test/r/subquery_mat_none.result
        Switch from table scan with sorting to full index scan that avoids
        sorting
    
      mysql-test/suite/gcol/r/gcol_keys_myisam.result
      mysql-test/suite/gcol/r/gcol_select_myisam.result
        Switch from table scan with sorting to full index scan that avoids
        sorting

[33mcommit 240fe89d1872f0f52aa147e4eaa59b74156d19a7[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Oct 24 12:57:16 2016 +0200

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Add a [1;31mfast[mpath for simple (non-tailored) UCA 9.0.0 collations,
    where as long as the string is pure ASCII, we can skip a lot of
    the checks and lookups normally required. Once we hit a non-ASCII
    character, we fall back to the regular path, but return if we
    see ASCII characters again. (This ensures a single non-ASCII
    character, such as an emoji, won't make us fall off the [1;31mfast[m path
    entirely.)
    
    This is based on an idea and initial implementation from Xing,
    but adjusted so that it is somewhat more generic.
    
    Microbenchmark results (64-bit, Skylake 3.4 GHz, GCC 6.1):
    
      BM_SimpleUTF8MB4          1329 -> 363 ns/iter  [+266.1%]
      BM_MixedUTF8MB4            603 -> 321 ns/iter  [ +87.9%]
      BM_MixedUTF8MB4_AS_CS     2037 -> 982 ns/iter  [+107.4%]
    
    sysbench goes from 5429 -> 7431 tps (+36.9%).
    
    Change-Id: I4cc22e7141ba7b3ddd99da97bf32ef30156fb28b

[33mcommit 270fd3411e3d671a73ed9725940a30080f59ce6d[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Thu Aug 25 16:52:45 2016 +0530

    WL#6392 : Upgrade to Transactional Data Dictionary
    
    With the implementation of the new data dictionary, the metadata will
    be stored in the InnoDB tables. For the users to upgrade from the older
    MySQL version(5.7) to mysql-8.0, dictionary tables should be created and
    populated in old data directory from various metadata sources.
    
    When the Mysql-8.0 server comes up, it detects for the presence of
    dictionary tables.  If dictionary tables are not present,
    they will be created in old data directory and populated
    with the metadata. Then the server will proceed with normal start.
    
    If dictionary tables are present, server will proceed with normal startup.
    
    Upgrade Steps for Users
    ------------------------
    
    1. Do a pre requisite check on 5.7 data directory.
    2. Do a slow shutdown of mysql-5.7 server. Slow shutdown involves setting
       global variable 'innodb_[1;31mfast[m_shutdown' to zero before server shutdown.
    3. Start mysql-8.0 server on 5.7 data directory.
       mysql-8.0 server will detect if Dictionary tables are present or not.
       If dictionary tables are not present,  they will be created in old data
       directory. Metadata will be populated in dictionary tables.
       Then server will proceed with normal start.
    4. Execute mysql_upgrade client tool.
    5. Shutdown and start server again with normal configuration. (Recommended)
    
    Reviewed-by: Nisha Gopalakrishnan <nisha.gopalakrishnan@oracle.com>
    Reviewed-by: Thayumanavar Sachithanantham <thayumanavar.x.sachithanantha@oracle.com>
    Reviewed-by: Dmitry Lenev <dmitry.lenev@oracle.com>

[33mcommit 4f3823e76c3165fbe5abb898587feaaea97e343e[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Thu Aug 25 16:52:45 2016 +0530

    WL#6392 : Upgrade to Transactional Data Dictionary
    
    With the implementation of the new data dictionary, the metadata will
    be stored in the InnoDB tables. For the users to upgrade from the older
    MySQL version(5.7) to mysql-8.0, dictionary tables should be created and
    populated in old data directory from various metadata sources.
    
    When the Mysql-8.0 server comes up, it detects for the presence of
    dictionary tables.  If dictionary tables are not present,
    they will be created in old data directory and populated
    with the metadata. Then the server will proceed with normal start.
    
    If dictionary tables are present, server will proceed with normal startup.
    
    Upgrade Steps for Users
    ------------------------
    
    1. Do a pre requisite check on 5.7 data directory.
    2. Do a slow shutdown of mysql-5.7 server. Slow shutdown involves setting
       global variable 'innodb_[1;31mfast[m_shutdown' to zero before server shutdown.
    3. Start mysql-8.0 server on 5.7 data directory.
       mysql-8.0 server will detect if Dictionary tables are present or not.
       If dictionary tables are not present,  they will be created in old data
       directory. Metadata will be populated in dictionary tables.
       Then server will proceed with normal start.
    4. Execute mysql_upgrade client tool.
    5. Shutdown and start server again with normal configuration. (Recommended)
    
    Reviewed-by: Nisha Gopalakrishnan <nisha.gopalakrishnan@oracle.com>
    Reviewed-by: Thayumanavar Sachithanantham <thayumanavar.x.sachithanantha@oracle.com>
    Reviewed-by: Dmitry Lenev <dmitry.lenev@oracle.com>

[33mcommit 0a10fc8b5ca0f7eac1c952f9ab0ee1720360b728[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Fri Aug 12 17:45:09 2016 +0200

    WL#6599 - New Data Dictionary and I_S integration.
    
    This WL defines INFORMATION_SCHEMA (I_S) system view over DD tables,
    representing a I_S table. This will eliminate the need of preparing a
    temporary table for each I_S table during execution and enable [1;31mfast[mer
    execution of I_S queries.
    
    A. Functional changes introduced:
    ---------------------------------
    A.1) Implements following I_S tables as a system view.
    
      CHARACTER_SETS
      COLLATIONS
      COLLATION_CHARACTER_SET_APPLICABILITY
      SCHEMATA
      TABLE_NAMES
      TABLES
      VIEWS
      COLUMNS
      STATISTICS
      KEY_COLUMN_USAGE
      TABLE_CONSTRAINTS
    
    A.2) Implements following SHOW commands to use A.1).
    
      SHOW CHARSET
      SHOW COLLATION
      SHOW DATABASES
      SHOW TABLES
      SHOW TABLE STATUS
      SHOW COLUMNS
      SHOW KEYS/INDEXES
      SHOW STATISTICS
      DESCRIBE
    
    A.3)
      Introduces a session variable 'information_schema_stats' that
      enables use to decide how to get the table/index dynamic
      statistics. Setting it to 'latest' would get latest statistics
      from storage engine. And setting it to 'cached' would get
      statistics stored in mysql.table_stats/index_stats. These are two
      new DD tables introduced by this WL. These tables are updated
      when user runs ANALYZE TABLE on a table. For more details see HLS
      2.1.4) and 2.1.12).
    
    A.4) Introduced following new DD columns, see HLS 2.1.8) for more
         details.
    
      COLUMNS.COLUMN_KEY
      COLUMNS.COLUMN_TYPE
      COLUMNS.DEFAULT_VALUE_UTF8
      TABLES.ROW_FORMAT
    
    A.5)
      Implements special handling for SHOW COLUMNS/KEYS for temporary
      tables as the meta data of temporary tables are not stored in DD.
    
    A.6)
      I_S tables are temporary tables on 5.7. This make them
      possible to access under LOCK TABLE mode with explicitly
      locking I_S tables. Now with this WL, the query execution
      procedure fails to process I_S system view as the under laying DD
      table are not locked.
    
      So, this WL makes the SQL server to open the DD tables used by
      a I_S system view without requiring them to be locked explicitly.
    
    B. Performance improvements:
    ----------------------------
    
    See mysql wiki page WL6599_I_S_performance_with_data_dictionary
    for more details. (HLS section 5)
    
    C. Compatibility issues:
    ------------------------
    There are few differences in the way mysql server would behave
    after this WL. The detailed list of these change in behavior is
    listed under HLS section 6).
    
    D. Source files:
    ----------------
    Most of code changes are placed in sql/dd/info_schema folder.
    
    * Refer code in sql/dd/info_schema/show.* to know how SHOW
      commands are implemented.
    
    * Refer code in sql/dd/info_schema/stats.* to know how the
      retrieval of dynamic statistics are implemented.
    
    E. Related WL's and Bugs:
    -------------------------
    
    * WL#7167 Change DDL to update rows for view columns in
      DD.COLUMNS and other dependent values.
    
      I_S.COLUMNS will get column meta data for views from
      mysql.columns. The view's column meta data are stored in
      mysql.columns by this WL. The WL takes care of enabling several
      test cases that is disabled by this WL#6599. So WL#6599 and
      WL#7167 would be pushed together. They are QA'ed together.
    
    * WL#7464 - InnoDB: provide a way to do non-locking reads.
      This WL enables execution of I_S queries do to non-locking reads.
    
    * WL#8232 - New data-dictionary: change approach to table
                row_format and index algorithm validation/handling
    
    Upcoming WL:
    * WL#9494   Implement INFORMATION_SCHEMA system views for
                SP/TRIGGERS/EVENTS/REFERENTIAL_CONSTRAINTS
    
    * WL#9495   Update schema tables of dynamic plugins into data
                dictionary.
    
    The following bugs would be fixed by this WL:
      Bug#11748044
      Bug#13878164
    
    F. Disabled tests:
    ------------------
    
    thread_pool.thread_pool_i_s : Would be fixed by WL#9495.
    i_innodb.innodb_bug14150372 : WL6599_INNODB_SPORADIC

[33mcommit 1876925b3314346bacf6d364dd1a4fec22054e47[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Jun 27 11:56:57 2016 +0200

    Bug #23759968: ENABLE THE GNU GOLD LINKER
    
    Speeds up linking significantly; on my Debian 8 machine, a rebuild of a single
    unit test (which is almost all linking) is about 50% [1;31mfast[mer (33% less time).
    
    Change-Id: I981b01a34aeaa43e975337a7b93c0bb0880b0b26

[33mcommit 9c5412867c3bef6d78f55992eed26509081aed71[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Jun 14 16:54:13 2016 +0200

    Fix several failures in 'testSystemRestart -n SR_DD_n*' tests
    
    Tests where inserting into tables or updating rows at the
    max speed of the test client machines for the duration of
    each test loop.
    
    As the new vigdis servers are [1;31mfast[mart than the machines they
    replaced, we are now able to fill the TableSpace and/or
    redo logs to their max sizes, and thus the test failes.
    
    This patch introduce a load limiting machanism which limit
    the client load to 10.000 insert/update/deletes pr sec.
    
    This should also avoid that these tests fails the next time
    the ATR test are moved to [1;31mfast[mer hardware.

[33mcommit 1c8b6a4d8f834a740c2b9335c7968b58e7202441[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue May 10 09:26:09 2016 +0200

    Bug#23202735 CLIENT PERFORMANCE REDUCED DUE TO THREADS WOKEN UP TOO EARLY
    
    This patch fixes two issues related to threads being
    woken up when not needed, and thus resulting in unnecessary
    context switches.:
    
    1)
    Avoid API Clients waiting in the poll queue to be woked up every 10ms.
    
    The 'poll-right' is given to (only!) one of the clients waiting
    for do_poll. The rest of the clients just wait there such that
    they can be woken up when the poller delivers something to them.
    However, a max wait time of 10ms is currently enforced, such that
    they may be woken to immediately be put back to sleep. This also
    implies dequeuing and requeing in the mutex protected poll queue.
    
    Iff the client threads waiting in the poll queue are properly
    signaled when signals are delivered, there should be no need to
    wake them up regularly. This patch removes the enforced 10ms max
    wait time, and instead wait the time specified by the callee.
    
    2)
    Fix a performance problem in ::do_poll() where the polling 'clnt' does not
    check whether it has been woken up *itself* before completing the poll.
    
    It is sufficient that only some trp_client's in the poll-queue
    received data. ::do_poll will then signal these clients and
    give up its poll right, even if the max specified wait_time
    have not expired.
    
    Thus, another of the clients in the poll-queue has to be
    appointed as the new poller, and a *thread switch* is required
    to wake up that thread for more do_poll work.
    
    This patch allows do_poll() to continue polling until
    either the max specified wait_time have expired, or
    the polling client itself has been woken up (by being
    delivered what it waited for) This avoid unnecessary
    thread switches between the client threads and thus
    reduce the overhead in the API client. This results
    in a ~10% performance improvement when the client
    threads does the polling themself.
    
    This is similar to the mechanism already implemented
    in the receiverThread, which explicit request to 'stay poll owner'
    when it has been activated. We still see that having the receiverThread
    doing the poll is [1;31mfast[mer than using the client thread. However,
    we believe that most of this is due to the receiver thread allowing
    more trp_client to have delivered signals before signaling them
    vs the client threads. (256 vs 16)

[33mcommit c43d3321f1ba519f60caea9273e9332843ec232a[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Thu May 5 10:22:01 2016 +0300

    WL#7743 Work-in-progress.
    
    Preparations for WL#9162. Introduce flag which allows SE indicated that it
    supports partitioning changes through in-place API but still requires
    special partition_info mark-up used by [1;31mfast[m partitioning ALTER path.
    
    Moved code from Partition_helper::change_partitions() method to
    a new method to allow its reused by InnoDB native partitioning
    implementation.

[33mcommit e9a94a472de97692b7b7c929a1deb81e66bd0dc2[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Fri Jan 8 09:55:53 2016 +0100

    Bug#22455022: REMOVE EXTRA #INCLUDES FROM SQL/ HEADERS
    
    Another round of sql/ header simplifications.
    Do not #include headers that are not needed.
    Use forward declarations if possible.
    
    Gives fewer depedencies and [1;31mfast[mer compilation.

[33mcommit e314703f70243b25a13976a9b64826cf1572f122[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Oct 30 15:30:37 2015 +0100

    Bug#22127020 GET RID OF DYNAMIC_ARRAY IN ST_MYSQL_OPTIONS
    
    Our array abstractions should be removed, and substituted with modern data
    structures.
    
    Templatized vectors are:
     - type safe
     - easier to read/maintain
     - [1;31mfast[mer
    
    Patch two: replace DYNAMIC_ARRAY

[33mcommit 31350e8ab15179acab5197fa29d12686b1efd6ef[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Tue Nov 3 13:27:06 2015 +0530

    WL#6378 New data dictionary (umbrella).
    
    A. Overview:
    ------------
    This big patch introduces data dictionary (DD) schema in MySQL
    server. Some of the main benefits of this is,
    
    * The .FRM files are gone, and all dictionary changes will
      now happen in the dictionary schema stored in InnoDB.
    
    * Builds a base platform enabling us to improve performance of
      INFORMATION_SCHEMA queries, which can be implemented as a view.
    
    * This patch enables a forthcoming incremental patch that would
      remove internal dictionary table of InnoDB. Enables,
       - There by eliminate inconsistencies between .FRM files and
         InnoDB tables.
       - Remove file system dependencies (lower-case-table-names).
       - Single repository of meta data for Server, SE and Plugins.
       - Eliminate meta data redundancy.
    
    * Remove db.opt and rely on dictionary tables.
    
    B. Work logs:
    -------------
    The WL#6378 is the umbrella WL tracking all dependent WL's. This
    patch contains implementation of following dependent WL's,
    
    * Worklogs that deal with just DD API framework:
    
      WL#6379 - Schema definitions for new DD.
                This important WL defines the central data dictionary
                table definitions.
    
      WL#6380 - Formulate framework for API for DD.
    
      WL#7284 - Implement common code for different DD APIs.
      WL#6385 - Define and Implement API for Schema.
      WL#6382 - Define and Implement API for Table objects.
      WL#6389 - Implementation of common View API.
      WL#6387 - Define and Implement API for Tablespaces.
      WL#7630 - Define and Implement API for Table Partition Info
      WL#8150 - Dictionary object cache.
      WL#7770 - Develop GUNIT test framework and guidelines for DD API.
      WL#7771 - Make sure errors are properly handled in DD API.
    
    * Worklogs that change server code invoking DD API's:
    
      WL#6390 - Use new DD API for handling non-partitioned tables.
      WL#7836 - Use new DD API for handling partitioned tables.
      WL#6394 - Bootstrapping the new data dictionary.
      WL#7784 - Store temporary table meta data in memory.
      WL#8542 - Server shutdown procedure with new data dictionary
      WL#7593 - New data dictionary: don't hold LOCK_open while
                reading table definition.
      WL#7464 - InnoDB: provide a way to do non-locking reads
                This is pre-requisite for WL#6599.
    
    C. Tips to DD API users:
    ------------------------
    * Refer code in sql/dd/dd_schema.* to quickly learn how to write
      code using DD API and update dictionary tables.
    
      Refer sql/dd/cache/dictionary_client.h to get overview on what
      is Dictionary_client and Auto_release interface.
    
      Interested can refer to sql/dd_table_share.{h,cc} which
      implements mapping between the TABLE_SHARE and the dd::Table DD
      object.
    
    * Overview of the directory structure and source files introduced
      by this patch is as following,
    
      DD user exposed files:-
    
      sql/dd/        - Top level directory containing most of DD code.
      sql/dd/*.h     - Headers that you need to operate on DD.
      sql/dd/types/  - Contains headers to operate on single
                       dictionary object.
      sql/dd/dd_*.cc - Contains MySQL server and DD API framework
                       glue code. E.g., Code that updates to DD tables
                       upon table creation/alter table/drop table and
                       so on.
      sql/dd/cache/  - Contains implementation of DD Object cache.
    
      Implementation that is hidden to DD user:-
    
      sql/dd/impl/   - Contains implementation of DD API's.
      sql/dd/impl/cache/  - Contains implementation of DD object cache
                            operations.
                             E.g., dd::cache::Dictionary_client
      sql/dd/impl/types/  - Contains implementation of DD user object
                            operations. E.g., dd:Table, dd::View etc.
      sql/dd/impl/tables/ - Contains implementation of DD table
                            operations. E.g., dd::tables::* classes
                            that abstracts operations on a DD table.
      sql/dd/impl/raw/    - Contains implementation of generic
                            operations on all DD tables.
    
    * The code related to .FRM handle is removed. So, the following
      files are removed,
        sql/datadict.h
        sql/datadict.cc
        sql/discover.h
        sql/discover.cc
        sql/unireg.h
        sql/unireg.cc
    
    D. New configuration variables and startup options:
    ---------------------------------------------------
    * Introduced a new option "--install-server", behaving like
      "--bootstrap", but additionally creating the dictionary tables.
      Note that the --install-server is a temporary workaround until
      MTR use --initialize.
    
    * The existing "--bootstrap" option behaves like before as far
      as possible, but note that the changes in plugin initialization
      means that e.g. InnoDB must be able to start, the DD must be
      able to start, etc., for bootstrap to enter the stage where SQL
      commands are actually executed.
    
    * The mysql_install_db and the mysql_test_run scripts are modified
      to use the new "--install-server" option.
    
    * The cmake script create_initial_db.cmake.in is also changed to
      use --install-server rather than --bootstrap.
    
    * WL#8150 adds server options schema_definition_cache,
      tablespace_definition_cache and stored_program_definition_cache
      size. These define the DD object cache size for respective DD
      objects.
    
    E. Upcoming improvements
    -----------------------
    * WL#6599 New Data Dictionary and I_S integration
      Information schema queries will be execute [1;31mfast[mer as this WL
      would make information schema tables as a view on top of DD
      tables.
    
    * WL#7743 New data dictionary: changes to DDL-related parts of SE API
      - Support atomic/crash-safe DDL.
      - Support auxiliary columns (InnoDB-specific)
      - Support auxiliary tables (needed for InnoDB FTS)
    
    * WL#6394 - Bootstrapping the new data dictionary.
      - Improvements in bootstrap procedure supporting removal of
        InnoDB dictionary.
    
    * WL#7896 Use DD API to work with triggers.
      - Will remove use of .TRN and .TRG files and start using
        mysql.triggers DD table.
    
    * Additional system tables are to be moved from MyISAM
      WL#7897 Use DD API to work with stored routines
      - Will remove mysql.proc MyISAM table and use mysql.routines
        InnoDB dictionary table.
    
      WL#7898 Use DD API to work with events.
      - Will remove mysql.event MyISAM table and use mysql.events
        InnoDB dictionary table.
    
    * WL#6391: Hide DD system tables from user.
      - Will hide direct access to DD system tables from user.
    
    F. Permanent changes in behavior.
    ---------------------------------------------
    * Since the .frm files are gone, you will not be able to copy
      .FRMs/data files and move them around. We will address this
      when we finish the implementation of new import, based on
      serialized dictionary information, see WL#7069.
    
    * Related to the above is the fact that --innodb-read-only
      option does not currently work. In 5.7, meta-data would be
      written to .FRM files and not be affected by the option, but
      now as meta-data is written to InnoDB tables, we must
      reconsider the semantics of this option.
    
    * The setting of the system variable 'lower_case_table_names'
      determines the collation of e.g. the 'name' column in the table
      storing the meta data for tables. This collation is decided once
      and for all when the dictionary table is created. Thus, we do
      not support changing 'lower_case_table_names' afterwards.
    
    * Character sets and collation tables are populated at initial
      boot, and for every subsequent startup, unless the server or
      the dictionary storage engine (InnoDB) is started in read
      only mode.
    
    G. Intermediate limitations in functionality:
    ---------------------------------------------
    * Tests on upgrade/downgrade will not work, and will be
      temporarily disabled. QA will also have to temporarily postpone
      any upgrade tests, until we have completed the upgrade tool
      (WL#6392) from 5.7 to 5.8. We are working towards building a
      intermediate solution for system QA.
    
    * Some InnoDB tests related to recovery of TRUNCATE are
      disabled. But n-test can be run as long as you are not trying to
      recover TRUNCATE. The tests will be enabled when we push the
      bundle of WLs(7141/7016/7743), which will move the storing of
      InnoDB DD to the common data dictionary, and make DDL atomic.
      Until which recovery after killing the server will also not
      work.
    
    * MySQL Cluster cannot be used with this version of the server.
    
    H. Disabled tests:
    ------------------
    Apart from test that are disabled due to above functionality that
    does not work now. Additionally we have temporarily disabled a
    few other tests, which might be a bit challenging for bug fixing
    in trunk in very restricted areas of the code. Refer
    sql/dd/mtr_readme.txt to see which exact test cases are disabled.

[33mcommit 05437f95cd7225b91c74729b992ea9cfda951a3b[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Oct 27 12:20:40 2015 +0100

    Bug#22103604 GET RID OF DYNAMIC_ARRAY IN MYSQLDUMP COMP_ERR AND MY_DIR()
    
    Our array abstractions should be removed, and substituted with modern data
    structures.
    
    Templatized vectors are:
     - type safe
     - easier to read/maintain
     - [1;31mfast[mer

[33mcommit 0b3adc8c8bbd400187a31b4c0bc7c2f45538590f[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Jun 18 12:14:28 2015 +0300

    Remove the commented out atomic inc code
    
    Atomic increment is only a little bit [1;31mfast[mer than a busy loop trying to
    CAS x with x+1, even when lots of threads fight to update a few values,
    but the atomic increment does not provide a way to check the value
    before doing the operation.
    
    WL#7170 InnoDB buffer estimates for tables and indexes

[33mcommit e5d074fa5a3c383e0446b96db7851183a02737ef[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jun 16 17:35:17 2015 +0300

    Disable stats collection in the lock free hash
    
    Also enlarge the dataset of the tests because without the debug
    stats collection it now runs significantly [1;31mfast[mer.
    
    WL#7170 InnoDB buffer estimates for tables and indexes

[33mcommit 87dbde022c53d393f24d181ff00e52eb5e30922c[m
Merge: 112025a48f8 5eef003ae44
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri May 15 10:46:34 2015 +0300

    Merge remote-tracking branch 'local/mysql-trunk' into mysql-trunk-wl7170
    
    * local/mysql-trunk:
      Fix Bug#20783098 INNODB_CHECKSUM_ALGORITHM=CRC32 IS NOT BYTE ORDER AGNOSTIC
      Bug#20819189: ASSERT IF .FRM EXISTS BUT NO PARTITIONED INNODB TABLE.
      Bug#20561087 : REPLACE_USER_TABLE() DOES NOT CHECK ERROR WHEN READING FROM MYSQL.USER
      Bug#20819189: ASSERT IF .FRM EXISTS BUT NO PARTITIONED INNODB TABLE.
      BUG#19706455: RESET MASTER SHOULD RESET GTID STATE AND NOT ERROR OUT WHEN BINLOG IS OFF
      Test suite cleanup
      Some cosmetic changes which had been suggested in the review of wl#2489 but had to wait for wl#5275 and wl#7870 to be pushed.
      Test cleanup
      Bug#21074643: SERVER SETS OPEN_FILES_LIMIT UNCONDITIONALLY
      Fix for build failure after pushing a767e483e9496e8427d50f59dfa4842d4895e08a
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Bug#20896539 - A QUERY DIGEST SOMETIMES CONTAIN BACKTICKS AND SOMETIMES NOT DEPENDING ON CS
      Post push cleanup
      WL#8216: Deprecate and remove the sync_frm sysvar
      PB2 failures (valgrind and result mismatch) fixes.
      Follow up patch of bug20734998 for fixing Werror failure.
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20762557, Bug#20697533 : Disabled following tests since they fail very often on PB2: main.explain_for_connection_rqg_json main.explain_for_connection_rqg_trad rpl.rpl_perfschema_applier_status
      Test commit
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      WL#8186: Deprecate conversion of pre MySQL 5.1 encoded database names
      Bug#20980885: ENSURE THAT START/STOP GROUP REPLICATION ALWAYS REQUIRE SUPER PRIVILEGE
      Partial backport from mysql-trunk to mysql.5.7 of Bug#21041451: ENABLE AND FIX ADDITONAL WARNINGS REPORTED BY CLANG in order to fix Clang 3.4 warnings in release build. No new warning options are added in the backport.
      Bug#21074358: SOME NEW 5.7 SOURCE FILES ARE D0S FORMATTED
      Bug #17818062       PERFORMANCE SCHEMA, ISSUE WITH UPPERCASE ROUTINES NAMES, PERFSCHEMA.MISC FAILS
      Bug #17818062         PERFORMANCE SCHEMA, ISSUE WITH UPPERCASE ROUTINES NAMES, PERFSCHEMA.MISC FAILS
      Bug#17832047: Crash in calculate_materialization_costs
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      Added openssl multithreading to client.
      Added openssl multithreading to client.
      Bug#20721087 UPGRADE TO BOOST 1.58.0
      Bug#20734998 FAILING ASSERTION: !CURSOR->INDEX->IS_COMMITTED()
      Bug #21047137 REMOVE -GCC FROM NAME OF SOLARIS PACKAGES/TARBALLS
      Bug#19316063: MAKE MTS WORK WITH RELAY_LOG_RECOVERY=1 WHEN GTID IS ENABLED
      Bug#21062842 : Made i_main.costmodel_plan change experimental.
      Bug# 19823076 : READ OF FREED MEMORY IN MY_MB_WC_SJIS WITH                 SOUNDS LIKE OPERATOR IN SUBQUERY
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      BUG#20743468: ASSERTION `OLD_VALUE >= 1' FAILED. | ABORT (SIG=6) IN GTID_STATE::END_ANONYMOUS_ BUG#20748502: ASSERTION `THD->VARIABLES.GTID_NEXT.TYPE== ANONYMOUS_GROUP' FAILED.
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      WL#7589: Updated the README file.
      Bug#21041451: ENABLE AND FIX ADDITONAL WARNINGS REPORTED BY CLANG
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20753620: DBUG: DICT_LOAD_FOREIGN, HA_INNOPART::CHECK, HA_INNOPART::CREATE_NEW_PARTITION
      Silence rpl.rpl_xa_survive_crash_debug in Valgrind
      Bug#21021894 : UNHELPFUL ERROR FOR MYSQL_SSL_RSA_SETUP WHEN DATADIR DOESN'T EXIST
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      Bug#21021754 - OPTION FOR MAX_STATEMENT_TIME IS MISSING
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      BUG #21063087 - MTR SHOULD PASS --INNODB_UNDO_TABLESPACES VARIABLE AT BOOTSTRAP
      BUG#20921940 DEBUG ONLY-CODE MAY HAVE SIDE EFFECTS IN HA_INNOBASE::
      - Bug#21046781: WHILE TRUNCATE UNDO-TABLESPACE FILE COULD BE CLOSED IN BACKGROUND
      BUG#21041449 ASSERT IN I_INNODB.INNODB_BUG16244691
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug #20445525 ADD A CONSISTENCY CHECK AGAINST DB_TRX_ID BEING IN THE FUTURE
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20835095 CRASH AT CREATE_REF_FOR_KEY IN SQL/SQL_SELECT.CC
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20980217 - TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE DOES NOT SHOW CORRECT INDEX NAMES
      Bug#20923066: SSL AND RSA KEY MATERIAL EXPIRATION SHOULD BE EXTENDED
      Corrected validate_password_strength and export_set functions
      Post push fix for BUG#18731252
      Bug#21046582 GEOMETRYCOLLECTION COLUMNS CAN'T STORE SUBTYPES
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      Fix for PB2 test failure.
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      - Bug#21053486: TRUNCATE_RECOVER FAILING IN MYSQL-TRUNK
      Bug#21021894 : UNHELPFUL ERROR FOR MYSQL_SSL_RSA_SETUP WHEN DATADIR DOESN'T EXIST
      Bug#20705648 - max_statement_time leaks memory on windows Bug#20705642 - max_statement_time: assertion failed: pending || thd_timer->thread_id
      Bug#20996273 ALTER USER REWRITE CAUSES DIFFERENCES ON SLAVE
      Fix to remove data dir reference
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Bug#20987568 - INCREASE STOP TIMEOUT OF COMMUNITY RPM SHUTDOWN SCRIPT /ETC/INIT.D/MYSQLD
      - Bug#21046968 : POSSIBLE RACE IN THE TRUNCATE CODE
      WL#7899: Add the tests that were accidentally omitted.
      WL#7899: InnoDB: Map compressed temporary tables to uncompressed
      Bug#20918881 CRASH WITH CENTROID - INVALID FREE
      Bug#20854952 SHOW GLOBAL VARIABLES RETURN WARNING ABOUT SQL_LOG_BIN BEING DEPRECATED
      Bug#21021670 - MISLEADING WARNING WHEN PER-QUERY STATEMENT TIME IS EXCEEDED
      Bug#20854952 SHOW GLOBAL VARIABLES RETURN WARNING ABOUT SQL_LOG_BIN BEING DEPRECATED
      Bug #20692556 : PREPARED STATEMENTS DO NOT TRACK STATUS LIKE STATISTICS
      - Bug#20023425: EMBEDDED SERVER FAILS TO BOOTSTRAP/START UP WITH   INNODB_UNDO_TABLESPACES=2
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Bug #20376498: MAX_ALLOWED_PACKET ERROR DESTROYS ORIGINAL               DATA
      BUG#20753463 HANDLE_FATAL_SIGNAL (SIG=11) IN __STRLEN_SSE2_PMINUB ON              CHANGE MASTER
      Bug#20507804 FAILING ASSERTION: TRX->READ_ONLY && TRX->AUTO_COMMIT && TRX->ISOLATION_LEVEL==1.
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      BUG#18731252 SLAVES WITH SAME SERVER_ID / SERVER_UUID COMPETE FOR              MASTER CONNECTION
      BUG#20768847 ASSERTION 0 IN HA_INNOBASE::COMMIT_INPLACE_ALTER_TABLE
      Post-push fix for BUG#20470724: SET GTID_PURGED SHOULD NOT ROTATE BINLOG
      Fixed Bug#20145024: WRONG RESULT FOR COUNT DISTINCT QUERY IN DERIVED TABLE
      Bug #20592961  'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381 - post fix
      BUG#20977779 CANNOT IMPORT TABLES CONTAINING PREFIX INDEXES
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Fix to avoid build break
      Bug#20814280 SEVERAL PERFORMANCE SCHEMA UNIT TESTS FAIL
      Bug#20814280 SEVERAL PERFORMANCE SCHEMA UNIT TESTS FAIL
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Test cleanup
      Test cleanup
      BUG#20470724: SET GTID_PURGED SHOULD NOT ROTATE BINLOG
      Bug#20748537 INNODB: FAILING ASSERTION: NODE->PCUR->REL_POS == BTR_PCUR_ON
      BUG#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bugi#20593257 FIREWALL PLUGIN LEAK PINS UNDER SPECIAL CIRCUMSTANCES
      BUG#20949314 PARTITION_HELPER::PH_RND_INIT(BOOL): ASSERTION `0' FAILED
      Fix firewall_qc broken test case when the FIREWALL_PLUGIN variable isn't set. This affected 32bit debian
      Fix firewall_qc broken test case when the FIREWALL_PLUGIN variable isn't set. This affected 32bit debian
      Bug#20963147 DECOUPLE DIGEST SIZE FROM SERVER AND PFS
      Bug #20926253 VALGRIND FAILURE IN INNODB.ALTER_MISSING_TABLESPACE
      - Bug#20023425: EMBEDDED SERVER FAILS TO BOOTSTRAP/START UP WITH   INNODB_UNDO_TABLESPACES=2
      Bug#20963147 DECOUPLE DIGEST SIZE FROM SERVER AND PFS
      Raise version number after cloning 5.6.25
      Raise version number after cloning 5.5.44
      BUG#21023683 FAILURE IN EMBEDDED I_INNODB.INNODB-ALTER
      Follow-up to BUG#20913616 - FIREWALL INTEGRATES BADLY WITH QUERY CACHE
      Bug #20914786 : MYSQL_UPGRADE FAILS WITH SHOW_COMPATIBILITY_56 = OFF
      Bug #20753378 ASSERTION `GTID_NEXT->TYPE != AUTOMATIC_GROUP || THD->OWNED_GTID.IS_EMPTY()'
      Bug #20592961  'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381
      Bug #20592961 'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381
      Bug #20753378 ASSERTION `GTID_NEXT->TYPE != AUTOMATIC_GROUP || THD->OWNED_GTID.IS_EMPTY()'
      Fix for missing test recording and test output differences on Windows.
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Bug#20913616 FIREWALL INTEGRATES BADLY WITH QUERY CACHE
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      BUG#19897405: CRASH WHILE ACCESSING VIEWS IN STORED ROUTINE               AND TABLES ARE FLUSHED
      Bug#20515155 Views: Assertion failed: is_view_or_derived() && is_merged()
      Bug #20987420 PB2 FAILURE OF TEST CASE INNODB_ZIP.INNODB_16K
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      BUG#20007583: THE EVENT_SCHEDULER USERNAME IS NOT RESERVERD.               ALLOWS PROCESSLIST VIEW.
      Windows installer in need of fixing to accommodate for WL#7307
      Bug#20768717: DEBUG BUILD FAILS WHEN USING GCC 5 DUE TO COMPILER WARNING
      post push minor test fix for bug:19887143
      BUG#20768847 ASSERTION 0 IN HA_INNOBASE::COMMIT_INPLACE_ALTER_TABLE
      - bug#20938115: innodb_undo_logs max limit should be downgraded from 126 to 94^
      Bug #20563332 : OPEN_FILES_LIMIT BINARY PUT INTO ./BIN DIRECTORY OF A BUILD?
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      Addendum to the fix for bug #20681412:
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug#20979020 - THE TRX IN DDL SHOULD ALWAYS NOT BE ROLLED BACK
      Bug#20709462: GENERATED COLUMNS NOT PRINTED CORRECTLY IN SHOW CREATE TABLE
      Bug#20583321: CRASH ON PS_THREAD_INFO / SYS USAGE
      Bug #18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Fixed failing test
      Bug#20583321: CRASH ON PS_THREAD_INFO / SYS USAGE
      Bug #19077239 mtr tests fixed.
      Bug#19077239 re-enabling disable tests mysql_secure_installation amd mysql_secure_installation_ssl
      Revert "WL#8462: test_services are plugins serving as examples for how plugin services can be tested with mtr."
      Bug #19887143 : THREAD/SQL/MAIN DOESN'T CHANGE STATE/INFO AFTER STARTUP
      WL#7895 - Add systemd support to server.
      Fixed Bug #20683741 UNZIP REQUIRED TO RUN MYSQL-TEST-RUN.PL BUT NOT CHECKED FOR BY CMAKE
      Bug#20865674-VALGRIND FAILURE IN INNODB.CREATE_TABLESPACE
      BUG#19821087 UPDATES TO INDEXED COLUMN MUCH SLOWER IN 5.7.5
      Fixed Bug #20949226: CAN ASSIGN NON-DEFAULT() VALUE TO GENERATED COLUMN
      rb8590 Fixes to sporadically failing on PB2 rpl_xa_survive_crash_debug
      WL#8462: test_services are plugins serving as examples for how plugin services can be tested with mtr.
      Bug #20681412 MYSQLD --INITIALIZE REFERS TO MYSQL_INSTALL_DB AND BOOTSTRAP
      Bug#20937654 CANNOT BUILD WITH "-DDISABLE_SHARED=ON" FOR CMAKE BECAUSE OF REWRITER PLUGIN
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      Fixed failing tests
      WL#6940 Server version token and check
      Bug #20181776 :- ACCESS CONTROL DOESN'T MATCH MOST SPECIFIC                  HOST WHEN IT CONTAINS WILDCARD
      Bug#20961660 RPL TESTS ARE FAILING WITH INNODB: UNDO TABLESPACES MUST BE READABLE!
      WL#4601: Remove [1;31mfast[mmutex from the server sources
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      BUG#20955104: ADD UNIT TEST BINARIES AS OPTIONAL TARGETS WHEN MERGE_UNITTESTS=1
      Bug#19865673 DDL LIKE ADD INDEX IS VERY SLOW IN 5.7.5
      Bug #20294225 - INVALID MEMORY ACCESS
      Bug#20275612  MEMCACHED INNODB PLUGIN BREAKS MYSQL ENTERPRISE BACKUP
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug #18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Bug#19822257: WRONG VALUE PASSED TO --INIT-FILE OPTION CAUSES SERVER HANG
      BUG#20748570  BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      Bug#20515155 Views: Assertion failed: is_view_or_derived() && is_merged()
      Improved the way --print-defaults works.
      Bug#20615597 Assertion !thd->is_error() at st_select_lex::prepare()
      BUG#20960406  NO_PROTOCOL.INC SHOULD BE IN MYSQL-TEST/INCLUDE DIRECTORY
      WL#8165 Use new records per key interface in NDB
      Bug #20683237 BACKPORT 19817663 TO 5.1 and 5.5
      Bug #20275612 MEMCACHED INNODB PLUGIN BREAKS MYSQL ENTERPRISE BACKUP
      Bug#20895852 UNDERSIZED TMP_TABLE_SIZE - ASSERTION OR ERROR 2027 (HY000): MALFORMED PACKET
      Bug#20895852 UNDERSIZED TMP_TABLE_SIZE - ASSERTION OR ERROR 2027 (HY000): MALFORMED PACKET
      Revert "Bug#20683741 fixed."
      Revert "Updated file have_util_uz.inc under Bug Bug#20683741"
      Revert "Fixed Bug#20683741"
      WL#6940 Server version token and check
      Bug #20052580 MISSING MUTEX/LOCK IN ACL_AUTHENTICATION()
      Bug#20318154 : NEGATIVE ARRAY INDEX WRITE V2
      Bug#20952953 RPL.RPL_SLAVE_SKIP FAILS IN VALGRIND
      Bug#20952953 RPL.RPL_SLAVE_SKIP FAILS IN VALGRIND
      Fixed Bug#20683741
      Bug#20937173 CLEANUP GIS_DEBUG USELESS CODE
      WL#6940 Server version token and check
      Bug#20922238: REDUCE HEADER FILE DEPENDENCIES IN MY_SYS.H AND M_STRING.H
      BUG#20889900: UNITTESTS SHOULD START THE SERVER WITH APPROPRIATE OPTIONS
      Bug#20810627 ASSERTION: REC_PAGE_NO > 2 IN IBUF_GET_MERGE_PAGE_NOS_FUNC
      Bug#20748570 BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      WL#8017 Infrastructure for Optimizer Hints
      Fixing the query tipping points
      Modified the test to run only on 64 bit machine
      Revert accidental changes to collections/default.push
      Bug#20927239: MY_TIMER-T UNIT TEST DOES NOT WORK WITH MERGE_UNITTESTS=0
      Bug#20922238: REDUCE HEADER FILE DEPENDENCIES IN MY_SYS.H AND M_STRING.H
      Post push fix for BUG#20431860
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Bug#20748570 BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      Bug#20902791 MYSQLDUMP DUMPS SYS_SCHEMA
      Bug#20782142 PAM tests Fixed
      Updated file have_util_uz.inc under Bug Bug#20683741
      BUG#17259750 - STACK CORRUPTION IN VIO_IO_WAIT ON MAC OS X
      BUG# 20798617 - MYSQL CALLS  EXIT(MYSQLD_ABORT_EXIT) WITHOUT                 SHUTTING DOWN INNODB.
      BUG#20597821 INVALID READ OF BLOB MEMORY FREED IN ::CLEAR_BLOB_HEAP_PART
      Bug#20911624 THE SERVER CRASH WHEN TEST ST_INTERSECTS WITH ST_BUFFER
      Bug #20904893         INNODB: FIX RECENT WINDOWS 32 AND 63 BIT COMPILER WARNINGS
      Bug#20921370: NEW CLANG 3.6 WARNINGS - MUST ENABLE -WNO-UNUSED-LOCAL-TYPEDEF
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Clean up mysql-test/collections
      Enable run of default suites on daily valgrind
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Bug#20903701 FIX VALGRIND WARNINGS IN UNIT TESTS
      WL#8161: Locking service for read/write named locks
      Bug#20789078 innodb: assertion: index->id == btr_page_get_index_id(page)
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug#18486509 ASSERTION FAILED: TABLE->KEY_READ == 0 IN CLOSE_THREAD_TABLE
      WL#8161: Locking service for read/write named locks
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Fix Bug#20618309 ASSERT SLOT1->PAGE_LEVEL == SLOT2->PAGE_LEVEL, BTR_ESTIMATE_N_ROWS_IN_RANGE()
      Bug #20476395 DICT_LOAD_FOREIGNS() FAILED IN COMMIT_INPLACE_ALTER_TABLE
      Bug#20573701 DROP DATABASE ASSERT ON DEBUG WHEN OTHER FILES PRESENT IN DB FOLDER.
      Bug#20573701 DROP DATABASE ASSERT ON DEBUG WHEN OTHER FILES PRESENT IN DB FOLDER.
      Bug#20902600: REDUCE HEADER FILE DEPENDENCIES IN SP* AND EVENT* FILES
      Bug #20883256         INNODB: WARNINGS: NONNULL PARAMETER WILL EVALUATE TO 'TRUE' ON FIRST ENCOUNTER
      Bug#20888417: REMOVE FUNCTION DECLARATIONS WITHOUT DEFINITIONS
      Bug#20814396 PB2 IS SECRET ABOUT WHAT UNIT TESTS IT RUN
      WL#8161: Locking service for read/write named locks
      BUG #20414588 - REMOVE HARD-CODED AIO DISABLE FROM MTR
      Bug#20882432 INCORRECT MERGE_THRESHOLD LENGTH IN SYS_INDEXES AFTER UPGRADE, TRUNCATE, RESTART
      Clarify comment in my_global.h about where and why this header should be included.
      Dummy commit to keep the push hook happy.
      Bug#20856729: QUERY REWRITE: WRONG IFDEF SYMBOL IN SERVICE_PARSER.H
      Bug#20364862 : MYSQLADMIN PASSWORD AFFECTS EXTERNAL AUTH ACCOUNTS
      Bug#20364862 : MYSQLADMIN PASSWORD AFFECTS EXTERNAL AUTH ACCOUNTS
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Bug #19953365 MY_PRINT_DEFAULTS DOES NOT MASK PASSWORDS
      Bug#20752436: INNODB: FAILING ASSERTION: 0 IN FILE HANDLER0ALTER.CC LINE 6647
      BUG#17650326 MYSQLBINLOG PRINTS INVALID SQL FROM RELAY LOGS WHEN GTID IS ENABLED
      Bug#20350989: MYSQLBINLOG CAN'T DECODE EVENTS > ~1.6GB
      Bug#20609063 - STDOUT AND STDERR REDIRECTION ISSUES
      Bug#20752436: INNODB: FAILING ASSERTION: 0 IN FILE HANDLER0ALTER.CC LINE 6647
      Bug#20886222 MOVE THE DECLARATION OF FIL_NODE_T TO A HEADER FILE,              AND CLEAN UP COMMENTS Move the definition of the data structure fil_node_t from fil0fil.cc to fil0fil.h so that diagnostics code outside that module can access information about the files belonging to a tablespace. Also do other cleanup and formatting changes.
      Bug#20888417: REMOVE FUNCTION DECLARATIONS WITHOUT DEFINITIONS
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Test cleanup
      Convert a func comments to new the InnoDB style.
      Non-functional style fixups
      Bug#20872436 MAKE DIST BY MISTAKE COPIES FILES WITH VARIABLE EXPANSION
      Bug#20882345: MOVE CODE OUT OF HANDLER.H
      Post-merge fix for WL#7806: Remove bogus files.
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug#20615023 SIGNAL 11 IN ITEM_FIELD::RESULT_TYPE DURING 1ST EXECUTION OF PREPARED STMT
      Bug#20872436 MAKE DIST BY MISTAKE COPIES FILES WITH VARIABLE EXPANSION
      BUG 20459905 - DEADLOCK OF THREADS DETECTED! 5.7.5, 1 THREAD SQL TESTCASE, SPORADIC, IN IB_LOGF
      Bug#20863042 Stop filling mtr logs with InnoDB page dumps
      Remove a test from the experimental collection.
      Bug#20865407: DBUG_ASSERT(1) MAKES NO SENSE
      BUG#20857756: BUILD NT_SERVC.CC ONCE FOR ALL UNITTESTS ON WIN32
      Clean up the post-commit fix for Bug#20872655 debug instrumentation.
      Bug#20874411 INNODB SHUTDOWN HANGS IF INNODB_FORCE_RECOVERY>=3 SKIPPED ANY ROLLBACK
      Followup fix for BUG#20518099
      Post-commit fix or work-around for Bug#20872655 debug instrumentation.
      Post-merge fix for Bug#20872655 XA ROLLBACK IS NOT CRASH-SAFE
      Bug#20518099 - CLEANUP UNIV_INNOCHECKSUM in innodb code base
      Bug#19363615 : innodb.log_file fails very frequently on windows and solaris. Moved test from experimental to disabled state
      Raised version after tagging 5.1.74 (some commits skipped)
      Bug#20872655 XA ROLLBACK IS NOT CRASH-SAFE
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Bug#20788811 MAX_STATEMENT_TIME: ASSERTION `EXPLAIN_OTHER || UNIT->IS_OPTIMIZED()' FAILED.
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Test cleanup
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES            OF INNODB_CHECKSUM_ALGORITHM
      Bug#20104307 GTID_EXECUTED TABLE COMPRESSION THREAD MAY NOT WAKE UP
      sys_vars.innodb_compress_debug_basic requires P_S to run
      Bug#20859285: REDUCE HEADER FILE DEPENDENCIES OF SQL_CLASS.H AND TABLE.H
      Add daily and weekly collections of tests that shun --parallel.
      Bug#20578834 - INNODB READ ONLY MODE AND NON EXISTENT TMP DIR CRASHES SERVER
      Bug #20809045    BUFFER OVERFLOW IN MYSQL
      Silence rpl_xa_survive_crash_debug in Valgrind.
      Bug# 19573096: LOADING CORRUPTED GEOMETRY DATA INTO A                MYISAM TABLE CAUSES THE SERVER TO CRASH
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES                    OF INNODB_CHECKSUM_ALGORITHM
      Bug#20857979 REMOVE DEPENDENCY ON HANDLER.H FROM PFS_ENGINE_TABLE.H
      Bug#20768820 MAIN.BIGINT TEST FAILS WHEN BUILT WITH GCC 5 IN RELEASE BUILD
      Bug#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bug#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bug#20855853 MDL SUBSYSTEM ENCAPSULATION BROKEN
      Bug#20816223 test fix.
      Remove MCP_WIX
      Remove MCP_WIX
      WL#7806: Add a test case from Viswanatham Gudipati with some cleanup by me.
      Test cleanup
      WL#7806: Relax a test that started to fail due to WL#6205.
      WL#7795 PERFORMANCE SCHEMA, HISTORY PER THREAD
      WL#7795 PERFORMANCE SCHEMA, HISTORY PER THREAD
      Clean up a test case. Use slow shutdown in order to avoid generating redo log after restart, for processing old undo logs or change buffer records.
      WL#7806: Re-enable a test and work around a problem in WL#6965.
      WL#7806: Add a temporary workaround until WL#7691.
      WL#7806: Temporarily remove the fil_sys_lookup[] for user tablespaces in order to ensure that we are not masking Bug#18645050.
      WL#7806: Add a flat fil_sys_lookup[] array so that fil_spaces_lookup() can avoid acquiring fil_system->mutex when looking up the system tablespace or the undo tablespaces. This is addressing a performance regression.
      WL#7806: Correct some comments.
      Test that no redo log gets generated unexpectedly.
      Rename some tests to comply with new policy:
      Try to get a test to work on Windows.

[33mcommit ca6ecd8229c53b0a139304bf6641cef6e529e61a[m
Merge: b840f9e9e35 2e91bec76f5
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Apr 8 12:35:31 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug #20590548 UNABLE TO LOGIN WITH USER WHOSE PWD CHANGED FROM 5.6.23 MYSQLADMIN IN 5.7.6
      Bug#20726413 : MYSQL_SSL_RSA_SETUP DOES NOT HAVE USER OPTION
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES                    OF INNODB_CHECKSUM_ALGORITHM
      WL#8244 Hints for subquery strategies. Part#2: Add support for SEMIJOIN/_SEMIJOIN and SUBQUERY hints
      WL#8244 Hints for subquery strategies. Part#1: Add optimizer_switch for DuplicateWeedout strategy.
      WL#7696 follow up fix, check return values.
      Fixed bug#20745142: GENERATED COLUMNS: ASSERTION FAILED: THD->CHANGE_LIST.IS_EMPTY()
      Fixed bug#20797941: WL8149:ASSERTION `!TABLE || (!TABLE->READ_SET ||                     BITMAP_IS_SET(TABLE->READ_SET
      BUG#20593808 - CRASH WITH PARTITIONED TABLES + MULTITABLE DELETE
      WL#7696 follow up fix.
      Bug#20788853 MUTEX ISSUE IN SQL/SQL_SHOW.CC RESULTING IN SIG6. SOURCE LIKELY FILL_VARIABLES
      WL#7696 followup - remove unused file
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, rerecord the test
      WL#7696 follow up fix, add INNODB_COMPRESS_DEBUG to the test.
      Bug#20840377 UNITILAISED BYTES REPORTED AT MY_WRITE.C:63
      Fixed failing tests after commit 335a53004313ab5a971cf17dea36f1dc4490db9f MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20755430 COST CONSTANT CACHE MUTEX NOT INSTRUMENTED BY PERFORMANCE SCHEMA
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      WL#7696 follow up fix.
      WL#7696 follow up fix - add INNODB_COMPRESS_DEBUG to the list
      Addendum to bug #20810928: fixed the test to reflect that COM_SHUTDOWN can be a zero-length RPC
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20678411 BROKEN MAKEFILE DEPENDENCY: SQL_YACC.YY AND LEX_TOKEN.H
      Bug #17299181    CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      BUG#20093172 LOG_STATE DECLARED VOLATILE, MISSING MEMORY BARRIERS
      BUG#20042205 RPL_GTID CHECKABLE_RWLOCK DEBUG CODE DOESN'T NEED VOLATILE              LOCK_STATE
      BUG#20042109 MYSQL_BIN_LOG::M_PREP_XIDS DOESN'T NEED TO BE VOLATILE
      BUG#20754369: BACKPORT BUG#20007583 TO 5.1
      Bug #17299181  CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      Bug#20411374:CAN NOT EXECUTE CHANGE MASTER AFTER ERROR OCCURED IN MTS MODE
      Bug#20683741 fixed.
      Bug #20814051 CREATE USER BINLOG EVENTS INCLUDE NEW ACCOUNT KEYWORD
      BUG#20510811 - RQG_ALTER_ONLINE_PART RUN INTO ASSERTION: NODE->ENTRY
      Bug#20279241 - ALTER TABLE XXX CHARACTER SET UTF8, CONVERT TO CHARACTER SET LATIN1 SHOULD FAIL
      Adapt new sql/ha_ndbcluster.cc code to use the new ER_THD() macro
      Remove MCP_GLOBAL_SCHEMA_LOCK patch
      Bug #20810928: CANNOT SHUTDOWN MYSQL USING JDBC DRIVER
      Fixed Bug #20683741.
      Test cleanup
      Bump version to 7.5.0
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20811494 SHOW_COMPATIBILITY_56 = OFF INCOMPATIBLE WITH CONNECTORS
      Bug#20531812: MEMORY CONSUMED QUICKLY WHILE EXECUTING LOOP IN PROCEDURE
      Bug#20683959 LOAD DATA INFILE IGNORES A SPECIFIC ROW SILENTLY UNDER DB CHARSET IS UTF8
      Remove MCP_BUG16021021
      Remove MCP_WIX
      Bug#20313067 CHECK TABLE REPORTS WRONG COUNT FOR SPATIAL INDEX AND OTHER GIS PROBLEMS
      Bug#20124342 MYSQL 5.6 SLAVE OUT OF MEMORY ERROR ? Problem: I/O thread on Slave with master_info_repository=TABLE settings, is leaking memory that leads to Out of memory (OOM) after some time.
      Fix merge error in mysql_system_tables_fix.sql
      Remove MCP tags for BUG16226274
      BUG#20811125 INNODB FTS: FTS_PRINT_DOC_ID PRINTS TOO MANY DEBUG INFORMATION
      Bug#20762059 - innodb_thread_concurrency=1 and queries using intrinsic temp tables, causes hang
      Create an .inc file which does slow shutdown before restarting innodb in read-only mode.
      Bug#19811953 ENVELOPE() FUNCTION RETURNS INVALID POLYGON Bug#20196720 ENVELOPE(P) RETURNS NULL FOR A NON NULL POLYGON P
      Bug #20544581         ASSERTION: REC_PAGE_NO > (ULINT) 4 - (REC_SPACE_ID != 0)
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 - Fix a merge issue.
      WL#7696 - Fix a merge issue
      WL#7696 - Fix the column ordinatlity. Messed up in a previous merge.
      WL#7696 - Fix a compilation error
      move some compression tests elsewhere until using Win32::API module is approved. Improve error detection, if there is no module, the tests will succeed, not fail as before, but the testing power will be somewhat limited.
      Bumped rpm version for oel due to respin
      Bug#20756770 MYSQL SERVER DOESN'T COMPILE AGAINST OPENSSL 1.0.1M
      Patch for Bug#17162055: SSL.CMAKE SILENTLY CHOOSES BUNDLED YASSL INSTEAD OF ERRORING FOR OLD OPENSSL VER
      Bug#20755346 EXAMPLE SCRIPT IN FIREWALL MISSES WHERE CLAUSE
      Bug#20764521 REGRESSION: FIREWALL USE GENERAL_HOST TO RESOLVE HOST
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      Resurrect unintentionally remove disabled.def file
      Resurrect unintentionally remove disabled.def file
      Bug#20651661 NDBEVENTBUFFER LEAKS GCI_OP
      Remove three files which did not properly remain
      WL#7696 - Make LZ4 decompress safe during recovery
      Remove hack to allow large number of failing tests in mtr.pl
      WL#7696 - Reset the contents of the page to NUL.
      WL#7696 - Use the double write buffer pages for compressed pages.
      WL#7696 - Fix syntax error on Windows.
      WL#7696 - Fix debug assertion.
      mysql-test/include/innodb-compress-utils.inc:   add OSD support to get allocated file size for Windows
      add the result file missing in the previous commit
      Test update:   mysql-test/suite/innodb/t/table_compress.test:     fix one failing case for 32k   mysql-test/suite/innodb/r/table_compress_2.result: make use of new     include files   mysql-test/suite/innodb/t/table_compress_3.test: new test to cover     what was not covered yet, shared tablespaces in particular   mysql-test/include/innodb-compress-verify.inc: common sequence     for compression verification   mysql-test/include/innodb-compress-utils.inc: perl compression     related utilities.     Note: OSD Windows file allocated size is not implemented yet.     The test is still expected to pass on Windows because the allocated     size is forced to the expected value.
      Bug #20536590: BACKPORT BUG #12368204 AND BUG #16953758 TO MYSQL-5.6
      WL#7696 - Code clean up. Ignore table COMPRESSION setting if set to NONE.
      WL#7696 - Minor code cleanup
      WL#7696 - Fix the punch hole size calculation.
      Bug#20712432 AUTOTEST: TESTFK FAIL IN CLEARTABLE WITH 256 REFERENCED ROW EXISTS
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#17775772 POTENTIALLY UNINITIALIZED BUFFER IN NDBOUT::PRINT* PRINTOUT   - print nothing or just empty newline instead of uninitialized buffer   - catch error with an assert in debug compile
      Bug#17775607 POTENTIALLY UNINITIALIZED BUFFER IN VNDBOUT_C PRINTOUT  - print empty newline instead of uninitialized buffer  - catch error with an assert in debug compile  - Mark vndbout_c as static and thus local to implementation Conflicts in copyright:        storage/ndb/include/util/NdbOut.hpp     storage/ndb/src/common/util/NdbOut.cpp
      Remove unused parameter ndbcluster_drop_event()
      Bug#20032381 KILLED_STATE SAVE IN NDBCLUSTER_BINLOG RETRY AT SHUTDOWN DOESN'T NEED TO BE VOLA
      Bug#20014045 MONOTONIC SPELT INCORRECTLY IN NDB CODE
      Bug#20092754:  MYSQLD CRASH (FOUND UNCOMITTED AUTOCOMMIT+RBWR TRANSACTION, COMMIT STATUS 3)
      mysql-test/suite/innodb/t/table_compress_2.test:
      Raise version number after cloning 7.4.5
      Correct MTR command for 64k run. Adiing missing "k".
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      Tetss that use innodb_compress_debug should run against debug server
      Added runs with differnt combination and page size setting for Innodb suites
      mysql-test/suite/innodb/t/table_compress.test:   Fix failure when hole punching is not available.   Now the test will be skipped instead
      Revert accidental bump of server version back to 5.6.23
      Fix a compilation warning in non-debug mode
      BUG#18949230: Removed unneeded ndbassert and fixed printout, also recorded number of real periods
      Added some extra output to ndbapi tests utilities as an aid to hunt down the AutoTest failure 'testBasic -n Bug54986 D2'
      Added log printout about invalidation of REDO log and where log head was found
      WL#6815 Adapt MySQL Cluster to 5.7
      Added autotest files for Mikaels environment, added comments about how to get file system as part of results in autotest, added comment about how to handle older git versions with autotest
      BUG#20546157: Fix problems in START_PERMREQ and START_INFOREQ that hangs node restarts when invalidation of nodes is still ongoing at node restart
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20480035 REMOVE MCP_BUG44529
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disable ndb_rpl_circular_2ch* waiting for Bug20592110
      Disable ndb_addnode_witbinlog waiting for Bug17400320
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75720: Fix platform issues with ndb_dd_dump test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      WL#7696 - Don't print a warning on Windows if SPARSE FILE attribute can't be set
      BUG#20631645: Ensure that SYSFILE->latestLCP_ID is properly up-to-date in the pause LCP protocol
      Fix regression caused by wl#7674 in testBasic -n RefreshTuple T6 D1
      Fix regression caused by wl#7674 in testDict -n Bug13416603 I2.
      Fix for Bug#20408733:
      WL#7696 - Punch hole message is Linux specific.
      WL#7696 - Backport code from mysql-trunk to mysql-5.7
      Followup fix for "Bug20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK"
      WL#6815 Adapt MySQL Cluster to 5.7
      Another follow up fix for "BUG11748566 - MYSQL SHOWS WRONG DEFAULT VALUE FOR PK IF  NOT NULL NOT SPECIFIED"
      BUG#20568586: Fix ndb_cpcd to avoid reading a closed file
      BUG#20567730: Ensure that late arriving LCP_FRAG_ORD with lastFragmentFlag set from new master are handled correctly, correct is to ignore them if such a signal arrives in idle LCP state
      Fix for bug#20538179
      BUG#20546899: Faulty ndbrequire fixed
      BUG#20553247: Fix memcpy overlapping copy issue
      BUG#20553247: Use memmove for overlapping memory copy
      Commit this fix on behalf of Pekka N:
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      BUG#19811871 VERSION NUMBR NOT SHOWN IN LOG WHEN [RE]STARTING 5.6.21 SERVICE WITH SLES11 REPO
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      Updated copyright information
      Bug#20228839: MISSING DATABASE '-D' OPTIONS FOR FEW OF THE HUGO TOOLS
      Re-enable clusterj tests disabled during 7.4.4 release.
      Bug#20593065 MULTI UPDATE RETURNS DIFFERENT DATA WITH ENGINE NDB
      This commit is a followup to the fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_time calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop timeout to be configured).
      Add support for SLES12
      Merge 7.3->7.4
      Merge 7.2->7.3
      Overriding release() function from the DynamicObject class in its subclasses.
      This commit is a fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_time calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop timeout to be configured).
      Reverse order of libraries used when linking the ndbapi examples
      Add small MCP for problem with Partition_handler::get_default_num_partitions
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM: fix test regression
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7549: Fix test case for removed EMPTY_LCP protocol
      BUG#20444078: Removed unneeded log printout
      BUG#20444078: Fix master takeover of COPY_GCIREQ protocol
      WL#6815 Adapt MySQL Cluster to 5.7
      Revert accidental version number change
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20528878 : P_S UNIT TEST IS FAILING
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM
      Temporarily hack mtr.pl to allow a large number of failing tests
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disabling ndb.clusterj and ndb.clusterj_jpa tests for 7.4.4 release.
      WL#6815 Adapt MySQL Cluster to 5.7
      bump version to 7.4.5
      Bump version to 7.4.5
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20281479: Entered eternal loop when starting node in MGM server due to buggy bug fix
      Fix unintentional increase in testsize by a factor of 100 of 'testBasic -n Bug54986'
      BUG#20513571: Introduce MaxSendDelay for large clusters
      Fix failing AutoTest 'testIndex -n NFNR3*'
      BUG#20512063: Moved verbose logging to only be used in verbose mode
      Add missing failure detection for 'testBasic -n Bug54986'.
      BUG#20281479: Ensure that START_ORD is properly sent from management server
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20504971: Fixed restart_info table to provide its output
      WL#6815 Adapt MySQL Cluster to 5.7
      Proper error printouts after reaching NDBT_FAILED in test cases
      Backport fix for BUG#20276462
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Updated to newest version of flexAsynch
      Patch related to bug#18401543
      BUG20308276: Don't use same list for master and participant part of takeover processing
      Fix issue in AutoTest where test are being killed by WatchDog during memory allog in startphase 0.
      BUG20276462: Fixed spelling error in error code
      BUG#20276462: Error code ZNODE_FAILURE_ERROR has no treatment in NDB API, use NODE_SHUTDOWN_ERROR instead
      WL#8148 NDB: Add git support to Autotest
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT
      Bug#20234994 JOINS ARE NOT PUSHED AFTER WL6042
      Revert "Adapt pushed joins to WL#6042"
      Fix for Bug#19053226 AUTOTEST FAIL: TESTSRBANK -N MIX -L 300 -R 15 T1
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) PART III
      Bug#20410087 GCOV COVERAGE DATA FOR NDB KERNEL IS MISSING
      WL#8294 NDB: turn on signal checksum as default
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Disabling mtr tests on 7.1 which fail because SSL certificates have expired.
      Re-recording mtr test result after ssl certificate update
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT Generated new certificates with validity upto 2029.
      Fix test client failure for AutoTest 'testNodeRestart -n ClusterSplitLatency'
      Bug#19785977:  CRASH IN NDBINDEXSCANOPERATION::SCANINDEXIMPL
      Bug#20423898 BAD TEST TESTNODERESTART -N LCPTAKEOVER CAN NOT FAIL.
      Improve ndb_rpl_circular_2ch_rep_status reliability.
      Test was random failing due to matching random binlog junk. Make false matches less likely.
      A little brute force to understand the issues with ndb_rpl_circular_2ch_rep_status
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      Experimental experiment with experimental status.
      A more standard variant of !valgrind.
      BUG#19667566 : PARTITION BY WITH COMMENT LEADS TO MYSQL SERVER REBOOT IN MYSQL CLUSTER
      Sacrifice Valgrind run to improve ndb_rpl_slave_binlog_index reliability.
      Backport of fix for bug#16209645
      Bug#17579998 TEST 'TESTNODERESTART -N GCP -L 1 T1' FAILS DUE TO MYSQLD ABORTED
      ndb_rpl_slave_binlog_index.test
      ndb_types.test contained binary raw data from 'bit' and 'binary' columns.
      Bug #20372169         NDB : INCORRECT STATUS VARIABLES NDB_LAST_COMMIT_EPOCH_[SERVER|SESSION]
      Fix of uncorrect merge (7.2 -> 7.3) of regression fix for bug#19524096
      Fix regression introduced by fix for bug#19524096.
      Fix regression introduced by fix for bug#19524096.
      Fix regression introduced by fix for bug#bug#19524096.
      Improve ndb_rpl_slave_binlog_index.test behaviour under Valgrind.
      Bug#20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK INTEGRATION
      Add some improved debugging to help understand non locally reproducable problems with ndb_binlog_last_commit_epoch testcase.
      This commit is a fix for Bug#19880969 (CLUB FOR 7.1, LINUX-RELEASE, 345 WARNINGS IN BUILD). The fix suppresses these warnings, so that the corresponding square in club becomes green rather than red.
      Bug #19306793         CORE IN NDBAPI WHEN EXTENDED EXTENSION TABLE IS CREATED IN MYSQL 7.4
      Quick fix of corrupted special comment characters. No code change.
      Updated the copyright year in README and welcome message
      Improve garbage collection of clusterj artifacts
      Updating copyright year
      Some copyright fixes to files changed in 2014
      Fixing user visible copyright years
      Fix for 7.4.3 build failures
      Fix for copy right year
      Corrected copyright year by sreedhar
      Updated README and banners to 2015
      bump version to 7.1.35
      pgmanpe pe-dump.diff pgman: dump max page entries bug#18484117 bug#19915761 bug#19958804
      pgmanpe pe-config.diff pgman: configure max page entries bug#18484117 bug#19915761 bug#19958804
      BUG#19480197, BUG#73667, BUG#74945: Ensure Local object has transferred back object to real object before calling recursive function
      Cherrypick fix which removes MCP_WL1735 from 7.4
      Cherrypick fix for bug20009152 from 7.4
      Adapt pushed joins to WL#6042
      Follow up fix for bug#20112981
      Fix for bug#20112981
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - rewrite clean_away_stray_files() to use find_files() direct rather than going via make_db_list(). - The only difference between make_db_list() and find_files() is that the information_schema database is not   return in the list of databases. But it's currently not possible  to create a NDB table in information_schema   and thus there can not be any "stray" tables there either.  - testcase added to ndb_reconnect which shows access denied when trying to create table    in information_schema  - This avoids patching the MySQL Server to make the static make_db_list() function available    to use in ha_ndbcluster_binlog and thus the MCP for make_db_list() and LOOKUP_FIELD_VALUES   can be removed. - Also remove the NDB_WITHOUT_MAKE_DB_LIST which was used for compiling ndbcluster in MySQL Server
      Remove unused TNTO_NO_REMOVE_STRAY_FILES Thd_ndb option
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#19898269, BUG#74594: Fixed wrong order of sending bitmap of LCP participants to ensure that starting node can correctly calculate the lcpOngoing flag for each fragment
      Another addendum patch for bug#20112981, adressing comment from Mikael R.
      Incremental addendum patch for bug#20112981
      Fix for bug#20112981
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#75220: Added option to use 10 and 20 LDM threads (same for NoOfLogParts)
      BUG#20215395: Bug in cluster join protocol
      Added jams to place where data nodes freezes in startup
      BUG#19590336: Preparatory patch adding lots of jam:s to DD code, also a few more more comments added
      Additions to wl#7674
      Bug#18715165, BUG#17069285
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug#20193236 SOME COMPILER WARNINGS BECAME ERRORS AFTER MERGE OF MYSQL SERVER 5.5.41
      Cherrypick from 5.6 : Bug#20009154 - FIX REGRESSION AFTER HA_FLUSH_LOGS() HOOK FOR NDB IS REMOVED.
      Bug 19895502 -  BINARY LOG GROUP COMMIT CAUSES REGRESSION FOR NDB REPLICATION.
      This commit is a followup to WL#8145 (NdbInfo : Per-fragment operations info). That WL introduced an error causing 'testScan -n Bug54945 T1' to fail: short-signal scans crashes because the attrinfo section is not available at the point where the code tries to read it to find the size of the interpreted progam. This commit fixes that by not trying to count program size for short-signal scans and lookups. Since these only happen during online upgrade, they are not important for per-fragment statistics.
      Bug #19992856 MYSQL CLUSTER TRIGGER ON DELETE FALSE POSITIVE
      This commit is a followup to the fix for bug#19976428 ("reports failing with 'out of longmessagebuffer' error"). This commit updates a regression test (testIndex/FireTrigOverload) so that it will expect the right error code (293 "Inconsistent trigger state in TC block" instead of 218 "Out of LongMessageBuffer").
      autotest auto1.diff testBasic -n Bug16834333 : fix dict cache crash
      Bug #19858151         MAKING DATA NODE SELF-EXCLUDE MECHANISM MORE ROBUST
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Updated fix for bug#20113145:
      Follow up to fix for bug#bug#20166585:
      Follow up to fix for bug#bug#20166585:
      This commit fixes bug #19976428 ("reports failing with 'out of longmessagebuffer' error"), and a set of other issues related to the pool of "Fired Trigger" records.
      Bug#17069285 : SEGMENTATION FAULT IN NDB_PRINT_FILE
      Update to recent fix where we failed to close scan cursors at the end of their lifetime.
      WL#7514: Fitted into infoEvent max size and decreased some too wordy log printouts
      Update 'v3' fix for bug#20166585:
      WL#7514: Fixed an incorrect assert
      Fix for various AutoTest 'testIndex ...' crashing due to excessive memory usage.
      Bug#18715165, BUG#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for: - Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT - BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      The AutoTest testcase 'testScan -n Bug54945 T1' crashed as it failed to create a transaction object which was later referred without first checking that it was created.
      Fix for crashing AutoTest: 'testNdbApi -n RecordSpecificationBackwardCompatibility'
      WL#6815  Adapt MySQL Cluster to 5.7
      Fix flexAsynch also in 7.3, backport from 7.4
      WL#7508: Parallelize synchronization of starting nodes with live nodes
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - Test fails since the two new default sql_modes  ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES   are displayed by "show create procedure"  - Update .result file to include the two new default sql_modes(as has been done in similar   places)
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      Experimental fix for several AutoTest which crash with an unreadable stack dump very early in their lifecycle, like:
      Fixed crashing AutoTest testBitfield.
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Cherrypick fix for ndb_memcache out of source from 7.4
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20135403 NDB_MEMCACHE TEST DOES NOT WORK IN OUT OF SOURCE BUILD
      Fixed crashing AutoTest: './testLimits -n ExhaustSegmentedSectionPk WIDE_2COL'
      Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT
      BUG#74594: Fixed a hang in PAUSE LCP protocol when LCP was completed between PAUSE and UNPAUSE
      Removed lots of jam noise from QMGR preventing one from seeing the bugs
      WL#6815  Adapt MySQL Cluster to 5.7
      Revert some junk lines from pfs_upfgrade*.result files
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherry-picked from mysql-5.6.22-release
      Cherry-pick from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-pick from mysql-5.5.41-release
      Added tag mysql-5.6.22
      Added tag mysql-5.5.41
      BUG#74594: Fix missing state update that causes PAUSE LCP protocol to hang
      BUG#74594: Added some more DUMP printouts for PAUSE LCP protocol
      WL#7650: Make atrt work on Mac OS X
      Removed assert / require from NDBT_ResultRow c'tor and rewrote it such that it could be constructed even if the the object is not in 'Retrieved' state.
      BUG#75007: Ensure we wait until master takeover is completed before handle LCP_COMPLETE_REP from LQH and DIH participants in the LCP protocol
      Bug#20029843 7.4.2 REGRESSION: UPGRADE_TRAFFIC FAILURES FOR 7.4 -> 7.3: Fixed incorrect conditional expressions
      Cherrypick fix for ndb_dist_priv.sql from 7.4
      WL#6815  Adapt MySQL Cluster to 5.7
      Cherrypick fix for mysql_system_tables_fix.sql from 7.4
      WL#6815 Adapt MySQL Cluster to 5.7
      Encourage MySQL to treat numeric variables as numbers so that ndb_rpl_conflict_epoch2_extra does not return incorrect results from inequality tests.
      BUG#75007: More work on ensuring that we drop the right signals of the LCP_COMPLETE_REP and LCP_FRAG_REP, a bit tricky to decide, wrote up an analysis in a comment and a fairly simple code based on this analysis
      Cherrypick fixes for ndb_alter_table_online from 7.4
      Remove usage of DEFAULT 0 for TIMESTAMP
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fixed for ndb_update_no_read from 7.4
      Turn "info" off after each section in test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fix for ndb_dd_disk2memory from 7.4
      Add missing enable_query_log comman in ndb_dd_disk2memory.test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75007: Fixed interaction with early master takeover initialisation and handling of failed node in LCP, code in new master
      BUG#75007: Handle side effect of bug fix, there are signals generated by node failure handling that must be allowed to pass through the code as they are required for node fail handling to be done properly
      Apply patch for MCP_BUG19704825to 5.7.5
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#74594: Fix of variable length in message to management server to avoid printing garbage
      BUG#75007: Ensure that we drop LCP_FRAG_REP and LCP_COMPLETE_REP that originates from a dead node. The LCP could potentially be done before this arrives due to node failure handling, these signals are sometimes delayed and thus we need to take care that we can still receive them.
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Assumption that all alive nodes have participated in LCP at close down time caused havoc since we can now be alive and still not have participated in the LCP. So had to move the send of the last LCP_COMPLETE_REP backwards a bit to be able to reuse the m_participatingDIH bitmap to send to.
      remove last NDB_WITHOUT_COLUMN_FORMAT ifdef  - since all versions of MySQL Server which ndbcluster   compiles against now supports "field->column_format" and "field->storage_type" - one NDB_WITHOUT_COLUMN_FORMAT left behind(or reappeared)
      BUG#19795152: Missed essential ptrCheckGuard in upgrade/downgrade situations
      WL#7514: More printouts to log for system restart case
      BUG#18610698: New test case
      BUG19795152: Fix Software upgrade issue
      Add missing delete of Ndb instance created by testcase
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Minor tweak of jamming and of a loop
      BUG#19795217: Checked the LCP state a bit too early
      BUG#74594: Added one more cluster log event
      BUG#74594: Wrong check if LCP is idle when sending UnPause message
      bug#20045455 Improve error reporting for clusterj
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Fixed a compiler warning in new tool
      BUG#74594: Wrote an analysis tool for reading DIH Fraglist files to enable easier analysis of system restart bugs
      BUG#74594: Queued LCP_COMPLETE_REP comes from LQH, not from DIH
      BUG#74594: Fixed a typo bug in an important condition
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Added a new ndbrequire to find problem
      WL#7514: Added a bit more logging of the actual start order signal
      flexBench created its worker threads, flexBenchThread, with a stack of insufficent size. This later caused the threads to crash.
      WL#7509: Add undocumented interface to change Disk Write Speed in LCPs, change isn't persistent over restarts, useful to handle SRs where restarts are too slow
      WL#7509: Tweaked the adaptive LCP speed parameters to be a bit slower in changing
      BUG#74594: Add DUMP_STATE_ORD variant to print pause state to cluster log
      BUG#19795108: Proper fix of node restart status using the new Node Recovery Status module
      BUG#19795152: Handle Partial System restarts
      BUG#74594: Used wrong variable in non-master to decide on pauseAction
      Attempt better "htonll" portability in NDB memcache code
      Fix for bug#19390895
      BUG#74594: Ensure that we drop PAUSE_LCP_REQ signals from master if it concerns a node that already has died
      BUG#74594: Node failure in inopportune time caused crash
      BUG#74594: Decrease amount of useless jam:ing to make bugs more visible
      Bug#19642978: NDB_RESTORE CORES ON BUILT-IN PRIMARY KEY + STAGING BLOB CONVERSIONS ON SPARC
      Fix for bug#20031313  AUTOTEST CASE 'TESTDICT -N GETTABINFOREF' NEVER WORKED FOR >= 4 DATA NODES
      BUG#74594: Turned ndbrequire condition the wrong way, caused obvious crash, added a few more ndbrequires while at it
      BUG#19795152: Also NODE_FAILURE_COMPLETED and ALLOCATED_NODE_ID can be states from where a node fails from DISCONNECT_REP although the node hasn't really started its start yet.
      BUG#74594: Removed buggy ndbrequire, not correct though to possibility of delaying arrival of LCP_FRAG_REP when copying table to disk
      BUG#19795152: NdbTick_Elapsed parameters in wrong order
      BUG#19795152: Added one more acceptable state transition, ALLOCATED_NODE_ID -> ALLOCATED_NODE_ID
      BUG#74594: Missed setting lcp id in COPY_TABREQ, added ints of LCP variables on replica and fragment records, removed init of lcpStatus in INCL_NODEREQ which depended on old fact that we included when LCP was idle, now this is no longer necessary, missed init of m_lcp_start_time in including node in LCP, added a number of log prints
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#19676350 NDB_RPL_CONFLICT_EPOCH SHOWS SCHEMA DIST TIME FAST FORWARD DUE TO EINVAL
      BUG#74594: missed init of c_queued_lcp_complete_rep
      BUG#74594: Handle fromTimeQueue issues with LCP_FRAG_REP
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed stopping of pause properly in master and in non-master
      BUG#74594: Wrong assumption in START_LCP_REQ removed, fix of ndbrequire of COPY_TABREQ counter improved
      BUG#74594: Added new parameters to allocStoredReplica
      BUG#74594: Missed init of fragId and tableId in replica record, wrong assumption about m_participatingDIH in START_LCP_REQ
      BUG#74594: Missed clear of own node in NodeReceiverGroup in sending FLUSH_LCP_REP_REQ
      BUG#74594: Fixed typo
      BUG#74594: Missing inserts into signal table
      BUG#74594: Fixes for wrong assert, missing state update and wrong condition
      BUG#74594, fix for sanity check
      BUG#19795152: Fix a placement new that overwrote the node recovery timers in debug mode, added a bit more debug code and arranged the parameters in some common functions a bit more logically
      BUG#74594: Added missing file CopyTab.hpp
      BUG#74594: Remove need for long wait for LCP to copy meta data to make restart times more predictable and [1;31mfast[mer
      BUG#74639: Preparatory patch to handle overload bugs that is likely to be caused by higher pressure on LCPs and restarts
      BUG#19795152: Added missing file: NodeRecoveryStatusRep.hpp
      BUG#19795152: Wait for LCP start at node restart, add node recovery status table as well
      BUG#19795217: Remove EMPTY_LCP protocol from master takeover
      BUG#74594: Part 2: Fix a potential LCP stoppage
      BUG#74594: Part 1: Remove a faulty ndbrequire
      BUG#19795029: Improve logging of restarts developed in WL#7514
      BUG#19795108: Fix of node restart status for adapting speed of LCP disk write speed
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug#20007248 NDB NOT FUNCTIONAL ON POWER
      Bug#20007216 FLEXASYNC USES 32BIT MATH, LEADING TO INCORRECT SUMMARY ON POWER8
      Fix regression in AutoTest -n DropWithTakeover T1 introduced by fix for bug#19874809:
      Add missing newline before end of file in AsyncNdbContext.cpp
      Fix build failure in MCP patch for BUG19553099
      bug#20017292 Clusterj logging levels too verbose
      Bug#20009152 FIELD NAME NOT INCLUDED IN WARNING WHEN CONVERTING TO FIXED
      WL#7640  Ndb Active Active Delete-Delete handling
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Fix Club test regressions after backport of bug#19524096:
      WL#7640  Ndb Active Active Delete-Delete handling
      Provide easy way to store documents with no mapping and no schema defined   define new method on session factory: db(database_name) returns db object   db object has properties corresponding to table names     if table does not exist, create the table       if user has not mapped the table, create default table mapping and table       if user has mapped the table, use table mapping to create the table   Operations on session using non-existing table name     will now create the table if it does not exist and user has mapped the table
      Fix bad #ifdef
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Bug #19817817 TFBUFFER::VALIDATE() CONST: ASSERTION `(P->M_BYTES & 3) == 0\' FAILED
      Backport of fix for bug#19524096
      Bug#19999242 DELETEING NDB_CLUSTER_CONNECTION WITH NDB INSTANCES
      bug#19913569
      Avoid segv when closing session factory with sessions still active
      Bug #17592990: DATA MISMATCH BETWEEN C NDB API AND MYSQL CLI.
      Backport of fix for Bug#19724313
      Fix for bug#19880747:
      Fix for bug#19875663
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Fix for bug#19881025:
      This commit is an update of WL#7375 (Ndbinfo: Per-fragment memory usage reporting). Column fixed_elem_free_rows in view ndbinfo.memory_per_fragment is renamed to fixed_elem_free_count to get a more consisten naming.
      Fix for bug#19874809 :
      Added sles11 repo packages
      This commit implements WL#8145 (NdbInfo : Per-fragment operations info).
      Follow up fix for bug#18352514 fixing a build failure.
      Addendum fix for bug#18352514:
      bump version to 7.4.3
      Bug #19875710         NDB : COMMIT ACK MARKERS LEAK @ LQH IN 7.4
      BUG#19815044: Part 4, remove usage of global block variable m_pgman_ptr, it is used for parameter passing, but can in some weird situation in DBTUP it can be reassigned to a value that can cause an inconsistent database.
      BUG#19815044: Part 3, fix such that an aborted insert after a committed delete doesn't lead to that triggers for delete isn't executed by ensuring that delete_insert_flag is properly maintained
      BUG#19815044: Part 1: Improve jamming support to make it easier to read what's going on bug situations
      BUG#19815044: Add test case for it used in autotest
      BUG#19815041: Crash on abort of delete after successful delete on a disk data table
      Add global.fail_connect to test utilities
      Fix ProjectionErrorTest
      Improve error reporting for multidb tests
      big lint-fixing patch
      Fix unified_debug issue with per-file levels for C++ files Remove workaround for this in executable programs
      Converter use in DBTableHandler (fixes freeform tests for ndb)
      Big deglobalization patch. Removes many global variables (but not all).
      Move SQL.create and SQL.drop from test harness into adapters. NDB depends on MySQL for this.
      Enhance closeAllOpenSessionFactories() so it takes a callback & returns a promise
      Fix for bug#19712569
      When using node --harmony and strict mode, DBIndexHandler cannot be forward declared   and still use the function DBIndexHandler(parent, dbIndex) syntax.
      jscrund: add support for B tests with varying size varchar. (Only supported by jscrund_mysqljs crund backend).
      lint globals cleanup
      Fixes restart race causing test timeout in AutoTest 'testDict -n schemaTrans'
      Return an error if writing non-Buffer data to binary columns
      Allow flexible mapping for node.js domain classes
      Fix for bug#18352514
      Fix for bug#19661543
      Remove warning introduced with patch for BUG#19236945
      Bug #19236945 ADDRESSSANITIZER BUG SHOW UP IN NDBRECATTR::RECEIVE_DATA CALLED FROM RESTORE.CPP
      bug#19793475 - NO WAIT FOR EPOCHS THAT HAVE NO DB CHANGES MADE BY THIS NDB THD TO BE IN BINLOG
      Removing the extra blank line from daily-basic-autotest-conf
      Fixed compilation error due to changed file name
      Bug#19267720:  NDB REPLICATION : DO NOT SETUP CONFLICT RESOLUTION FOR EXCEPTIONS TABLES
      formatting
      Docs work
      BUG#19795072: Fix problems related to ndbinfo tables for disk write speed
      BUG#19643174: Fix races in relation to sending TC_COMMIT_ACK and handling of complete of a transaction
      Removed compiler warnings
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000): GOT ERROR 4547 PART II
      Cherrypick from 7.4 (revno 4354): Implement status variables exposing last commit epochs for the server   and each session.
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      BUG#19724313: Handle multiple threads crashing at the same time properly
      Added missing include for previous patch Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Restore computeChecksum to computeXorChecksum that was reverted in patch for Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Merge of Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Refactoring of Packer::unpack in preparation of merging Bug#19582925
      Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      wl#7674-5 fixing errors
      wl#7674-5 fixing errors and compiler warnings
      wl#7674 Backward compatibility/new event api methods
      wl#7675 Introduce state machine for event buffering
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) : GOT ERROR 4547 : 'RecordSpecification has overlapping offsets'
      Applying the patch for regression bug#19582807 for 7.1.33 cluster release
      Improve Query documentation
      Cherrypicked
      Cherrypicked
      Bug #19582807 MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Wl#7639 Ndb Active Active Manageability improvements
      Removed compiler warnings
      WL#7642 Ndb Active Active Binlog Read Tracking: Removed uninitialized data to remove valgrind warnings
      Work on new README
      Bug #17257842     EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #19766167         NDB : VALGRIND REACHABLE MEMORY IN NDB_RPL_CONFLICT_EPOCH_TRANS
      Fix new log printouts - Use log functions of component in favour of sql_print_information - Break long lines
      In-Progress Packaging / Documentation improvements
      Iterate array rather than for/in
      Add mynode.closeAllOpenSessionFactories()
      Windows testcase fix attempt
      Follow up patch for WL#7953 Transporter handshake retry
      WL#7642 Ndb Active Active Binlog Read Tracking: Updated result for ndb_rpl_conflict_read_tracking test case to reflect new conflict counters
      WL#7640  Ndb Active Active Delete-Delete handling
      bump version to 7.3.8
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      bump version to 7.2.19
      bump version to 7.1.34
      Bug#19692387 PORT FIX FOR BUG 18770469 TO MYSQL CLUSTER 7.3
      Added ndb_print_file man pages
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug#18487960: SIG 11 on delete with index merge
      Follow up patch for WL#7953 Transporter handshake retry
      Follow up patch for WL#7953 Transporter handshake retry
      Patch 2 for WL#7953 Transporter handshake retry
      Patch 1 for WL#7953 Transporter handshake retry
      Patch 3 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 2 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 1 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      adding checksum to the cnf file
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19600834  late code review comment
      Bug #19600834 DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH)
      Bug #19600834         DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH) ...
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3
      Bug #19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3  - revert the reverted
      Bug#19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Change from mysql-5.6 to build Oracle Linux 7 RPMs
      WL#7640  Ndb Active Active Delete-Delete handling
      WL7640 Add delete-delete conflict count
      Adding ndb_print_file to spec file
      Repush of WL#7544 after 7.4.1 clone tag.
      bump version to 7.4.2
      Set version 7.4.1
      Revert WL#7544, not to be included in DMR 7.4.1
      Reorder member initializer list for thr_data to follow initialization order. This removes compiler warning introduced in fix of Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      WL#7544: Optimisations of the NDB API receiver thread in various manners. 1) Optimising method to unpack field data from TRANSID_AI signal, 2) optimised handling of trp_client locking check, 3) reorganised code in NDB API receiver thread for better performance and more readability, 4) Optimisation signal receive handler
      BUG#19451060: One more step on the way to understanding commit ack markers
      Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Fix for bug#19559313, call getPerformStateString() with a nodeId arg instead of a state argument
      Fix for Bug#19552283 :
      Update documentation to remove useProjection       Update Session.js to remove useProjection
      BUG#19552349: Avoid stack overrun by removing endless recursive call
      BUG#19451060: Further refinements of bug fix, previous ndbrequire revealed a race that could cause multiple REMOVE_MARKER_ORDs to appear for the same transaction, added long comment about this specific race variant. Left a part of the ndbrequire still to ensure that this only happens when receiving REMOVE_MARKER_ORD sent by API through TC_COMMIT_ACK and not through API failure handling
      Bug #18703922  DUMP-CODE ACTIVATED DEBUGGING ON WATCHDOG OVERLOAD ISSUES
      Bug #17730825  NDB API: POSSIBLE LEAK OF CONNECTION OBJECTS
      BUG#19524096: Converted many 4009 errors to temporary error 4035, ensured APIs can use new data nodes sooner, fixed some wrong error categories, removed no longer used errors, fixed some anomaly in communication towards the API, small improvement of restart printouts, should give autotest a much better chance to get rid of redness
      Bug #17893872         ER_DUP_ENTRY WHEN INSERTING TO AUTO-INC COLUMN ON SPARC MULTI-MASTER SETUP
      BUG#19451060: Added more descriptive information at crashes related to commit ack markers, changed name of noFired to numFired for clarity, added possibility to put last in free list to aid crash printouts
      Fix for spelling error in Win32 code
      WL#7509: Introduced more configurability of disk write speeds and added a number of new ndbinfo tables to track this new more adaptive behaviour
      WL7845: More and safer ways to print records in DBTC
      BUG#19451049: Missing call to prepareTUPKEYREQ from handle_lcp_keep, added comment about handle_lcp_keep
      bug#19124970 - PB WITH POLLEVENTS , NDBEVENTS
      Backport from 7.2
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      The Bug was due to m_out object used in NdbOut operator was not initialized/set to the output stream. Added an ndb_init() call to initialize it to output stream. Added an environmental variable $NDB_PRINT_FILE to give path to its binary in  mysql-test/mysql-test-run.pl file. Added a unit test and its result file.
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      bug#19031389 bugfix.diff bug fix
      bug#19031389 bugtest.diff bug test
      BUG#19513967: Fixed missing init of longer bitmask
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      BUG#17703874
      Bug#19202654: NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      Bug #18354165         16723708 CHANGED EVENT CATEGORY VALUES
      Clusterj windows CMakeList error
      Clusterj support for autoincrement columns http://wl.no.oracle.com/worklog/NDB-RawIdeaBin/index.pl?tid=8027
      Added missing logging.properties
      Clusterj improve maven handling for out-of-source builds
      Bug#18875137: NDB_RESTORE STILL MISSING SOME TYPE CONVERSIONS
      Fix for Bug#19414511:
      Bug #19236785  ADDRESSSANITIZER BUG IN ~NDB_MOVE_DATA Bug #73311      AddressSanitizer bug in ~Ndb_move_data
      Bug #19235428  ADDRESSSANITIZER BUG IN DATABUFFER2<SZ,POOL>::IMPORT (DBDICT::ALTERTABLE_PARSE) Bug #73310     AddressSanitizer bug in DataBuffer2<sz,Pool>::import (Dbdict::alterTable_parse)
      Bug #19235170  ADDRESSSANITIZER BUG IN DBUTIL::GET_SYSTAB_TABLEID Bug #73308  AddressSanitizer bug in DbUtil::get_systab_tableid
      Bug#11764704 : Exclude missing tables when restoring a backup  - added an option "--exclude-missing-tables" to ndb_restore tool  - when enabled, the missing tables will be added to the    exclude tables list before starting to restore.  - updated test cases accordingly.
      Revert fix merged in from 5.5.39 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert fix merged in from 5.6.20 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert quick fix for dtrace problems in release tree. New fix in CMake files will be merged in from 5.6.20.
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      This commit is a followup to the one below. It changes the fragment_num colum (in memory_per_fragment), such that it gives the global frgament id rather than a node-local sequence number. That way, it is possible to see where each fragment (or some replica of it) is located. This is consistent with the output from 'ndb_desc -pn -d <database> <table>.
      Bug 19028487 NPE when scanning rows with blob or text columns
      More fixes for bug#19053226
      Fixes for bug#19053226
      More fixes for bug#19053226
      bug#18410939 - MEMORY LEAK AT EVENT BUFFER ALLOCATING A DUMMY EVENT LIST WHEN INCONSISTENCY
      Bug #17184024         ERROR 4 IN LIBNDBCLIENT.SO.6.0.0 (3-7474573041)
      bug#19122346 fix3.diff FK use full name PP/CC/name + debug
      bug#19122346 fix2.diff fix test error from 7.3 r4203 FK_Bug18069680
      bug#19122346 fix1.diff FK use full name PP/CC/name
      ndb - RSS-DynArr256
      A new ndbapi test case: testNodeRestart -n DeleteRestart.
      Bug #18731008    NDB : AVOID MAPPING EMPTY PAGES DUE TO DELETES DURING NR Bug #18683398    MEMORY LEAK DURING ROLLING RESTART
      Bug #19193927         TC TAKEOVER TAKES TOO LONG CAUSING MANY PROBLEMS
      ndb
      Bug#19193756 MTR GENERATES TOO LONG SOCKET PATHS
      Merge from mysql-cluster-7.2.17-release
      ndb
      use primitive types
      Include stdlib.h for malloc() and free()
      Compiler issues on some Windows platforms
      Add debug to trace bug#18411034 - CRASH IN NDB-SHARE
      Updated the list of tables to be deleted after running ndb clusterj tests Added new test and the model to build specification
      Merge latest nodejs-adapter from 7.3 to 7.4
      Unconditionally disable dtrace for rpm, barfs on Oracle dtrace
      Remove superfluous -master.opt file for the removed test case ndb_mt_recv.
      Unconditionally disable dtrace for rpm-oel, barfs on Oracle dtrace
      correcting copyright headers
      Fix issues with Read/Modify/Update of NDB VO objects containing blobs.
      All NDB read results (including those containing BLOB and TEXT columns) are now ValueObjects.
      Fix bug of using Persistent<T>(x) rather than Persistent<T>::New(x)
      work on support for NdbRecord-backed ValueObjects which contain TEXT or BLOB columns.
      More TEXT tests for NDB
      less debugging output at end of test run
      Fix composition value checking
      Implement bufferForText and textFromBuffer in C++.
      rawNdbDefaultvalue does not require a full-fledged Node Buffer
      let compiler supply default destructors
      Another attempt to fix crashing bug in BlobHandler
      Expose the string encoder statistics in NdbTypeEncoder.cpp to JavaScript.
      Move v8 calls from worker thread to main JS thread
      Support TEXT columns with character set UTF-8 or ASCII. Other charsets (which require recoding) are not yet supported.
      A test file that does not export a test case now causes a warning rather than an error.  This should make it a little easier to develop new tests.
      Column Metadata API provides charsetName rather than charsetNumber
      Fix apparent bug in calculating size requirement of UTF-8 buffer
      Restore compatibility with node-mysql 2.0.0
      Fix crash on stub commit / stub rollback
      update cmake & gyp build lists
      Finish read & write BLOB implementation for NDB adapter
      Implement connection pooling for mysql adapter
      Fix tests that do not close session after running test
      Improve error reporting for connecting to database
      Add suggestion to user to maximize performance of updates
      Improve spi test error reporting
      Succesful insert into BLOB column
      Add BLOB column to stringtypes test suite & confirm that existing tests pass with a mapped (but unused) BLOB field.
      Test that storing a non-BLOB in a BINARY column gives error SQLState 22000
      Use Error SQLState 0F001 "Bad BLOB" (actually a "Locator Exception") if value intended for a BLOB column is not a Buffer.
      Initial implementation work on BLOB support for NDB adapter.
      Refactor connection handling to prepare for connection pooling
      WL#7626 Implement many-to-many relationships for Document Composition
      Don't try immediate startTransaction() unless using async api.
      Keep a single usedOperationSets array rather than one per DBSession. The array is at file scope in NdbTransactionHandler. It does not grow past 4000 elements (a literal constant). Underlying DBOperationSet native objects are freed when the wrapper is placed in the recycler array.
      Disable mysql tests for now
      Attempt to recycle DBOperationSet wrappers
      wrapPointerInObject and unwrapPointer take a v8::Handle<T> rather than a v8::Local<T>
      Improve error reporting for relationships that are null or undefined
      Test a slightly different approach to V8 wrapping
      Minor refactoring in NdbOperation
      Remove the use of "proto" in DBTableHandler
      Refactor DBTableHandler.getFields() into a simple case getFields() and a separate more complex getFieldsWithListener(). Removed the resolveDefaults option which was always set to false.
      Improve error reporting for ProjectionTest
      Improve error reporting for ProjectionTest
      Improve error reporting for test failures
      Compiler error
      Stub out NdbSession.buildReadProjectionOperation in hopes that test suite will run.
      WL#7626 Composition Implement support for one-one, one-many, and many-many relationships. Replace useProjection with implementation for find (projection, key).
      Rather than having a JavaScript wrapper for Record::setNotNull(), implicitly call setNotNull() when writing a data value in encoderWrite().
      Don't use a startTransaction() hint for unique key operations.
      In JsValueConverter for pointer types, if the JavaScript value is Null, represent it as a null pointer.
      Remove what little was left of NdbTransaction_wrapper.cpp
      move ENABLE_WRAPPER_TYPE_CHECKS define into adapter_global.h
      portability fix
      Update source file lists for gyp & CMake
      Add option free-percent
      New design for scans. This removes the previous wrapper for NdbScanOperation and ScanImpl.cpp file and consolidates all scan functions into ScanOperation. Expected: start 416 tests, pass 413, fail 2, skip 1.
      fix wrappers for boolean types
      In test driver allow --stats=query, e.g. --stats=spi/ndb/DBSession
      Add HandleScope to all toJS() template functions just to be safer from enigmatic V8 memory leaks. Provide toJS() and isWrappedPointer() specializations for type bool.
      Refactor NDB execute. This patch renames PendingOperationSet to DBOperationSet, and makes DBOperationSet the "point of contact" for JavaScript calls to begin and execute transactions. All t_basic tests now pass.
      New SPI test   begin transaction; delete (execute NoCommit) ; read deleted row ; commit.
      Minor bug fixes for passing SPI tests
      Major JavaScript logic changes in NDB adapter. NdbTransactionContext, NdbSession, NdbOperation, and NdbConnectionPool are adapted to use the call flow of DBSessionImpl and DBTransactionContext rather than the native call flow of the NDB API.
      This commit includes various small C++ fixes. The next commit includes major JavaScript logic changes. With these together, spi tests pass.
      Add new connection property ndb_sesion_concurrency Refactor initialization of NdbSession and connecting of the new NdbSession to its impl.
      Adapt DBDictionaryImpl to use DBSessionImpl rather than Ndb.
      Revise protocol for registering a transaction open / closed. Use only two calls, registerIntentToOpen() and registerTxClosed(). Always make these calls from JavaScript main thread.
      NdbTransaction is no longer wrapped for JavaScript
      Template class NativeCFunctionCall_4_
      DBSessionImpl
      Adapt AsyncNdbContext to be aware of DBTransactionContext
      executeAsync() on AsyncNdbContext is no longer wrapped for JavaScript; use executeAsync() on DBTransactionContext instead.
      Refactor DBOperationHelper:  it now takes a DBTransactionContext rather than an NdbTransaction.  it now defines operations, but does not prepare them.
      Rename addOperation() to getNextOperation()
      Add two new classes, DBTransactionContext and DBSessionImpl. These will free the JavaScript code from the start/prepare/execute cycle of Ndb and NdbTransaction, eventually allowing operations to be performed with fewer scheduled async calls and therefore less overhead.
      Adapt DBOperationHelper to the KeyOperation / ScanOperation change.
      Bug fix where the do_close flag must be associated with the transaction rather than its parent Ndb object.
      Refactor Operation and DBScanHelper into two classes called KeyOperation and ScanOperation.
      This change alllows Ndb::startTransaction() to run as a sync call in the main JS thread if we suspect that it will not block.  As a proof of concept, this allows you to measure the performance with this change; but it should not be used as-is, because the guess could be wrong, which would cause the main thread to block waiting for network I/O.
      In the common case where an async method call returns int zero, try to optimize away creating a new JavaScript value.
      Slight change to the compatibility strategy for some libuv changes.
      Combine NdbTransaction execute() and close() into a single scheduled call whenever execType is Commit or Rollback.  This saves the scheduling cost of running the close() call by itself.
      Various fixes for lint.
      Remove old stats API.
      Use new stats API in MySQL code.
      Use new stats API in NDB code.
      Revised statistics API. Now each module owns, at file scope, its own stats object. The module registers the stats object with the global statistics, which keeps a reference to it in the stats tree. This should reduce the cost of keeping statistics to practically zero.
      Delay after (rather than before) the first test iteration. This allows V8 to compile all the JavaScript code before dtrace starts running. High dtrace profiling rates caused the first iteration to run very slowly and skewed the profile towards compile times rather than run times.
      Optional delays both before & after jscrund run
      jscrund: add option to delay start of test run
      Add useProjection to Session   this function specifies a projection to be used for find and query operations
      Minor work on DBDictionaryImpl Contain the code for handling NdbDictionary 3-part/slashed/names in DictionaryNameSplitter class. Reformat patch indent width from 4 spaces to 2 spaces. buildDBForeignKey() takes only the fk* and must use its own private name splitter.
      Error 23000 when attempting to set a non-nullable column to null.
      Restore table which should not have been removed from test suite
      Add support for foreign key metadata
      update literal mapping test for schema
      Fix errors in test case & misc. lint errors.
      Check in test case where one operation in a batch has a data type error. This test fails for both NDB and MySQL.
      Expose NdbRecordObject::prepare() to JavaScript. This is a step towards fixing handling of encoder errors for value objects.
      Write a negative value to an unsigned int field of an NDB Value Object. This test causes the test suite to hang forever.
      Run executeAsynch() in JS main thread rather than a UV worker thread. We had seen higher latency using async ndbapi vs. sync ndbapi, but this change eliminates most of that difference.
      unused table in test suite
      Fix for compiler warning in TimestampWriter validity check
      NDB encoding-related changes.  (1) distinguish between 22003 numeric value out of range and HY000 for "value is not numeric"  (2) provide a (hopefully) [1;31mfast[mer path to encoderWrite and encoderRead by wrapping them as methods of Record
      Refactor error handling
      Attempt to optimize encodeKeyBuffer() for single-column indexes
      Fix reporting of session factory if no mappings
      Remove JsValueAdapter in loader; it is no longer needed.
      This fixes the failing "timestamp 1969" test case for NDB. Test still fails with MySQL.
      Fixes for lint test failures
      Test & fix NDB handling of encoder errors for numeric types
      Tests for numeric types
      This renames the integraltypes suite to numerictypes and adds stub tests for float, double, and decimal columns
      Test for particular expected errors rather than simply for operation failure
      Add decimal support in NdbTypeEncoders Remove JS wrapper for decimal utilities from ndb_util
      Encoders for NDB integer values: if the [1;31mfast[m integer conversion fails, try a slow one, then test whether the result is legal.  This should allow writing valid JS string and float values to int columns.
      Improve handling of errors from NDB data type encoders
      Improve handling of data encoder errors in the ndb adapter
      fix sql_mode for mysql adapter
      Implemented test cases
      Stub out new test cases for data type casting
      If MySQLTime.valid is set to false, NdbTypeEncoder will reject the value.
      Allow user to set sql_mode in mysql adapter with a default of STRICT_ALL_TABLES
      Change console.log to udebug.log in issues/2014-03-18Test
      Add shell script to manage regular runs of jscrund
      Adapt loader to use new Batch.getOperationCount() api
      Batch: use getOperationCount()  rather than getSize()
      Add Batch.getSize() method
      Add test case for issue of bad data type for column
      Fix typo
      Add test case for issue where a TableMapping created from a literal mapping could not be used to perform operations (fixed in bzr 686).
      Changes to sample data loader after code review with Craig. This version still has lots of untested features (and combinations of features) but it can load CSV data and random data.
      Bug fix creating TableMapping from object literal
      WL#7578 Replace usage of ndb_schema_share->key with hardcoded text
      WL#7578 Move subscriber bitmaps to NDB binlog component
      WL#7578 Move the g_nodeid_map to Ndb binlog thread
      WL#7578 move clearing of subscribed to binlog thread
      WL#7578 Always expect everyone to ack the schema op
      WL#7578 Refactor schema distribution code
      WL#7578 Refactor schema distribution code
      ndb
      WL#7578 note about nodeid from global cluster connection
      WL#7578 Don't use ndb_schema_share from ack_schema_op
      Initial checkin of JavaScript data loader tool
      Remove windows line endings from ndb_schema_object.cc
      Try to reduce overhead of stats.incr() calls
      Remove the error handling in jscrund_mysqljs backend which duplicates work performed in the jscrund frontend.
      Add conditional guards around udebug log messages.
      Add conditional guards around udebug log statements.
      Improve error reporting while loading mysql node_module
      The node-mysql driver by default constructs an Error object in order to get a stack that includes the user's call to Query. This can be a performance bottleneck.

[33mcommit 3cb16e9c3879d1790159d2856cb7aa0bd3d201fd[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Fri Mar 20 09:24:45 2015 +0100

    Bug#20742269: DO NORMAL FSYNC ON OS X
    
    Stop using fcntl() with the OS X specific F_FULLFSYNC flag and
    instead do normal fsync(). Since InnoDB always uses fsync() and
    more and more system tables are being moved to InnoDB, the possible
    durability gain is slim to none. This also makes OS X behave similar
    to other platforms.
    
    The gain: Doing normal fsync() is significantly [1;31mfast[mer than using
    F_FULLFSYNC. E.g the main.m_i_db test shows 2X-8X improvement with
    this patch (depending on SSD or normal disk).
For keyword time:
[33mcommit e93a30a8a9d87a84112c57dd1bed57a307518bfa[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Fri May 25 09:41:29 2018 +0800

    Bug#28065244 - MYSQL UPGRADE FROM 8.0.11 TO 8.0.12 MISSING COLS FROM INNODB_TABLES/COLUMNS
    
    The problem is that newly added columns in I_S.innodb_tables and
    I_S.innodb_columns can be shown in these two tables themselves.
    However, they should also be shown in I_S.COLUMNS, but currently no.
    
    The cause is that server depends on the plugin version change to
    decide if the metadata of I_S.COLUMNS should be recreated or not.
    Currently, InnoDB maps the server version to this plugin version.
    But since the plugin version only accepts the format of X.Y, so the
    MYSQL_VERSION_PATCH was always not included into this version.
    So an upgrade from 8.0.11 to 8.0.12(or any minor upgrade) would not
    recreate the metadata properly, because both 8.0.11 and 8.0.12 would
    be remembered as 8.0, then there is no change on the version.
    
    To fix it properly, InnoDB should not use map the server version to
    the plugin version by discarding the MYSQL_VERSION_PATCH. For the plugin
    version used for InnoDB I_S views, the new format MYSQL_VERSION_MAJOR.X
    is used. Here MYSQL_VERSION_MAJOR is always the major version, currently
    it's 8. And about the 'X', it doesn't mean the MYSQL_VERSION_MINOR any
    more. Instead, it now only means the I_S views structure version,
    starting from 1 for now, to distinguish from current 8.0. Every [1;31mtime[m a
    column of InnoDB I_S views gets changed, this X should be increased
    by 1, etc.
    
    Please note that the plugin version for 'InnoDB' is not changed in
    this patch, it's still the MYSQL_VERSION_MAJOR.MYSQL_VERSION_MINOR.
    
    RB: 19729
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 16ce5272fce833c8ee6b53ac04b70a3be5da92e8[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Wed May 23 09:16:26 2018 +0200

    Bug#27960500: UPGRADE 5.7 -> 8.0.11 -> 8.0.{12,13} FAILS DUE TO FTS TABLES WITH 0 TIMESTAMPS
    
    The hidden FTS "tables" were created by InnoDB with 0 [1;31mtime[mstamps
    for 'created' and 'last_altered' on upgrade from 5.7, and for new
    tables created in 8.0.11.
    
    Upon a DD upgrade from 8.0.11 to 8.0.12, new DD tables are created,
    and meta data is migrated to the new tables by INSERT statements.
    This failed because 0 [1;31mtime[mstamps are not accepted with the server
    default SQL mode.
    
    This patch does the following:
    
    1. Make sure FTS tables are created with correct [1;31mtime[mstamps.
    2. Add an upgrade step when upgrading from before 8.0.12 to
       correct the 0 [1;31mtime[mstamps to CURRENT_TIMESTAMP before the
       meta data is migrated.
    
    Additionally, error reporting from server side SQL statement
    execution is improved.
    
    Change-Id: Ic373931c3dd2ba46314c0d0c689ff0e8db61fa8e

[33mcommit 53e0776dc4bb031b46569573069db68ddcc4300e[m
Author: Ivo Roylev <ivo.roylev@oracle.com>
Date:   Mon May 21 23:24:02 2018 +0300

    Bug#27980823: HEAP OVERFLOW VULNERABILITIES IN MYSQL CLIENT LIBRARY
    
    There is an ASSERT on a run[1;31mtime[m condition that should be a dynamic check.
    There is also reported a weakness with buffer length. Currently cannot simulate an attack service there, but beafing up the code anyway.

[33mcommit 526d2734a783831a66063af016cc3c38b22f3bbe[m
Author: Ivo Roylev <ivo.roylev@oracle.com>
Date:   Mon May 21 22:08:45 2018 +0300

    Bug#27980823: HEAP OVERFLOW VULNERABILITIES IN MYSQL CLIENT LIBRARY
    
    There is an ASSERT on a run[1;31mtime[m condition that should be a dynamic check.
    There is also reported a weakness with buffer length. Currently cannot simulate an attack service there, but beafing up the code anyway.

[33mcommit a4fa326ddb1884323fe1a9c83f42489f2049675b[m
Author: Ivo Roylev <ivo.roylev@oracle.com>
Date:   Mon May 21 18:35:15 2018 +0300

    Bug#27980823: HEAP OVERFLOW VULNERABILITIES IN MYSQL CLIENT LIBRARY
    
    There is an ASSERT on a run[1;31mtime[m condition that should be a dynamic check.
    There is also reported a weakness with buffer length. Currently cannot simulate an attack service there, but beafing up the code anyway.

[33mcommit 053e13ddff16284df27653b0e6e74ef7a2ababa8[m
Author: Nuno Carvalho <nuno.carvalho@oracle.com>
Date:   Tue May 15 16:15:50 2018 +0200

    BUG#28025905: PB2 GROUP_REPLICATION.GR_EXIT_STATE_ACTION_ON_RECOVERY_STAGE0 FAILS SPORADICALLY
    
    The test gr_exit_state_action_on_recovery_stage0 simulates a error
    during stage 0 of distributed recovery, which will cause the applier
    to stop. Also this test is storing the relay log positions in a
    crash-safe fashion, that is, the positions are stored together with
    the applied transaction.
    If the test does run with parallel applier configured, depending on
    how much [1;31mtime[m the applier worker take to stop, the worker may not be
    able to store its positions, though on this test it does not matter,
    the transaction will error out and the positions will not move
    forward.
    
    This test was detecting the error message "Error writing relay log
    configuration", but like explained above that is a possible
    consequence of the simulated error, so we are suppressing it.

[33mcommit 191cb951b5b9153d5976cea4bcf91062830cefb9[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Thu May 3 13:19:27 2018 +0200

    Bug#27945658: OVERLAPPING SOURCE AND DESTINATION FOR MEMCPY DURING 5.7 UPGRADE
    
    This patch does the following:
    
    1. Make various upgrade related DD tests executable only as big-tests
       when running with valgrind (since they take very long [1;31mtime[m to complete).
    
    2. Make the call to 'restore_record()' in 'prepare_fields_and_keys()'
       conditional (do it only if TABLE::record[0] != TABLE::s::default_value)
       to avoid the valgrind error. This is necessary since the upgrade from
       5.7 assigns TABLE::record[0] = TABLE::s::default_value).
    
    Change-Id: Ib702439ae8571370fbed6be034b5d0f67b6dd2c5

[33mcommit b94d7c40f06e502b2a7da757fdf46cbde9120543[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Mon Apr 30 11:40:53 2018 +0200

    Tweak some tests for the weekly run
    
    innodb.innodb_pagesize_max_recordsize:
    
    - add more [1;31mtime[m for server restart
    
    main.sum_distinct-big:
    
    - stop it from running in Valgrind as it [1;31mtime[ms out

[33mcommit 32d423289c8c52a959913a615b2110ffb46df815[m
Author: Thayumanavar S <thayumanavar.x.sachithanantha@oracle.com>
Date:   Fri May 4 05:40:19 2018 +0200

    BUG#27699248 - PRPEPARED_STATEMENT::INSERT_PARAMS_FROM_VARS
                   IS INSANELY SLOW.
    
    Executing a prepared statement to insert rows with large number of parameters                                                                                                         takes a long [1;31mtime[m. To write statement to binlog, the query string is prepared                                                                                                         during the execution. The query string preparation in this scenario involves                                                                                                          many string append calls to expand heap allocated memory and memcpy. Hence the                                                                                                        delay in statement execution is observed.
    
    The fix involves the following changes:
    1. A reasonable size of memory is reserved for the query string. Memory of size
       "original statement string size + 32 [1;31mtime[ms the number of parameters" is
       reserved to avoid reallocations during string appends in common use cases.
    
    2. The String class does not support strings of 4GBytes length. It results in
       an overflow on 64-bit word size platforms. A debug assert is added for 64-bit
       platforms to check overflow condition. It is responsibility of caller to
       ensure the memory buffer to hold string doesn't exceed 4G bytes in length.
       An error is reported if the query string size exceeds the string supported
       size during execution of the prepared statements.
    
    3. Unneeded local variable to hold the query string is removed.

[33mcommit c58c6f8f66ddd0357ecd0c99646aa6bf1dae49c8[m
Author: Aakanksha Verma <aakanksha.verma@oracle.com>
Date:   Fri May 4 15:53:13 2018 +0530

    Bug #27155294   MAX_EXECUTION_TIME NOT INTERUPTED WITH FULLTEXT SEARCH
    USING MECAB
    
    PROBLEM
    
    While running select with optimizer hint -> max_execution_[1;31mtime[m to return
    the count of rows using the column that is primary key,the query doesn't
    get interrupted after the max_execution_[1;31mtime[m is reached.
    Optimizer does some optimization to fetch count of rows without actually
    searchin of rows if the column in count expression can never be NULL .
    Since there is no trx interruption check inside fts optimize query the
    query isn't interrupted.
    
    FIX
    
    Add an interruption check in the long running fts_ast_visit function so
    that query gets interrupted as expected.
    
    Reviewed by: Jimmy Yang<Jimmy.Yang@oracle.com>
    RB: 19490

[33mcommit f5f92f42a70ae5e102262bc75f4615ba7b98d92e[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Mon Apr 23 12:01:07 2018 +0200

    Tweak some tests to make them run properly on weekly
    
    innodb.ddl_crash_alter_table_partition
    innodb.ddl_crash_basic
    - Suppress a warning in InnoDB
    
    innodb.atomic_truncate_crash
    innodb.blob_redo
    - Add extra [1;31mtime[m for server restart
    
    main.ssl-big
    - Stop it from running in ASAN as it terminates with 'too many connections'

[33mcommit b8635a6b546ff3fae9c324ac32cac017cb943b00[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Apr 17 14:18:38 2018 +0200

    Bug#27849973 ABORT THE DEBUG SERVER IN CASE OF ASSERTIONS IN THE STD LIBRARY ON WINDOWS
    
    Change implementation of my_parameter_handler, which is used as an
    argument to _set_invalid_parameter_handler on Windows. This will abort the
    server if the C/C++ run[1;31mtime[m reports "out of range" or similar errors.
    
    Fix failing mtr test 'main.import' on windows, reading an empty file
    is a no-op.
    
    Make the error-handling of a failing create_pid_file() deterministic on windows.
    
    Change-Id: Ib81c614636d6791ba2f7afd191bbdac0ae8a0d57

[33mcommit c5f7404a56dea30d6e52ba70f0ffd677836a6921[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Fri Apr 20 11:39:59 2018 +0200

    BUG#90526 [MySQL 8.0 GA Release Build] Assertion failure: write_max_size > 0
    BUG#90523 [MySQL 8.0 GA Release Build] InnoDB Assertion: (capacity & (capacity - 1)) == 0
    BUG#90522 [MySQL 8.0 GA Release Build] InnoDB: Assertion failure: (n & (n - 1)) == 0
    
    We misinterpreted what PLUGIN_VAR_NOSYSVAR was supposed to provide.
    It was documented as "Not a server variable" which seemed to suggest
    that the variable is hidden (especially as it was then being skipped
    when setting values to sysvars).
    
    We tested and observed that sysvars could neither set via option file
    nor during run[1;31mtime[m. But we missed that the variable still could be set
    via command line option.
    
    In result the new EXPERIMENTAL sysvars were configurable via cmd line,
    even when ENABLE_EXPERIMENT_SYSVARS was not configured for cmake.
    
    Restored the previous name - NOSYSVAR and implemented EXPERIMENTAL
    sysvars in different way - wrapped their definition by a simple ifdef.
    
    This is the most safe way to do it. In future we could try to think
    about introducing PLUGIN_VAR_EXPERIMENTAL to make life easier - as
    we had to set default values for all underlying global variables,
    because we can no longer rely on sysvars initialization to default.

[33mcommit 61c1a2df14c7e8d78263374cafea103e6b145738[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Thu Apr 19 20:34:14 2018 +0200

    BUG#27664539 INNODB: ASSERTION FAILURE: BUF0FLU.CC:457:
                 (BUF_POOL->FLUSH_LIST).START == __NULL
    
    If no-redo mini transaction modifies a given page first [1;31mtime[m, but the
    page was stored on disk before, it must ensure that the lsn set to the
    newest_modification of the page is not smaller than the page_lsn stored
    on disk (available at frame + FIL_PAGE_LSN).
    
    Added assertion that ensures that the new page_lsn is never smaller than
    the previous one. It is checked whenever page is flushed to disk, when
    the newest_modification is being copied to field at frame + FIL_PAGE_LSN.

[33mcommit 8b5f81ed8fd9fc83c308d66522cfc320f9a227fb[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Thu Apr 19 16:16:09 2018 +0200

    Fixed issues discovered by PB2 after fix for BUG#27664539 was pushed.
    Addressed new comments in RB.
    
    We introduced new system variable - innodb_log_checkpoint_fuzzy_now.
    
    1. Therefore we had to create new mtr test for that variable.
    
    2. Improved doxygen comment for innodb_log_checkpoint_fuzzy_now_set.
    
    3. The test innodb.log_flush_order was unstable because from [1;31mtime[m to [1;31mtime[m,
       max_trx_id needs to be stored to disk, which is solved via mini transaction.
       In such case the prepared trap on DEBUG_SYNC_C point fired in wrong place,
       when trx_sys mutex was held, leading to deadlock and [1;31mtime[mouted test.
    
    4. The buf_flush_wait_flushed() was unused after we removed the only usage
       in the bug fix. Removed the function.
    
    5. Removed the unused include file - log_flush_order_test_redo_noredo.inc.
    
    6. The forced fuzzy checkpoint should not update the main flushed_lsn.

[33mcommit f163f536e11e0800a2c70063b5865415fd48d84a[m
Author: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
Date:   Fri Apr 13 13:42:47 2018 +0200

    Bug #27838272: REMOVING THE HENRY SPENCER LIBRARY
    
    Description:
    We introduced the ICU library for regular expressions a few months ago.
    The X plugin is still using it. The [1;31mtime[m has now come to remove the old
    "regex" library.
    
    Reviewed-by: Lukasz Kotula <lukasz.kotula@oracle.com>
    Reviewed-by: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>
    RB:19480

[33mcommit 8410d68cf97e0df033d6427c8381862920ebb1d9[m
Author: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>
Date:   Fri Apr 13 10:59:03 2018 +0200

    Bug#27257774 CONFUSING ERROR MESSAGE WHEN AUTHENTICATING WITHOUT SSL
    
    Improved error handling on a mysqlx client side:
    - in authentication sequence report last significant error, not just the
      last one
    - in case of any fatal error break the authentication sequence
    - in case of peer disconnected, broken pipe or read/write [1;31mtime[mout errors
      break the authentication sequence
    
    RB: 19362
    Reviewed by: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
    Reviewed by: Lukasz Kotula <lukasz.kotula@oracle.com>

[33mcommit a082df5ae8a5e6a04f2cd40b75bcda6ec33f6e9c[m
Author: Venkatesh Duggirala <venkatesh.duggirala@oracle.com>
Date:   Fri Apr 13 10:59:59 2018 +0530

    Bug#27373559 COMMIT ORDER DEADLOCK + RETRY LOGIC IS NOT CONSIDERING TRX
    ERROR CASES
    
    Problem:
    ========
    When two workers threads are involved in "Commit order deadlock",
    slave worker thread is retrying a transaction even when the
    transaction error is a 'non temporary' error.
    
    Analysis:
    =========
       As part of BUG#20136704 fix,  commit order deadlock checking mechanism
       is  introduced. Every [1;31mtime[m when a transaction needs to wait for
       another transaction  to release a row lock, innodb will
       call a slave function to check if there is an order commit deadlock.
       If it found an order commit deadlock, It will set a deadlock flag to
       the slave worker which is holding the row lock. Thereafter,
       the worker will roll its transaction back and retry it again.
    
       At this point, this retrying transaction *should* have no
       non-temporary errors.
    
       Having a non-temporary error may be a sign of:
    
            a) Slave has diverged from the master;
            b) There is an issue in the logical clock allowing a transaction to be
               applied in parallel with its dependencies (the two transactions are
               trying to change the same record in parallel).
    
       For (a), a retry of this transaction will produce the same error. For
           (b), this transaction might succeed upon retry, allowing the slave to
            progress without manual intervention, but it is a sign of problems in LC
            generation at the master.
    
    Fix:
    ====
       Slave server will make the worker to retry a transaction (which is involved in
       commit order deadlock) only if there are no fatal errors.

[33mcommit f5e58d179119d0982d4938ebadcf6354aa9bad89[m
Author: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
Date:   Mon Apr 9 14:06:13 2018 +0200

    Bug #27259783 CRASH IN HOSTNAME_CACHE_SEARCH WHEN RESTART COMMAND STRESSED WITH MULTIPLE CLIEN
    
    Description:
    There is patch provided for Bug#27245319 to allow restart command from
    xplugin connection. While testing for restart command using 2 terminals
    for quite some [1;31mtime[m, observed that server crashes with sig11 in crash
    in hostname_cache_search
    
    Reviewed-by: Lukasz Kotula <lukasz.kotula@oracle.com>
    Reviewed-by: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>
    RB:19383

[33mcommit c3778161bddb807869faa906604dcc32d05beeff[m
Author: Nisha Gopalakrishnan <nisha.gopalakrishnan@oracle.com>
Date:   Wed Apr 4 20:36:14 2018 +0530

    Bug#27073100: PARTITION UPDATE_TIME NOT CORRECT AFTER
                  RESTART/REBUILD
    
    Analysis
    ========
    
    When restarting MySQL or rebuilding the table, all partitions will
    initially have 'update_[1;31mtime[m' set to NULL. When a partition is updated,
    'update_[1;31mtime[m' for all partitions with a higher ordinal position will
    also be updated. Function store_schema_partitions_record() doesn't mark
    the 'update_[1;31mtime[m' field as NULL, when 'update_[1;31mtime[m' for the partition is
    ZERO. This causes get_schema_partitions_record() to use previous partition
    'update_[1;31mtime[m'.
    
    Fix
    ===
    
    The function 'store_schema_partitions_record()' now sets the 'update_[1;31mtime[m'
    to NULL, if it is set to zero in InnoDB.
    
    Change-Id: I25cb844e258342f4d73e264c6767c1319e915326

[33mcommit 83212377c084314d73e183c2a8ed08b037baef51[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Wed Apr 11 10:23:26 2018 +0800

    Bug#26523254 - MODE == 16 || !FIX_BLOCK->PAGE.FILE_PAGE_WAS_FREED FOR DROP TABLE
    
    This is due to some complex scenario:
    1. Some ALTER TABLE ... ADD INDEX tries to create a new index I on table T1
    2. However, it fails afterwards, so I is marked as aborted. Note that the
    related dict_index_t is not removed from memory, because some other thread
    is accessing this table. So dict_index_t of I is only marked as
    ONLINE_INDEX_ABORTED_DROPPED.
    3. In this post_ddl, the physical index was freed, and the
    file_page_was_freed for the root page is now set to false
    4. Since the root page has been freed, another CREATE INDEX on T2 may take
    over this page, but this [1;31mtime[m it's not a root page.
    5. Then this new CREATE INDEX may free this page, because this is the last
    page of one level. This happens in BtrBulk::finish(). At this stage,
    the page is set to free explicitly, with file_page_was_freed set to true.
    6. Now a command to drop T1 is issued. Since this is a table residing in
    a general tablespace, it has to drop each index one by one. So DDL logs
    to free index are written, including freeing index I.
    7. In the post_ddl of this DROP TABLE, it will check the status of I,
    and find that the root page of I is now marked as file_page_was_freed=true,
    which is not expected, thus the assertion.
    
    This basically would not make any further bug, just checking the flag fails. However, it indeed makes no sense to free a already freed index in step 7, so in step 6, it's not necessary to write DDL log for this index I, if the status of this index is not ONLINE_INDEX_COMPLETE, supposing any failed index should be dropped previously.
    
    RB: 19377
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 099f4f307802fd1dadc87224b013a9cc53bc44e2[m
Author: Sergey Glukhov <sergey.glukhov@oracle.com>
Date:   Tue Apr 10 14:32:36 2018 +0300

    Bug#27665997 Incorrect behavior while using Item_field to populate in get_[1;31mtime[m_value().
    
    Compilation error fix.

[33mcommit 9512479c80a502cbf6c332a7167a04ff039384bc[m
Author: Sergey Glukhov <sergey.glukhov@oracle.com>
Date:   Tue Apr 10 10:33:30 2018 +0300

    Bug#27665997 Incorrect behavior while using Item_field to populate in get_[1;31mtime[m_value().
    
    The type of the Item passed to get_[1;31mtime[m_value() can be different from
    MYSQL_TYPE_TIME or MYSQL_TYPE_NULL. Added the code which handles this
    situation.

[33mcommit f5017c9a6fd197372dc5c6ffb86d422d26183121[m
Author: Sreeharsha Ramanavarapu <sreeharsha.ramanavarapu@oracle.com>
Date:   Tue Apr 10 06:03:18 2018 +0530

    Bug #27389294: INCORRECT BEHAVIOR WITH DATETIME COLUMN AND
                   QUERY REQUIRING SORTING
    
    Issue:
    ------
    This problem occurs under the following conditions:
    1) A select query is required to do an "open table"
       (i.e. it follows a FLUSH TABLE or it is the first query
        to access that table).
    2) ORDER BY ... LIMIT's presence mandates sorting.
    3) A DATETIME column is used for ref-access.
    
    Root cause:
    -----------
    1) While optimizing a subquery with ORDER BY:
       a) it is decided that every evaluation of the subquery,
          for every outer row, will use a ref access and a
          filesort.
       b) ref access is set up for WHERE (the referenced value
          is a column of the outer query).
       c) a filesort is set up; this filesort wants to
          implement the ref access too, for this it calls
          get_quick_select_for_ref(); to read the referenced
          value.
    
    2) my_date[1;31mtime[m_packed_from_binary() is reached through
       store_key_field::copy_inner() while checking the number
       of rows the ref-access might return.
    
       copy_field.from_field -> (field object of t1_a.c3)
       copy_field.to_field   -> (to object of t1_b.c3)
    
    my_date[1;31mtime[m_packed_from_binary() sees a junk value for
    t1_a.c3 is junk as no row of the outer table t1_a has been
    read yet. It is an invalid DATETIME value.
    
    Why does this problem not occur with every other statement?
    For most DML statements empty_record() / restore_record()
    is called at some point and a valid DATETIME value is
    placed in the record buffer.
    
    What about SELECT statements?
    SELECT queries call empty_record() / restore_record() only
    in the execution phase, after the plan is created.
    
    Solution:
    ---------
    Calling cp_buffer_from_ref() during the optimization phase
    is unsafe because it might access an uninitialized column.
    So remove the call to this function from
    get_quick_select_for_ref(). The actual ref value isn't
    required to create a QUICK_RANGE object anyway.

[33mcommit 80327897edf0614b9f07d840606345604025cdeb[m
Author: Annamalai Gurusami <annamalai.gurusami@oracle.com>
Date:   Mon Apr 9 06:17:50 2018 +0200

    WL#11328 - InnoDB: Optimizing Small Changes to BLOBs
    
    Post-push fix. Resolving a object life[1;31mtime[m issue. Making use of
    mem heap allocator for standard containers.

[33mcommit e8374b7aca8ae91afe8fe23ba700e9ff5ba51be7[m
Author: Arun Kuruvila <arun.kuruvila@oracle.com>
Date:   Mon Apr 9 12:01:52 2018 +0530

    Bug#27302337: MYSQL ABORTS WITHOUT PROPER ERROR MESSAGE ON
                  STARTUP IF GRANT TABLES ARE CORRUPT
    
    Description: Mysql server aborts with improper error message
    while start up.
    
    Analysis: Incomplete error message is thrown to server error
    log if the server failed to initialize ACL/grant/[1;31mtime[m zones
    structures or failed to remove temporary table files during
    server start up.
    
    Fix: Appropriate error message is thrown to error log for
    the scenarios mentioned above. This issue is already fixed
    in 8.0+

[33mcommit 3d3e66046ad45d78e4f7fcf4d0a1c231637842e2[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Apr 6 13:20:42 2018 +0200

    Bug#27822413 RUNTIME ERROR: CALL TO FUNCTION MYSQL_SYS_VAR_LONGLONG(THD*, INT) THROUGH POINTE
    
    To repeat: build with clang UBSAN, ./mtr main.gis
    
    storage/myisam/ha_myisam.cc:1362:32: run[1;31mtime[m error:
    call to function mysql_sys_var_longlong(THD*, int) through pointer to incorrect function type 'unsigned long long *(*)(THD *, int)'
    sql/sql_plugin.cc:2745: note: mysql_sys_var_longlong(THD*, int) defined here
        #0 0xb0685b9 in ha_myisam::enable_indexes(unsigned int) storage/myisam/ha_myisam.cc:1362:32
    
    All PLUGIN_VAR_LONGLONG variables are actually ulonglong, see struct
    System_variables, so treat them as ulonglong when resolving.
    
    Change-Id: Iec88a6bebfb092d7e9621bcec7296d68cfd6f289

[33mcommit 918b509b327eb5f470babe35c90c1edd56d4a218[m
Author: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
Date:   Fri Mar 9 19:50:20 2018 +0100

    Bug #27267054: X PLUGIN IS COMPILED TWICE
    
    Description:
    X Plugin code is compiled twice with different preprocessor definitions.
    WL#11040 changes the dynamic plugin to a static library.
    Instead compiling second [1;31mtime[m in xplugin_unit_tests,
    it might link to libmysqlx.a
    
    
    Reviewed-by: Lukasz Kotula <lukasz.kotula@oracle.com>
    Reviewed-by: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>
    RB:19154

[33mcommit 009956eb73202d3fe65daf05f33b778cb1ae9092[m
Author: Ingo Struewing <Ingo.Struewing@oracle.com>
Date:   Wed Mar 21 11:13:12 2018 +0100

    Bug#27571663 - MEB FAILS WHEN INNODB_LOG_FILE_SIZE IS DIFFERENT FOR INITIALIZE AND SERVER START
    
    MEB failed do scan the redo log up to its logical end under
    circumstances. One such case was resizing of the log files.
    Resizing can happen by shutdown and start of the server with
    a new value for the log file size. The case was repeatable
    after two resizes with one megabyte of extended size each.
    
    The core of the problem lies in a new redo log format
    (version 3). In this format, the log header field
    LOG_HEADER_START_LSN does not always have the expected
    value. Instead the relation of LOG_CHECKPOINT_LSN and
    LOG_CHECKPOINT_OFFSET is significant for lsn to offset
    calculations.
    
    So far MEB relied on LOG_CHECKPOINT_LSN for lsn to offset
    calculations. Due to the unreliable values, MEB could start
    to read the log from a wrong offset. It could get a
    zero-filled block, on which it assumed end of log.
    
    This patch fixes the lsn to offset calculations. It gets rid
    of MEB's own calculation and calls an InnoDB function for
    this calculation instead. (log_files_real_offset_for_lsn()
    from log0write.cc, log0log.h, log0types.h).
    
    It does also fix the creation of the log files at restore
    [1;31mtime[m. The checkpoint offset field needs to be set
    appropriately.
    
    Unrelated changes:
    
    Fix variable types used for lsns and offsets. Lsns have
    lsn_t and offsets have utin64_t.
    
    Reorder functions around the calculation in header and
    implementation file to a consistent order.
    
    Reduce the number of functions with similar signature.
    
    Rename variables, so that the same name is used for the
    same "thing" throughout.
    
    Rename functions so, that a prefix of log_ is reserved for
    InnoDB functions, a prefix of meb_ is used for MEB
    functions, that are implemented inside InnoDB sources, a
    function name with get_ extracts information from memory
    structures, a function name with read_ invloves reading of
    information from a file.
    
    Move meb_read_checkpoint_info from log0recv.cc to
    Redo_log_adapter::get_checkpoint_info().
    
    Fix a message about parsing redo log when redo log was not
    parsed.
    
    Fix tests, that used the message about parsing. Use the
    message about scanning instead.
    
    In tests, use $MYSQLTEST_VARDIR/tmp for logs.
    $MYSQLTEST_VARDIR/log is not preserved by MTR after a
    failing test. But the MEB logs are most valuable then.
    
    Add new test script meb.log_size_increase to repeat the
    reported bug when the patch is not applied.
    
    RB#19145

[33mcommit 21712df634870162277ed5438058f45719b1a448[m
Author: Venkatesh Duggirala <venkatesh.duggirala@oracle.com>
Date:   Wed Mar 28 16:19:01 2018 +0530

    Bug#27368735 BINLOG NAME AND POS ARE WRONG IN GROUP_REPLICATION_APPLIER CHANNEL'S ERROR MSGS
    
    Problem: When group_replication_applier channel's applier thread is facing
             an error, master_log_name and end_log_pos in the error message
             are incorrect.
    
    Analysis: In Group replication, events of a transaction are replicated
              before they were written in the binlog of the originating node. So
              the final master_log_name and the end_log_pos of those events are unknown
              at the [1;31mtime[m they are getting applied on the replica by group_replication_applier's
              applier thread.
    
    Fix: Now the error messages caused on group_replication_applier channel
         will not contain binary log name and the binary log position.

[33mcommit f46fe72ca7b0d9120eca2926e6a53bbd7d593553[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Fri Jan 26 12:35:27 2018 +0100

    Bug #27629719: SET PERSIST STORES TRUNCATED TIMESTAMPS
    
    Increased the resolution of the peristed variables [1;31mtime[mstams to the
    maximum allowed.
    Increased the delcared resoltion of
    performance_schema.variables_info.set_[1;31mtime[m used to display these.
    Added a test to make sure the fractional seconds are operational.
    Bumped the pfs version

[33mcommit 365426d551d4cc32f36bb497ee1f2f3b585e7a42[m
Author: Jens Even Berg Blomsoy <jens.even.blomsoy@oracle.com>
Date:   Mon Mar 5 15:54:22 2018 +0100

    Bug #27512609 POST PUSH FIX
    
      Problem:
      Not freeing the MEMROOT was not a negligible offence
      and caused a memory leak in ASAN and Valgrind builds.
    
      Solution:
      In my_tz_free() reset the default [1;31mtime[m zone and the
      global system variable [1;31mtime[m zone to the state they
      were before my_tz_init() was called. In this way
      there are no hanging pointers into the freed
      tz_storage variable.

[33mcommit 97cf6dd301bec0de017123ee82f2dc59fc389be7[m
Author: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
Date:   Mon Mar 19 18:45:50 2018 +0100

    Bug #27691698: UNDEFINED BEHAVIOR WHEN ACCESSING XPLUGIN STATUS VARIABLES
    
    Description:
    All tests in the x test suite give UBSAN warnings:
    storage/perfschema/pfs_variable.cc:1386:9:
    run[1;31mtime[m error: call to function
    void xpl::Server::global_status_variable_server<long long,
    &xpl::Global_status_variables::m_aborted_clients>(THD*, SHOW_VAR*, char*)
    through pointer to incorrect function type
    'int (*)(THD *, SHOW_VAR *, char *)'
    
    Reviewed-by: Lukasz Kotula <lukasz.kotula@oracle.com>
    Reviewed-by: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>
    RB:19183

[33mcommit c67f6127286df8948801e3b3464c581c2b705b3d[m
Author: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
Date:   Mon Mar 19 11:09:51 2018 +0100

    Bug #27691897 UNDEFINED BEHAVIOR IN RESET_GLOBAL_STATUS_VARIABLES
    
    Description:
    All tests in the x test suite give UBSAN warnings:
    sql/sql_udf.h:108:20: run[1;31mtime[m error:
    call to function (anonymous namespace)::reset_global_status_variables
    (UDF_INIT*, UDF_ARGS*, char*, char*)
    through pointer to incorrect function type
    'long long (*)(UDF_INIT *,UDF_ARGS *, unsigned char *, unsigned char *)'
    
    Reviewed-by: Lukasz Kotula <lukasz.kotula@oracle.com>
    Reviewed-by: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>
    RB:19179

[33mcommit 176fde06c5c4840284ab869487dde50c776c8761[m
Author: Marek Szymczak <marek.szymczak@oracle.com>
Date:   Mon Mar 26 14:38:13 2018 +0200

    Bug#27492122 SHUTDOWN HANG WHEN FIREWALL HAS MORE THAN 250K RULES
    
    Problem
    =======
    
    Deletion of 250k elements from the hash takes very long [1;31mtime[m.
    
    Analysis
    ========
    Elements are removed from the hash using its synchronization feature, where this
    is not required. All elements are removed in two scenarios:
    - Firewall shutdown
    - set_firewall_mode UDF is called. Exclusive access is guaranteed by the rwlock:
      WR_lock lock(&fw_users_lock).
    
    Fix
    ===
    
    Native destructor hash feature is used, which clears all elements on hash destroy
    (lf_hash_destroy). Are elements are destroyed within a second.
    
    Reviewed-by
    ===========
    Kristofer Alvring <kristofer.pettersson@oracle.com>
    Georgi Kodinov <georgi.kodinov@oracle.com>
    Marc Alff <marc.alff@oracle.com>

[33mcommit e57a6e4d9dd03587b8b2ad6c5b11601f4d8120fe[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Tue Mar 13 14:09:29 2018 +0530

    BUG#27591319: MESSAGE FROM LAST --ECHO IS NOT FLUSHED BEFORE TIMING
                  OUT ON SET DEBUG_SYNC
    
    Issue:
    ------
    SET DEBUG_SYNC = 'now WAIT_FOR something' statement in a test cases
    test [1;31mtime[m out, because something is never triggered, then the most
    recent '--echo' command is not reflected in the log file.
    
    bash> echo sample.test
    --echo one
    --echo two
    --echo three
    SET DEBUG_SYNC = 'now WAIT_FOR ever';
    
    bash> ./mtr main.sample --testcase-[1;31mtime[mout=1
    
    This obviously will [1;31mtime[mout, since we never trigger signal named
    'ever'. But, the strange thing is that log file contains only:
    
    bash> cat var/log/main.sample/sample.log
    one
    two
    
    The last echo statement output is not written to the log file.
    
    Fix:
    ----
    1. Flush the the contents in output buffer to file after writing the
       them.
    
    2. Created 'include/analyze-[1;31mtime[mout.test' file.
    
    Change-Id: Id5449a3893958123a1ed555e57ed757643200abd

[33mcommit 51a13022ae21a48a5a2f04dd0e889c269fa472d1[m
Author: Ingo Struewing <Ingo.Struewing@oracle.com>
Date:   Wed Mar 21 11:13:12 2018 +0100

    Bug#27571663 - MEB FAILS WHEN INNODB_LOG_FILE_SIZE IS DIFFERENT FOR INITIALIZE AND SERVER START
    
    MEB failed do scan the redo log up to its logical end under
    circumstances. One such case was resizing of the log files.
    Resizing can happen by shutdown and start of the server with
    a new value for the log file size. The case was repeatable
    after two resizes with one megabyte of extended size each.
    
    The core of the problem lies in a new redo log format
    (version 3). In this format, the log header field
    LOG_HEADER_START_LSN does not always have the expected
    value. Instead the relation of LOG_CHECKPOINT_LSN and
    LOG_CHECKPOINT_OFFSET is significant for lsn to offset
    calculations.
    
    So far MEB relied on LOG_CHECKPOINT_LSN for lsn to offset
    calculations. Due to the unreliable values, MEB could start
    to read the log from a wrong offset. It could get a
    zero-filled block, on which it assumed end of log.
    
    This patch fixes the lsn to offset calculations. It gets rid
    of MEB's own calculation and calls an InnoDB function for
    this calculation instead. (log_files_real_offset_for_lsn()
    from log0write.cc, log0log.h, log0types.h).
    
    It does also fix the creation of the log files at restore
    [1;31mtime[m. The checkpoint offset field needs to be set
    appropriately.
    
    Unrelated changes:
    
    Fix variable types used for lsns and offsets. Lsns have
    lsn_t and offsets have utin64_t.
    
    Reorder functions around the calculation in header and
    implementation file to a consistent order.
    
    Reduce the number of functions with similar signature.
    
    Rename variables, so that the same name is used for the
    same "thing" throughout.
    
    Rename functions so, that a prefix of log_ is reserved for
    InnoDB functions, a prefix of meb_ is used for MEB
    functions, that are implemented inside InnoDB sources, a
    function name with get_ extracts information from memory
    structures, a function name with read_ invloves reading of
    information from a file.
    
    Move meb_read_checkpoint_info from log0recv.cc to
    Redo_log_adapter::get_checkpoint_info().
    
    Fix a message about parsing redo log when redo log was not
    parsed.
    
    Fix tests, that used the message about parsing. Use the
    message about scanning instead.
    
    In tests, use $MYSQLTEST_VARDIR/tmp for logs.
    $MYSQLTEST_VARDIR/log is not preserved by MTR after a
    failing test. But the MEB logs are most valuable then.
    
    Add new test script meb.log_size_increase to repeat the
    reported bug when the patch is not applied.
    
    RB#19145

[33mcommit 41e975467d9c986200b6a0bdaaf807b473b35cfa[m
Author: Rahul Sisondia <rahul.sisondia@oracle.com>
Date:   Wed Mar 21 11:36:04 2018 +0100

    Bug#27454299 SYSTEM USERS USING MYSQL_NATIVE_PASSWORD WHEN
                 CACHING_SHA2_PASSWORD IS DEFAULT
    
    Description
    ------------
    While fixing this bug last [1;31mtime[m I chose the 1000 iterations to generate the
    digest for these 3 system users. I assumed that they are locked users and not
    used for internal purpose.
    
    Harin however had a different opinion that we must be consistent with the
    default behavior of caching_sha2_passwprd plugin which does the 5000 iterations
    to create digests. It will be consistent and there is not really any performance
    impact during initilzation/upgrade. Hence this change.
    
    Review:
    -------
    RB#18957

[33mcommit 4804928a3c9b45ae25d395645754041e0b7b7df8[m
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Thu Mar 15 12:10:35 2018 +0530

    Bug#25669553: MYSQLD_BOOTSTRAP_CMD ENV VARIABLE IS NOT RESET IF TEST HAD
                  BOOTSTRAP OPTIONS
    
    Post push fix:
    
    With the preliminary fix for this bug, the datadir is reinitialized
    each [1;31mtime[m after a test with bootstrap options in the opt file is run,
    to ensure the variable $MYSQLD_BOOTSTRAP_CMD is reset to its original
    value. However, that fix was not optimal and now we save the original
    value of $MYSQLD_BOOTSTRAP_CMD and reset it after the test run.
    
    Change-Id: I2633e258d2dcf44e033d21d83654fd1641e72337
    
    Conflicts:
            mysql-test/mysql-test-run.pl

[33mcommit 27e74c6c9c5b8a49d1323f2e134ceb9292ea5a06[m
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Thu Mar 15 12:10:35 2018 +0530

    Bug#25669553: MYSQLD_BOOTSTRAP_CMD ENV VARIABLE IS NOT RESET IF TEST HAD
                  BOOTSTRAP OPTIONS
    
    Post push fix:
    
    With the preliminary fix for this bug, the datadir is reinitialized
    each [1;31mtime[m after a test with bootstrap options in the opt file is run,
    to ensure the variable $MYSQLD_BOOTSTRAP_CMD is reset to its original
    value. However, that fix was not optimal and now we save the original
    value of $MYSQLD_BOOTSTRAP_CMD and reset it after the test run.
    
    Change-Id: I2633e258d2dcf44e033d21d83654fd1641e72337

[33mcommit 71464a1edb94d93c0f0c986752b95bcc4d0eb28a[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Mar 12 14:51:11 2018 +0100

    WL #11590: More flexible filesort [patch 3/10, incremental buffer]
    
    Instead of allocating one big filesort buffer up-front, start with
    a small buffer, only increasing it (exponentially) once we actually get more
    data. If we actually need all of the buffer, we do somewhat more mallocs
    than in the allocate-once case, but on Linux, the mallocs disappear
    entirely in the rest of the work. (On Windows, we do see a regression
    in heavily concurrent sort benchmarks, but that will be fixed in a future
    worklog.)
    
    For the case where we have a large buffer but don't use it (e.g. 256 kB
    of data with 32 MB large buffer), we do save a fair amount of CPU [1;31mtime[m (on the
    order of 7–8%, although of course this will vary with the exact circumstances).
    Also, of course, we save the RAM we don't use.
    
    Note that we never move data between the sort buffers -- once rows are written
    into a buffer, they never move. This means we need separate storage for the
    record pointers, which means we also need some care to make sure we don't
    overrun the sort buffer budget too much with the hidden cost of storing the
    pointers.
    
    Change-Id: I0599bc10947aec95ae80a3dbbf04e81d2017cfb0

[33mcommit 5948f89f005825b1e7294aa5847bc106a8102789[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Mon Mar 19 07:35:33 2018 +0100

    Bug #27712996 'SERVER FAILED TO RESTART' IN UPGRADE TESTS ON SOLARIS
    
    Solution: increase the waiting [1;31mtime[m for restart.
    
    Reviewed-by: Sivert Sørumgård <sivert.sorumgaard@oracle.com>
    Reviewed-by: Pavan Naik <pavan.naik@oracle.com>

[33mcommit 436c0007d83543a0a22e98393c62db392f4bb1dd[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Mar 9 16:24:12 2018 +0100

    Bug#27667440 RUNTIME ERROR: CALL TO FUNCTION MYSQL_SYS_VAR_LONG(THD*, INT) THROUGH POINTER TO
    
    To repeat: build with clang UBSAN, ./mtr main.func_math
    
    storage/innobase/handler/ha_innodb.cc:1624:11: run[1;31mtime[m error:
    call to function mysql_sys_var_long(THD*, int) through pointer to incorrect function type 'unsigned long *(*)(THD *, int)'
    sql/sql_plugin.cc:2741: note: mysql_sys_var_long(THD*, int) defined here
        #0 0xa1df719 in thd_lock_wait_[1;31mtime[mout(THD*) storage/innobase/handler/ha_innodb.cc:1624:11
    
    All PLUGIN_VAR_LONG variables are actually ulong, see struct System_variables,
    so treat them as ulong when resolving.
    
    Change-Id: Ieffc0a3ac6d12231140aaf569382ad11e279d38b

[33mcommit 19a816c5078b046091d68e6d77bc01f64e2331ba[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Mar 9 16:12:26 2018 +0100

    Bug#27667410 FIELD.H RUNTIME ERROR: POINTER INDEX EXPRESSION WITH BASE 0X000000000000 OVERFLO
    
    To repeat: build with clang UBSAN, ./mtr main.func_math
    
    sql/field.h:4198:13: run[1;31mtime[m error: pointer index expression with base 0x000000000000 overflowed to 0xfffffffffffff8b0
        #0 0x54ff314 in Field_bit::move_field_offset(long) sql/field.h:4198:13
    
    Don't increment bit_ptr if it is == nullptr (not in use)
    
    Change-Id: I1d6c32af12c86eb4849c909ec62c3efb224f5f40

[33mcommit b4d52a4008850baf7595e90b34dde097e0ff9c7c[m
Author: Jens Even Berg Blomsoy <jens.even.blomsoy@oracle.com>
Date:   Mon Mar 5 15:54:22 2018 +0100

    Bug #27512609 POST PUSH FIX
    
      Problem:
      Not freeing the MEMROOT was not a negligible offence
      and caused a memory leak in ASAN and Valgrind builds.
    
      Solution:
      In my_tz_free() reset the default [1;31mtime[m zone and the
      global system variable [1;31mtime[m zone to the state they
      were before my_tz_init() was called. In this way
      there are no hanging pointers into the freed
      tz_storage variable.

[33mcommit f0bcecb315a268d9de16e1c2e07a33523626dba7[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Fri Mar 9 11:48:18 2018 +0530

    BUG#27557011: MTR: SUPPORT --PARALLEL AND --REPEAT OPTIONS TO WORK TOGETHER
    
    Description:
    ------------
    Option '--repeat=N' runs a test N number of [1;31mtime[ms, but not in parallel even
    though the '--parallel' option value is greater than 1.
    
    Fix:
    ----
    1. Extended MTR to run a test N number of [1;31mtime[ms in paralle when '--repeat=N'
       option is specified and '--parallel' option value > 1.
    
    2. Both '--big-test' and '--enable-disabled' options are enabled by default
       when tests are specified on command line.
    
    Change-Id: I942e7c7eb5d87f1f6b279b2167c66ac8eed26527

[33mcommit fce60a0822a28e7282f4c1179ed123a97ae7b75b[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Thu Mar 8 14:53:12 2018 +0100

    Bug #27629719: SET PERSIST STORES TRUNCATED TIMESTAMPS
    
    Increased the resolution of the peristed variables [1;31mtime[mstams to the
    maximum allowed.
    Increased the delcared resoltion of
    performance_schema.variables_info.set_[1;31mtime[m used to display these.
    Added a test to make sure the fractional seconds are operational.
    Bumped the pfs version

[33mcommit 811e6875ae778d9e299391a1232859a891d0270f[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Mar 8 12:20:16 2018 +0100

    Bug#27660330 ADD SUPPORT FOR CLANG UBSAN bool system variables
    
    Use 'bool' rather than 'char' for boolean system variables.
    
    run[1;31mtime[m error: call to function mysql_sys_var_bool(THD*, int)
    through pointer to incorrect function type 'char *(*)(THD *, int)'
    sql/sql_plugin.cc:2733: note: mysql_sys_var_bool(THD*, int) defined here
    
    Change-Id: Ie712ed9be7134cf349f7ea236353849013a313e9

[33mcommit 14a5b231af5a499d3283d30fc3f6af6bcdda8cab[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Mar 8 12:43:03 2018 +0100

    Bug#27660330 ADD SUPPORT FOR CLANG UBSAN lf_alloc-pin
    
    Remove function pointer casting in lf_alloc-pin
    
    mysys/lf_alloc-pin.cc:330:5: run[1;31mtime[m error:
    call to function alloc_free(unsigned char*, unsigned char*, LF_ALLOCATOR*) through pointer to incorrect function type 'void (*)(void *, void *, void *)'
    mysys/lf_alloc-pin.cc:354: note: alloc_free(unsigned char*, unsigned char*, LF_ALLOCATOR*) defined here
        #0 0x9a7a297 in lf_pinbox_real_free(LF_PINS*) mysys/lf_alloc-pin.cc:330:5
    
    Change-Id: Ib00ea768670971a4851e8f250a7bb211ab9ffafb

[33mcommit 469b616539cd7e0159ae5e27e01b0951953e1952[m
Author: Rahul Sisondia <rahul.sisondia@oracle.com>
Date:   Mon Mar 5 10:52:55 2018 +0100

    Bug#27454299 SYSTEM USERS USING MYSQL_NATIVE_PASSWORD WHEN CACHING_SHA2_PASSWORD
    IS DEFAULT
    
    Description
    -----------
    
    Starting from 8.0.4, the default authentication plugin has been changed from
    mysql_native_pasword to caching_sha2_password but this change didn't impact
    the three system users which are created at the [1;31mtime[m of initializing the
    database.  These users are created/upgraded through predefined SQL scripts.
    
    Fix:
    ----
    
    1. Updated the default auth plugin to 'caching_sha2_password' in the SQL
       commands called at the [1;31mtime[m of  database initialize.
    2. Introduced a new sql file 'mysql_system_users' to create the system users.
       'mysql_system_tables.sql' is called by 'mysql_upgrade' as well so I
        consolidated the users creation at one place which is called during
        database initialization.
        a. Moved the creation of mysql.session and mysql.infoschema from
           sql_initialize.cc to the new file. This is consistent and avoids
           unnecessary pollution in cpp file.
    
    3. Following good old behavior is still intact.
        a.  mysqld --initialize creates three user with default
            auth plugin(i.e. caching_sha2_password.)
        b. mysql_upgrade - don't change the default auth plugin of the existing
           user but any new users are created with the default
           auth plugin (i.e. caching_sha2_password)
        For instance  - after upgrading from 5.7 to 8.0
        user                             plugin                     existing/new
        mysql.sys                   mysql_native_password            existing
        mysql.session               mysql_native_passwoed            existing
        mysql.infoschema            caching_sha2_passwors             new
    
     4. Removed the trailing spaces
    
    Testing :
    -------
    No new test case is written. Existing tests files have been updated.
    
    MTR suites passed in the local run.
    
    Branch - mysql-8.0-itch
    PB2 id - 12670561
    Timestamp - 2018-03-05 10:56:27

[33mcommit eb487593033ed11243d7174edb478473df56fe14[m
Author: Jens Even Berg Blomsoy <jens.even.blomsoy@oracle.com>
Date:   Fri Mar 2 17:19:48 2018 +0100

     Bug #27512609  5.7->8.0 UPGRADE CRASH WITH DEFAULT-TIME-ZONE SET
    
       Initial problem:
       Upgrading from 5.7 to 8.0 with --default-[1;31mtime[m-zone="+00:00"
       or any other [1;31mtime[m. Would crash the on the first atempt to
       start the server. This was caused by freeing a MEM_ROOT
       "my_tz_free()" to early, leaving dangling pointers.
       This happened in migrate_events_to_dd().
    
       Solution:
       Decided to not free the MEM_ROOT and just let it
       live for the duration of the server. This should
       not cause any problems as the amount of memory allocated
       is negligible
    
       The main changes to the code is as follows:
    
       event.cc:
       removed my_tz_free() from migrate_events_to_dd() at
       one point.
    
       dd_upgrade_test.test
       Added a test for the situation of upgrading from 5.7 to 8.0 with
       a default [1;31mtime[m zone set.
    
       Added a 5.7 data directory as a zip to be used within the upgrade test.

[33mcommit 79a27190c16f87733f64f9f10e9823998b072e9f[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Mar 1 14:40:41 2018 +0100

    Bug#27500610 - PERFORMANCE SCHEMA MEMORY INSTRUMENTATION CAUSES OVERHEAD
    
    Before this fix,
    
    the perforance schema memory instrumentation
    could cause run[1;31mtime[m overhead when enabled.
    
    The root cause is due to instruments with the following properties:
    - the instrument flags are 0,
      defined as per thread and not global
    - the instrumented memory is allocated / freed
      very often during execution
    - the instrumented memory can be allocated by one thread
      and freed by a different thread.
    
    Not having the global (PSI_FLAG_ONLY_GLOBAL_STAT) flag
    indicates that the performance schema should maintain:
    - per thread stats
    - per account stats
    - per user stats
    - per host stats
    as well as global statistics.
    
    Frequent instrumentation, and memory transfer of ownership between threads,
    causes a lot of overhead when maintaining the high/low water mark.
    
    The affected code to maintain high/low water marks is:
    - PFS_thread::carry_memory_stat_delta()
    - PFS_account::carry_memory_stat_delta()
    - PFS_user::carry_memory_stat_delta()
    - PFS_host::carry_memory_stat_delta()
    
    This fix requalifies many memory instruments as global,
    with the flag PSI_FLAG_ONLY_GLOBAL_STAT.
    
    This is a fix for both:
    
    1) Correctness.
    
    Instruments that keep track of a global resource,
    for example "memory/sql/host_cache::hostname",
    are by definition global.
    Keeping per thread stats is meaningless.
    
    2) Performances.
    
    This avoids keeping track of high/low watermarks,
    and reduce overhead.
    
    Also, a minor bug was fixed in pfs_memory_claim_v1(),
    which did not honor the PSI_FLAG_ONLY_GLOBAL_STAT flag.

[33mcommit 164248019054e593d799263a66be040677cba037[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Mar 1 10:22:20 2018 +0800

    Bug#26710839 - ASSERTION FAILURE: ROW0MYSQL.CC:1076:PREBUILT->MAGIC_N == ROW_PREBUILT_ALLOCATED
    
    This is because that there is one handler open for doing TRUNCATE in InnoDB,
    this is fine before current drop+create mode, however, with the new mode,
    InnoDB has to close the only open handler before dropping the old table.
    After dropping the old table, if there is anything wrong during next steps,
    InnoDB could not construct the m_prebuilt->table easily or properly,
    then in later SE API calls, as long as they access the m_prebuilt->table,
    it may hit all kinds of assertion because the table object could be broken
    already.
    
    So to fix this issue thoroughly, the best is server closes all opening
    handlers before diving into InnoDB for TRUNCATE. Then InnoDB will open
    and close the tables internally, without the effort to maintain the
    row_prebuilt_t structure. In the patch, TRUNCATE operation will go into
    the handler::create() API too, but with different SQL commands, then
    InnoDB can identify the exact operation, and either create a table,
    or truncate a table.
    
    With this patch, some error messages for FK constraints becomes shorter
    and cleaner. At the mean[1;31mtime[m, it's possible to truncate a corrupted table now.
    
    RB: 17260
    Reviewed by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed by: Sivert Sorumgard <sivert.sorumgaard@oracle.com>

[33mcommit 20cf6e55522cb0c303fd9e5c39d24085cedb8272[m
Author: Debarun Banerjee <debarun.banerjee@oracle.com>
Date:   Wed Feb 28 11:38:03 2018 +0530

    BUG#23476050 THREADS STUCK WAITING TO ENTER INNODB
    
    Problem :
    --------
    There are two different symptoms in this bug.
    
    1: deadlock between two sessions
        Session-1: holds Innodb ticket and asks for partition Auto INC lock
        Session-2: holds partition Auto INC lock and asks for Innodb ticket
    
    It happens with innodb_thread concurrency = 1 but could happen with
    higher value also.
    
    The case is not frequently observed as generally the partition Auto INC
    lock held for short [1;31mtime[m i.e. the lock is always released immediately
    before attempting to wait for anything else.
    
    There is a special case with "Statement Based Replication" and
    multi-row insert statement where the Auto INC lock is held until the
    whole statement is over. This is to ensure that the auto increment
    values are consecutive: a requirement from statement based replication.
    
    Since we hold Innodb tickets also for the duration of the statement
    and in the special case the Auto Inc lock is acquired in partition
    layer before acquiring Innodb ticket it conflicts with the order
    of acquisition in general case resulting in the deadlock.
    
    2: deadlock between two sessions
        Session-1: High priority transaction holds Innodb ticket and waits
                   for the victim to come out of Innodb
        Session-2: Set to be In Innodb and waits for Innodb ticket
    
    It happens with innodb_thread concurrency = 1 but could happen with
    higher value also. There could be many such pairs of victim and
    high priority transactions.
    
    Solution :
    ----------
    1. In partition layer, acquire Innodb ticket before asking for
       partition Auto INC lock.
    
    2. Release Innodb ticket while waiting for victim transaction to
    come out. This is similar to what we do while waiting for lock
    in Innodb.
    
    Reviewed-by: Jimmy Yang <Jimmy.Yang@oracle.com>
    
    RB: 18869

[33mcommit 9529df4b330629e2f2ad9675a6da7e135bfee0e5[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Tue Feb 13 15:26:10 2018 +0100

    Bug #27309094: REJECT LCTN CHANGING AFTER --INITIALIZE
    
    We cannot allow restarting the server with a lower_case_table_names
    setting which is different from the setting that was used when the
    server was initialized, because the collations used by the DD tables
    is defined at initialization [1;31mtime[m, while the server operates according
    to the new l_c_t_n setting internally. Thus, this would lead to an
    inconsistency in the way identifiers are compared and ordered.
    
    This patch implements the following:
    
    1. Abort server restart if the lower_case_table_names setting is
       different from the setting which was used during --initialize.
    
    2. (Unrelated to this bug) When looking up the property key 'DD_VERSION'
       in the DD table 'dd_properties', if the key is not found, then also
       look for the key 'DD_version', which was used in DD version 1. The
       motivation for this is to provide a more meaningful error message.
    
    3. (Unrelated to this bug) Add comments in sql/dd/dd_version.h
       describing the changes from DD version 1 to DD version 80004.
    
    4. (Unrelated to this bug) Fix 'inheritance by domination' warnings.
    
    Change-Id: I1cfae8cd7889edfe3adcee409dec9e83a1fd3881

[33mcommit 99caaea65dd30164324ebfb031c4555668366fcb[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Feb 23 10:20:05 2018 +0100

    Bug#27584796 ADD NEW CMAKE OPTION: BUNDLE_RUNTIME_LIBRARIES
    
    Add new cmake option to bundle
     msvcp140.dll
     ucrtbase.dll
     vcrun[1;31mtime[m140.dll
     msvcp140d.dll
     ucrtbased.dll
     vcrun[1;31mtime[m140d.dll
    
    with server MSI or .zip packages
    
    Also:
    remove some obsolete compiler flags for building unit tests on Windows/Mac
    
    Change-Id: I8442842a45eb2b9f57a90852df6a185d439cbc49

[33mcommit db3b4c462c1fb4e26e7f01141125223ffdbba54f[m
Author: Harin Vadodaria <harin.vadodaria@oracle.com>
Date:   Wed Feb 21 12:08:08 2018 +0100

    Bug#27335346: SYSBENCH CONNECT TEST SHOWS -14% REGRESSION
                  FOR ROOT USER WITOUT PASSWORD
    
    Description: Plugin lock optimization were missing for
                 caching_sha2_password. This resulted into one
                 lock/unlock per connection.
                 This impacted performance.
    
    Solution: Lock built-in plugins at server startup and keep
              them locked till server shutdown. Also, use these
              plugin handles instead of going through
              lock/unlock at the [1;31mtime[m of connection.

[33mcommit 4cc3739a29416192b59fc552e01e0ef549689e0a[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Wed Feb 7 12:22:13 2018 +0100

    Bug #27402243: DC->FETCH_GLOBAL_COMPONENTS(DD::TABLESPACES)
                   TAKES TOO MUCH TIME WITH 1MILLION
    
    Problem: Bad performance when fetching DD objects by first
    reading the object ids followed by uncached acquisition of
    the individual objects.
    
    Analysis: May combine the two loops and read objects based
    on the record at hand instead of just fetching the id and
    reading the object in a second loop. However, reading the
    record (with children) must be done in a separate transaction
    since we may otherwise end up opening the same index twice
    (e.g. when reading dd::Table objects), which is not supported.
    
    Solution: The fix, as indicated above, improves performance
    of this step by about 20%. The objects being read are added
    to the auto delete structure in the dictionary client to keep
    the object ownership the same as it was before this patch.
    Thus, the fetch() method is now a member of the dictionary
    client, and both the method itself and methods calling it are
    hence now non-const.
    
    Fetching the tablespace objects is done to populate the DD
    cache in InnoDB. After fetching the objects, InnoDB is
    validating the tablespace files by opening them. This phase
    takes a considerable amount of [1;31mtime[m, and it might be considered
    whether the fetching and validation could be done on demand
    rather than up front. Bug#27556902 is filed to track this issue.
    
    Change-Id: I3202e1529bc9f9209d12415aeca12aa8c1a196bc

[33mcommit 97f52dc836ee46f2c9c47096737258004daf728e[m
Author: Ole-Hjalmar Kristensen <Ole-Hjalmar.Kristensen@oracle.com>
Date:   Tue Feb 20 15:08:27 2018 +0100

    Fix for Bug #26771524   MONOTONIC CLOCK IS MISSING IN XCOM
    
    The problem is that the internal tasks in xcom waiting for a [1;31mtime[mout will get
    stuck if someone changes the system clock back in [1;31mtime[m.
    
    This patch creates a replacement monotonic clock function based on performance counters
    in Windows and based on clock_get[1;31mtime[m on Posix.

[33mcommit 295bad1b1c7be928d08e82b506b0238a8ead61fd[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Feb 20 14:48:44 2018 +0100

    Bug#27471510 PERFORMANCE_SCHEMA STATUS AND VARIABLE BY THREAD ARE NOT SAFE
    
    Patch for 8.0.
    
    Before this fix, executing:
      SELECT * FROM performance_schema.status_by_thread
      SELECT * FROM performance_schema.variables_by_thread
    under heavy load was unsafe.
    
    Root cause 1
    ============
    
    SELECT * from performance_schema.status_by_thread
    inspects the status variables of running sessions.
    
    For sessions using SSL, SSL status variables are inspected.
    
    For example, the status variable "Ssl_cipher_list" is evaluated
    by executing function show_ssl_get_cipher_list()
    
    This function is implemented as follows:
    
    show_ssl_get_cipher_list()
    {
      if (thd->get_protocol()->get_ssl()) // (a)
      {
        ...
        SSL_get_cipher(thd->get_protocol()->get_ssl())); // (b)
        ...
      }
    }
    
    The problem is that evaluating
      thd->get_protocol()->get_ssl()
    to access the underlying SSL structure is unsafe,
    and subject to race conditions.
    
    The value returned in (a) can change by the [1;31mtime[m (b)
    is evaluated, for example when using prepared statements,
    because the thd->get_protocol() pointer will change
    during execution of PREPARE and EXECUTE.
    
    Fix 1
    =====
    
    thd->get_protocol()->get_ssl()
    is not a proper way to access SSL data for the session.
    
    Instead, THD::m_SSL now keeps the SSL data attached to the
    THD session.
    
    THD::m_SSL is set after the SSL connection is established,
    is reset upon disconnect,
    and is immutable during the session execution.
    
    Inspecting this attribute is safe when LOCK_thd_data is held,
    which make table performance_schema.status_by_thread safe.
    
    Root cause 2
    ============
    
    SELECT * from performance_schema.variables_by_thread
    inspects the variables of running sessions.
    
    In particular, variable "session_track_system_variables"
    is inspected.
    
    This variable value is stored in THD::variables.track_sysvars_ptr
    
    On the session connection,
      THD::variables.track_sysvars_ptr
    is duplicated and points to allocated memory,
    in this call:
        thd->session_sysvar_res_mgr.init(&thd->variables.track_sysvars_ptr,
    thd->charset());
    
    This is because Session_sysvar_resource_manager::init()
    modifies the THD::variables.track_sysvars_ptr pointer itself.
    
    On session disconnect,
      Session_sysvar_resource_manager::deinit()
    free the allocated memory,
    which leaves the THD::variables.track_sysvars_ptr pointer
    invalid, referencing freed memory.
    
    As soon as cleanup_variables() unlocks LOCK_thd_data,
    a race condition is possible,
    when using the now invalid THD::variables.track_sysvars_ptr pointer.
    
    Fix 2
    =====
    
    In cleanup_variables(),
    clear the offending pointer before freeing the underlying memory
    with the call to session_sysvar_res_mgr.deinit()
    
    This makes table performance_schema.variables_by_thread safe.

[33mcommit 80976f88f2cd35f28a8320a40fa17da32723cc92[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Feb 15 17:15:36 2018 +0100

    WL#10310 Redo log optimization: dedicated threads and concurrent log buffer.
    
    Post-push fixes for clang warnings:
    
    storage/innobase/buf/buf0flu.cc:437:20: error: unused function
          'buf_flush_list_order_validate' [-Werror,-Wunused-function]
    static inline bool buf_flush_list_order_validate(lsn_t earlier_added_lsn,
    
    storage/innobase/os/os0file.cc:314:23:
    error: missing field 'm_file' initializer
          [-Werror,-Wmissing-field-initializers]
      pfs_os_file_t file{0};
    
    storage/innobase/srv/srv0srv.cc:1954:16:
    error: unused function '[1;31mtime[mval_diff_us'
          [-Werror,-Wunused-function]
    
    Change-Id: I2eb1b8347ca7d041ce3c6ac3c0b3a635d5f4805a

[33mcommit 0b1b0b40408d0738ac41f3d1185f5b895730b265[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Feb 15 17:15:36 2018 +0100

    WL#10310 Redo log optimization: dedicated threads and concurrent log buffer.
    
    Post-push fixes for clang warnings:
    
    storage/innobase/buf/buf0flu.cc:437:20: error: unused function
          'buf_flush_list_order_validate' [-Werror,-Wunused-function]
    static inline bool buf_flush_list_order_validate(lsn_t earlier_added_lsn,
    
    storage/innobase/os/os0file.cc:314:23:
    error: missing field 'm_file' initializer
          [-Werror,-Wmissing-field-initializers]
      pfs_os_file_t file{0};
    
    storage/innobase/srv/srv0srv.cc:1954:16:
    error: unused function '[1;31mtime[mval_diff_us'
          [-Werror,-Wunused-function]
    
    Change-Id: I2eb1b8347ca7d041ce3c6ac3c0b3a635d5f4805a

[33mcommit faa06483b91919790fb4dc489c1e2841ac1d4c18[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Thu Feb 15 16:29:53 2018 +0100

    Bug#24713879 ASSERTION `MAYBE_NULL' FAILED. HANDLE_FATAL_SIGNAL IN TEM_FUNC_CONCAT::VAL_STR
    
    We have an outer query and a subquery.
    Outer query's table is found empty at optimization: this sets the
    table's column to NULL (table->set_null_row()) even though columns are
    defined as not nullable.
    Then when we optimize the subquery, which sets up ref lookup using
    outer table's column as reference, and wants to evaluate it
    immediately as it's a constant CONCAT; but CONCAT didn't expect to see
    a NULL argument, as the column was not nullable at fix_fields() [1;31mtime[m.
    Solution:
    - don't optimize subquery if outer query JOIN is known to have empty
    result (let EXPLAIN show "Not optimized, outer query is empty").
    - there remains one case where subquery must be optimized: it's if the
    outer query has aggregates without GROUP BY: then it has a non-empty
    result and any subquery in SELECT list must be evaluated and thus be
    optimized, which reopens the issue
    - we detect that in is_null_on_empty_table() and mark the column as
    nullable. As it's done in fix_fields(), it properly propagates to
    CONCAT.

[33mcommit 6be2fa0bdbbadc52cc8478b52b69db02b0eaff40[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Wed Feb 14 09:33:42 2018 +0100

    WL#10310 Redo log optimization: dedicated threads and concurrent log buffer.
    
    0. Log buffer became a ring buffer, data inside is no longer shifted.
    
    1. User threads are able to write concurrently to log buffer.
    
    2. Relaxed order of dirty pages in flush lists - no need to synchronize
       the order in which dirty pages are added to flush lists.
    
    3. Concurrent MTR commits can interleave on different stages of commits.
    
    4. Introduced dedicated log threads which keep writing log buffer:
        * log_writer: writes log buffer to system buffers,
        * log_flusher: flushes system buffers to disk.
       As soon as they finished writing (flushing) and there is new data to
       write (flush), they start next write (flush).
    
    5. User threads no longer write / flush log buffer to disk, they only
       wait by spinning or on event for notification. They do not have to
       compete for the responsibility of writing / flushing.
    
    6. Introduced a ring buffer of events (one per log-block) which are used
       by user threads to wait for written/flushed redo log to avoid:
        * contention on single event
        * false wake-ups of all waiting threads whenever some write/flush
          has finished (we can wake-up only those waiting in related blocks)
    
    7. Introduced dedicated notifier threads not to delay next writes/fsyncs:
        * log_write_notifier: notifies user threads about written redo,
        * log_flush_notifier: notifies user threads about flushed redo.
    
    8. Master thread no longer has to flush log buffer.
    
    9. Introduced dedicated log thread which is responsible for writing checkpoints.
       No longer concurrent user threads need to compete for this responsibility.
    
    10. Master thread no longer has to take care of periodical checkpoints.
        Log checkpointer thread writes checkpoint at least once per second
        (before it was once per 7 seconds).
    
    11. The following exposed system variables, can be changed in run[1;31mtime[m now:
        * innodb_log_buffer_size,
        * innodb_log_write_ahead_size.
    
    12. Master thread measures average global cpu usage in OS.
    
    13. Introduced new exposed system variables:
        * innodb_log_wait_for_flush_spin_hwm,
        * innodb_log_spin_cpu_abs_lwm,
        * innodb_log_spin_cpu_pct_hwm.
        They control when we need to use spinning for the best performance,
        to reduce latency which would otherwise come from communication
        between log threads and user threads. The first one is based on
        average flush [1;31mtime[m, the two others are based on cpu usage.
    
    14. Introduced new CMake option: ENABLE_EXPERIMENT_SYSVARS=0/1. System variables
        can be marked as hidden unless the experiment mode is turned on.
    
    15. There is a list of hidden new system variables for experiments with redo log.
        We skip listing them here.
    
    16. Created dedicated tester for redo log alone (as gtest).
    
    17. Created doxygen documentation for the new redo log.
    
    18. The dict_persist margin is updated when number of dirty pages is
        changed, instead of calculations on demand.
    
    19. Mechanism used to copy last incomplete block for Clone has been changed,
        because log buffer is concurrent now.
    
    20. Added more useful MONITOR counters for redo, including average lsn rate.
    
    21. Introduced sharded rw-lock to have an option to stop the world in redo,
        because log_mutex is removed.
    
    22. Invented and implemented a concurrent data structure which tracks progress
        of concurrent operations and can answer up to which point they all have been
        finished (when there is some order defined but they are allowed to be executed
        out of the order). This structure is used for concurrent writes to log buffer
        and re-used for concurrent additions to flush lists.
    
    23. Introduced a universal mechanism to wait on event, which starts with
        provided number of spin delays, then fallbacks to waits on event,
        starting at small [1;31mtime[mout, but increasing [1;31mtime[mout every few waits.
        This mechanism is used in communication between user and log threads,
        and in communication between different log threads.
    
    24. We slow-down redo log writer when there is no space in redo allowing
        checkpoints to progress and rescue the state of redo.
    
    25. Log buffer can be resize in run[1;31mtime[m - the size can also be decreased.
    
    26. Simplified shutdown procedure to avoid a possible returns in logic
        to previous phases.
    
    27. Removed concept of multiple log groups.
    
    28. Relaxed conditions required for checkpoint_lsn. It can now point to
        any data byte within redo (does not need to point to a records group
        beginning).
    
    29. Windows: always use buffered IO for redo log.
    
    30. Mysql test runner received a new feature (thanks to Marcin):
        --exec_in_background.
    
    Review: RB#15134
    
    Reviewers:
        - Marcin Babij <marcin.babij@oracle.com>,
        - Debarun Banerjee <debarun.banerjee@oracle.com>.
    
    Performance tests:
        - Dimitri Kravtchuk <dimitri.kravtchuk@oracle.com>,
        - Daniel Blanchard <daniel.blanchard@oracle.com>,
        - Amrendra Kumar <amrendra.x.kumar@oracle.com>.
    
    QA and MTR tests:
        - Vinay Fisrekar <vinay.fisrekar@oracle.com>.

[33mcommit 8f5ed27f8b0d85717c54d23fcca0e47cf9409b80[m
Author: Rahul Sisondia <rahul.sisondia@oracle.com>
Date:   Wed Feb 14 10:08:43 2018 +0100

    Bug#27400095 unable to access 8.0.4 server after starting on top of 5.7.20
    database
    
    Description
    -----------
    
    This problem was reported while starting the server after in-place upgrade from
    the mysql 5.7.20 to 8.0.4 version when --skip-grant-tables options is enabled.
    
    During the investigation it turned out that starting from 8.0.4 default
    authentication plugin has been changed to chaching_sha2_password due to that
    problem could also be seen if the 8.0.4 server is started with
    --skip-grant-tables options then 8.0.4 client is unable to connect to it.
    
    This happens because caching_sha2_password client/server plugins require more
    packets interchange after the client has sent the scrambled password to the
    server.
    If server after receiving the scrambled packet from the client detects that
    --skip-grant-tables option is specified then it simply returns the CR_OK packet
    while client is expecting either fast_auth_success or
    perform_full_authentication packet.
    
    Fix:
    ---
    We now let the server continue the handshake process with the decoy user instead
    of returning the CR_OK packet to the client.  This required the following
    changes -
      1. Added a check in the find_mpvio_user method so that if acl_users are null
         then it can directly create the decoy user.
      2. In the parse_client_handshake_packet, let it set the user as decoy user
         and continue.
      3. We set the MPVIO as SUCCESS in case of --skip-grant-tables therefore if
         any error is encountered after this point will set in the diganotic_area
         as well. We must reset that in --skip-grant-tables is specified.
         This problem was discovered while testing the fix with PIPE protocol.
    
    Unrelated changes - Fixed typos in the doxygen comments.
    
    Testing :
    -------
    
    Added two new test files.
    skip_grant_protocols -
        Executes on non-windows platforms. Verifies the fix with socket protocol.
    skip_grant_protocols_windows -
        Execute on windows platform. Verifies the fix with the shared-memory
        and named-pipe protocols.
    
    Verified the scenario reported in the bug manually as it is not possible to
    write MTR test for it. Neither it is required.
    
    branch - mysql-8.0-itch  ( In progress)
    push id: 12544359
    Date - 2018-02-08 09:40:17 
    
    Report from loki-
    
    Unit tests: 100% tests passed, 0 tests failed out of 46
    --------------------------------------------------------------------------
    The servers were restarted 1458 [1;31mtime[ms
    Spent 24259.968 of 1409 seconds executing testcases
    
    Completed: All 5828 tests were successful.
    
    1663 tests were skipped, 147 by the test itself.
    
    Review :
    --------
    RB#18698

[33mcommit 1b050394f2a95bdf729c5bef2a287a955f1c3b86[m
Author: Venkatesh Duggirala <venkatesh.duggirala@oracle.com>
Date:   Wed Feb 14 12:27:54 2018 +0530

    Bug#27041759 RESET MASTER WHILE A TRX IN BGC(AFTER FLUSH) LEAVING
    SERVER IN BAD GTID STATE
    
    Problem: When a transaction is in Binlog group commit, (flush stage is done
             but third stage, commit stage, is not done yet), if some one executes
             RESET MASTER, binlog will not contain the transaction (it will be
             cleared by RESET MASTER), but after the transaction is committed,
             transaction gtid is added to gtid_executed. And this gtid cannot be
             utilized by server again even though the transaction is already
             cleared from the binlog. This leaves the server in bad gtid state.
    
    Analysis: Server adds the transaction's gtid to owned_gtid during the flush stage.
        And at the [1;31mtime[m of commit stage, the owned_gtid is added to gtid_executed.
        As the above problem statement states, if there is RESET MASTER in between
        these two stages, the transaction content is getting cleared but we are adding
        the gtid to gtid_executed which leaves the server in bad gtid state.
    
    Fix: RESET MASTER is going to acquire global read lock to make sure
        that no transacation is currently in commit stage while doing it's
        operation. If there are any ongoing commits, RESET MASTER will wait
        until those commits are done. Acquiring global read lock will also
        make sure that no new commits will enter into commit stage. At the
        end of the 'RESET MASTER' operation, it will release the global
        read lock.
    
        Other cases:
           > If the thread is already acquired 'global read lock' by executing
        'FLUSH TABLES WITH READ LOCK' command, then RESET MASTER will not
        try to acquire again.
           > If the thread is holding lock (read/write) on any table, RESET MASTER
             will throw error ER_LOCK_OR_ACTIVE_TRANSACTION.

[33mcommit eb91dc41900352381ceb1eea1ab46a806c3889fd[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Wed Feb 14 05:55:51 2018 +0100

    Bug #27522405   SET PERSIST NOT HONORING TIMESTAMPS CAUSING A GR INIT FAILURE
    
    Problem: When binlog_checksum is persisted to a value NONE and other needed GR
    specific variables are persisted, next server start should make GR start on
    boot which is not the case.
    
    Analysis: Although persisted variables are sorted out based on [1;31mtime[mstamp.
    Internally in code we maintain 2 separate list, 1 for server variables and 1
    for plugin variables. In first iteration we set all persisted server variables
    and in second iteration we set all plugin variables(during plugin load). Since
    binlog_checksum is a dynamic variable it is set to its persisted value very
    late in server startup phase. GR plugin variables although defined as dynamic
    variables they are set even before GR plugin is loaded. Thus we see that GR
    does not start on boot even when binlog_checksum is persisted before GR
    variables. To be precise GR is loaded before the server loads the value for
    binlog_checksum.
    
    Fix: Fix is to introduce a flag PERSIST_AS_READ_ONLY which when set for server
    variables will make the variable a pseudo read only variable. For any server
    variable when this flag is set this variable is written to
    "mysql_server_static_options" which will make variable to be set at command line
    during server start.

[33mcommit bf82b17ba1a21a92fc9cb60d1d9b62039e765111[m
Author: Alfranio Correia <alfranio.correia@oracle.com>
Date:   Mon Feb 12 16:35:42 2018 +0000

    BUG#26394418: SETTING GR_FORCE_MEMBERS HITS ERROR1231 SOMETIMES WHILE UNBLOCKING THE GROUP
    
    When we are forcing a new config, there is an asymmetry in the
    system.  Consider 3 nodes, A, B, and C which are survivors from
    the old config and C is the node forcing the new config. A and B
    are continually trying to determine the value of the messages in
    the pipeline, but are unable to do so, because they cannot get
    majority. After some retries, the randomized, exponential backoff
    [1;31mtime[mr will reach its maximum value, and the nodes will retry with
    an interval of 2^3 seconds.
    
    C will initially install the forced config locally, and use this
    config to try to push both the new config and any messages already
    in the pipeline. However, it will typically not succeed, since A
    and B have been incrementing the ballot numbers of these messages,
    including the message number that will be used to send the forced
    config, so C will have to wait until it sees an incoming prepare
    from A or B to reset its ballot number to something higher.
    Depending on the exact timing, however, this may not happen until
    C has reached the max value for its backoff [1;31mtime[mr. A,  B, and C
    will then retry at approximately the same rate.
    
    Normally, this will not be a problem, since all nodes have the same
    config, and the interval is long enough that one of them will reach
    consensus before any of the others retry with a higher ballot, but
    in this case, C is the only one that can reach consensus, and C may
    see enough incoming prepare messages that it thinks that one of the
    other two should get the chance to finish its consensus round first,
    effectively blocking until the command [1;31mtime[ms out.
    
    To avoid this problem, we suppress pushing or retry of messages if
    a node does not see enough nodes that it can get a majority. In the
    scenario described above, this would stop A and B from proposing
    values until they have received the new config.

[33mcommit 7985be4a0f707e77e967dd722f80db7b2743cfb7[m
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Tue Feb 6 12:19:32 2018 +0530

    Bug#27492656: MTR IGNORES THE INIT_FILE OPTION WITH --BOOTSTRAP DURING SERVER INITIALIZATION
    
    Issue:
    ------
    If the --init-file option is given as a value to the --bootstrap option in MTR,
    the SQL statements in the file must be executed during the server initialization
    [1;31mtime[m. However, MTR has a bootstrap.sql of its own which it uses during the
    initialization process, and that overwrites any sql file which is passed on the
    command line by the user.
    
    Fix:
    ----
    If --init-file option is passed during the initialization process, then the
    contents of this sql file are appended to the end of the bootstrap.sql file
    which MTR uses.
    
    Change-Id: Iff62eb0859c56806dae086fdfb79bd8b3e154b78

[33mcommit 28eac338d3593de8a4d0a74b2d11014ce9cbed35[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Fri Feb 2 15:01:09 2018 +0100

    Bug#27484133    WINDOW FUNCTIONS COULD READ LESS ROWS FROM TEMPORARY TABLE
    
    A refactoring of the logic of how window functions buffer rows and
    re-reads them from the frame buffer.
    This reduces the count of calls to handler::rnd_pos() by 25%.
    During this refactoring, other things have been cleaned up:
    - more comments in code
    - if user didn't specify a frame, create a frame of
    RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW (if there is ORDER BY
    in window), or
    BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING (sql_yacc.yy)
    This allows to eliminate quite few tests like "if frame==nullptr".
    - changed signature of create_tmp_table() to make it less
    window-ish: the last parameter (enum TMP_WIN*) is removed,
    because it's possible to infer its value from other information:
    we now give a non-zero Temp_table_param::m_window only if it's
    the OUT table, not the frame buffer; so testing m_window is equivalent
    to testing TWP_WIN_CONDITIONAL; not_all_columns is also used, as tmp
    tables which don't care for windowing have it false. Thus,
    enum_tmpfile_windowing_action is removed.
    - when we want to calculate FIRST/LAST/NTH_VALUE without
    modifying the current value of other aggregates, instead of evaluating
    other aggregates but with a "dont_aggregate" flag, we don't evaluate
    them (see CFT_WF_USES_ONLY_ONE_ROW)
    - "dynamic frame upper bound" strategy was for
    RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ;  instead, let it flow
    into the normal range-framing code, but still with a couple of if()s
    here and there to keep optimizations (see range_to_current_row and
    range_from_first_to_current_row)
    - cleaning up of some ref slices was missing (cleanup_item_list)
    - setup_tmp_table_write_func: "phase" can be inferred from
    qep_tab->ref_item_slice
    - saving/restoring special records FBC_FIRST_IN_STATIC_RANGE
    and FBC_LAST_RESULT_OPTIMIZED_RANGE was useless, as WF values
    of previous row are still present in OUT table.
    - some[1;31mtime[ms we ask to fetch row N from frame buffer, and do the same
    shortly after; added Window::m_row_has_fields_in_out_table
    which keeps track of the last row fetched, so bring_back_frame_row()
    can consult this variable to know it doesn't really have to fetch
    it a second [1;31mtime[m.
    - m_input_row_clobbered was there to avoid a fetch in case
    the input row hadn't been clobbered; now that we have
    m_row_has_fields_in_out_table we can ask for a fetch unconditionally:
    if row hasn't been clobbered it won't actually be fetched.
    - introduced Window:m_needs_card to avoid recalculation of this info
    for every row (some_wf_needs_frame_card() is thus removed).
    - make "static aggregate" and "row inversion" and "range inversion"
    mutually exclusive
    - setup_windows(): merged prepared-stmt and non-prep-stmt init
    branches as much as possible
    - short-circuiting of last tmp table: made it apply to more cases
    (e.g. if SQL_BUFFER_RESULT and two windows, short-circuit is
    now possible)
    - mgmt of special records moved out of buffer_record_somewhere() for
    separation of concerns
    - it was common to call bring_back_frame_row() then copy_fields();
    made the former call the latter.
    - in process_buffered_windowing_record: if range frame, set
    upper_limit to INT64_MAX; this is clearer than having
    some_wf_needs_frame_card() return true if range frame (had the same
    effect, but was more hidden).
    - thanks to the caching in bring_back_frame_row(), two_pass_done logic
    is not needed anymore; removed; only one call to
    process_wfs_needing_card() is necessary in code.
    - reestablish_new_partition_row() removed
    - end_write_wf(): moved an if() up so that we have less nested blocks
    - The number of rnd_pos() calls is reduced as announced; but this is
    not tested in MTR, as numbers vary by a few units, depending on if
    test is run alone or not, with prep-stmt or not; so the SHOW STATUS
    are added to window_functions.test but commented out.

[33mcommit 9d591e29af1654b99a670d975ad8b9c95b011747[m
Author: Neha Kumari <neha.n.kumari@oracle.com>
Date:   Fri Feb 2 09:12:08 2018 +0530

    Bug#27252658 :CHANGE DEFAULT VALUE OF BINLOG_EXPIRE_LOGS_SECONDS
    
    Problem:
    At present the default value of binlog_expire_logs_seconds is 0, so in future
    when expire_logs_days is removed the default expiration [1;31mtime[m will be set to
    '0', which will make the logs to be not purged at all, where in expectation
    they should have been purged after 30 days.
    
    Fix:
    To avoid the above scenario these are the three combinations regarding when
    to consider the default value of what.
    
    1) If user provides values for both options, both variables are set
       accordingly and 'binlog_expire_logs_seconds' takes effect.
    
    2) If user provides a value for only one of the options, that particular
       variable is set accordingly, and the other variable defaults  to 0.
    
    3) If user does not provide a value for any of the options, then
       'binlog_expire_logs_seconds' defaults to 30 * 24 * 60 * 60 and 'expire_logs_days' to 0.
    
    This patch also changes the default value of expire_logs_days to 0.

[33mcommit 0d0f673a017447bca9bd30e96d4aeb12a62991d1[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Thu Feb 1 17:52:42 2018 +0100

    Bug#25894101: TEST CASE I_INNODB.INNODB_BUG16244691 FAILED IN SHUTTING DOWN
    THE SERVER.
    
    Problem: Innodb purge threads could end up in a situation where they
    needed to process a large number of log records referring to dropped
    tables, which do not exist in the DD. The purge thread looks up the
    tables in the DD using the se_private_id, and this would take a long
    [1;31mtime[m since the DD would need to access both the TABLES and PARTITIONS
    tables on disk to verify that the table did not exist. This could lead to
    [1;31mtime[mouts, e.g. during shutdown.
    
    Solution: Add a cache of se_private_ids known not to be associated
    with a table. The cache must be an lru of fixed size, since there is
    no simple way to determine when an se_private_id will no longer be
    used.
    
    Change-Id: I9510da9116f26bbbb3aa00a0abdba0e63ea27503

[33mcommit 419c714e58e47165a954dc6b935a83f84badf8b9[m
Author: Martin Hansson <martin.hansson@oracle.com>
Date:   Wed Dec 20 11:54:16 2017 +0100

    Bug#27289282: ACTUALLY CONSTRUCT TABLE_LIST OBJECTS
    
    Mainly, C-casting of the result of a mem_root malloc or
    calloc is replaced with actually calling the
    constructor. Some[1;31mtime[ms, however, the TABLE_LIST is part of a
    larger chunk of memory. In these cases, that practice is
    untouched and a placement-new is used instead.
    
    MyISAM code still commits the above atrocities since we
    don't want to touch it.
    
    Fortunately, most members of TABLE_LIST already have default
    initializers which keeps the constructor lithe and readable
    even without the zero-initializations.
    
    Some[1;31mtime[ms TABLE_LIST objects are copied, and this has been
    replaced with the obvious choice of copy-construction. This
    revealed that MDL_key objects (member of MDL_request objects
    which is a member of TABLE_LIST) forbade copy-construction
    but were copied behind our backs using memcpy(). This
    copying is now made visible by enabling the copy-constructor
    and it's also possible to break in a debugger.
    
    Another hack also got uncovered: dd::enum_table_type has a
    fourth value of 0 which is invisible since it's a
    side-effect of the zeroing-out. This is probably why the
    enum explicitly starts on 1. This is fixed by adding the
    enum value INVALID_TABLE.
    
    Change-Id: Ic9d1f58dca36deba6a9be33fd5e2c2e8b3dcd49d

[33mcommit 0b20dc85a796960fc0af94cd1e4394fdfd9be091[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Thu Nov 30 18:19:31 2017 +0100

    Bug#21616914: MAIN.JSON_CONVERSIONS TIMES OUT IN VALGRIND
    
    Strip down the [1;31mtime[m it takes to run the json_conversions test by
    making the following changes:
    
    1. Remove some redundant verification of the contents in the test
    tables. The contents of a big test table were dumped, and multiple
    regular expressions were used on the output to filter out
    non-deterministic data. The input data were validated in different and
    cheaper ways later in the test, so this partly redundant and very [1;31mtime[m
    consuming step was removed.
    
    2. A table that was populated by doing multiple INSERT INTO ... SELECT
    DISTINCT FROM statement that used subqueries to avoid inserting
    duplicates into the table, is now instead populated using a single
    INSERT INTO ... SELECT statement where the SELECT is a big UNION. This
    single statement is much faster than the original ones.
    
    3. Add an index on a column that is used for equality predicates in
    many of the queries in the test.
    
    4. Testing of the JSON comparator with the != operator is removed. The
    non-standard != operator is indistinguishable from the standard <>
    operator after the query has gone through the tokenizer, so it doesn't
    contribute to the code coverage.
    
    5. Some parts of the test, which use multiple SELECT statements to
    work through a table, are rewritten to use a single SELECT statement
    which goes through the entire table in a single pass.
    
    6. Remove some duplicated SELECT statements that tested conversions
    from the YEAR data type.
    
    Change-Id: I55bfbea5fad26cf0feba717ef32b43c4e88c1457

[33mcommit 13cf322f2e2d6fef77cb2bc8ff0ff25e5268a87a[m
Author: Maria Couceiro <maria.couceiro@oracle.com>
Date:   Mon Jan 15 16:36:12 2018 +0000

    BUG#20454797 WAIT_FOR_SLAVE_PARAM.INC IS NOT CHECKING FOR ERROR WHILE WAITING THE PARAMETER
    
    Problem an analysis:
    The mtr include "wait_for_slave_param.inc" was not detecting errors.
    Instead, it would always trigger the [1;31mtime[mout waiting for the parameter
    if an unexpected error stopped one of the slave threads. This
    misbehavior of the include generated [1;31mtime[mout errors when other errors
    were the real cause of the issue in some test cases.
    
    Fix:
    Corrected the code in "wait_for_slave_param.inc" to detect the errors.
    Also, added a condition that checks for expected errors, so they can be
    safely ignored.
    Corrected the test cases that were misusing the mtr include
    "stop_slave.inc" to stop slaves when errors were present in either the
    connection or the applier thread. These tests now ignore the expected
    error.

[33mcommit 119db39f43e5a45502134a0eb6e86687124ed734[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Mon Jan 29 09:53:05 2018 +0100

    BUG#27041350: ASSERTION `THD->IS_SYSTEM_THREAD() || THD->KILLED ||
    THD->IS_ERROR()' FAILED.
    
    Problem: Exhausting the stack could some[1;31mtime[ms trigger an assert,
    rather than returning the expected error message. Root cause was that
    certain internal error handlers incorrectly suppressed the stack
    overrun error. This in turn meant that the assert fired incorrectly.
    
    Solution: Fix the internal error handler so that stack overrun errors
    are propagated correctly.
    
    Change-Id: I5ce8c4ba9dbad5fcbc52943e2a31ffcd764eedaa

[33mcommit 81ac35c8e87557c4667b7527f22384c348612411[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Sun Jan 28 21:52:01 2018 +0800

    Bug #26003816   RPL.RPL_IPV4_AS_IPV6 AND RPL.RPL_IP_MIX FAILS SPORADICALLY ON PB2
    
    Problem
    =======
    When the mysql_socket_bind(...) call on the INET socket fails, mysqld
    reports an error like that:
    [ERROR] Can't start server: Bind on TCP/IP port: No such file or directory
    [ERROR] Do you already have another mysqld server running on port: 3310 ?
    [ERROR] Aborting
    
    Analyse
    =======
    Some[1;31mtime[ms the port is not released fast enough when stopping and
    restarting the server. This happens quite often with the test
    suite on busy systems. Retry to bind the address at some intervals
    during the port [1;31mtime[mout. The value of port [1;31mtime[mout is 0 in the
    test. So the above error happens if the first try of binding the
    address fails.
    
    Fix
    ===
    To fix the problem, set --port-open-[1;31mtime[mout to 10000 to allow
    enough retries to bind the address.

[33mcommit b5f878d8466dffceb43adc762fdc8b722f1a25fc[m
Author: Tiago Jorge <tiago.jorge@oracle.com>
Date:   Thu Jan 25 14:08:06 2018 +0000

    BUG#27436052    MEMORY LEAKS IN GCS UNIT TESTS
    
    Problem
    ---------------------------------
    The following unit tests are failing with memory leaks in ASAN:
    gcs_parameters
    gcs_whitelist
    gcs_xcom_interface_unit
    
    Compile with -DWITH_ASAN=1, run the tests directly from the run[1;31mtime[m output
    directory or just run 'ctest -R "gcs*"'
    
    Analysis
    ---------------------------------
    This is caused by successive calls to Whitelist configure() method, now that the
    Whitelist has objects instead of std::vector. It was clearing the list instead
    of doing a list cleanup.
    
    This is not observable in Group Replication since the object is always created
    and destroyed in subsequent calls.
    
    Fix
    ---------------------------------
    Add a clear() method to the whitelist and call it in configure(). Refactor the
    destructor to also use the new method.

[33mcommit d978d9abe390e85c2cd685beb29b966f742f5c67[m
Author: Jens Even Berg Blomsoy <jens.even.blomsoy@oracle.com>
Date:   Fri Jan 26 10:40:25 2018 +0100

    Bug #27340709 ASSERT IN MAIN.MYISAM STARTING IN YEAR 2018
    
       Initial problem:
       myisam.main was failing on Windows in check_date[1;31mtime[m_range.
       The fail started Jan 1, 2018. At this date, converting a ulonglong to
       a long caused a negative number in: Time_zone_system::gmt_sec_to_TIME.
       This fail is shown only on Windows as the size of a long is 4 bytes,
       while the size of a long on Linux(IA-64) is 8.
    
       Solution:
       Add a convertion from longlong [1;31mtime[m to MYSQL_TIME format in:
       Item_func_internal_check_[1;31mtime[m::get_date(). Similar to that of:
       Item_func_internal_update_[1;31mtime[m::get_date().
    
       The main changes to the code is as follows:
    
       item_[1;31mtime[mfunc.cc:
       Added a convertion from longlong [1;31mtime[m to MYSQL_TIME in:
       Item_func_internal_check_[1;31mtime[m::get_date

[33mcommit 4c48c2bb9c4ced32f8f3f17425eaae14708e7a18[m
Author: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>
Date:   Fri Jan 26 09:52:00 2018 +0100

    BUG#27436471: MEMORY LEAKS IN XPLUGIN UNIT TESTS
    
    Free memory resources acquired in X plugin [1;31mtime[mrs unit tests.
    
    RB: 18558
    Reviewed by: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
    Reviewed by: Lukasz Kotula <lukasz.kotula@oracle.com>

[33mcommit 68000078165c55faea5b1f5048450ccad2c36a99[m
Author: Maria Couceiro <maria.couceiro@oracle.com>
Date:   Thu Jan 11 17:00:56 2018 +0000

    BUG#27370035 RPL_DELAYED_SLAVE SHOULD USE REPLICATION TIMESTAMPS TO IMPROVE STABILITY
    
    Problem and analysis:
    The test rpl_delayed_slave is currently disabled due to its sporadic
    failures. It relies on a set of sleeps followed by thread state checks
    to verify whether events were correctly delayed before being applied in
    the slave. This approach is prone to produce unstable results as slower
    machines may not have reached the expected state after the [1;31mtime[mout,
    causing the test to fail.
    
    Fix:
    Replace all sleep followed by thread state checks with asserts relying
    on the immediate_commit_[1;31mtime[mstamp reported in the binary log, which can
    be found in check_slave_delay.inc file.
    Move the Seconds_behind_master checks to the corresponding test case and
    reformulate the assertions so that they are more deterministic.
    Remove all [1;31mtime[m conditions that are prone to fail on slower machines.
    Most of these conditions are already tested in other sql delay tests.

[33mcommit 85425463fd00d8f2cd7e0c91d6d01c7f51f63d33[m
Author: Rahul Sisondia <rahul.sisondia@oracle.com>
Date:   Wed Jan 24 05:34:21 2018 +0100

    Bug#27225806 VALGRIND REPORTS INVALID READ AT CREATE_AUTHID_FROM IN
    SQL_AUTHORIZATION.CC
    
    Description
    -----------
    Valgrind issue was discovered while adding the test for BUG#26881798.The actual
    problem is that in role caches maintain the shallow copy of the acl users.
    These copies used to get invalidated in case of an error scenario. In case of
    error situation acl_reload() is called which  reverts the acl cache to previous
    valid state that means that if the shallow copies in the role caches gets
    invalid unless the role cache is refreshed too.
    
    Fix:
    ------
    1. Now acl_reload() method also reloads the role cache along with acl cache.
    if either of the latter two fails then acl caches as well as role caches are
    reverted to the previous sane state.
    
    2. populate_roles_caches() which reloads the role caches, checks in case of
    error condition if either of the role cache g_default_roles or
    g_aithid_to_vertex is valid then it returns failure.
    
    3. Removed the redundant missing key and corrupt tables checks from
    thepopulate_roles_caches() as they are now already part of tabless sanity check
    method check_acl_tables_intact().
    
    4. Ensure that check_acl_tables_intact() and check_acl_tables() are called from
    the open_grant_tables() which opens the ACL tables and reports an error in case
    of any of the acl table is found not intact.
    
    5. Above change are ensure that acl_init() method continue to work the way it
    was earlier because it possible someone might start 8.0 from 5.7 database.
    
    6. Removed the following redundant methods. Since the role caches are loaded
    through the acl_reload() method anyways.
    
      close_all_role_tables()
      roles_init_from_tables()
      roles_init(THD *thd)
    
    7. Removed redundance table_intact.check() from following methods  since it is
    already taken care of through open_grant_tables() method.
    
      handle_grant_data()
      change_password()
      mysql_alter_user()
    
    8. Method roles_init() used to add a warning message with error code
    'ER_AUTHCACHE_ROLE_TABLES_DODGY'. This code was introduced through Bug#24447771.
    It is found that this error code is redundant because a new generic error code
    'ER_MISSING_ACL_SYSTEM_TABLE' is introduced through
    WL#6595(Password rotation policy) . Therefore former error code is marked
    as obsolete.
    
    9. Removed the redundant inialization of roles and mandatory caches from the
    init_acl_cache()
    
    10. Renamed the method check_acl_tables() as check_engine_type_for_acl_table()
    
    11. Removed the redundant inialization of roles and mandatory caches from the
    init_acl_cache()
    
    Unrelated changes - Replaced the value 1 with boolean flag true in the
    clean_up() method, removed the redundant call of shutdown_acl_cache() method in
    the same method.
    
    Testing :
    -------
    
    - mysql-test/t/roles-upgrade.test
      Removed the search patter for obsolete error
    
    - mysql-test/suite/i_main/t/grant.test
      Scenario reported in the bug was already added in the grant.test file above,
      it just required us to add grant statement though.
    
    - mysql-test/t/grant_debug.test
      Added test scenario to verify that role caches are reverted to sane state in
      case of test failures.
    
    ----Test result in local testing----
    
    Unit tests: 100% tests passed, 0 tests failed out of 46
    Report from unit tests in /mysql-trunk/build_dir/mysql-test/var/ctest.log
    The servers were restarted 1456 [1;31mtime[ms
    Spent 24683.342 of 1383 seconds executing testcases
    Completed: All 5800 tests were successful.
    1651 tests were skipped, 143 by the test itself.
    
    ----Test result in PB2 testing----
    
    Commit#1e05d139ddfe44094326c736dcef72069bf24102
    Timestamp - 2018-01-17 00:46:00 
    Branch - mysql-trunk-itch
    
    ----verified, no doxygen error -----
    
    ---- Verified ASAN and valgrind run ----
    
    Branch - mysql-trunk-asan
    Commit#8852225dbf1238a9f552c523b595ac269ca7c72e
    Timestamp - 2018-01-24 04:33:25
    Status - Completed, no new failure reported.
    
    Branch - mysql-8.0-valgrind
    Commit#dd86b4c02b910818a540fc58df916292b5fda7c1
    Timestamp - 2018-01-23 18:04:08
    Status - In progress, however no new failure found in the local run.
    
    Review: RB#18454Bug#27225806 VALGRIND REPORTS INVALID READ AT CREATE_AUTHID_FROM
    IN
    SQL_AUTHORIZATION.CC
    
    Description
    -----------
    Valgrind issue was discovered while adding the test for BUG#26881798.The actual
    problem is that in role caches maintain the shallow copy of the acl users.
    These copies used to get invalidated in case of an error scenario. In case of
    error situation acl_reload() is called which  reverts the acl cache to previous
    valid state that means that if the shallow copies in the role caches gets
    invalid unless the role cache is refreshed too.
    
    Fix:
    ------
    1. Now acl_reload() method also reloads the role cache along with acl cache.
    if either of the latter two fails then acl caches as well as role caches are
    reverted to the previous sane state.
    
    2. populate_roles_caches() which reloads the role caches, checks in case of
    error condition if either of the role cache g_default_roles or
    g_aithid_to_vertex is valid then it returns failure.
    
    3. Removed the redundant missing key and corrupt tables checks from
    thepopulate_roles_caches() as they are now already part of tabless sanity check
    method check_acl_tables_intact().
    
    4. Ensure that check_acl_tables_intact() and check_acl_tables() are called from
    the open_grant_tables() which opens the ACL tables and reports an error in case
    of any of the acl table is found not intact.
    
    5. Above change are ensure that acl_init() method continue to work the way it
    was earlier because it possible someone might start 8.0 from 5.7 database.
    
    6. Removed the following redundant methods. Since the role caches are loaded
    through the acl_reload() method anyways.
    
      close_all_role_tables()
      roles_init_from_tables()
      roles_init(THD *thd)
    
    7. Removed redundance table_intact.check() from following methods  since it is
    already taken care of through open_grant_tables() method.
    
      handle_grant_data()
      change_password()
      mysql_alter_user()
    
    8. Method roles_init() used to add a warning message with error code
    'ER_AUTHCACHE_ROLE_TABLES_DODGY'. This code was introduced through Bug#24447771.
    It is found that this error code is redundant because a new generic error code
    'ER_MISSING_ACL_SYSTEM_TABLE' is introduced through
    WL#6595(Password rotation policy) . Therefore former error code is marked
    as obsolete.
    
    9. Removed the redundant inialization of roles and mandatory caches from the
    init_acl_cache()
    
    10. Renamed the method check_acl_tables() as check_engine_type_for_acl_table()
    
    11. Removed the redundant inialization of roles and mandatory caches from the
    init_acl_cache()
    
    Unrelated changes - Replaced the value 1 with boolean flag true in the
    clean_up() method, removed the redundant call of shutdown_acl_cache() method in
    the same method.
    
    Testing :
    -------
    
    - mysql-test/t/roles-upgrade.test
      Removed the search patter for obsolete error
    
    - mysql-test/suite/i_main/t/grant.test
      Scenario reported in the bug was already added in the grant.test file above,
      it just required us to add grant statement though.
    
    - mysql-test/t/grant_debug.test
      Added test scenario to verify that role caches are reverted to sane state in
      case of test failures.
    
    ----Test result in local testing----
    
    Unit tests: 100% tests passed, 0 tests failed out of 46
    Report from unit tests in /mysql-trunk/build_dir/mysql-test/var/ctest.log
    The servers were restarted 1456 [1;31mtime[ms
    Spent 24683.342 of 1383 seconds executing testcases
    Completed: All 5800 tests were successful.
    1651 tests were skipped, 143 by the test itself.
    
    ----Test result in PB2 testing----
    
    Commit#1e05d139ddfe44094326c736dcef72069bf24102
    Timestamp - 2018-01-17 00:46:00 
    Branch - mysql-trunk-itch
    
    ----verified, no doxygen error -----
    
    ---- Verified ASAN and valgrind run ----
    
    Branch - mysql-trunk-asan
    Commit#8852225dbf1238a9f552c523b595ac269ca7c72e
    Timestamp - 2018-01-24 04:33:25
    Status - Completed, no new failure reported.
    
    Branch - mysql-8.0-valgrind
    Commit#dd86b4c02b910818a540fc58df916292b5fda7c1
    Timestamp - 2018-01-23 18:04:08
    Status - In progress, however no new failure found in the local run.
    
    Review: RB#18454

[33mcommit 19ca83a71f2d6e7a29feeb6a9082fd50889db788[m
Author: Havard Dybvik <havard.dybvik@oracle.com>
Date:   Thu Jan 11 17:41:31 2018 +0100

    Bug#27312703 ASAN: HEAP-USE-AFTER-FREE: GREATEST/LEAST FUNCTIONS
    
    The underlying buffer of a String passed to val_str() was reused in the
    returned String, although the two Strings themselves were different
    objects. Hence, despite being two seemingly independent Strings, freeing
    the allocated space in one of them invalidated the buffer of the other.
    Because the String comparison function accesses the underlying buffers
    of both Strings, both buffers need to be non-overlapping and valid at
    [1;31mtime[m of comparison. Failing to meet this requirement caused
    HEAP-USE-AFTER-FREE.
    
    To ensure use of two distinct String objects with non-overlapping and
    valid buffers, use a boolean variable instead of pointer comparisons to keep
    track of which String object to pass to val_str().
    
    Also changed:
     - Follow the design of other Item classes and reintroduce a String
     member to the Item class for LEAST/GREATEST to avoid copying from a
     temporary buffer after comparison.
     - To improve readability in comparison functions for LEAST/GREATEST,
     use a boolean member variable instead of a comparison sign to determine
     whether arguments should be compared as LEAST or GREATEST.
     - Rewrite signed/unsigned integer comparison in LEAST/GREATEST.
    
    Change-Id: Ica42f259fc2176e9cd00513304b636f9bd7dd6dd

[33mcommit 27a99ce7c435e5c9c893005a35f951b3ecb8f128[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Fri Jan 12 13:48:21 2018 +0100

    Bug#27114719 FUNCTIONAL DEPENDENCY CHECK FAILS ON FIRST CALL, SUCCEEDS ON NEXT
    
    To make FDs be recognized between a generated column and its
    source columns (Bug 21807579) I introduced a walk() on the gcol.
    For example, if 'c' is a gcol equal to a+2, and we have to validate:
     SELECT c FROM t GROUP BY a;
    then we walk the expression of 'c' (a+2), process 'a' (part of GROUP
    BY so ok) and '2' (constant so ok).
    During this, when we process 'a', to find that it's in GROUP BY we
    use is_in_fd(), which itself uses Group_check::local_column(). That last
    function checks if the searched column 'a' is part of the query block
    we're validating now (if it's not, it may be an outer ref, hence constant).
    This test of query block is done in Item_ident::local_column() with:
        else if (context->select_lex == sl)
          return Bool3::true3();                           // qualifying query is 'sl'
    Alas, columns which are underlying of a gcol are not "plugged" into
    this query block; indeed:
    - if the table is opened for the first [1;31mtime[m, gcol's definition
    is parsed with a fresh, dedicated LEX (see unpack_gcol_info());
    in fix_fields_gcol_func() each underlying Item_field gets the context
    of that fresh LEX (fix_fields_gcol_func() calls change_context_processor()),
    which isn't any context of the query.
    - if the statement re-runs, TABLE::refix_gc_items() calls
    fix_fields_gcol_func() again, but with the query's current LEX,
    so Item_field gets the top query's context, which is arbitrary
    (and some[1;31mtime[ms wrong - imagine the gcol is in a subquery).
    
    Thus, their 'context' is unusable and the equality test above, fails.
    
    We could try to set 'context' to the context of the gcol, but it's
    not possible: if a gcol is referenced in the top query and in a subquery,
    like in:
     select (select t1.a), t1.a from t1;
    then there is a single TABLE, a single 'field' and thus a single
    field->gcol_info: underlying Items are shared between both refs to
    t1.a, so there is no right context for underlying items.
    
    Fix: let fix_fields_gcol_func() set their context to nullptr.
    Let Item_ident::local_column() treat this as "local".

[33mcommit 1bd8998f32c1a62d4e1a6066dedc428f6bb6ee87[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Jan 11 10:52:03 2018 +0100

    Bug#27184567 QUERYING REPLICATION PERFORMANCE SCHEMA TABLES VIA INDEXES
    GIVES WRONG RESULTS
    
    Before this fix,
    queries on performance_schema.replication_* tables
    some[1;31mtime[ms returned incorrect results (missing rows),
    in particular when the query execution path used an index.
    
    For example in particular, where clauses involving the
    CHANNEL_NAME columns failed to return rows matching
      WHERE CHANNEL_NAME = ''
    which is the default channel name.
    
    With this fix, the implementation of every index
    on every performance_schema.replication_* table
    has been investigated, and the following bugs
    were identified and corrected.
    
    1) Column CHANNEL_NAME.
    
    Background:
    
    In the performance schema in general,
    a record value is rarely represented by both
    - a null bit
    - a value
    
    Instead, a record value is typically represented by
    a single attribute (for example m_thread_id),
    with the special meaning that m_thread_id == 0
    represents a NULL column, not a 0 column.
    
    Bug:
    
    WHERE CHANNEL_NAME = '' does not return matching rows.
    
    Root cause:
    
    The default channel name is represented by a string,
    with a length of 0.
    
    When using an index, method
      PFS_key_name::match()
    is called to decide if a record matches the index condition.
    
    When processing a CHANNEL_NAME = '' record,
    PFS_key_name::match() considers that the record is a NULL
    column instead, so that the where clause is evaluated as
      WHERE NULL = ''
    which is false, discarding the record.
    
    Fix:
    
    Implement a new method
      PFS_key_name::match_not_null()
    which considers a record of length 0 to be an empty string,
    and use this in every index implementation involving
    a CHANNEL_NAME column.
    
    2) Column THREAD_ID
    
    Bug:
    
    Conditions
      WHERE THREAD_ID IS NULL
      WHERE THREAD_ID IS NOT NULL
    are not implemented properly,
    resulting in
    - missing matching rows
    - extra non matching rows
    
    Root cause:
    
    Some index implementations,
    for example:
      PFS_index_rpl_applier_status_by_coord_by_thread::match()
    evaluate the record THREAD_ID value,
    and discard NULL THREAD_ID as non matching,
    without even looking at the index key condition.
    
    The code causing this is:
    
        if (row.thread_id_is_null)
        {
          return false;
        }
    
    This is incorrect, because when the key search is actually
      WHERE THREAD_ID IS NULL
    records with a NULL should be matching, not discarded.
    
    Fix:
    
    Do not attempt to evaluate conditions in table index ::match() methods,
    and always delegate the index evaluation to the underlying
    key, as in:
    
        if (!m_key.match(row.thread_id))
        {
          return false;
        }
    
    This allows the PFS_key::match() logic to determine matches,
    which turns out to use a complex logic,
    to account for NULL in columns and or keys.
    
    3) Table replication_applier_status_by_worker, primary key.
    
    Bug:
    
    The primary key for this table is
      PRIMARY KEY (CHANNEL_NAME, WORKER_ID)
    aka, it has two parts.
    
    The index on the second part, WORKER_ID, is not working.
    
    Root cause:
    
    PFS_index_rpl_applier_status_by_worker_by_channel::match()
    only implements filtering for the CHANNEL_NAME part,
    as in:
    
      if (m_fields >= 1)
      {
        ... read the channel name value ...
        ... match the channel name key part ...
      }
    
    The second part
    
      if (m_fields >= 2)
      {
        ... read the worker id value ...
        ... match the worker id key part ...
      }
    
    is simply missing in the code.
    
    Fix:
    
    Implemented the second key part (WORKER_ID) in the index.
    
    3) Table replication_applier_status_by_worker, index iteration
    
    Background:
    
    This table logic is more complicated than other replications tables,
    because the table exposes at the same [1;31mtime[m:
    - data for Single Thread Slave, reporting 1 thread per channel
    - data for Multi Thread Slave, reporting many threads per channel,
      with each worker thread.
    
    Bug:
    
    table_replication_applier_status_by_worker::index_next()
    is not iterating properly for this table.
    
    Root cause:
    
    The ::index_next method implements two separate scans:
    - a scan using m_applier_pos / m_applier_next_pos
    - a scan using m_pos / m_next_pos
    
    This is flawed, as the storage engine interface in general,
    and the interactions with the optimizer in particular,
    expects only one concept of position per table.
    
    The position used was only m_pos,
    per the table constructor:
    
    table_replication_applier_status_by_worker::
      table_replication_applier_status_by_worker()
      : PFS_engine_table(&m_share, &m_pos), <-- here
        m_pos(),
        m_next_pos(),
        m_applier_pos(0),
        m_applier_next_pos(0)
    {
    }
    
    The m_applier_pos attribute was not part of the table "position".
    
    Beside, the record length ("ref length") was wrong,
    using sizeof(PFS_simple_index) while m_pos is a double index,
    causing even more bugs when iterating.
    
    Fix:
    
    Define a single position concept for this table,
    pos_replication_applier_status_by_worker.
    
    Rewrite ::index_next to only use one position, not two.
    
    Define a pos_t typedef, and use sizeof(pos_t) for "ref length".
    
    4) Table replication_connection_status, THREAD_ID index.
    
    Bug:
    
    The index by THREAD_ID is not working properly.
    For example
      WHERE THREAD_ID = <the THREAD_ID of a record>
    fails to match the record.
    
    Root cause:
    
    On one hand, the logic to build the record,
      table_replication_connection_status::make_row()
    uses:
      mi->info_thd
    to find the THREAD_ID value.
    
    On the other hand, the logic to evaluate the index,
      PFS_index_rpl_connection_status_by_thread::match()
    uses:
      mi->rli->info_thd
    to find the THREAD_ID value.
    
    This points to a different thread, and returns a
    different THREAD_ID, so that an index on THREAD_ID
    does not match its own record.
    
    Fix:
    
    PFS_index_rpl_connection_status_by_thread::match()
    uses the same logic as
    table_replication_connection_status::make_row(),
    pointing to the same thread.
    
    5) Misc code cleanup
    
    a)
    
    Systematically define a pos_t typedef per table,
    and use sizeof(pos_t) for ref length,
    to have more maintainable code and avoid
    incorrect lengths.
    
    b)
    
    Remove incorrect uses of MY_ATTRIBUTE((unused))
    
    6) Test suite
    
    Implemented missing tests,
    to enforce that tables return the same data
    with and without an index:
      performance_schema.idx_compare_replication_*.test
    
    Systematically tested the following conditions:
    - key_part IS NULL
    - key_part IS NOT NULL
    - key_part = '' (for CHANNEL_NAME)
    - key_part != '' (for CHANNEL_NAME)
    - key_part = <expected existing value>, for example for THREAD_ID.

[33mcommit 71b0c585173257ff7a27f0cebe562f69ada2720a[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Fri Jan 12 11:14:55 2018 +0800

    Bug#26848711 - PERFORMANCE REGRESSION IN "CREATE TABLE" SPEED AND SCALABILITY IN 8.0.3
    
    The performance regression is mainly due to that DDL logs are logged and
    flushed after every transaction commit under dict mutex and lock protection.
    So it showed that dict_operation_lock is very hot.
    
    Since it has to flush redo logs after every transaction commits, so that
    it's true crash-safe DDL, this penalty can't be avoided. However,
    after new DD, dict_operation_lock along with dict_sys mutex are not
    necessary to be held for such a long [1;31mtime[m during DDL, so we should
    try to deprecate dict_operation_lock and ask for dict_sys mutex
    as less as possible.
    
    Current patch mainly fix this issue in above way for CREATE TABLE and
    the modified code will of course affect ALTER TABLE a bit too.
    Basically, dict_operation_lock is not necessary for CREATE TABLE any more.
    And dict_sys mutex would be acquired only when dict_sys information
    is modified, such as adding new dict_table_t to cache, increase
    dict_sys->size etc. The dict_sys mutex should not be held during
    creating physical data files, etc. Once it's proper [1;31mtime[m to get rid of
    these dict lock and mutex for all DDLs, it could be possible to clean up
    dict_sys mutex further.
    
    At the mean[1;31mtime[m, since dict_sys mutex is not held during the whole
    process of CREATE TABLE, once the dict_table_t is added to global cache,
    it has to be kept in cache without eviction before writing metadata of it
    to dd::Table. So this requires some changes for
    innobase_basic_ddl::create_impl().
    
    Furthermore, in this patch, dict_table_close() doesn't have to acquire
    dict_sys mutex any more, instead it has to acquire a per-table mutex
    called dict_table_t::mutex, to prevent the race from ha_innobase::open().
    
    RB: 17608
    Reviewed by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit cf92312dd9541cb991f41a07f4925f4397f760a1[m
Author: Pedro Figueiredo <pedro.figueiredo@oracle.com>
Date:   Wed Jan 10 18:11:13 2018 +0000

    Bug#27041402 ASSERTION `NEW_VALUE >= 0' FAILED.
    
    Overall description
    -------------------
    Two issues are being address by this fix, one reported and one encountered
    while debugging and testing:
    
    B1. Starting with GTID_MODE set to OFF and ENSURE_GTID_CONSISTENCY set to
        OFF, start a XA transaction, create a temporary table, end the XA
        transaction and prepare the XA transaction. The server will exit with
        an assertion triggered error.
    B2. The testing on this patch has exposed a problem with empty transactions
        being wrongfully written to the binlog, when GTID is manually set, both
        inconsistent with the normal empty transaction pattern and with erroneous
        and inconsistent transaction IDs.
    
    B1.a) Description
    -----------------
    Starting with GTID_MODE set to OFF and ENSURE_GTID_CONSISTENCY set to
    OFF, start a XA transaction, create a temporary table, end the XA
    transaction and prepare the XA transaction. The server will exit with
    an assertion triggered error.
    
    B1.b) How To Repeat
    -------------------
    CREATE DATABASE test;
    USE test;
    XA START 'test2';
    CREATE TEMPORARY TABLE t1(a INT);
    XA END 'test2';
    XA PREPARE 'test2';
    SET @@SESSION.GTID_NEXT = 'ANONYMOUS'; # Then attempt to shutdown server
                                             using 'mysqladmin shutdown'
                                             or just leave the shell.
                                             Then check log
    
    B1.c) Analysis
    --------------
    - This only occurs when 'gtid_consistency_mode' is 'OFF' and  'gtid_mode'
      is 'GTID_MODE_OFF' or 'GITD_MODE_OFF_PERMISSIVE'.
    - According to comment in 'THD::is_ddl_gtid_compatible()':
    
           [CREATE|DROP] TEMPORARY TABLE is unsafe to execute
           inside a transaction because the table will stay and the
           transaction will be written to the slave's binary log with the
           GTID even if the transaction is rolled back.
           This includes the execution inside Functions and Triggers.
    
    - Thence, if statement is 'CREATE TEMPORARY TABLE' or
      'DROP TEMPORARY TABLE', 'handle_gtid_consistency_violation(...)'
      is invoked, setting  'THD::has_gtid_consistency_violation' to true
      and incrementing 'Gtid_state::atomic_automatic_gtid_violation_count'.
    - After the statement is actually processed, in 'mysql_execute_command(...)',
      the 'binlog_gtid_end_transaction(THD*)' method is invoked.
    - 'XA PREPARE' is not included int the test conditions found in
      'binlog_gtid_end_transaction()' and probably should be.
    
    B1.d) Fix
    ---------
    - Change the test condition inside 'binlog_gtid_end_transaction()'
      to include 'XA PREPRARE'.
    - Either:
      a) Change the test condition inside 'binlog_gtid_end_transaction()'
         to include 'XA COMMIT ONE PHASE'.
      b) Remove test for 'thd->slave_thread' value from condition and allow
         'XA_COMMIT' and 'XA_ROLLBACK' to be always evaluated.
    - The fix implemented was the second one, since testing for
      'thd->slave_thread' in the applier flow may interfere with mysqlbinlog
      execution.
    
    B2.a) Description
    -----------------
    XA empty transactions are being wrongfully written to the binlog, when GTID
    is manually set, both inconsistent with the normal empty transaction pattern
    and with erroneous and inconsistent transaction IDs.
    
    B2.b) How to repeat
    -------------------
     --source include/master-slave.inc
     --connection master
     SET GTID_NEXT= 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:1';
     XA START 'trx';
     XA END 'trx';
     XA COMMIT 'trx' ONE PHASE;
     --sync_slave_with_master
     --source include/rpl_end.inc
    
    B2.c) Analysis
    --------------
    - When the XA transation is empty, the sequence of statements is wrongfully
      written to the binlog, looking like the following:
    
          /*!80001 SET @@session.original_commit_[1;31mtime[mstamp=1513000909470702*//*!*/;
          SET @@SESSION.GTID_NEXT= 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:2'/*!*/;
          # at 406
          #171211 14:01:49 server id 2  end_log_pos 478 CRC32 0x4084ddcc  Query   thread_id=6     exec_[1;31mtime[m=0     error_code=0
          SET TIMESTAMP=1513000909/*!*/;
          BEGIN
          /*!*/;
          # at 478
          #171211 14:01:49 server id 2  end_log_pos 586 CRC32 0x8679205a  Query   thread_id=6     exec_[1;31mtime[m=0     error_code=0
          SET TIMESTAMP=1513000909/*!*/;
          XA END X'747278',X'',18446744073709551615
          /*!*/;
          # at 586
          #171211 14:01:49 server id 2  end_log_pos 625 CRC32 0x9cc5a4d8  XA PREPARE X'747278',X'',4294967295
          XA COMMIT X'747278',X'',4294967295 ONE PHASE
          /*!*/;
          # at 625
    
    - The XA transaction ID is not the same for 'XA END' and 'XA COMMIT'
      statements, generating errors when processing and applying binlog
      events. The 'formatID' attribute is being initialized to '-1' in the
      class constructor. The '18446744073709551615' and '4294967295' are just
      'unsigned long' and 'unsigned int' representations for '-1'. This means
      that the 'formatID' attribute may be set when processing 'XA START'
      or some other statement in the block. Since this block is empty, the
      attribute may have not been set.
    - Usually, empty transactions are represented by 'BEGIN; COMMIT;' and
      this format could be applied here.
    - The sequence of binlog events when not setting the GITD_NEXT variable and
      executing the exact same statements don't include any related statement,
      not even 'BEGIN; COMMIT;'
    
    B2.d) Fix
    ---------
    - Change 'MYSQL_BIN_LOG::commit()' behaviour: test for a 'XA COMMIT'
      transation that has already been commited (empty transaction) and, if
      so, write a Query_log_event with a 'COMMIT' query, instead of
      XA_prepare_log_event.
    - 'MYSQL_BIN_LOG::commit()' had different code blocks handling how a
      'XA COMMIT' statement would finalize the transaction. Merged both
      blocks.

[33mcommit bf5fbb63cd19ca4de7cfdc6bdcd6e5cb5489af4d[m
Author: Harin Vadodaria <harin.vadodaria@oracle.com>
Date:   Wed Jan 10 13:23:55 2018 +0100

    Bug#26475282: ALTER FROM SUBSEQUENT TRANSACTION HITS ER_CANNOT_LOCK_USER_MANAGEMENT_CACHES
    
    Description: MDL lock is used to protect in-memory ACL
                 caches. When an ACL DDL is in progress,
                 ACL tables and ACL caches are locked in
                 exclusive mode to prevent concurrent updates
                 and access. The sequence of locking/unlocking
                 is following
    
                 Open and Lock ACL tables
                   -> Lock ACL_CACHE MDL in EXCLUSIVE mode
                     -> Unlock locked ACL tables
                       -> Unlock ACL_CACHE MDL
    
                 In normal cases, this works. Even when two
                 connections start ACL DDLs concurrently.
                 However, if an ACL statement results into
                 error, we rollback all table changes and
                 reinitialize ACL caches by reading
                 information from underlying ACL tables.
                 This reinitialization code is shared with
                 that of ACL cache initialization. This means
                 that we would have following sequence in
                 case of error encountered in ACL DDL:
    
                 Open and Lock ACL tables
                   -> Lock ACL_CACHE MDL
                     -> Unlock locked ACL tables
                       -> Open and lock ACL tables
                         -> (Lock ACL_CACHE MDL - NoOp)
                           -> Unlock locked ACL tables
                             -> Unlock ACL_CACHE MDL
    
                 Note that Unlock/Lock again is required
                 because table changes need to be rolled back
                 and table closed so that next [1;31mtime[m it is
                 opened, it is in the same state it was before
                 ACL DDL execution began.
    
                 Since this sequence involves unlocking and
                 relocking ACL tables while holding ACL_CACHE
                 MDL, another transaction can potentially come
                 in when table locks are relased above, execute
                 another ACL DDL, Open and lock ACL tables and
                 wait for ACL_CACHE MDL - which is held by first
                 transaction that is being rolled back. Since
                 we have a deadlock, MDL's deadlock detection
                 kicks in and denies ACL_CACHE MDL to new
                 transaction which then goes on and fails with
                 lock denied error. First transaction then goes
                 on and completes rollback and reverts ACL
                 caches to original state.
    
    Solution: In order to avoid potential deadlock followed
              by lock denied error, lock order is changed
              to following:
    
              Lock ACL_CACHE MDL in EXCLUSIVE mode
                -> Open and Lock ACL tables
                  -> Unlock locked ACL tables
                    -> Unlock ACL_CACHE_MDL.
    
              This way, in case of an error during ACL DDL,
              lock sequence will be
    
              Lock ACL_CACHE MDL
                -> Open and Lock ACL tables
                  -> Rollback changes made in tables
                    -> Unlock locked ACL tables
                      -> (Lock ACL_CACHE MDL - NoOp)
                        -> Open and lock ACL tables
                          -> Unlock locked ACL tables
                            -> Unlock ACL_CACHE MDL
    
              If another transaction initiates ACL DDL when
              reinitialization is in progress, it will
              instead wait for previous one to release
              ACL_CACHE MDL and then proceed.
    
    Reviewed-By: Dyre Tjeldvoll <dyre.tjeldvoll@oracle.com>
    Reviewed-By: Kristofer Älvring <kristofer.pettersson@oracle.com>

[33mcommit 468b36d6a5d01324226728a8a82771cf5df34316[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Wed Jan 10 16:44:23 2018 +0800

    Bug #24702091   MTR'S CHECK OF RPL_NOGTID.RPL_UPGRADE_SLAVE_MASTER_INFO FAILS
    
    Problem
    =======
    MTR's internal check of some test scripts failed as below.
     block_encryption_mode  aes-128-ecb
     bulk_insert_buffer_size        8388608
    -character_sets_dir     /export/home2/pb2/test/sb_3-20434341-1473926827.77/mysql-8
    .0.1-dmr-linux-x86_64-devbld/share/charsets/
    +character_sets_dir     /export/home2/pb2/test/sb_3-20434341-1473926827.77/mysql-8
    .0.1-dmr-linux-x86_64-devbld/share/cha
     character_set_client   latin1
     character_set_connection       latin1
    
    Analysis
    ========
    The mysql_set_character_set_with_default_collation and
    mysql_set_character_set (both defined in client.cc) will temporarily
    change the global variable charsets_dir. This makes them
    non-thread-safe.
    In particular, this can cause access to freed memory in the replication
    receiver thread (aka IO thread) when using multi-source replication. In
    multi-source replication, two such threads are likely to start executing
    at nearly the same [1;31mtime[m. Then both threads can do the following at about
    the same [1;31mtime[m:
     1. From connect_to_master:
         1.1. call mysql_options(mysql, MYSQL_SET_CHARSET_DIR, (char *)
    charsets_dir), which will
         1.2. set mysql->options.charset_dir to strdup(charsets_dir).
     2. From connect_to_master:
         2.1. call mysql_reconnect, which will call
         2.2. mysql_set_character_set, which will
         2.3. temporarily change the global charsets_dir to
    mysql->options.charset_dir, then
         2.4. do some work, and finally
         2.5. change back charsets_dir to its previous value
     3. From handle_slave_io, call mysql_close, which calls
    mysql_close_free_options, which frees mysql->options.charset_dir.
    
    Since no locks are protecting the global charsets_dir, the following
    can happen:
     1. T1 executes 1, 2.1, 2.2, 2.3, leaving the global charsets_dir set
    to the T1's mysql->options.charset_dir.
     2. T2 executes 1.1 (thus passing T1's mysql->options.charset_dir as
    the third argument to mysql_set_options), 1.2 (allocate the same space
    pointed by T1's mysql->options.charset_dir) and 2 (store dir into the
    space allocated above).
     3. T1 continues to execute 2.4, 2.5, 3 (restoring the global
    charsets_dir and freeing T1's mysql->options.charset_dir)
     4. T2's mysql->options.charset_dir is freed before it executes 3,
    since it points to the same space with T1's mysql->options.charset_dir.
    
    So the global charsets_dir of a running server is changed unsafely.
    
    Fix
    ===
    After fixing Bug#24465518, we don't change the global charsets_dir
    of a running server, so the problem was fixed. Then we can remove
    force_restart.inc from these test scripts.

[33mcommit 7f233327f198e2839655eee5fff53c6cca80a0fd[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Tue Jan 9 19:06:49 2018 +0200

    Bug #27157520: SET PERSIST FOR GTID_MODE AND ENFORCE_GTID_CONSISTENCY
      IS NOT WORKING PROPERLY
    
    1. Implemented sorting the persisted values by [1;31mtime[mstamp before applying. So now they apply in the order set.
    2. Increased the resolution of the [1;31mtime[mr storage
    3. Added a test along the lines of the bug report depending on the relationship
      between the two replication sysvars.

[33mcommit 6903e468fdef01bb258917b645d7175a9e4d4dda[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Fri Jan 5 14:26:36 2018 +0200

    Bug #27016247: SET PERSIST_ONLY DOES NOT CONSIDER RUNTIME VALIDATION
    
    Turned off the call to the check() function for SET PERSIST_ONLY since
    the functions are geared towards checking the run[1;31mtime[m value and
    not the values supplied via the command line or the INI file(s).
    
    Added a test case

[33mcommit a5c15f5911987b05fa926303d91376f18da5fd88[m
Author: Nuno Carvalho <nuno.carvalho@oracle.com>
Date:   Tue Jan 9 11:32:11 2018 +0100

    BUG#27016053: REGRESSION IN BINLOG_LOG_ROW INTRODUCED BY ADD_PKE
    
    Group Replication plugin is a multi or single primary replication
    solution, on which members do execute transactions optimistically
    and at commit [1;31mtime[m they decide, if conflicts happen, which must
    commit or rollback.
    The conflict detection is based on the write-sets of each
    transaction, which is collected along the transaction life when it
    does a update.
    During detailed performance analysis it was discovered that there
    were non-optimized memory allocations and memory copy operations on
    the write-set extraction.
    
    In order to solve the performance regression, the following actions
    were made:
     1) optimize memory allocation;
     2) reduce memory copy operations;
     3) only collect foreign key write-sets when the current table has
        foreign keys.

[33mcommit 838871ffe5b464364bd6489b389b0c438a0b69ac[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Tue Jan 9 18:13:36 2018 +1100

    Bug#26399073 - MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS
    
    Fix a performance regression; InnoDB has a system where the performance
    schema key is decided by FILE, and the patch that extended the basename
    function to work with both / and \ made these allocations slower (as it
    uses std::string, which can allocate on the heap).
    
    However, there is no reason whatsoever that this lookup needs to be done
    run[1;31mtime[m in a map. Change it to use a constexpr function; it goes through
    the array linearly, but it's small and it's compile-[1;31mtime[m. The end result
    is that the compiled code stores a PSI key directly, instead of taking
    FILE, removing its path run[1;31mtime[m and looking it up in an std::map.
    
    Improves a data loading benchmark with ~3%, in addition to the ~7%
    regression it fixes
    
    rb#18379 Approved by Bin. Fixed by Steinar.

[33mcommit 1b0a0645a2803b4a5f3bd5ada356a3edf9d1624a[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Tue Jan 9 18:13:36 2018 +1100

    Bug#26399073 - MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS
    
    Fix a performance regression; InnoDB has a system where the performance
    schema key is decided by FILE, and the patch that extended the basename
    function to work with both / and \ made these allocations slower (as it
    uses std::string, which can allocate on the heap).
    
    However, there is no reason whatsoever that this lookup needs to be done
    run[1;31mtime[m in a map. Change it to use a constexpr function; it goes through
    the array linearly, but it's small and it's compile-[1;31mtime[m. The end result
    is that the compiled code stores a PSI key directly, instead of taking
    FILE, removing its path run[1;31mtime[m and looking it up in an std::map.
    
    Improves a data loading benchmark with ~3%, in addition to the ~7%
    regression it fixes
    
    rb#18379 Approved by Bin. Fixed by Steinar.

[33mcommit 1337154e1eb3b716a7882e671b0f2e4d2d72e5e4[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Jan 5 15:22:33 2018 +0100

    Bug#27247280 UNINSTALL/INSTALL OF COMPONENT_LOG_FILTER_DRAGNET BROKEN ON ALPINE LINUX
    
    To reproduce: run main.log_options_cmdline on Alpine Linux.
    
    This is a simple instance of:
    
      Bug#27151550 PLUGINS/COMPONENTS SHOULD NOT RELY ON DLCLOSE() TO RUN DESTRUCTORS
    
      There is no guarantee that unloading (destructors are invoked) happens on
      dlclose. On musl (as opposed to glibc), constructors only run the first [1;31mtime[m
      a library is run, and destructors only run on exit. For portable code,
      dlclose cannot be assumed to unload the symbols immediately.
    
    The fix for this plugin is simply to set log_error_filter_rules to
    nullptr when shutting down the plugin. This ensures that it is null
    when re-starting the plugin.
    
    Change-Id: I8e48f8682930a73dd3878808ae70a1ff691dabde

[33mcommit e3ac8e72aa4ff0df86e61642056edbd4531957ae[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Fri Jan 5 16:13:16 2018 +0800

    Bug #24700334   MTR'S CHECK OF RPL.RPL_MULTI_SOURCE_SLAVE_START_STOP FAILS
    
    Problem
    =======
    MTR's internal check of some test scripts failed as below.
     block_encryption_mode  aes-128-ecb
     bulk_insert_buffer_size        8388608
    -character_sets_dir     G:/ade/test/sb_1-20445141-1473971193.18/mysql-advanced-8.0.1-dmr-winx64/share/charsets/
    +character_sets_dir
     character_set_client   latin1
     character_set_connection       latin1
    
    Analysis
    ========
    The mysql_set_character_set_with_default_collation and
    mysql_set_character_set (both defined in client.cc) will temporarily
    change the global variable charsets_dir. This makes them
    non-thread-safe.
    In particular, this can cause access to freed memory in the replication
    receiver thread (aka IO thread) when using multi-source replication. In
    multi-source replication, two such threads are likely to start executing
    at nearly the same [1;31mtime[m. Then both threads can do the following at about
    the same [1;31mtime[m:
     1. From connect_to_master:
         1.1. call mysql_options(mysql, MYSQL_SET_CHARSET_DIR, (char *)
    charsets_dir), which will
         1.2. set mysql->options.charset_dir to strdup(charsets_dir).
     2. From connect_to_master:
         2.1. call mysql_reconnect, which will call
         2.2. mysql_set_character_set, which will
         2.3. temporarily change the global charsets_dir to
    mysql->options.charset_dir, then
         2.4. do some work, and finally
         2.5. change back charsets_dir to its previous value
     3. From handle_slave_io, call mysql_close, which calls
    mysql_close_free_options, which frees mysql->options.charset_dir.
    
    Since no locks are protecting the global charsets_dir, the following
    can happen:
     1. T1 executes 1, 2.1, 2.2, 2.3, leaving the global charsets_dir set
    to the T1's mysql->options.charset_dir.
     2. T2 executes 1.1 (thus passing T1's mysql->options.charset_dir as
    the third argument to mysql_set_options), 1.2 (allocate the same space
    pointed by T1's mysql->options.charset_dir) and 2 (store dir into the
    space allocated above).
     3. T1 continues to execute 2.4, 2.5, 3 (restoring the global
    charsets_dir and freeing T1's mysql->options.charset_dir)
     4. T2's mysql->options.charset_dir is freed before it executes 3,
    since it points to the same space with T1's mysql->options.charset_dir.
    
    So the global charsets_dir of a running server is changed unsafely.
    
    Fix
    ===
    After fixing Bug#24465518, we don't change the global charsets_dir
    of a running server, so the problem was fixed. Then we can remove
    force_restart.inc from these test scripts.

[33mcommit 5669eaccf7381e8fea9f996d316cab953fe8e60a[m
Author: Rahul Sisondia <rahul.sisondia@oracle.com>
Date:   Wed Jan 3 12:53:43 2018 +0100

    Bug#25658586 RENAME USER THROW ERROR EVEN IF AUTHORIZATION_ID IS NOT IN
                 ROLE GRAPH
    
    Description
    -----------
    When an authId is no longer in the role graph then rename of that authid should
    be successful but it throws error at present.
    
    At the [1;31mtime[m of revoking the specified role for the specified user,
    there are two problems :
    - There is check such that if there is no edges connected to
      the auth id then it is not role id anymore. We got the
      condition in the check wrong.
    - The auth id on which edges are checked in the point#1 must
      be of the role, instead we find out the adjacent vertices of
      the user.
    - In case a user id dropped then we must update role flag of
      the connecting acl users otherwise rename after the drop
      user.
    
    Fix:
    ---
    
    - Change the condition such that role is set to true if there
      exist adjacent vertices on the specified role id.
    - Check for the adjancent vertices on the role auth id instead
      of the auth role id.
    - Added an utility function that updates the role flag on the
      ACL user and calling the method wherever needed.
    
    Testing :
    -------
    Added the test scenario reported in the bug just before the existing test
    scenario available in the role.test file. Verified the test suites execution
    on loki01.
    
    Result from Sandbox run :
    
    Unit tests: 100% tests passed, 0 tests failed out of 46
    --------------------------------------------------------
    The servers were restarted 1473 [1;31mtime[ms
    Spent 25864.133 of 1459 seconds executing testcases
    
    Completed: Failed 3/5735 tests, 99.95% were successful.
    
    Failing test(s): perfschema.variables_info i_innodb.table_compress_3
    i_innodb.innodb_bug14621190_debug_sync
    
    Note: Above test failures has nothing to do with this fix so we can ignore that.
    
    Review :
    ------
    RB#18236

[33mcommit d4813bc33f2d8ecb0852564cafc075ac342d10fa[m
Author: Varun Nagaraju <varun.nagaraju@oracle.com>
Date:   Tue Jan 2 12:27:34 2018 +0530

    Bug #27115804 MTR.PL SHOULD LOOK IN RUNTIME_OUTPUT_DIRECTORY FOR BINARIES
    
    DESCRIPTION : When running mtr.pl on (primarily) Windows from a <build directory>, it will not find the ndb* binaries.
    
    FIX : mtr.pl is made to look in run[1;31mtime[m_output_directory instead of the old storage/ndb/* locations.

[33mcommit a68c818723b56080258103e95543171384a353f1[m
Author: Varun Nagaraju <varun.nagaraju@oracle.com>
Date:   Fri Dec 29 16:56:14 2017 +0530

    Bug #27115804 MTR.PL SHOULD LOOK IN RUNTIME_OUTPUT_DIRECTORY FOR BINARIES
    
    DESCRIPTION : When running mtr.pl on (primarily) Windows from a <build directory>, it will not find the ndb* binaries.
    
    FIX : mtr.pl is made to look in run[1;31mtime[m_output_directory instead of the old storage/ndb/* locations.

[33mcommit 3698e67db215b7f69d35690e83d4a15a312562f3[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Fri Dec 29 17:20:27 2017 +0100

    Bug#27326647 NDBINFO TEST DEPENDS ON NDB_INDEX_STAT TABLES
    
    The test query from ndbinfo.ndb$dict_obj_info would some[1;31mtime[ms include
    the ndb_index_stat tables. The query looked at all tables with id higher
    than a certatin values and the ndb_index_stat tables may very well have
    such higher value since it's not known when they are created during a
    test.
    
    Fix by including only the 5 tables releated to t1, this can be assumed
    since global schema lock would be hold while creating t1.
    
    Change-Id: I6b994fad48c3f70ecfb5c84d1d6f35ac5761b5c1

[33mcommit 1a9072d6d3a61daf0ea07878d7c0fe3254f47860[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Fri Dec 29 17:20:01 2017 +0800

    Bug #26288697   RPL_GTID.RPL_MULTI_SOURCE_MTR_INCLUDES FAILS SPORADICALLY ON WINDOWS
    
    Problem
    =======
    The test rpl_gtid.rpl_multi_source_mtr_includes fails
    with a redundant Rotate log event in a rlay log file
    on windows platform.
    
    Analysis
    ========
    When a slave receiver received a previous log event, it
    writes a rotate log event into a relay log file, since
    the event does not have any meaning for the slave and
    was just sent to show the slave the master is making
    progress and avoid possible deadlocks. So at this
    point, the event is replaced by a rotate event what
    will make the slave to update what it knows about the
    master's coordinates. So it is possible that the slave
    receiver received two previous log events continuously
    on relay log rotation, then a redundant Rotate log event
    is displayed in the case.
    
    Fix
    ===
    The purpose of this test verifies that all replication
    include files can be used for a new created channel and
    also for the default channel when passing the channel
    name as a parameter. To keep the purpose of the test
    and fix the problem at the same [1;31mtime[m, we let
    show_relaylog_events.inc display the fixed events of
    the relay log without changing to pass the channel name
    as a parameter.

[33mcommit 0a0e50b31b9293b87afee1e184b696fc21680c90[m
Author: Pekka Nousiainen <pekka.nousiainen@oracle.com>
Date:   Thu Dec 28 00:42:58 2017 +0200

    wl#7614 rowmap-02.diff
    
    add stat for job rowmap merge u[1;31mtime[m

[33mcommit 3e966048ef409579c4b8bf82dd683a70119cb6bb[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Dec 21 10:00:20 2017 +0100

    WL#8500 Adapt MySQL Cluster to 8.0
    
    Follow up fix to prior patch which adapted ndbcluster(the plugin) to the
    new logging functions of MySQL Server. As part of that patch the prefix
    "NDB" was removed from two debug [1;31mtime[m error printouts and that caused
    the error log warning suppression in ndb_rpl_slave_replay.test to fail.
    
    Fix by changing the suppressions in test to not include "NDB "
    
    Also rewrite the logic in ndb_log_detect_prefix() to check for
    prefix NDB after checking for the allowed subsystem prefixes. Thus it
    shuld detect all redundant "NDB" prefixes in log messages.
    
    Change-Id: I8b982032386a1074dbfdb08f5cbe06380d3ac990

[33mcommit 3585af5a062edd588254ff5b3a3dbb98ab60e6b1[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Dec 21 09:42:08 2017 +0100

    WL#9185 MySQL Cluster support for new DD
    
    Remove old hack to detect bug 18976 from ndb_binlog_ddl_multi using fixed
    [1;31mtime[m sleeps without checking if condition is fulfilled. This shaves 20
    seconds off test run [1;31mtime[m, imagine how much [1;31mtime[m that has
    taken during the 11 years it's been in there.
    
    Change-Id: Ia83bab569327a4cd25e8ef2a287e7487234714ee

[33mcommit 9b938b417f6ee61f83663bf8c58a77853baa1ab5[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Tue Dec 19 11:24:54 2017 +0100

    WL#8648 NDB_SHARE lifecycle improvements
    
    Remove call to ndbcluster_binlog_setup_table() from
    ha_ndbcluster::open() since the NDB_SHARE should already have been
    created by create(), schema distribution or auto discovery. The
    DBUG_ASSERT(false) checking this code path has been there a long
    [1;31mtime[m now, just fail the open() in the very rare case tha no
    NDB_SHARE exist.
    
    Change-Id: I7ac78897babcf0d31f771088b475fe9fd13fc8bb

[33mcommit 769b1d3ad0e8e0a1ab60a47224034ad8251aa71e[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Tue Dec 19 10:00:12 2017 +0100

    WL#9185 MySQL Cluster support for new DD
    
    Problem with installing NDB table in DD during "schema dist synch" i.e
    when the MySQL Server reconnect to the cluster. This occured because
    an old table with a different named was earlier installed using the same
    id as the table being installed. Each engine is only allowed to install
    one table with same id in the DD at the same [1;31mtime[m. Since NDB is the
    master for dictionary information, it's well known that the other table
    does not exist anymore and can be safely removed. This is a rather rare
    failure but may occur when DDL changes has happened while the MySQL
    Server has been disconnected from the cluster.
    
    Implement new Ndb_dd_client::store_table() which handles the failure by
    removing the old table definition by id and then retrying the install.
    
    Enable ndb_reconnect.test again
    
    Change-Id: I1af3e4a17a841e296d80678a32742489c6fe8bd9

[33mcommit 7d07248bc79aea622865b9b218caeb4414c4f093[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Thu Dec 14 12:01:51 2017 +0100

    Bug#27278348 FAILURE OF RQG RUNS ON PB2 VALGRIND
    
    - Increase [1;31mtime[mout for reconnecting after a server restart in
      mtr tests.
    
    - Improve handling of dd::Properties: Avoid memory reshuffling
      while unescaping strings.

[33mcommit e25517e73ce84e976e13faf4c6a90bb388af13b1[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Tue Dec 19 11:55:03 2017 +0100

    Bug #25677422: SET_TIME IN VARIABLES_INFO REFLECTS RESTART TIME FOR
    PERSISTED VARIABLES
    
    Post-push fix: perfschema.variables_info:
     removed a [1;31mtime[mstamp from the result since it's non-deterministic.

[33mcommit 180c0cf07c26da46ff0ef4b38f795922c45865cb[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Mon Dec 18 14:02:31 2017 +0100

    Bug #25677422: SET_TIME IN VARIABLES_INFO REFLECTS RESTART TIME FOR PERSISTED
                   VARIABLES
    
    Post-push fix: sql/persisted_variable.cc:925:17: error: '[1;31mtime[mstamp' may be used
    uninitialized in this function [-Werror=maybe-uninitialized]
    
    Change-Id: Ib6f4853aa5c91b54991aed42863234b584c5368f

[33mcommit 742bdc5a79175b97106bd386fd43c949472d94d9[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Thu Jan 21 10:08:31 2016 +0100

    Bug#21974696: WRONG RESULT WHEN GROUPING ON VALUE FROM SUBQUERY
                  AND USING COUNT DISTINCT
    
    Queries that group the results on subqueries which return BLOB, or a
    BLOB-based type such as TEXT or JSON, some[1;31mtime[ms fail to find the group
    boundaries and return wrong results.
    
    This bug was fixed in MySQL 8.0.4 with the fix for
    Bug#26188578 Bug#26164633 Bug#26360114 Bug#26781725 Bug#26848089 Regressions with WL#9236.
    
    Adding a test case that verifies that the bug is fixed.

[33mcommit 687b2eb201f64bfc6bfbc8fa22f375f0a16861dd[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Mon Dec 18 09:16:54 2017 +0100

    Bug #25677422: SET_TIME IN VARIABLES_INFO REFLECTS RESTART TIME FOR PERSISTED
                   VARIABLES
    
    Problem: performance_schema.variables_info tables columns like SET_USER,
    SET_TIMESTAMP, SET_HOST represent when and by wholm a variable was set.
    However when a variable is persisted and after server restart, the variables
    SET_TIME instead of showing [1;31mtime[m when this variable was set, it shows the
    server restart [1;31mtime[m.
    
    Fix: Fix is to persist user/host/[1;31mtime[mstamp in mysqld-auto.cnf so that when
    this cnf file is read the values can be read and applied back on server. This
    will reflect the correct [1;31mtime[m and user for all the persisted variables. This
    fix will change the format of mysqld-auto.cnf to accomodate more details for
    all variables which are being persisted.

[33mcommit ae966030a0232bfb652efe1415507b65095a168d[m
Author: Jaideep Karande <jaideep.karande@oracle.com>
Date:   Fri Dec 15 12:34:19 2017 +0100

    BUG#27060005: GROUP REPLICATION THREAD'S INITIALIZATION METHODS CAN GET STUCK WAITING
    
    Problem: Initalizer thread can deadlock if spwaned thread executes in 0 [1;31mtime[m
    
    Description:
    So usually, when GR starts a thread, the starting methods do:
    
    > start_method  << initializer thread
    > {
    >   lock(run_lock)
    >
    >   launch_thread
    >
    >   while (!running)
    >   {
    >     mysql_cond_wait(&run_cod, &run_lock);  << Step A << RACE_RUNNER_1
    >   }
    >
    >   unlock(run_lock)
    > }
    
    And threads handling methods do:
    
    >
    > thread_handler_method   << spawned thread
    > {
    >   lock(run_lock)
    >   running=true << Step B
    >   mysql_cond_broadcast(&run_cond);
    >   unlock(run_lock)
    >
    >   execution
    >
    >   lock(run_lock) << << RACE_RUNNER_2
    >   running=false << Step C
    >   mysql_cond_broadcast(&run_cond);
    >   unlock(run_lock)
    >
    > }
    
    In above code if execution [1;31mtime[m nears to NULL, initializer thread and spawned
    thread function will race at point RACE_RUNNER_1 and RACE_RUNNER_2 for
    run_lock.
    
    If spawned thread wins the race, it will turn running=false causing
    initializer thread to deadlock in conditional wait as well while loop.
    
    Resolution:
    Code has been modified to wait only when thread is running.

[33mcommit db3fd68e09e90badf1b4889be6b9ed3de0eef21e[m
Author: Gleb Shchepa <gleb.shchepa@oracle.com>
Date:   Thu Dec 7 16:21:28 2017 +0400

    WL#8989: Create an internal API for the MySQL parser to enumerate reserved and non-reserved words
    
    Part I. Grammar preparation.
    
    * Replace the existent type tag <symbol> with <keyword> for a better
      readability.
    
    * Add the new type tag <keyword> to currently untyped terminal and
      non-terminal symbols.
    
    Part II. Create a simple compile-[1;31mtime[m program for transforming
             sql_yacc.yy into a .h file that contains an array of
             reserved and non-reserved words.
    
    * Find %token declarations with the <keyword> type tag by a regexp.
    
    * Separate %type declarations are ignored for the simplicity.
    
    Part III. Introduce a new system view: INFORMATION_SCHEMA.keywords.
    
    * Hardcode the statical list of keywords and reserved words into a view
      on top of a long JSON_TABLE(...) expression.
    
    * Use a trick in the .test file to trace changes in keywords: notify the
      developer to update the target I_S version in the mysqld binary where
      necessary -- this will force DD to refresh I_S view declarations on
      the next run.
    
    Change-Id: Ib40e7f743f4deb069df0a0bbc00c39e4460f7c33

[33mcommit 7389285c6be5ee87558786799ba912794276d312[m
Merge: 61d80ab1ceb 553a3140822
Author: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
Date:   Thu Dec 14 17:35:46 2017 +0100

    Merge branch 'mysql-8.0' into mysql-trunk
    
    Conflicts:
            mysql-test/collections/mysql-8.0-stage.push
            mysql-test/include/mysqld--help.inc
            packaging/rpm-docker/mysql.spec.in
            packaging/rpm-fedora/mysql.spec.in
            packaging/rpm-oel/mysql.spec.in
            packaging/rpm-sles/mysql.spec.in
            rapid/plugin/x/client/mysqlxclient/xsession.h
            rapid/plugin/x/client/xconnection_impl.cc
            rapid/plugin/x/ngs/include/ngs/command_delegate.h
            rapid/plugin/x/ngs/include/ngs/error_code.h
            rapid/plugin/x/ngs/include/ngs_common/socket_interface.h
            rapid/plugin/x/ngs/ngs_common/operations_factory.cc
            rapid/plugin/x/ngs/src/client.cc
            rapid/plugin/x/ngs/src/protocol/row_builder.cc
            rapid/plugin/x/ngs/src/socket_events.cc
            rapid/plugin/x/protocol/CMakeLists.txt
            rapid/plugin/x/src/mysql_show_variable_wrapper.cc
            rapid/plugin/x/src/mysql_show_variable_wrapper.h
            rapid/plugin/x/src/mysql_variables.h
            rapid/plugin/x/src/query_formatter.cc
            rapid/plugin/x/src/query_formatter.h
            rapid/plugin/x/src/query_string_builder.cc
            rapid/plugin/x/src/query_string_builder.h
            rapid/plugin/x/src/sql_data_context.cc
            rapid/plugin/x/src/sql_data_context.h
            rapid/plugin/x/src/xpl_client.cc
            rapid/plugin/x/src/xpl_client.h
            rapid/plugin/x/src/xpl_performance_schema.h
            rapid/plugin/x/src/xpl_plugin.cc
            rapid/plugin/x/src/xpl_server.cc
            rapid/plugin/x/src/xpl_server.h
            rapid/plugin/x/src/xpl_system_variables.h
            rapid/plugin/x/tests/driver/common/utils_string_parsing.h
            rapid/plugin/x/tests/driver/driver_command_line_options.cc
            rapid/plugin/x/tests/driver/processor/script_stack.h
            rapid/plugin/x/tests/mtr/t/admin_list_objects_docpath.test
            rapid/unittest/gunit/xplugin/test_main.cc
            rapid/unittest/gunit/xplugin/xpl/callback_command_delegate_t.cc
            rapid/unittest/gunit/xplugin/xpl/row_builder_t.cc
            rapid/unittest/gunit/xplugin/xpl/stubs/command_service.cc
            rapid/unittest/gunit/xplugin/xpl/stubs/log_subsystem.cc
            rapid/unittest/gunit/xplugin/xpl/stubs/misc.cc
            rapid/unittest/gunit/xplugin/xpl/stubs/security_context_service.cc
            rapid/unittest/gunit/xplugin/xpl/stubs/sql_session_service.cc
            rapid/unittest/gunit/xplugin/xpl/xdate[1;31mtime[m_t.cc
            rapid/unittest/gunit/xplugin/xpl/xdecimal_t.cc

[33mcommit a8f8b90c3c1928af48bc4d3d67bb9f82c3597250[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Dec 14 14:39:30 2017 +0100

    Bug#27266086    POLLEVENTS() 'MAX_WAIT' MAY OVERSLEEP UP TO 9MS
    
    As the max wait [1;31mtime[m was waited for in chunks of max 10ms, we could
    have less than 10ms remaining in the last wait-nap. However, we
    still waited for 10ms, which could result in up to a 9ms
    over sleep.
    
    Patch recalulate the sleep  [1;31mtime[m for each nap, and wait less than
    10ms if less than 10ms remains.

[33mcommit 1721b3fb138dea33b1d53e3f4061f6be69a45653[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Dec 13 17:00:45 2017 +0100

    WL#9267 - Mysqlx connection [1;31mtime[mout
    
    Post-push fix warning from Clang/Mac:
    rapid/plugin/x/ngs/include/ngs/vio_wrapper.h:45:8: warning: 'get_vio' overrides a member
          function but is not marked 'override' [-Winconsistent-missing-override]
    
    Change-Id: I92a01cffe15e1dc51a26008ea773b62258ea6b67

[33mcommit 6e18ea9527e5edb054ab31dd69a10a45b80f9195[m
Author: Venkatesh Venugopal <venkatesh.venugopal@oracle.com>
Date:   Thu Dec 14 11:13:57 2017 +0530

    Bug #18089914 - REFACTORING: RENAME GROUP TO GTID
    
    Problem:
    --------
    When global transaction identifiers (GTIDs) were
    implemented, a working name some[1;31mtime[ms used internally was
    'group' rather than 'transaction'. This was rejected and we
    now use 'transaction' everywhere. But there are still
    remainders of 'group' in the code. So we should rename some
    C++ identifiers.
    
    Note: this has no user-visible effects, it only changes C++
    identifier names.
    
    Fix:
    ----
    Renamed,
    
    enum_group_type
    { AUTOMATIC_GROUP, ANONYMOUS_GROUP, INVALID_GROUP,
      UNDEFINED_GROUP,GTID_GROUP, NOT_YET_DETERMINED_GROUP },
    ER_GTID_NEXT_TYPE_UNDEFINED_GROUP,
    ER_GTID_UNSAFE_BINLOG_SPLITTABLE_STATEMENT_AND_GTID_GROUP
    
    to
    
    enum_gtid_type
    { AUTOMATIC_GTID, ANONYMOUS_GTID, INVALID_GTID,
      UNDEFINED_GTID, ASSIGNED_GTID, NOT_YET_DETERMINED_GTID },
    ER_GTID_NEXT_TYPE_UNDEFINED_GTID,
    ER_GTID_UNSAFE_BINLOG_SPLITTABLE_STATEMENT_AND_ASSIGNED_GTID.

[33mcommit c0363c35734580e73adcbd6c16b75eac11e21c11[m
Author: Gleb Shchepa <gleb.shchepa@oracle.com>
Date:   Thu Dec 7 16:21:28 2017 +0400

    WL#8989: Create an internal API for the MySQL parser to enumerate reserved and non-reserved words
    
    Part I. Grammar preparation.
    
    * Replace the existent type tag <symbol> with <keyword> for a better
      readability.
    
    * Add the new type tag <keyword> to currently untyped terminal and
      non-terminal symbols.
    
    Part II. Create a simple compile-[1;31mtime[m program for transforming
             sql_yacc.yy into a .h file that contains an array of
             reserved and non-reserved words.
    
    * Find %token declarations with the <keyword> type tag by a regexp.
    
    * Separate %type declarations are ignored for the simplicity.
    
    Part III. Introduce a new system view: INFORMATION_SCHEMA.keywords.
    
    * Hardcode the statical list of keywords and reserved words into a view
      on top of a long JSON_TABLE(...) expression.
    
    * Use a trick in the .test file to trace changes in keywords: notify the
      developer to update the target I_S version in the mysqld binary where
      necessary -- this will force DD to refresh I_S view declarations on
      the next run.
    
    Change-Id: Ib32a43d35a2cf1076e7087d783fc47e0d5c7a19b

[33mcommit b8ca7a3caeec9052e622a95724114070ccb54745[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Tue Dec 12 12:24:32 2017 +0100

    WL#8195 Adapt MySQL Cluster to 8.0
    
    - enable ndb_basic.test now when SDI has been compressed enough to
      fit in the NDB dictionary
    - fix test to use charset=latin1 for maxed out tables as otherwise the
       max row szie of 14000 is blown
    - accept new column "Visible" in SHOW INDEX
    - remove "ndb_cache_check_[1;31mtime[m" which was removed when query cache was removed

[33mcommit 6fe8eb8e734506da5030a9bc587f95fbd7d68465[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon Dec 11 16:06:59 2017 +0100

    WL#9185 MySQL Cluster support for new DD
    
     - the new SDI format is rather verbose and takes up unnecessary storage
       space and network bandwidth. Since it's generated seldom and stored
       for a long [1;31mtime[m, it's well worth using some extra CPU resources in
       order to minimize it's size.
     - Add new minify() function which will rewrite the "pretty" SDI format
       into a "minified" SDI format. This minification has no effect on
       deserialization.
    
    Change-Id: I33bde275e3b32b7120e10290d78762d6a24d945b

[33mcommit 55b0cc6f29ba805c4c864abf111aa046819efc5a[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon Dec 11 15:59:24 2017 +0100

    Bug#27247586 SETEXTRAMETADATA SHOULD USE HIGHER COMPRESSION
    
     - The extra metadata for a table in NDB need to be compressed as much
       as possible, it's rarely changed and stored for a long [1;31mtime[m.
     - Increase compression level to 'best' in order to shrink
       the extra metadata as much as possible.
    
    Change-Id: Ic7453e927aeb2429794ceb1bc795efc299f11b3b

[33mcommit 863aac45c8c124d8a80e505e80bd6770d94fe718[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Mon Aug 28 15:19:00 2017 +0200

    WL#9553: Upgrading the transactional data dictionary tables.
    
    This patch implements support for changing the DD table
    definitions.
    
    Overview.
    ---------
    The main changes are the following:
    
    - SE private data previously hard coded in InnoDB is now
      used only during first [1;31mtime[m server start. The meta data
      is stored in a DD table. On restart, the meta data is
      fetched from the DD table instead of InnoDB. Thus, we
      may have SE private data that can change.
    
    - During upgrade, we create the required target tables in
      a temporary schema, and migrate the meta data from the
      actual DD tables to the new target tables.
    
    - At the end of upgrade, we modify the persistently stored
      SE private data mentioned in 1) to that of the new target
      tables. We also adjust the schema ID of the target tables
      to simulate altering the schema of the tables. This way,
      we are able to switch from the old to the new DD version
      atomically. The temporary schemas are removed on next
      restart.
    
    In more detail, the patch implements the following:
    
    Performance schema.
    -------------------
    - Change in a performance schema test: Select only the PS_VERSION
      from 'mysql.dd_properties' to avoid reflecting irrelevant meta
      data in the result file, and thus to avoid unnecessary re-recordings
      of the result file.
    
    - Minor changes in the way Plugin_table_impl is used; replaced by
      Object_table_impl for more uniform code.
    
    - Approved by Marc Alff.
    
    Handler and handlerton API and InnoDB.
    --------------------------------------
    - The handler function 'get_se_private_data()' will now be
      called only during '--initialize'. During ordinary restart,
      it will be called once to get the SE private data for the
      'mysql.dd_properties' table, which can never change. This
      is the table that stores the SE private data for the other
      DD tables.
    
    - Modify 'get_se_private_data()' to be in line with what
      'dd_write_table()' does when storing SE private data:
    
      * Store se_private_data for columns. This is now done
        for DD tables in the same way as it is done for
        user tables.
      * Extend se_private_data for indexes to also store
        table_id and space_id. Again, this is done to get
        the same set of meta data for DD tables and user
        tables.
    
      Could dd_write_table() be used to ensure consistency in the
      meta data that is stored?
    
    - At the end of upgrade, we start over DD initialization to
      do the same as for a restart. Thus, we had to provide a new
      parameter to 'get_se_private_data()' to reset the counters
      for this to work with two phases of function calls in the
      case of upgrade.
    
    - We maintain a set in InnoDB of SE private ids of the DD tables.
      This set is used this instead of the hard coded id range used
      previously.
    
    - Replace hard coded ids of tables used in the processing
      of I_S queries by name based lookup.
    
    - Change the order of the DD and DDSE tables in the System_tables
      registry to make sure the table 'innodb_dynamic_metadata' is
      created on a low table id and index id. The motivation is that
      for now, this table must stay at fixed ids because it may be
      opened by InnoDB before the DD is available.
    
    - Approved by Jimmy.
    
    Extensions of 'mysql.dd_properties' and data structures.
    --------------------------------------------------------
    - Valid key/value pairs are explicitly defined:
    
        DD_VERSION                Actual DD version.
        IS_VERSION                Actual I_S version.
        PS_VERSION                Actual P_S version.
        SDI_VERSION               Actual SDI version.
        LCTN                      L_C_T_N setting used during
                                  --initialize.
        MYSQLD_VERSION_LO         Lowest server version which has
                                  been using the data directory.
        MYSQLD_VERSION_HI         Highest server version which has
                                  been using the data directory.
        MYSQLD_VERSION            Current server version.
        MINOR_DOWNGRADE_THRESHOLD The current DD can be used by
                                  previous MRUs, unless their
                                  target DD version is less than
                                  the downgrade threshold.
        SYSTEM_TABLES             List of system tabels with
                                  definitions.
        UPGRADE_TARGET_SCHEMA     Temporary schema used during
                                  upgrade.
        UPGRADE_ACTUAL_SCHEMA     Temporary schema used during
                                  upgrade.
    
    - Simplify Object_table, Object_table_definition,
      Plugin_table_definition, their subclasses and clients.
      Remove unnecessary functions, and rename according to
      usual naming rules. Merge Object_table* and Plugin_table*
      into one class.
    
    - Version number handling does not need to be part of these
      classes, this will be handled elsewhere, so it is removed.
    
    - Object table definitions now may hold definitions of both
      the target and actual tables.
    
    - Introduce explicit enumerations for options, indexes and
      foreign keys for the DD table definitions.
    
    - Explicitly define indexes needed by foreign keys.
    
    - Use the index enumerations when creating instances of
      object keys.
    
    - A new 'DD_bootstrap_ctx' class is introduced as an aid in the
      upgrade process, but also for normal DD bootstrapping. The
      handling of the bootstrap stages is moved into this class.
    
    Changes to the current DD initialization.
    -----------------------------------------
    - Extend the bootstrapper to create target or actual tables
      depending on context.
    
    - Change the way DD objects are flushed (during --initialize) and
      synced (during restart) to avoid problems with overlapping
      ID sequences for the scaffolding and the persisted object IDs.
      This is needed since the DD tables will no more be fixed on low
      IDs.
    
    - Add a new stage before creating tables where the inert table
      'dd_properties' is opened and the version numbers etc. is read.
      Here, the actual DD table definitions are read in case of
      upgrade or minor downgrade.
    
    New handling of upgrade.
    ------------------------
    - Create two temporary schemas with unused schema names, store
      in 'dd_properties'.
    
    - Upon restart, the temporary schemas are dropped.
    
    - First initialize the meta data for the actual DD tables, and
      use this to open the actual tables.
    
    - Then create the target tables, and migrate the meta data from
      the old to the new tables.
    
    - Adjust object ids to simulate altering schema of the new
      and old DD tables at the end of DD upgrade.
    
    - Update properties for all tables, make sure removed
      tables are not reflected in the persisted properties.
    
    Add 'options' columns.
    ----------------------
    - Add a general purpose column to all DD tables that store
      DD entities (i.e.:
    
            catalogs,
            character_sets,
            collations,
            column_statistics,
            events,
            resource_groups,
            routines,
            schemata,
            st_spatial_reference_systems,
           *tables,
           *tablespaces
    
    - Plus a selection of important non-entity tables:
    
           *columns,
           *indexes,
            foreign_keys,
            triggers,
           *parameters
    
    - Tables prefixed by '*' above already have a column named
      'options' which can be used for this purpose.
    
    Miscellaneous.
    --------------
    - Set created/last altered when creating schema.
    
    - Add command line option for disabling automatic DD upgrade.
    
    - Change test for is_dd_table_name() to check for table types in the
      System_tables registry.
    
    - Change dictionary object type names for better conformity.
    
    - Remove *_type classes for the DD object classes.
    
    - Refactor object table usage
    
    Test changes.
    -------------
    - Extend dd_schema_definition_debug_c{i,s} to also record the
      CREATE TABLE statements for the DD tables.
    
    - Record new test results.
    
    - Mask out the DD version number from the SDI which is extracted
      from tablespace files in some tests.

[33mcommit 0aba1fdcc16b5017d99d424c32ce48d5c0541a74[m
Author: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>
Date:   Fri Dec 8 09:53:04 2017 +0100

    WL#9267 - Mysqlx connection [1;31mtime[mout
    
    X plugin is monitoring I/O operations for authenticated users so it
    could drop idle connections.
    
    RB: 17006
    Reviewed by: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
    Reviewed by: Lukasz Kotula <lukasz.kotula@oracle.com>
    
    Approved by: Prabeen Kumar Pradhan <prabeen.pradhan@oracle.com>

[33mcommit 6672cba6222347757b96ed24e28ea3dffaf21e2e[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Fri Dec 8 13:01:22 2017 +0100

    WL#9059: [4/8] Allow storing SRSs with given ID in DD
    
    Spatial reference systems have user-defined IDs, while other DD objects
    are given an auto-generated ID at storage [1;31mtime[m. Modify the assertion
    that assumes that all new dictionary objects are auto-numbered to make
    an exception for spatial reference systems.
    
    Change-Id: If9febd94ddc3d645a21c47d205f88bce9640428a

[33mcommit 50a22e15858548ca3e6788cffd99b823200ca09a[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Fri Dec 8 13:01:22 2017 +0100

    WL#9059: [4/8] Allow storing SRSs with given ID in DD
    
    Spatial reference systems have user-defined IDs, while other DD objects
    are given an auto-generated ID at storage [1;31mtime[m. Modify the assertion
    that assumes that all new dictionary objects are auto-numbered to make
    an exception for spatial reference systems.
    
    Change-Id: If9febd94ddc3d645a21c47d205f88bce9640428a

[33mcommit 1591fabc776d5bac207cdc23fbcf1591fd04eb20[m
Author: Andre Negrao <andre.negrao@oracle.com>
Date:   Thu Dec 7 20:01:15 2017 +0000

    Bug#26695357 SOME SELECTS STILL PRESENT IN XCOM CODE
    
    Description:
    -----------
    After fixing parent issue BUG#25892493, one noticed that selects are still
    present in XCom client code, which is used to connect from GR/GCS to the XCom
    running thread.
    
    Fix:
    ---
    This patch removes the two 'select()' calls that were still present in XCom:
    - In [1;31mtime[md_connect(), the select is replaced by a poll function;
    - All code enclosed by '#ifdef USE_SELECT' has been removed, including a
    select() call contained inside one function implemented within one such
    conditional block.

[33mcommit 79047012442e5dc7f43e917b504389fd1c4cb134[m
Author: Andre Negrao <andre.negrao@oracle.com>
Date:   Thu Dec 7 20:01:15 2017 +0000

    Bug#26695357 SOME SELECTS STILL PRESENT IN XCOM CODE
    
    Description:
    -----------
    After fixing parent issue BUG#25892493, one noticed that selects are still
    present in XCom client code, which is used to connect from GR/GCS to the XCom
    running thread.
    
    Fix:
    ---
    This patch removes the two 'select()' calls that were still present in XCom:
    - In [1;31mtime[md_connect(), the select is replaced by a poll function;
    - All code enclosed by '#ifdef USE_SELECT' has been removed, including a
    select() call contained inside one function implemented within one such
    conditional block.

[33mcommit b35783e8893098467034a2a86cfacb0ba601b812[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Thu Dec 7 16:47:29 2017 +0100

    Bug#24734971: PERFORMANCE REGRESSION IN DICTIONARY OPERATIONS DUE TO METADATA LOCKING
    
    Problem: Search in, and traversal of lists of MDL_tickets maintaned by
    MDL_context becomes [1;31mtime[m consuming when the number of tickets is
    large.
    
    Fix: 1) Add a hash index for the lists to get O(1) lookup based on MDL_key.
         2) Keep track of the subset of the tickets for which
            MDL_context::materialize_fast_path_locks already have been
            called, and only iterate over tickets added since the last
            call.
    
    Change-Id: Ie4275d02ee310112ba36614a9c331da869d71d18
    (cherry picked from commit e531c8a23f8edeb4b845be98b5cfa29d46bc7af1)

[33mcommit 1543ad8f62d3f3287215c8a51cd4e600cf2faeca[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Thu Dec 7 16:47:29 2017 +0100

    Bug#24734971: PERFORMANCE REGRESSION IN DICTIONARY OPERATIONS DUE TO METADATA LOCKING
    
    Problem: Search in, and traversal of lists of MDL_tickets maintaned by
    MDL_context becomes [1;31mtime[m consuming when the number of tickets is
    large.
    
    Fix: 1) Add a hash index for the lists to get O(1) lookup based on MDL_key.
         2) Keep track of the subset of the tickets for which
            MDL_context::materialize_fast_path_locks already have been
            called, and only iterate over tickets added since the last
            call.
    
    Change-Id: Ie4275d02ee310112ba36614a9c331da869d71d18

[33mcommit 9c9bdf17e2159af46ef036910a1e33fa14a5261e[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Dec 1 11:18:12 2017 +0100

    Bug #26399073: MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS [noclose]
    
    Fix a performance regression; InnoDB has a system where the performance
    schema key is decided by __FILE__, and the patch that extended the
    basename function to work with both / and \ made these allocations
    slower (as it uses std::string, which can allocate on the heap).
    
    However, there is no reason whatsoever that this lookup needs to be done
    run[1;31mtime[m in a map. Change it to use a constexpr function; it goes through
    the array linearly, but it's small and it's compile-[1;31mtime[m. The end result
    is that the compiled code stores a PSI key directly, instead of taking
    __FILE__, removing its path run[1;31mtime[m and looking it up in an std::map.
    
    Improves a data loading benchmark with ~3%, in addition to the ~7% regression
    it fixes.
    
    Change-Id: Ia536f6342278fcd6cc990053c3d2b0978e781b29

[33mcommit 2a7f51157003032675d98e0b8af698e80d1b5973[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Dec 6 16:53:17 2017 +0100

    Bug#24688694 SEVERAL UNSTABLE TESTS IN SUITE PERFSCHEMA
    
    Removed duplicated test cases from test
      perfschema.idx_compare_ees_by_thread_by_error,
    which failed due to [1;31mtime[mout.

[33mcommit c91826d07549f640ff2b916d81bbdd9b2dd16f5f[m
Author: Jaideep Karande <jaideep.karande@oracle.com>
Date:   Wed Dec 6 13:24:40 2017 +0100

    Bug#27128868: CRASH FOR SHOW BINLOG EVENTS CMD IN BINARY_LOG::VIEW_CHANGE_EVENT::READ_DATA_MAP
    
    Issue: "SHOW BINLOG EVENTS FROM 490;" some[1;31mtime[ms causes crash
    
    Reason: Code assumes position 490 is a valid event and reads header.
    If bytes in binlog file converts to an event and right length, it simply read
    data and converts to event.
    So invalid position, by chance, has good values(i.e. convertible to an event)
    in the header, at a position of event_type and event_length tricks the code.
    Later causing core dump during conversion to an event.
    
    Test case: main.ctype_cp932_binlog_stm
    
    Issue is duplicate of Bug#20286642(open) and WL#9562(open)
    
    Resolution:
    Removed statement "SHOW BINLOG EVENTS FROM 490;" from test-case for
    successfull run.

[33mcommit 41d77887081ea0ffaeca0dff54fb862846eabfc1[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Wed Dec 6 08:43:55 2017 +0100

    Bug#27152428 JSON_TABLE + PREPARED STATEMENT + VIEW HAS PROBLEM IN DURING RESOLUTION
    
    Assume a prepared statement:
    - SELECT FROM (SELECT FROM (SELECT ...) AS DT) AS DT1, JSON_TABLE(DT1.col);
    - DT1 is resolved, which materializes DT
    - JSON_TABLE is resolved
    - DT1 is merged
    Now we execute the statement:
    - in the first loop in the function,
          DT1 is not resolved again, as it was merged,
          and DT is not reached
    - we must thus defer resolution of JSON_TABLE
    - until DT is reached and resolved by the special branch 'if
      (!first_execution)' for formerly-nested derived tables
    - and then we can resolve TF.
    
    As we didn't defer JSON_TABLE, its argument DT1.col was resolved against
    the not-yet-resolved DT, leading to assertion failure:
    sql_base.cc:8414: Field* find_field_in_table_ref():
      Assertion `table_list->table' failed.
    (which means: "DT isn't ready!").
    
    Fix: we run the code in this function twice: a first [1;31mtime[m for all non-TF
    tables, a second [1;31mtime[m for TF.
    This is a low-effort fix as in 9.0 it can be eliminated by WL#6570.

[33mcommit ec54ad242e1326d3424174ce9bd5d953c67a3298[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Nov 9 12:33:59 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    Testcase based on previous dump-2355-patch from Frazer:
    
      ALL DUMP 2355 <nodeId>
    
      On nodeId, it waits a short [1;31mtime[m (200 millis), then it shuts down.
      On non-nodeId nodes, it starts sending harmless signals to nodeId, but with an
      artificial delay in the signal preparation, so that the shut down of the
      destination may occur 'during' this preparation phase.
      The 'assert that the sendBuffer is empty' code is uncommented.
    
      Effect :
      - NodeId shuts down, then in early restart the other node(s) get an assertion
        failure as their SendBuffers for the node are not empty at connect [1;31mtime[m.
    
      Why :
      - Sending a signal is not atomic w.r.t. the transporter disconnecting, the
        send buffer being cleared, and signal sending being stopped
      - Therefore it is possible for ongoing sends to get into the send buffer
        *after* the send buffer has been cleared
      - This can cause the assert to fail when communication is opened again :
        Bug #24444908
      - This can cause a previous-incarnation FAIL_REP to be reanimated and kill
        the new node incarnation :
        Bug #25128512
    
    Additionaly two 'fixes' related to these bugs,:
    
      1.  Remove bad error handing code in TransporterRegistry::connect_server
          Once the Transporter itself has connected, it owns the socket, so we must
          not close it from the TransporterRegistry::newSession() thread
    
      2.  Small improvements to FD nulling

[33mcommit 475a412e3903dac02bf9da3e4e240ae56b3d4685[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Nov 9 12:33:59 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    Testcase based on previous dump-2355-patch from Frazer:
    
      ALL DUMP 2355 <nodeId>
    
      On nodeId, it waits a short [1;31mtime[m (200 millis), then it shuts down.
      On non-nodeId nodes, it starts sending harmless signals to nodeId, but with an
      artificial delay in the signal preparation, so that the shut down of the
      destination may occur 'during' this preparation phase.
      The 'assert that the sendBuffer is empty' code is uncommented.
    
      Effect :
      - NodeId shuts down, then in early restart the other node(s) get an assertion
        failure as their SendBuffers for the node are not empty at connect [1;31mtime[m.
    
      Why :
      - Sending a signal is not atomic w.r.t. the transporter disconnecting, the
        send buffer being cleared, and signal sending being stopped
      - Therefore it is possible for ongoing sends to get into the send buffer
        *after* the send buffer has been cleared
      - This can cause the assert to fail when communication is opened again :
        Bug #24444908
      - This can cause a previous-incarnation FAIL_REP to be reanimated and kill
        the new node incarnation :
        Bug #25128512
    
    Additionaly two 'fixes' related to these bugs,:
    
      1.  Remove bad error handing code in TransporterRegistry::connect_server
          Once the Transporter itself has connected, it owns the socket, so we must
          not close it from the TransporterRegistry::newSession() thread
    
      2.  Small improvements to FD nulling

[33mcommit c4734d8ff4473d472ffad456a263a2029aeb66a6[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Nov 9 12:33:59 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    Testcase based on previous dump-2355-patch from Frazer:
    
      ALL DUMP 2355 <nodeId>
    
      On nodeId, it waits a short [1;31mtime[m (200 millis), then it shuts down.
      On non-nodeId nodes, it starts sending harmless signals to nodeId, but with an
      artificial delay in the signal preparation, so that the shut down of the
      destination may occur 'during' this preparation phase.
      The 'assert that the sendBuffer is empty' code is uncommented.
    
      Effect :
      - NodeId shuts down, then in early restart the other node(s) get an assertion
        failure as their SendBuffers for the node are not empty at connect [1;31mtime[m.
    
      Why :
      - Sending a signal is not atomic w.r.t. the transporter disconnecting, the
        send buffer being cleared, and signal sending being stopped
      - Therefore it is possible for ongoing sends to get into the send buffer
        *after* the send buffer has been cleared
      - This can cause the assert to fail when communication is opened again :
        Bug #24444908
      - This can cause a previous-incarnation FAIL_REP to be reanimated and kill
        the new node incarnation :
        Bug #25128512
    
    Additionaly two 'fixes' related to these bugs,:
    
      1.  Remove bad error handing code in TransporterRegistry::connect_server
          Once the Transporter itself has connected, it owns the socket, so we must
          not close it from the TransporterRegistry::newSession() thread
    
      2.  Small improvements to FD nulling

[33mcommit ff9f46d387470fa4a9b839ca744589b00390cf0f[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Mon Dec 4 17:19:21 2017 +0100

    Bug #27135084: WINDOW FUNC: CRASH IN ITEM_FUNC_INT_DIV::VAL_INT
    
    Different error handling in window functions, due to backport of fixes
    for misc. date/[1;31mtime[m functions.
    
    Change-Id: I5eb68c5be3812687ea25393493c3dcca0ed82e09

[33mcommit 5c410a41e284fbf99eb1d943ebad1c3ef38e5110[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Mon Dec 4 11:04:46 2017 +0100

    BUG#25835748: Post-push fix, check for is execution thread and spin[1;31mtime[m was wrong way, needed a exclamation mark for negation

[33mcommit cfcbe404b2ab4bd5600fa0b52246a6d6cb5c6836[m
Author: Rahul Sisondia <rahul.sisondia@oracle.com>
Date:   Fri Dec 1 09:58:40 2017 +0100

    Bug#25122897 SET DEFAULT ROLE NOT TRANSACTIONAL
    
    Description
    -----------
    When SET DEFAULT ROLE statement is executed,
    Sql_cmd_alter_user_default_role::execute() method is called.
    This method performs a few sanity checks and then alters the default roles for
    every user one by one. It means we acquire the table lock and ACL lock for every
    user, make the changes and commit them for the user. Instead, we must acquire
    the locks once, do the alter roles for all users and then commit in the end.
    
    Fix:
    ------
    - Introduced a new method named mysql_alter_or_clear_roles() which is called
      from the Sql_cmd_alter_user_default_role::execute(). The new method acquires
      the locks, alters the roles for all users according to the specified role_type
      and then commits the acl ddl changes.
    
    - Since we now need to pass the role_type in the method argument therefore, we
      had to do the forward declaration of the same in the auth_common.h . Only enum
      class can be forward declared therefore, changed the "enum role_enum" to
      "enum class role_enum" and updated the cascade effects of the same.
    
    - Removed the following 3 wrapper methods
       -  mysql_clear_default_roles
       -  mysql_alter_user_set_default_roles_all
       -  mysql_alter_user_set_default_roles
    
    Testing :
    
    Introduced a new test file 'atomic_alter_roles' that verifies the following the three scenarios
    a. SET DEFAULT ROLE 'role 1' , 'role 2' to user1 , user 2
    b. SET DEFAULT ROLE ALL to user 1, user 2
    c. SET DEFAUL ROLE NONE to user1 , user 2
    Added a new test in the existing file 'atomic_create_user' that verified the following scenario
    a. CREATE USER user 1, user 2 DEFAULT ROLE 'qa';
    
    Ctest results -
    
    100% tests passed, 0 tests failed out of 46
    Total Test [1;31mtime[m (real) =  55.21 sec
    
    > -----Original Message-----
    > From: MYSQL-PREPUSH-TESTING_WW_GRP@oracle.com [mailto:MYSQL-
    > PREPUSH-TESTING_WW_GRP@oracle.com]
    > Sent: Fri, December 1, 2017 11:08 AM
    > To: rahul.sisondia@oracle.com
    > Subject: Pre-push testing result on linux platform : mysql-trunk [ Fail ]
    >
    > Build#3844 - Changeset:
    > + 1bd963041228d62ef050722338b7d7b926b5cdc4 Bug#25122897 SET
    > DEFAULT ROLE
    > + NOT TRANSACTIONAL
    >
    > MTR    : All tests are successful
    > CHTEST : Unsuccessful
    
    Note - CHTEST failure seems uprelated to this bug fix.
    
    Review : RB#18034

[33mcommit d18087817ee08aa4ac2254822f0d046e15b43ea8[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Fri Dec 1 05:29:11 2017 +0100

    Bug #26495619: PERSISTED PLUGIN VARIABLES ARE NOT CONSIDERED DURING
                   SERVER RESTART
    Problem: System variables can be set either from command line or through
    sql using SET statement. Variables set as part of command line does not
    go through run[1;31mtime[m validation, whereas variables set using SET statement
    are validated using check() function. Thus read only variables are set as
    part of command line and dynamic variables are set using SET statement.
    
    Variables persisted using SET PERSIST or PERSIST_ONLY syntax will ensure
    that variables are validated using check() when server is restarted, except
    with an exception for read only variables because they are appended to command
    line during server startup.
    
    There are certain group replication(GR) specific variables which are defined
    to be DYNAMIC variables, but cannot be changed once GR is up and ONLINE. This
    kind of behaviour confuses the existing SET statement execution logic. Thus
    when GR variables are persisted, and later when server is started persisted
    GR variables could not be set early before GR plugin is loaded. This will not
    make GR to come ONLINE on boot process.
    
    ex:
    SET PERSIST group_replication_group_name="aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa",
                group_replication_group_seeds="localhost:13011,localhost:13123",
                group_replication_local_address="localhost:13123",
                    group_replication_bootstrap_group= ON,
                group_replication_start_on_boot=ON;
    
    With above variables persisted, GR should start on boot when server is
    restarted. This does not happen because SET statement logic expects these
    variables to be readonly so that these can be set early before plugin is
    loaded. To obtain this semantics variables needs to be decleared as READ
    ONLY, and for certain reasons these variables cannot be changed to readonly.
    
    Fix: A new flag named PLUGIN_VAR_PERSIST_AS_READ_ONLY is introduced which
    needs to be set in variable declaration to indicate that these are variables
    which can be changed before plugin is loaded but not after that. This flag
    will be checked in SET statement logic and will treat them as a read only
    variables. Thus when server is restarted these variables can be appended to
    command line, making GR to start on boot.

[33mcommit db646302f4143444932c54d38b2b73684c337edb[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Nov 30 15:37:43 2017 +0100

    WL#8960 - InnoDB: Partial Update of Large Objects (BLOBs)
    
    Post-push fix: remove warnings
    
    variable 'new_block' is used
          uninitialized whenever 'if' condition is false [-Wsome[1;31mtime[ms-uninitialized]
    warning: unused variable
          'SMALL_THRESHOLD_PAGE_COUNT' [-Wunused-const-variable]
    
    Change-Id: Ic7930d0036353ac08c68e8d9c6087e9b2ab9b86e

[33mcommit 16eca80a933dc2e49dd791db87f6c4d39ea2cc7c[m
Author: Nisha Gopalakrishnan <nisha.gopalakrishnan@oracle.com>
Date:   Thu Nov 30 16:45:44 2017 +0530

    BUG#27041502: ASSERTION `TYPE() != MYSQL_TYPE_TIMESTAMP' FAILED.
    
    Analysis:
    =========
    Inserting a NULL value in a table having TIMESTAMP field
    as primary key and a trigger(INSERT/UPDATE) defined on the
    table caused an assert in debug build. On the release build,
    appropriate error is reported.
    
    With WL9687, the 'explicit_defaults_for_[1;31mtime[mstamp'
    was enabled by default. Hence TIMESTAMP columns are NULL
    by default and no auto promotion happens.
    
    As part of WL#6030:
    When there are triggers installed on a table, the WL6030
    temporarily sets the Field as nullable during BEFORE-triggers
    are processed by setting Field->set_tmp_nullable(). So the
    fill_record() call do not report ER_BAD_NULL_ERROR. And WL6030
    introduces a new function Field::check_constraints() which does
    the checks after triggers are processed, which was not updated
    based on WL9687's expectation and had assert on TIMESTAMP field
    as explained in current commit message. In absence of triggers,
    fill_record()reports an error ER_BAD_NULL_ERROR, as
    Field->set_tmp_nullable() is not set.
    
    Hence the assert during the constraint check was fired based on
    the previous behavior i.e TIMESTAMP columns cannot be NULL(due to
    auto promotion).
    
    Fix:
    ===
    Removed the assert since TIMESTAMP columns can be NULL
    and constraints on the column should be evaluated.

[33mcommit 37c65442bd5222185d94d696d85c47f76a013ca3[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Wed Nov 29 11:00:27 2017 +0100

    Bug#27190109 SHUTDOWN_SERVER TIME IS TOO SHORT FOR VALGRIND IN SOME TESTS
    
    Make the tests use the default [1;31mtime[mout (60 sec) instead of 10 sec.
    
    Approved by Shipra Jain <shipra.x.jain@oracle.com>.

[33mcommit d3c39c158eb69df11d623b8a14c87f10cc4c3686[m
Author: Tiago Alves <tiago.alves@oracle.com>
Date:   Thu Nov 23 11:18:11 2017 +0000

    BUG#27166613 Ensure ATRT waits for processes to be undefined before (re)start
    
    While CPCD is of asynchronous nature (i.e. when requesting to start a process
    does not necessarily mean the process has started when the method returns)
    ATRT assumed CPCD was syncrhonous. Hence, when ATRT restarted a process it
    could happent that it would start a process before it has completely stop
    leading to test run failures.
    
    The main change was to add logic to wait for a process to stop. This logic
    must be used after stopping a process or a set of processes.
    We did not make wait for process stop part of the stop logic to prevent
    refreshing state every [1;31mtime[m we want to stop a process and to allow stopping
    several processes in one go, and then waiting for those to finish also in
    one go.
    
    The above change additionally required that process status update is done
    via update_status method only, hence emoving wrong assumptions about the
    processes life-cycle (e.g. when saving a process, first perform stop, and
    then save its status).
    
    Additionally, we made CpcClient connection more robust by checking that
    messages are actually sent and received (prevent erroneous usage of the
    API before connection is open).
    
    Finally, added extra logging to ATRT to be able to more easily diagnose test
    failures.
    
    NOTE: There's an interesting situation when resetting processes configuration,
          we start by stopping the management nodes first and then the data nodes.
          Stopping the second last data node, causes the last data node to quit
          by itself (watchdog). We updated the logic not to fail on this scenario.
          However, a better approach would be to reverse all this logic, stopping
          first all the servers, then the data nodes, and last the mgmd nodes.

[33mcommit a1741fcd395cd0f8748a65500557b636d2217200[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Tue Nov 28 13:19:46 2017 +0100

    WL#8987 Add the ICU library to handle RLIKE/REGEXP.
    
    Follow-up patch to avoid [1;31mtime[mout for regexp searches in MTR's check-warnings.
    
    Approved by Pavan Naik <pavan.naik@oracle.com>.

[33mcommit 14458e0bf8f3325ad1785cbf2cb99ad85e093af9[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Nov 21 16:32:24 2017 +0100

    Bug #26399073: MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS [noclose]
    
    Stop comparing func_name() on pointers alone; there is no guarantee that
    a C string literal evaluates to the same pointer every [1;31mtime[m you return it
    from a function. In particular, ASan on Windows breaks this assumption.
    
    Unbreaks main.func_string on Windows ASan.
    
    Change-Id: I13d63ba9da6a2dec020b22b7828ffb65acd91635

[33mcommit 0741cc8d5184fbdb5d8841c91601bbc40cd0de24[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Fri Nov 24 10:42:44 2017 +0100

    Bug#27168722: Speed up the GET_JSON_WEIGHT function in the json_conversions test
    
    Make GET_JSON_WEIGHT a simple CASE statement to avoid a table scan for
    each call. The json_conversions test relies heavily on the
    GET_JSON_WEIGHT function, and this change reduces the [1;31mtime[m it takes to
    run the test from 100 seconds to 30 seconds with a debug build in my
    environment.
    
    Change-Id: I660f4c0ea41050b5c47953285e843a95dacbc797

[33mcommit bda9d52fbac0ae7813e1317eb400f616f01732bc[m
Author: Tatiana Azundris Nuernberg <tatjana.nuernberg@oracle.com>
Date:   Tue Nov 28 03:26:42 2017 +0000

    Bug#26576922: SERVER DOESN'T ALWAYS FALL BACK TO DEFAULT ERROR MESSAGES
    
    Server was changed so it would start even if lc-messages-dir
    contained an invalid path; it would then fall back on the
    built-in error messages. The intention was primarily to have
    the server come up even in the absence of lc-messages-dir
    (i.e. to require as few start-up arguments as possible, ideally
    just the data-dir); that the server would throw an error, but
    no longer abort on invalid values was just a welcome side effect.
    
    The same was not true for lc-messages (the actual language),
    as that had a sensible default value (and therefore satisfied
    the above requirement, "server works with argument omitted").
    Paul noted that users might find it confusing that providing
    an invalid value throws a non-fatal error for one case
    (lc-messages-dir), and a fatal one for the other (lc-messages).
    
    Therefore, we now throw an error but continue for all three of
    lc-messages-dir, lc-messages, and lc-[1;31mtime[m-names.

[33mcommit e2337109eac02485896578a2ac932dc1b45196a8[m
Author: Tatiana Azundris Nuernberg <tatjana.nuernberg@oracle.com>
Date:   Tue Nov 28 03:26:42 2017 +0000

    Bug#26576922: SERVER DOESN'T ALWAYS FALL BACK TO DEFAULT ERROR MESSAGES
    
    Server was changed so it would start even if lc-messages-dir
    contained an invalid path; it would then fall back on the
    built-in error messages. The intention was primarily to have
    the server come up even in the absence of lc-messages-dir
    (i.e. to require as few start-up arguments as possible, ideally
    just the data-dir); that the server would throw an error, but
    no longer abort on invalid values was just a welcome side effect.
    
    The same was not true for lc-messages (the actual language),
    as that had a sensible default value (and therefore satisfied
    the above requirement, "server works with argument omitted").
    Paul noted that users might find it confusing that providing
    an invalid value throws a non-fatal error for one case
    (lc-messages-dir), and a fatal one for the other (lc-messages).
    
    Therefore, we now throw an error but continue for all three of
    lc-messages-dir, lc-messages, and lc-[1;31mtime[m-names.

[33mcommit 476f4f4ea0616db78a110453c900e817cf76dafe[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Mon Nov 27 15:32:56 2017 +0100

    Bug#27041526 assertion `mon > 0 && mon < 13' failed.
    
    The problem is that, when the value of a [1;31mtime[mstamp field is
    used as argument to IF() condition in SQL, its
    datatype/value changes based on the setting of variable
    collation_connection.  More details of this issue is
    reported in Bug#27143384. This bug will be fixed independent
    of fix for this bug. The root cause of core dump is that the
    value of mysql.table_stats.cached_[1;31mtime[m is treated as a
    string value, when collation_connection is set to
    utf32_general_ci.  Converting this string version of
    [1;31mtime[mstamp into a integer value gives us a invalid longlong
    [1;31mtime[mstamp value. When we use this wrong [1;31mtime[mstamp value to
    get MYSQL_TIME, we end-up getting invalid date values and
    assert.
    
    The expression which hits the issue in Bug#27143384 is,
    "IF(ISNULL([1;31mtime[mstamp_field), 0, [1;31mtime[mstamp_field)". This
    patch uses COALESCE() which suite better. Part of problem
    was the optimizer by default converts the [1;31mtime[mstamp fields
    into strings.  And the IF() resulted in automatic conversion
    to integer only in certain charset (as discussed in
    bug27143384). In order to avoid depending on implicit
    conversions, this patch uses CAST() to explicitly request
    the [1;31mtime[mstamp value as a unsigned value. This code change
    can be a permanent change, and need not really be reverted
    back after Bug#27143384 is fixed.
    
    The patch also sets null_on_null property for UDF's as
    false. The UDF return's NULL as soon as it sees one of it's
    argument is NULL. This change is not really required for
    the fix in hand. However, this change was expected to be done
    for UDF's implemented in I_S as per optimizer's suggestions
    in past. The test case contains a SELECT with TABLE_ROWS
    column in WHERE condition, which demonstrates the problem.
    
    The patch also sets the few other internal I_S functions
    with Functype as DD_INTERNAL_FUNC. This was a omission
    when I_S.FILES system view was implemented.
    
    A new test case is added to main.information_schema.
    
    Change-Id: I6904103094c288958af46b6c203a726c31b3093d

[33mcommit a2e09bfd11d0940b6908760437d875c6b91c5bd9[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Mon Nov 27 15:32:45 2017 +0100

    Bug#26770836 SLAVE HANGS - WAITING FOR TABLE METADATA LOCKS
    
    A DDL on table would trigger change in view metadata update.
    We acquire MDL locks on view and the dependent tables during
    this process. We release these acquired locks just after
    finishing the view metadata update, and we do not hold the
    MDL lock until the statement is committed.
    
    An expectation from binary log subsystem is that it assumes
    all MDL acquired by the statement are held till commit
    phase, so two statements acquiring conflicting sets of locks
    can't be committed at the same [1;31mtime[m. This assumption is
    broken by release-before-commit optimization done during
    view metadata update.
    
    This patch enables MDL locks acquired during view metadata
    update to be held until commit. A test case is added to make
    sure we acquire lock after view metadata is updated. The test
    case for Bug#25685371 is removed as we no more release locks
    at the end of view metadata update, and the problem reported
    there cannot occur.
    
    Change-Id: I3757428fc01788b9314a961b5fd2f83830811485

[33mcommit 490f74226dc225baa30c319e29783ad377b9865f[m
Author: Kristofer Älvring <kristofer.pettersson@oracle.com>
Date:   Mon Nov 27 13:58:38 2017 +0100

    Bug#27136346 SYSBENCH CONNECT TEST SHOWS -95% REGRESSION FOR NON-ROOT VS ROOT USER
    
    None root users experienced a 95% drop in CPU utilization due to a cache
    which is suppose to store database privileges based on user name and host
    for fast acccess. The cache is protected be a rw lock that needs to be
    checked for success. The check was inveresed so it reported failure
    on success and vice versa which ultimately caused the performance issues
    as a write lock was taken 10 [1;31mtime[ms for every connection attempt by
    internal system processes.

[33mcommit 52d3594db2feb8be1309ced2ebdcda53aa6dae63[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Sat Nov 25 20:36:38 2017 +0100

    Bug#27171283: FREQUENT BUFFER REALLOCATIONS WHEN SERIALIZING JSON
    
    When serializing a JSON value to its binary representation,
    String::reserve(size_t) is some[1;31mtime[ms called to make sure the
    destination buffer has enough room to hold an integer or double value
    of a given size. Unfortunately, if the String needs to allocate more
    memory, this variant of reserve() only reserves the minimum amount of
    memory needed, so it is very likely that a new reallocation is needed
    shortly after. This hurts performance, especially when serializing
    arrays with many numeric values.
    
    This patch makes the serialization use the two-argument variant of
    String::reserve() so that reallocations will increase the buffer size
    exponentially and amortize the cost of the reallocations.
    
    Microbenchmarks (64-bit, Intel Core 2 Quad 2.83GHz, GCC 7.2):
    
    BM_JsonBinarySerializeIntArray      17492816 -> 352638 ns/iter [ +4861%]
    BM_JsonBinarySerializeDoubleArray   80549060 -> 321707 ns/iter [+24938%]
    BM_JsonBinarySerializeStringArray     744725 -> 728882 ns/iter [  +2.2%]
    
    Change-Id: Icdb6316c80021043ada5467f4798028b8d44c7e4

[33mcommit dc0f375966f053c41dfb1c4c3064d3f945d2e122[m
Author: Martin Hansson <martin.hansson@oracle.com>
Date:   Fri Nov 24 14:33:40 2017 +0100

    WL#8987: Follow-up. Removes unused code, fixes warnings and test case [1;31mtime[mouts.

[33mcommit 200bf464776319dd2619cd7dc398d53c5e2e958b[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Thu Nov 2 14:46:26 2017 +0530

    WL #8478: UNDO log speedup- parallel LGMAN applying
    
    Enforce ordering of application of undo records for a given page
    in the LDM threads.
    
    With parallel undo log application, many undo records can be sent to the
    LDM threads without waiting for the LDM threads to finish applying them.
    Before applying a log record, we must fetch the page (get_page) and
    some[1;31mtime[ms, if the page is not available immediately, we have to wait for it
    before the log record can be applied. Waiting is done by periodically
    checking if the page is available (do_busy_loop()).
    However, between the checks, a subsequent log record belonging to the same
    page might get processed. This is because multiple log records are sent from
    LGMAN to the LDM threads continuously without waiting for the LDM threads to
    finish applying them. (WL8478)
    This subsequent log record will try to get the page as well and might succeed.
    This will result in unordered application of the undo records.
    The solution for this is to order the undo records belonging to a page.
    This is done by maintaining a queue of undo records received in LDM per
    page and applying them in order when the page becomes available in the
    page cache

[33mcommit ec7bf1468c902c32ffd7f2b13db3a8b44dd8f6ca[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Fri Nov 24 09:15:32 2017 +0100

    Bug#27167816 NDB.TEST_MGMD IS ALWAYS SKIPPED
    
     - make the lone mysqld in this configuration support ndbcluster
       so that tets is not skipped
     - look for ndb_mgmd in run[1;31mtime[m_output_directory (relative to testMgmd)
     - improve comments for testcase for bug#61607 which seems broken
     - skip tets on Windows without searching for testMgmd which is
       never built on that platform
    
    Change-Id: Ifce63f56577d46826f9d621e79a19c0692a84c90

[33mcommit 12cc37f7f3bf3a9d744f87809d8032cd607e6d44[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Thu Nov 23 17:05:21 2017 +0100

    BUG#25835748
      Adding :
        - Whether a thread is an exec thread or not
        - The concept of fixed vs temporary thread types.
          All existing thread types are fixed thread types
          Temporary thread types are types which threads become temporarily.
          They may be bound to cpusets which overlap with permanent thread types cpusets
    
      The SparseBitmask class is extended with a bitOR function, allowing one SparseBitmask to be merged in to another.
    
      A new IndexBuild thread type is added.
      This is different to the existing thread types as it is not a permanent type
      of thread, but rather a transient state of a thread.
      IoThreads can rebind to this thread type's properties at run[1;31mtime[m, while they are building ordered indexes.
      This allows users to configure any kind of cpu locking they like for Index Build threads, independent of the IoThread locking.
      By default :
        - IndexBuild threads will be unlocked
        - If IoThreads are locked in some way
        - IndexBuild threads will be locked to the set of *all* cores defined for the ndbmtd (e.g. LDM, TC, recv, send, IO...)
    
      The rationale here is that offline index build occurs in situations where it is the only relevant
      task in the cluster (SR, NR, ndb_restore --rebuild-indexes)
    
      This means that :
        - Users who currently have IoThreads locked to a subset of all cores defined
          for the ndbmtd will see greater potential IndesBuild parallelism, with no changes
        - They can get the old behaviour back by specifically locking IoThreads to the same cores as IndexBuild threads
        - Users can set any locking they like for IdxBuild threads
    
      Oddities :
        - The number of IndexBuild threads comes from elsewhere, the count is ignored (Similar to IoThreads)
        - The real[1;31mtime[m property is ignored
    
      Make calls to use the new IndexBuild thread type mapping for the duration of each offline index fragment build
    
      MTR testcase giving some coverage of offline (and online) index build with parallelism via ndb_restore.
    
      Make TwoPassInitialNodeRestartCopy the default setting
    
      Make build index threads parallel default
    
      Fix of BUG#26928111 that could have caused unlock to main or recv CPU locking for Linux platforms

[33mcommit 1a8c10bf2f8e81e97162cacc82f22e2419bf286e[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Nov 22 16:56:43 2017 +0100

    Bug#27151550 PLUGINS/COMPONENTS SHOULD NOT RELY ON DLCLOSE() TO RUN DESTRUCTORS
    
    There is no guarantee that unloading (destructors are invoked) happens on
    dlclose. On musl (as opposed to glibc), constructors only run the first [1;31mtime[m
    a library is run, and destructors only run on exit. For portable code,
    dlclose cannot be assumed to unload the symbols immediately.
    
    The fix is to always clean internal data structures at plugin startup.
    
    In the test_status_var_service, plugin initialization simply consists
    of setting a pointer to null;
    
    Also: disable asynch IO by default on Alpine, it was broken by this patch:
    
    Author: Satya Bodapati <satya.bodapati@oracle.com>
    Date:   Mon Jul 3 14:21:59 2017 +0200
    
        WL#9538 - InnoDB_New_DD: Integrating InnoDB SDI with new DD
    
    (cherry picked from commit 47384bb52f78b3475c85810c60b169614a34e276)

[33mcommit 7ed7179a539da32470e2e5188b9298c25c41b002[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Nov 22 16:56:43 2017 +0100

    Bug#27151550 PLUGINS/COMPONENTS SHOULD NOT RELY ON DLCLOSE() TO RUN DESTRUCTORS
    
    There is no guarantee that unloading (destructors are invoked) happens on
    dlclose. On musl (as opposed to glibc), constructors only run the first [1;31mtime[m
    a library is run, and destructors only run on exit. For portable code,
    dlclose cannot be assumed to unload the symbols immediately.
    
    The fix is to always clean internal data structures at plugin startup.
    
    In the test_status_var_service, plugin initialization simply consists
    of setting a pointer to null;
    
    Also: disable asynch IO by default on Alpine, it was broken by this patch:
    
    Author: Satya Bodapati <satya.bodapati@oracle.com>
    Date:   Mon Jul 3 14:21:59 2017 +0200
    
        WL#9538 - InnoDB_New_DD: Integrating InnoDB SDI with new DD

[33mcommit 4e8bd458d2c1ca3540dee08800634863ba3a35c0[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Wed Nov 15 22:56:56 2017 +0100

    Bug#27125787 CPCD PROCESS MONITOR DOES NOT HANDLE TRANSITION FROM STOPPING TO STOPPED
    
    Better handling of process statuses when stopping a process:
     * After stopping, only processes no longer executing are marked as stopped
     * Processes that didn't immediately stop will keep status STOPPING and handled
       by monitoring
    
    Make cpcd process monitor (repeatably) kill process with SIGKILL if nice
    shutdown (SIGTERM) takes longer than 5 seconds.
    
    Made cpcd always remove process definition when undefine process have been
    issued for process and process has stopped.
    
    undefine process no longer returns failure when process is still running
    at the [1;31mtime[m, only if process is not defined or undefine is already in progress.
    
    Change contributed and reviewed jointly with Tiago Alves.

[33mcommit 9d567c601f4b719837699666c269fc50b3401121[m
Author: Tatiana Azundris Nuernberg <tatjana.nuernberg@oracle.com>
Date:   Thu Aug 31 06:52:48 2017 +0100

    Bug#26286871: LOG_SINK_JSON SERVICE DOESN'T WORK WITH RPM DEFAULT INSTALLATION
    
    Throw diagnostics when configured log-services exist, but cannot
    be opened/initialized (e.g. because they cannot open their files):
    
    - at run-[1;31mtime[m, send diagnostics to the client
    
    - at start-up, try to fall back to default services,
      print diagnostics there, then abort
    
    - at start-up, if default services fail, print diagnostics
      directly to the error stream, then abort

[33mcommit 6458cd8ecdc389803dbe8ed688d3d161aa47fd15[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Nov 14 15:31:57 2017 +0100

    Bug#27116899 ADDRESSSANITIZER: STACK-USE-AFTER-SCOPE IN NDBCLUSTER.PARTITION_BASIC
    
    Building with clang, and -fsanitize=address -fsanitize-address-use-after-scope
    we get warnings about stack use after scope.
    
    We have source code like this:
        sets[num_sets].value= &auto_value;
    which means 'auto_value' must have longer life[1;31mtime[m than the 'sets' array.
    
    Change-Id: I56b7a2e568320aa963afad708de3eeeb9806d4e5
    Fix: move three auto variables up in scope, before
    NdbOperation::SetValueSpec sets[3];

[33mcommit 0ab06e256e47f5a27b025a28b1a26548324538a5[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Nov 14 15:31:57 2017 +0100

    Bug#27116899 ADDRESSSANITIZER: STACK-USE-AFTER-SCOPE IN NDBCLUSTER.PARTITION_BASIC
    
    Building with clang, and -fsanitize=address -fsanitize-address-use-after-scope
    we get warnings about stack use after scope.
    
    We have source code like this:
        sets[num_sets].value= &auto_value;
    which means 'auto_value' must have longer life[1;31mtime[m than the 'sets' array.
    
    Change-Id: I56b7a2e568320aa963afad708de3eeeb9806d4e5
    Fix: move three auto variables up in scope, before
    NdbOperation::SetValueSpec sets[3];

[33mcommit 11986f269784fcb04509c2f7b1b650ed261217c6[m
Author: Rahul Sisondia <rahul.sisondia@oracle.com>
Date:   Thu Nov 16 09:59:13 2017 +0530

    Bug#26328274 SKIP_NAME_RESOLVE RESULTS IN REMOTE IP GETTING MATCHED WITH LOCALHOST
    Bug#26202411 - ASSIGNING A USER AS A ROLE WILL CHANGE THE USER REACH 
    
    Description
    -----------
    
    The root cause of the both issue is same.  The problem has been identified after the changes for WL#988 is pushed.
    In case the server is started with --skip-name-resolve option and client tries to connect the server through IP address then obviously host name is not resolved so it remains empty. When server tries to match the host from the connecting user to the ACL users one by one. The ACL user with localhost comes first in the ACL users list.  At this point ACL user with localhost matches with the empty host name when wild_case_compare() method is called. That must not happen.
    
    At the moment above method assumes that if the host name is empty then it always matches  irrespective of the value of the string to be matched with.
    
    Note - the second bug was reported with the docker image.  As pointed in the bug image Docker image also adds the --skip-name-resolve option. I could reproduce the problem with the latter option  on usual server.
    
    Fix:
    ----
            - Added a check such that empty string matches only with the wild many (%) string to be matched with. In other cases of empty string, this method returns not matching (i.e. true) value.
    
            - Current code assumed that host can be NULL or empty string but host can never be NULL. It can be empty string. Made necessary changes in the code and created Bug#27121559  to refactor the
            set_host_ptr() /set_user_ptr() methods.
    
            - Adjusted a few comments in the method within the periphery of 80 columns.
    
    Testing :
    ---------
    
            - Verified the scenarios reported in both bugs manually before and after fix.
    
            - Extended existing unit tests for the method wild_case_compare() in the file wild_case_compare-t.cc
    
            - Pre push testing result
    
        ----------------------------------------
    Build#3728 - Changeset:
    + 967ca0a484ba95dd61b2a501f17a969c3e7371ee Bug#26328274
    
    MTR : There are some test failures
    
    ## The status of MTR run no.1 is:- ##
    COMMAND : perl mysql-test-run.pl --mem --parallel=36 --force --max-test-fail=0 --retry=1 --retry-failure=1 --experimental=./collections/default.experimental --comment=MATS    --xml-report=mtr-report0.xml
    OVERALL STATUS:  tests="7146" failures="1" disabled="34" skipped="1694" errors="0" [1;31mtime[m="25098.223" name="AllTests"
    FAILED TEST(S) ARE:
    rpl_gtid.rpl_gtid_split_statements_debug
    ## The status of MTR run no.2 is:- ##
    COMMAND : perl mysql-test-run.pl --mem --parallel=36 --force --max-test-fail=0 --retry=1 --retry-failure=1 --experimental=./collections/default.experimental --comment=RAPID_PLUGINS --suite=x,group_replication    --xml-report=mtr-report1.xml
    OVERALL STATUS:  tests="520" failures="0" disabled="1" skipped="182" errors="0" [1;31mtime[m="6598.817" name="AllTests"
     ----------------------------------------------------------------
    
     Note- rpl_gtid_split_statements_debug test is failing without this patch also.

[33mcommit bd5d79f7b5d444539a78c7acfa0c96384908d6d3[m
Author: Thayumanavar S <thayumanavar.x.sachithanantha@oracle.com>
Date:   Thu Nov 16 03:54:51 2017 +0100

    BUG#27041552 - M_THD->GET_TRANSACTION()->IS_EMPTY(TRANSACTION_CTX::STMT)
                   ETC. ASSERTION
    
    An event whose schedule happens with global autocommit OFF on expiry
    results in an assert. The assert happens because on expiry the event is
    dropped and as part of drop, the autocommit gurad constructor is called.
    This guard asserts if there is an open pending transaction.
    The drop of the event happens on expiry once the event schedule is executed.
    This drop should happen in it's own transaction so the fix is to commit any
    open transaction if any pending at [1;31mtime[m of drop.

[33mcommit 8b0c8ead247a67ad1c60cbc11749c938624192d1[m
Author: Tiago Vale <tiago.vale@oracle.com>
Date:   Fri Nov 10 12:14:56 2017 +0000

    Bug#26961059 M_CONSUMER LOGGING THREAD IS CREATING 1000'S OF ENTRIES IN EVENT_WAITS TABLES
    
    PROBLEM
    Gcs_async_buffer maintains a circular buffer that stores events on behalf of
    application threads. The buffer is consumed by a dedicated thread.
    Even when there are no events to consume, this thread is constantly waking up
    every 500ms.
    
    ANALYSIS
    The Gcs_async_buffer::m_consumer thread wakes up every 500ms because it's using
    [1;31mtime[md_wait in Gcs_async_buffer::sleep_consumer(). In the current state, it's
    incorrect to change [1;31mtime[md_wait to wait because it can lead to a deadlock when
    the consumer sees the buffer empty and the producer fills it before the
    consumer blocks.
    
    Example interleaving:
    Consumer thread                        Producer thread
    | gcs_logging_system.cc#L240-L243      |
    |                                      | gcs_logging_system.cc#L166-L186
    | gcs_logging_system.cc#L245-L248      |
    
    The core issue in the design that prevents replacing [1;31mtime[md_wait with wait is
    that, in the consumer thread, checking if the buffer is empty and sleeping is
    not atomic.
    
    FIX
    Make the check-buffer-and-sleep action of the consumer thread atomic using the
    existing mutex (m_free_buffer_mutex).
    This renders the other mutex (m_wait_for_events_mutex) unnecessary.
    
    Reviewed-by: Alfranio Correia <alfranio.correia@oracle.com>
    Reviewed-by: Andre Negrao <andre.negrao@oracle.com>
    RB: 17905

[33mcommit 9a055d9491b7f08eed3da04dafb616df39af1d0f[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Mon Nov 13 13:11:09 2017 +0100

    Bug#27108794 CLANG/ASAN: STACK-USE-AFTER-SCOPE TABLE_UPGRADE_GUARD::~TABLE_UPGRADE_GUARD
    
    To repeat: cmake -DWITH_ASAN=1 -DWITH_ASAN_SCOPE=1
    ./mtr --mem --sanitize main.dd_upgrade_error
    
    A few dd tests fail with:
    ==26861==ERROR: AddressSanitizer: stack-use-after-scope on address 0x7000063bf5e8 at pc 0x00010d4dbe8b bp 0x7000063bda40 sp 0x7000063bda38
    READ of size 8 at 0x7000063bf5e8 thread T2
        #0 0x10d4dbe8a in Prealloced_array<st_plugin_int**, 16ul>::empty() const prealloced_array.h:186
        #1 0x10d406a8b in lex_end(LEX*) sql_lex.cc:560
        #2 0x10dae4b6d in dd::upgrade::Table_upgrade_guard::~Table_upgrade_guard() (mysqld:x86_64+0x100f87b6d)
        #3 0x10dadc557 in dd::upgrade::migrate_table_to_dd(THD*, std::__1::basic_string<char, std::__1::char_traits<char>, Stateless_allocator<char, dd::String_type_alloc, My_free_functor> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, Stateless_allocator<char, dd::String_type_alloc, My_free_functor> > const&, bool) (mysqld:x86_64+0x100f7f557)
        #4 0x10dad7e85 in dd::upgrade::migrate_plugin_table_to_dd(THD*) (mysqld:x86_64+0x100f7ae85)
        #5 0x10daec6a1 in dd::upgrade::do_pre_checks_and_initialize_dd(THD*) upgrade.cc:1216
        #6 0x10cd0a5c0 in bootstrap::handle_bootstrap(void*) bootstrap.cc:336
    
    Change-Id: I265ec6dd97ee8076aaf03763840c0cdf9e20325b
    Fix: increase life[1;31mtime[m of 'LEX lex;' which is used by 'table_guard'

[33mcommit b382f3935c07e6a64dd1145f4f3219f591090c8b[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Thu Oct 26 01:47:58 2017 +0200

    WL#8069
    More work on ndb_print_backup_file
    More paths coverage tested
    Various debug flags reset
    
    We relied on that the GCI received in START_NODE_LCP_REQ could
    be used as maxGciCompleted. This wasn't true since we could be
    in the final phase of a local LCP as part of the restart at this
    point in [1;31mtime[m. Given that this was merely an optimisation, the
    code to check this variable was simply removed to ensure that
    even if slightly more GCIs have to be executed during restarts,
    the restarts will be much safer.

[33mcommit 4abcc4ad89c8fa49129ee453134e365d5d61bd81[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Thu Oct 19 12:34:51 2017 +0200

    WL#8069
    Introduced a last seen in scans in DBLQH. Used this to track
    LCP scans, NR scans and Backup scans. If they stall for more
    than 10 seconds a printout in the node log will be done,
    indicating the [1;31mtime[m of the stall and what line it stalled on.
    
    Can later be used to crash nodes that are in this hang state
    for too long.

[33mcommit 6f60021227526dbf752ecde8ae0f21066405c2df[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Mon Oct 2 16:09:03 2017 +0200

    BUG#26908347: Fix for cleared [1;31mtime[mr in [1;31mtime[m tracking in complex scan frag case

[33mcommit 0978d13ce43429806418bc7f2a7aef531a0aab97[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Thu Jul 27 12:09:31 2017 +0200

    WL#8069: LCP watchdog fired due to long LCP that was closing LCP control files for idle LCP every [1;31mtime[m it checked, fixed by adding table and frag id for this state as well

[33mcommit 49306d0125177bf1e2035df0577aa294fa294d81[m
Author: Sreeharsha Ramanavarapu <sreeharsha.ramanavarapu@oracle.com>
Date:   Mon Nov 13 06:23:01 2017 +0530

    Bug #27041382: ASSERTION `!TABLE->IN_USE->IS_ERROR()'
                   FAILED.
    
    Issue:
    ------
    When a trigger contains incorrect syntax and the
    subsequent INSERT doesn't have any column-list specified,
    inserting a new row shouldn't be attempted. But this
    happens and it hits an assert.
    
    Solution:
    ---------
    check_for_broken_triggers() raises this problem but the
    return code is ignored by
    prepare_triggers_for_insert_stmt(), since this function
    only returns a void.
    
    Fix will be to move Table_trigger_dispatcher::mark_fields()
     (which eventually calls check_for_broken_triggers()) into
    the Sql_cmd_insert_base::prepare_inner() similar to the way
    it is done in UPDATE. This way, we won't be executing for a
    long [1;31mtime[m with an unhandled exception.

[33mcommit b2417c6de436f059a3bb88ac5a5f91fcc468d330[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Thu Nov 2 11:23:14 2017 +0100

    WL#11158: Step 3:
    Modify TRIX to use the configured maximum schema object batch size for
    UI builds.
    Other SUB_SYNC_REQ requestors are left as-is for the [1;31mtime[m-being.
    TRIX is modified rather than DICT as :
     - Only UIs have an incoming parallelism parameter, the other
       request types do not...
     - Not clear that DICT is the correct place to determine the
       parallelism to use
    A full solution should decide on the above, potentially increasing
    parallelism for other build types based on config or other inputs.

[33mcommit b1dc7aedca8358f5286c0172ea2c9a247cdf9ca8[m
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Thu Nov 9 15:10:51 2017 +0530

    Bug#25998513: FILE OPERATIONS IN MYSQLTEST FAIL ON WINDOWS
    
    Issue:
    ------
    A few tests have been failing on Windows when file operations
    such as move_file and remove_file fail.
    
    Fix:
    ----
    - Added the retry parameter to the mysqltest command in  one test
      script to retry the operation a specified number of [1;31mtime[ms.
    
    - Increased the retry parameter to the mysqltest command in two test
      scripts to retry the operation a specified number of [1;31mtime[ms.
    
    Change-Id: Ie846a4a090586e51d172a5078c719544881ed227

[33mcommit a18d3eda8153946cebf380903328c0af10c86631[m
Author: Satya Bodapati <satya.bodapati@oracle.com>
Date:   Tue Oct 31 13:02:38 2017 +0530

    Bug#26995951 - REGRESSION IN SERVER STARTUP TIME
    
    Problem:
    -------
    As part of Bug#26832347 - INNODB: CANNOT FIND SPACE FOR TBS_.*_RENAME IN
    TABLESPACE MEMO, an extra iteration of dd::Tablespaces is introduced to
    fix the cache.
    
    Fetching dd::Tablespaces is taking 1min for 1Million tablespaces.
    This increased the startup [1;31mtime[m
    
    Fix:
    ----
    Avoid the tablespaces fetch & cache update if there are no prepared
    trxs.
    
    Note: We cannot use trx_sys->n_prepared_trx at
    dd_tablespace_update_cache() because binlog would have
    committed/rolledback the prepared trxs by the [1;31mtime[m we are at
    dd_tablespace_update_cache(). It would be always 0. So we need to
    introduce extra bool to detect the presence of prepared trxs.
    
    Reviewed-By: Bin Su <bin.x.su@oracle.com>
    RB: 17805

[33mcommit 2d9d74f9c29b6c78ddab75772ff8daeda4c2dc66[m
Author: Ashish Padiyar <ashish.padiyar@oracle.com>
Date:   Tue Nov 7 12:11:14 2017 +0530

    Bug#26965866: MYSQL_UPGRADE_GRANT.TEST RUNS TOO MUCH, CAUSING TIMEOUT
    
    Issue:
    ------
    mysql_upgrade_grant test was timing out quite often on solaris11-sparc-64bit
    in 8.0+ branches. The test runs for a considerably long [1;31mtime[m on other platforms
    as well.
    
    Fix:
    -----
    --source include/big_test.inc was added to make the test a big test.

[33mcommit 84091e8d346f6399d72031e297250cff9e3c877c[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Tue Nov 7 09:28:21 2017 +0800

    Bug #25694140  THE IMPLEMENTATION OF QUERYING P_S.REPLICATION_APPLIER_FILTERS IS SUBOPTIMAL
    
    When querying performance_schema.replication_applier_filters or
    performance_schema.replication_global_applier_filters tables,
    it generates a view on the filters for every row that is
    created. This is suboptimal.
    
    We implement the best approach to make sure that the P_S view over
    the filters is generated only when the filters are changed. To
    per-channel replication filters, actually increasing counter does
    not change the structure of the P_S view. So we should hold the
    write lock of rpl_channel_filters to generate the P_S view only on
    startup, on CHANGE REPLICATION FILTER, on RESET SLAVE ALL, and on
    CHANGE MASTER to ..., then we just need to hold a read lock of
    rpl_channel_filters to read the P_S view while querying
    P_S.replication_applier_filters. To global replication filter,
    we should hold the write lock of Rpl_global_filter to generate
    its P_S view only on startup and on CHANGE REPLICATION FILTER,
    then we just need to hold a read lock of Rpl_global_filter to read
    its P_S view while querying P_S.replication_applier_global_filters.
    At the same [1;31mtime[m, we optimize the code to create a derived class
    of class Rpl_filter for global replication filter and fix a prone
    issue.

[33mcommit 5786d084717ef87454ac05f0d6208e872ebaf762[m
Author: Ashish Padiyar <ashish.padiyar@oracle.com>
Date:   Mon Nov 6 18:04:38 2017 +0530

    Bug#26965866: MYSQL_UPGRADE_GRANT.TEST RUNS TOO MUCH, CAUSING TIMEOUT
    
    Issue:
    ------
    mysql_upgrade_grant test was timing out quite often on solaris11-sparc-64bit
    in 8.0+ branches. The test runs for a considerably long [1;31mtime[m on other platforms
    as well.
    
    Fix:
    -----
    --source include/big_test.inc was added to make the test a big test.

[33mcommit ff1420f5892e40b1dcca7c887f936ef462c20d40[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Fri Oct 20 15:49:38 2017 +0200

    Bug#20964700: RECURSION OF ITEM_FUNC::WALK LEAD TO STACK OVERFLOW
    
    Constant propagation is some[1;31mtime[ms too eager and creates cycles in the
    Item tree, which again leads to infinite recursion when the Item tree
    is processed.
    
    This patch skips constant propagation when the constant expression
    contains a reference to the column it is meant to replace, thus
    avoiding the creation of cycles in the Item tree.

[33mcommit 65bb451034ab20d0c35c62de568027bb7fd7f434[m
Author: Pedro Figueiredo <pedro.figueiredo@oracle.com>
Date:   Mon Nov 6 12:35:50 2017 +0000

    Bug#26926291 RPL.RPL_SPEC_VARIABLES FAILS ON PB2 SPORADICALLY
    
    Description
    -----------
    rpl.rpl_spec_variables is seen to be failing on pb2 sporadically
    Error output is:
    
        rpl.rpl_spec_variables 'mix'             w19 [ fail ]
            Test ended at 2017-09-29 21:39:59
    
        mysqltest: In included file ./include/sync_slave_sql.inc at line 151:
        included from ./include/sync_slave_sql_with_master.inc at line 79:
        included from ./mysql-commercial-9.0.0-dmr-linux-x86_64-valgrind/mysql-test/suite/rpl/t/
           rpl_spec_variables.test at line 204:
        At line 150: Error in sync_with_master.inc
    
        ERROR: sync_slave_sql.inc failed on connection 'slave'
        ERROR: use_gtids='0'
        ERROR: _saved_gtids=''
        ERROR: _saved_file='master-bin.000001'
        ERROR: _saved_pos='815297'
        ERROR: _saved_channel_name=
        ERROR: [1;31mtime[mout='300'
        ERROR: result='-1'
        ERROR: error type: Timeout after 300 seconds.
    
    Analysis
    --------
    - Could not replicate the problem locally.
    - Tested several 'mtr' options to slow down the process, etc, with no
    success in replicating the problem.
    - Tested some visible points of failure:
      . Heap max limit exceeded with ENGINE=MEMORY,
      . Inserting 2000 records and synchonize might take more than 300 secondsm
      . I/O thread stops,
      but would fail every [1;31mtime[m and not sporadically.
    - Test fails with the --repeat > 1, due to the usage of a --copy_file command
    without validation for the existance of such files in the destination dir. The
    --copy_file command does not allow file override and files if the destination
    files already exist.
    
    Fix
    ---
    - Reduce the amount of records inserted in order to ensure that the [1;31mtime[mout interval
    isn't, in fact, being reached.
    - Add config variables, for:
      * record count, '$row_count'
      * heap size, '$heap_size'
      * record size, '$record_size'.
    - Making '$record_count' dependant of the division of the other two variables.
    - Replace --copy_file with --copy_files_wildcard, which allow file to be
    overwritten
    
    Notes
    -----
    - '$record_size' may hold any value, it all depends on the amount of records
    one whishes to insert in the tables.

[33mcommit 2cbd4501a139bb65cee3135874b8caaa2d1730cc[m
Author: Hemant Dangi <hemant.dangi@oracle.com>
Date:   Fri Nov 3 20:37:11 2017 +0530

    Bug#26435775: START AND STOP GR HANGS AFTER NO SPACE LEFT ON DEVICE ERROR
    
    Issue:
    ======
    When user tries to kill the START GROUP_REPLICATION thread which is blocking
    for very long [1;31mtime[m, it changes its state to killed but it still doesn't die.
    Such a case is when the applier module initialization is waiting for disk
    space. Also the user is not able to execute new START/STOP GROUP_REPLICATION
    query, as they also blocks on lock (plugin_running_mutex).
    Internally, START GROUP_REPLICATION thread acquires a lock (plugin_running_mutex)
    which it only release when it finishes. And when user tries to kill any thread
    in MySQL it doesn't kill the thread, just set its THD::killed state to either
    of THD::killed_state. As we wait for the applier module to start without looking
    at the thread state, the start group replication procedure is stuck. So till this
    START GR thread release the plugin_running_mutex lock, the user can't stop group
    replication or start a new one.
    
    Solution:
    =========
    The start group replication thread waits for applier to complete.
    We change its blocking wait to [1;31mtime[mdwait where it can check THD::killed
    state after every 1 second, and if it finds that thread has been killed,
    it comes out of wait loop.

[33mcommit 5892c502b46bf0dffe6afcb6b4b079d48c46d94d[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Thu Oct 19 10:18:08 2017 +0200

    Bug#26739438: DEADLOCK ON GET_LOCK(..., 0)
    
    Problem: Concurrent calls to GET_LOCK could cause deadlock, even with
    a wait [1;31mtime[m of 0.
    
    Root cause was that MDL_context::acquire_lock() would add the ticket
    as waiter and perform deadlock detection analysis even when the wait
    [1;31mtime[m was 0.
    
    Solution: Return error immediately if lock cannot be obtained and wait
    [1;31mtime[m is 0.
    
    (cherry picked from commit c528fee7d9c8186bcc14549f62b1f835ab01c0c5)

[33mcommit 09783de0079e47ecf085a9ce5cdc1a4558bfe50f[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Thu Oct 19 10:18:08 2017 +0200

    Bug#26739438: DEADLOCK ON GET_LOCK(..., 0)
    
    Problem: Concurrent calls to GET_LOCK could cause deadlock, even with
    a wait [1;31mtime[m of 0.
    
    Root cause was that MDL_context::acquire_lock() would add the ticket
    as waiter and perform deadlock detection analysis even when the wait
    [1;31mtime[m was 0.
    
    Solution: Return error immediately if lock cannot be obtained and wait
    [1;31mtime[m is 0.

[33mcommit ee606e62bbddd7ac3579b4a20ef8684fa7cd83fe[m
Author: Krzysztof Kapuścik <krzysztof.kapuscik@oracle.com>
Date:   Thu Oct 26 11:34:41 2017 +0200

    BUG #26818787: ASSERTION: DATA0DATA.IC:430:TUPLE
    
    Fix for an issue with purge of secondary index with virtual and
    externally stored column(s). If new record was being inserted
    at place of a deleted one (insert by modify) and purge was trying
    to build index entry from that record at the same [1;31mtime[m a NULL
    was returned by row_build_index_entry and then used.

[33mcommit 884eb149ba42db68f98b4926c034f1af7b354f6d[m
Author: Jaideep Karande <jaideep.karande@oracle.com>
Date:   Wed Nov 1 18:00:51 2017 +0100

    BUG#26023928: PB2 TEST CASE FAILURE GROUP_REPLICATION.GR_CORE_REPLICATION_COMMANDS
    
    Problem: GR_CORE_REPLICATION_COMMANDS is failing randomly on PB2
    
    Description: Observed post load and applier channel stop some[1;31mtime[m one of member
    is getting expelled.
    We know this issue can be see due to 5 seconds [1;31mtime[mout.
    Issue has not been seen since 27 September on PB2.
    
    Resolution:
    Test case is not related to work load testing.
    Test case has been modified to reduce work load from 1500 to 150 inserts.
    Applier START/STOP has also been modified.
    This reduced test case execution timing.
    On server where test case used to execute in 97 seconds now test finishes in
    82 seconds.

[33mcommit 312a9d385f129a3803a0d2bc70e4b23ede72d30b[m
Author: Nuno Carvalho <nuno.carvalho@oracle.com>
Date:   Wed Sep 13 19:27:23 2017 +0200

    WL#11139: Remove group_replication_allow_local_disjoint_gtids_join option
    
    The option group_replication_allow_local_disjoint_gtids_join[1] was
    introduced with the purpose[2]:
      This variable is an override mechanism for a new consistency feature
      in the plugin. When you try to add to the group a server that has
      more data than the existing members, by default the joining member
      will be rejected.
      The purpose is to avoid possible recovery and run [1;31mtime[m errors in
      the plugin leading to data divergence and other issues. If you are
      sure of what you are doing, and that the extra data is safe, then
      you can use this option.
    
    The scenarios on which this can help users are:
    
     S1) Solve a broken majority asap
         * Group had 3 members in single-primary mode
         * 2 members crashed and end up with different data
           (GTID_EXECUTED) when compared with the group.
         * User wants to add one of the members (S2) to solve the
           majority loss or increase group members number to handle
           possible future member failures.
         * The member that is still on the group is the one that is the
           primary or will be elected as primary when majority is
           re-established, since is the only one ONLINE.
         * The group will be stable if a future failover does not switch
           to the S2 member.
    
    The run[1;31mtime[m errors that may happen are that the member which did
    force the join with disjoint GTIDS, if it does a write, the changed
    rows will never be updated by other members. Certification will
    fail.
    The recovery errors that may happen are that if this member is
    chosen as donor, it will distribute the disjoint GTIDS among the new
    members and increase the likelihood of the run[1;31mtime[m errors to happen.
    
    It must never be used unless the DBA knows exactly what she/he is
    doing or does need to solve a broken majority, on which crashed
    members suffered corruption and she/he will not perform writes on
    it. Which can already be done by resetting master and setting
    GTID_PURGED to match the GTID executed of the group if they really
    want to add the damaged server to the group.
    
    People use this option to force member join, and assume that since
    member did successfully join everything is OK. Which is not the
    case, data is inconsistent.
    
    The correct procedure to fix a majority loss is described at
    https://dev.mysql.com/doc/refman/8.0/en/group-replication-network-partitioning.html
    
    Since the trade-off between this option benefit vs danger is
    negative, we are removing this option.

[33mcommit e6a2f0522bde437775011db951ed53a16b3884f6[m
Author: Pedro Figueiredo <pedro.figueiredo@oracle.com>
Date:   Tue Oct 31 10:49:29 2017 +0000

    Bug#20818704 BINLOG_WAIT_FOR_EXECUTED_GTID_SET_INTERRUPT FAILS SPORADICALLY WITHQUERY REAP
    
    Description
    -----------
    binlog_wait_for_executed_gtid_set_interrupt.test  Fails sporadically on
    Daily-trunk, here is the failure log:
    
        binlog.binlog_wait_for_executed_gtid_set_interrupted 'row' w7 [ fail ]
        Test ended at 2015-04-01 22:41:07
    
        CURRENT_TEST: binlog.binlog_wait_for_executed_gtid_set_interrupted
        mysqltest: At line 34: query 'reap' succeeded - should have failed with errno
        1317...
    
        The result from queries just before the failure was:
        RESET MASTER;
        CREATE TABLE t1 (c1 INT NOT NULL PRIMARY KEY) ENGINE=InnoDB;
        INSERT INTO t1 VALUES (1);
        SELECT WAIT_FOR_EXECUTED_GTID_SET('MASTER_UUID:4', 100);
        DROP TABLE t1;
        KILL QUERY CONNECTION_ID;
    
    Analysis
    --------
    - The purpose of the test is to check if the ER_QUERY_INTERRUPTED error number is
    returned when a connection is killed with 'KILL QUERY' when 'WAIT_FOR_EXECUTED_GTID_SET'
    is active.
    - The 100 seconds [1;31mtime[mout maybe being reached due to overload on the machine.
    - No other race condition seems to be plausible to happen on the given test.
    
    Fix
    ---
    - Increase the [1;31mtime[mout on 'WAIT_FOR_EXECUTED_GTID_SET' to a very high value, in
    order to ensure that the the function exists due to the 'KILL QUERY' statement.

[33mcommit 0e132604bec77f9c48c8dd02de871d06bdccebc3[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Wed Oct 25 23:31:02 2017 +0530

    Bug#26944731 : UPGRADE TO 8.0 FAILS: DUPLICATE SET VALUES IN TABLE FROM
                   A PERMISSIVE SQL_MODE..
    Bug#26948678 : MYSQLD: INVALID DEFAULT VALUE FOR 'CACHED_TIME'
    
    1> In-place upgrade from 5.7 fails when server is started with
       --explicit-defaults-for-[1;31mtime[mstamp=0 in creating dictionary tables
       with error: Invalid default value for 'cached_[1;31mtime[m'
    
    2> In-place upgrade from 5.7 fails irrespective of user provided sql
       mode if SET data type has duplicated values with error:
       Column <column_name> has duplicated value <value> in SET
    
    3> --initialize with --explicit-defaults-for-[1;31mtime[mstamp=0 to
       create new data directory fails in creating performace schema
       'variables_info' table with error:
       Invalid default value for 'SET_TIME'
    
    Fix:
    -----
    1> Set explicit-defaults-for-[1;31mtime[mstamp to true for the bootstrap thread.
       Dictionary tables and performance schema tables are created from
       bootstrap threads. This will allow dicitonary and performace schema
       table creation by following the standard behavior for [1;31mtime[mstamp data
       type.
    
    2>  While migrating tables, mysql_prepare_create_table() is called which
        checks for duplicated value in SET data type. Error is reported for
        duplicated values only in strict sql mode. Set sql_mode to ZERO when
        populating data dictionary for in-place upgrade.

[33mcommit 556d45deb2d3c8180c5df483f056b0fe53bf82fb[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Tue Oct 24 22:32:59 2017 +0200

    Bug#26188578 Bug#26164633 Bug#26360114 Bug#26781725 Bug#26848089 Regressions with WL#9236
    
    Bug#26188578 WL#9603: HAVING CONDITION IS OPTIMIZED OUT FOR ALIAS ON AGGREGATE W/O GROUP BY
    Bug#26164633 WL#9603: WRONG RESULT WHEN PARTITION EXPR USING AGGREGATES EVALUATES TO NULL
    Bug#26360114 WRONG RESULT WITH AGGREGATE AND HAVING CLAUSE IN VIEW
    Bug#26781725 INCORRECT RESULTS FOR QUERY(MAX FUNC+HAVING CLAUSE) WHEN USED INSIDE VIEW
    Bug#26848089 LEAD/LAG WINDOW FUNCTIONS ON QUOTED JSON STRINGS RETURNS SAME VALUE FOR ALL ROWS
    
    Regressions introduced by changes to Item_ref done in the patch for
    window functions (WL#9236).
    
    Background of existing design before the WL of window functions:
    
    - Item_ref is very old design which was introduced for SQL clause
    HAVING, when HAVING references an item of the SELECT list through an
    alias. It points to an Item ('ref' pointer). When there is a tmp table
    involved in the execution (e.g. GROUP BY before HAVING), we may
    calculate a SELECT list expression (let's say it's an Item_func) and
    store it in the tmp table in the group's row. The
    tmp table's column where it's stored is known as the Item's result_field.
    If HAVING references that expression through an alias, HAVING contains
    Item_ref with a 'ref' pointing to the Item_func. When evaluating
    HAVING, we want to use the already calculated value of Item_func
    (_not_ evaluating the Item_func again, as it may not be deterministic),
    we do that by looking at the value stored in ref->result_field.
    That is why Item_ref::val_int calls ref->val_int_result(), not
    val_int().
    - So the system is relying on the capacity of Item_ref to
    automatically pick the stored value.
    - While that sounds ok for queries with no or only one tmp table, it
    is not enough for more complex queries
    - hence, a second design: "ref item slices": in different phases of
    execution (simply: depending on which table, tmp or non-tmp,
    we're reading now), a same SELECTed expression is represented by
    different Items: it may be SUM initially (Item_sum), then, once
    calculated (with Item_sum::val_int()) and stored in a tmp table with
    one row per group, it becomes Item_field (a column of the tmp
    table). After all groups have been written, if a filesort is used
    to do a final ORDER BY, that sort must call the Item_field's val_int,
    not the Item_sum::val_int which is just the value of the last group.
    - So, depending on which table we're reading now, the SELECTed
    expression is one object or another; for that, we wrap the expression
    in Item_ref, with 'ref' pointing to a place (a cell in the "ref item
    slice"), and at this place we deposit a pointer either to the original
    Item_sum or to the tmp table's Item_field, depending on the phase
    we're in.
    Phases are identified by numbers (grep for the REF_SLICE enum).
    
    With the advent of window functions, more tmp tables are used, and
    form a chain. The fact that Item_ref::val_int always reads ref->result_field
    (i.e. what was saved in the next tmp table) some[1;31mtime[ms leads to reading
    not-yet-calculated data from the next tmp table.
    For example, if we have an Item_func I_F, and a tmp table used for windowing,
    and we have an Item_ref I_R to the I_F (HAVING always creates an
    Item_ref), and before the tmp table is written we use I_R::val_int,
    that gets the value of I_F->result_field, reading random data from the
    tmp table. Such I_R::val_int() (or val_int_result(), equivalently)
    could occur in filesort(), for example.
    HAVING is one problem; but the ORDER BY clauses of windowing also use
    Item_ref; and aggregate functions also do (if involved in a more
    complex expression, see Item::split_sum_func2). Aggregate functions
    may be used as arguments to windows, so, depending on the phase,
    Item_ref should pick the aggregate function's value or its saved
    value, which it can't do. The behaviour of Item_ref of "always reading
    the result_field", combined with the increased number of tmp tables,
    made things harder to manage than they used to be.
    
    So things are refactored in this patch:
    - Item_ref::val_(int,etc)() just calls ref->val_(int,etc)(), doesn't
    read ref->result_field anymore
    - when you are reading QEP_TAB Q and want to evaluate an expression
    which depends on values stored in Q and previous tables in the
    execution order, switch to Q->ref_item_slice slice: it will switch to
    Items which point into Q's table.
    - when you are doing a GROUP BY where grouped rows are not
    materialized in a tmp table (because rows are produced in group order
    by the join), a pseudo-tmp table buffer is used (no change here); if
    you want to evaluate an expression which depends on values
    stored in this buffer, use the REF_SLICE_TMP3 slice.
    - the reads above include: sorting the table, evaluating a condition
    on the table, etc.
    
    Changes:
    
    All val_*result() are removed.
    So Item_ref::val_(int,etc) calls ref->val_(int,etc), not
    val_result. Thus, "ref" needs to be "advanced by one step", as we
    don't look into "its result already stored into the next tmp
    table", anymore. So ref slices are "advanced by one  step" during
    execution.
    Unchanged meaning of "the current ref slice of JOIN":
    it's still the "ref"s (targets) for Item_refs when evaluating Items in
    the current phase of execution.
    Unchanged meaning of QEP_TAB::ref_item_slice: the
    it's still the "ref"s (targets) for Item_refs when evaluating Items
    when reading this QEP_TAB.
    Exception: QEP_TAB::ref_item_slice is not anymore set to
    REF_SLICE_TMP3, as that latter slice is never the one to use to read
    from any QEP_TAB; it's the one to use to read from a pseudo-tmp-table
    of GROUP BY. A consequence is that we cannot use
    QEP_TAB::ref_item_slice to switch to REF_SLICE_TMP3 anymore, so we use
    a new member JOIN::before_ref_item_slice_tmp3 for that.
    Almost all execution functions need to advance to the right slice
    before they read a table.
    
    QEP_TAB::all_fields and QEP_TAB::fields are removed: we can get the
    same information from QEP_TAB::ref_item_slice, using new function
    JOIN::get_current_fields().
    
    class Item:
    all val_x_result() are gone, all calls to them replaced with val_x().
    Item_ref made to behave like Item_direct_ref; thus, Item_direct_ref
    removed and replaced with Item_ref.
    
    Item_field::save_in_field_inner() (item.cc):
        after the changes done to fix_inner_refs() in this patch,
        for the materialization of some IN subquery, we use store_key_item
        to store the left args of the IN subquery,
        while we used to use store_key_field (see comment about fix_inner_refs);
        these left args are indeed outer refs belonging to a grouped query;
        store_key_field() takes its source in Item_field::field;
        store_key_item() rather uses Item_field::save_in_field_inner()
        which takes its source in Item_field::result_field, which assumes
        this field contains the up-to-date value. This logic sounds
        strange and the present patch uses the "field" member as source,
        instead. Perhaps the old logic was necessary when ref slice wasn't
        "advanced one step" as we do now. The modified code is from before
        2000 so we cannot know more about its reason.
    
    item_subselect.cc: ref_by[1] introduced (see explanation there). So we
    now have two "ref_by" pointers; it's then difficult to pass both as
    arguments to split_sum_func2 in sql_resolver.cc so we let
    split_sum_func2 find pointers itself.
    
    sql_join_buffer.cc: assert that we needn't switch slice, because we never
    use join buffer on a tmp table. Removed useless switch.
    
    JOIN::set_ref_item_slice(): as we use it more now, make it do nothing if
    slice number doesn't change (optimization).
    Switch_ref_item_slice: now it's used in one case where the said slice
    may or not exist, so I make the object a no-op if the slice doesn't
    exist.
    
    JOIN::set_group_rpa: not needed anymore as set_ref_item_slice()
    detects when sliceno doesn't change so we can call it repeatedly;
    removed.
    
    SELECT_LEX::fix_inner_refs(): simplified as Item_direct_ref and
    Item_ref are one now, no need to choose between the two.
    
    sql_select.cc:get_store_key():
    there was an "else if" branch special for DIRECT_REF.
          else if ((*(Item_ref**)(item_ref)->ref)->ref_type()
                   == Item_ref::DIRECT_REF &&
                   item_ref->real_item()->type() == Item::FIELD_ITEM)
                   field_item= static_cast<Item_field*>(item_ref->real_item());
    It was specific of an outer reference belonging to a query with GROUP
    BY. It relied on the two different types of Items created in
    fix_inner_refs(). I remove this because it's not possible anymore to
    distinguish Item_ref from Item_direct_ref (they're one now), and the
    distinction is necessary to make this 'else' work. Likely it makes us
    pick store_key_item() instead of store_key_field(), in this outer-ref
    case, which is acceptable.
    
    sql_select.cc: reset_wf_result_fields(): removed.
      More info about the problem that required this function:
      select from (select WF1 over w1, WF2 over w2) dt;
      where "dt" is materialized. First the "dt" table structure is created with
      create_tmp_table() and that sets WF{1,2}->result_field (pointing into
      columns of "dt"). Then the inner subquery is optimized, that calls
      create_tmp_table() for the two windows. First for w1: WF1 is to be
      calculated in w1 so a column is added for its result in the tmp table; so
      its result_field gets re-set to point there, all fine. Continuing with the
      creation of wf1, WF2 is skipped. Then change_to_use_tmp_fields() sees that
      WF1 and WF2 have a result_field (see test
      'else if ((field= item->get_tmp_table_field()))'), so concludes that the ref
      slice used to read the tmp table of w1 should contain Item_fields for WF1
      and WF2; that's incorrect for WF2, and leads to WF2 never being calculated.
      My fix: in create_tmp_table(), when the destination table is to materialize
      a derived table / UNION (i.e. is not a group-by/windowing table), there's no
      reason to set result_field (results are not saved by this means anyway, but
      by Query_result_union::send_data() which reads the last table of the query
      and writes that to the materialized table), so don't set it.
    
    sql_select.cc: JOIN::make_tmp_tables_info():
          Complement to comment "Exit the TMP3 slice": failing test was
          main.func_group, consider:
          SELECT (SELECT COUNT(DISTINCT t1.b)) FROM t1 GROUP BY t1.a;
          When evaluating COUNT(DISTINCT t1.b): we copy t1.b to tmp table used by
          COUNT(DISTINCT) (i.e. tmp table of Aggregator_distinct):
          for that we must copy t1.b from JOIN's result, not from TMP3 slice:
          indeed TMP3 was filled when we switched to a new group (see
          end_send_group), so it contains the value of t1.b for the first row of
          the group; while COUNT(DISTINCT) wants the value of the current row (or
          it would think all rows of group have same value of t1.b). So the
          copy_field to the COUNT(DISTINCT) tmp table must take its source in
          JOIN, so ref slice must not be TMP3 in setup_sum_funcs.
          Alternatively, I tried to let COUNT(DISTINCT) read from TMP3, so I had
          to update t1.b in TMP3 for every read row but:
          - it broke the undocumented behaviour that "for a non-functionally dependent
          column in group we choose first row"
          - it broke other tests
    
    sql_executor.cc:
    simplified slice switching: switch, when about to read a table, to the
    Items which point to this table; in practice it means:
    - before reading first row (as it may start with a filesort, which may
    have to evaluate some ORDER BY expression on the table); slice switch
    remains in force for next rows too
    - for tmp tables: before evaluating HAVING; even a bit earlier: before
    copy_fields() (see comment in end_send_group())
    - copy_funcs(): no need to calculate functions in two passes, anymore;
    so tmp_table_param::hidden_func_count is removed (was added by the WF
    WL). Proper order is given by sort_copy_func() now.
    - setup_copy_fields(): no need for special case for Item_aggregate_ref,
    said Evgeny; indeed I don't understand why it still would be needed:
    as Item_ref::val_* just evaluates the referenced Item_field (doesn't
    look at result_field), we can just copy the underlying Item_field.
    - complement to comment "As GROUP expressions have changed" at *end* of
    end_send_group():
            Fixes test: main.group_by, query:
            select a, round(rand(100)*10) r2, sum(1) r1 from t1 where a = 1 group  by a
            having r1>1 and r2<=2;
    - complement to comment "We have created a new Item_field" in
    setup_copy_fields():
                The only new thing is below: let 'item->field' allow access to
                REF_SLICE_TMP3. This won't disturb the Copy_field as it has cached
                field->ptr (in copy_field->set()) before the change to
                'item->field' below.
                Why this change: because when we are in slice TMP3 (end_send_group), to
                evaluate HAVING we use Item_ref::val_int() which doesn't anymore use
                ref->val_int_result() but ref->val_int() instead: and
                Item_field::val_int() uses 'field' not 'result_field' so the
                Item_field here must have valid data (i.e. TMP3) in its 'field'.
    - change in QEP_TAB::remove_duplicates(): the function
    used (this-1)->fields. Now that I get rid rid of this member, I found
    a way to do without it: it was used to count hidden fields in 'this';
    I replaced the counting with the existing hidden_field_count.
    - assertions of type:
      this != join()->before_ref_item_slice_tmp3
    are added to make sure that only well-identified functions read from
    REF_SLICE_TMP3.
    
    sql_tmp_table.cc:
    - don't set result_field when it doesn't make sense;
    removes the need to clear it later (i.e. removed
    reset_wf_result_fields()).
    - as we can now create a tmp table by using as source the fields of slice
    REF_SLICE_TMP3, which don't point in a real table::record[0], fixed the
    "move_field" logic in calculation of the field's default value.
    - added sort_copy_func() to evaluate Copy_func-s in proper order (see
    comment there); uses new function Item_ref::contains_alias_of_expr()
    (item.cc); requires to replace Item* pointer in Func_ptr_array with a
    pair of Item* and alias-of-expr property: class Func_ptr.
    - complement to comment "Let each group expression know"
          it is needed to fix Bug#26475312. Indeed, the scenario was (see
          test in window_functions_bugs.test):
          - for group-by write to a tmp table tmp1
          - there is no group aggregate function (so this GROUP BY is there only
          to make distinct groups) so we use end_write() with a duplicate
          elimination in tmp1
          - the concatenation of group expressions is too long to make it a unique
          key so we use a "unique constraint" (hash_field) instead
          - after tmp1 there is tmp2 for windowing.
          - in end_write() we do check_unique_constraint(); after checking
          hash_field it gets a "candidate duplicate"; to check it more thoroughly
          we use group_rec_cmp() to compare the two rows; this function finds the
          value of group expressions in each row; for that it evaluates the
          expressions; but (after the refactoring) the slice we're at is that of
          tmp1 (not of the table before tmp1, anymore); the expression is
          thus a Item_field with 'field' in tmp1; and 'result_field' in tmp2; when
          group_rec_cmp() used get_tmp_table_item() on this Item_field it returned
          result_field i.e. group_rec_cmp() was reading in tmp2, wrongly.
          The fix is the make group_rec_cmp() find the proper 'field'. We record
          it below. Note that it was recorded in the old code too, but not if using
          hash_field (see branch "if (group && !using_unique_constraint)").
          - I also changed unique_hash_group like group_rec_cmp as they looked
          similar.
    - complement to comment "Get the value from default_values":
            Using move_field_offset(diff) below assumes that orig_field->ptr
            points into record[0], which may not be the case. Example:
            - we are creating a tmp table to materialize the query's result, for a
            PS cursor
            - the last table of the query, i.e. input to the cursor's tmp table,
            is the result of GROUP BY, so here 'fields' is items of
            REF_SLICE_TMP3
            - so orig_field is from REF_SLICE_TMP3, it was created by
            setup_copy_fields() from table->field[x] and its ptr points to a
            temporary memory area.
            Conclusion: so we rather use orig_field->table->field[x] which is
            properly in record[0].  By adding 'diff' to ptr we point that field to
            its default value.
            Fixed mysql_client_test.test (precisely the test for bug 11904 there).
    
    table.h: st_order::field renamed to clearer name field_in_tmp_table.
    
    New MTR test bits for better coverage of modified code.
    Tests for the four fixed bugs.
    
    having.test: UPDATEs to the series table are added to make sure a
    failing section doesn't make other following sections fail.
    
    Change-Id: I9775573b821886932b48b08c5ae9ece12e249e71

[33mcommit 66db91a666ce7b425438d991d410a9e396c0065e[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Thu Oct 19 10:51:12 2017 +0200

    Bug#25190109 AFTER WINDOW FUNCTIONS ARE PUSHED, SIMPLIFY SOME CTE CODE
    
    In the implementation of window functions, we extended HEAP_POSITION
    which makes the need for allow_scan_from_position go away
    (see change in sql_tmp_table.cc).
    Practical consequence: in a recursive CTE with UNION DISTINCT,
    and if there are lots of columns in the CTE, so that their total
    length was bigger than a few hundred bytes, we were forcing the
    CTE's tmp table to be innodb, now we don't anymore, it will be
    MEMORY.
    
    Also, window functions were developed to work with both MEMORY
    and Temptable as internal engine; but right before the release of WF
    there was a MTR test [1;31mtime[mout which led us to force Temptable; later
    investigation showed that the failure was just a wrongly sized
    max_heap_table_size, so there was nothing to worry about,
    so we re-enable MEMORY for WFs.

[33mcommit b25ac043da4dda40b7f0e8d36ec1bd68cca7b02d[m
Author: Athreya Permunda <athreya.permunda@oracle.com>
Date:   Fri Oct 27 12:25:07 2017 +0530

    Bug #27009386 SOME NDBAPI EXAMPLE PROGRAMS DO NOT CLEANUP DATA, TABLE BEFORE EXIT
    
    The ndbapi_array_simple and ndbapi_array_using_adapters example programs fail to run
    when tried to run more than once. This is because the program fills the respective
    table with tuples when run the first [1;31mtime[m and tries to insert the same tuples when
    run again, thus giving an error that the tuples already exist.
    code: 630, msg: Tuple already existed when attempting to insert.
    
    Fix:
    After inserting and reading the tuples of the tables, perform a cleanup, i.e., delete
    all tuples in the tables.

[33mcommit 7d4ef451ec0af1d6a425481c55fbdb9a67c337b9[m
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Thu Oct 26 08:45:38 2017 +0530

    Bug#24671890: ENHANCE THE METHOD REMOVE_FILE IN MTR
    
    Issue:
    ------
    File operations in MTR tests fail some[1;31mtime[ms due to environmental
    issues on certain platforms. To overcome this problem, a retry
    argument was requested for the file operations.
    
    Fix:
    ----
    Six file operations in MTR now have an optional retry argument,
    which when specified, retries the operation a given number of
    [1;31mtime[ms at an interval of one second each. remove_file, move_file,
    file_exists, remove_files_wildcard, copy_files_wildcard, and
    copy_file have this optional argument.
    
    The usage is as follows:
    --<file_operation> <file_names(s)> [<retry>]
    
    This fix also made the pattern argument in remove_files_wildcard
    and copy_files_wildcard mandatory.
    
    Reviewed-by: Pavan Naik <pavan.naik@oracle.com>
    Reviewed-by: Srikanth B R <srikanth.b.r@oracle.com>
    Reviewed-by: Yashwant Sahu <yashwant.sahu@oracle.com>
    RB: 16667

[33mcommit 58600169c2a7c1caee387a8d9f14db1332b64abe[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Oct 24 15:32:20 2017 +0200

    Bug #26927386: REDUCE COMPILATION TIME [noclose]
    
    Pull MYSQL_SOCKET out of mysql/psi/mysql_socket.h and into its own file;
    this means violite.h doesn't need to pull in all of PFS just to use a
    simple two-element struct.
    
    Saves about four seconds of compilation wall [1;31mtime[m.
    
    Change-Id: I899b889907a060b54ef8f806478659b7cf9aa443

[33mcommit fa854d25c36fda29c308094aa117a56cfa44e892[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Oct 24 14:53:39 2017 +0200

    Bug #26927386: REDUCE COMPILATION TIME [noclose]
    
    Re-run IWYU on unittest/gunit/test_utils.h; saves approx. 1–2 seconds
    of compilation wall [1;31mtime[m.
    
    Change-Id: Ibfab686aa7e77f5e40f234832b1ba849db033268

[33mcommit c5f10685da59a3144c9ad7cd1bc64f14af648d85[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Oct 24 13:52:51 2017 +0200

    Bug #26927386: REDUCE COMPILATION TIME [noclose]
    
    Move thd_proc_info into plugin.h (where set_thd_proc_info already resides),
    so that sql_class.h doesn't need to include plugin.h anymore. Saves approx.
    two seconds of compilation wall [1;31mtime[m, and increases incrementality.
    
    Change-Id: Ie6af0edbcd784dbe4a1721d94dcfeef1c78a6265

[33mcommit ae16bb5a8c0f415881bc82c449be5f669da00a71[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Oct 24 12:02:45 2017 +0200

    Bug #26927386: REDUCE COMPILATION TIME [noclose]
    
    Move Plugin_table into a separate header file, so that PFS table files
    do not need to include all of handler.h. Necessitated a fair amount of
    IWYU-ing in PFS, although no complete run was done.
    
    In all, saves 7–9 seconds compilation wall [1;31mtime[m.
    
    Change-Id: Ia849201fa1bed00aada57ecd0abef6b714e63db1

[33mcommit bcf9783055151bdbea58c31b0eec4587c1674677[m
Author: Pedro Figueiredo <pedro.figueiredo@oracle.com>
Date:   Wed Oct 25 14:48:23 2017 +0100

    Bug#26449236 RPL.RPL_SLAVE_REGISTER_COVERAGE FAILS SPORADICALLY ON PB2
    
    Description
    -----------
    rpl.rpl_slave_register_coverage fails sporadically on pb2, however passes on
    retry. Frequency of failure is very high. The test looks unstable. Hence
    raising a bug.
    
    Analysis
    --------
    - The test fails due to the value of 'Last_IO_Errno' column for the 'SHOW
    SLAVE STATUS' command being equal to 0
    
    - This value is retrieved both in the
    'mysql-test/suite/rpl/t/rpl_slave_register_coverage.test' file and in the
    'mysql-test/include/wait_for_slave_param.inc'
    
    - This value being equal to 0 means that the slave IO thread hasn't raised
    an error within the [1;31mtime[mout interval stored in $slave_[1;31mtime[mout varaible
    and used in the file 'mysql-test/include/wait_for_slave_param.inc'
    
    - Since the error that should be raised is one resulting from changing from
    an authorized user to an unauthorized one, it means that the slave may haven't
    synchronized with the master, yet, and might be hanging on
    
    Fix
    ---
    - Add a synchronization point after the 'CREATE USER rpl_user', by sourcing
    'include/sync_slave_sql_with_master.inc'.

[33mcommit e5d727a07c11e87b41f6de17e2fee109047fb67d[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Oct 23 11:02:50 2017 +0200

    Bug #26927386: REDUCE COMPILATION TIME [noclose]
    
    Change the PFS_NEW macro to using THR_MALLOC directly instead of going through
    the THD. Saves ~100 compilation units from including all of sql_class.h, which
    reduces compilation wall [1;31mtime[m by 5–6 seconds.
    
    Change-Id: I7839133a1f69b3cd6ea50de44ca9d39a41bedd34

[33mcommit 1e6054303067c6a2da0435bdf70b692f56ac494b[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Oct 18 16:51:42 2017 +0200

    Bug #26927386: REDUCE COMPILATION TIME [noclose]
    
    Clean up some obsolete code from m_string.h, allowing us to remove
    some unneeded #includes.
    
    Reduces the build [1;31mtime[m by a second or two, and increases incrementality.
    
    Change-Id: I23ce15c7417f55e5fb9193a769550f26e01e0e96

[33mcommit 928ab88ee922f978646a82a7b96f0ee0765ba649[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Oct 18 12:59:59 2017 +0200

    Bug #26927386: REDUCE COMPILATION TIME [noclose]
    
    Do a manual IWYU-like run over my_sys.h, removing the dependency on a lot
    of PSI files. Reduces compilation [1;31mtime[m by about six seconds, and increases
    build incrementality significantly.
    
    Change-Id: Iee360d956c2ab23b6e03d08bfa3d335fa36b4190

[33mcommit d37b65fc24b5b61f2298713e0c761d84366fdc78[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Fri Oct 20 11:21:32 2017 +0530

    Bug#26740635: DAYOFYEAR FUNC: ASSERTION FAILED: NULL_VALUE
    
    Problem:
    ASSERT fails in ::get_date_from_[1;31mtime[m as one of the function called from
    here returns true after checking for thd->is_error(). However the error
    is raised by functions called earlier which results in null_value not
    being set for this function.
    This makes the ASSERT fail as get_[1;31mtime[m() is expected to return TRUE only
    when null_value is set to true.
    
    Analysis:
    Errors are generated in the following functions, but are not propagated
    correctly because of the broken interfaces.
    Item_cond_or::val_int():
    Evaluation of the first argument to Item_cond_or raises the error and
    sets "null_value" to true as expected. But Item_cond_or does not check
    for the error. Instead it checks for null_value and continues to evaluate
    the second argument.
    While evaluating the second argument, one of its function call returns
    true because of the ERROR that was raised earlier for the first argument.
    This is not right, as ::get_date_from_[1;31mtime[m expects ::get_[1;31mtime[m to return
    true only after setting null_value to true and there by failing the assert.
    
    Item_func_bit_neg::int_op()
    null_value is not set because an integer overflow error was raised.
    
    Item_sum_bit::eval_op()
    Error is raised when an invalid json object is detected. But ::eval_op()
    is not checking for errors.
    
    Item_func_make[1;31mtime[m::get_[1;31mtime[m()
    Error is raised while evaluating the arguments. But null_value is not set
    to true as its argument's "null_value" is not set to true. One of the argument
    in the failing case is actually an Item_func_equal which considers NULL to be
    a valid value. However in this case, null_value is set to TRUE because of an
    error.
    
    Solution:
    As of now, we do not have clearly defined interfaces to return errors. So,
    for now we change the assert to also check if error has been set.

[33mcommit 4df726f8743374a55597e07fab4204bf7bf400c4[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Oct 17 14:14:28 2017 +0200

    Bug #26927386: REDUCE COMPILATION TIME [noclose]
    
    Cut the link from table.h to handler.h, by moving NESTED_JOIN into
    its own header file. Shaves a few seconds off total compilation [1;31mtime[m.
    
    Change-Id: Ie3db171befeb430c73e3bec68eabdf33ebdd1008

[33mcommit 4fa3d6a0981a21d24edb52a4537f18a339c314a6[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Oct 17 13:38:48 2017 +0200

    Bug #26927386: REDUCE COMPILATION TIME [noclose]
    
    Cut the link from mysqld.h to system_variables.h, and move sql_exchange
    out of query_result.h, which means a lot of files don't need to parse
    sql_lex.h. Together, this reduces compilation wall [1;31mtime[m by ~8 seconds
    on a quadcore.
    
    Change-Id: I9b551314142532697187273f99ab448ec8eba0aa

[33mcommit b495301ffa6585e033ba42329de7546b41c19a98[m
Author: Dmitry Shulga <dmitry.shulga@oracle.com>
Date:   Wed Oct 18 15:18:45 2017 +0700

    Bug #25185947 -- ISSUES WITH RENAMING ROOT USER
    
    When a user root@localhost is renamed to any other name an attempt
    to run the statement SHOW DATABASE results in error:
    ERROR 1449 (HY000): The user specified as a definer ('root'@'localhost') does
    not exist
    
    The reason for the bug is that as of version 8.0 handling of SHOW DATABASE
    goes to INFORMATION_SCHEMA.SCHEMATA view, that is the real view.
    
    The view INFORMATION_SCHEMA.SCHEMATA is defined as SUID view with root@localhost as definer.
    Therefore, every [1;31mtime[m a view is accessed and the view is not already in the cache an
    attempt to compile the view is made. Since the view has an invalid definer (the definer
    user was renamed) opening the view fails.
    
    In order to fix the error a new system user 'mysql.infoschema'@localhost is introduced.
    This user specified as definer for every view in information_schema. The user
    'mysql.infoschema'@localhost is locked and have only grant to select from tables/views
    in information_schema. His sole role is just to be owner of views in information_schema.
    Note that we can't use name longer than 16 characters for this user since it will complicate
    privilege tables upgrade from 5.7 versions.
    
    The side effect of introducing a new user who is owner of system view in information_schema
    is that direct upgrade of privilege tables from 5.1 to 8.0 is no more possible.
    
    The approach this patch takes is a mid-term workaround, long-term solution should involve
    tracking view dependencies on users and prohibiting user renames if there are views
    dependent on them (or updating view definitions accordingly, see also WL6359
    'Implement dependency tracking for SQL objects').

[33mcommit 06be797507c1bdf6d5602fe394f3bc38fbab30a3[m
Author: Dag Wanvik <dag.wanvik@oracle.com>
Date:   Mon Oct 16 11:15:53 2017 +0200

    Bug#26389508 INT JOIN_READ_KEY(QEP_TAB*): ASSERTION `!TABLE->HAS_NULL_ROW()' FAILED
    
    Analysis:
    
    When a window with buffering follows a equijoin on a unique index
    (JT_EQ_REF) , we can get into trouble because windowing modifies the
    input record, presuming that once the windowing has been handed the
    record, next [1;31mtime[m control passes back to the join code a (new) record
    will be read to the input record.
    
    However, this does not hold with JT_EQ_REF, cf. the caching done in
    join_read_key:
    
    From its Doxygen:
    
      "Since the eq_ref access method will always return the same row, it
       is not necessary to read the row more than once, regardless of how
       many [1;31mtime[ms it is needed in execution.  This cache element is used
       when a row is needed after it has been read once, unless a key
       conversion error has occurred, or the cache has been disabled."
    
    Fix:
    
    We solve this problem by reinstating the input record before handing
    control back from end_write_wf. We optimize: only do this if the
    window in question follows after such a JOIN, i.e. window #1, and it
    has actually clobbered the input record. This can only happen if
    the last qep_tab has type JT_EQ_REF.
    
    Another, perhaps better approach, is to refactor to never touch the
    input record but keep the copying between the out record and the frame
    table record instead. Left for future refactoring.
    
    Added some missing Window method "const"s, and folded a couple of
    one-liners into window.h (from .cc).
    
    Repro added.
    
    Change-Id: I33bc43cd99ff79303b17d181abc3805ce226fb85

[33mcommit 9074ad8893c50ce8b75ad64171981b636933d7a2[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon Oct 16 11:51:46 2017 +0200

    WL#8500 Adapt MySQL Cluster to 8.0
    
     - configure ndb_error_reporter in $bld_dir/run[1;31mtime[m_output_directory/
     - don't look for ndb_error_reporter in storage/ndb/tools/ anymore

[33mcommit e819c4c3e096b3b732f41ea18037412cecd4ed51[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Oct 16 10:32:17 2017 +0200

    Bug #26826272: REMOVE GCC 8 WARNINGS [noclose]
    
    Fix an instance of undefined behavior, where one would allocate some
    memory, cast it to an object, set some fields and then run placement
    new, where the constructor would expect those fields to still be set.
    (The code also calls a virtual member function from its constructor,
    which seldom is a good idea but at least has defined semantics.)
    
    This is undefined behavior because an object's life[1;31mtime[m starts at the
    constructor, so any stores done before that are dead and can be optimized
    away. GCC 6 and newer does so in some cases, precluding some upcoming
    warning cleanups. Fixing this UB instance allows those cleanups to
    proceed.
    
    Also fixes a leak if the second open_cached_file() should fail.
    
    Change-Id: Iddcbc71dbfe5265c89cc6d39e09746b0029140d1

[33mcommit c985a282580e1801c917a74c1b2bae5e76ad7995[m
Author: Satya Bodapati <satya.bodapati@oracle.com>
Date:   Wed Oct 4 19:20:28 2017 +0530

    Bug#26832347 - INNODB: CANNOT FIND SPACE FOR TBS_.*_RENAME IN TABLESPACE MEMO
    
    Problem:
    --------
    A crash after ALTER TABLESPACE x RENAME to y, a subsequent rename fails.
    
    When binlog is enabled, crash happens after DDL trx is written to
    binlog but before commit in engine.
    
    On startup, we create in-memory tablespace by reading from DD
    (boot_tablespaces()).
    
    At this point of [1;31mtime[m, binlog recovery is not yet over and reading from
    DD will give outdated/stale information. A fil_space_t object will be
    created with name 'x'. Post binlog recovery, the DD will have
    tablespacename as 'y'.
    
    Subsequent rename is 'ALTER TABLESPACE y RENAME to z'. DD asks SE to
    rename tablespace from y to z. InnoDB tries to look for tablespace with
    name 'y' but cannot find it. It has created the in-memory object with
    'x'. Hence, it throws error and rename fails.
    
    Fix:
    ----
    After dictionary rollback, binlog recovery and DDL_LOG replay, DD is
    consistent. At this stage, re-read all tablespace names and fix the
    cached tablespace objects (fil_space_t).
    
    Reviewed-By: Bin Su<bin.x.su@oracle.com>
    RB: 17551

[33mcommit 0f5682012aa490fa8407997b4471b08c5ef90faf[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Oct 10 09:45:53 2017 +0200

    Bug#26927607 DYNAMIC LINKING WITH OPENSSL FOR NDBCLUSTER ON MACOS
    
    Extra patch for -DWITH_NDB_TEST=1
    All executables which link with mysqlclient must be created with
    MYSQL_ADD_EXECUTABLE so that the openssl .dll / .dylib / .so
    is found at link [1;31mtime[m and at run[1;31mtime[m
    
    (cherry picked from commit b10fd56f16d58be75d1f33d06ef3f4e1f350532c)

[33mcommit a8c94e4664b8c11d1f26e6b7af488cad864bd4a2[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Sep 29 13:11:16 2017 +0200

    Bug#26927607 DYNAMIC LINKING WITH OPENSSL FOR NDBCLUSTER ON MACOS
    
    Add support for -DWITH_NDBCLUSTER=1 -DWITH_SSL=</path/to/custom/openssl>
    
    Problem:
    Linking CXX executable ndbinfo_sql
    dyld: Library not loaded: libssl.1.0.0.dylib
    
    Fix: MYSQL_ADD_EXECUTABLE does the necessary magic to find openSSL
    
    Problem:
    Linking CXX shared module ndb_engine.so
    ld: file not found:
    /Volumes/hd2/pb2/build/sb_0-23974122-1498237767.55/openssl-1.0.2k-macos10.12-x86-64bit/lib/libcrypto.1.0.0.dylib
    
    Fix: Link with the copied libraries, rather than the original ones.
    
    Problem:
    Failed to open library "/export/home/tmp/didrik/trunk-add-executable-ndb/storage/ndb/memcache/ndb_engine.so": dlopen(/export/home/tmp/didrik/trunk-add-executable-ndb/storage/ndb/memcache/ndb_engine.so, 6): Library not loaded: libssl.1.0.0.dylib
      Referenced from: /export/home/tmp/didrik/trunk-add-executable-ndb/storage/ndb/memcache/ndb_engine.so
      Reason: image not found
    
    otool -L storage/ndb/memcache/ndb_engine.so says:
            libssl.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            libcrypto.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1238.60.2)
            /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 307.5.0)
    
    Fix: set LIBRARY_OUTPUT_DIRECTORY for ndb_engine,
         and patch ndb_engine with install_name_tool
    
    otool -L library_output_directory/ndb_engine.so
    library_output_directory/ndb_engine.so:
            @loader_path/libssl.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            @loader_path/libcrypto.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1238.60.2)
            /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 307.5.0)
    
    make install DESTDIR=/tmp/foo
    otool -L /tmp/foo/usr/local/mysql/lib/ndb_engine.so
    /tmp/foo/usr/local/mysql/lib/ndb_engine.so:
            @loader_path/libssl.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            @loader_path/libcrypto.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1238.60.2)
            /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 307.5.0)
    
    ================
    For linux: ensure that load-[1;31mtime[m dependencies after install
    are resolved relative to $ORIGIN.
    
    chrpath library_output_directory/ndb_engine.so
    library_output_directory/ndb_engine.so: RPATH=$ORIGIN/:/export/home/didrik/openssl-1.0.2k-ubuntu17.04-x86-64bit/lib:
    
    make install DESTDIR=/tmp/foo
    
    chrpath /tmp/foo/usr/local/mysql/lib/ndb_engine.so
    /tmp/foo/usr/local/mysql/lib/ndb_engine.so: RPATH=$ORIGIN/:$ORIGIN/
    (the result here depends on cmake version, there should be at least one '$ORIGIN/'
    
    (cherry picked from commit 57e83a35625f6e1c45ff5e7d9c3341a15a0125a2)

[33mcommit 023f7661998f7d0c15cc3435ff2faa08caaeddc2[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Oct 10 09:45:53 2017 +0200

    Bug#26927607 DYNAMIC LINKING WITH OPENSSL FOR NDBCLUSTER ON MACOS
    
    Extra patch for -DWITH_NDB_TEST=1
    All executables which link with mysqlclient must be created with
    MYSQL_ADD_EXECUTABLE so that the openssl .dll / .dylib / .so
    is found at link [1;31mtime[m and at run[1;31mtime[m
    
    (cherry picked from commit b10fd56f16d58be75d1f33d06ef3f4e1f350532c)

[33mcommit 02aa88cc0f1778c46f831bb3abfbd89c7199c775[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Sep 29 13:11:16 2017 +0200

    Bug#26927607 DYNAMIC LINKING WITH OPENSSL FOR NDBCLUSTER ON MACOS
    
    Add support for -DWITH_NDBCLUSTER=1 -DWITH_SSL=</path/to/custom/openssl>
    
    Problem:
    Linking CXX executable ndbinfo_sql
    dyld: Library not loaded: libssl.1.0.0.dylib
    
    Fix: MYSQL_ADD_EXECUTABLE does the necessary magic to find openSSL
    
    Problem:
    Linking CXX shared module ndb_engine.so
    ld: file not found:
    /Volumes/hd2/pb2/build/sb_0-23974122-1498237767.55/openssl-1.0.2k-macos10.12-x86-64bit/lib/libcrypto.1.0.0.dylib
    
    Fix: Link with the copied libraries, rather than the original ones.
    
    Problem:
    Failed to open library "/export/home/tmp/didrik/trunk-add-executable-ndb/storage/ndb/memcache/ndb_engine.so": dlopen(/export/home/tmp/didrik/trunk-add-executable-ndb/storage/ndb/memcache/ndb_engine.so, 6): Library not loaded: libssl.1.0.0.dylib
      Referenced from: /export/home/tmp/didrik/trunk-add-executable-ndb/storage/ndb/memcache/ndb_engine.so
      Reason: image not found
    
    otool -L storage/ndb/memcache/ndb_engine.so says:
            libssl.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            libcrypto.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1238.60.2)
            /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 307.5.0)
    
    Fix: set LIBRARY_OUTPUT_DIRECTORY for ndb_engine,
         and patch ndb_engine with install_name_tool
    
    otool -L library_output_directory/ndb_engine.so
    library_output_directory/ndb_engine.so:
            @loader_path/libssl.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            @loader_path/libcrypto.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1238.60.2)
            /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 307.5.0)
    
    make install DESTDIR=/tmp/foo
    otool -L /tmp/foo/usr/local/mysql/lib/ndb_engine.so
    /tmp/foo/usr/local/mysql/lib/ndb_engine.so:
            @loader_path/libssl.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            @loader_path/libcrypto.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1238.60.2)
            /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 307.5.0)
    
    ================
    For linux: ensure that load-[1;31mtime[m dependencies after install
    are resolved relative to $ORIGIN.
    
    chrpath library_output_directory/ndb_engine.so
    library_output_directory/ndb_engine.so: RPATH=$ORIGIN/:/export/home/didrik/openssl-1.0.2k-ubuntu17.04-x86-64bit/lib:
    
    make install DESTDIR=/tmp/foo
    
    chrpath /tmp/foo/usr/local/mysql/lib/ndb_engine.so
    /tmp/foo/usr/local/mysql/lib/ndb_engine.so: RPATH=$ORIGIN/:$ORIGIN/
    (the result here depends on cmake version, there should be at least one '$ORIGIN/'
    
    (cherry picked from commit 57e83a35625f6e1c45ff5e7d9c3341a15a0125a2)

[33mcommit 3cfa5559c57f02ec1bd3741c3606e4a8e2c2ba18[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Oct 10 09:45:53 2017 +0200

    Bug#26927607 DYNAMIC LINKING WITH OPENSSL FOR NDBCLUSTER ON MACOS
    
    Extra patch for -DWITH_NDB_TEST=1
    All executables which link with mysqlclient must be created with
    MYSQL_ADD_EXECUTABLE so that the openssl .dll / .dylib / .so
    is found at link [1;31mtime[m and at run[1;31mtime[m

[33mcommit 4f3c55ffb5fac19a61fb9c5054a11c4de4bb7544[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Sep 29 13:11:16 2017 +0200

    Bug#26927607 DYNAMIC LINKING WITH OPENSSL FOR NDBCLUSTER ON MACOS
    
    Add support for -DWITH_NDBCLUSTER=1 -DWITH_SSL=</path/to/custom/openssl>
    
    Problem:
    Linking CXX executable ndbinfo_sql
    dyld: Library not loaded: libssl.1.0.0.dylib
    
    Fix: MYSQL_ADD_EXECUTABLE does the necessary magic to find openSSL
    
    Problem:
    Linking CXX shared module ndb_engine.so
    ld: file not found:
    /Volumes/hd2/pb2/build/sb_0-23974122-1498237767.55/openssl-1.0.2k-macos10.12-x86-64bit/lib/libcrypto.1.0.0.dylib
    
    Fix: Link with the copied libraries, rather than the original ones.
    
    Problem:
    Failed to open library "/export/home/tmp/didrik/trunk-add-executable-ndb/storage/ndb/memcache/ndb_engine.so": dlopen(/export/home/tmp/didrik/trunk-add-executable-ndb/storage/ndb/memcache/ndb_engine.so, 6): Library not loaded: libssl.1.0.0.dylib
      Referenced from: /export/home/tmp/didrik/trunk-add-executable-ndb/storage/ndb/memcache/ndb_engine.so
      Reason: image not found
    
    otool -L storage/ndb/memcache/ndb_engine.so says:
            libssl.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            libcrypto.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1238.60.2)
            /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 307.5.0)
    
    Fix: set LIBRARY_OUTPUT_DIRECTORY for ndb_engine,
         and patch ndb_engine with install_name_tool
    
    otool -L library_output_directory/ndb_engine.so
    library_output_directory/ndb_engine.so:
            @loader_path/libssl.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            @loader_path/libcrypto.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1238.60.2)
            /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 307.5.0)
    
    make install DESTDIR=/tmp/foo
    otool -L /tmp/foo/usr/local/mysql/lib/ndb_engine.so
    /tmp/foo/usr/local/mysql/lib/ndb_engine.so:
            @loader_path/libssl.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            @loader_path/libcrypto.1.0.0.dylib (compatibility version 1.0.0, current version 1.0.0)
            /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1238.60.2)
            /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 307.5.0)
    
    ================
    For linux: ensure that load-[1;31mtime[m dependencies after install
    are resolved relative to $ORIGIN.
    
    chrpath library_output_directory/ndb_engine.so
    library_output_directory/ndb_engine.so: RPATH=$ORIGIN/:/export/home/didrik/openssl-1.0.2k-ubuntu17.04-x86-64bit/lib:
    
    make install DESTDIR=/tmp/foo
    
    chrpath /tmp/foo/usr/local/mysql/lib/ndb_engine.so
    /tmp/foo/usr/local/mysql/lib/ndb_engine.so: RPATH=$ORIGIN/:$ORIGIN/
    (the result here depends on cmake version, there should be at least one '$ORIGIN/'

[33mcommit 28d198a27cd00d62cb7cee059adf1a1c303b747d[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Oct 10 16:13:25 2017 +0200

    Bug #26927386: REDUCE WEIGHT OF SQL_CLASS.H [noclose]
    
    Move the RAII guards defined in sql_class.h into its own header file.
    
    No immediate significant gain in compile [1;31mtime[ms, but paves the way for more
    cleanups later (and it removes 200 lines from sql_class.h).
    
    Change-Id: I98e6ae474096e898867bb78e23b528fd3150d69a

[33mcommit 2fc08e5915ec293390092d878942eaca4b9dd21f[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Oct 12 08:55:01 2017 +0200

    WL#9185 MySQL Cluster support for new DD
    
     - disable ndb_share.test and ndb_reconnect.test
     - there is a problem with the "check_not_readonly" which now has been
       rewritten to create a table called check_not_readonly, that table is
       some[1;31mtime[ms installed a second [1;31mtime[m when running schema distribution
       synchronization during mysqld restart. Need to find a different way
       to wait for "not readonly or fix so it's not installed a second [1;31mtime[m
       (must be a race)

[33mcommit 9624f8a9415a71bada6d524d463eb0e222d80f92[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Fri Oct 6 10:59:16 2017 +0200

    Bug#26542829: Assertion !(check_date[1;31mtime[m_range(l[1;31mtime[m)) failed
    
    The symptoms of this bug is some[1;31mtime[ms an assertion, some[1;31mtime[ms
    only a valgrind warning about "jump or move depends on uninitialised
    value" in do_copy_null(). The problem may occur when a derived table
    with an ORDER BY clause is merged into an outer query, when the columns
    from ORDER BY are not also referenced in outer query. The problem is
    due to missing to mark the column underlying "field2" in the read set
    of table t1.
    
    field2 is used in ORDER BY inside a derived table. field2 references
    a column from the SELECT list. But since fields from SELECT list
    in a derived table are not marked in the read_set when they are first
    resolved, we need to make sure those fields are marked when used for
    other purposes, such as in ORDER BY. Notice that we only want to
    mark columns when merging into an outermost query expression, and
    not into another derived table.
    
    Bug case is added to main.derived-no-prepared due to bug#26808862.

[33mcommit f5d7e0d3b988f0b7fa19b69c57f9994edbf9e9c8[m
Author: Havard Dybvik <havard.dybvik@oracle.com>
Date:   Tue Mar 21 12:46:31 2017 +0100

    Bug#25123839: LEAST AND GREATEST MAKES INCONSISTENT DATA TYPES, COMPARED TO UNION AND COALESCE
    
    Resolving of result type in LEAST/GREATEST and UNION is now done using
    the same logic as in COALESCE by passing all arguments to
    Item::aggregate_type().
    
    This change affects how the arguments to LEAST/GREATEST are compared and
    consequently the output. Previously, comparisons some[1;31mtime[ms depended on
    the "context" in which the output would be used. For example,
    LEAST("11","2") would compare the arguments as strings and return "11",
    whereas LEAST("11", "2") + 0 would compare the arguments as integers and
    return 2 due to the output being used in an "integer context".
    
    There exists, however, at this [1;31mtime[m no clear definition of what a
    "string context", "integer context", etc. is. It has therefore been
    decided to drop the "context" term.
    
    The arguments are now compared depending only on the result type from
    the function itself. The result from LEAST("11", "2") will thus always
    be "11", leading to a more deterministic behavior. It is the actual
    result from this comparison that is converted to any required output
    type, such as an integer.

[33mcommit 8c8baa626d786eed1dc1b5cef5b1445179e14718[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Oct 4 15:03:42 2017 +0200

    Bug#24488219: INCLUDE WHAT YOU USE [noclose]
    
    Re-run IWYU on sql/, excluding sql/gis/ and sql/dd/. Some manual
    editing was, as always, required.
    
    Takes compilation [1;31mtime[m of sql_class.h (with -O2 -g, GCC 7.2) down
    from 1.9 to 1.3 seconds.
    
    Change-Id: I017e57331ede1a9b0f5cec1857c81d0b0c0cda5f

[33mcommit 974a90c849bc14a6f9be2bd597449edb940f8a3e[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Oct 5 14:21:03 2017 +0200

    WL#8500 Adapt MySQL Cluster to 8.0
    
     - problem with tests verifying that the DD is consistent between
       MySQL Server's. Tests are using information_schema queries which
       caches table statistics.
     - fix by turning off caching to make sure that statistics is fetched
       from SE every [1;31mtime[m

[33mcommit 7cb51e23c1628cbec2aa4540f64dd2fc67234688[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Fri Sep 15 14:23:06 2017 +0200

    WL#9185 MySQL Cluster support for new DD
    
     - problem with "shadow table" preventing DROP DATABASE
       from removing the NDB tables from DD on participant
     - fix by adding code which lists all NDB tables in DD, drops
       them from there, invalidates them in NdbApi, closes any
       open MySQL Server table shares, marks the table as dropped
       and releases the server NDB_SHARE for the dropped tables
     - add comments decribing the above and also the case that
       the actual DROP DATABASE query is some[1;31mtime[ms prevented from
       removing the actual data directory (and other artifacts)
     - this is a problem also in previous versions, dropping
       a database where some MySQL Servers have "shadow" tables will
       leave the metadata for all dropped NDB tables on the participants

[33mcommit cb8c55d7d243bd26f8b1000b6a75cbf5d83a6b50[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Fri Sep 29 14:12:44 2017 +0200

    Bug#24510948: ALTER TABLE+INSERT+DROP DB HANG
    
    Problem: Running insert, alter and drop schema concurrently could
    trigger a deadlock.
    
    Root cause was that it was possible to block waiting for a TABLE_SHARE
    being opened by another thread while already holding MDL on the
    schema. The other thread would, as part of opening the share, attempt
    to also acquire MDL on the schema. This could result in a pseudo
    deadlock, as the operation would proceed only after the thread
    requesting the MDL had [1;31mtime[md out.
    
    Solution: When the share is not found in the tdc and there is no prior
    MDL on schema, get_table_share() must temporarily release LOCK_open,
    acquire MDL on schema, and retry the tdc lookup. This way there is no
    need to acquire schema MDL while share->open_in_progress is true. Note
    that the MDL now has transaction duration rather than a (shorter) explicit
    duration. This should not harm concurrency, as exclusive access to the
    schema was always prevented by MDL on a table in it, and concurrent
    access is still possible.
    
    (cherry picked from commit 6a87de7a33ba3b9504d9aa6f283701595aa2c1c7)

[33mcommit 273269a16e4f4764a55fd1af01ea2b921c2eab66[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Fri Sep 29 14:12:44 2017 +0200

    Bug#24510948: ALTER TABLE+INSERT+DROP DB HANG
    
    Problem: Running insert, alter and drop schema concurrently could
    trigger a deadlock.
    
    Root cause was that it was possible to block waiting for a TABLE_SHARE
    being opened by another thread while already holding MDL on the
    schema. The other thread would, as part of opening the share, attempt
    to also acquire MDL on the schema. This could result in a pseudo
    deadlock, as the operation would proceed only after the thread
    requesting the MDL had [1;31mtime[md out.
    
    Solution: When the share is not found in the tdc and there is no prior
    MDL on schema, get_table_share() must temporarily release LOCK_open,
    acquire MDL on schema, and retry the tdc lookup. This way there is no
    need to acquire schema MDL while share->open_in_progress is true. Note
    that the MDL now has transaction duration rather than a (shorter) explicit
    duration. This should not harm concurrency, as exclusive access to the
    schema was always prevented by MDL on a table in it, and concurrent
    access is still possible.

[33mcommit 85cb5534dfd0cf81d1c0367d8e29673c2e450d48[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Oct 3 13:49:09 2017 +0200

    Bug#26911453 UBSAN ERROR ON SETRINGORDERTEST.SETRINGORDERCCW UNIT TEST
    
    Fix misc UBSAN warnings in unit tests.
    To repeat:
    export UBSAN_OPTIONS="print_stacktrace=1"
    
    ./run[1;31mtime[m_output_directory/merge_large_tests-t --gtest_filter='-*DeathTest*' > /dev/null
    
    unittest/gunit/gis_algos-t.cc:78:70:
    run[1;31mtime[m error: downcast of address 0x000012dc0be8 which does not point to an object of type 'Gis_polygon_ring'
    
    include/sql_string.h:683:35: run[1;31mtime[m error: null pointer passed as argument 2, which is declared to never be null
        #1 0x373e7af in histograms::Value_map<String>::add_values(String const&, unsigned long long) sql/histograms/value_map.cc:149
        #2 0x294fcf2 in dd_column_statistics_unittest::add_values(histograms::Value_map<String>&) unittest/gunit/dd_column_statistics-t.cc:62
    
    run[1;31mtime[m_output_directory/merge_keyring_file_tests-t --gtest_filter='-*DeathTest*' > /dev/null
    
    plugin/keyring/common/keyring_key.cc:82:57: run[1;31mtime[m error: null pointer passed as argument 2, which is declared to never be null
    
    Change-Id: I2651362e3373244b72e6893f0e22e67402b49a52
    (cherry picked from commit 1fe3f72561994da1d912a257689e1b18106f8828)

[33mcommit d620927356adc4ed3e47bcc2ab942f907438d607[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Oct 3 13:03:40 2017 +0200

    Bug#26571995 SET DEFAULT ROLE ALL don't set mandatory roles.
    
    Post-push fix for UBSAN warning:
    run[1;31mtime[m error:
    null pointer passed as argument 1, which is declared to never be null
    sql/auth/sql_authorization.cc:7525
    
    To repeat: ./mtr --mem --sanitize json_table
    
    (cherry picked from commit 01fee7c1eb7aa2d516dab2e2d3e678056ad6ee5e)

[33mcommit 74f076fe19191a7a9fc6b48aeb90c9c465a74b88[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Fri Aug 18 17:10:06 2017 +0530

    Bug #26026218 : TRANSPORTER ERROR 0X8004, 0X8023; CHECKSUM; UNSUPPORTED BYTE ORDER
    
    Checksum checking is added to the TCP Transporter using the new class + utils.
    
    doSend() obtains an array of IOVECs and attempts to send all of the data from
    them, in multiple passes.
    
    The OS may manage to send some, all or none of the data, which could result in
    IOVEC offsets changing, becoming odd etc over [1;31mtime[m.
    
    doSend() will :
      a) Check checksums for all data available in IOVECs prior to OS::send()
      b) Check checksums for all sent data afer OS::send()
    
    Obviously this adds some CPU load to the threads performing sending.

[33mcommit ab5cc9ccda0dd35a81e0247ee0066d596b4b5c57[m
Author: Dag Wanvik <dag.wanvik@oracle.com>
Date:   Thu Sep 7 11:02:35 2017 +0200

    Bug#23529242 CONCAT: ASSERTION FAILED: MAYBE_NULL
    
    Analysis:
    
    In the repro:
    
       SET SQL_MODE= ''; // required to see issue, see [1]
       SELECT CONCAT(UNIX_TIMESTAMP(COUNT(1)), '|');
    
    we hit an assert that Item_func_concat::maybe_null is true when we see
    a NULL being returned from UNIX_TIMESTAMP.
    
    UNIX_TIMESTAMP return a NULL due to the illegal
    "date[1;31mtime[m" value:
    
        mysql> select unix_[1;31mtime[mstamp(count(1));
        +--------------------------+
        | unix_[1;31mtime[mstamp(count(1)) |
        +--------------------------+
        |                     NULL |
        +--------------------------+
        1 row in set, 2 warnings (0.00 sec)
    
        Warning (Code 1292): Incorrect date[1;31mtime[m value: '1'
    
    TIMESTAMP(1) and UNIX_TIMESTAMP(1) do behave differently:
    
        mysql> select [1;31mtime[mstamp(1);
        +--------------+
        | [1;31mtime[mstamp(1) |
        +--------------+
        | NULL         |
        +--------------+
        1 row in set, 1 warning (0.00 sec)
    
        mysql> select unix_[1;31mtime[mstamp(1);
        +-------------------+
        | unix_[1;31mtime[mstamp(1) |
        +-------------------+
        |                 0 |
        +-------------------+
        1 row in set, 1 warning (0.00 sec)
    
    and the documentation for UNIX_TIMESTAMP states unequivocally:
    
      "If you pass an out-of-range date to UNIX_TIMESTAMP(), it returns 0."
    
    But on the other hand when we have the COUNT(1) aggregate as an
    argument we get a NULL, which is a bug.
    
    Next, CONCAT has deduced it is not nullable based on the information
    about its arguments: UNIX_TIMESTAMP and the literal which is trivially
    not NULL. So, when that function does return a NULL,
    Item_func_concat::val_str hits the ASSERT.
    
    CONCAT has the wrong idea: it is indeed nullable because
    UNIX_TIMESTAMP is so, and the latter isn't marked as such. If it were,
    CONCAT would get that property too by the propagation in
    Item_func::fix_func_arg, but see [1].
    
    But back to COUNT(1): why doesn't the wrong argument COUNT(1), which
    evaluates to 1, give the same result as plain 1 as an argument.  The
    crucial difference is an intervening Item_ref in the item tree for the
    former which is sets null_value if an error is returned from the
    called get_date (called from Item_unix_[1;31mtime[mstamp::val_[1;31mtime[mval ->
    Item::get_[1;31mtime[m_val -> Item_ref::get_date:
    
       return (null_value= (*ref)->get_date_result(l[1;31mtime[m,fuzzydate));
    
    so in turn, UNIX_TIMESTAMP get its null_value set, too.  We see,
    though, that Item_unix_[1;31mtime[mstamp::val_[1;31mtime[mval doesn't expect any
    underlying Item_ref to do just that (from its Doxygen):
    
    /**
       If argument is NULL, sets null_value. Otherwise:
       if invalid DATETIME value, or a valid DATETIME value but which is out of
       the supported Unix [1;31mtime[mstamp range, sets 'tm' to 0.
    */
    
    Fix:
    
    Let UNIX_TIMESTAMP(1) continue to return 0 when it sees an invalid
    argument, in contrast to TIMESTAMP().
    We can achieve this by letting Item_ref::get_date just return the error
    code of the underlying get_date_result as before, but explicitly propagate
    the null value (instead on setting it only based on the error code), thus:
    
      bool result= (*ref)->get_date_result(l[1;31mtime[m,fuzzydate);
      null_value= (*ref)->null_value;
      return result;
    
    Note that Item_direct_ref::get_date already does the null propagation in this way.
    
    With the change, [1;31mtime[m_func with the new repro passes. I will run a
    larger set of tests to see if it has any repercussions.
    
    [1]
    
    If we use strict mode, CONCAT is marked as nullable disregarding its arguments
    in Item_str_func::fix_fields, cf this line, last condition:
      :
      /*
        In Item_str_func::check_well_formed_result() we may set null_value
        flag on the same condition as in test() below.
      */
      maybe_null= (maybe_null || thd->is_strict_mode());
      :
    
    This is why the setting of SQL_MODE is required in the repro.
    
    Repro added in func_[1;31mtime[m.test.
    
    Change-Id: Idd552856465ababd95a6c40794d67a57efb4b7ed

[33mcommit 188fe40785ef9c69813062e27f9a7fa5556cf7f1[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Oct 3 13:49:09 2017 +0200

    Bug#26911453 UBSAN ERROR ON SETRINGORDERTEST.SETRINGORDERCCW UNIT TEST
    
    Fix misc UBSAN warnings in unit tests.
    To repeat:
    export UBSAN_OPTIONS="print_stacktrace=1"
    
    ./run[1;31mtime[m_output_directory/merge_large_tests-t --gtest_filter='-*DeathTest*' > /dev/null
    
    unittest/gunit/gis_algos-t.cc:78:70:
    run[1;31mtime[m error: downcast of address 0x000012dc0be8 which does not point to an object of type 'Gis_polygon_ring'
    
    include/sql_string.h:683:35: run[1;31mtime[m error: null pointer passed as argument 2, which is declared to never be null
        #1 0x373e7af in histograms::Value_map<String>::add_values(String const&, unsigned long long) sql/histograms/value_map.cc:149
        #2 0x294fcf2 in dd_column_statistics_unittest::add_values(histograms::Value_map<String>&) unittest/gunit/dd_column_statistics-t.cc:62
    
    run[1;31mtime[m_output_directory/merge_keyring_file_tests-t --gtest_filter='-*DeathTest*' > /dev/null
    
    plugin/keyring/common/keyring_key.cc:82:57: run[1;31mtime[m error: null pointer passed as argument 2, which is declared to never be null
    
    Change-Id: I2651362e3373244b72e6893f0e22e67402b49a52

[33mcommit b890f4d2069111b2c9daf3933f84298b4e2b8f6d[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Oct 3 13:03:40 2017 +0200

    Bug#26571995 SET DEFAULT ROLE ALL don't set mandatory roles.
    
    Post-push fix for UBSAN warning:
    run[1;31mtime[m error:
    null pointer passed as argument 1, which is declared to never be null
    sql/auth/sql_authorization.cc:7525
    
    To repeat: ./mtr --mem --sanitize json_table

[33mcommit b4f23630df6c8955526e483af3f8fdf05bca3be5[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Sep 29 10:34:24 2017 +0200

    Bug#26781567 REMOVE C LEGACY
    Bug#26612465 BUILDING WITH CMAKE 3.9.0 OR NEWER GIVES DEPRECATION WARNINGS
    
    Post push fix for: Move some InnoDB memcached files from C to C++
    Turns out we need some 'extern "C"' in order to load the memcached plugin:
    
    bin-ndb/storage/ndb/memcache/ndb_engine.so:
    undefined symbol: _Z11slabs_clsidP14default_enginem
    $c++filt _Z11slabs_clsidP14default_enginem
    slabs_clsid(default_engine*, unsigned long)
    
    _Z12item_releaseP14default_engineP10_hash_item
    item_release(default_engine*, _hash_item*)
    
    _Z30default_engine_create_instancemPFP18server_handle_v1_tvEPP16engine_interface
    default_engine_create_instance(unsigned long, server_handle_v1_t* (*)(), engine_interface**)
    
    On Mac:
    cmake changes to build dbclient_so
    
    storage/ndb/src/common/portlib/NdbCondition.cpp:175
    error: no matching
          function for call to 'clock_get[1;31mtime[m'
      clock_get[1;31mtime[m(clock_id, abs[1;31mtime[m);
    
    Tested with:
    ./mtr --mem --suite=ndb_memcache,ndbcluster
    
    (cherry picked from commit 310d0c4676f0d5d1d544eacfb7e184a7654d1f78)

[33mcommit 286ab1abe33cb129c81261cadfcd94d44e50a606[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Tue Sep 26 12:19:51 2017 +0200

    Bug#26867509: JSON_OBJECT CREATES INVALID JSON CODE
    
    When inserting JSON values from a grouped query into a string column,
    the inserted values could some[1;31mtime[ms include the concatenation of all
    the values previously inserted into that column.
    
    The fix is to make Item_copy_json::save_in_field_inner() reset the
    buffer before converting the JSON value to text.
    
    Change-Id: I328c88f2fee95ff4406b21d961d9297a3b9fa624

[33mcommit 22dd7ea786421e5d75660baaedfea582d258757a[m
Author: Neha Kumari <neha.n.kumari@oracle.com>
Date:   Fri Sep 29 15:38:19 2017 +0530

    Bug#25656992:DROP TEMPORARY TABLE CREATES A TRANSACTION IN BINARY LOG ON READ ONLY SERVER
    
    Problem:
    
    If "DROP TEMPORARY TABLE..." gets executed on server with GTID enabled and
    read_only mode enabled, then 'DROP /!40005 TEMPORARY / TABLE IF EXISTS
    sometablename' gets inserted in server binary log. This creates errant
    transaction, that other slaves in cluster might not have and can break
    replication if server with errant transaction gets promoted to master and
    this transaction is already deleted from binary logs
    
    Fix:
    
    Do not write DROP TEMPORARY TABLE into binary log if nothing dropped.
    
    The fix is implemented through following changes.
    - Only count those temporary tables whose DROPs are actually going to
      be binlogged in mysql_rm_table for
      ER_GTID_UNSAFE_BINLOG_SPLITTABLE_STATEMENT_AND_GTID_GROUP
      diagnostic.
    - In mysql_rm_table_no_locks, process tables temporary tables needing and
      not needing binlog separately.
    - In mysql_alter_table, add a thd->decide_logging_format call in one of
      the temporary table opening paths in order to record the create-[1;31mtime[m
      binlog format for an ALTER TABLE-recreated temporary table correctly.

[33mcommit 6b84bec3e9dcdf54b69f034fd0cee240b0bf64a2[m
Author: Arnab Ray <arnab.r.ray@oracle.com>
Date:   Thu Sep 21 12:37:14 2017 +0530

    WL#8500 Adapt MySQL Cluster to 8.0
    
    - Add separate result files for the ndb_dist_priv_default and
      ndb_dist_priv_ndb tests. Both tests previously shared the same
      result file, ndb_dist_priv_common
    - Change the ndb_fk_no_fk_ndb test to use a result file with the
      same name in place of the ndb_fk_no_fk_legacy.result file used
      previously
    - Add the ndb_no_result_file include file to various tests that
      have no result file. An effort to generate result files for these
      tests would be good but that is left as a task for a later [1;31mtime[m
    - These changes were required due to the fix for Bug#26406981
      FLAG MISSING .RESULT FILE AS FAILED TEST. A test without a
      corresponding result file is now marked as failed by MTR.
    
    (cherry picked from commit 90dde3c3c06b5e6e2e63205bdb7b7b05a4ffcb77)

[33mcommit a903861311a8b2ec6e1fe42569ff6c9f78a9fb66[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Sep 29 10:34:24 2017 +0200

    Bug#26781567 REMOVE C LEGACY
    Bug#26612465 BUILDING WITH CMAKE 3.9.0 OR NEWER GIVES DEPRECATION WARNINGS
    
    Post push fix for: Move some InnoDB memcached files from C to C++
    Turns out we need some 'extern "C"' in order to load the memcached plugin:
    
    bin-ndb/storage/ndb/memcache/ndb_engine.so:
    undefined symbol: _Z11slabs_clsidP14default_enginem
    $c++filt _Z11slabs_clsidP14default_enginem
    slabs_clsid(default_engine*, unsigned long)
    
    _Z12item_releaseP14default_engineP10_hash_item
    item_release(default_engine*, _hash_item*)
    
    _Z30default_engine_create_instancemPFP18server_handle_v1_tvEPP16engine_interface
    default_engine_create_instance(unsigned long, server_handle_v1_t* (*)(), engine_interface**)
    
    On Mac:
    cmake changes to build dbclient_so
    
    storage/ndb/src/common/portlib/NdbCondition.cpp:175
    error: no matching
          function for call to 'clock_get[1;31mtime[m'
      clock_get[1;31mtime[m(clock_id, abs[1;31mtime[m);
    
    Tested with:
    ./mtr --mem --suite=ndb_memcache,ndbcluster

[33mcommit c079ab47a73b1fd197a82854adc6d5c885864cae[m
Author: Neha Kumari <neha.n.kumari@oracle.com>
Date:   Thu Sep 28 13:09:41 2017 +0530

    Bug#24670909:USING TEMPORARY TABLES ON SLAVES INCREASES GTID SEQUENCE NUMBER
    
    Problem:
    Previously, a session disconnect causes DROP TEMPORARY TABLE IF EXISTS
    to be binlogged for all the opened temp tables in that session. Even
    though temporary table operation are not otherwise binlogged in row or
    mixed mode, this was done regardless of binary log format in use, as
    it was not tracked, whether a particular temp table was not created in
    STATEMENT mode - in which case it does need the DROP.
    For ROW/MIXED users, this behavior causes spurious binlog writes
    and GTIDs generated on otherwise read only servers.
    
    Fix:
    Track the binlog format at temporary table create [1;31mtime[m
    (open_table_uncached and after final decide_logging_format call for
    CREATE ... SELECT), and that can be used to decide whether a DROP should be
    logged or not in method close_temporary_tables.

[33mcommit 9565ee10a4180770f16734def1bea9b0295cae1b[m
Author: Srikanth B R <srikanth.b.r@oracle.com>
Date:   Tue Sep 26 14:29:12 2017 +0530

    Bug#26178130: MTR REPORTS "USE OF UNINITIALIZED VALUE IN CONCATENATION"
    
    Description
    -----------
    MTR some[1;31mtime[ms reports following error on its console:
    Use of uninitialized value in concatenation (.) or string at
    <path>/mysql-test-run.pl line <line>.
    
    Fix
    ---
    The warning was being reported due to the property 'shortname'
    being undefined in the test information hash for few reporting
    tests like the one used for the --report-features option. The
    property has been initialized with its name in order to resolve
    the issue.
    
    Reviewed-by: Pavan Naik <pavan.naik@oracle.com>
    RB: 17320

[33mcommit 2f1951fabf9f129efe27cb49372042851d0891e2[m
Author: Luis Soares <luis.soares@oracle.com>
Date:   Mon Sep 25 17:29:57 2017 +0100

    BUG#25390330: ASSERT IN RPL_REPLICATION_OBSERVERS_EXAMPLE_PLUGIN_CHANNELS_RECEIVER_THREAD
    
    The channel service reports that the applier is waiting
    if all applier threads states are set to waiting. The
    test case asserts that the applier threads are waiting
    through the channel service immediately after a sychronization
    with the master. However, this by itself does not guarantee
    that the thread states will be set to waiting by the [1;31mtime[m
    the channel service is invoked. Indeed in some cases, that
    does not happen and an assertion is triggered.
    
    The expectation of the test is that eventually the threads
    will be waiting. As such, the fix is to only proceed to
    testing the observer plugin after the initial conditions
    are met, i.e., master and slave are synchronized and
    the applier threads have updated their states correctly.

[33mcommit 1343f6684508e16d644ce0f637d1011608e28c05[m
Author: Pekka Nousiainen <pekka.nousiainen@oracle.com>
Date:   Thu Sep 21 15:07:43 2017 +0300

    wl#7614 noregex-01.diff
    
    csv: regex date/[1;31mtime[m to hand-coded

[33mcommit 545b168a5b8966cd4a35386dfcafd31f35e080a7[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Sep 13 12:57:13 2017 +0200

    Bug #26781567: REMOVE C LEGACY
    
    Replace the final typedefs to st_* and *_st structs.
    
    Note in particular that st_mysql_show_var was called some[1;31mtime[ms SHOW_VAR
    and some[1;31mtime[ms STATUS_VAR (by way of duplicated forward-declaring typedefs).
    This patch changes it so that it's universally SHOW_VAR, which seems to
    match better with the original type name.
    
    Change-Id: Ide483ceac31284d909c42adb46496308dd4d4f85

[33mcommit 9372193f659f58bb955dfb45cbebd4305d891c1d[m
Author: Anibal Pinto <anibal.pinto@oracle.com>
Date:   Tue Sep 19 15:42:41 2017 +0200

    BUG#26378948: ASSERTION IN GROUP_REPLICATION.GR_FILTER_CRASH
    
    The "--shutdown_server 0" at the test case is some[1;31mtime[ms (depending
    on the host overload) making the debug framework to return from
    "debug_sync_set_action" function with an error (because no other thread
    signaled the "signal.continue").
    
    The debug sync was used to block server 1 to hold server 2 on recovery,
    now we stop group_replication_applier on server 1 to cause same behavior.

[33mcommit 118b404e54ee1d4db81e566a6aaf38c32aad453e[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Sep 19 09:12:03 2017 +0200

    Bug #26574924 UPGRADE TO BOOST 1.65.0
    
    Post-push fix: with UBSAN build:
    
    ./mtr --mem --sanitize main.gis
    
    include/boost_1_65_0/patches/boost/geometry/algorithms/detail/overlay/insert_touch_interior_turns.hpp:68:26: run[1;31mtime[m error: signed integer overflow: 7407392592600 * 22222177777800 cannot be represented in type 'long long int'

[33mcommit 242aee2b9440cf60a24a9d844b2786ca7c711e66[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Sep 19 09:12:03 2017 +0200

    Bug #26574924 UPGRADE TO BOOST 1.65.0
    
    Post-push fix: with UBSAN build:
    
    ./mtr --mem --sanitize main.gis
    
    include/boost_1_65_0/patches/boost/geometry/algorithms/detail/overlay/insert_touch_interior_turns.hpp:68:26: run[1;31mtime[m error: signed integer overflow: 7407392592600 * 22222177777800 cannot be represented in type 'long long int'

[33mcommit 8c6bf7e30001395cd5000aa49bc21e316f2bb5ee[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Sep 18 23:06:35 2017 +0200

    WL#10986 REMOVE PERFORMANCE_SCHEMA.SETUP_TIMERS IN 8.0
    
    Abandoned printing warnings on [1;31mtime[mr overhead,
    too unstable under heavy load.

[33mcommit 3396d888b1bc5add69f51e7c271f84a461352b1c[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Mon Sep 18 14:23:30 2017 +0200

    Bug#26802211 MYSQL_UPGRADE DUMPS CORE
    
    Optimized build gives valgrind error:
    
    ==20397== Conditional jump or move depends on uninitialised value(s)
    ==20397==    at 0x512F0B: Mysql::Tools::Base::Options::Debug_options::options_parsed() (debug_options.cc:93)
    ==20397==    by 0x50830C: Mysql::Tools::Base::Options::Composite_options_provider::options_parsed() (composite_options_provider.cc:69)
    ==20397==    by 0x50CB24: Mysql::Tools::Base::Abstract_program::run(int, char**) (abstract_program.cc:90)
    ==20397==    by 0x4505B4: main (program.cc:1083)
    
    Same thing with UBSAN:
    ../../../mysqlcom-pro-9.0.0-dmr/client/base/debug_options.cc:93:13:
    run[1;31mtime[m error: load of value 104, which is not a valid value for type 'bool'
    
    Fix: initialilze class members.

[33mcommit 8b9cead096ae4d70c54e989b77042b0bd5236237[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Mon Sep 18 10:18:33 2017 +0200

    Bug #26395134: SET PERSIST_ONLY HAS WRONG EFFECT ON P_S.VARIABLES_INFO
    
    Problem: SET PERSIST_ONLY sql will not change the value of a variable,
    however when executing this sql, the sql causes
    performance_schema.variables_info.variable_source column to be changed
    to DYNAMIC which gives an impression that the variable has been changed
    at run[1;31mtime[m which is not correct.
    
    Fix: When SET PERSIST_ONLY sql is executed do not change
    variable_source/set_user/set_[1;31mtime[m/set_host columns in
    performance_schema.variables_info table.

[33mcommit e25ea3f3e4da04e3b351f65274e6c60185cad5a8[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Sep 15 13:19:00 2017 +0200

    Bug#26802211 MYSQL_UPGRADE DUMPS CORE
    
    Same thing with mysqlpump, this [1;31mtime[m memleak rather than coredump:
    
    Move 'program' from static scope, to inside the body of main in mysql_upgrade.
    This ensures proper initialization order for static objects used by the
    client library.

[33mcommit 526c23a0ad836bff046bbe04d83aab74692854dd[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Sep 12 14:16:05 2017 +0200

    Bug#26787170 DD VERSION NUMBER NOT MAINTAINED FOR PERFORMANCE SCHEMA
    
    Before this fix, the version number for the performance schema
    stored in the data dictionary was not consistently updated
    each [1;31mtime[m a performance schema table DDL changes.
    
    The root causes are:
    - the version number itself is in dd code, not maintained by
      the performance schema team, and easy to overlook.
    - there is no process in place to enforce that this version
      number is modified on schema changes,
      making it even more easy to overlook.
    
    With this fix:
    - File storage/perfschema/pfs_dd_version.h
      now contains the value of the version number stored in the data dictionary
    - A new MTR test script, perfschema.dd_version_check,
      is designed to break when schema changes are detected,
      acting as a reminder that the data dictionary version
      needs to be adjusted.

[33mcommit ae78676aa88d97066ba0040ded8b312705578608[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Sep 13 18:46:03 2017 +0200

    Bug#25608115 VARIABLES_INFO.SET_TIME COLUMN INITIALIZED INCORRECTLY
    
    Before this fix, the column SET_TIME
    in table performance_schema.variables_info
    was set incorrectly.
    
    It was set to the [1;31mtime[m a user performs a SELECT query,
    instead of being the [1;31mtime[mstamp when the variable changed.
    
    The root cause is the design of the table DDL itself:
    
    - Variables that are never set, because they are immutable,
      should not have a SET_TIME.
    - The column however was declared NOT NULL,
      which forces the code to provide a value.
    
    Related issue, the SET_USER and SET_HOST column,
    while nullable according to the DDL,
    where never set to NULL.
    
    With this fix, columns SET_TIME, SET_USER, SET_HOST
    are cleaned up to work as expected for an audit trail:
    
    1) SET_TIME is nullable.
    
    2) When a variable is never set,
    columns SET_TIME, SET_USER and SET_HOST are NULL.
    
    3) When a variable is set,
    column SET_TIME is the [1;31mtime[mstamp when the value was set, not read.
    Columns SET_USER and SET_HOST are set
    to the user/host who performed the change.

[33mcommit e6ec9b7388b9c8abbfc718690c0b2b2a70a9df4c[m
Author: Kristofer Älvring <kristofer.pettersson@oracle.com>
Date:   Tue Sep 12 11:45:17 2017 +0200

    Bug#25658967 REVOKE ALL IS NOT REVOKING ALL PRIVILEGE WHEN CURRENT_USER() IS USED
    
    The REVOKE statement failed to revoke dynamic privileges if the
    target user was specified as CURRENT_USER().
    CURRENT_USER() is not evaluated by the parser. Instead evaluation
    must happen at run[1;31mtime[m for each and every statement which use this
    function which wasn't the case for the code related to revolval of
    all dynamic privileges.

[33mcommit be7cf2c9fc2d51f193c4082b7e1aa88e7a5fd914[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Sep 12 15:01:34 2017 +0200

    Bug#25608115 VARIABLES_INFO.SET_TIME COLUMN INITIALIZED INCORRECTLY
    
    Before this fix, the column SET_TIME
    in table performance_schema.variables_info
    was set incorrectly.
    
    It was set to the [1;31mtime[m a user performs a SELECT query,
    instead of being the [1;31mtime[mstamp when the variable changed.
    
    The root cause is the design of the table DDL itself:
    
    - Variables that are never set, because they are immutable,
      should not have a SET_TIME.
    - The column however was declared NOT NULL,
      which forces the code to provide a value.
    
    Related issue, the SET_USER and SET_HOST column,
    while nullable according to the DDL,
    where never set to NULL.
    
    With this fix, columns SET_TIME, SET_USER, SET_HOST
    are cleaned up to work as expected for an audit trail:
    
    1) SET_TIME is nullable.
    
    2) When a variable is never set,
    columns SET_TIME, SET_USER and SET_HOST are NULL.
    
    3) When a variable is set,
    column SET_TIME is the [1;31mtime[mstamp when the value was set, not read.
    Columns SET_USER and SET_HOST are set
    to the user/host who performed the change.

[33mcommit 1e1bb9155091f42f510f68936ed7394c56c30ad2[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Aug 30 07:29:26 2017 +0200

    Bug#26612465 BUILDING WITH CMAKE 3.9.0 OR NEWER GIVES DEPRECATION WARNINGS [noclose]
    
    - Collect all "convenience" libraries in
      ${CMAKE_BINARY_DIR}/archive_output_directory
    
    - Extend the ADD_CONVENIENCE_LIBRARY macro with a POST_BUILD target
      which will save library location for later merge with other static libraries.
    
    - Add an ADD_IMPORTED_LIBRARY macro for merging of imported static libraries
      with "convenience" libraries.
    
    - Implement a new GET_DEPENDEND_OS_LIBS which does not depend on the
      LOCATION property.
    
    - Keep a list of known "convenience" libraries, and ensure that all
      libraries and library locations are known at merge [1;31mtime[m.
    
    - Rewrite all the merge targets, with separate rules for
      MSVC / APPLE / LINUX / UNIX
    
    (cherry picked from commit dc42a8443ac0d1c6516897a7a2e88c782b27008f)

[33mcommit 97e2d518d904c4543caa7c688ded5268402c5238[m
Author: Satya Bodapati <satya.bodapati@oracle.com>
Date:   Thu Aug 31 15:30:46 2017 +0200

    Bug#26628126 WL9536: ASSERTION FAILURE: LOG0DDL.CC:1629:ERR == DB_SUCCESS
    
    Problem:
    --------
    In DDL trx post commit, we try to acquire MDL on SDI table to prevent concurrent purge.
    And MDL acquisition can fail to due low MDL lock wait [1;31mtime[mout or because of KILL QUERY.
    
    We don't expect failure during DDL trx post commit and assert MDL acquisition cannot fail.
    
    Fix:
    ----
    Acquire the SDI MDLs during drop of file_per_table tablespace & drop general tablespace.
    Remove SDI tables from cache in DDL trx post commit.
    
    Reviewed-By: Jimmy Yang <jimmy.yang@oracle.com>
    RB: 17265

[33mcommit befa4fc063564d03138d76747c02f3c4a0d1ee28[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Sep 11 15:38:22 2017 +0200

    Bug #26399073: MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS [noclose]
    
    Fix a warning that shows up several hundred [1;31mtime[ms during a regular compilation.
    
    Change-Id: Ica807609caaf9ac9d467bc9fda8614a5d1b7f5ed

[33mcommit e48cf25ed53261fa3c6aeec79333421ca5231faa[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Tue Sep 12 09:48:38 2017 +0800

    Bug#26535746 - DIFFERENT PARTITIONS CAN'T HAVE DIFFERENT ROW FORMAT
    
    After meta-sync push, the row format of the table would be updated
    every [1;31mtime[m if it's changed after a DDL, stored in dd::Table::row_format.
    This should be fine for normal InnoDB table. However, this applies to
    partitioned table too. So the row format of partitioned table would be
    consistent with the row format of the latest created/altered partition.
    Since it used to allow different partitions have different row formats,
    with above update strategy, every partitioned table would only know one
    row fromat from dd::Table::row_format, this result in some row format
    mismatch after next opening table.
    
    Since we do allow different row formats for different partitions,
    row format of every partition should be stored separately, then they
    won't be forgot. So for partitioned table:
    1. The dd::Table::row_format would not be updated by InnoDB internally
    for partitioned table, so does the key_block_size option
    2. row format of every partition should be stored in
    dd::Partition::se_private_data["format"], if this partition has
    different row format from the row format defined for the table.
    
    RB: 17257
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit b8dcd63d07273e9bbb7dca5ae20eb016eb1047dc[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Sep 7 10:14:09 2017 +0200

    Bug#26666274 INFINITE LOOP IN PERFORMANCE SCHEMA BUFFER CONTAINER
    
    Problem 1
    =========
    
    Under load, the performance schema code can execute
    an infinite loop in
      PFS_buffer_default_array::allocate()
    
    Root cause 1
    ============
    
    Consider the following loop:
    
      size_t monotonic;
      size_t monotonic_max;
    
      monotonic = m_monotonic.m_u32++;
      monotonic_max = monotonic + m_max; (a)
    
      while (monotonic < monotonic_max)
      {
        ...
        monotonic = m_monotonic.m_u32++; (b)
      }
    
      When the value of monotonic gets close to 2^32,
      the value of monotonic_max gets beyond 2^32 in (a)
      This is ok, as both variables are 64 bits integers.
    
      However, in the loop,
      m_monotonic.m_u32++ is only a 32 bits value (b),
      so that when incrementing to the next value,
      the monotonic counter will never get passed 2^32,
      and therefore will never reach monotonic_max.
    
      The while loop never ends, causing the bug.
    
    Fix 1
    =====
    
      The solution is to change m_monotonic to
      be a PFS_cacheline_atomic_size_t,
      to match the type (size_t) of monotonic and monotonic_max.
    
      With this fix, the loop works properly beyond 2^32.
    
      However, another issue was found by analysis.
    
    Problem 2:
    ==========
    
      When the value of monotonic gets close to 2^64,
      the value of monotonic_max gets beyond 2^64,
      causing an overflow, and wraps to a low integer (a).
    
      In this case, the while loop is never entered,
      because monotonic is near 2^64 and monotonic_max is near 0.
    
      The buffer is declared full, without looking at it.
    
      While theoretical (2^64 is a big value, the server needs
      to be up for a long [1;31mtime[m to get to this state),
      this can potentially lead to extra allocation
      of new container pages, consuming more memory than necessary.
    
    Fix 2
    =====
    
      Add logic that detects the overflow on monotonic_max,
      and reset the monotonic counter to 0.
    
    Misc
    ====
    
      This fix also changes several integer computations
      to use size_t, to clean up the code to avoid other overflows.

[33mcommit 79f49360dca75e6495cd104fc651a7db4212e6be[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Thu Aug 10 18:55:39 2017 +0200

    Bug#26614455: MAKE CACHED JSON_PATH OBJECTS IMMUTABLE
    
    The cached Json_path object returned by Json_path_cache::get_path() is
    mutable. If a caller modifies the returned object and doesn't restore
    the original state of the object when it is done, the cache is
    corrupted and could cause wrong results the next [1;31mtime[m it is used.
    
    JSON_SEARCH is the only caller that does any modification on the
    cached Json_path object. This patch changes it so that it doesn't
    modify the Json_path object. Instead it makes the modifications on a
    String object that represents the path. Since the path needs to be
    converted to a string in the end anyway, this saves some round-trips
    between Json_path representation and String, and gives a small speedup
    as an extra bonus.
    
    Json_path_cache::get_path() is changed to return a pointer to a const
    Json_path object.
    
    Additional changes in the JSON_SEARCH function, while at it:
    
    Remove the String members m_one_or_all_value and m_escape. Since the
    valid values of the one-or-all argument and escape character argument
    of JSON_SEARCH are quite small (3 characters and 1 character), there
    isn't any point in caching these strings in the Item object. Creating
    a small buffer on the stack would be enough to avoid heap allocation
    in all the common cases.
    
    Microbenchmarks (64-bit, Intel Core i7-4770 3.4 GHz, GCC 6.3):
    
    BM_JsonSearch              1389 -> 1163 ns/iter [+19.4%]
    BM_JsonSearch_Wildcard     3203 -> 3216 ns/iter [ -0.4%]
    
    Change-Id: I31c5adaafc41403efcbc1edb84ec76b2b7949b57

[33mcommit bd87573bc159c849f34aa8293ec43ac053cbfda0[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Sep 7 10:14:09 2017 +0200

    Bug#26666274 INFINITE LOOP IN PERFORMANCE SCHEMA BUFFER CONTAINER
    
    Problem 1
    =========
    
    Under load, the performance schema code can execute
    an infinite loop in
      PFS_buffer_default_array::allocate()
    
    Root cause 1
    ============
    
    Consider the following loop:
    
      size_t monotonic;
      size_t monotonic_max;
    
      monotonic = m_monotonic.m_u32++;
      monotonic_max = monotonic + m_max; (a)
    
      while (monotonic < monotonic_max)
      {
        ...
        monotonic = m_monotonic.m_u32++; (b)
      }
    
      When the value of monotonic gets close to 2^32,
      the value of monotonic_max gets beyond 2^32 in (a)
      This is ok, as both variables are 64 bits integers.
    
      However, in the loop,
      m_monotonic.m_u32++ is only a 32 bits value (b),
      so that when incrementing to the next value,
      the monotonic counter will never get passed 2^32,
      and therefore will never reach monotonic_max.
    
      The while loop never ends, causing the bug.
    
    Fix 1
    =====
    
      The solution is to change m_monotonic to
      be a PFS_cacheline_atomic_size_t,
      to match the type (size_t) of monotonic and monotonic_max.
    
      With this fix, the loop works properly beyond 2^32.
    
      However, another issue was found by analysis.
    
    Problem 2:
    ==========
    
      When the value of monotonic gets close to 2^64,
      the value of monotonic_max gets beyond 2^64,
      causing an overflow, and wraps to a low integer (a).
    
      In this case, the while loop is never entered,
      because monotonic is near 2^64 and monotonic_max is near 0.
    
      The buffer is declared full, without looking at it.
    
      While theoretical (2^64 is a big value, the server needs
      to be up for a long [1;31mtime[m to get to this state),
      this can potentially lead to extra allocation
      of new container pages, consuming more memory than necessary.
    
    Fix 2
    =====
    
      Add logic that detects the overflow on monotonic_max,
      and reset the monotonic counter to 0.
    
    Misc
    ====
    
      This fix also changes several integer computations
      to use size_t, to clean up the code to avoid other overflows.

[33mcommit cd001f536c158e98775d38a574729eb4373ae102[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Aug 30 07:29:26 2017 +0200

    Bug#26612465 BUILDING WITH CMAKE 3.9.0 OR NEWER GIVES DEPRECATION WARNINGS [noclose]
    
    - Collect all "convenience" libraries in
      ${CMAKE_BINARY_DIR}/archive_output_directory
    
    - Extend the ADD_CONVENIENCE_LIBRARY macro with a POST_BUILD target
      which will save library location for later merge with other static libraries.
    
    - Add an ADD_IMPORTED_LIBRARY macro for merging of imported static libraries
      with "convenience" libraries.
    
    - Implement a new GET_DEPENDEND_OS_LIBS which does not depend on the
      LOCATION property.
    
    - Keep a list of known "convenience" libraries, and ensure that all
      libraries and library locations are known at merge [1;31mtime[m.
    
    - Rewrite all the merge targets, with separate rules for
      MSVC / APPLE / LINUX / UNIX

[33mcommit 545a0ab6c49ff6cc31c60a3ebf2ff3a5b1034530[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Wed Sep 6 18:17:07 2017 +0530

    Bug#26203731 : INFORMATION_SCHEMA.TABLES TABLE STATISTICS ARE NULL
    
    In MySQL 8.0, SHOW TABLE STATUS ...  and SELECT * FROM
    INFORMATION_SCHEMA.TABLES ... do not return meaningful data for the
    fields rows, avg_row_length, data_length, max_data_length, index_length,
    data_free, update_[1;31mtime[m. Instead they return NULL. On MySQL 5.7 these
    statements return valid data. Same behavior is observed for cardinality
    column in INFORMATION_SCHEMA.STATISTICS table.
    
    New implementation of information schema in 8.0 introduces two modes for
    dynamic table statistics retrieval for information schema - `cached` and
    `latest`. In cached mode, dynamic meta-data is fetched from
    mysql.table_stats and mysql.index_stats tables. The data is populated
    and refreshed in the stats table by explicit ANALYZE command on the
    tables. If data is fetched from information schema in `cached` mode
    without first executing ANALYZE, user will get `NULL` or stale data
    for dynamic table statistics.
    
    Fix:
    
    - Implement [1;31mtime[m based caching of the dynamic metadata in mysql.table_stats
      and mysql.index_stats.
    
    - Time based caching will fetch data from Storage engines when retriving
      data for first [1;31mtime[m. User will never get NULL value.
    
    - Remove 'cached' and 'latest' modes for data fetching from information
      schema. Remove information_schema_stats variable.
    
    - Add SESSION variable `information_schema_stats_expiry` to specify the
      value of [1;31mtime[mout for cached data.
    
    - Default value of information_schema_stats_expiry variable is 24 hours
      (86400 seconds).
    
    - If information_schema_stats_expiry is specified as ZERO, always retrieve
      latest data from storage engine.
    
    - Do not store the retrieved dynamic data in mysql.table_stats and
      mysql.index_stats if any of the following condition is satisfied:
      - information_schema_stats_expiry value is ZERO.
      - innodb_read_only is ON.
      - transaction_read_only is ON.
      - read_only is ON.
      - super_read_only is ON.
      - data is retrieved for performance schema table.
    
    - For other values for information_schema_stats_expiry, store the data
      retrieved from storage engine in mysql.index_stats and mysql.table_stats.
      The stored data will be used for further queries on information_schema.tables
      and information_schema.statistics till data expires.
    
    - Remove internal system views TABLES_DYNAMIC, STATISTICS_DYNAMIC and
      SHOW_STATISTICS_DYNAMIC.
    
    - The metadata of columns of information schema which store dynamic
      information now depends directly on the UDF implementing them. Add
      'unsigned' flag the UDFs to maintain unsigned property of the columns.

[33mcommit eb18a7528b84bdddd945121c46734e8dd5bc4ae8[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Wed Sep 6 18:17:07 2017 +0530

    Bug#26203731 : INFORMATION_SCHEMA.TABLES TABLE STATISTICS ARE NULL
    
    In MySQL 8.0, SHOW TABLE STATUS ...  and SELECT * FROM
    INFORMATION_SCHEMA.TABLES ... do not return meaningful data for the
    fields rows, avg_row_length, data_length, max_data_length, index_length,
    data_free, update_[1;31mtime[m. Instead they return NULL. On MySQL 5.7 these
    statements return valid data. Same behavior is observed for cardinality
    column in INFORMATION_SCHEMA.STATISTICS table.
    
    New implementation of information schema in 8.0 introduces two modes for
    dynamic table statistics retrieval for information schema - `cached` and
    `latest`. In cached mode, dynamic meta-data is fetched from
    mysql.table_stats and mysql.index_stats tables. The data is populated
    and refreshed in the stats table by explicit ANALYZE command on the
    tables. If data is fetched from information schema in `cached` mode
    without first executing ANALYZE, user will get `NULL` or stale data
    for dynamic table statistics.
    
    Fix:
    
    - Implement [1;31mtime[m based caching of the dynamic metadata in mysql.table_stats
      and mysql.index_stats.
    
    - Time based caching will fetch data from Storage engines when retriving
      data for first [1;31mtime[m. User will never get NULL value.
    
    - Remove 'cached' and 'latest' modes for data fetching from information
      schema. Remove information_schema_stats variable.
    
    - Add SESSION variable `information_schema_stats_expiry` to specify the
      value of [1;31mtime[mout for cached data.
    
    - Default value of information_schema_stats_expiry variable is 24 hours
      (86400 seconds).
    
    - If information_schema_stats_expiry is specified as ZERO, always retrieve
      latest data from storage engine.
    
    - Do not store the retrieved dynamic data in mysql.table_stats and
      mysql.index_stats if any of the following condition is satisfied:
      - information_schema_stats_expiry value is ZERO.
      - innodb_read_only is ON.
      - transaction_read_only is ON.
      - read_only is ON.
      - super_read_only is ON.
      - data is retrieved for performance schema table.
    
    - For other values for information_schema_stats_expiry, store the data
      retrieved from storage engine in mysql.index_stats and mysql.table_stats.
      The stored data will be used for further queries on information_schema.tables
      and information_schema.statistics till data expires.
    
    - Remove internal system views TABLES_DYNAMIC, STATISTICS_DYNAMIC and
      SHOW_STATISTICS_DYNAMIC.
    
    - The metadata of columns of information schema which store dynamic
      information now depends directly on the UDF implementing them. Add
      'unsigned' flag the UDFs to maintain unsigned property of the columns.

[33mcommit 72b7d3260b997d782236b3fbe6546240dd2c547b[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Thu Aug 24 09:27:00 2017 +0200

    WL#9193 : Autoscale InnoDB resources based on system resources by default
    
    Turn the feature off for the [1;31mtime[m being.

[33mcommit 984acf1b3bb0b545065f848b1db9ec33094d6393[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Tue Aug 29 19:04:36 2017 +0800

    Bug#26535746 - DIFFERENT PARTITIONS CAN'T HAVE DIFFERENT ROW FORMAT
    
    After meta-sync push, the row format of the table would be updated
    every [1;31mtime[m if it's changed after a DDL, stored in dd::Table::row_format.
    This should be fine for normal InnoDB table. However, this applies to
    partitioned table too. So the row format of partitioned table would be
    consistent with the row format of the latest created/altered partition.
    Since it used to allow different partitions have different row formats,
    with above update strategy, every partitioned table would only know one
    row fromat from dd::Table::row_format, this result in some row format
    mismatch after next opening table.
    
    Since we do allow different row formats for different partitions,
    row format of every partition should be stored separately, then they
    won't be forgot. So for partitioned table:
    1. The dd::Table::row_format would not be updated by InnoDB internally
    for partitioned table, so does the key_block_size option
    2. row format of every partition should be stored in
    dd::Partition::se_private_data["format"], if this partition has
    different row format from the row format defined for the table.
    
    RB: 17257

[33mcommit 58ee24028014744abdcb6f5aed743c880f3da986[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Aug 31 16:44:32 2017 +0200

    BUG#24785784 ASAN: SIGFPE AT MY_TIMER_INIT_FREQUENCY(MY_TIMER_INFO*) IN
    MYSYS/MY_RDTSC.CC
    
    Before this fix, function my_[1;31mtime[mr_init_frequency()
    could cause a division by zero with ASAN or UBSAN builds.
    
    With this fix,
    my_[1;31mtime[mr_init_frequency() is now more robust,
    and simply return a frequency of 0 when computing
    the cycle [1;31mtime[mr frequency is not possible.
    
    Also, improved my_[1;31mtime[mr_init_frequency(),
    to remove a loop invariant (unneeded subtraction).

[33mcommit 900d4b591d38e829709827c83ec281756a27501d[m
Author: Dag Wanvik <dag.wanvik@oracle.com>
Date:   Mon Aug 28 18:51:17 2017 +0200

    Bug#26703246 ASSERTION FAILED: DELSUM+(INT) Y/4-TEMP >= 0
    
    Wrong null handling in Item_lead_lag::get_date/get_[1;31mtime[m
    
    [ This patch also fixes bug#26703156 - ASSERTION FAILED:
      !CHECK_TIME_MMSSFF_RANGE(LTIME) ]
    
    Item::get_[1;31mtime[m and Item::get_date are expected to return true if
    Item::null_value has been set. This is contrary to the common
    convention where the return boolean signals an error.
    
    Item_lead_lag would return false instead of true if
    Item_lead_lag::m_has_value was false. In the repros this happens
    because there is no FROM tables (i.e. a single row result) and all
    LEAD/LAG calls has a non-zero offset, so
    
             m_has_value == false  and
             null_value == true
    
    Upper level logic doesn't check null_value, but rather relies on the
    returned value to detect nulls.
    
    Fixed, and repro test cases added to lead_lag.test

[33mcommit c5099a817a4d3fd32d80fed62525253c6212e111[m
Author: Tatiana Azundris Nuernberg <tatjana.nuernberg@oracle.com>
Date:   Thu Aug 31 06:52:48 2017 +0100

    Bug#26286871: LOG_SINK_JSON SERVICE DOESN'T WORK WITH RPM DEFAULT INSTALLATION
    
    Throw diagnostics when configured log-services exist, but cannot
    be opened/initialized (e.g. because they cannot open their files):
    
    - at run-[1;31mtime[m, send diagnostics to the client
    
    - at start-up, try to fall back to default services,
      print diagnostics there, then abort
    
    - at start-up, if default services fail, print diagnostics
      directly to the error stream, then abort

[33mcommit d034d7599c4b1da891fe7ae9510b14adb7ee49df[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Aug 11 12:45:49 2017 +0200

    WL #10343: Switch GCC optimization from -O3 to -O2
    
    Change from -O3 to -O2 everywhere, for smaller binaries, faster compile
    [1;31mtime[ms and generally better performance. Mark some performance schema
    function as force-inline to avoid performance regressions, since they
    are important to inline despite being big.
    
    Change-Id: Ib7603f141e6974aeed7e4fde2ef7697864231ae3

[33mcommit a990b2724f4fb54416f55ddc4334133ae456fedd[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Mon Aug 28 09:25:30 2017 +0200

    Bug#26709497 VALGRIND WARNINGS IN UNIT TESTS
    
    There are misc valgrind warnings, to reproduce:
    valgrind --leak-check=full --show-leak-kinds=all
    run[1;31mtime[m_output_directory/xxx-t* --gtest_filter='-*DeathTest*' > foo
    
    Fix: initialize objects, cleanup after execution.
    With this patch, warnings are gone, and the "small" tests report no leaks.
    The "large" tests still have some reachable objects.
    
    Change-Id: I5018223eac9764c469470997dacc24182fad89e3

[33mcommit 4aa347ddc7673d0488e9958bc921fe9dcf7980d5[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Aug 24 19:11:11 2017 +0800

    Bug#25886814 - TEST CASE SKIP_LOCKED_NOWAIT HIT TIMEOUT ON PB2.
    
    The cause for this bug is the same with bug#26629790.
    Since that bug has been fixed, this bug is also fixed at the same [1;31mtime[m.
    
    Some adjustment for this test case to make it work after WL#8592,
    and re-record the result file for it.
    
    RB: 17195
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit e046814087e82a3b509f163494f562034679cb03[m
Author: Sven Sandberg <sven.sandberg@oracle.com>
Date:   Mon Aug 21 09:43:47 2017 +0200

    Post-push fix: WL#2955: RBR replication of partial JSON updates
    
    Fix sporadic test failure.
    
    Variable $fix in rpl_row_jsondiff_stress may be empty; when that
    happens the line '--eval $fix' failed.  It is expected and allowed
    that $fix is empty some[1;31mtime[ms, just a bit unlikely due to the ranomized
    nature of this test, and therefore the mistake was not found earlier.
    Fixed by guarding '--eval $fix' with 'if ($fix)'.

[33mcommit 948d2ebbb3183831a332c6412d03dbb818c2d618[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Mon Aug 21 10:46:33 2017 +0800

    Bug#26629790 - TEST CASES HIGH_PRIO_TRX_* HANG AFTER MAIN.PARTITION_INNODB.
    
    In some ALTER PARTITION scenarios, it could return directly in external_lock.
    However, TrxInInnoDB::end_stmt() was not called. This leads to the previous
    [1;31mtime[mout.
    
    Solution is call end_stmt() before return, and also adjust some counter
    related variables here instead of in commit phase.
    
    This patch also reverts previous workaround.
    
    RB:17154
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit db0aff08a0591e9d006e35d8fb8e581b6d1b9070[m
Author: Neha Kumari <neha.n.kumari@oracle.com>
Date:   Tue Aug 22 16:00:30 2017 +0530

    BUG#24590891: RESTARTING A SLAVE AFTER SEEDING IT WITH A MYSQLDUMP LOSES ITS POSITION
    
    Post-push fix:
    This test was disabled becuase the mysqlpump part of the test was failing.
    Only the mysqldump part is enabled for the [1;31mtime[m being, once Bug#26116415 is
    fixed testing for mysqlpump should also be enabled.

[33mcommit 50db4e8a370446252475250e967102b08c34ff8d[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Aug 17 11:03:49 2017 +0200

    Bug #26597243: AMBIGUOUS INCLUDE PATHS [final]
    
    Remove now redundant INCLUDE_DIRECTORIES directives from various CMakeLists.txt
    files, giving us mostly consistent include paths everywhere. There are still
    some exception (like mysqlgcs and InnoDB), but they can stay for the [1;31mtime[m being;
    the bulk of the work is done.
    
    Change-Id: Ibe93a84a2024e5663110e34c199f7f510af2e183

[33mcommit 7c486b87cabb3dcb11a74f400b07be4cc4bd728d[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Mon Aug 21 12:06:40 2017 +0300

    Addendum to fixing bug #26173244:
    Fix for a failing test udf_skip_grants
    Rased the flag for UDF initialiation at the right [1;31mtime[m to indicate
    if SQL UDF definition/removal is allowed.
    The flag is no longer used to indicate if the global structures
    are allocated or not (as they are always allocated).

[33mcommit 0fa014405e7dc3d1e4efad137602b20f17e2617b[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Mon Aug 21 12:06:40 2017 +0300

    Addendum to fixing bug #26173244:
    Fix for a failing test udf_skip_grants
    Rased the flag for UDF initialiation at the right [1;31mtime[m to indicate
    if SQL UDF definition/removal is allowed.
    The flag is no longer used to indicate if the global structures
    are allocated or not (as they are always allocated).

[33mcommit 594a74f40fa006a0ca42023147c623a8f4040d57[m
Author: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>
Date:   Tue Aug 22 08:34:11 2017 +0200

    BUG #26638422: FRACTIONAL TIME VALUE INCORRECT
    
    Microseconds part of Time and DateTime was not correctly displayed.
    Added missing preceding '0' in the fractional part of [1;31mtime[m representation.
    
    RB: 17140
    Reviewed by: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
    Reviewed by: Lukasz Kotula <lukasz.kotula@oracle.com>

[33mcommit 335771eab09bca1b47a911bc69e2d3cfd5965897[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Mon Aug 21 12:06:40 2017 +0300

    Addendum to fixing bug #26173244: Fix for a failing test udf_skip_grants Rased the flag for UDF initialiation at the right [1;31mtime[m to indicate if SQL UDF definition/removal is allowed. The flag is no longer used to indicate if the global structures are allocated or not (as they are always allocated).

[33mcommit eb9d3ac9b0d54d42abc81fb5b3e35cd8b379bec1[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Mon Aug 21 12:06:40 2017 +0300

    Addendum to fixing bug #26173244: Fix for a failing test udf_skip_grants Rased the flag for UDF initialiation at the right [1;31mtime[m to indicate if SQL UDF definition/removal is allowed. The flag is no longer used to indicate if the global structures are allocated or not (as they are always allocated).

[33mcommit 6aee469375a4eafb39d6bfe55027d0721f4c7c2c[m
Author: Sven Sandberg <sven.sandberg@oracle.com>
Date:   Sat May 6 14:33:42 2017 +0200

    WL#2955: RBR replication of partial JSON updates
    
    This worklog enables the replication of small updates of big JSON
    documents more space-efficiently.  More precisely, when using RBR, we
    will write only the modified parts of JSON documents, instead of the
    whole JSON document.
    
    The patch includes the following major components:
    
    - Implement the new option binlog_row_value_options
    
    - Implement logic to generate JSON diffs only when needed
    
      Before, JSON diffs were generated unconditionally by the optimizer.
      We changed so that JSON diffs are only generated when the option is
      enabled (unless inhibited by other options).
    
    - Implement new event type and use it when the option is enabled
    
    - Refactor: make max_row_length a private member of Row_data_memory
    
      This function was only used internally in class Row_data_memory, but
      was defined as a global function in table.cc.  Moved it to a private
      member of Row_data_memory.
    
    - Refactor: simplify pack_row and unpack_row
    
      Made several refactorings in these functions, including:
    
      New utility classes for handling null bits: When reading and writing
      a row in a row event, the logic for iterating over fields was
      interleaved with low-level bit operations to maintain a bitmap of
      null fields.  This made the code error-prone and hard to understand
      and edit.  This refactoring encapsulates the bitmap handling in
      utility classes, and simplifies pack_row / unpack_row accordingly.
    
    - Refactor: add const to integer decoder functions in pack.cc
    
      Functions in mysys/pack.cc that read from a buffer did not declare
      the buffer as const.  This patch makes net_field_length_size use a
      const parameter and makes other functions use const internally.
      Since these functions are part of the ABI, we also have to update
      include/mysql.h.pp.  (We do not const-ify pointers-to-pointers in
      function declarations, since that breaks compilation on other places
      that call the functions using non-const arguments.)
    
    - Refactor: change Json_diff_vector from a type alias to a class
    
      This was needed because extend Json_diff_vector with more member
      functions.  It also simplifies some forward declarations.
    
    - Refactor: do not overload global identifier TABLE in rpl_tblmap.h
    
      Class table_mapping in rpl_tblmap.h is used both in mysqlbinlog and
      in the server.  In the server, it maps numbers to TABLE objects.  In
      mysqlbinlog, it maps numbers to Table_map_log_event objects.  This
      was implemented by using the type name TABLE, and in mysqlbinlog use
      a typedef that makes TABLE an alias for Table_map_log_event.
    
      This patch changed rpl_tblmap.h so that it does not use the
      identifier TABLE.  Instead, it uses the new typedef Mapped_table
      that maps to TABLE in the server and to Table_map_log_event in
      mysqlbinlog.
    
    - Refactor: remove unused variable Rows_log_event::m_master_reclength
    
      There was a member variable Rows_log_event::m_master_reclength that
      was set to a (strange) value which was never read.  Removed this.
    
    - Refactor: simplify Rows_log_event::read_write_bitmaps_cmp
    
      This member function was implemented only in the base class, but had
      a switch that made it execute differently depending on the
      instance's subclass.  Changed to use a pure virtual function in the
      base class and implement the different logic in each subclass.
    
    - Implement encoder of new event format
    
      Outline of the pipeline:
    
       1. In binlog.cc:Row_data_memory, take a new argument in the
          constructor having two 'data' pointers (this constructor is used
          for Update_rows_log_event and is invoked in
          binlog.cc:THD::binlog_update_row).  This the value of the new
          server option binlog_row_value_options.  Based on this variable,
          determine if Json diffs may be used, estimate how much memory
          will be used (using the new function
          json_diff.cc:Json_diff_vector::binary_length), decide if full
          format or partial format will be used, and adjust the allocated
          memory accordingly.
    
       2. In binlog.cc:THD::binlog_update_row, pass two new arguments to
          pack_row:
    
          - row_image_type, which specifies if this is a
            Write/Update/Delete, and if it is a before-image or
            after-image.
    
          - value_options, which contains the value of
            binlog_row_value_options for update after-images.
    
       3. In rpl_record.cc:pack_row, accept the two new arguments.  If
          this is an update after-image and the bit in value_options is
          set, then determine if any column will use partial format.  If
          any column will use partial format, write the value_options
          field, followed by the partial_bits, to the output.  Otherwise,
          just write value_options=0 to the output and skip the
          value_options.
    
       4. From rpl_record.cc:pack_row, invoke the new function
          rpl_record.cc:pack_field to write a single field.  If the column
          is JSON and this is the after-image of an Update and the bit in
          value_options is set, invoke the new function
          field.cc:Field_json::pack_diff.  Otherwise, or if
          field.cc:Field_json::pack_diff returned NULL, fall back to the
          usual non-diff writer.
    
       5. In Field_json::pack_diff, determine again if this field will be
          smaller in full format or in partial format.  If full format is
          smaller, just return NULL so that rpl_record.cc:pack_field will
          write the full format.  Otherwise, invoke the new function
          json_diff.cc:Json_diff_vector::write_binary.
    
       6. In json_diff.cc:Json_diff_vector::write_binary, write the length
          using 4 bytes, followed by all the diffs.  Write each diff using
          the new function json_diff.c:Json_diff::write_binary.
    
       7. In json_diff.c:Json_diff::write_binary, write a single diff to
          the output.
    
    - Implement decoder of the new format
    
      The pipeline is now:
    
       1. Add a parameter to
          log_event.cc:Rows_log_event::unpack_current_row, which says if
          this is an after-image or not.  Set the parameter from all the
          callers in log_event.cc.
    
       2. Move Rows_log_event::unpack_current_row from log_event.h to
          log_event.cc and make it pass two new arguments to
          rpl_record.cc:unpack_row: row_image_type, which indicates if
          this is Write/Update/Delete and before-image or after-image, and
          has_value_options, which is true for Update events when
          binlog_row_value_options=PARTIAL_JSON.
    
       3. Make rpl_record.cc:unpack_row accept the two new parameters.
    
          First make a few small refactorings in rpl_record.cc:unpack_row:
    
          - Clarify some variable names and improve the comment for the
            function.
    
          - Remove comments about unpack_row being used by backup, having
            rli==NULL.  This may have been an intention at some point in
            [1;31mtime[m, perhaps in 5.1, but probably never was true.  And rli is
            unconditionally dereferenced in the main loop, so it cannot be
            NULL.  Instead assert that it is not NULL.  Also assert that
            other parameters are not NULL, as well as other preconditions.
    
          - Improve some debug trace printouts.
    
          - Return bool instead of int since the caller does not need to
            distinguish more than two different return statuses.
    
          Then implement the new logic:
    
          - When partial format is enabled, read partial_bits before the
            after-image (from within the main loop, as well as from the
            loop that consumes unused fields), and also read partial_bits
            after the before-image (after the main loop).  For the
            before-image, leave the read-position before the partial_bits.
            Use the new auxiliary function start_partial_bits_reader to
            read the value_options and initialize the Bit_reader
            accordingly, in the two places (after before-image and before
            after-image).
    
          - In order to read the correct number of bits before the
            after-image, start_partial_bits_reader needs to know the
            number of JSON columns on the master.  This is known from the
            table_map_log_event via the table_def class.  For convenience
            (and reuse in the mysqlbinlog patch), we add a member function
            rpl_utility.cc:table_def::json_column_count.  This function
            also caches the computed column count, to speed up successive
            calls (e.g. for many-row updates).
    
          - For the before-image, set the corresponding bit in the table's
            read_set, for any column having a 1 in the partial_bits.  This
            tells the engine to fetch the blob from storage (later, when
            the engine is invoked).  The blob will be needed since we have
            to apply the diff on it.
    
          - Call an auxiliary function rpl_record.cc:unpack_field to read
            each field move some special case handling for blobs into this
            function too.
    
       4. In rpl_record.cc:unpack_field, call
          field.cc:Field_json::unpack_field for partial Json fields.
    
       5. Add new function field.cc:Field_json::unpack_field, which
          invokes the new function
          json_diff.cc:Json_diff_vector::read_binary to read the
          Json_diff_vector, and the pre-existing (since WL#10570) function
          apply_json_diffs to apply the diff.
    
          The Json_diff_vector uses a new MEM_ROOT rather than the one of
          the current_thd, because that allows memory to be freed for each
          value, which saves resources e.g. in case of many-row updates.
    
          Before apply_json_diff can be invoked, we need to call
          table->mark_column_for_partial_update and
          table->setup_partial_update, in order to enable the *slave*
          server to generate JSON diffs in the *slave's* binary log.
    
       6. Add the new function json_diff.cc:Json_diff_vector:read_binary.
          This function reads the length of the field, then iterates over
          the diffs, reads each diff in turn, constructs Json_path and
          Json_wrapper/Json_dom objects, and appends them to the
          Json_diff_vector.
    
          We implement the auxiliary function net_field_length_checked,
          which reads an integer in packed format (see mysys/pack.cc),
          checking for out-of-bounds conditions.
    
    - Implement decoding and pretty-formatting of JSON diffs in mysqlbinlog
    
      mysqlbinlog outputs row events in two forms:
    
      - BINLOG statements that a server can apply.  There is nothing to
        change to make this work for the new event type.
      - "Pseudo-SQL" that humans can read, in case mysqlbinlog is invoked
        with the -v flag.  This is what the present patch implements.
    
      The pipeline in mysqlbinlog is:
    
       1. log_event.cc:Rows_log_event::print_verbose invokes
          log_event.cc:Rows_log_event::print_verbose_one_row with the new
          argument row_image_type, which indicates if this is a
          Write/Update/Delete and whether it is a before-image or
          after-image.
    
       2. In log_event.cc:log_event.cc:Rows_log_event::print_verbose_one_row
          we do two things:
    
          - Refactorings:
    
            - Use a Bit_reader to read the null bits, instead of using bit
              arithmetic.
    
            - Use safer boundary checks.  The code has a pointer to row
              data and a pointer to the end of the row data.  In C/C++, a
              pointer may point to the next byte after an allocated block
              of memory, but incrementing it further has an undefined
              result.  After reading the length of a field, the correct
              way to check that this length is not corrupt is to compare
              it with the end pointer minus the pointer to the read
              position.  (Before, it added the length to the read position
              and compared with the end pointer, but the read position
              plus the length is undefined.)
    
          - Implement the feature:
    
            - Read the value_options, if this is the after-image of a
              PARTIAL_UPDATE_ROWS_EVENT.
    
            - If value_options has the PARTIAL_JSON bit set, read the
              partial_bits.
    
            - Pass the partialness of the column as a parameter to
              log_event.cc:log_event_print_value.
    
       3. In the new function log_event_print_value, accept the new
          parameter, and in case the value is partial, call the new
          function log_event.cc:print_json_diff to parse and print the
          Json diffs.
    
       4. In the new function log_event.cc:print_json_diff, read, parse,
          and print all the diffs.
    
          The output has the form:
            JSON_<func>(
            JSON_<func>(
            ...
            JSON_<func>(@column, path[, value][,
                        path [,value][,
                        ...]]),
            ...
                        path[, value][,
                        path [,value][,
                        ...]]),
                        path[, value][,
                        path [,value][,
                        ...]])
    
          In this output format, the JSON_<func> functions appear in
          *reversed* order, whereas all the (path, value) pairs appear in
          order of appearance.  Therefore, we make two passes over the
          sequence of diffs:
    
           1. Read just the operations and store them in a vector.  Then
              print the operations in reverse order. Operations are
              printed using the new function
              log_event.cc:json_wrapper_to_string.
    
           2. Read the full diffs and output in the order of appearance.
    
       5. Add a new function log_event.cc:json_wrapper_to_string to print
          a Json_wrapper.  This ensures that the Json values are printed
          in the correct type.  JSON_<func> functions will convert SQL
          types to their JSON equivalents: for instance, the JSON function
          JSON_SET('[1, 2]', '$[0]', '[]') will set the 0th element of the
          JSON array to a string containing an open and closing square
          bracket, and not to an empty JSON array.  To account for this,
          different data types need different quoting, and to insert a
          JSON object or JSON array we need to cast the string to JSON
          first.
    
       6. To output JSON values with correct quoting for SQL strings, we use
          the existing my_b_write_quoted, but change it so that:
    
          - it uses a lookup table (computed only once) for simplicity and
            performance;
    
          - it prints common escapes such as \n, \\ in a more
            human-readable way.
    
    - BUG#26018522: MYSQLBINLOG -V PRINTS JSON IN ROW EVENTS WRONG
      mysqlbinlog -v had two problems:
    
      P1. It only read the length of JSON objects from two bytes. But the
          length of JSON data in row events is encoded (in little endian)
          using four bytes.  Therefore, it printed the wrong data for JSON
          objects bigger than 64K.  This also caused subsequent errors.
    
      P2. It only dumped the raw bytes of the buffer (quoted).  But row
          events contain a binary format for JSON, so the output was not
          useful.
    
      We fix these two problems as follows:
    
      F1. Read the length from four bytes.
    
      F2. Link mysqlbinlog with the parts of the server that can parse
          binary JSON and format it in human-readable form.  This includes
          three files:
          - json_binary.cc can parse the binary JSON format.
          - json_dom.cc can format human-readable JSON.
          - sql_[1;31mtime[m.cc is used by json_dom.cc to format [1;31mtime[m and date.
          All these files contain code that mysqlbinlog does not need and
          which needs to link with more parts of the server (e.g. THD).  To
          avoid link problems we put such code inside #ifdef MYSQL_SERVER.
    
    - Created a new test suite for tests that should not be
      parallelized by MTR because they require many mysqlds.
    
      The new suite contains test cases requiring many (6 or more) mysqlds
      in a replication topology. Running those test cases with
      "--parallel" > 1 may exhaust the test host I/O resources. So, this
      new suite should run only with "--parallel=1".

[33mcommit 56d42e1763e2627e377a6cbc50895a791dd122f2[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Sat Aug 19 09:20:47 2017 +0200

    InnoDB NewDD worklogs (WL#9535 and WL#9536)
    
    Post-push fix: disable innodb.autoinc_persist_debug in Valgrind, since
    it [1;31mtime[ms out.

[33mcommit 1afff519aa3e919331b45376d799052e6433e0ca[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Fri Aug 18 09:15:46 2017 +0200

    WL#9814 Implement INFORMATION_SCHEMA system views for FILES/PARTITIONS
    
    This patch implements I_S.FILES as a system view over data
    dictionary tables, and remove 5.7 code that uses a temporary
    table to represent I_S view.
    
    Following changes are made in the patch:
    
    * Define a system view over data dictionary tables representing
      I_S.FILES.
    
    * Remove 5.7 code from sql_show.cc for I_S.PARTITIONS.
    
    * Add new handler API handlerton::get_tablespace_statistics_t with
      following signature.
    
      typedef bool handlerton::(*get_tablespace_statistics_t)(
                      const char *tablespace_name,
                      const dd::Properties &ts_se_private_data,
                      ha_tablespace_statistics *stats);
    
      This handler provides following data to I_S.FILES,
        ID,
        TYPE,
        LOGFILE_GROUP_NAME,    // To be used by NDB
        LOGFILE_GROUP_NUMBER,  // To be used by NDB
        FREE_EXTENTS,
        TOTAL_EXTENTS,
        EXTENT_SIZE,
        INITIAL_SIZE,
        MAXIMUM_SIZE,
        AUTOEXTEND_SIZE,
        VERSION,     // To be used by NDB
        ROW_FORMAT,  // To be used by NDB
        DATA_FREE,
        STATUS
    
    * Add new internal native functions to fetch above statistics for
      I_S.FILES.
        INTERNAL_TABLESPACE_ID()
        INTERNAL_TABLESPACE_TYPE()
        INTERNAL_TABLESPACE_FREE_EXTENTS()
        INTERNAL_TABLESPACE_TOTAL_EXTENTS()
        INTERNAL_TABLESPACE_EXTENT_SIZE()
        INTERNAL_TABLESPACE_INITIAL_SIZE()
        INTERNAL_TABLESPACE_MAXIMUM_SIZE()
        INTERNAL_TABLESPACE_AUTOEXTEND_SIZE()
        INTERNAL_TABLESPACE_DATA_FREE()
        INTERNAL_TABLESPACE_STATUS()
    
    * Added new per statistics cache class dd::info_schema::Tablespace_statistics
      to store statistics retrived by SE to be used when processing
      single row of a I_S query. This avoids internal native functions to
      invoke SE API only once per row.
    
    * Renamed dd::info_schema::Statistics_cache to
      dd::info_schema::Table_statistics because we now have not only table
      statistics by tablespace statistics to be cached.
    
    * Added ORDER BY clauses in some of I_S query to force order of
      tuple returned. Because, now the optimizer returns the rows and
      not read from temporary table as in 5.7 I_S design.
    
    * Add new error message that can be reported when by I_S.FILES when
      tablespace is missing when fetching tablespaces statistics.
    
    * Remove part of test case in main.information_schema. Because,
    
      - The problem reported back then is only applicable for 5.7
        code.
    
      - The output of EXPLAIN ... <select on I_S system view> goes
        through optimizer and then plan return might vary.
    
    * Suppress additional warnings generated which report missing tablespaces.
      This happens now, because of one of following,
    
      case1) If .ibd is copy by user manually on file-system, then DD is not
             updated and hence I_S do not see it. The 5.7 behavior is that it looks
             at .ibd file in file-system and not in DD.
    
      case2) Once I_S query execution starts we see the content of DD as of the
             [1;31mtime[m I_S query started. If there is a new tablespace added or removed,
             then I_S would not see it.
    
    * MySQL 5.7 does prefix './' with all .ibd files which are to be stored in
      data directory. MySQL 8.0 had skipped it. I_S.FILES system view prefixes
      './' if filename does not have explicit patch already specified by user.
    
      Perhaps this should need a fix in server or innodb. Probably the concern
      raised in Bug#26518545 is the same. We might need to change
      I_S.FILES.FILE_NAME definition after the bug fix.
    
    * Test case for Bug#23477214 is removed now. Because the race condition
      does not apply now after I_S.FILES becomes a system view.
    
    * Record result files with capital I_S column names, this is expected. See
      WL6599 for more info.
    
    * We now show 1024 character of partition comment string, unlike just 80
      characters shown in 5.7 by I_S.

[33mcommit 95e48a2f4bca52bdec120ea31e63a4cd83714995[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Fri Aug 18 17:35:20 2017 +0530

    Bug#26091333 : ASSERTION `RC == TYPE_OK' FAILED
    
    dd::Raw_record::store() asserts in debug version due to error in
    conversion of [1;31mtime[mstamp data.
    
    The sequence leading to assert is :
    - dd::Object is cached with local [1;31mtime[m stored for [1;31mtime[mstamp columns.
    - [1;31mtime[m_zone value is changed. Cached dd::Object is not aware of the change.
    - Any DDL operation which calls Dictionary_client::update() copies data
      from existing dd::Object.
    - During this copy, the [1;31mtime[mstamp column data is treated as local [1;31mtime[m
      and converted to epoch [1;31mtime[m according to value of [1;31mtime[m_zone before
      storing.
    
     - If [1;31mtime[mstamp value becomes invalid (negative) during conversion,
       it leads to an assert.
     - For invalid value of [1;31mtime[mstamp, release build will give an error
       for the DDL commands.
     - For valid value of [1;31mtime[mstamp, the value of create_[1;31mtime[m will change
       with DDL.
    
    Fix:
    
    - Store [1;31mtime[mstamp data for dd::Objects in GMT [1;31mtime[m_zone.
    - Cache [1;31mtime[mstamp data for dd::Objects in GMT [1;31mtime[m_zone.
    - Implement function gmt_[1;31mtime[m_to_local_[1;31mtime[m to convert GMT [1;31mtime[m
      to local [1;31mtime[m.
    - Return [1;31mtime[mstamp data based on the request flag by caller function.
      - Within dictionary framework, [1;31mtime[mstamp data should be requested
        with flag as false to get GMT [1;31mtime[m_zone data.
      - Server should request [1;31mtime[mstamp column data with flag as true
        to get local [1;31mtime[m_zone data.

[33mcommit 703cef030228ab4953521bafdfba06916ca98506[m
Author: Sreeharsha Ramanavarapu <sreeharsha.ramanavarapu@oracle.com>
Date:   Fri Aug 18 07:57:56 2017 +0530

    WL#9680: Remove unused date_format, date[1;31mtime[m_format,
             [1;31mtime[m_format, max_tmp_tables

[33mcommit 50b32fd596242efc4de3b0ebad8039212c7528e7[m
Author: Karthik Kamath <karthik.kamath@oracle.com>
Date:   Wed Aug 16 19:38:18 2017 +0530

    BUG#26580041: PUSH OF WL#9644 CAUSED REGRESSION SERVER
                  SHUTDOWN
    
    ANALYSIS:
    =========
    Shutdown [1;31mtime[m of server with empty database increased
    two fold.
    
    During shutdown, we close all the connections to the
    server. During that stage, first we signal all threads
    that they need to be killed. This will give them some
    [1;31mtime[m to gracefully abort their statements and inform
    their clients that the server is about to die. There is
    a hardcoded sleep in the code which gives [1;31mtime[m for the
    threads to die if they are not killed already.
    Event scheduler is now enabled by default and thus the
    event scheduler thread needs to be killed explicitly after
    all the client connections are killed. This thread was
    killed after the sleep and hence triggered the sleep
    every[1;31mtime[m there was a shutdown because this thread was
    still active. Thus the shutdown [1;31mtime[m increased.
    
    FIX:
    ====
    The event scheduler is now stopped and the thread is
    killed before the sleep after all the client connections
    are signalled to die.
    Do note that, when we try to stop the event scheduler,
    an acknowledgement from the scheduler that it has stopped,
    is necessary. Already running events will not be stopped.

[33mcommit 7674c07d2db9f40a29c36b560011d43a3e898b5f[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Wed Aug 16 11:48:40 2017 +0530

    Bug #26496645: WINDOW FUNCTIONS: CRASH IN WINDOW::RESTORE_SPECIAL_RECORD
    
    Problem
    When we have a value which is less than argument value for a range frame in
    a windowing function, mysql server exits
    
    Analysis:
    Currently, for a range optimizable window function, the result of the
    window function is stored into a in-memory table in the form of a
    special record, which can be restored later.
    This saves us [1;31mtime[m from calculating the results again for the next row if
    the value for window function is expected to be the same. But for a case
    when all the values in the frame are less than the specified range value,
    we skip saving this special record. This results in restoring a non-existent
    record and the server exits because of this.
    
    Solution:
    Added saving of the special record to the code flow in
     process_buffered_windowing_record.

[33mcommit 888959721bf9641f581ab86ae5154dd9961e6a30[m
Author: Anitha Gopi <anitha.gopi@oracle.com>
Date:   Wed Aug 16 03:54:34 2017 +0200

    Removed debug-server option from couple of command lines. Daily runs if run on debug-server cannot finish on [1;31mtime[m

[33mcommit 2232803bdbbce7e105fcc7db39921aa7b5061580[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Tue Aug 15 08:52:56 2017 +0200

    Bug#26629454 INNODB_ZIP.INNOCHECKSUM_3 TIMES OUT IN CHECK-WARNINGS
    
    Mark the test as big-test in order to give check-warnings more [1;31mtime[m.
    
    Approved by Pavan Naik <pavan.naik@oracle.com>.

[33mcommit 2d6c9e1f08f52f4d5651cb2cb76430d5973b7d68[m
Author: Dag Wanvik <dag.wanvik@oracle.com>
Date:   Thu Aug 10 02:40:47 2017 +0200

    Bug#26500442 WINDOW FUNCTIONS: CRASH IN WINDOW::HAS_WINDOWING_STEPS
    
    [ Revision 2: updated canons for window_functions_explain due to cost
      differences as a result of this patch. More work is needed on cost
      for window functions and will be addressed in Bug#26612356 ]
    
    Analysis:
    
    The immediate cause: the crash happens when resolving mistakenly
    thinks the window function is constant and can be evaluated at resolve
    [1;31mtime[m as part of setup_fields.  This leads to a crash when accessing
    Window::m_select which doesn't have a value until after
    Window::setup_windows has been called, and this happens after
    setup_fields.
    
    The root cause: the mistaken identification of the window function as
    constant happens because the wf call has used_tables_cache==0.
    
    Fix:
    
    Setup correct value for wf call's used_tables_cache in
    Item_sum::update_used_tables.
    
    Repro test added.

[33mcommit 199eb8047690350b39cd60b3381d3c0b2c3cc8b1[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Aug 8 15:30:14 2017 +0200

    Bug #26562464: ONE DEFINITION RULE VIOLATIONS [noclose]
    
    The C++ One Definition Rule states, among others, that all structs must be
    defined equivalently in all translation units in a program, or undefined
    behavior occurs. This patch doesn't fix all the ODR violations found by GCC
    when using link-[1;31mtime[m optimization, but it fixes some of them, and makes it
    possible to build MySQL with LTO at all.
    
    Change-Id: I436d612c73a301c66e83e122f48cf230d621a6f1

[33mcommit 790e766822b2603f91f8758e534051e721045f16[m
Author: Srikanth B R <srikanth.b.r@oracle.com>
Date:   Thu Aug 10 10:56:14 2017 +0530

    Bug#26187243: FIX AND IMPROVE SEARCH FUNCTIONS IN MTR
    
    Issue:
    ------
    There are bugs/weaknesses in the search functions used in MTR tests:
    - include/search_pattern_in_file.inc: This function reads 50000 bytes
      per chunk and searches for a pattern in the chunk. However, this is
      bound to fail if the pattern crosses the border between two chunks
      and can cause sporadic failures.
    - include/search_pattern.inc: It reads the whole file into a list in
      memory and then processes lines one by one. It would be efficient
      if a single line is read at a [1;31mtime[m instead of the entire file.
      Also, matching lines which had a pair of single quotes are being
      ignored when the file is sourced multiple [1;31mtime[ms due to improper
      cleanup.
    
    Fix:
    ----
    Search functions have been consolidated into two inc files:
    - include/search_pattern.inc: It should be used for searching patterns
      which occur within a single line. It loads one line from the file at
      a [1;31mtime[m and searches the specified pattern in it. A buffer having the
      specified number of lines prior to the matching line and a file
      lookup for those after it are used to get context lines.
    - include/search_pattern_multiline.inc: It reads the whole file into
      memory and should be used to match patterns which might be spread
      across multiple lines.
    
    Usage of search functions in test scripts was reviewed and they have
    been modified to use search_pattern.inc for all single-line searches.
    
    Reviewed-by: Pavan Naik   <pavan.naik@oracle.com>
                 Deepa Dixit  <deepa.dixit@oracle.com>
    RB: 16811

[33mcommit ccf3c915f4f16f3cc163c32964b5af271d7bc5c8[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Wed Aug 9 14:01:52 2017 +0200

    Bug#25903274 PERFORMANCE REGRESSION WITH PREPARED STATEMENTS
    
    Introduced by CTEs.
    Consider:
      with cte as (select ?) select ? from cte;
    
    In trunk the list of '?'s, lex->param_list, is built in
    Item_param::itemize() which happens after parsing, in contextualization,
    and a CTE is contextualized when a reference to it is seen in FROM
    (when we parse WITH we make a PT_subquery but we don't contextualize it,
    just save it somewhere; when we see "FROM cte" we look "cte" up, find its
    PT_subquery node, and contextualize it); so the first '?' (of the CTE
    definition) is added second to the list, as the SELECT list has already
    been contextualized and added the second '?' first... CTEs introduced this
    possibility of a shuffled list. I worked around this by adding a sort()
    in init_param_array(), sorting by position-in-query, but a query with
    65k '?' [1;31mtime[md out.
    
    Fix: (Roy's idea) instead of building param_list during contextualization,
    build it when the parser sees the '?' and creates Item_param: this ensures
    that the list is naturally sorted in order of position-in-query, without
    the need for an explicit sort().
    
    No testcase; but the [1;31mtime[m to run main.mysql_client_test on my machine
    goes from 132 seconds down to 42 seconds. And that test has a query
    with a lot of '?'.

[33mcommit 8f84968789f5cdc5f5df451da3805971a5f39fe8[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Tue Aug 8 08:30:15 2017 +0200

    Bug#26582158 INNODB_REDO_LOG_ENCRYPT-SETTING TESTCASES ARE UNSTABLE
    
    Some of the testcases that test innodb_redo_log_encrypt:
    
    innodb.log_encrypt_3
    innodb.log_encrypt_kill
    sys_vars.innodb_redo_log_encrypt_kill
    
    set innodb_redo_log_encrypt to 1, sleep for some [1;31mtime[m, and expect the
    InnoDB master thread to have run and reset it back to zero because the
    server configuration does not support redo log encryption in those
    test parts. Using the sleep is a poor replacement for test
    synchronisation as the master thread is not guaranteed to have run on
    a loaded system.
    
    Fix by replacing sleeps with waits until the variable becomes zero.
    
    Patch contributed by Laurynas Biveinis.
    
    Approved by Allen Lai <zheng.lai@oracle.com>.

[33mcommit fb8d67315d2cb956976d838559ae3bdc88d43d60[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Jul 14 13:00:22 2017 +0200

    Bug#26442367 ALWAYS ENABLE SAFE_MUTEX IN DEBUG BUILDS, MAKE MEMCACHED UBSAN CLEAN
    
    CMakeLists.txt contains this snippet:
    
    IF(NOT WITH_INNODB_MEMCACHED)
      FOREACH(LANG C CXX)
          SET(CMAKE_${LANG}_FLAGS_DEBUG
              "${CMAKE_${LANG}_FLAGS_DEBUG} -DSAFE_MUTEX")
      ENDFOREACH()
    ENDIF()
    
    There  should be  no  reason to  disable safe_mutex  if  we build  the
    memcached  plugin  (it  actually   hides  real  problems,  since  most
    pushbuild trees are built with  the memcached plugin) Enabling it, and
    running with  UBSAN shows a  few issues,  with wrong mutex  usage, and
    undefined behaviour.
    
    engine.h
    src/innodb_engine.c:312:32:
    run[1;31mtime[m error: index 1 out of bounds for type 'feature_info [1]'
    
    config_parser.c
    config_parser.c:127:24:
    run[1;31mtime[m error: signed integer overflow: 1073741824 * 1024 cannot be represented in type 'int'
    
    innodb_engine.c
    the double assignment to innodb_eng->info.info.features[0].feature *must* be wrong
    innodb_engine.c:2341:3: run[1;31mtime[m error:
    null pointer passed as argument 1, which is declared to never be null
    
    sql/sql_plugin.cc
    ==9557== Process terminating with default action of signal 6 (SIGABRT)
    ==9557==    at 0x78DD91F: raise (in /usr/lib64/libc-2.24.so)
    ==9557==    by 0x78DF519: abort (in /usr/lib64/libc-2.24.so)
    ==9557==    by 0x78D5DA6: __assert_fail_base (in /usr/lib64/libc-2.24.so)
    ==9557==    by 0x78D5E51: __assert_fail (in /usr/lib64/libc-2.24.so)
    ==9557==    by 0x23272A2: safe_mutex_assert_owner (thr_mutex.h:151)
    ==9557==    by 0x2329884: plugin_del(st_plugin_int*) (sql_plugin.cc:1097)
    ==9557==    by 0x232C1FB: memcached_shutdown() (sql_plugin.cc:1889)
    ==9557==    by 0x21BC38F: clean_up(bool) (mysqld.cc:1925)
    ==9557==    by 0x21C7A72: mysqld_main(int, char**) (mysqld.cc:5970)
    ==9557==    by 0x21B9795: main (main.cc:25)
    
    Change-Id: I88bb6751ae8401d4c461a6f03dd098f016e0adf8

[33mcommit 88dedf5ec580b060380f6bb7e05c5392c7ba9fb6[m
Author: Darshan M N <darshan.m.n@oracle.com>
Date:   Wed Aug 2 21:26:25 2017 +0530

    WL#9536 Fixed pb2 failures
    
    This patch fixes a few pb2 failures
    
    1. main.mdl_tablespace test failure - test was waiting on a wait event in
       performance_schema.event_waits_history_long which used to get removed from
       the table quicklty because of the increased number of PS events resulting
       in a [1;31mtime[mout. Moved the TRUNCATE TABLE event_waits_history_long statement
       to truncate the table just before we allow ALTER to continue which moves
       the event from events_current table to events_history_long.
    
    2. main.information_schema - GROUP_CONCAT() in a query needed to be ordered
       to avoid result content mismatch error.
    
    3. main.dd_string - needed to record the test case.

[33mcommit 34a9bad08cb29410db399f098f828ed6ce907908[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Thu Aug 3 10:28:25 2017 +0200

    Bug#25526439: Assertion failed: is_fixed_or_outer_ref(this)
    Bug#25071305: Assertion failed: first_execution || !tl->is_view_or_derived() ...
    Bug#24716127: Incorrect behavior by insert statement with "on duplicate ..."
    
    This is a combined fix for three regression bugs in INSERT resolving
    that came after WL#5094 refactoring.
    
    The main problem here is about bad sequence of resolver actions, as
    WL#5094 introduced one sequence for all INSERT syntax that proved to
    be insufficient. The problem was that apply_local_transforms() was
    some[1;31mtime[ms not performed for subqueries in the INSERT ... ON DUPLICATE KEY
    UPDATE clause.
    
    It is necessary to know one implementation detail in order to grasp the
    full problem: Subqueries on INSERT ... VALUES clauses and subqueries in
    ON DUPLICATE KEY UPDATE clauses are attached to the last query block of
    the query expression of the INSERT statement, even though they are not
    actually referenced from this query block. And apply_local_transforms()
    will only be applied to subquery objects when called from an outermost
    query block.
    
    The solution is to identify three distinct cases for ON DUPLICATE KEY
    UPDATE resolving, with their required resolver sequences:
    
    1. INSERT INTO t ... VALUES ... ON DUPLICATE KEY UPDATE ...
       - Resolve VALUES expressions.
       - Resolve ON DUPLICATE KEY UPDATE expressions.
       - Call apply_local_transforms() on outer-most query block, which
         will include any subqueries in VALUES expressions.
    
    2. INSERT INTO t ... SELECT <non-union> ON DUPLICATE KEY UPDATE ...
       - Resolve SELECT query block, but do not call apply_local_transforms().
       - Combine context for SELECT query block and INSERT table
         (if the query block is non-grouped).
       - Resolve ON DUPLICATE KEY UPDATE expressions.
       - Call apply_local_transforms() on outer-most query block.
    
    3. INSERT INTO t ... SELECT ... UNION ... ON DUPLICATE KEY UPDATE ...
       - Resolve ON DUPLICATE KEY UPDATE expressions.
         (the outer query block may stay unresolved because there are no
          references into it).
       - Resolve the query expression, include calling apply_local_transforms()
         which will also include any subqueries in ON DUPLICATE KEY UPDATE
         clauses.
    
    In addition, we have extended with two new subquery context types:
    CTX_INSERT_VALUES and CTX_INSERT_UPDATE. They are used to generally
    provide more information about the parsing process, and in particular
    make it possible to build AST without outer references from subqueries
    in INSERT ... VALUES statements and in INSERT ... ON DUPLICATE KEY UPDATE
    statements.

[33mcommit c1990afbab7b61436bb8fe781aceaa4fb9a68a45[m
Author: Darshan M N <darshan.m.n@oracle.com>
Date:   Wed Aug 2 17:47:59 2017 +0200

    BUG#26555951 CRASH IN INNODB_DEADLOCK_WITH_AUTOINC - PB2 TEST FAILURE
    
    Problem:
    ========
    The problem is localized to the function lock_grant_vats().  The objects involved
    in the problem are "heap", "waiting" and "granted".  The objects "waiting" and
    "granted" are using "heap".  This "heap" is freed at the end of the function.
    The destructors of "waiting" and "granted" are called after that.  So this results
    in crash.
    
    Solution:
    =========
    The solution should be to increase the life[1;31mtime[m of "heap".  The "heap" needs to be
    freed after destroying objects "waiting" and "granted".
    
    RB: 16943
    Reviewed-by: Annamalai Gurusami <annamalai.gurusami@oracle.com>

[33mcommit 41455b9bee50e5206046f9adb094339784908d2c[m
Author: Darshan M N <darshan.m.n@oracle.com>
Date:   Sun Jul 30 18:47:31 2017 +0200

    WL#9536 Fixed another set of pb2 failures
    
    1) rpl_half_atomic_ddl_no_binlog test failure - recorded test results
    
    2) main.mdl_tablespace test failure - test was waiting on a wait event in
       performance_schema.event_waits_history which used to get removed from the
       table quicklty because of the increased number of PS events resulting in
       a [1;31mtime[mout. Fixed the issue by using performance_schema.event_waits_history_long
       which has more size than history and truncating this table before using it.

[33mcommit d057432973264cae4d7b59760b3fbde857e55673[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Sat Jul 29 13:48:02 2017 +0200

    Follow-up to WL#10972 : stabilize test
    
    One machine is pb2 is fast, and executes the 1000 iterations so fast
    that we don't have [1;31mtime[m to switch to the other connection and kill.
    So, allow more iterations, like before wl#10972 was implemented.

[33mcommit 3de057a008430c9b958706a35a0170eaebfb01f1[m
Author: Deepthi ES <deepthi.e.s@oracle.com>
Date:   Wed Jul 26 14:04:35 2017 +0530

    Bug#26495812 REMOVE MASTER-INFO-REPOSITORY=FILE/RELAY-LOG-INFO-REPOSITORY=FILE RUNS IN DAILY
    
    This patch removes the runs for following options in PB2 daily runs :
    1. master-info-repository=FILE
    2. relay-log-info-repository=FILE.
    
    Background :
    - master-info-repository and relay-log-info-repository values decide whether
      replication slave status information is logged to TABLE/FILE.
    - WL#6959 deprecated the options master_info_repository=FILE and
      relay_log_info_repository=FILE.
    Hence, we can reduce the turnaround [1;31mtime[m for daily runs by removing testing
    of features that are now deprecated.

[33mcommit bb9ccb61ca3a0e357cdf77380e8ad97de035a654[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Thu Jun 29 11:25:31 2017 +0200

    Bug#26369555: USE LAST-WINS STRATEGY FOR DUPLICATE KEYS IN JSON OBJECTS
    
    MySQL keeps the first key/value pair in a JSON object if multiple
    pairs with the same key have been specified. This is an unusual way to
    handle duplicate keys in JSON object, and not one that is mentioned as
    a possibility in RFC 7159.
    
    This patch makes it instead keep the last key/value pair in case there
    are duplicates. This is consistent with how JavaScript evaluates JSON
    objects, and it is also mentioned as a possible strategy in RFC 7159.
    
    This affects parsing of JSON text, so that {"a": 1, "a": 2} is
    normalized to {"a": 2} instead of {"a": 1}. It also affects the
    JSON_OBJECT function and the JSON_OBJECTAGG aggregate function, as
    they will now use the last value seen if the same key is encountered
    multiple [1;31mtime[ms.
    
    This change also fixes bug#26238736.
    
    Change-Id: I1c462c76264871894b7116f6ff8101956991f3e0

[33mcommit 192792505ae4a86e7a1d8328513847f5226cc721[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Tue Jul 4 20:22:29 2017 +0200

    Bug#25908290 FEW TESTS FAILING WITH ERROR "SHUTDOWN_SERVER" FAILED WITH ERROR 2. MY_ERRNO=175 [noclose]
    
    Tweak the shutdown_server [1;31mtime[mout to avoid PB2 problems.

[33mcommit 793e8e74ff6e34274a093638d5abe0c988f1394c[m
Author: Xing Zhang <xing.z.zhang@oracle.com>
Date:   Tue Jun 20 10:46:18 2017 +0800

    Bug #26286790: PERFORMANCE ISSUE OF EXPLICIT COLLATE CLAUSE
    
    Ordering by a varchar field with explicit collation is much slower than it
    with implicit collation, even if the explicit collation is same as the
    implicit one. A certain sorting with implicit collation needs 0.5 sec, but
    the sorting with explicit collation needs about 1 min.
    
    Cause:
    A item is created for the field with explict collation, and filesort treats
    its weight buffer length is fixed. But for the field with implicit
    collation, filesort treats its weight buffer length is variable. This
    causes there are much more chunks is created and needed to merge when doing
    filesort for the field with explicit collation. It consumes a lot of [1;31mtime[m.
    
    Fix:
    All new UCA collations we added don't need padding spaces anymore, so we
    let filesort know that the weight buffer length of the item is variable.
    
    Result:
    without this patch, [1;31mtime[m used to sorting reporter's data needs 0.51 sec and
    58.73 sec.
    With this patch, [1;31mtime[m used to sorting reporter's data needs 0.54 sec and
    0.76 sec.
    
    Change-Id: I5394faabf6325ff43f71ae6076dedebd3d75c105

[33mcommit 3da82d5953561cb5c8180efa51d3efce4c3b2076[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Sat Jul 8 11:00:11 2017 +0530

    BUG#26388194: MAKE MTR TO SEARCH FOR AN EXECUTABLE ONLY IN
                  'RUNTIME_OUTPUT_DIRECTORY'
    
    Description:
    ============
    After WL#10524, all executables will end up in
    "MYSQL_BINDIR/run[1;31mtime[m_output_directory" and MTR code had been modified
    to search for executables in the new location. But search for
    executables in old locations are not removed yet. So if an executable
    exists in old path, then it might be picked up by MTR and might cause
    unnecessary issues. MTR code needs some clean up.
    
    Fix:
    ====
    Remove the search for executables in old location(s) and search for
    them only in 'run[1;31mtime[m_output_directory' directory.
    
    Reviewed-by: Deepa Dixit <deepa.dixit@oracle.com>
    Reviewed-by: Tor Didriksen <tor.didriksen@oracle.com>
    RB: 16716

[33mcommit ae38a4c7d64711b15385459878071ff208568322[m
Author: Terje Rosten <terje.rosten@oracle.com>
Date:   Fri Jul 7 09:18:17 2017 +0200

    Bug#26328958 TEST FAILURE IN MAIN.BASEDIR WITH CUSTOM -DINSTALL_MYSQLSHAREDIR=
    
    Background:
    
    Cmake creates ${cmake_binary_dir}/sql/share/ regardless of
    INSTALL_SHAREDIR setting, to "fix" this MTR sets --lc-messages-dir and
    --basedir options.
    
    mysqld in main.basedir runs without --basedir and --lc-messages-dir
    options and breaks due to mismatch between compiled-in install layout
    and sandbox layout.
    
    Solution:
    
    Make both source and build sandbox layout more identical to install
    layout by moving sql/share/ to share/, such that
    run[1;31mtime[m_output_directory/ and share/ will have common parent
    (${cmake_binary_dir}) like in install layout.
    
    This make sense since WL#10441 as mysqld will find basedir and
    lc-messages-dir itself, if cmake creates share directory in
    ${cmake_binary_dir}/ according to -DINSTALL_MYSQLSHAREDIR, things
    would work out of box without options specified. This will work in
    build sandbox and after "make install". In other words mysqld basedir
    is moved from ${cmake_binary_dir}/sql/ to ${cmake_binary_dir}/ in
    sandbox.
    
    After change options --basedir and --lc-messages-dir can be removed
    from MTR runs, and special cases in mysqld.cc can be removed too.
    Search path "sql/share" is removed or adjusted.
    
    Tests fragments that don't have stable output any longer have been
    removed.
    
    Basedir option is used by MTR to find "itself" in sandbox mode, hence
    it can't be removed even if not used by mysqld. Variable is renamed
    to #mtr_basedir in generated my.cnf.
    
    Note:
    
    This means errmsg-utf8.txt is moved from sql/share to share/,
    take care when merging from older major versions.

[33mcommit 7e51e236af42d55c4f49d1c9bfcf8f240a323ab8[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Jun 15 21:21:30 2017 +0200

    WL#10824 Remove query cache [step 13, remove ndbcluster remnants]
    
    Remove code from ndbcluster maintaining various counters
    and lists for determining when a query should be evicted
    from the cache. This includes the entire "ndb util thread" as
    well as the system variable "ndb-cache-check-[1;31mtime[m"

[33mcommit b77037da7fa558fb8642ab5d5cb8b87ec1d71ede[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri May 26 13:05:59 2017 +0200

    Bug #25997748: MIGRATE FROM HASH TO STD::UNORDERED_MAP [patch 8, noclose]
    
    More conversions from HASH; stored procedures, [1;31mtime[mzones,
    and getting rid of the old Hash_set wrapper that made an STL-like
    (but not quite STL-compatible) interface around HASH.
    
    Change-Id: I29eafc42c3e69a45cf2e710a15981c8066f1886b

[33mcommit 39645535beda0a8ccd981ee91cc7c13a77acba5c[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Tue Jul 4 10:41:56 2017 +0100

    Bug #26364729 NDB : IMPROVE LOGGING OF NODE FAILURE HANDLING IN TC
    
     - Node failure handling in TC has a number of sub-steps which run
       concurrently.  All must complete before TC node failure handling
       is complete.
       Logging coverage is extended to record when a sub-step completes,
       and which sub-steps remain.
    
     - GCP / Node failure handling interactions
       TC takeover causes GCP participant stall at the Master TC to
       allow it to extend the current GCI with the taken-over
       transactions.
       - The stall can begin in various GCP protocol states
       - The stall can end in various GCP protocol states
       Logging coverage is extended to cover all scenarios.
       Additionally, 'debug print' style logging is change to be
       more consistent and understandable to users.
    
     - QMGR monitors node failure handling duration which requires
       participation of many blocks.  Currently it generates a
       warning log to the cluster log every minute, and generates
       some DIH debug information after 5 minutes.
       This functionality is made more aggressive, logging once
       every 30 seconds of delayed node failure handling, and
       including the DIH debug information every [1;31mtime[m.
    
     - Prefix of "DBTC instance %u:" shortened to "DBTC %u:"
    
     - A new ERROR code is added to assist testing.

[33mcommit a3d2aae231a0b54ab746a54e53ba1ee813f6f811[m
Author: Libing Song <libing.song@oracle.com>
Date:   Wed Jun 28 13:54:28 2017 +0800

    BUG#26148011 RPL.RPL_MULTI_SOURCE_CORRUPT_REPOSITORY
                 FAILS WITH RESULT CONTENT MISMATCH
    
    DESCRIPTION
    ===========
    The test uses show_relaylog_events.inc to show the content of
    some relay logs. the relay logs some[1;31mtime[ms have different
    content. That caused test failures.
    
    ANALYSIS
    ========
    The reason is that FLUSH LOGS is called immediately after
    slave is started. At the [1;31mtime[m, slave may or may not
    get Rotate/Format_description events from master. Most of
    the [1;31mtime[m, the events arrive before FLUSH LOGS and are written
    into the relay logs which are not showed by the test. But
    they some[1;31mtime[m arrive just after FLUSH LOGS, so they are
    written to the relay logs which are showed by the test.
    
    FIX
    ===
    The test just cares if SHOW RELAYLOG EVENTS FOR CHANNEL can
    be executed successfully, but not the result of the statement.
    So we just ignore the result by using --disable_result_log.

[33mcommit 7410151c5b072e964d92165ba1fb66c66841717a[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Mon Jul 3 17:41:52 2017 +0530

    WL#10524: Dynamic Linking of OpenSSL in MySQL Server for Windows
    
    Post-push fix, modified MTR to search for mysqld executable in
    run[1;31mtime[m_output_directory first.

[33mcommit 5ed6fc6bb56af560e5ab3b3d7e5c5da9fc452942[m
Author: Dag Wanvik <dag.wanvik@oracle.com>
Date:   Tue Jun 20 20:49:31 2017 +0200

    Bug#26359109 REFACTOR ITEM_FUNC::FIX_NUM_TYPE_SHARED_FOR_CASE FOR REUSE BY LEAD/LAG
    
    [ was: Settled a TODO FIXME item: reuse fix_num_type_shared_for_case for LEAD/LAG ]
    
    [ Revision 2: after Roy's 2. review
    
      - Renamed fix_*from_args -> aggregate_*  (after first rename in revision 1)
      - Fixed bug in set_data_type_date[1;31mtime[m: used wrong MAX_*_WIDTH constant
      - Removed Docygen reference to max_chars for methods that don't see
        that level of detail.
      - Unfolded logic into separate switch branches for readability in
        Item::aggregate_temporal_properties
    ]
    
    [ Revision 1: after Roy's review
    
      - All review items except:
    
      "I also wonder if we should skip max_length calculation here and
      thus ignore decimals in that calculation. Calculation of decimals
      might still be needed to avoid regressions in results, but
      max_length should be strictly derived from the float type, IMHO."
    
      and one changed that caused a crash:
    
      "I do not think we should set decimals here, we should accept the
      constructor default."
    
      which, if done, breaks func_[1;31mtime[m.test
    ]
    
    Settled a windowing TODO FIXME item: reuse fix_num_type_shared_for_case
    for LEAD/LAG
    
    - Added the method header file and made it non-static, so we can use
      it in Item_lead_lag.
    
    - Changed its signature to accept Item instead of Item_func, since
      Item_sum (parent class of Item_lead_lag) is not an Item_func.
    
    - In the process lifted auxiliary type resolving functions up from
      Item_result_field/Item_func up to Item (at Roy's request: we felt
      they belong more naturally there than in Item_result_field even
      though that is the closes common ancestor of Item_func and
      Item_sum).

[33mcommit 8b4aba8d58ab1d929fa216a69f959f6a22520c79[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Jun 27 14:00:24 2017 +0200

    WL#10524 Dynamic Linking of OpenSSL in MySQL Server
    
    Add bin symlink to run[1;31mtime[m_output_directory

[33mcommit b88808fd875bd7adfc26199055ba32e0212fbff9[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Mar 22 16:55:18 2017 +0100

    WL#10524 Dynamic Linking of OpenSSL in MySQL Server
    
    Extend MYSQL_ADD_EXECUTABLE with new arguments, and use it for
    generating *all* executables (including unit tests). Store all
    executables in ${CMAKE_BINARY_DIR}/run[1;31mtime[m_output_directory
    
    New target copy_openssl_dlls, which copies OpenSSL DLLs to
    run[1;31mtime[m_output_directory. All tools/executables used during build
    [1;31mtime[m depend on this (on windows only)
    
    Rewrite the regex unit test to run all three tests by default, rather
    than having three separate tests.
    
    Fix unused/unmaintained plugin/keyring/keyring-test
    
    Extend mtr to look for executables in
    ${CMAKE_BINARY_DIR}/run[1;31mtime[m_output_directory.
    
    The executable 'my_safe_process', used by mtr to start the server, is
    the only executable *not* moved to run[1;31mtime[m_output_directory.
    This is in order to minimize the changes necessary to mtr.

[33mcommit 584457f08c8990737b43e7a0e953f8d591125ae1[m
Author: Lakshmi Narayanan Sreethar <lakshmi.narayanan.sreethar@oracle.com>
Date:   Tue Jun 27 16:59:21 2017 +0530

    Bug#26027722 : Unknown Initial Character Set
    
    MySQL Server has now switched to utf8mb4 as the default charset. And
    over [1;31mtime[m, a lot of new charsets has been added and the total has
    already exceeded 256. But the CharsetMapImpl still handles only 256
    charsets. It also currently doesn't initialise the mysql_charset_name
    array properly - due to which a ClusterJ app might crash when handling
    charset with charset number 255.
    
    This patch updates ClusterJ to adapt to the new default Charset of the
    server.
    
    Changes
    
     CharsetMapImpl.h & CharsetMapImpl.cpp
     - Updated the class to handle atmost 512 charsets.
     - Fixed the issue in initialization of mysql_charset_name array and
       changed it to a private member.
    
     clusterj/pom.xml.in
     - Updated the pom to use the lastest Connector/J. The old version had
       some issues handling the utf8mb4 charset.
    
     DynamicObjectTest.java
     - Updated the expected charset and maximum column length in the
       testcase.
    
     storage/ndb/clusterj/clusterj-test/src/main/resources/schema.sql
     - Change charset of table `hope` to latin. The default charset utf8mb4
       increases the record length of the table beyond maximum and the
       table creation fails. Changing the charset to latin1 reduces the
       record length and fixes this issue.
    
     mysql-test/suite/ndb/t/disabled.def
     - Enabled the clusterj test back again.

[33mcommit 425588ef52491b160059713cc06657b001070a40[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Mon Jun 26 10:15:20 2017 +0200

    Bug#26336244: REMOVE USAGE OF BOOST IN MYSQLPUMP SOURCE CODE
    
    The mysqlpump code has some usage of boost that is easily avoided:
    
    boost::trim is used to remove the trailing newline character from the
    string returned by std::c[1;31mtime[m. However, all users of the returned
    string add a trailing newline for formatting purposes. This use of
    boost::trim can simply be dropped, and the formatting can stop adding
    the newline back.
    
    boost::split is used to read lines from a string, or some[1;31mtime[ms values
    from a comma-separated list. The use of boost::split causes
    maybe-uninitialized warnings inside of boost in gcc 7 under certain
    optimization levels (at least with -Og). It can be replaced with the
    use of std::istringstream and std::getline to read individual tokens
    from the stream. In one case std::string::substr is sufficient.

[33mcommit d9737c9114ceed97eff7f2e3edd974d43feb1f8e[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Mon Jun 26 08:45:15 2017 +0200

    Remove a couple of optimizer tests from valgrind runs.
    
    main.greedy_optimizer and main.window_functions_big [1;31mtime[m out.
    
    Approved by Anitha Gopi <anitha.gopi@oracle.com> over e-mail.

[33mcommit 5a54ce6645393343c43d7a67261e5597cbd6c275[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Sat Jun 17 14:02:14 2017 +0200

    Bug#25418534: JSON_EXTRACT USING WILDCARDS TAKES FOREVER
    
    Patch #2:
    
    find_child_doms() checks for duplicates each [1;31mtime[m it adds a result to
    the result vector. As explained in the header comment for
    Json_wrapper::seek(), the duplicate elimination is needed for paths
    which contain multiple ellipses, so in most cases it is unnecessary
    work.
    
    This patch makes find_child_doms() only check for duplicates in the
    case where the path contains multiple ellipses, and only when
    inspecting an ellipsis path leg which is not the first one.
    
    Additionally:
    
    Remove checks for empty vector after a successful call to push_back().
    That is, replace checks for is_seek_done(result, only_need_one) with a
    simple check for only_need_one when we know the result vector cannot
    be empty.
    
    Call is_seek_done() from the loop in Json_dom::seek() instead of at
    the top of find_child_doms(), so that we can break out of the loop
    earlier if we find a match and only need one.
    
    Microbenchmarks (64-bit, Intel Core i7-4770 3.4 GHz, GCC 6.3):
    
    BM_JsonDomSearchEllipsis              25693 ns/iter [+210.9%]
    BM_JsonDomSearchEllipsis_OnlyOne      17881 ns/iter [+324.3%]
    BM_JsonDomSearchKey                     128 ns/iter [  +0.8%]
    BM_JsonBinarySearchEllipsis          231319 ns/iter [ +38.7%]
    BM_JsonBinarySearchEllipsis_OnlyOne  222726 ns/iter [ +41.6%]
    BM_JsonBinarySearchKey                   86 ns/iter [   0.0%]
    
    Change-Id: I0ee624830680247ec5aed302c0408db00240d441

[33mcommit 3ea6ece3105a0420fbe0e3fa86019505888bc392[m
Author: Thirunarayanan Balathandayuthapani <thirunarayanan.balathandayuth@oracle.com>
Date:   Fri Jun 23 10:15:07 2017 +0530

    Bug#26197113 SLOW DYNAMIC TABLE STATISTICS RETRIVAL FROM I_S AFTER MYSQL-TRUNK-META-SYNC PUSH
    
    Analysis:
    
    If the table is not present in the cache then opening the table
    takes lot of [1;31mtime[m and it leads to slow performance in information
    schema queries.
    
    Following changes are done to fix the issue,
    
    InnoDB changes:
    
    - Instead of opening the table, InnoDB can fetch the stats
      information from innodb_table_stats and innodb_index_stats.
    
    - Fetch the record from innodb_table_stats using db_name, table name
      and it will give information about n_rows, clustered index_size and
      sum of other index size.
    
    - Fetch the space id from Tablespace SE private data for
      general/system tablespace (or) Fetch the space id using db_name,
      table_name from fil_space_t hash.
    
    - Use the space_id to calculate the available length in the
      tablespace.
    
    - Maximum value of autoincremnt fetched from innodb_dynamic_metadata
      using table id and autoincrement fetched from table_se_private data.
    
    - Cardinality can be fetched from innodb_index_stats table using
      db_name, table name, index name and column offset.
    
    - If the table doesn't have persistent stats then InnoDB loads
    the table from the disk.
    
    Server changes:
    
    - Supply mysql.tablespaces.se_private_data to internal functions
      INTERNAL_*(), which is used by SE to read the SE specific tablespace
      metadata when fetching table dynamic statistics. E.g., InnoDB would
      read the SE specific space_id from se_private_data column.
    
    - INFORMATION_SCHEMA.TABLES system view is now joined with
      mysql.tablespaces, to get the mysql.tablespaces.se_private_data for a
      table.
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Bin Su <bin.x.su@oracle.com>
    Reviewed-by: Praveenkumar Hulakund <praveenkumar.hulakund@oracle.com>
    RB: 16467

[33mcommit f70ea5b86024be897a4d2f427fc569c9ec86c09a[m
Author: Debarun Banerjee <debarun.banerjee@oracle.com>
Date:   Fri Jun 23 11:06:12 2017 +0530

        WL#9209: InnoDB: Clone local replica
        ====================================
        Create a server plugin that can be used to retrieve a snapshot
        of the running system. Here we would support syntax to take a
        physical Snapshot of the database and store it in same
        machine/node where the database server is running.
    
        We should be able to start mysqld server on the cloned directory
        and access data. The clone operation should work with concurrent
        DMLs on the database.
    
        INSTALL PLUGIN clone SONAME 'mysql_clone.so';
        CLONE LOCAL DATA DIRECTORY [=] 'data_dir';
        UNINSTALL plugin clone;
    
        Review: rb#15068
    
        WL#9212: InnoDB: Monitor Clone status
        =====================================
        Support metadata view in performance schema to monitor progress
        of an ongoing clone operation. A clone operation might take [1;31mtime[m
        to clone the entire database. Administrator can view the current
        status and percentage of clone operation completed by querying
        this view in local and remote server.
    
        EVENT_NAME = "statement/sql/clone"
        EVENT_NAME = "stage/sql/clone (file copy)"
        EVENT_NAME = "stage/sql/clone (page copy)"
        EVENT_NAME = "stage/sql/clone (redo copy)"
    
        Review: rb#14160
    
        Merged from mysql-trunk-wl8953 [3db0acef]

[33mcommit df5c7956bb106edd16304219faaf5e67099fe7a9[m
Author: Thirunarayanan Balathandayuthapani <thirunarayanan.balathandayuth@oracle.com>
Date:   Fri Jun 23 10:15:07 2017 +0530

    Bug#26197113 SLOW DYNAMIC TABLE STATISTICS RETRIVAL FROM I_S AFTER MYSQL-TRUNK-META-SYNC PUSH
    
    Analysis:
    
    If the table is not present in the cache then opening the table
    takes lot of [1;31mtime[m and it leads to slow performance in information
    schema queries.
    
    Following changes are done to fix the issue,
    
    InnoDB changes:
    
    - Instead of opening the table, InnoDB can fetch the stats
      information from innodb_table_stats and innodb_index_stats.
    
    - Fetch the record from innodb_table_stats using db_name, table name
      and it will give information about n_rows, clustered index_size and
      sum of other index size.
    
    - Fetch the space id from Tablespace SE private data for
      general/system tablespace (or) Fetch the space id using db_name,
      table_name from fil_space_t hash.
    
    - Use the space_id to calculate the available length in the
      tablespace.
    
    - Maximum value of autoincremnt fetched from innodb_dynamic_metadata
      using table id and autoincrement fetched from table_se_private data.
    
    - Cardinality can be fetched from innodb_index_stats table using
      db_name, table name, index name and column offset.
    
    - If the table doesn't have persistent stats then InnoDB loads
    the table from the disk.
    
    Server changes:
    
    - Supply mysql.tablespaces.se_private_data to internal functions
      INTERNAL_*(), which is used by SE to read the SE specific tablespace
      metadata when fetching table dynamic statistics. E.g., InnoDB would
      read the SE specific space_id from se_private_data column.
    
    - INFORMATION_SCHEMA.TABLES system view is now joined with
      mysql.tablespaces, to get the mysql.tablespaces.se_private_data for a
      table.
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Bin Su <bin.x.su@oracle.com>
    Reviewed-by: Praveenkumar Hulakund <praveenkumar.hulakund@oracle.com>
    RB: 16467

[33mcommit 1b5c66a69e72dda334dd87b44f6c9e06b960f50f[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Jun 6 12:51:06 2017 +0200

    wl#10234: Fix broken testScan -n Bug16402744 doing ERROR_INSERT 8097.
    
    Original testcase was intended to check behaviour when taking
    a CONTINUEB break just before sending fragment scan REQs
    for the last fragment to be scanned.
    
    This has detoriated over [1;31mtime[m, and became even more broken as part of
    this wl when splitting the DIH-REQ - start LQH Scan logic, into two phases
    where *both* of these phases incorrectly handled the same 8097 error insert.
    
    1) Patch fixes issue above such that 8097 error insert is only
       handled prior to sending the last 'start frag scan' to LQH as
       original intended.
    
    2) if (ERROR_INSERTED_CLEAR(8097) .. was checked as first term in the
       condition for when to take a CONTINUEB-break. This caused the
       error code to be CLEAR'ed the first [1;31mtime[m it was checked, and not
       after also the two other terms evaluated to 'true'.
    
    3) The 'Last fragId' check was expressed as:
        'scanFragP.p->scanFragId == scanptr.p->scanNoFrag-1)'
       However'scanFragId' was not yet assigned when checked. Replaced
       with scanptr.p->scanNextFragId which it will be assigne dfrom.
    
    Also see commit msg for bug16402744 for understanding how this testcase
    was intended to work.

[33mcommit 5dacf5fca342c55413fd3b1ccad4fb4c22c68999[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Thu Jan 28 15:15:32 2016 +0100

    Bug#21974346: GROUPING ON AGGREGATED RESULTS NOT ALWAYS REJECTED
    
    If a subquery references the alias of an aggregated expression from
    one of the outer query blocks, it could some[1;31mtime[ms be accepted even if
    the alias was referenced from within the GROUP BY clause of the query
    block where the aggregation happened. Such queries are meaningless and
    should be rejected.
    
    The problem lies in Item_ref::fix_fields(), which currently rejects
    the reference if it is not inside the HAVING clause of the query block
    that contains the reference. There are two problems with this:
    
    1) It is not the position within the query block that contains the
    reference that should decide if the reference is valid, but the
    position inside the query block where the aggregation happens.
    
    2) Non-outer references to aggregated expressions are allowed other
    places than HAVING, for example in ORDER BY. Outer references could be
    accepted in those positions too. They should be rejected if they are
    in the GROUP BY clause, though, since grouping happens before
    aggregation.
    
    This patch makes the following changes:
    
    Item_ref::fix_fields() now raises an error if a reference to an
    aggregated expression is in the GROUP BY clause of the query block
    where the referenced expression is aggregated. As before, it also
    raises an error if the reference is not in the HAVING clause of the
    query block it is referenced from. The net effect is that we reject
    the previously accepted meaningless queries, but we don't accept any
    new queries that were previously rejected.
    
    resolve_ref_in_select_and_group() is reorganized to make it clearer
    how it works. It now returns earlier when it knows what the result is
    going to be, so that it doesn't have to check the same conditions
    multiple [1;31mtime[ms. This part of the patch is just a cleanup, and it is
    not essential for the correctness of the queries. It was originally
    included in the patch in order to remove some dead code for rejecting
    invalid forward references, but the dead code was revived in
    bug#22328395.
    
    Change-Id: I83a71931f5edf5e016bda5ba48672245d0eb099b

[33mcommit 484fa9beee494eb246517899caa21c77729183ac[m
Author: Erik Froseth <erik.froseth@oracle.com>
Date:   Tue Jun 20 13:46:37 2017 +0200

    Bug#26303972 HISTOGRAM.CC:1169: BOOL HISTOGRAMS::DROP_ALL_HISTOGRAMS
    
    Problem: When altering a table, the server will try to either rename
    or remove any column statistics that might become invalid due to the
    altering. During this process, the server tries to open the original
    table definition in order to retrieve all the columns of the original
    table, pre altering. The column statistics code tried in this case
    to open the original table definition after it became unavailable.
    
    Fix: Pass the original table definition that has already been aquired
    earlier down to the column statistics code. This way we know for sure
    that the table definition is available.
    
    Another problem that revelaed itself was that the value of
    create_info->encrypt_type was freed at the [1;31mtime[m we tried to read it
    in alter_table_drop_histograms (revealed by valgrind). The fix was
    to instead look at the options of the altered table definition to
    determine whether encryption is enabled or not for the altered
    table.
    
    Change-Id: I24e98c0282f156fbc6d2f6e6ca670d85d02c1641

[33mcommit 46c512787aa616d3dbe5182672bb5079a6830eac[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Tue Jun 20 11:24:24 2017 +0200

    Bug#25908290 FEW TESTS FAILING WITH ERROR "SHUTDOWN_SERVER" FAILED WITH ERROR 2. MY_ERRNO=175 [noclose]
    
    Make the tests run with longer [1;31mtime[mout for server shutdown.
    
    Approved by Pavan Naik <pavan.naik@oracle.com> over IM.

[33mcommit 8b548e1247e9b44b059d93f8beb86895080e7a41[m
Author: Arnab Ray <arnab.r.ray@oracle.com>
Date:   Sat Jun 10 00:36:44 2017 +0530

    WL#8500 Adapt MySQL Cluster to 8.0
    
    - Update the gcol_supported_sql_funcs_ndb and ndb_many_fragments
      result files
    - New result is due to WL#9687: Change default for
      explicit_defaults_for_[1;31mtime[mstamp to ON. Timestamp columns are
      now nullable by default
    - Another change is due to change in default character set to
      utf8mb4
    
    (cherry picked from commit 0d13c1ffe160636053ce7ea60d86c79dca597ad5)

[33mcommit 4b4bff53cafab0a0992bdb48f8a0d6fa51f56eab[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Wed Jun 14 17:13:46 2017 +0530

    WL#9687 : Change default for explicit_defaults_for_[1;31mtime[mstamp to ON
    
    Post push fix:
    
    main.mysql_client_test fails when executed with valgrind with error
    'Conditional jump or move depends on uninitialised value'. The
    reason is that fprintf() is passed with a NULL pointer instead of
    valid string.
    
    With change of the default value of explicit_defaults_for_[1;31mtime[mstamp,
    NULL value is not auto converted to current_[1;31mtime[mstamp value for a
    [1;31mtime[mstamp column. Instead, NULL is inserted in [1;31mtime[mstamp column.
    The test case ends up passing NULL instead of valid [1;31mtime[mstamp to
    fprintf() and this causes the valgrind error. The fix is to insert
    current_[1;31mtime[mstamp for [1;31mtime[mstamp column.

[33mcommit 180197d12147b757122f8e9425a926ab744178bb[m
Author: Erik Froseth <erik.froseth@oracle.com>
Date:   Wed Jun 14 15:01:14 2017 +0200

    WL#8943 Extend ANALYZE TABLE with histogram support
    
    Post-push fix:
    
    1) Remove the file mysql-test/include/analyze-[1;31mtime[mout.test
       that was added by a mistake.
    
    2) Adjust the help text for the new option "--column-statistics"
       in mysqldump and mysqlpump.
    
    Change-Id: Id1d28814dedb859a87f943d313f8318f9445315b

[33mcommit cf2783ab7c8895d3b95017cc27cf7c3976a6ea9c[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Jun 13 14:54:55 2017 +0200

    Bug #25997748: MIGRATE FROM HASH TO STD::UNORDERED_MAP [noclose]
    
    Post-push fix: Fix a concurrency issue where DROP PROCEDURE could get a
    hash pointer outside the ACL lock, leading to a crash if FLUSH PRIVILEGES was
    running at the same [1;31mtime[m, replacing the hash.
    
    Change-Id: Ic05865663414673ebbf8a793eeed65bd0a8aa5d8

[33mcommit 194d1057907c8cc3000f329727fe72bee50ae967[m
Author: Arnab Ray <arnab.r.ray@oracle.com>
Date:   Sat Jun 10 00:36:44 2017 +0530

    WL#8500 Adapt MySQL Cluster to 8.0
    
    - Update the gcol_supported_sql_funcs_ndb and ndb_many_fragments
      result files
    - New result is due to WL#9687: Change default for
      explicit_defaults_for_[1;31mtime[mstamp to ON. Timestamp columns are
      now nullable by default
    - Another change is due to change in default character set to
      utf8mb4

[33mcommit 794e1742151562a39186b172efc4584fd840606d[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Mon May 29 17:22:25 2017 +0300

    Pre-requisite patch for WL#6049 "Meta-data locking for FOREIGN KEY tables".
    
    Ensure that we set Foreign_key_spec::db at the Foreign_key_spec
    construction [1;31mtime[m and not later, during statement execution
    phase. Also now we normalize both database and table names in
    --lower-case-table-name > 0 modes at this point. For cases
    when original database and table names are necessary
    Foreign_key_spec::orig_ref_db/orig_ref_table members
    were introduced.

[33mcommit 84ff6252483723ee417c7a08a015f41df9f55352[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Thu May 11 09:01:13 2017 +0200

    WL#10302: When performing system restart we can some[1;31mtime[ms start from an old GCI, in this case we need to update the m_max_completed_gci at reception of CNTR_START_CONF since no GCPs will be executed during a SR. Fixed a bug in lgman.cpp introduced by WL#10302, after this it is better understood how the LGMAN actually uses head and tail.

[33mcommit f2cddfb41821e5e150b0edcd925948561e0eee13[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Tue May 2 09:54:04 2017 +0200

    WL#8069: Fixed a test case that dropped SCAN_NEXTREQ signals, some[1;31mtime[ms this dropped a SCAN_NEXTREQ as part of a LCP scan and this caused the wrong error to occur and thus test case to fail

[33mcommit 7e1b37963df7f912bfb480cd731c67c54a738bad[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Wed Apr 12 12:01:07 2017 +0200

    WL#8069:
    Decreased test [1;31mtime[m for TableAddAttrs tests, got a bit too long, some debug changes
    BUG#25860002:
    Fixed an issue where I missed to initialise the lcpPtr

[33mcommit 7ebb9121ed15ff1d6462588c5b409dc96326440e[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Fri Apr 7 17:00:07 2017 +0200

    WL#8069: We missed setting LCP_SKIP bit in a very short [1;31mtime[m interval between ScanOp::First to setting ScanOp::Next, in this interval we reported all rows as being scanned and thus no need to set LCP_SKIP bits, led to inconsistent data much later in a restart

[33mcommit 49eb19da4e0a8d8a96f96811480057f4c70fbea7[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Mon Apr 3 16:20:26 2017 +0200

    WL#8069: Crash when not EXEC_FRAGCONF have arrived in [1;31mtime[m instead of entering eternal wait loop

[33mcommit 72a8eddbb669aab1c3a4e81e40891696c8e6a7b7[m
Author: Anibal Pinto <anibal.pinto@oracle.com>
Date:   Tue Jun 6 17:57:07 2017 +0200

    BUG#25700098: GROUP_REPLICATION.GR_REPLICATION_TIMESTAMPS TEST IS FAILING.
    
    The issue is once the joining server is online some[1;31mtime[ms the view_id
    transaction is being shown as last_applied_transaction in applier channel
    instead of the recovery channel. Some[1;31mtime[ms view_id transaction is being applied
    through applier channel and being skipped in recovery channel.
    
    The transaction for the view change is spitted in three steps: BEGIN, VCLE
    (view change log event) and the COMMIT.
    
    Once the recovery channel applier dispatches the VCLE event, it triggers the
    recovery process end. This recovery process end will inform applier channel
    that it can start to apply its queued transactions.
    The first queued transaction on applier channel it is the same exact view
    change that did arrive through recovery. View change it is logged on all
    members on the same order. This view change will be skipped since its GTID was
    already applied on recovery channel.
    
    Though, on unlikely situations, the actual apply of the COMMIT of the view
    change that arrives through recovery may be delayed, and the recovery end
    signal, sent after event dispatch may interrupt its apply.
    On that case the view change will be applied through the applier channel. Since
    the view changes are exactly the same and the order it is ensured, there is no
    issue. The only subtle change it is that DBA will see it being applied through
    a different channel and its server_id will be the one of the joining server and
    not the donor.

[33mcommit 129aca97f926414a479d01b71b364656d93d4b76[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Wed Jun 7 08:57:07 2017 +0200

    Bug #25563891: OPTION SET BY !INCLUDE OR !INCLUDEDIR SHOWED AS 'COMPILED'
                   IN P_S.VARIABLES_INFO.
    Bug #25608115: VARIABLES_INFO.SET_TIME COLUMN INITIALIZED INCORRECTLY
    Bug #25776940: SERVER NOT COMING UP WHEN VARIBLES SET WITH PERSIST&RESTARTED
                   WITH SKIP-GRANT-TA
    
    Problem: P_S.variables_info table: VARIABLE_SOURCE column is not reflected
             with correct values for variables which are specified in config file
             as part of include directive file.
    Fix:     default_paths is a hash map which keeps track of all standard paths
             with respective variable source enum values. Since include directives
             can be specified in cnf and login config files, we add the new path
             specified as part of include dir in this hash map along with appropriate
             enum value. This update will cause ps.variables_info.variable_source
             column to be populated with correct values.
    Test:    Added the new testcase to persisted_variables_extended.test.
    
    Problem: When event_scheduler variable is persisted and server is restarted
             with --skip-grants-tables option then server does not start and
             instead reports error as below:
             2017-03-24T08:50:13.127995Z 2 [ERROR] Failed to set persisted options.
             2017-03-24T08:50:13.128091Z 0 [ERROR] Setting persistent options failed.
             This error is not allowing end user to understand what the problem is.
    Fix:     Fix is to report some meaningfull error so that user can take necessary
             actions to overcome the error.
    Test:    Did manual test and i see that proper error message is reported.
    
    Problem: performance_schema.variables_info table SET_TIME columns default value
             is not set to server startup [1;31mtime[m, instead set to [1;31mtime[m when first
             SELECT is executed on this table.
    Fix:     Intialize this columns default value to server startup [1;31mtime[m.
    Test:    Added the new testcase to persisted_variables_extended.test.

[33mcommit 7369c319bcac341b730b80769420ca503f00fcda[m
Author: Anitha Gopi <anitha.gopi@oracle.com>
Date:   Wed May 24 05:20:25 2017 +0200

    Bug #25819886   IMPROVEMENTS TO MTR TEST COLLECTIONS
    
    Made following changes to test collections:
    1.  Improved comments
    2. Removed references to disabled-per-push.list, disabled-daily.list and disabled-weekly.list. Tests should be disabled with the normal disabled.def mechanism and not by any other means.  Per push runs have to be kept short by moving tests to daily and weekly, not by disablng lists.
    3. Removed disabled-per-push.list, disabled-daily.list and disabled-weekly.list
    4. Use --do-suite MTR option to avoid listing several suites in command line .  eg: Replace "--suite=rpl,rpl_gtid,rpl_nogtid" with --do-suite=rpl. This makes command lines easier to read. It also ensures that any new suites that are added will run if the suite name is prefixed with "rpl".
    5. Removed --testcase-[1;31mtime[mout=60 from command lines that do not have --big-test. These should run with default [1;31mtime[mout
    6. Removed runs with --binlog-checksum set to CRC32. This is the default value and hence just duplicates normal runs of replication suites
    7. Removed explicit references to --retry-failure and --max-test-fail. Tests
     should just use the default values
    8. Removed bug#23622964-valgrind-skip-list. The test is skipped in valgrind by not_valgrind.inc
    
    Reviewed by : Erlend Dahl <erlend.dahl@oracle.com>

[33mcommit 2622e8c22a8634390820c0a297c4a83e1e4d718a[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Mon Jun 5 11:49:57 2017 +0100

    Bug#25891014 NDB : ONLINE BACKUP LOG CONTAINS EXTRA ENTRIES
    
    Current ndbmtd online backup is including too many entries in the
    backup log.
    
    Specifically, row changes occurring to fragments managed by LDM
    instance 1 are always recorded in the log, even if they are for
    non-primary fragments.
    
    This wastes resources at restore [1;31mtime[m, and can result in other
    problems when e.g. staging tables are used for schema transforms
    during ndb_restore.
    
    This patch corrects the problem, and adds an MTR testcase which
    checks that the backup log contains only the expected entries,
    and no duplicates.

[33mcommit 6de594adf488add4514884d18c337745b1d227fb[m
Author: Joao Gramacho <joao.gramacho@oracle.com>
Date:   Tue Mar 7 12:05:46 2017 +0000

    WL#10406: Improve usability when receiver thread is waiting
              for disk space
    
    Step 1
    ======
    
    This patch replaced the requirement to access Master_info format
    description event from Master_info->data_lock to relay_log->LOCK_log.
    
    It also changed the locking order at queue_event() to
    relay-log->LOCK_log, Master_info->data_lock.
    
    It made the SQL thread not rely on the relay log LOCK_log to be
    stopped anymore.
    
    Step 2
    ======
    
    Truncating the relay log in correct event boundaries
    ----------------------------------------------------
    
    This patch introduced the MYSQL_BIN_LOG::truncate_relaylog_file(). This
    function is called after errors writing events to the relay log, passing
    the relay log end pos (the end of the last known successfully written
    event) to minimize the possibility of the applier thread to read a
    partial (bad) event.
    
    Displaying "Waiting for disk space" on status
    ---------------------------------------------
    
    This patch introduced enter_stage_hook to make my_write() able to set
    the current thread stage as "Waiting for disk space" before calling
    wait_for_free_space() function and restoring the previous thread stage
    after the function call.
    
    This will make any thread waiting for disk space on my_write() to report
    this information not only in error logs but also in thread status
    interfaces (performance schema tables, SHOW SLAVE STATUS, etc.).
    
    WL related bug fixes
    ====================
    
    BUG#26111422 ASSERTION `IS_OPEN()' FAILED AT
                 MYSQL_BIN_LOG::TRUNCATE_RELAYLOG_FILE
    
    Problem
    -------
    
    The replica server is trying to truncate a closed relay log file when an
    unrecoverable error occurred while rotating the relay log.
    
    Analysis
    --------
    
    In the case of an unrecoverable error when rotating the relay log, the
    server will take the configured BINLOG_ERROR_ACTION.
    
    When BINLOG_ERROR_ACTION=ABORT_SERVER, the server will be shutdown.
    
    When BINLOG_ERROR_ACTION=IGNORE_ERROR, the server will close the relay
    log. The only way of recovering the closed relay log is to restart the
    whole server.
    
    The code at truncate_relaylog_file() is asserting that the relay log was
    opened when called to prevent trying to truncate a closed relay log.
    
    Fix
    ---
    
    Because of the possibility of calling the function after an error
    rotating the relay log, the truncate_relaylog_file() function should
    not assert that the relay log is open and also should take no action
    when the relay log was closed.
    
    BUG#26161405 EXECUTING STOP SLAVE WHEN IO_THREAD IS "WAITING FOR DISK
                 SPACE" CAUSES PROBLEMS
    
    Problems
    -------
    
    STOP SLAVE [IO_THREAD] will set mi->abort_slave flag and will wait until
    the I/O thread to be stopped.
    
    When the I/O thread is waiting for disk space, the mi->abort_slave
    signal will not be checked by the I/O thread until finishing queuing the
    current event. So, "STOP SLAVE" will be blocked (until STOP SLAVE
    [1;31mtime[mout with an error).
    
    Also, any thread waiting for disk space at "my_write" (thread that used
    the MY_WAIT_IF_FULL flag) could report itself as "Waiting for disk
    space".
    
    Shutting down the server while having an I/O thread waiting for disk
    space would hang the server without accepting new connections until disk
    space be freed.
    
    Fixes
    -----
    
    STOP SLAVE [IO_THREAD] throws a warning message into the server error
    log recommending either to free some disk space or to use 'KILL' to
    abort I/O thread operation.
    
    Only the relay log related operations will change the thread status to
    "Waiting for disk space". A new flag was used to signal the my_write
    function to change the thread status.
    
    Shutting down the server while having an I/O thread waiting for disk
    space will make the I/O thread to be killed, truncating the current
    relay log file if possible.
    
    Fixed a doxygen issue at MYSQL_BIN_LOG::truncate_relaylog_file().
    
    Fixed an issue in "performance_schema.threads" that was not showing
    "Waiting for disk space" at PROCESSLIST_STATE field.

[33mcommit 57092afe02aa086f344345d22f8e188e7ac4e155[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue May 30 12:08:12 2017 +0200

    Bug#26147274 ASSERTION `ITEM->MAYBE_NULL' AT MAKE_SORTKEY_FROM_ITEM IN SQL/FILESORT.CC
    
    Problem:
    filesort gets an unexpected NULL value during execution (maybe_null == false)
    
    This is caused by disabling date[1;31mtime[m checks during insert, then re-enabling
    them during select ... order by. Item_func_min_max::get_date() calls
    check_date which does *was_cut= MYSQL_TIME_WARN_ZERO_IN_DATE; return TRUE;
    
    Change-Id: Ib3b2b0f0d61c2429347c1a30279acfc49b0479d4
    Fix: use error_int() to return correct status in Item::val_date_temporal()

[33mcommit cc6b9fa428fd539a39b03adb6e8cb762f2f95dac[m
Author: Darshan M N <darshan.m.n@oracle.com>
Date:   Thu Jun 1 10:49:22 2017 +0530

    Bug#24658707 ASSERT: BUF0BUF.CC:2469:BUF_BLOCK_GET_STATE(BLOCK)
    == BUF_BLOCK_FILE_PAGE
    
    Issue
    =====
    The issue is that during commit_inplace_alter_table we wake up the purge
    thread and we take a btr search latch and try to disable the adaptive hash
    search system and empty the index. The purge operation happening in the
    background, when flushing the pages, tries to remove possible adaptive hash
    index on the page and it sets the the block state as BUF_BLOCK_REMOVE_HASH
    and waits on the btr search latch taken by the alter command. And in the
    alter command when we're trying to empty the hash index of the same block
    we hit the assertion ut_ad(buf_block_get_state(block) ==
    BUF_BLOCK_FILE_PAGE) as the block state was changed by the purge operation.
    Both the threads would be working on the same block at the [1;31mtime[m of
    assertion.
    
    Fix
    ===
    The fix has already been pushed to trunk as part of meta-sync branch.
    Readding the assert which was removed earlier to silence the pb2 failures
    which was because of this bug.
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit fa3880ae35bcc593d40e2f30c8d074748162984e[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Tue May 16 12:58:54 2017 +0200

    WL#10441: Add mysqld_safe-functionality to server
    
    - Find the the absolute path of the executable and make argv[0] point to it
    
    - Deduce mysql_home (aka basedir) from the executable path
    
    - Let mysqld::run[1;31mtime[m::mysqld_daemonize() return (rather than call
      exit directly) on the parent side, and call
      flush_error_log_messages() to get all messages from the daemonize
      process properly formatted. Move the call to mysqld_daemonize() to a
      point where paths have been resolved agains CWD so that a daemon
      process treats relative paths in the same way as a regular server.
    
    - Print the name of the chosen error log file before opening and redirecting
      stderr so that users can see where the daemon will try to log messages.
    
    - Fix a bug in open_error_log() which assumed the log file could be used if stat
      showed it to be writable for user (that will be true even if it is not owned
      by the current uid). When calling my_freopen() on such a file the stderr
      FILE pointer becomes invalid, and this causing messages to be lost.
    
    - New mtr test main.basedir.

[33mcommit 343ebfda66b8d5bc8c681dced86e47389cee10f8[m
Author: Neha Kumari <neha.n.kumari@oracle.com>
Date:   Sat May 27 15:54:54 2017 +0530

    Bug#25973525:INCORRECT WARNING IS LOGGED ON"FLUSH LOGS"WHEN BINARY-LOG IS IN USE AND ELD!=0
    
    Problem:
    With current behaviour if expire_logs_days/binlog_expire_log_seconds(on mysql-trunk)
    is set, following warning will be logged whenever the user issues
    "FLUSH LOGS"/"PURGE LOGS BEFORE" and binlog file is in use, though the file is
    not old enough to get purged.
    Eg:
    2017-04-27T09:42:10.202909Z 10 [Warning] file ./master-bin.000001 was not purged
    because it was being readby thread number 12
    
    The warning is incorrect since it gives a notion to the user that system tried
    to purge the log-file even when it was not old enough to get purged.
    
    Analysis:
    The root cause is that we check if a log is being used by other thread firstly
    while purging it.
    
    Fix:
    To fix the problem, we check if a log older than the purge [1;31mtime[m firstly, then
    check if it is being used by other thread while purging it. This will ensure
    that the above warning is gone.
    
    The changes in test rpl_4threads_deadlock was done because it started failing
    after the changes done in binlog.cc. The reason for failure is explained below.
    
    The sync point 'purge_logs_after_lock_index_before_thread_count' is set in the
    method which checks if the log is in use, after the changes done in binlog.cc
    this check(if the log is in use) will be done after purge_[1;31mtime[m check. The
    purge_[1;31mtime[m in test was set as 9999-12-12 which was effectively being converted
    to 0(Bug#26147576) and thus the sync point will never be reached.
    To fix this the purge_[1;31mtime[m is modified to 2038-01-19(highest permissible value).
    
    Additional changes done in rpl_4threads_deadlock
    - We need to have the FLUSH LOGS command inside the while loop so that we have
      binary logs to flush in second iteration as well, as the PURGE LOGS command
      will purge all but the current binary log file.

[33mcommit e796a72c7a334b55897d1eef84906a9e85f1f617[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Sat May 27 00:05:33 2017 -0600

    WL#10322: Deprecate innodb_undo_logs in 5.7
    
    * Add (deprecated) to innodb-undo-logs description and mention that it
    is actually setting the number of rollback segments.
    * Delete “(deprecated)” from innodb-rollback-segments message.
    * Add a deprecation warning message when innodb_undo_logs is used
    at run[1;31mtime[m and also at startup in a config or the command line.
    * Return a warning when innodb_undo_logs is used at run[1;31mtime[m.
    * Rename srv_undo_logs to srv_rollback_segments in code
    * Rename innodb_undo_logs to innodb_rollback_segments in all collections
    and testcases except sysvars.innodb_undo_logs_basic.
    * Fix sysvars.innodb_undo_logs_basic to suppress the deprecation warning.
    Add a restart to exercise the deprecation code for using it at startup.
    
    Approved by Satya in RB#15389

[33mcommit b769734044054ffec65a5f70fbd6c94527b2db74[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Wed May 24 22:22:15 2017 -0700

    WL#10322: Deprecate innodb_undo_logs in 5.7
    
    * Add (deprecated) to innodb-undo-logs description and mention that it
      is actually setting the number of rollback segments.
    * Delete “(deprecated)” from innodb-rollback-segments message.
    * Add a deprecation warning message when innodb_undo_logs is used
      at run[1;31mtime[m and also at startup in a config or the command line.
    * Return a warning when innodb_undo_logs is used at run[1;31mtime[m.
    * Rename srv_undo_logs to srv_rollback_segments in code
    * Rename innodb_undo_logs to innodb_rollback_segments in all collections
      and testcases except sysvars.innodb_undo_logs_basic.
    * Fix sysvars.innodb_undo_logs_basic to suppress the deprecation warning.
      Add a restart to exercise the deprecation code for using it at startup.
    
    Approved by Satya in RB#15389

[33mcommit 0eccb1ab6eef6f1998a2d15025358d81a1ba8100[m
Author: Joao Gramacho <joao.gramacho@oracle.com>
Date:   Fri Feb 17 15:48:37 2017 +0000

    BUG#25584734 SHOW BINLOG/RELAYLOG EVENTS BLOCKED WAITING FOR LOCK_LOG
    
    Problem/Analysis
    ----------------
    
    The access to the binary/relay log events by SHOW BINLOG|RELAYLOG EVENTS
    blocked the log access by acquiring the log lock_log for the whole
    "dump", but this was fixed in BUG#20928790.
    
    After BUG#20928790 was fixed, SHOW BINLOG|RELAYLOG EVENTS statements
    acquire the log's lock_log only for a brief amount of [1;31mtime[m to calculate
    the end of the log file. This was necessary in MySQL 5.6 in order to
    avoid to read "partial" events while the binary/relay log was being
    written (by commits or by the receiver thread).
    
    In MySQL 5.7, WL#5721 has implemented the binlog_end_pos, to allow the
    dump thread to read from the binary log (even from the "hot" log file)
    without the need of acquiring the log's lock_log. In this way, no dump
    thread would block commits from happen.
    
    In MySQL 8.0.1, WL#8599 made the applier threads to rely on
    binlog_end_pos too.
    
    Fix
    ---
    
    Now, SHOW BINLOG|RELAYLOG EVENTS was modified to
    rely on the binlog_end_pos for the "hot" log file. This made the
    statements to not block commits or receiving events at all.

[33mcommit 7fc29107d02cb9c8239ffa6baad63bbf10dd152e[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Wed May 24 15:05:19 2017 +0530

    WL#9687 : Change default for explicit_defaults_for_[1;31mtime[mstamp to ON
    
    Change default value of explicit_defaults_for_[1;31mtime[mstamp to ON.
    Add deprecation warning when the value of
    explicit_defaults_for_[1;31mtime[mstamp is changed from TRUE to FALSE.
    
    In MySQL 5.6 explicit_defaults_for_[1;31mtime[mstamp option was introduced (and
    deprecated) in WL#6292 with the intention of suggesting users to switch
    to new behavior. In most cases though, users ignore the warnings from
    explicit_defaults_for_[1;31mtime[mstamp. This worklog will change the default
    value of explicit_defaults_for_[1;31mtime[mstamp to TRUE, with users able to
    revert back to the FALSE behavior in mysql-8.0.
    
    Fix test cases to execute with default behavior by:
    i>   Record new default value of explicit_defaults_for_[1;31mtime[mstamp option.
    ii>  Record the result difference by not promotion of [1;31mtime[mstamp columns
         by default.
    iii> Timestamp columns are now nullable by default and no auto
         promotion happens. Record test output.
    iv>  Test tried to insert ZERO date in NO_ZERO_DATE mode. This
         is not allowed for [1;31mtime[mstamp column by default. Adjusted test case.
    v>   Fix sql mode to test the intended behavior of the test and
         record result file.
    vi>  There are error scenario to check that CREATE TABLE statement fails
         with 2 [1;31mtime[mstamp column with NO_ZERO_DATE sql. This is deprecated
         behavior. Removed the test scenario.
    vii> Record the extra warning when trying to insert NULL to
         TIMESTAMP NOT NULL column. Value inserted in the table changed
         from current_[1;31mtime[mstamp value to '0000-00-00 00:00:00'.

[33mcommit ed7491240b0054fe1bacba129b8a19536f6ecf69[m
Author: Arnab Ray <arnab.r.ray@oracle.com>
Date:   Tue May 23 12:13:32 2017 +0530

    WL#8500 Adapt MySQL Cluster to 8.0
    
    - Enable tests that were previously disabled due to Bug#25858461
      FAILURE TO DROP DATAFILE FROM TABLESPACES WITH MULTIPLE DATAFILES
    - The ndb_dd_dump test is enabled and result file is updated to
      reflect the change in default character set
    - The ndb_dd_basic test remains disabled but this [1;31mtime[m under new
      Bug#26124155 filed
    - The ndb_binlog_ddl_multi test remains disabled and should be
      fixed as part of WL#9185
    - The ndb_rpl_dd_basic test was enabled
    - The ndb_rpl_dd_partitions is enabled and result file is updated
      to reflect the change in default character set

[33mcommit 7a42244e3a2f1b058e8a46f96da264bb1e4d1dab[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Tue May 23 08:40:20 2017 +0200

    Bug#26078612 PB2 TEST FAIL: NDB_RPL.NDB_RPL_BINLOG_FORMAT_ERRORS. MIXED ENGINE + SELF_LOGGING
    
    - disable testcase ndb_rpl_binlog_format_errors
     - this test has failed forever but shows up all
       the [1;31mtime[m in trunk-cluster where tests are
       run with mysqld-debug

[33mcommit e2cb1cb2bb6b6ac7285291bac0402eeda16881f4[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Fri Apr 28 09:52:05 2017 +0200

    Bug#18513130: STRANGE INTERACTION OF SQL_MODE=ANSI AND PARTITION BY TIMESTAMP
    
    The problem was that the presence of the ANSI_QUOTES SQL mode
    influenced how partitioning expressions were stored and
    how they were parsed on table definition load.
    
    This made it possible to successfully create a partitioned table
    that would result in a parsing error on later retrieval if the
    SQL mode changed in the mean[1;31mtime[m.
    
    This patch fixes the problem by temporarily turning off
    ANSI_QUOTES when storing partitioning expressions in the
    data dictionary and when they are printed using SHOW CREATE TABLE.
    This means that partitioning expressions are no longer stored
    exactly as given by the user, but rather using Item::print()
    after the expression has been parsed. This is similar to how
    view expressions are handled.
    
    This patch also enforces that (sub-)partition expressions
    can be maximum 2048 characters long. Before this fix, the
    server would assert if a longer expression was used.

[33mcommit 165bfb4b9f0c301a17a7fa0be730c7d4785b7467[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu May 18 11:12:03 2017 +0800

    WL#9536: Fix [1;31mtime[mout and deadlock step two - fix gr_capture.o
    
    Don't rollback other DDL asynchronously when locking conflicts
    on innodb_ddl_log table.
    
    TODO: We may evaluate if the internal parser should be replaced
    by low-level btr functions, thus we can fix the lock conflicting
    on innodb_ddl_log.

[33mcommit 959f63800bc569f0a9f691818f17db6d20f975fd[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Sun May 14 10:09:50 2017 +0800

    WL#9536: Fix deadlock and [1;31mtime[mout step one - don't hold dict_sys mutex
    during pars_sql.

[33mcommit ca4e321ed4761bfcf1e19cba4943816eef911a96[m
Author: John David Duncan <john.duncan@oracle.com>
Date:   Fri May 12 08:33:38 2017 -0700

    Workaround for bug#25690926
    For gcc 6.x and newer, compile NDB kernel with -flife[1;31mtime[m-dse=1

[33mcommit 370fb55b7789e36a6c4237746acd8509c7a6114d[m
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Fri May 12 18:28:00 2017 +0530

    WL#10298: Change run[1;31mtime[m tests to run with new default charset
    
    Post push fix: Fixing the tests which were missed earlier.
    
    Reviewed-by: Bernt Johnsen <bernt.johnsen@oracle.com>
    Reviewed-by: Thayumanavar S <thayumanavar.x.sachithanantha@oracle.com>
    RB: 16069

[33mcommit c9dc288fdaac234dcc47650462466c2bb7a8fd72[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Thu May 11 17:10:17 2017 +0100

    Bug #24829435   NDB : NDBTABLE::GETCOLUMN(CONST CHAR*) IS INEFFICIENT
    
    The getColumn functionality in the NdbApi dictionary is used to
    map from a column name to a column object.
    This can be used explicitly by users, or implicitly as part of
    passing a column name to an NdbApi function.
    The current implementation uses a linear search of an array of
    strings (column names), whose cost scales O(n) in the number of
    columns.  This has been seen to waste cpu in real-world NdbApi
    applications.
    It is possible for applications to lookup column objects or ids
    upfront, and then use them which gives O(1) access to a column
    object.
    However to improve the experience of users using column name strings
    at run[1;31mtime[m, a column name hash is implemented.  This should give
    ~O(1) lookup performance from name strings to column objects.
    
    It is still recommended to perform name->object/id lookups upfront,
    but the cost of doing them at run[1;31mtime[m is reduced.
    
    A new test is added to testNdbApi which can be used to show
    that column lookup performance is independent of the #columns.

[33mcommit 22e06a2dda8f697d21ddab76e41c14384fea7bbb[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed May 10 17:27:34 2017 +0200

    Bug#26040934 REMOVE OBSOLETE INCLUDE_DIRECTORIES IN CMAKE FILES
    
    This is a followup to the patch for
    Bug #25436469 BUILDS ARE NOT REPRODUCIBLE
    
    perl will some[1;31mtime[ms report
    Use of uninitialized value $dir1 in pattern match (m//) at
    scripts/invoke-with-relative-paths.pl line 62.
    
    This turns out to be obsolete/wrong cmake INCLUDE_DIRECTORIES directives.
    
    Change-Id: I9d63ff273720ddc150880f9d4f251473b7f9e1df
    Fix: print a warning in the perl script if an unknown path is detected.
    Also: remove all obsolete INCLUDE_DIRECTORIES from .cmake files.

[33mcommit 9650bf4eb098e2eb79151f2ebb8b7a43a88ced68[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu May 11 11:43:45 2017 +0200

    WL#9185 MySQL Cluster support for new DD
    
     - change ndb_sdi_serialize() to take table_def as pointer, this was
       written before table_def* was passed to most handler functions. Thus
       only converting to reference at the very last [1;31mtime[m before calling
       dd::serialize()

[33mcommit ca7ad6ec5dc36f103d0a96516684db7e1b2f1862[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon May 8 10:57:51 2017 +0200

    WL#8500 Adapt MySQL Cluster to 8.0
    
     - fix problem caused by change to utf8 as default charset where the
       explain output new shows a 4 [1;31mtime[ms larger key, looking at test case
       that seems ok

[33mcommit 896bc78d6097a2ae7ea8f6472b7dbf6595146da4[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon Mar 6 15:41:47 2017 +0100

    WL#9185 MySQL Cluster support for new DD
    
     - allow the schema distribution setup to overwrite
       table definition of mysql.ndb_schema and mysql.ndb_apply_status
       if they already exists in DD
     - remove too verbose printout for "schema distribution setup failure"
       which happens "all the [1;31mtime[m" if NDB restarts

[33mcommit 532c767957683ab28661974ce4ef3b26c9cf0644[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue May 9 16:43:31 2017 +0200

    WL#9344: Logging services: error messages
    
    Post-push fix: do not set MY_BASENAME on compiler command line, it
    serializes the build on windows, thus more than doubling the compile [1;31mtime[m.
    
    Instead: implement it with a constexpr function examining __FILE__
    
    Also: silcence a warning for name shadowing.

[33mcommit 0eb6dc9fc445504d1734446bcb9433d1c439e526[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Apr 27 15:05:55 2017 +0200

    Bug #25965593: REPLACE MY_QSORT WITH STD::SORT
    
    Make an iterator/reference class combination that allows std::sort
    to sort objects whose length is not known at compile [1;31mtime[m, and convert
    all remaining uses of my_qsort() to it.
    
    Change-Id: I9fdfebf4368b8dee15e3945169eb5731746c7666

[33mcommit 971d3c56b354b593bded745b3f38afcc9ff5b0a1[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Mon May 8 12:23:32 2017 +0530

    BUG#25821838 : --ERROR IS NOT PROPERLY WORKING IF IT IS USED INSIDE WHILE LOOP
    
    Description:
    ============
    "--error" mysqltest command is used to specify expected error(s) for
    the next query in a MTR test script. It is not working properly if it
    is used inside a while loop with if condition. It is getting evaluated
    every [1;31mtime[m irrespective of the if condition.
    
    E.g:
    
    --let $p=0
    while ($p <= 1 )
    {
      if ($p == 0)
      {
        --error 1051
      }
      DROP TABLE t1;
      CREATE TABLE t1(i int);
      --inc $p
    }
    
    DROP TABLE query should fail with "error 1051" in the first iteration,
    but in the second iteration it should not throw any error. But the
    above test script fails with an error in the second iteration saying
    that "DROP TABLE t1 succeeded - should have failed with errno 1051".
    
    Issue:
    ======
    "--error" command gets evaluated in false context also and expects the
    next query to fail with the errno provided in the command.
    
    Fix:
    ====
    Don't evaluate the "error" command if the condition evaluates to false.
    
    Reviewed-by: Bjorn Munch <bjorn.munch@oracle.com>
    Reviewed-by: Srikanth B R <srikanth.b.r@oracle.com>
    RB: 16083

[33mcommit 1d15c419d61c21701e4f1633788d09c94ceaea1f[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed May 3 12:20:14 2017 +0200

    WL#9834: Follow up patch that fixes some failures on Windows, test case
    gcs_xcom_group_member_information-t, due to nodes getting the same UUID
    (i.e. [1;31mtime[mstamp) value when they were supposed to be different.
    
    Fix: Add SetUpTestCase functions to do My_xp_util::init_[1;31mtime[m,
    otherwise all [1;31mtime[mstamps are zero.

[33mcommit 7e66a93517ab3a48a56cf0d7f527cfa927d30033[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Apr 28 15:49:39 2017 +0200

    Bug#25957991 ADD EXPLICIT DEPENDENCY ON LIBSTATOMIC.SO ON SOLARIS
    
    Post-push fix: disable INSTALL of g++ run[1;31mtime[m libraries on Solaris.

[33mcommit 63b6908dceaba1158c83e0b60189facda1cc45c0[m
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Fri Apr 28 18:51:03 2017 +0530

    WL#10298: Change run[1;31mtime[m tests to run with new default charset
    
    Description:
    ============
    WL#7554 changed the default character set from latin1 to utf8mb4.
    Some tests were rewritten to use latin1 temporarily, so now
    they have been changed to use utf8mb4.
    
    Reviewed-by: Bernt Johnsen <bernt.johnsen@oracle.com>
    Reviewed-by: Thayumanavar S <thayumanavar.x.sachithanantha@oracle.com>
    RB: 16069

[33mcommit 15cca2a59da77fe55d657dc166d7aabed125bc02[m
Author: Maitrayi Sabaratnam <maitrayi.sabaratnam@oracle.com>
Date:   Fri Apr 28 12:39:42 2017 +0200

    Bug#25806659 - NDBREQUIRE(LOGFILEPTR.P->FILEREF != RNIL) FAILS, FOR NEXT REDO LOG FILE NOT OPEN
    
    At the last write on a redo log file n, a command to open file n+2 is
    issued. At this [1;31mtime[m, it is expected that file n+1 is already opened
    for next writes. However, this may not be the case for a tardy disk,
    causing node crash.
    
    This fix will add handling an unopened file gracefully by introducing
    waits.

[33mcommit e9f46d9955790dd0515919a3d7af82e63609e63b[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Apr 6 13:26:54 2017 +0200

    WL #9554: Varlen keys for sorting multibyte String values
    
    Unicode collations are sorted by means of variable-length weight strings.
    In the worst case, these weight strings can become very long; for instance, for
    utf8mb4_0900_as_cs, we have a strnxfrm_multiply of 24, which is interpreted as
    every byte in the input string becoming potentially 24 bytes. In other words, a
    VARCHAR(100), which can be up to 400 bytes, gets 9600 bytes allocated for
    filesort, even if it just contains a simple 'a' (which is six bytes of weight
    plus some level separators). The default set max_sort_length=1024 masks this
    problem somewhat by truncating the weight strings, at the cost of incorrect and
    unpredictable sorting when sorting strings that actually need long weight
    strings.
    
    This worklog aims to introduce variable-length keys when sorting NO PAD collations.
    (PAD collations still need to be fixed length, because they are conceptually
    extended to infinity.) It builds on the existing semantics for sorting JSON using
    variable-length keys; it doesn't try to replace strnxfrm with strnncollsp,
    which would also be an interesting avenue, but can happen in a later worklog.
    
    Benchmark results are good: For the distinct_ranges sysbench test
    (using varchar keys), we win about 12% on a single core of Skylake 3.4 GHz.
    For a test of sorting 300000 first names in a VARCHAR(100) COLLATE utf8mb4_0900_as_cs,
    setting max_sort_length=65536 (so that both sides actually sort based on all
    their data, as opposed to truncating the key and sacrificing correctness),
    it is about five [1;31mtime[ms as fast, due to vastly less spilling to external storage
    (77 versus 11075 chunks). This is even though external storage in this case is
    RAM, not disk -- if it would be actually hitting the SSD, the difference would
    be even more dramatic.
    
    Change-Id: I4704ffe04e2b35db47e5c1b98160f6a4731157ad

[33mcommit b2a02507dfeaff0226d8672b4f0fceda60b41072[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Fri Sep 23 11:31:43 2016 +0100

    Bug#24444878 MYSQLD CRASH DURING UNIQUE KEY CREATION
    
    - Regression introduced by fix for Bug#23089566
      HA_NDBCLUSTER::OPEN_INDEXES MEMORY LEAK. The mysqld crash in a
      debug compile assert.
    
    - Testcase created to show the problem, the debug [1;31mtime[m assert in
      release_indexes() removed to avoid since m_table poiunter is not
      really used by the function. It was just a way to detect if table
      is open or not.

[33mcommit 46dfab1885c7fc35f6c9f1ba5fa72f7ccaf42b56[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Apr 26 16:13:15 2017 +0200

    Bug#25957991 ADD EXPLICIT DEPENDENCY ON LIBSTATOMIC.SO ON SOLARIS
    
    man -M /opt/developerstudio12.5/man CC
           -xatomic=a
               Specify which atomics support run[1;31mtime[m library is linked.
               a must be one of the following:
               studio    Link with the libstatomic  library  bundled  with  Oracle
                         Developer Studio.
               gcc       Link with the libatomic library in /usr/lib.
               none      Do not link with any atomics support library.
               The option -xatomic=studio is the default when neither -latomic nor
               -xatomic  is  specified,  and  the   compiler   is   compiling   in
               -std={c++03|c++11|c++14} mode.
    
    The server already depends on -xatomic=studio.
    We are actively switching from my_atomic_xxx to std::atomic,
    so make the dependency explicit.

[33mcommit a0f6a1453ec33c5c9dd5e6be24934c46f55805e3[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Mon Apr 24 16:00:11 2017 +0200

    Bug#25945568: MYSQL 5.7 FAILS TO BUILD WITH MUSL LIBC
                  DUE TO NOT FINDING SIGEV_THREAD_ID
    
    The problem was that posix_[1;31mtime[mrs relied on non-posix standard
    features which made the code not compile on Alpine Linux.
    This patch rewrites the code to use standard posix. This means
    that the ~same code can also be used on Solaris.
    
    Also fix various minor other issues for compiling on Alpine.

[33mcommit 4ee6e97572d0e286614e661062de6e82e77f4b30[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Tue Apr 25 15:46:12 2017 +0530

    BUG#11766444 : MTR PRINTS WRONG FILE AND LINE NUMBER WHEN TESTS FAIL
    
    Description :
    =============
    When a test case fails, MTR some[1;31mtime[ms prints the wrong line number.
    This happens if a test case fails inside a while loop and it is not
    the first iteration of the loop.
    
    E.g:
    ----
    --let $i = 2
    while ($i)
    {
      dec $i;
      if (!$i)
      {
        execute this invalid query;
      }
    }
    
    When executing the above test case, MTR fails with the following
    message:
    
    mysqltest: At line 9: query 'execute this invalid query' failed: 1064:
    You have an error in your SQL syntax; check the manual that
    corresponds to your MySQL server version for the right syntax to use
    near 'invalid query' at line 1
    
    Note that the error was on line 7 but the test reports line 9.
    
    Issue :
    =======
    The variable 'start_lineno' keeping track of the current line number
    in a test is not updated after the first iteration and hence printing
    the line number of the last line of the loop.
    
    Fix :
    =====
    Introduced a new variable 'lineno' in 'st_command' structure to keep
    track of the the line number for each command. During the iteration
    after the first one, use this variable to update the 'start_lineno'
    variable to the current line number.
    
    Reviewed-by: Deepa Dixit <deepa.dixit@oracle.com>
    Reviewed-by: Srikanth B R <srikanth.b.r@oracle.com>
    RB: 16015

[33mcommit da6b05d2a91e901902b78a6680fd4d3501d8e310[m
Author: Alfranio Correia <alfranio.correia@oracle.com>
Date:   Sun Apr 23 11:27:10 2017 +0100

    WL#9834: Follow up patch that fixes some failures on Windows, test case
    gcs_xcom_group_member_information-t, due to nodes getting the same UUID
    (i.e. [1;31mtime[mstamp) value when they were supposed to be different.
    
    Introduced a delay between the calls that define the [1;31mtime[mstamp so they
    will be different.

[33mcommit 76f095b113be80e3c4506aa73716161acfbe8c59[m
Author: Dinesh Surya Prakash <dinesh.prakash@oracle.com>
Date:   Thu Apr 20 14:03:08 2017 +0530

    Bug #25844166 NDB_CONFIG TO PRINT CONFIG DIFFERENT FROM DEFAULT
    
    There are more than 256 configurations in cluster. So, when we like to find
    the configuration that are changed during run [1;31mtime[m it is difficult to find
    them, hence have added an option(--diff_default) to ndb_config to print
    only the configurations that are different from the default configuration
    of the node.

[33mcommit d31bd43cbe2ba1208e0ed14903e2a5ce9d9c4654[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Wed Apr 19 12:33:41 2017 +0530

    Bug#25252679 : ENABLE MAIN.MYSQL_UPGRADE.TEST
    
    - Enable main.mysql_upgrade.test
    - Record result file according to latest trunk.
    - Divide main.mysql_upgrade test case into four tests
      main.mysql_upgrade.test
      main.mysql_upgrade_options.test
      main.mysql_upgrade_grant.test
      main.ps_sys_upgrade.test
    - Mark main.mysql_upgrade_options and main.ps_sys_upgrade
      as big test. Add 60 min [1;31mtime[mout values for these tests.
    - Create on disk tables instead of temporary tables from
      backup_tables_priv_and_users.inc to handle server restarts.

[33mcommit 0811017d90c2a207c28882f3a8fa72d05d66ee6e[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Wed Apr 19 11:06:53 2017 +0530

    BUG#24736713 : MTR DOC: BEHAVIOUR OF TESTCASE-TIMEOUT WITH VALGRIND IS NOT CLEAR
    
    Description:
    ============
    When running a test with testcase-[1;31mtime[mout = 1 for example and valgrind
    enabled the test will not [1;31mtime[mout after 1 minute.
    
    The behavior changes, as with valgrind the [1;31mtime[mout is multiplied by
    10. This behavior is not described/documented anywhere though.
    
    Fix:
    ====
    Updated the MTR doxygen documentation.
    
    Reviewed-by: Anitha Gopi <anitha.gopi@oracle.com>
    Reviewed-by: Deepa Dixit <deepa.dixit@oracle.com>
    RB: 15983

[33mcommit 149f8841a9ce85163a5a7dbf2e7442d654299d42[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Wed Apr 5 12:18:07 2017 +0530

    Bug #21576576: IMPROVE HEARTBEAT FAILURE REPORTING FOR SYSTEM RESTART
    
    Problem
    =======
    
    If one of the nodes fail due to missing sending heartbeats during
    system restart, all other nodes report that another node failed
    without any additional info.
    
    First, node 2 crashes because it thinks node 4 is dead due to missing
    heartbeats though it's not really dead.
    Then, after some [1;31mtime[m node 4 shuts itself down because of node 2 crash.
    
    Fix
    ===
    
    Added additional info to the failure.
    Now, the node that failed to send heartbeat along with heartbeat
    error is reported in the error log and data node log.
    
    Steps to test the fix:
    
    1) Start a 2 node cluster, where the data nodes have id 2 and 4.
    2) ndb_mgm -e "all restart -n"
    3) ndb_mgm -e "4 error 946"
    4) ndb_mgm -e "all start"
    Wait for a few minutes.
    
    The error log of node 2 will have the fixed error message.

[33mcommit 43c1e2eae1585ece4bf9b24e4ae221ae1d8e73f3[m
Author: Maria Couceiro <maria.couceiro@oracle.com>
Date:   Thu Mar 16 17:57:53 2017 +0000

    BUG#25316086 MYSQL 8.0 ASSUME TRX BEING APPLIED WITH 5.7- MYSQLBINLOG DUMP AS ORIGINAL
    
    Problem and analysis:
    When a mysqlbinlog output generated by a server unaware of the variable
    original_commit_[1;31mtime[mstamp (5.7-) is applied in a 8.0+ server, this
    latter server will generate new original_commit_[1;31mtime[mstamps as it
    assumes the transactions are its own.
    
    Fix:
    When applying a transaction and the original_commit_[1;31mtime[mstamp is
    unknown, if the transaction was originated by the binlog applier, set
    the [1;31mtime[mstamp to zero.
    
    Note:
    If the output of mysqlbinlog is modified by the user (such as
    removing SET @@SESSION.PSEUDO_SLAVE_MODE=1 or applying directly the
    SQL statements), the server will still set the
    original_commit_[1;31mtime[mstamp as if it were the original master.

[33mcommit 03a7bfb9d0cce5a18763e2d97a45c023a9593ffe[m
Author: Nisha Gopalakrishnan <nisha.gopalakrishnan@oracle.com>
Date:   Tue Apr 11 16:19:51 2017 +0530

    BUG#25805260: MYSQL 8.0.X CRASHES WHEN OLD-STYLE TRIGGER MISSES
                  THE "CREATED" LINE IN .TRG
    
    Analysis
    ========
    The server exits during inplace upgrade of triggers created
    before MySQL-5.7.2.
    
    The triggers created before 5.7.2 does not have the 'created'
    line in the trigger definition. During the upgrade of such a
    trigger definition, the computation of [1;31mtime[mstamp for 'created'
    triggers the server exit.
    
    Fix
    ===
    During the upgrade of triggers, if the 'created' value exist,
    utilize the value else use the current [1;31mtime[mstamp. Hence it
    is backward compatible.

[33mcommit 1a4e2b2d94440c7aa3cc969831f8d2a207b8d084[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Apr 6 10:31:34 2017 +0200

    Bug #25835560: SET DEFAULT SYMBOL VISIBILITY TO HIDDEN
    
    Hide all symbols by default and export only the ones that are supposed
    to actually be visible. This primarily affects mysqld, but also plugins
    and statically linked libraries of various sorts now stop polluting the
    server's namespace. In addition, we export 297 “legacy” functions and
    classes that were already in use by existing plugins; this is not meant
    as an endorsement of the practice, and is likely to break in the future,
    but fixing them all is a longer procedure that will take [1;31mtime[m.
    
    A stripped mysqld binary (RelWithDebInfo) on Linux goes from 38 to 34 MB,
    exporting 950 instead of 20854 symbols.
    
    Windows builds can now skip the WScript step that goes through every
    symbol and exports it manually through a .def file. On a 16-core Xeon
    build server (vale31), this reduces the build [1;31mtime[m of a full debug
    build by about 40 seconds (from 9 minutes 25 seconds to 8 minutes
    45 seconds). The difference for an incremental build, ie., just touching
    sql/main.cc and rebuilding, is even bigger; it goes from 1m42s to
    just under 13 seconds, as the incrementality is significantly increased.
    
    Change-Id: I2d1c39b6822502139e3286c7473db81c876b7bbc

[33mcommit ff39f25d09506637eb38249f039203daf4fb5e51[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Thu Apr 6 16:43:22 2017 +0100

    Bug #25830247   NDB : CPUSET LOCKING DOES NOT REUSE CPUSET STRUCTURES
    
    There is code spread across NdbLockCpuUtil.c and NdbThread.c for managing a set of cpuset arrays.  The idea is that a minimal set of unique cpusets will be maintained.  Cpusets can be reused by different threads, with reference counting used to avoid leaks.
    
    However :
     - The code to reuse a cpuset does not work as the cpuset content is not updated when a cpuset is created, so the search cannot work
     - The code to release a cpuset does not work as the cpuset id of a thread is not read before it is nulled, leaking the cpuset.
    
    Probably these bugs are not too problematic for static cpuset assignments, but they cause problems when the number of unique cpusets is high, or if cpuset locking is changed at run[1;31mtime[m.

[33mcommit e07873e062c2cfbbf31ce8e87be1aa5dc4dd6db0[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Mar 29 17:42:58 2017 +0200

    Bug#25800933 BROKEN CONCURRENCY CONTROL WHEN UPDATING 'M_NODE_TOTAL_SEND_BUFFER_SIZE'
    
    The node internal scheduler (mt.cpp) collect statistics about its own
    progress and its outstanding work. One such statistics being collected is
    the amount of outstanding 'send-bytes' which is being collected in
    send_buffer::m_node_total_send_buffer_size. This may later be
    used by the send thread scheduler, which use amount of outstanding sends
    as a metric to self tune its send performance vs latency.
    
    In order to reduce lock contention on the internal send buffers, they
    have been split in two thr_send_buffer parts: the 'm_buffer' and
    'm_sending' buffers - each of them are protected by their own mutex.
    'm_node_total_send_buffer_size' was maintained to reflect the total size
    in these two send buffers.
    
    It turns out that we were not consistent regarding which mutex we
    used in updating 'm_node_total_send_buffer_size':
    
     - In link_thread_send_buffers() we locked send_buffer::m_buffer_lock
     - In bytes_sent() we locked send_buffer::m_send_lock
     - In reset_send_buffer() we locked both.
    
    Thus there is effectively no concurrency protection of
    'm_node_total_send_buffer_size'.
    
    This patch replace m_node_total_send_buffer_size with the two
    seperate 'm_buffered_size' and 'm_sending_size' which keeps
    track of respective size of the two buffers. These new counters
    are updated under protection of the two different mutexes
    protecting each of the send buffers.
    
    mt_get_send_buffer_bytes() will add these together to get the
    total size. This method is already documented as doing an
    unprotected 'get' of the buffer seize, which should be OK as
    we can do with a buffer size being slightly off. As the
    concurrency controll is now fixed , the updates will be
    correct, and the value will not 'drift' over [1;31mtime[m.

[33mcommit 414a358a37aefb7c88f598d86280148281e27d16[m
Author: Nuno Carvalho <nuno.carvalho@oracle.com>
Date:   Tue Apr 4 15:05:45 2017 +0200

    BUG#25828978: SHORTEN TIME SPENT ON GROUP REPLICATION TESTS PER PUSH
    
    In order to shorten the [1;31mtime[m spent on Group Replication tests per
    push, tests that do take more than 1 minute to run are marked as
    big test.
    Additionally, per push tests are run on binaries without debug
    information.
    
    Suite run duration on OEL7:
      per push before changes: 28m00s
      per push after changes:   9m28s

[33mcommit f17b667cd9f5cd677a3cc16038ed0f3fe8d5f69d[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Wed Apr 5 10:44:49 2017 +0200

    Bug#25833932: ALLOW A DICTIONARY OBJECT TO BE UPDATED TWICE
    
    Change Dictionary_client::update() so that it can be called
    twice for the same dictionary object. This makes it easier
    to have longer-lived dictionary objects (i.e. not acquire
    new instances all the [1;31mtime[m).
    
    Internal API quality of life issue only, no user-visible
    consequences.

[33mcommit 36990c9642ec78a3a655e2a2bb5df0adee8e227d[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Wed Apr 5 13:08:00 2017 +0530

    Bug#25586673 : ASSERT IN DA FOR SQL_CMD_UPDATE::UPDATE_SINGLE_TABLE
    Bug#25586959 : SERVER CRASH IN SQL_CMD_DELETE::DELETE_FROM_SINGLE_TABLE
    
    The asserts reported in the bug are to make sure that no error has
    been reported by the statement. ER_TRUNCATED_WRONG_VALUE error is
    reported due to conversion from warning to error by STRICT mode.
    This error is ignored and the statement execution continues,
    leading to the assert.
    
    Fix:
    Check for errors using THD::is_error() in functions:
    - make_truncated_value_warning
    - build_equal_items
    - TABLE::update_const_key_parts
    
    Return type of following function have been changed from void to bool
    for error handling:
    - make_truncated_value_warning
    - adjust_[1;31mtime[m_range_with_warn
    - push_zero_date_warning
    
    - Field_temporal::set_warnings
    - Field_temporal::set_date[1;31mtime[m_warning
    - Item::update_null_value

[33mcommit 6d892011b8b1afd7ca53bde9cd7a636041ff557f[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Fri Mar 31 15:02:33 2017 +0200

    Bug#24624556: RDTIMESTAMPCOUNTER.TESTCYCLE UNIT TEST FAILS ON AARCH64.
    
    The precision of the low-level ARM64 cycle [1;31mtime[mr varies
    depending on implementation. Our current unit tests assumes
    that the precision is low and therefore fails on some ARM64
    machines. Remove this check from the unit test so that the
    unit test passes on ARM64 regardless of precision.

[33mcommit cf81b376dad3a4e3192ace5aaf5c572ba06b6a69[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Fri Mar 31 09:38:15 2017 +0200

    Bug#25807358: GET RID OF TMP_DISABLE_BINLOG/REENABLE_BINLOG MACROS
    
    There are three problems with these two macros:
    1) Lowercase names means they look like functions (less serious)
    2) reenable_binlog() overwrites THD::variables::option_bits so
       that any changes to these bits since tmp_disable_binlog()
       are lost (less serious)
    3) The first starts a scope which the second ends (more serious)
    
    The latter means that any variables declared between use
    of the first and the second macro, are not visible afterwards.
    This can give difficult to understand compiler errors.
    And even worse it can mean that destructors for e.g. RAII objects
    are run at a not-obvious [1;31mtime[m, breaking the application at run[1;31mtime[m.
    
    This patch removes the two macros and replaces them with
    a RAII-style class.

[33mcommit 4a0d42922cfebf519c44304dcd10f1b0b5180e92[m
Author: Alfranio Correia <alfranio.correia@oracle.com>
Date:   Thu Mar 30 08:24:43 2017 +0100

    BUG#25477979 : GROUP REPLICATION: SERVER ASSERTION UPGRADING SECOND SERVER FROM 5.7 TO 8.0.1
    
    PROBLEM
    -------
    The patch for BUG#25311008 "NODE THAT FAILS AND RE-ENTERS MIGHT BE EXPELLED
    WITH NO REASON" introduced the notition of a uuid (i.e. [1;31mtime[mstamp) assigned
    to a node and the information is used to prevent a group from expelling a
    different incarnation of a node.
    
    However, the patch was designed to be pused into 5.7.17 which was the first
    Group Replication release. This did not happen and the patch was not
    originally designed to support different types of ids, a common situation
    when different replication releases are mixed.
    
    So the server crashes due to some asserts that are not necessarily true
    when different releases are mixed.
    
    FIX
    ---
    To fix the problem, we accomodate the possibility of having variable size
    ids such as uuids, [1;31mtime[mstamps or hostname:port.

[33mcommit f8373b2db4075f7cef78f28d9146acc21ddab9e5[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Thu Mar 30 04:55:17 2017 +0200

    Provide more buffer pool for innodb.innodb-copy-alter-debug
    
    Problem: restarting a server in innodb.innodb-copy-alter-debug often
    [1;31mtime[ms out in the 64K page size runs because there is too little room
    in the buffer pool.
    
    Solution: increase the size of the buffer pool (.opt file).
    
    Approved by Anitha Gopi <anitha.gopi@oracle.com>.

[33mcommit 38dfc3edc3bb9e23a0c629f6efebd5a22f3edada[m
Author: Maitrayi Sabaratnam <maitrayi.sabaratnam@oracle.com>
Date:   Wed Mar 29 18:02:10 2017 +0200

    Fixing testSystemRestart StaleNodeTakeoverDuringSR to ignore error
    711 and increase the createTable wait [1;31mtime[mout.

[33mcommit 11ad34e4ad5ec094aa4099c4b33c703635860501[m
Author: Daniel Blanchard <daniel.blanchard@oracle.com>
Date:   Wed Mar 29 16:02:55 2017 +0100

    Bug #25799855 DOCS/INFO_SRC BUILD-DATE ENTRY MISSING ON WINDOWS
    
    Issue
    -----
    The CMAKE macro CREATE_INFO_SRC defined in cmake/info_macros.cmake.in
    uses a Perl script to generate a date string that populates the
    Docs/INFO_SRC file's build-date entry.
    
    Unfortunately, the date formatting options used in the Perl script are
    unavailable on Windows, resulting in an incorrect or empty (depending
    upon the Perl distribution used) build-date entry.
    
    Fix
    ---
    Replace perl script that formats build [1;31mtime[m stamp in
    cmake/info_macros.cmake.in with more portable CMAKE command
    
    STRING(TIMESTAMP bdate "%Y-%m-%d %H:%M:%S +0000" UTC)
    
    Reviewed by: Tor Didriksen <tor.didriksen@oracle.com>
    RB: 15849

[33mcommit 3bb5217444026029f6ea3aa2a8182e42cdc44ae8[m
Author: Daniel Blanchard <daniel.blanchard@oracle.com>
Date:   Wed Mar 15 15:02:20 2017 +0000

    Bug #25101724 QUERIES IN "SHOW PROCESSLIST" OSCILLATE WITH CONSTANT TIMES HIGHER EACH DAY
    
    Issue:
    ------
    the start [1;31mtime[m of a query/THD is obtained from my_micro_[1;31mtime[m, but the
    end/current [1;31mtime[m as used by show processlist is obtained from my_[1;31mtime[m.
    These two different [1;31mtime[m functions currently make different OS API calls
    on Windows to obtain the current [1;31mtime[m. The problem is caused by the fact
    that the current implementation of my_micro_[1;31mtime[m (using
    QueryPerformanceCounter) will drift relative to wallclock [1;31mtime[m, of the
    order of 1 second per day.
    
    Fix:
    ----
    The my_micro_[1;31mtime[m QueryPerformanceCounter implementation is replaced with
    an (indirect) call to GetSystemTimePreciseAsFileTime when available,
    falling back to GetSystemTimeAsFileTime on older versions of Windows. The
    Fill_process_list::operator()(THD *inspect_thd) function used by SHOW
    PROCESSLIST is also modified to use the same function (my_micro_[1;31mtime[m) for
    obtaining the start and end [1;31mtime[ms used in the duration calculation.
    
    The my_micro_[1;31mtime[m_ntp function is now redundant, and thus calls to it
    are replaced with calls to my_micro_[1;31mtime[m.
    
    Similar replacement of QueryPerformanceCounter timing with
    GetSystemTimePreciseAsFileTime /GetSystemTimeAsFileTime in InnoBase.
    
    Reviewed-by: Sunny Bains <sunny.bains@oracle.com>
                 Thayumanavar X Sachithanantha
                 <thayumanavar.x.sachithanantha@oracle.com>
    RB: 15719

[33mcommit b5e97e6273d745b0e1e0c9cb10eadf43ad891e3d[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Mar 22 09:19:31 2017 +0100

    Bug#25654833 MYSQL CLUSTER 7.5.5 REPLICATION SLAVE SQL THREAD HANGS WITH CREATE TABLE
    
    This is 'best effort' patch for the above problem, which seems to be a regression introduced in 7.5.5. Based on bug description, we *assume* this to be caused bu the 'part 3 of 4' push of patch for Bug#25042101 'SPLIT BINLOG INJECTOR_MUTEX IN TWO, DO REQUIRED CLEANUP':
    
    .........
      Remove thread_yield() in binlog injector code previously put there
      as a temp stopgap in the commit below. This used to be required
      as the injector thread held the injector_mutex > 99% of the [1;31mtime[m when
      waiting for pollEvents(). That blocked client threads either wanting to
      access the data shared from the injector thread, or needing the injector_mutex
      while waiting for injector_cond to be signaled
    
      This should not be required anymore, as:
    
      1) injector_mutex has been splitt in two separate mutexes.
      2) We changed init of the injector_event_mutex from a 'FAST' to a 'SLOW'
         mutex which has better 'farness' properties in the scheduler
    .........
    
    The theory is that using the more 'fair' SLOW-mutex variant is not as 'fair' as assumed to be on all OS/VM variants. Thus the 'yields' may be unsafe to remove.
    
    Bug has been hard to reproduce:
    
     - It has been 'randomly' reproduced using Oracle Linux 7 on top
       of 'Virtualbox'
     - It has than gone away for a couple of days.
     - It has *not* been reporoduced with this patch.
    
    So it should be reasonable to expect that reintroducing the 'thread_yields' should solve the problem.
    
    We cant say for sure though....
    
    (cherry picked from commit f0e06cc2bc975ca5be084be9c307803e1da53cd4)

[33mcommit 0fc03c3bd33d9fee47be967b978e1a8e8896dbd6[m
Author: Tiago Jorge <tiago.jorge@oracle.com>
Date:   Tue Jan 24 11:06:05 2017 +0000

    BUG#25310344 - MYSQL GCS DOES NOT HANDLE THE FAILURE OF NODE WHILE IT IS JOINING THE CLUSTER
    
    Description:
    -----------
    If a node never becomes alive or becomes alive but fails before a view
    that contains it being delivered to the application, the node is never
    expelled from the cluster and the application will never be aware of
    its existence.
    
    However, the configuration delivered to GCS already contains the node
    and as such it is considered to compute the majority.
    
    Suggested Fix:
    -------------
    Keep track of nodes that are joining the cluster and expel them if
    they do not join it after some[1;31mtime[m. The [1;31mtime[mout must be configurable
    through a user interface.
    
    This is a port from BUG#23613854 - MYSQL GCS DOES NOT HANDLE THE
    FAILURE OF NODE WHILE IT IS JOINING THE CLUSTER

[33mcommit a0c9d05785116482d4fffba5c1a898a2a6c0946b[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Mar 21 12:25:18 2017 +0100

    Bug#25748049 MAIN.TYPE_BLOB FAILS ON 32BIT LINUX AND WINDOWS WITH UTF8MB4
    
    Problem:
    Create_field::length is some[1;31mtime[ms number of bytes, some[1;31mtime[ms number of characters.
    So with utf8mb4 we multiply by four, and divide by four in misc places.
    This is extra problematic when using four-byte ints for the calculation
    (size_t on 32bit platforms, long on windows)
    
    Fix: always do these calculations using eight-byte ints, and check for
    against MAX_FIELD_BLOBLENGTH (== UINT_MAX32)
    
    Turns out we had forgotten to divide by four for MYSQL_TYPE_JSON
    in Create_field::Create_field()

[33mcommit f9a5c2caa466689a4d5d73565940ef4c5e4b1760[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Mar 22 09:19:31 2017 +0100

    Bug#25654833 MYSQL CLUSTER 7.5.5 REPLICATION SLAVE SQL THREAD HANGS WITH CREATE TABLE
    
    This is 'best effort' patch for the above problem, which seems to be a regression introduced in 7.5.5. Based on bug description, we *assume* this to be caused bu the 'part 3 of 4' push of patch for Bug#25042101 'SPLIT BINLOG INJECTOR_MUTEX IN TWO, DO REQUIRED CLEANUP':
    
    .........
      Remove thread_yield() in binlog injector code previously put there
      as a temp stopgap in the commit below. This used to be required
      as the injector thread held the injector_mutex > 99% of the [1;31mtime[m when
      waiting for pollEvents(). That blocked client threads either wanting to
      access the data shared from the injector thread, or needing the injector_mutex
      while waiting for injector_cond to be signaled
    
      This should not be required anymore, as:
    
      1) injector_mutex has been splitt in two separate mutexes.
      2) We changed init of the injector_event_mutex from a 'FAST' to a 'SLOW'
         mutex which has better 'farness' properties in the scheduler
    .........
    
    The theory is that using the more 'fair' SLOW-mutex variant is not as 'fair' as assumed to be on all OS/VM variants. Thus the 'yields' may be unsafe to remove.
    
    Bug has been hard to reproduce:
    
     - It has been 'randomly' reproduced using Oracle Linux 7 on top
       of 'Virtualbox'
     - It has than gone away for a couple of days.
     - It has *not* been reporoduced with this patch.
    
    So it should be reasonable to expect that reintroducing the 'thread_yields' should solve the problem.
    
    We cant say for sure though....

[33mcommit 04ce196a1cd94aef2ce34b5dca3330719aa73d1a[m
Author: Maria Couceiro <maria.couceiro@oracle.com>
Date:   Mon Mar 13 11:15:18 2017 +0000

    BUG#25710507 MYSQLBINLOG ASSUMES OCT TO BE AVAILABLE IN MYSQL 8.0.0
    
    Problem:
    Original commit [1;31mtime[mstamp related statements were introduced in the
    binlog in MySQL 8.0.1. However, mysqlbinlog is wrongly reporting that
    these statements have been present since 8.0.0 because they are dumped
    as:
    /\*\!80000 SET @@session.original_commit_[1;31mtime[mstamp=
      MICROSECONDS-FROM-EPOCH\*//\*\!\*/;
    and MySQL 8.0.0 did not support them yet.
    
    Fix:
    Changed the version to 80001 in mysqlbinlog dump.

[33mcommit b1f35740f886c6a87c047cd4b51c9ae64e4ae91f[m
Author: Craig L Russell <craig.russell@oracle.com>
Date:   Fri Mar 17 18:08:41 2017 -0700

    WL#9545 Clusterj automatic reconnect on cluster failure
    
    clusterj-api/pom.xml.in
      change Java version from 1.5 to 1.7
    
    clusterj-api/src/main/java/com/mysql/clusterj/Constants.java
      add property com.mysql.clusterj.connection.reconnect.[1;31mtime[mout
      add default for com.mysql.clusterj.connection.reconnect.[1;31mtime[mout
    
    clusterj-api/src/main/java/com/mysql/clusterj/Session.java
      make Session extend AutoCloseable for easier application error handling
    
    clusterj-api/src/main/java/com/mysql/clusterj/SessionFactory.java
      add method reconnect(int) to allow application to reconnect
      add method reconnect() to allow automatic reconnect
      add method currentState() to report state: Open, Closed, Reconnecting
    
    clusterj-core/pom.xml.in
      change Java version from 1.5 to 1.7
    
    clusterj-core/src/main/java/com/mysql/clusterj/core/SessionFactoryImpl.java
      implement new methods from SessionFactory
      add internal flag to getSession to allow reconnect to get a session when not open
      implement reconnect thread to asynchronously reconnect to cluster
        while reconnecting, getSession will throw a ClusterJUserException
    
    clusterj-core/src/main/java/com/mysql/clusterj/core/SessionImpl.java
      add multiple checks for session closing to fail fast on cluster disconnect
    
    clusterj-core/src/main/java/com/mysql/clusterj/core/query/QueryImpl.java
      add multiple checks for session closing to fail fast on cluster disconnect
    
    clusterj-core/src/main/java/com/mysql/clusterj/core/store/Db.java
      add method assertNotClosed(String)
    
    clusterj-core/src/main/resources/com/mysql/clusterj/core/Bundle.properties
      add new messages for reconnection
    
    clusterj-test/pom.xml.in
      change Java version from 1.5 to 1.7
    
    clusterj-test/src/main/java/testsuite/clusterj/AutoCloseableTest.java
      new test case for Session AutoCloseable semantics
    
    clusterj-test/src/main/java/testsuite/clusterj/ReconnectTest.java
      new test case for application-initiated reconnect
    
    clusterj-tie/pom.xml.in
      change Java version from 1.5 to 1.7
    
    clusterj-tie/src/main/java/com/mysql/clusterj/tie/ClusterConnectionImpl.java
      add a wait for Ndb objects to close after marking them closing
    
    clusterj-tie/src/main/java/com/mysql/clusterj/tie/ClusterTransactionImpl.java
      use new assertNotClosed method
    
    clusterj-tie/src/main/java/com/mysql/clusterj/tie/DbImpl.java
      implement new assertNotClosed method
      allow closing an ndb object even if a transaction is open
    
    clusterj-tie/src/main/java/com/mysql/clusterj/tie/DbImplForNdbRecord.java
      implement new assertNotClosed method
    
    clusterj-tie/src/main/java/com/mysql/clusterj/tie/NdbRecordImpl.java
      add multiple checks for session closing to fail fast on cluster disconnect
    
    clusterj-tie/src/main/java/com/mysql/clusterj/tie/NdbRecordScanOperationImpl.java
      add multiple checks for session closing to fail fast on cluster disconnect
    
    clusterj-tie/src/main/java/com/mysql/clusterj/tie/NdbRecordScanResultDataImpl.java
      add multiple checks for session closing to fail fast on cluster disconnect
    
    clusterj-tie/src/main/resources/com/mysql/clusterj/tie/Bundle.properties
      add new messages
    clusterj-tie/src/test/resources/clusterj.properties
      add new default property connect [1;31mtime[mout for running tests
    
    clusterj-tie/src/test/java/testsuite/clusterj/tie/AutoCloseableTest.java
      new test case for AutoCloseable
    
    clusterj-tie/src/test/java/testsuite/clusterj/tie/ReconnectTest.java
      new test case for application reconnect
    
    clusterj-unit/pom.xml.in
      change Java version from 1.5 to 1.7
    
    storage/ndb/config/type_JAVA.cmake
      change Java version from 1.5 to 1.7

[33mcommit fea0416b4232a75e71f9245cff3d731ebb86a722[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Tue Mar 14 20:56:31 2017 +0530

    Bug#25633041 : SHOW CREATE PROC/FUNCTION RESULT AFTER
                   LIVEUPGR IS DIFFERENT TO DUMPUPGR
    
    In place upgrade from mysql-5.7 to mysql-8.0 stored servers
    default client and connection character set for stored routines.
    This changes the behavior of the stored routines.
    
    Stored routines use the character set and collation in effect at
    routine creation [1;31mtime[m. If user wants to change the database default
    character set or collation, stored routines that use the database
    defaults must be dropped and recreated so that they use the new defaults.
    
    Fix:
    Use the client and connection collation in effect when
    stored procedure and stored function was created for inplace upgrade.
    
    Updated main.dd_upgrade_test.test result file which was
    recored mistakenly.

[33mcommit a3514a70ba5020405794301eb1c7a057864269f3[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Aug 30 10:24:15 2016 +0200

    Bug#24561887 ADD NOT_SPARC_DEBUG.INC
    
    Add mtr file not_sparc_debug.inc in order to disable
    a couple of tests which typically [1;31mtime[mout after 900 seconds in debug mode.
    Also disable for UBSAN builds.
    
    Change-Id: I1eb026da9258b87281c8c3b73873eed42dd75c16
    (cherry picked from commit 01d9325a2df6b6d4248bcd9e21dc6a361ac72ac7)

[33mcommit 49d561cf62df99f2c0f826f67176fd0421211dab[m
Author: Maria Couceiro <maria.couceiro@oracle.com>
Date:   Mon Mar 13 11:15:18 2017 +0000

    BUG#25710507 MYSQLBINLOG ASSUMES OCT TO BE AVAILABLE IN MYSQL 8.0.0
    
    Problem:
    Original commit [1;31mtime[mstamp related statements were introduced in the
    binlog in MySQL 8.0.1. However, mysqlbinlog is wrongly reporting that
    these statements have been present since 8.0.0 because they are dumped
    as:
    /\*\!80000 SET @@session.original_commit_[1;31mtime[mstamp=
      MICROSECONDS-FROM-EPOCH\*//\*\!\*/;
    and MySQL 8.0.0 did not support them yet.
    
    Fix:
    Changed the version to 80001 in mysqlbinlog dump.

[33mcommit 801f232155f5f87f9989ccb049cbd522de2c6053[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Mon Mar 13 15:45:25 2017 +0100

    Bug#25398515: Refactor accumulated Item properties into a bitset
    
    - Add a bitset named m_accum_properties in class Item.
    - Accumulate m_accum_properties from leaf Item nodes up to the root.
    - Remove Item::with_subselect, Item::with_stored_program and
      Item::with_sum_func, and re-implement them as bits in m_accum_properties.
    - Reimplement Item::has_subquery() and Item::has_stored_program() as
      non-virtual functions that operate on current Item's m_accum_properties.
    - Replace boolean Item::with_sum_func with a bit in m_accum_properties.
    - Implement non-virtual public function Item::has_aggregation().
    - Add the necessary setter functions for subquery, stored_program and
      aggregation properties for class Item.
    - Notice that the aggregation property may be set dynamically, e.g
      for Item_func_grouping, so in this case we need to override
      Item_func::update_used_tables().
    - Due to an anomaly with second [1;31mtime[m resolving related to Item_cache
      objects, the has_aggregation property for this object needs special
      treatment.

[33mcommit 6c4b100cfbcd0104c1568703e3e3e13d76242fbf[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Mon Mar 13 15:39:37 2017 +0100

    Bug#24930129: REDUCE NUMBER OF DICTIONARY CACHE LOOKUPS
    
    Post-push fix: Only check for metadata locks when DD objects
    are released if EXTRA_DD_DEBUG is set instead of doing it
    by default for debug builds. This check is expensive as
    DD objects are cloned and then deleted for every check.
    This cost was made more evident by the patch for Bug#24930129
    which lead to [1;31mtime[mouts for main.merge on Windows.
    
    No changes for release builds.

[33mcommit 68016e19b489437f9489b7c7e11c964ec022ff03[m
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Mon Mar 13 18:59:45 2017 +0530

    Bug#25701174: SERVER FAILS TO START FOR TESTS WITH BOOTSTRAP OPTIONS IN OPT FILE DURING RETRY
    
    Issue:
    ------
    If a test which has an opt file containing options passed to --bootstrap fails and
    if retry is enabled, the server fails to start again. During the retry, MTR cannot recognize
    bootstrap options set in the opt file because the 'bootstrap' key word is removed when the
    test is run the first [1;31mtime[m. So on retry, the server throws an error and fails to start.
    
    Fix:
    ----
    The bootstrap options are saved into a list when the test is run for the first [1;31mtime[m.
    On retry, there is no need to extract the bootstrap options from the opt file again.
    
    Reviewed-by: Pavan Naik <pavan.naik@oracle.com>
    RB: 15677

[33mcommit 1889d5a46eacae053d005ac1a338d5364dce2c57[m
Author: Anitha Gopi <anitha.gopi@oracle.com>
Date:   Fri Mar 10 01:32:12 2017 +0100

    Use --skip-combination to avoid usage of combinations in rpl suite. This will run tests in rpl suite with the default value of binlog-format.
    Also removed skip of disabled-per-push.list. Test suite is runnig in reasonable [1;31mtime[m without skipping these tests.
    
    Approved by Erlend Dahl <erlend.dahl@oracle.com>

[33mcommit c52be31754299b118cac1161d6e67840d130ba72[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Wed Mar 8 15:45:21 2017 +0100

    Bug#25685371: `E->USAGE() == 1' AT DD::CACHE::SHARED_MULTI_MAP<T>::REMOVE
                  FOR DROP VIEW
    
    This assert could be triggered by various DDL statements executing
    at the same [1;31mtime[m as view metadata was being updated. The problem
    was that if view metadata was being updated for several views,
    the metadata lock on the first view was dropped while the local
    dictionary client still had the object. If a concurrent DDL
    operation then tried to drop the view, the DD cache reference
    counter would be 2 and not 1 as it should have been.
    
    The root cause was that the DD cache Auto_releaser that tracks
    DD cache usage and handles reference counting had a too big
    scope so that its scope exceeded that of the metadata lock.
    This patch fixes the problem by making sure the Auto_releaser
    destructor (which decrements the reference count) is executed
    before locks are released.
    
    The patch also fixes an unrelated issue where an internal
    error handler allocated on the stack could still be in
    use when the scope ended leading to undefined behavior.
    Finally, the patch includes some minor cleanups.

[33mcommit fefc49211947bbc4155f8629281c45344bedf218[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Mon Mar 6 09:12:30 2017 +0100

    Bug#25669580: regression: assertion failed: 0 in Item_num_func1::str_op
    Bug#25669590: regression: assertion failed: collation.collation == ...
    Bug#25669606: regression: assertion failed: !is_temporal()
    
    Bug#25669580:
    Problem here is that for ROUND function when second argument is constant NULL,
    data type is uncritically copied from first argument. If first argument
    is not numeric, assign DOUBLE as type.
    
    Bug#25669590:
    Problem was caused by a too aggressive assert (although I see no harm in it)
    
    Bug#25669606:
    Problem is that Item_func_nullif inherits from Item_bool_func2,
    and thus Item_int_func, in order to utilize the comparison mechanism
    for equality operations. However, by doing this, in 5.7 the derived
    type of this Item is MYSQL_TYPE_VAR_STRING, even though the first argument
    is a temporal type. After bug#25221172, derived type is correctly
    MYSQL_TYPE_TIME, but then we reach Item::get_[1;31mtime[m_from_int(), which
    crashes because it is not implemented for temporal types.
    
    Quick fix: Adjust data type of item to MYSQL_TYPE_VAR_STRING in
    Item_func_nullif::resolve_type().
    
    Best fix would be to let Item_func_nullif inherit from Item_func_case
    and remove implementations for resolving and evaluation.

[33mcommit 3fd3328211cf0578d5b144b82f004e9c107da8e2[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Mar 3 11:02:38 2017 +0100

    Bug #25642319: ILLEGAL MIX OF COLLATIONS FOR TIME/VARCHAR
    
    When doing comparisons, don't try to coerce the right argument to the left's
    collation; instead, use the appropriate aggregations to try to find a superset.
    At the same [1;31mtime[m, fix a field in DTCollation that would have undefined value when
    using set().
    
    Also, make sure UTF32 is counted as a superset of any collation, because it is.
    (Previously, only utf8mb4 would have this status.)
    
    Change-Id: Ib55502cf2a36cbca77332a1d0f2b300a2c558273

[33mcommit 41cb4c37bf4fdccd155916cb645c0d9cf808ca4a[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Sat Mar 4 11:47:03 2017 +0100

    Stop innodb.tablespace_rename from running in Valgrind.
    
    The test [1;31mtime[ms out.
    
    Also, remove 'not_embedded' since the embedded server doesn't exist
    any more on 8.0.

[33mcommit 7d17582eb0cfd25bcb0c37b067c7839fa7d32d31[m
Author: Oystein Grovlen <oystein.grovlen@oracle.com>
Date:   Sat Mar 4 07:14:01 2017 +0100

    WL#10128: Add defaults column to optimizer cost tables
    
    This worklog adds generated columns that will show the default values for
    the constants defined in the two system tables, server_cost and engine_cost.
    
    Details:
    
    scripts/mysql_system_tables.sql
       Add column definition to cost constant tables.
    
    scripts/mysql_system_tables_fix.sql
       Add SQL code to upgrade cost constant tables to include column.
    
    sql/opt_costconstants.cc
       Added comment to remind developers that above scripts need to be
       updated to if cost constants are changed.
    
    sql/opt_costconstantcache.cc
       In order for resolving of generated column to work correctly when
       opening cost tables, lex_start() must be called.
    
    mysql-test/t/opt_costmodel_tables.test
    mysql-test/r/opt_costmodel_tables.result
       Added test that default_value is defined for all cost constants.
       Added test that verifies that default_value columns may not be updated
       Update test and result files to handle new column.
    
    mysql-test/t/opt_costmodel_upgrade.test
    mysql-test/r/opt_costmodel_upgrade.result
       New test file to test upgrade of cost tables.
       mysql_upgrade currently fails with 4k pages.
       Only run test when page size is minimum 8k
       Defined as big test since it may [1;31mtime[m out with high load.
    
    mysql-test/t/opt_costmodel_restart.test
    mysql-test/r/opt_costmodel_restart.result
    mysql-test/t/opt_costmodel_warnings.test
    mysql-test/r/opt_costmodel_warnings.result
       Update test and result files to handle new column.
    
    mysql-test/suite/funcs_1/r/is_columns_mysql.result
    mysql-test/suite/innodb/r/innodb-system-table-view_ci.result
    mysql-test/suite/innodb/r/innodb-system-table-view_cs.result
    mysql-test/suite/innodb/r/virtual_basic.result
       Update result files for tests that are affected by system tables definitions
    
    mysql-test/suite/i_innodb/t/discard_tablespace.test
       This test assumed that table created by the test was the only one
       with virtual columns.  This is no longer the case.  Fix assumes
       that system tables have lower table ids than the relevant table,
       and compares the maximum table id before and after ALTER TABLE.

[33mcommit 71995955a2343fd94f64a5894929e64a8d388292[m
Author: Andrei Elkin <andrei.elkin@oracle.com>
Date:   Fri Nov 25 15:17:17 2016 +0200

    commit c2718152b0e6d00dba8d791cf3866c7315418a85
    Author: Andrei Elkin <andrei.elkin@oracle.com>
    Date:   Fri Nov 25 15:17:17 2016 +0200
    
        WL#9175 Correct recovery of DDL statements/transactions by binary log
    
        The patch consists of two parts implementing the WL agenda which is
        is to provide crash-safety for DDL.
        That is a server (a general one, master or slave) must be able to recover
        from crash to commit or rollback every DDL command that was in progress
        on the eve of crash.
    
        The Commit decision is done to commands that had reached
        Engine-prepared status and got successfully logged into binary log.
        Otherwise they are rolled back.
    
        In order to achieve the goal some refinements are done to the binlogging
        mechanism, minor addition is done to the server recovery module and some changes
        applied to the slave side.
    
        The binary log part includes Query-log-event which is made to contain xid
        that is a key item at server recovery. The recovery now is concern with it along
        with its standard location in Xid_log_event.
    
        The first part deals with the ACL DDL sub-class and
        TRIGGER related queries are fully 2pc-capable. It constructs
        the WL's framework which is proved on these subclasses.
        It also specifies how to cover the rest of DDLs by the WL's framework.
        For those not 2pc-ready DDL cases, some[1;31mtime[ms "stub" tests are prepared
        to be refined by responsible worklogs.
    
        Take a few notes to the low-level details of implementation.
    
        Note #1.
    
        Tagging by xid number is done to the exact 2pc-capable DDL subclass.
        For DDL:s that will be ready for xiding in future, there is a tech specification
        how to do so.
    
        Note #2.
    
        By virtue of existing mechanisms, the slave applier augments the DDL
        transaction incorporating the slave info table update and the
        Gtid-executed table (either one optionally) at [1;31mtime[m of the DDL is
        ready for the final commit.
        When for filtering reason the DDL skips committing at its regular
        [1;31mtime[m, the augmented transaction would still be not empty consisting of
        only the added statements, and it would have to be committed by
        top-level slave specific functions through Log_event::do_update_pos().
    
        To aid this process Query_log_event::has_committed is introduced.
    
        Note #3 (QA, please read this.)
    
        Replication System_table interface that is employed by handler of TABLE type slave info
        had to be refined in few places.
    
        Note #4 (run[1;31mtime[m code).
    
        While trying to lessen the footprint to the run[1;31mtime[m server code few
        concessions had to be conceded. These include changes to
        ha_commit_trans()
        to invoke new pre_commit() and post_commit(), and post_rollback() hooks
        due to the slave extra statement.
    
        -------------------------------------------------------------------
    
        The 2nd part patch extends the basic framework,
        xidifies the rest of DDL commands that are
        (at least) committable at recovery. At the moment those include
        all Data Definition Statements except ones related to
        VIEWs, STORED Functions and Procedures.
    
        DDL Query is recoverable for these subclasses when it has been
        recorded into the binary log and was discovered there at the server
        restart, quite compatible with the DML algorithm.
        However a clean automatic rollback can't be provided for some
        of the commands and the user would have to complete recovery
        manually.

[33mcommit e3e1cd11d46dca1e0d528584ed9b314a1d96a48b[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Fri Mar 3 23:15:46 2017 +0800

    Wl#7361 MSR: per-channel replication filters
    
    There are per-channel and global replication filters. Each channel uses
    *only* its own per-channel replication filters to filter the event
    stream. It never uses global replication filters to filter the event
    stream. (A new channel would copy global replication filters to its
    per-channel replication filters if there are no per-channel replication
    filters and there are global replication filters on the filter type
    when it is being configured.)
    
    The per-channel replication filters and global replication filters can
    be configured in two ways:
    A) startup options: --replicate-*
    B) SQL commands: CHANGE REPLICATION FILTER
    
    Additionally, behavior for the following statements needs to be specified:
    C) RESET SLAVE [ALL] [FOR CHANNEL]
    D) SHOW SLAVE STATUS [FOR CHANNEL]
    
    Query, troubleshoot, monitor replication filters and do statistics:
    E) CREATE A NEW performance_schema.replication_applier_filters
    
    Show the global replication filters:
    F) CREATE A NEW performance_schema.replication_applier_global_filters
    
    A) Startup options: --replicate-*
    =================================
    
    The current startup options are extended by allowing to specify channel_name in
    filter variable to configure per-channel replication filters as follows.
      --replicate-do-db=<channel_name>:<database_id>
      --replicate-ignore-db=<channel_name>:<database_id>
      --replicate-do-table=<channel_name>:<table_id>
      --replicate-ignore-table=<channel_name>:<table_id>
      --replicate-rewrite-db=<channel_name>:<db1->db2>
      --replicate-wild-do-table=<channel_name>:<table regexid>
      --replicate-wild-ignore-table=<channel_name>:<table regexid>
    
    ---- Syntax ----
    
    Each command line parameter optionally takes a channel_name followed by a colon,
    further followed by the filter specification. Note that the first colon is
    interpreted as a separator, others are literal colons.
    
    ---- Semantics ----
    
    Without specifying channel_name in filter variable, the startup options
    shall act on the default channel. See below.
    
      --replicate-do-db=:<database_id>
      --replicate-ignore-db=:<database_id>
      --replicate-do-table=:<table_id>
      --replicate-ignore-table=:<table_id>
      --replicate-rewrite-db=:<from_db>-><to_db>
      --replicate-wild-do-table=:<table regex>
      --replicate-wild-ignore-table=:<table regex>
    
    Without specifying channel_name and a followed 'colon' in filter variable, the
    startup options shall configure the global replication filters. See below.
      --replicate-do-db=<database_id>
      --replicate-ignore-db=<database_id>
      --replicate-do-table=<table_id>
      --replicate-ignore-table=<table_id>
      --replicate-rewrite-db=<from_db>-><to_db>
      --replicate-wild-do-table=<table regex>
      --replicate-wild-ignore-table=<table regex>
    
    If the user specifies a per-channel replication filter through a command-line
    option (or in a configuration file) for a slave replication channel which
    does not exist as of now (i.e not present in slave info tables yet), then
    the per-channel replication filter is discarded with the following warning:
      "There are per-channel replication filter(s) configured for channel '%.192s'
    which does not exist. The filter(s) have been discarded."
    
    If the user specifies a per-channel replication filter through a command-line
    option (or in a configuration file) for group replication channels
    'group_replication_recovery' and 'group_replication_applier' which is
    disallowed, then the per-channel replication filter is discarded with
    the following warning:
      "There are per-channel replication filter(s) configured for group replication
    channel '%.192s' which is disallowed. The filter(s) have been discarded."
    
    How global and per-channel replication filters work together?
    - Any global replication filter option will add the filter to global
      replication filters on the filter type, not add the filter to every
      channel on the filter type.
    - Any per-channel replication filter option will add the filter to
      per-channel replication filters of the specified channel on the
      filter type.
    - Every slave replication channel will copy global replication filters
      to its per-channel replication filters if there are no per-channel
      replication filters and there are global replication filters on the
      filter type when it is being configured.
    
    Example: Suppose channels '' and 'ch1' exist before the server starts,
      the command line options --replicate-do-db=db1
      --replicate-do-db=ch1:db2 --replicate-do-db=db3
      --replicate-ignore-db=db4 --replicate-ignore-db=:db5
      would result in:
        global replication filters: do_db=db1,db3, ignore_db=db4
        default channel: do_db=db1,db3 ignore_db=db5
        ch1: do_db=db2 ignore_db=db4
    
    Note: GROUP REPLICATION channels should not be configurable using
      --replicate* nor CHANGE REPLICATION FILTER, and should not inherit
      from global filters.
    
    BTW: if user specifies multiple replicate-rewrite-db=FROM->TO options
    having the same FROM database, all are added together (put into the
    rewrite_do list) and the first one takes affect. The global replication
    filters and per-channel filters have the same behavior in the worklog.
    So there is no change on this, since a channel uses either global or
    per-channel rewrite filters on a filter type.
    
    B) SQL commands: CHANGE REPLICATION FILTER
    ==========================================
    
    Dynamic replication filters are currently settable using the
    CHANGE REPLICATION FILTER statement. We extend this command to
    introduce dynamic replication filters per channel, by allowing
    a FOR CHANNEL <channel_name> clause as follows.
    
    ---- Syntax ----
    
    CHANGE REPLICATION FILTER filter [, filter...] [FOR CHANNEL <channel_name>]
    
    filter:
        REPLICATE_DO_DB = (db_list)
      | REPLICATE_IGNORE_DB = (db_list)
      | REPLICATE_DO_TABLE = (tbl_list)
      | REPLICATE_IGNORE_TABLE = (tbl_list)
      | REPLICATE_WILD_DO_TABLE = (wild_tbl_list)
      | REPLICATE_WILD_IGNORE_TABLE = (wild_tbl_list)
      | REPLICATE_REWRITE_DB = (db_pair_list)
    
    ---- Semantics ----
    
    1) If an explicit FOR CHANNEL clause is provided, the statement acts on that
       configured slave replication channel removing any existing replication
       filter if it has the same filter type as one of specified replication
       filters, and replacing them with the specified ones. Filter types that
       were not explicitly listed in the statement are not modified. The statement
       is disallowed with an error 'ER_SLAVE_CONFIGURATION' on slave replication
       channel if it is not configured. The statement is disallowed with an error
       'ER_SLAVE_CHANNEL_OPERATION_NOT_ALLOWED' on group replication channels.
    
    2) CHANGE REPLICATION FILTER filter [, filter...] with no FOR CHANNEL clause
       does the following, both for every configured slave replication channel's
       per-channel filter and for the global replication filters: For every filter
       type, if the filter type is listed in the statement, then any existing
       filter rules of that type are replaced by the filter rules specified in
       the statement, otherwise the old value of the type is retained. The
       statement does not act on group replication channels, because replication
       filters on group replication channels are disallowed. For example,
    
    C. SQL COMMAND: RESET SLAVE [ALL] [FOR CHANNEL]
    ===============================================
    
    1) "RESET SLAVE FOR CHANNEL '<channel_name>'" does not remove the replication
       channel specified by 'FOR CHANNEL' clause, so it shall retain replication
       filters of the channel. It throws an error 'ER_SLAVE_CHANNEL_DOES_NOT_EXIST'
       if the channel does not exist. So this statement is not changed by the worklog.
    
    2) "RESET SLAVE" does not remove any replication channel, so it shall retain
       all per-channel replication filters and all global replication filters.
       So this statement is not changed by the worklog.
    
    3) "'RESET SLAVE ALL FOR CHANNEL '<channel_name>'" removes the replication
       channel specified by 'FOR CHANNEL' clause, so it shall remove all
       per-channel replication filters of the channel if the channel exists.
       Then SELECT * FROM performance_schema.replication_applier_filters
       and SHOW SLAVE STATUS proves there's no channel anymore and therefore
       its replication filters are gone too. It still throws an error
       'ER_SLAVE_CHANNEL_DOES_NOT_EXIST' if the channel does not exist as before.
    
    4) "RESET SLAVE ALL" with no FOR CHANNEL clause removes all replication
       channels, so it shall remove all per-channel replication filters but
       does not touch all global replication filters. When the new empty
       channel is being configured, it therefore uses the global replication
       filters (copies all global replication filters to its own per-channel
       replication filters). A user who wants to remove all global and
       per-channel filters can use the statement: CHANGE REPLICATION FILTER
       Replicate_Do_DB = (), Replicate_Ignore_DB = (),
       Replicate_Do_Table = (), Replicate_Ignore_Table = (),
       Replicate_Wild_Do_Table = (), Replicate_Wild_Ignore_Table = (),
       Replicate_Rewrite_DB = ().
    
    D. SQL COMMAND: SHOW SLAVE STATUS [FOR CHANNEL <channel_name>]
    ==============================================================
    
    SHOW SLAVE STATUS FOR CHANNEL <channel_name> shall show per-channel
    replication filters for the specified channel, or throw an error
    'ER_SLAVE_CHANNEL_DOES_NOT_EXIST' if the channel does not exist.
    SHOW SLAVE STATUS with no FOR CHANNEL clause shall show the
    per-channel replication filters on every channel.
    
    E. CREATE A NEW performance_schema.replication_applier_filters
    ==============================================================
    
    We shall introduce a new dedicated P_S table to display per-channel
    replication filters for usability. So create and maintain the new
    P_S table with the following columns:
      1) Channel_name: the name of the channel;
      2) Filter_name: REPLICATE_DO_DB, REPLICATE_IGNORE_DB,
                      REPLICATE_DO_TABLE, REPLICATE_IGNORE_TABLE,
                      REPLICATE_WILD_DO_TABLE, REPLICATE_WILD_IGNORE_TABLE,
                      REPLICATE_REWRITE_DB;
      3) Filter_rule: The values that user has configured with startup
                      options: --replicate-* or through CHANGE REPLICATION
                      FILTER command (This also includes empty set when user
                      unsets the rules).
      4) Configured_by: ENUM(STARTUP_OPTIONS, CHANGE_REPLICATION_FILTER,
                        STARTUP_OPTIONS_FOR_CHANNEL,
                        CHANGE_REPLICATION_FILTER_FOR_CHANNEL); (These
                        enumeration constants are the most self-descriptive
                        set of identifiers, and supporting all the use
                        cases: U1. Reflect the configured commands;
                        U2. Determine if the filter has been persisted;
                        U3. Debugging by a confused user, or learn the
                        logic of default filters by playing with
                        different ways to set them.)
      5) Active_since: Timestamp of when the configuration took place;
                       (To a new channel copying the global replication filters as
                        its own per-channel filters, set 'active_since'
                        to channel creation [1;31mtime[m.)
      6) Counter: the hit counter of the filter since last configuration;
    
      Note: (4) and (5) are important to troubleshooting. (6) is more about
      statistics (and monitoring).
    
    F) CREATE A NEW performance_schema.replication_applier_global_filters
    ======================================================================
    
    We shall introduce a new dedicated P_S table to display all global
    replication filters for usability. So create and maintain the new
    P_S table with the following columns:
      1) Filter_name: REPLICATE_DO_DB, REPLICATE_IGNORE_DB,
                      REPLICATE_DO_TABLE, REPLICATE_IGNORE_TABLE,
                      REPLICATE_WILD_DO_TABLE, REPLICATE_WILD_IGNORE_TABLE,
                      REPLICATE_REWRITE_DB;
      2) Filter_rule: The values that user has configured with startup
                      options: --replicate-* or through CHANGE REPLICATION
                      FILTER command (This also includes empty set when user
                      unsets the rules).
      3) Configured_by: ENUM(STARTUP_OPTIONS, CHANGE_REPLICATION_FILTER);
      4) Active_since: Timestamp of when the configuration took place;

[33mcommit a42ddab9aaae94d913683322b47c97ba514e9fab[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Fri Mar 3 11:02:38 2017 +0100

    Bug#25664323 SIGNED INTEGER OVERFLOW: 361810122 * 10 CANNOT BE REPRESENTED IN TYPE 'INT'
    
    Disable the test in UBSAN for the [1;31mtime[m being.
    
    Approved by Jon Olav Hauglid <jon.hauglid@oracle.com> over IM.

[33mcommit 201b2b20d110bc35ddf699754571cb0c064a3f72[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Fri Mar 3 12:40:55 2017 +1100

    Squashed commit of the following:
    
    WL#9499 - InnoDB: Replace MLOG_FILE_NAME with MLOG_FILE_OPEN
    
    Fix the performance issues introduced by WL#7142 and its followup WL#7806.
    
    1. Revert WL#7142 and WL#7806 changes, keep some of the tests to test
       the behaviour that was introduced by the two WLs
    2. Change the tests that rely on the above two WLs behaviour
    3. Use std::unordered_map instead of the homebrew hash table for the recovery
       code and space ID to name mapping
    4. Split the redo log hash table key from <space, page> -> apply records to
       <space> -> apply records
    5. Addition of two new system files (tablespaces.open.1 and tablespaces.open.2)
    
       - Rename MLOG_FILE_NAME to MLOG_FILE_OPEN
       - Remove the two pass recovery code, make it a single pass
       - Track file open, close and rename
       - Write and fsync the tracking state to disk on checkpoint and rename.
       Uses the files in #5 in a round robin fashion
    
    Introduce --innodb-scan-directories="path1;...pathN". Scan the paths for
    .ibd files to open during recovery. This option can be used if the files in #5
    above are corrupt or missing. You should not use this if you move files around.
    While they can be recovered the data dictionary will not be updated and it
    will cause issues during runtimg.
    
    rb#13686 Approved by Satya and Shaohua
    
    commit af3dc1301a768c01b971d14ad07549d6ef470fe6
    Merge: ac37b926e6a 4d81939d63a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Mar 3 11:16:10 2017 +1100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit ac37b926e6ad85b6c4e3d7880b905d082f1674be
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 23:12:24 2017 +1100
    
        WL#9499 - Fix test
    
    commit 2b05df7ffa592da9b19cec7ba31c04795a1cdfc0
    Merge: 3c79f3aee51 71b3bbff153
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 20:34:10 2017 +1100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 3c79f3aee51858b1859f4e8711883a85867c417a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 18:16:35 2017 +1100
    
        WL#9499 - Add an mtr tst
    
    commit 2c7496246c0e95e25c62ceb6fe5c1875f693ffac
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 17:34:50 2017 +1100
    
        WL#9499 Fix bugs
    
        1. Fix a memory leak, call mem_heap_free() instead of mem_heap_empty()
        2. Use a reference instead of copy by value during dblwr traversing
        3. Use absolute path names for tablespace.open.* files
    
    commit fbf87161f3c93979e5abe424fbe0678fdc32159e
    Merge: 517cf3a7bf0 c2b504664ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:39:32 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 517cf3a7bf0490c3168fed020e3096ec500e0a85
    Merge: 4786f93ad8a 5e974fd0ea4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:24:25 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Additional change is to call recv_recovery_from_checkpoint_finish() on abort.
        Instead of recv_sys_free().
    
    commit 4786f93ad8a25506a2a1f6e9d1207256a34b3665
    Merge: 5dc35e05b5f 275245cce32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:43:27 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 5dc35e05b5f2da95c36e191350e9c7087be72194
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:42:40 2017 +0100
    
        WL#9499 Free recv resources on abort
    
    commit bed693070395923ededba736f1c7102b8eb21e95
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 18:34:50 2017 +0100
    
        WL#9499 - Test cannot be run with Valgrind
    
    commit c5d423228ddf58b17866ff8be289dba4a19205d2
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:30:39 2017 +0100
    
        WL#9499 - Remove const
    
    commit ac42498506b4dffb22e74282d0ce037fe3acf977
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:00:30 2017 +0100
    
        WL#9499 - Clean up code
    
    commit bc48077cab9c3ccb1b2797c365fe0940c269a785
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 16:01:09 2017 +0100
    
        WL#9499 - Revert unrelated change
    
    commit 8b2bb0f6d6254b3cfde168d41356400009db12f4
    Merge: eb9b294ba78 153a79ff35d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:43:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit eb9b294ba786800f9e397cd87f01c4f4976edddb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:29:56 2017 +0100
    
        WL#9499 - Remove debug message
    
    commit abae66ad591854ee67a5013f3209be2f82e4d9bf
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 17:04:10 2017 +0100
    
        WL#9499 - Test only works in debug mode.
    
    commit 71ebea70391ef295bed49ee06a8b872f15ecfe97
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:18:08 2017 +0100
    
        WL#9499 - Update to mtr test from Matthias
    
    commit f108a5b92fc476c70c49e4937496b32d9d5d031f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:13:04 2017 +0100
    
        WL#9499 - Increment redo log version number
    
    commit 4439c83a4d3edd6e511706ccf9936770ed29e593
    Merge: fa459186b90 05923bef41d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 09:54:18 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit fa459186b90d7a5ddcba7e3c6c7a9871d0dce793
    Merge: 14ac4f81d84 b401f17e70d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 20:02:40 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 14ac4f81d84bec23a7be210504ca0be93619bf11
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 16:44:57 2017 +0100
    
        WL#9499 - Update from Matthias
    
    commit ed3191a9fc951151fd7d758a527e7ab81530b3f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:16:11 2017 +0100
    
        WL#9499 - Revert change pushed by nmistake
    
    commit 8c0edb998867bf557f6c86410552d6d123892000
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:11:21 2017 +0100
    
        WL#9499 - Don't redo log MLOG_FILE_OPEN until startup is complete
    
    commit 3b503ea1d3f89c0f7e3677d3b56f249c7ebff506
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:37:04 2017 +0100
    
        WL#9499 - Add tests
    
    commit 47af7bd6eec10eac55633d7c4cf54afe607f3649
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:00:30 2017 +0100
    
        WL#9499 - Fix compile problem
    
    commit a8b9a8c6ccb15e2be5ce5db5fa0bce24b86d2c87
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:51:05 2017 +0100
    
        WL#9499 Remove dead code
    
    commit b1dba474486ad10b61029b2ef4e6a91ea67dcea8
    Merge: 3cf9e9eb3e8 a4271026201
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:49:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 3cf9e9eb3e86e4c8f4d44cb79d3f7c456ea7d671
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 18 07:53:43 2017 +0530
    
        WL#9499 - Remove suggestion to use force recovery
    
        --innodb-scan-directories is a safer option for the user. Force recovery should
        be the absolute last resort.
    
    commit 4104c4bfd606270650aac95a9a724e106fe835c5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 09:00:47 2017 +0530
    
        WL#9499 - Fix error message
    
        User can try --innodb-scan-directories="..." if the tablespaces.open.* files
        are corrupt or unreadable.
    
    commit 19ab12e54923b070a0b4ffc76b9fe97ac54ad3cc
    Merge: 50b3a95e446 f0f51c410bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 05:22:57 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Replace readdir_r() with readdir(), compiler complains that readdir_r() is
        deprecated and recommends replacing it with readdir().
    
    commit 50b3a95e446b91853fc35716b63bdc173221d01f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:55:33 2017 +0530
    
        WL#9499 - Fix test
    
    commit 45d202ae0fa35aa3aced55cc1933aeefa33837de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:32:56 2017 +0530
    
        WL#9499 - Remove redundant test
    
    commit 48fe691b97735e5144e9d439a0adbf721b2dc554
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:18:11 2017 +0530
    
        WL#9499 - Add DEBUG sync points
    
    commit d986f4e04a9eb6c2c76d61cd4afe9541d77b34bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:03:50 2017 +0530
    
        WL#9499 - Remove PB2 control file
    
    commit 5af7dca9c305bd366ad2b5c3de26a870e913af4a
    Merge: 74022f50a5f 23a0e71aa3d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 15 09:05:05 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 74022f50a5ff7cb2801c0712601f8a467b409a28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 14 10:31:00 2017 +0530
    
        WL#9499 - Fix test
    
    commit f6188175ee62040ac6a844a5c54787839dff6155
    Merge: 24c867aab14 19ca7c6a5d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 13 12:37:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 24c867aab14556188503aac495f60d89ba3d26ec
    Merge: cb64b8c7f9f a4de6ab549e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 4 06:41:23 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cb64b8c7f9fa9ca05033a9d6f6193cf141746310
    Merge: 17c6c41da0a 88dbc4f4511
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:48:12 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 17c6c41da0afe3fc78843b75fa02578dab29a0ca
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:46:34 2017 +0530
    
        WL#9499 - Add a test for scan directories.
    
        The use case is where the location of the files is not changed but the
        tablespaces.open.* files are missing.
    
    commit 79cc52f1bd82dc65932eacbc9aa14a47e4196572
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 18:01:50 2017 +0530
    
        WL#9499 - If open fails space will be null.
    
    commit 22ea5f31ecc1fa0db8abd57d4a46578e5f891c9a
    Merge: f5b69930f95 853a52cf5a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 12:14:41 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f5b69930f95192ddfdb3ca170024a5c7e3416076
    Merge: 40a4c32f2c4 b18872ed4a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 2 13:54:24 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 40a4c32f2c42b584539a14cbc1ba0d4f0fe7d3c9
    Merge: b1d1923d37c d071c0e7a0b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 1 13:48:33 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit b1d1923d37c3d23a9f701a61b458b7e4cbd3c90c
    Merge: 2fc6c51edab 4ae71705a01
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 31 10:44:59 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2fc6c51edabc3de4537eceb0b82cd62063ada3a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 16:36:46 2017 +0530
    
        WL#9499 - Empty the tablespace.open.* files on normal shutdown.
    
    commit 738acb7d554f97455c8dba512282c7c2e6ba9f3a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:47:21 2017 +0530
    
        WL#9499 - Fix formatting
    
    commit 28f8579a6f729af354e0c50098d16fbfa17cc253
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:25:30 2017 +0530
    
        WL#9499 - Bug fix
    
        The DELETED state was set on a copy of the data structure
    
    commit dd5bf8ea81b7023fa1980c01d89219a690160b04
    Merge: 7eeab0a994d 9c7808e1054
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 21:14:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7eeab0a994db4cf0c2e080f27ff916c778ec65f8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:50:59 2017 +0530
    
        WL#9499 - Add tests.
    
    commit ddfaf047f43587ee807599b0b80b6d01a3579e8c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:48:06 2017 +0530
    
        WL#9499 - Create tablespace bug fix
    
        If there is a checkpoint after the create tablespace is logged and the
        server crashes after writing the page initialization to the redo log. Then
        we neither have the mapping in the redo log nor in the tablespace.open.*
        files. We must update the tablespace mapping before writing the CREATE
        redo log entry so that the state is written out to disk on checkpoint.
    
    commit 29546d3ebea2991e5b86b33edddb551c924bf1db
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 17:55:28 2017 +0530
    
        WL#9499 - Remove dead code from WL#7142
    
    commit eced7a3e4437ee4bb24a12290f561437ddb15611
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 14:51:09 2017 +0530
    
        WL#9499 - Use the tablespace.open.* files in a round robin fashion.
    
    commit d8eff788eea1ad5e6c7786b9d64963524f2b2c81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:56:12 2017 +0530
    
        WL#9499 - Fix duplicate entry
    
    commit 1d04e0cf0308c35ee7498e6919eab9a11c699d52
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:55:30 2017 +0530
    
        WL#9499 - Revert last push
    
    commit 8361d3c39366d6435a895d5b64dd23615d26fc28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Jan 26 09:05:52 2017 +0530
    
        WL#9499 - Write to the tablespace.open.* files in a round robin manner.
    
    commit 3eaba629ee5b5c26a5f4e80852fee2d446f3013f
    Merge: 6642c43d735 bdc49070128
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 25 14:03:15 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6642c43d7353063a455972ab2cbc21220c16be43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 08:34:35 2017 +0530
    
        WL#9499 - Rename fil_ibd_load to fil_ibd_open_for_recovery.
    
    commit fdd1897c79b29c9e0a69c1f81d94927da06d9424
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:28:49 2017 +0530
    
        WL#9499 - Enforce const semantics on Windows for Folder::exists().
    
    commit 9394f4653e10cc5d4ab9b7b0a0b9331fd2666f49
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:08:26 2017 +0530
    
        WL#9499 - Include <array>
    
    commit c1903d28800ae0f7af69552aa669622d552346b4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Jan 21 07:49:28 2017 +0530
    
        WL#9499 - Improve scan directory handling
    
        1. Convert relative paths to absolute paths
        2. Filter out duplicates
        3. Check directories at filtering stage
    
    commit dfea237f4bef914de4067153cbf382240112c4f4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 11:11:05 2017 +0530
    
        WL#9499 - Code clean up
    
    commit c4d51bfdf1c786b1c584c0af1bde080a4f37cc5b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 07:37:06 2017 +0530
    
        WL#9499 - Update the open/rename LSN when a file is opened or renamed.
    
        Minor code cleanup.
        Add diagnostic code for debugging.
    
    commit 5e1d159b571fe6dbfe13c627a245155b82c4bbfa
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 18 10:59:54 2017 +0530
    
        WL#9499 - Filter out '*' from innodb-scan-directories
    
    commit 361f2944f1940f11dfb16dec3589d68335f5e2d8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 21:01:06 2017 +0530
    
        WL#9499 - Code cleanup
    
    commit 288d70b356721887423ca3d2d72b42da331216cd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 13:08:08 2017 +0530
    
        WL#9499 - Sync open file map to disk before checkpoint.
    
    commit 3c602d1b4089cd262200650f4b33986fc9e26531
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:18:46 2017 +0530
    
        WL#9499 - Print expected bytes instead of generic message.
    
    commit f52e0985b8cbef3891385179d35dc8c7f567146a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:07:47 2017 +0530
    
        WL#9499 - Print file size instead of generic message.
    
    commit b27b1b4b4b70e286e2c669f997b0a669f6d6034c
    Merge: bbdd1c46f1e c101ec9b557
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 16 13:19:42 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit bbdd1c46f1ef08d956ea249e1f6f4bc93d3464f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Dec 10 14:41:12 2016 +0530
    
        WL#9499 - Handle the case where the rename has already been done on recovery.
    
    commit 141bdb02b1a402e786db5d8b165b781a5d7370a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 11:59:29 2016 +0530
    
        WL#9499 - Instrumentation for debugging
    
    commit 34815bb24a1c296d9739e7602dc6ccd53c58c44c
    Merge: 41ca3732a6f 13a46b4c5ea
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 09:44:03 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 41ca3732a6ffd8dfa16762a05df6b5c6b4b550c1
    Merge: 7137edb2d2c aba34f1205d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 11:10:08 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7137edb2d2ca60cdec44600ddf3f5cbde424e7a4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 05:56:06 2016 +0530
    
        WL#9499 - Remove unused code. Move id to name mapping sync before log flush.
    
    commit 2a50067e2da2f7819781de6550e55ca14995c7ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:57:41 2016 +0530
    
        WL#9499 - Initialize the PFS file handle
    
    commit d478d3492cdb40ec02fda9c043bf29b87bae11ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:05:52 2016 +0530
    
        WL#9499 - Fix whitespace
    
    commit 061af748a5e2fde6c1577ccdabfc8a89a9f753de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:02:25 2016 +0530
    
        WL#9499 - Set must flush on file close/delete.
    
    commit ad76e2b9c7ff757f60c66821e86696d5ab757b18
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 11:43:00 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5a95946d4567dc13cf5a12d6bcdb28b19a02b5bc
    Merge: 1a0f373eb7f da23d6b8e44
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 09:27:45 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1a0f373eb7f03dc22264f91f3f6ed1fd13825de7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 13:01:41 2016 +0530
    
        WL#9499 - Readd test result file back
    
    commit 00afde093183cf850f735940245af111dce82b72
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 12:59:49 2016 +0530
    
        WL#9499 - Don't purge the files based on LWM. It won't work.
    
        We need to also ensure that there aren't any pages in the buffer pool that
        belong to a tablespace that is closed. Redo log records can be written for
        such pages.
    
    commit 3199fe255103daa42f0332b7ff9d565eefff7429
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:41:39 2016 +0530
    
        WL#9499 - Fix typo
    
    commit 351cb6c42709405a79021276f310d7b996aadd1b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:32:02 2016 +0530
    
        WL#9499 - Remove unused function
    
    commit 61cc7f6b06c5280d58217b76d7627013ddcd8338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:22:31 2016 +0530
    
        WL#9499 - Reduce the compression level.
    
    commit 48142e360ff5cfb53d5e416f3d6b92e956237923
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:21:51 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 4de4f8b31ebdff31a2f7a97a1ad211770d20cdd6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 14:07:07 2016 +0530
    
        WL#9499 - Revert ef30f0754ab22e614ac22712c348ec5f53e0f09c
    
    commit c2f77f44c43c209fad86bba568aa521a2dcbf718
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 12:20:37 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 5fccb51769a13cb9a1fc0f29a832d3b0085ad52a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:30:18 2016 +0530
    
        WL#9499 - Print a message when checkpoint is disabled.
    
    commit ef30f0754ab22e614ac22712c348ec5f53e0f09c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:17:27 2016 +0530
    
        WL#9499 - Print progress in 10% units.
    
    commit bc0ded332624fa2c8a08ebfc955a03f1a24e069c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 08:13:54 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 68ce0208cc073452f5f791faf304971dbac7194a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:38:03 2016 +0530
    
        WL#9499 - Scan directories after the mutex code is initialized.
    
    commit 21e07c8fd6b8eddf158fb79980443f6c9f6d238e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:12:23 2016 +0530
    
        WL#9499 - Introduce --innodb-checkpoint-disabled (debug)
    
        Disable checkpointing if the variable is set. This is to force recovery if the
        server is killed during a test.
    
    commit 7033c9bb5ff7641764f70823a73d747b497a0eed
    Merge: 11a6e582417 c6af7f512b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 04:00:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 11a6e582417d45a80a7f19233c2d2191a17936eb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 03:59:05 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 0a38252e65d607b59b1e9f64d0c8003cdecfecfd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 25 05:56:42 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bcf650cc92b8636f3768dcc3deb33b90b2942134
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 08:46:07 2016 +0530
    
        WL#9499 - Change the open files number back to 2.
    
    commit 99960af2825529fb45d021a34ba6c072e8caa0dc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 07:13:58 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bdb91bc0ba03e01661c50c7175d3fd123d2bcd69
    Merge: 61f3e4a5663 a545bdd6e31
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:04:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 61f3e4a5663c375cd44ee766b263281ff7f0601b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:00:20 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 072ab837d0acb4d2ed817110598554acc44ec344
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 12:06:53 2016 +0530
    
        WL#9499 - Set the IMPORT page LSN to the flushed to disk LSN
    
    commit 7f18661432f3645eb9ce76680c62508ced115fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 11:28:47 2016 +0530
    
        WL#9499 - Force a checkpoint before the crash
    
    commit 83671e9c37fa61adfa5546cabe1463a91ff02241
    Merge: cc26d5ae16e d1f811eb6e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 10:52:16 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cc26d5ae16e8d723a2519f38bfbc084c13a766c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 18:40:51 2016 +0530
    
        WL#9499 - Fix latch ordering issue
    
        Cannot hold the log sys mutex when updating the checkpoint LSN for the open
        files in fil0fil.cc.
    
    commit 4474509addfbdf91b9f0ad890a971299c594e738
    Merge: 396755e195c 0856b10cde5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 08:00:05 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 396755e195c1c8d3b2485a58175dcf56ca2cbf3f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:58:05 2016 +0530
    
        WL#9499 - Remove newline added earlier
    
    commit ab5e60ba491e52f1529c22551a936d771b8b5ef9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:57:21 2016 +0530
    
        WL#9499 - Revert a change that was added by mistake.
    
    commit 38688417713e5ef8cbb65032fa0a547ab0c25c15
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 20:44:50 2016 +0530
    
        WL#9499 - Bug fix, using an invalidated iterator.
    
    commit 4082d44f6dc4a5605562e37ccad9ac4db69344c6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 11:30:49 2016 +0530
    
        WL#9499 - Fix doxygen comment
    
    commit d5ca99e14c010a5349aea6c8cc39493b2073b9c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 15:30:12 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a25f3af10ea2893c634dc961d6f2af05efa103ec
    Merge: c8c2a7eba4c aa039b73223
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:52:51 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit c8c2a7eba4cac29ff431588daf2d6def0c0ee5a6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:39:32 2016 +0530
    
        WL#9499 - Fix problem with open files acrosss checkpoints.
    
        The problem is that we write the open file state before writing the checkpoint.
        Before this change the closed files were purged from the open state map and
        the state written to disk. The problem is that the state and mapping of a file
        opened before the last checkpoint but closed just before we write the state
        will not be in the mapping on disk. One solution is to check older files and
        retrieve the mapping from there. The solution chosen is to avoid purging
        files based on open LSN. If the file was opened before the last checkpoint
        and closed within the current checkpoint we note the state as CLOSED but
        write the mapping to disk. It will be purged at the next checkpoint, if it is
        not opened again in the mean[1;31mtime[m.
    
        Previously an attempt was made to open all files straight after reading the
        mapping from disk. With this change only the state is loaded into memory the
        files are opened on demand. Added a check to verify that the tablespace ID
        from the first page matches the expected value.
    
        Fixed tests to use this new tablespace ID verification.
    
    commit 5dc929e54b1c259f0f8104739ae1f88e9b860f73
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 12:24:40 2016 +0530
    
        WL#9499 - Remove unused code
    
    commit 528b95d70dcc05a69a98ee2a76fdfb8dae1e82fe
    Merge: d9861c40964 75f05cba753
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:14:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d9861c40964ad8fd45ee2cbbd9d94946110e8a9a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 3007ea5af68f40b85bc93098d8385ac96bcbd660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 9592996d2f17c9005262faa75dc1ade9dedbd511
    Merge: da512d5591b ac925fc91f6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Oct 19 10:34:48 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit da512d5591b3379b793d6155089e90791fe94c61
    Merge: f42e2ddd7d5 e635dfe28c0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 30 05:20:10 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f42e2ddd7d50aacae679babe71643af379b5c492
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 15:05:28 2016 +0530
    
        WL#9499 - Fix assertion, the values can be ORred.
    
    commit 94cd08960bc3801acefd4b4ff4ddb4a3e7d7e81a
    Merge: 32a68f91330 59af373321b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 11:05:21 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 32a68f9133011871bfdaba3c742f6239e0a53061
    Merge: 7857f38ebce 15555ae2165
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 21 11:23:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7857f38ebce747135e055bc8a232b649f1aad351
    Merge: 427491f63f1 b43bf88cf80
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 19 11:43:17 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 427491f63f107247c36796e66f6224d20968f104
    Merge: e7fa4c53dcf 23343687722
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 14 22:40:47 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e7fa4c53dcf01ea0e101bd8aa817698492995034
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 19:22:00 2016 +0530
    
        WL#9499 - max_lsn should work with any number of tablespace open files.
    
    commit 09775960da43d36ca64504c1298b9adff3056575
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 17:47:29 2016 +0530
    
        WL#9499 - Fix Names hash bug.
    
    commit 8430c5b34d23cb1774597707fe583dfac93fb3a8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 09:49:47 2016 +0530
    
        WL#9499 - Use std::unordered_map for name to fil_space_t* hash.
    
    commit 5e8275caf9d50dc9ba2f2dadd3b8c0fdeb9c79b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Sep 10 07:55:42 2016 +0530
    
        WL#9499 - Reduce an extra fil_sys_t::mutex call by consolidating flush request.
    
    commit b29fd1039cf0022cff36a2a2311f464f1f6dbcc5
    Merge: 6235ee4902a a150caebee6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 9 20:44:56 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6235ee4902addd1a041b33469988bb1ea870dc7a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 10:58:00 2016 +0530
    
        WL#9499 - Add debug crash points.
    
    commit bf71fbc72b3570f55c8f01dd1a440e9eff761cb6
    Merge: ce6d2246a94 d25f38e38d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 09:47:37 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit ce6d2246a94801041da0bfece74b5ffdd9e8f796
    Merge: 69adae163de f28c4b9a41e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 7 11:20:50 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 69adae163de295ef0e910752cf5f8c96b1c1114f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:33:29 2016 +0530
    
        WL#9499 - Ensure that the MLOG_FILE_OPEN is always written first to the redo
    
    commit 20d5b1ebe6c899e2a0a1d135ad4303490516ce26
    Merge: 2d7d25c145f 4f1fb936211
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:17:58 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2d7d25c145fae59af744e91fce47fe009c869dad
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 10:06:56 2016 +0530
    
        WL#9499 - Add PFS instrumentation for the tablespace open file.
    
    commit 4e14a53ad129c1adcb0a3330931878a9f24c15cc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:53:57 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a465361e74136662471d2b9c0f307799efbe7269
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:17:43 2016 +0530
    
        WL#9499 - Move the file write code to a separate method.
    
    commit 7a26ba28bf7bf94808c47cfcdb6210c4abde2587
    Merge: f49914e5e61 ed389829067
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 07:55:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f49914e5e61b846c45f7b177308cd891918619e4
    Merge: a4fab040243 16fd507b84a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 31 11:23:42 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit a4fab040243a57fb8ef55f91812604352d8b92c8
    Merge: 93019973329 dfee02dc4f5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 10:42:20 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 9301997332923921b93de4946c4824164723050c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 09:09:05 2016 +0530
    
        WL#9499 - OSX/Solaris compilers don't like the code.
    
    commit 54afa110837a054de24ccda84ddbb4ef2d0b96a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 22:55:19 2016 +0530
    
        WL#9499 - During recovery PFS instrumentation can't be accessed by the user.
    
    commit fa5c11e8cf0fbcd1852535faa74b1a04200df2e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:15:07 2016 +0530
    
        WL#9499 - Fil_Open::purge() can be called during recovery too
    
    commit d8672a978d62db42f1a12ba152693a3c0d244d83
    Merge: d4251d0ed6f 14d2a977ce8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:10:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d4251d0ed6f9df5a3acbf97ce7ba8074f126044c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:07:14 2016 +0530
    
        WL#9499 - Remove a WL#7806 test.
    
        The test doesn't really help. It uses very simplistic checks for matching
        path names. It ignores links (soft and hard) completely. Besides during
        recovery the path names will work with the original path names.
    
    commit fba6656350d0a757b2cc936b017329e7f7ce2d32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:51:53 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b522d665d10dca905420cb9119692dffac5024c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:20:30 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 3a9aca50a2e193398d626b5f75d238b5aa704e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:19:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5923cd73fc3af904220dea20b033ffcbb7892606
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:12:44 2016 +0530
    
        WL#9499 - Use custom allocators.
    
    commit 8c5acab2641cedae9542b9ad9405032abbcb4618
    Merge: 1509c43fcff 3c1319b9901
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:21:28 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1509c43fcffb9a849542ef8f3a62e66fda490fc7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:08:34 2016 +0530
    
        WL#9499 - Fix bug, should be decrement in_use, not increment.
    
    commit 0ad783d5e6e3f99817c8b839fe8521f783577d35
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 07:58:49 2016 +0530
    
        WL#9499 - Change fil_node_t::in_use into a reference counter from bool.
    
    commit 3974f1ed40bfbadcee04fa5fc2e60a50b89f930c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 22:10:24 2016 +0530
    
        WL#9499 - Remove an assertion that is no longer an invariant.
    
    commit d79f12dec7c07698f02ce2e0d0396bcd01bdc683
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 21:52:21 2016 +0530
    
        WL#9499 - Rename fil_node_t::being_extended to in_use. Fix test.
    
    commit 1d3368bcf60e2e339d5917251b51201b94dd63a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:57:38 2016 +0530
    
        WL#9499 - Fix log info messages during recovery/apply.
    
    commit d3811bd67248d3ae014f0e6475b1b49524f5c35b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:40:01 2016 +0530
    
        WL#9499 - Don't print % processed if number of records to apply is small.
    
    commit 55af670ff81170da51fbcae6832c3d6191176602
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:21:31 2016 +0530
    
        WL#9499 - Update test with new log message to check.
    
    commit 60c3d6c074ae230ab594015ed2f99e2eefcf97e0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:09:04 2016 +0530
    
        WL#9499 - Record test, because of new config parameter innodb_scan_directories.
    
    commit bd79ff06406c86758a29a28dbe5e7d494a0aa51f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:05:38 2016 +0530
    
        WL#9499 - Remove WL#7142 artefact.
    
    commit bcb753b72b2a01ba35d952cbab45e420929f2b33
    Merge: e30834ecc60 27d64e974ec
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:26:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e30834ecc60522fca8d7b156a66c0765867dea6e
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Thu Aug 25 05:54:26 2016 +0200
    
        WL#9499 - Destroy the mutex in the Fil_Open destructor.
    
    commit a396d4714bdc46626e07d22b6871be153b627bd3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:17:06 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 282ad76aaeaeb6d91bbf81fcd3315f455d9f572c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:12:33 2016 +0530
    
        WL#9499 - Protect changes to Fil_Open state with a mutex.
    
    commit d338cb9468c126ee7e3eeae3bf37b0fc966bbf53
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 07:37:49 2016 +0530
    
        WL#9499 - Fix division by zero.
    
    commit 845324f19ba0a84538b87c072f6d99514533aa25
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:28:45 2016 +0530
    
        WL#9499 - Check for UNDO tablespace names during directory scan.
    
    commit 30ed1d19389e174605fdfc0b7d55fdf544933712
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:26:08 2016 +0530
    
        WL#9499 - Conform to new naming guidelines.
    
    commit 4cf67b352d4c8131064f832ec884db6166d50e71
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 22:04:43 2016 +0530
    
        WL#9499 - Add test for the configuration variable. Add a version number to the file.
    
    commit ad9c5bca0eba1d7bf8e29cd8ebd7062aae089f90
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 21:01:56 2016 +0530
    
        WL#9499 - Code clean up
    
    commit a9e848158909645ead86759ed7ab64789d18a0cb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 15:26:02 2016 +0530
    
        WL#9499 - Print redo apply progress per tablespace
    
    commit 8cf86cf1567cabc1b03b2e8f2ec1167f3c38ce6c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 13:04:55 2016 +0530
    
        WL#9499 - Print tablespace name and % completed per tablespace
    
    commit 35ccdf32d1d048400012a80422072fb41ceb1bbd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 10:35:26 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit c978fb2e18a4e0b4a93b44fc3c75234bcdb3f1f0
    Merge: 8bde4aeb01c 0832bf660e3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 22:25:57 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 8bde4aeb01c3bcdecfb884e566f0ae28797a5b36
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 13:21:10 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 7f502be746cbe0de1a0c3a992217691b167c2fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 12:12:08 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 247bcfda6744a67cc4e53d61658ca87d206b0660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:57:44 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 04509641b086a1b0b2c591573f95957f8a2f1cd0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:50:55 2016 +0530
    
        WL#9499 - Pass the filename directly to the callback
    
    commit 3efa317825886a3ae5d4a3c771fc0770a2c5a3ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 09:39:18 2016 +0530
    
        WL#9499 - Include tchar.h on Windows
    
    commit 55b814d2c2ebdea7c16a6d87a7251ca3f6e83775
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 07:47:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit e4d203688273b562691c912cb9c7024709757490
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 22:02:02 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 31433b21dcabba0a7705eb8b1879beb1d8c36517
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 21:37:41 2016 +0530
    
        WL#9499 - Move Dir_Walker::walk implementation to os0file.cc
    
    commit 11f9016477274c5420782e365b26762067e7b99b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 18:42:28 2016 +0530
    
        WL#9499 - Fix Windows version of Dir_Walk.
    
    commit f32b88e0b1ef99f220165897db745b1dba12f86b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 13:48:03 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b91ad88d96942f1e05443001b7d1c2f6818ff6d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 14:32:25 2016 +0530
    
        WL#9499 - Initialize active ID to filename set from scanned set.
    
    commit 4a09f677ae7095aac9b07f7beccba8e60c50b065
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 13:09:05 2016 +0530
    
        WL#9499 Scan specified directories to build the ID to name mapping.
    
    commit c13b791497e322e6a5cf64ba85da52ee2cf05d45
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:46:53 2016 +0530
    
        WL#9499 - Fix check for incomplete read.
    
    commit 8a849e0288309cec7228612a62fc2bfd71b595e9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:45:04 2016 +0530
    
        WL#9499 - Fix Windows build errors
    
    commit 4fc24b654da26e8411fc45bc96f73ff70dc73e43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:12:12 2016 +0530
    
        WL#9499 - Need to include string for Windows std::wstring.
    
    commit bcb5c2b23f54776e0faaafba2472bb2555aee561
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:02:59 2016 +0530
    
        WL#9499 - On POSIX fopen() mode should be "w+b".
    
    commit b3c7def1931867633d9b8bb601317e99a06c31a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 21:23:57 2016 +0530
    
        WL#9499 - Open file in binary mode for writing.
    
        Otherwise on Windows newline (0x0A) is translated to CRLF (0x0D0A).
    
    commit 0739399cb8a384c07b4b3540b73ade482d083f4a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 20:27:11 2016 +0530
    
        WL#9499 - More error messages during mapping file read. Add a directory walker.
    
    commit 1322de0af2235bc94630f7cb22e4ead1588775ee
    Merge: f266b100e2f 8fdbb2f5f1a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:47:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f266b100e2f23e775e5e04de8d26301d7f2f1072
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:18:07 2016 +0530
    
        WL#9499 - Flush the tablespace to mapping file buffers before fsync()
    
    commit 7c92536686033c2c70e7df831d569c1cd6f871f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:32:26 2016 +0530
    
        WL#9499 - Remove unused member variable m_lsn.
    
    commit 994c4766ef712e7da668788d0bdd648cbd764982
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:25:05 2016 +0530
    
        WL#9499 - Don't crash on uncompress failure. Try the next file if any.
    
    commit a419a190cdf734e3beca08d339c6c0d307ddff5f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:21:49 2016 +0530
    
        WL#9499 - Print an error code on uncopress failure
    
    commit 77cb39000e098ba4d06873723423521e6889a7d0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:12:11 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit afc632e0ef768542a96d4d15a897cb1780825d2e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 11:34:44 2016 +0530
    
        WL#9499 - Compress the tablespace open state file.
    
    commit 568c9e758084f671007789f7b5d1c996f5df39a0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 09:12:39 2016 +0530
    
        WL#9499 - Free the buffer on return
    
    commit 0f468cf8e50b9605a9e6c4e93c818b0f876c3c29
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 08:42:38 2016 +0530
    
        WL#9499 - Remove protobuf
    
    commit e789eb175d2da90cee2d46e30b91e623546f9e96
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 18 09:59:37 2016 +0530
    
        WL#9499 - Get native HANDLE
    
    commit 6014c5853c09fee75256f9de6a86a5fc0ea18508
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:50:37 2016 +0530
    
        WL#9499 - Use _fileno() on Windows
    
    commit 61e6b4d7c033d48b775b22c4ad6d6b4858cd4cd7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:37:01 2016 +0530
    
        WL#9499 - Use buffered IO for open state file writes
    
    commit 98f40b10c15e49d9a5e14689cdb34758bdf85a05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 12:36:06 2016 +0530
    
        WL#9499 - Don't complain about corrupted encrypted pages during dblwr recovery
    
    commit c674939cbdeaa4a9996960de0fa4e74954ad6f76
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 09:21:06 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for generated sources too.
    
    commit ff68ba26aeaa27070ceeaa8db4472a9ce4daa3c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 08:33:03 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for fil/fil0fil.cc
    
    commit 445985ca11810c528567a4222cad4a7f0ce49e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 19:44:29 2016 +0530
    
        WL#9499 - Read/Write open state files using absolute paths
    
    commit b4d91d3799d94eb2677be6512752ec27dfa5e0f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 14:37:40 2016 +0530
    
        WL#9499 - Fix doxygen errors
    
    commit 8be2de3b3077c0d0f26340c9c80f7ae2247eefbc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 11:20:24 2016 +0530
    
        WL#9499 - Record test, MLOG_FILE_NAME doesn't exist anymore
    
    commit 54e64dc4a97f5bf4b5606cea1841dfc1f04fe536
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 10:41:01 2016 +0530
    
        WL#9499 - Add protobuf library to the embedded library.
    
    commit 83b0fb38283e285e1e963dd2c7c144d70b130338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 21:17:13 2016 +0530
    
        WL#9499 - Improved DBLWR and System table checks and code cleanup
    
        1. Remove dead code
        2. If some pages from the dblwr buffer were not recovered during recovery
           because of a missing tablespace id -> name mapping. Check the tablespace
           ID against the Tablespaces meta-data after recovery.
        3. Track open of the system tablespace. Check if the name of any file
           has changed. We don't rename the system tablespace.
    
    commit 5ebfba1e083f6a1d2b70946b91a02d32733c7e87
    Merge: 7a1b724c04b 0c27bf6fc44
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Mon Aug 15 11:40:07 2016 +0200
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7a1b724c04bf9d2e4aba0e58fb95dc8fc75d55c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 15:07:47 2016 +0530
    
        WL#9499 - Free deferred page memory
    
    commit 4de5d3b03670e4d2e8ebce89e8b3f104968eb3e1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:45:25 2016 +0530
    
        WL#9499 - Remove unrelated changes
    
    commit c9e83914232480501b139c36ef616798a2ac1d05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:28:19 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 6ecdb21d63ef6dd5a6aff997720178ff6510f0d5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 13 14:31:52 2016 +0530
    
        WL#9499 - Don't exit if no open state files found

[33mcommit 983a6d9445d05a55c172485ac356122bacfdb760[m
Author: Maria Couceiro <maria.couceiro@oracle.com>
Date:   Tue Feb 7 10:12:47 2017 +0000

    WL#7374 Performance schema tables to monitor replication lags and queue
    
    This worklog implements the monitoring of replication lags using the
    replication P_S tables.
    The new monitoring information added consists of the GTID, the original
    and the immediate commit [1;31mtime[mstamps of the transaction that is currently
    being processed (plus the corresponding start processing [1;31mtime[mstamp) and
    of the last to be processed (plus the corresponding start and end
    processing [1;31mtime[mstamps) in each of these three tables:
    - performance_schema.replication_connection status
    - performance_schema.replication_applier_status_by_coordinator
    - performance_schema.replication_applier_status_by_worker
    
    All [1;31mtime[mstamp fields in these three tables have microseconds precision,
    including last_error_[1;31mtime[mstamp and last_heartbeat_[1;31mtime[mstamp.
    The field 'last_seen_transaction' in table
    performance_schema.replication_applier_status_by_worker was replaced by
    'applying_transaction' and 'last_applied_transaction'.

[33mcommit a7e1ef858ee82493dd8ad9a76bc9c22fe3b8c05b[m
Author: Neha Kumari <neha.n.kumari@oracle.com>
Date:   Thu Mar 2 12:30:08 2017 +0530

    WL#9237: Add a new variable binlog_expire_logs_seconds
    
    This worklog adds a system variable binlog_expire_logs_seconds in
    addition to the existing expire_logs_days variable.
    The ultimate requirement is that the user can set expire periods
    smaller than one day by providing another extra variable.
    The new variable binlog_expire_logs_seconds, will be set in those cases
    where the expire period is not a integer multiple of days
    like 1 day 2 hours and 32 minute.
    
    @ sql/binlog.cc
    
      The purge [1;31mtime[m now also considers the value of
      binlog_expire_logs_seconds.
    
    @ sql/mysqld.h
    
      Declared the new variable binlog_expire_logs_seconds
    
    @ sql/mysqld.cc
    
      The purge [1;31mtime[m now also considers the value of
      binlog_expire_logs_seconds.
    
    @ sql/sys_vars.cc
    
      Added the description for binlog_expire_logs_seconds, and
      modified the description for expire_logs_days.
    
    Added test case to test the new variable:
    
    - binlog_expire_logs_seconds: Ensure that when any of the two expire
      variable, expire_logs_days or binlog_expire_logs_seconds is set
      the purge happens on server restart and in cases where a force
      rotation of binlog happens.
    
    Extended the existing test cases:
    - expire_logs_days_basic: Added code to test the system variable
      binlog_expire_logs_seconds.

[33mcommit dbd2ca2f6e14ce0ec19e743eb2f0cfdb20df6573[m
Author: Joao Gramacho <joao.gramacho@oracle.com>
Date:   Tue Nov 1 06:45:39 2016 +0000

    WL#8599: Reduce contention in IO and SQL threads
    
    (Step 1)
    
    This patch introduces the changes for the worklog related to making the
    slave applier to read from the relay log the same way the Binlog_sender
    does from the binary log (using a non-shared IO_CACHE, not relying on
    relay_log->LOCK_log even when reading from the "hot" relay log file).
    
    Made binlog_end_pos atomic
    --------------------------
    
    The MYSQL_BIN_LOG::binlog_end_pos was refactored to be atomic. From the
    Binlog_sender perspective, this would allow reducing the amount of
    acquirements of binary log LOCK_binlog_end_pos. With this change, both
    binary and relay log files readers don't need to acquire the
    LOCK_binlog_end_pos while checking if they reached the end of the "hot"
    log file. They only need to acquire the LOCK_binlog_end_pos if they are
    actually going to wait for updates.
    
    @ sql/binlog.h:
    
    Renamed binlog_end_pos to atomic_binlog_end_pos and made it atomic.
    
      At MYSQL_BIN_LOG::get_binlog_end_pos(), we removed the assertion of
      the ownership of the LOCK_binlog_end_pos, as it is not necessary since
      the binlog_end_pos variable become atomic.
    
    @ sql/rpl_binlog_sender.cc
    
      Refactored Binlog_sender::wait_new_events() to first check if the
      waiting is really needed (if the binary log was not updated before the
      acquirement of LOCK_binlog_end_pos), and then, only if the
      Binlog_sender really need to wait, to enter the
      stage_master_has_sent_all_binlog_to_slave stage and wait for updates
      on the binary log.
    
    Removed the relay_log->LOCK_log usage from next_event()
    -------------------------------------------------------
    
    The slave applier was refactored to not use the relay_log->LOCK_log when
    reading events from the "hot" relay log file.
    
    It was introduced a new PSI mutex key(MYSQL_RELAY_LOG::LOCK_log_end_pos)
    to instrument the LOCK_binlog_end_pos on relay log files.
    
    @ mysql-test/suite/perfschema/r/relaylog.test
    
      The test case had to be recorded again after the addition of the new
      PSI mutex key.
    
    @ sql/mysqld.(cc|.h)
    
    Introduced the new "MYSQL_RELAY_LOG::LOCK_log_end_pos" PSI mutex key.
    
    In order to make the slave applier to not need to acquire
    relay_log->LOCK_log when reading from the "hot" relay log, the slave
    receiver now opens the relay log with the same flags as the binary log
    files are opened: O_WRONLY. This lead to many changes in the slave code.
    
    The rli->ign_master_log_* that relied on relay_log->LOCK_log are now
    being protected by the relay_log->LOCK_binlog_end_pos. This change was
    needed in order to guarantee that the updated generated by events
    ignored by the receiver thread would be properly handled by the applier
    regardless relay_log->LOCK_log.
    
    @ sql/binlog.h
    
      The MYSQL_BIN_LOG::update_binlog_end_pos() function is now also used
      for the relay log. The function was refactored to remove the relay log
      specific code. It also has now a new parameter to tell the function
      that the LOCK_binlog_end_pos was acquired by the caller.
    
      MYSQL_BIN_LOG::after_append_to_relay_log(),
      MYSQL_BIN_LOG::append_event() and MYSQL_BIN_LOG::append_buffer()
      function were renamed to MYSQL_BIN_LOG::after_write_to_relay_log(),
      MYSQL_BIN_LOG::write_event() and MYSQL_BIN_LOG::write_buffer()
      respectively.
    
    @ sql/binlog.cc
    
      At MYSQL_BIN_LOG::open(), there is no distinction about binary or
      relay log with respect to the flags used to open the IO_CACHE.
    
      At MYSQL_BIN_LOG::open_binlog(), replaced a check for the relay log
      that were relying on the io_cache_type to actually check if it is a
      relay log or not.
    
      At MYSQL_BIN_LOG::after_write_to_relay_log(), replaced the function
      used to get the actual file position from my_b_append_tell() to
      my_b_tell(). Also, instead of just signaling the update of the log
      file, this function also cleanup the rli->ign_master_log_name_end.
    
      MYSQL_BIN_LOG::write_event() is now asserting that the log_file.type
      is WRITE_CACHE.
    
      MYSQL_BIN_LOG::write_buffer() is now asserting that the log_file.type
      is WRITE_CACHE. It is also calling my_b_write() to write the buffer
      into the relay log IO_CACHE.
    
      MYSQL_BIN_LOG::wait_for_update_relay_log() was refactored to rely on
      LOCK_binlog_end_pos instead of LOCK_log and was moved to
      sql/rpl_slave.cc as wait_new_relaylog_events().
    
      At MYSQL_BIN_LOG::close, replaced a check for the relay log that were
      relying on the io_cache_type to actually check if it is a relay log or
      not.
    
    @ sql/log_event.cc
    
      Log_event::write_header() now calculates the event
      common_header->log_pos by using my_b_tell() as there is no IO_CACHE
      with SEQ_READ_APPEND type anymore.
    
    @ sql/rpl_rli.h
    
      It was removed the IO_CACHE *cur_log as it is not needed anymore.
    
      It was also removed the cur_log_old_open_count variable.
    
    @ sql/rpl_rli.cc
    
      Relay_log_info::Relay_log_info() now initialize the relay_log using
      the WRITE_CACHE cache type. It was added the initialization of the
      key_RELAYLOG_LOCK_log_end_pos that now is used by the relay log.
    
      It was removed any reference to relay_log->LOCK_log at
      Relay_log_info::init_relay_log_pos() function.
    
    @ sql/rpl_slave.cc
    
      The write_ignored_events_info_to_relay_log() function now relies on
      LOCK_binlog_end_pos instead of LOCK_log.
    
      At queue_event(), there is a rli->relay_log.lock_binlog_end_pos() call
      every [1;31mtime[m the rli->ign_master_log_* variables are going to be
      handled.
    
      It was created the relay_log_space_verification() static function with
      all the code related to relay log space verification that was inside
      the next_event() function.
    
      The major changes in this step were done at the next_event() static
      function. It doesn't use the relay_log->LOCK_log anymore, and rely on
      relay_log->LOCK_binlog_end_pos when reaching the "hot" relay log file
      boundaries. The function now only reads and event from the relay log
      file if the log is not "hot" or if current reading position is less
      than the binlog_end_pos.
    
      Introduced the wait_new_relaylog_events() function.
    
    @ mysql-test/suite/rpl/t/rpl_relay_log_locking(.test|.result)
    
      It was created a test case that relies on debug instrumentation to
      block the receiver thread while queuing an event and ensure that the
      applier thread is capable of reading from the relay log up to the last
      queued event.
    
    Other references
    ----------------
    
    This patch also fixed:
    
    BUG#25321231: TUNING THE LOG_LOCK CONTENTION FOR IO_THREAD AND
                  SQL_THREAD IN RPL_SLAVE.CC
    
    (Step 2)
    
    This patch made channels retrieved_gtid_sets to use their own
    sid_map/sid_lock and created a class to avoid locking when checking the
    current server GTID_MODE to be used Master_info and Binlog_sender.
    
    Gtid_mode_copy class
    --------------------
    
    Any operation needing to check the current server GTID_MODE would
    acquire the global_sid_lock in order to read the GTID_MODE. This is a
    very fast operation (just to access a server global variable), but while
    done by many concurrent threads it might generate impact, mostly on
    commit operations that acquire the global_sid_lock exclusively.
    
    Also, when the server is committing a group of transactions, as the
    global_sid_lock is acquired for writing, any operation trying to check
    the server GTID_MODE will have to be held.
    
    GTID_MODE is a global variable that should not be changed often, but
    the access to it is protected by any of the four locks described at
    enum_gtid_mode_lock.
    
    Every [1;31mtime[m a channel receiver thread connects to a master, every [1;31mtime[m
    a Gtid_log_event or an Anonymous_gtid_log_event is queued by a receiver
    thread, or is going to be sent by the Binlog_sender to a receiver, there
    must be checked if the current GTID_MODE is compatible with the
    operation.
    
    There are some places where the verification is performed while
    already holding one of the above mentioned locks, but there are other
    places that rely on no specific lock and, in this case, will rely on the
    global_sid_lock, blocking any other GTID operation relying on the
    global_sid_map for writing (like a group of transactions being
    committed).
    
    In order to avoid acquiring lock to check a variable that is not
    changed often, we introduced a global (atomic) counter of how many [1;31mtime[ms
    the GTID_MODE was changed since the server startup.
    
    The Gtid_mode_copy class was implemented to hold a copy of the last
    GTID_MODE to be returned without the need of acquiring locks if the
    local GTID mode counter has the same value as the global atomic counter.
    
    @ sql/mysqld.cc
    
      Introduced the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/rpl_gtid_misc.cc
    
      Declared the global atomic _gtid_mode_counter.
    
    @ sql/rpl_gtid.h
    
      Declared the external atomic _gtid_mode_counter.
    
      Defined DEFAULT_GTID_MODE as GTID_MODE_OFF.
    
      Introduced the Gtid_mode_copy class.
    
    @ sql/rpl_binlog_sender.h
    
      Inherited from Gtid_mode_copy to the Binlog_sender class.
    
    @ sql/rpl_binlog_sender.cc
    
      Replaced the calls to get_gtid_mode() by get_gtid_mode_from_copy().
    
    @ sql/rpl_slave.cc
    
      At recover_relay_log(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At init_recovery(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At start_slave_threads(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At get_master_version_and_clock(), replaced the call to
      get_gtid_mode() by get_gtid_mode_from_copy().
    
      At queue_event(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
    @ sql/sys_vars.cc
    
      Incremented the _gtid_mode_counter when GTID_MODE is changed. Also,
      made the GTID_MODE global variable to have DEFAULT_GTID_MODE as its
      default value.
    
    Retrieve_gtid_sets with their own SID maps/SID locks
    ----------------------------------------------------
    
    Any GTID set operation relying on a given SID map (and its respective
    lock) will be blocked by any other operation (in any other GTID set)
    holding the SID lock for writing.
    
    All server GTID state sets (lost_gtids, executed_gtids,
    gtids_only_in_table, previous_gtids_logged and owned_gtids) rely on the
    global SID map (and on the global SID lock). So, when GTIDs are
    committed in the server, the updates on the GTID state lock the SID map
    for writing to prevent other threads to perform updates on the GTID
    state (or read from it while it is being updated). The side effect of
    this way of avoiding other threads to read from or update a GTID set is
    blocking any other GTID activity in other GTID sets relying on the same
    SID map/SID lock. So, before this patch, the replication receiver
    threads had their Retrieved_Gtid_Set relying on the global SID map/lock.
    In this way, when a group commit was updating the GTIDs of the committed
    transactions, any replication receiver trying to queue a Gtid_log_event
    or finishing queuing a Gtid transaction had to wait for the group commit
    to unlock the global SID lock. Also, a group commit trying to lock the
    global SID lock for writing was waiting to all receiver threads queuing
    GTIDs to finish before having being granted with the lock ownership.
    
    The global SID lock on the cases described above is taken for doing
    small operations, and there is no significant impact on server
    performance in a slave server replicating using a single replication
    channel with medium to large transactions and without using MTS. But
    when the slave is scaled to have many replication channels and/or
    replicating many small transactions and using MTS, the impact of the
    concurrency in the global SID lock becomes noticeable.
    
    This patch is making all receiver threads to rely on their own
    (individual) SID maps and locks.
    
    @ sql/binlog.cc
    
      The MYSQL_BIN_LOG::init_gtid_sets() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      The MYSQL_BIN_LOG::open_binlog() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      The MYSQL_BIN_LOG::reset_logs() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      MYSQL_BIN_LOG::after_write_to_relay_log() now uses only the relay log
      sid_lock.
    
    @ sql/log_event.cc
    
      Previous_log_event should assert that the SID map of the GTID set
      passed as parameter is locked (is it not the global_sid_lock for relay
      log events).
    
    @ sql/mysqld.h
    
      Declared the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/mysqld.cc
    
      At gtid_server_init(), initialized the global _gtid_mode_counter.
    
      Introduced the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/rpl_channel_service_interface.cc
    
      The channel_get_last_delivered_gno() function now uses the relay log
      sid_lock.
    
      The channel_wait_until_apply_queue_applied() was refactored to avoid
      blocking both the relay log sid_lock and the global_sid_lock while
      waiting for the condition.
    
    @ sql/rpl_gtid.h
    
      Enabled the declaration of Sid_map::clear() regardless of compiler
      directives.
    
      Declared a new static function Sid_map::get_new_sid_map() to
      retrieve a new empty SID map with its own SID lock.
    
      Declared the Gtid_set::clear_set_and_sid_map() function that takes
      care of cleaning the SID map after cleaning the GTID set.
    
    @ sql/rpl_gtid_set.cc
    
      Introduced the Gtid_set::clear_set_and_sid_map() function that takes
      care of cleaning the SID map after cleaning the GTID set.
    
    @ sql/rpl_gtid_sid_map.cc
    
      Removed the compiler directives preventing the compilation of
      Sid_map::clear().
    
    @ sql/rpl_rli.h
    
      Made the (retrieved) gtid_set a pointer.
    
      Added function to get the GTID set SID map (get_sid_map()) and SID
      lock (get_sid_lock()).
    
      Changed add_logged_gtid() function to use the relay log SID map and
      lock.
    
      Declared a new wait_for_gtid_set() function receiving a char*
      parameter instead of a String*.
    
    @ sql/rpl_rli.cc
    
      Refactored the gtid_set initialization on Relay_log_info constructor
      and cleaned up the GTID set, SID map and lock on destructor.
    
      Introduced the new wait_for_gtid_set() function receiving a char*
      parameter instead of a String* and refactored the wait_for_gtid_set()
      that receives a String* to call the new introduced one.
    
      Added some assertions at Relay_log_info::wait_for_gtid_set() to ensure
      that the GTID set to wait is relying on global_sid_map or has no SID
      map.
    
      Relay_log_info::purge_relay_logs() now uses the relay log SID lock and
      also clears the relay log SID map when cleaning the retrieved GTID
      set.
    
      Relay_log_info::rli_init_info now uses the relay log SID lock.
    
      Relay_log_info::add_gtid_set() now uses the relay log SID lock.
    
    @ sql/rpl_slave.cc
    
      The recover_relay_log() function now uses the relay log SID lock and
      also clears the relay log SID map when cleaning the retrieved GTID
      set.
    
      The show_slave_status() functions were refactored to use the relay log
      SID lock when dealing with the retrieved GTID sets.
    
      The request_dump() function now uses the relay log SID lock when
      dealing with the retrieved GTID set.
    
      The queue_event() function now uses the relay log SID lock when
      dealing with GTIDs of received Gtid_log_events.
    
    @ storage/perfschema/table_replication_connection_status.cc
    
      The table_replication_connection_status::make_row() function was
      refactored to use the relay log SID lock when dealing with the
      retrieved GTID sets.
    
    (Step 3)
    
    This patch moved the call to flush_master_info() that was done by the
    I/O thread after a successful call to queue_event() to inside the
    queue_event() function, in order to take a ride in the already locked
    mi->data_lock and relay_log->LOCK_log.
    
    This will avoid acquiring the above mentioned locks twice for every
    successful event queued.
    
    It also added a new parameter to flush_master_info() to opt the flush of
    the relay log. Previous approach was leading to flush the relay log
    twice per event.
    
    @ sql/rpl_channel_service_interface.cc
    
      Specified the new queue_event() parameter to not flush master info
      after queuing the event.
    
    @ sql/rpl_slave.h
    
      Changes flush_master_info() declaration by adding a new parameter
      telling the function if it needs to acquire the required locks or if
      the locks are already acquired and a new parameter telling the
      function if it needs to flush the relay log.
    
      Declared QUEUE_EVENT_RESULT enum with the possible results of the
      queue_event() function.
    
      Changes queue_event() declaration to return QUEUE_EVENT_RESULT and
      also to support a new parameter telling the function to also flush
      master info on after an event be successfully queued.
    
    @ sql/rpl_slave.cc
    
      The flush_master_info() function was changed to not acquire the
      relay_log->LOCK_log always, but rely on the need_lock parameter to do
      so. It was also changed to only flush the relay log based on the new
      flush_relay_log parameter. This will prevent flushing the relay log
      twice when queuing events.
    
      On handle_slave_io(), refactored the calls to queue_event() and
      flush_master_info() to use the new implemented parameters.
    
      Refactored queue_event() function to return QUEUE_EVENT_RESULT, and to
      flush master info without the need of flushing the relay log in the
      case of a successful event be queued.
    
    Added test cases to improve code coverage:
    
    - rpl_write_ignored_events: ensure the ignored events not yet consumed
      by the slave are taken into account by the SQL thread if the I/O
      thread is stopped before the SQL thread consumed the ignored events
      info.
    
    - rpl_write_ignored_events_fail_writing_rotate: ensure I/O behavior
      when failures happen while writing the ignored events info to the
      relay log.
    
    Also commented an unreachable code to make gcov happy.
    
    Added test cases to verify that receiver threads GTID sets do not rely on
    global SID anymore.
    
    rpl_multi_source_block_receiver: checks that receiver thread receiving GTIDs
    (and adding them to its retrieved GTID set) can apply GTIDs from a server UUID
    that doesn't belong to the global SID map yet.
    
    rpl_line_topology_receiver_block: checks that receiver thread on slave
    receiving GTIDs (and adding them to its retrieved GTID set) can have other
    servers replicating from it.

[33mcommit 02336705f41385ca05666211fa83cb35a7df8491[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Wed Mar 1 12:08:21 2017 +0100

    Bug#24666169: I_S.TABLE_CONSTRAINTS.CONSTRAINT_NAME IS NOT UPDATED
                  AFTER RENAME TABLE
    
    Bug#25339192: NEWDD: SERVER SHOULD DISALLOW FOREIGN KEYS ON BASE
                  COLUMN OF STORED COLUMN
    
    This patch consists of three parts:
    
    1) When tables are renamed, any foreign keys with generated
    names are renamed as well. This is necessary since the table
    name is part of the generated name. We assume that the name
    was generated if it starts with table_name + '_ibfk_', similar
    to how InnoDB does it in earlier versions.
    This part fixes Bug#24666169.
    
    2) During ALTER TABLE, both the new and the old table definition
    exists in the data dictionary at the same [1;31mtime[m (uncommitted).
    In order to satisfy the unique constraint on schema_name+fk_name,
    pre-existing FKs were before not transferred to the new table
    definition until ALTER TABLE was almost completed. This meant
    that FK metadata was not available to InnoDB during ALTER TABLE
    processing. In order to make it available to InnoDB, foreign keys
    are now transferred to the new table definintion immediately,
    but with a temporary name to satisfy the unique constraint.
    The original name is restored at the end of ALTER TABLE.
    This part is required to fix Bug#25339192.
    
    3) As a consequence of 2), more validity checking of pre-existing
    foreign keys had been added to the SQL layer to avoid regressions
    in error reporting. This consists of checking and reporting
    ER_FK_DUP_NAME, ER_DROP_INDEX_FK and ER_FK_COLUMN_CANNOT_DROP.

[33mcommit ed104c73011d1598a7d69e1e2c1227bb3ce77ea6[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Tue Feb 28 20:40:48 2017 +0530

    Bug#25583588 : `M_PREBUILT->TABLE->N_REF_COUNT > 0' AT
                    HA_INNOBASE::UPDATE_THD IN HANDLER
    
    Post push patch:
    
    After pushing fix for bug#25583588, server does not show hidden tables
    even with the I_S implementation that uses ST_SCHEMA_TABLE interface.
    This affects the test case added by Bug#22285643, which uses
    I_S.PARTITIONS to check if there exists a hidden table. This leads
    to the [1;31mtime[mout of the test.
    
    Remove the test case and debug points introduced in the code
    for this test.

[33mcommit 0bbe8f73f9ea9cb2966dc7f1fbc0a15281eeb4b9[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Tue Feb 28 10:48:45 2017 +0100

    Squashed commit of the following:
    
    WL#9499 - InnoDB: Replace MLOG_FILE_NAME with MLOG_FILE_OPEN
    
    Fix the performance issues introduced by WL#7142 and its followup WL#7806.
    
    1. Revert WL#7142 and WL#7806 changes, keep some of the tests to test
       the behaviour that was introduced by the two WLs
    2. Change the tests that rely on the above two WLs behaviour
    3. Use std::unordered_map instead of the homebrew hash table for the recovery
       code and space ID to name mapping
    4. Split the redo log hash table key from <space, page> -> apply records to
       <space> -> apply records
    5. Addition of two new system files (tablespaces.open.1 and tablespaces.open.2)
    
     - Rename MLOG_FILE_NAME to MLOG_FILE_OPEN
     - Remove the two pass recovery code, make it a single pass
     - Track file open, close and rename
     - Write and fsync the tracking state to disk on checkpoint and rename.
       Uses the files in #5 in a round robin fashion
    
    Introduce --innodb-scan-directories="path1;...pathN". Scan the paths for
    .ibd files to open during recovery. This option can be used if the files in #5
    above are corrupt or missing. You should not use this if you move files around.
    While they can be recovered the data dictionary will not be updated and it
    will cause issues during runtimg.
    
    rb#13686 Approved by Satya and Shaohua
    
    commit fbf87161f3c93979e5abe424fbe0678fdc32159e
    Merge: 517cf3a7bf0 c2b504664ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:39:32 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 517cf3a7bf0490c3168fed020e3096ec500e0a85
    Merge: 4786f93ad8a 5e974fd0ea4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:24:25 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Additional change is to call recv_recovery_from_checkpoint_finish() on abort.
        Instead of recv_sys_free().
    
    commit 4786f93ad8a25506a2a1f6e9d1207256a34b3665
    Merge: 5dc35e05b5f 275245cce32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:43:27 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 5dc35e05b5f2da95c36e191350e9c7087be72194
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:42:40 2017 +0100
    
        WL#9499 Free recv resources on abort
    
    commit bed693070395923ededba736f1c7102b8eb21e95
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 18:34:50 2017 +0100
    
        WL#9499 - Test cannot be run with Valgrind
    
    commit c5d423228ddf58b17866ff8be289dba4a19205d2
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:30:39 2017 +0100
    
        WL#9499 - Remove const
    
    commit ac42498506b4dffb22e74282d0ce037fe3acf977
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:00:30 2017 +0100
    
        WL#9499 - Clean up code
    
    commit bc48077cab9c3ccb1b2797c365fe0940c269a785
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 16:01:09 2017 +0100
    
        WL#9499 - Revert unrelated change
    
    commit 8b2bb0f6d6254b3cfde168d41356400009db12f4
    Merge: eb9b294ba78 153a79ff35d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:43:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit eb9b294ba786800f9e397cd87f01c4f4976edddb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:29:56 2017 +0100
    
        WL#9499 - Remove debug message
    
    commit abae66ad591854ee67a5013f3209be2f82e4d9bf
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 17:04:10 2017 +0100
    
        WL#9499 - Test only works in debug mode.
    
    commit 71ebea70391ef295bed49ee06a8b872f15ecfe97
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:18:08 2017 +0100
    
        WL#9499 - Update to mtr test from Matthias
    
    commit f108a5b92fc476c70c49e4937496b32d9d5d031f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:13:04 2017 +0100
    
        WL#9499 - Increment redo log version number
    
    commit 4439c83a4d3edd6e511706ccf9936770ed29e593
    Merge: fa459186b90 05923bef41d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 09:54:18 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit fa459186b90d7a5ddcba7e3c6c7a9871d0dce793
    Merge: 14ac4f81d84 b401f17e70d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 20:02:40 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 14ac4f81d84bec23a7be210504ca0be93619bf11
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 16:44:57 2017 +0100
    
        WL#9499 - Update from Matthias
    
    commit ed3191a9fc951151fd7d758a527e7ab81530b3f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:16:11 2017 +0100
    
        WL#9499 - Revert change pushed by nmistake
    
    commit 8c0edb998867bf557f6c86410552d6d123892000
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:11:21 2017 +0100
    
        WL#9499 - Don't redo log MLOG_FILE_OPEN until startup is complete
    
    Date:   Wed Feb 22 09:54:18 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit fa459186b90d7a5ddcba7e3c6c7a9871d0dce793
    Merge: 14ac4f81d84 b401f17e70d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 20:02:40 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 14ac4f81d84bec23a7be210504ca0be93619bf11
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 16:44:57 2017 +0100
    
        WL#9499 - Update from Matthias
    
    commit ed3191a9fc951151fd7d758a527e7ab81530b3f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:16:11 2017 +0100
    
        WL#9499 - Revert change pushed by nmistake
    
    commit 8c0edb998867bf557f6c86410552d6d123892000
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:11:21 2017 +0100
    
        WL#9499 - Don't redo log MLOG_FILE_OPEN until startup is complete
    
    commit 3b503ea1d3f89c0f7e3677d3b56f249c7ebff506
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:37:04 2017 +0100
    
        WL#9499 - Add tests
    
    commit 47af7bd6eec10eac55633d7c4cf54afe607f3649
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:00:30 2017 +0100
    
        WL#9499 - Fix compile problem
    
    commit a8b9a8c6ccb15e2be5ce5db5fa0bce24b86d2c87
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:51:05 2017 +0100
    
        WL#9499 Remove dead code
    
    commit b1dba474486ad10b61029b2ef4e6a91ea67dcea8
    Merge: 3cf9e9eb3e8 a4271026201
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:49:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 3cf9e9eb3e86e4c8f4d44cb79d3f7c456ea7d671
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 18 07:53:43 2017 +0530
    
        WL#9499 - Remove suggestion to use force recovery
    
        --innodb-scan-directories is a safer option for the user. Force recovery should
        be the absolute last resort.
    
    commit 4104c4bfd606270650aac95a9a724e106fe835c5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 09:00:47 2017 +0530
    
        WL#9499 - Fix error message
    
        User can try --innodb-scan-directories="..." if the tablespaces.open.* files
        are corrupt or unreadable.
    
    commit 19ab12e54923b070a0b4ffc76b9fe97ac54ad3cc
    Merge: 50b3a95e446 f0f51c410bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 05:22:57 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Replace readdir_r() with readdir(), compiler complains that readdir_r() is
        deprecated and recommends replacing it with readdir().
    
    commit 50b3a95e446b91853fc35716b63bdc173221d01f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:55:33 2017 +0530
    
        WL#9499 - Fix test
    
    commit 45d202ae0fa35aa3aced55cc1933aeefa33837de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:32:56 2017 +0530
    
        WL#9499 - Remove redundant test
    
    commit 48fe691b97735e5144e9d439a0adbf721b2dc554
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:18:11 2017 +0530
    
        WL#9499 - Add DEBUG sync points
    
    commit d986f4e04a9eb6c2c76d61cd4afe9541d77b34bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:03:50 2017 +0530
    
        WL#9499 - Remove PB2 control file
    
    commit 5af7dca9c305bd366ad2b5c3de26a870e913af4a
    Merge: 74022f50a5f 23a0e71aa3d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 15 09:05:05 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 74022f50a5ff7cb2801c0712601f8a467b409a28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 14 10:31:00 2017 +0530
    
        WL#9499 - Fix test
    
    commit f6188175ee62040ac6a844a5c54787839dff6155
    Merge: 24c867aab14 19ca7c6a5d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 13 12:37:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 24c867aab14556188503aac495f60d89ba3d26ec
    Merge: cb64b8c7f9f a4de6ab549e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 4 06:41:23 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cb64b8c7f9fa9ca05033a9d6f6193cf141746310
    Merge: 17c6c41da0a 88dbc4f4511
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:48:12 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 17c6c41da0afe3fc78843b75fa02578dab29a0ca
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:46:34 2017 +0530
    
        WL#9499 - Add a test for scan directories.
    
        The use case is where the location of the files is not changed but the
        tablespaces.open.* files are missing.
    
    commit 79cc52f1bd82dc65932eacbc9aa14a47e4196572
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 18:01:50 2017 +0530
    
        WL#9499 - If open fails space will be null.
    
    commit 22ea5f31ecc1fa0db8abd57d4a46578e5f891c9a
    Merge: f5b69930f95 853a52cf5a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 12:14:41 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f5b69930f95192ddfdb3ca170024a5c7e3416076
    Merge: 40a4c32f2c4 b18872ed4a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 2 13:54:24 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 40a4c32f2c42b584539a14cbc1ba0d4f0fe7d3c9
    Merge: b1d1923d37c d071c0e7a0b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 1 13:48:33 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit b1d1923d37c3d23a9f701a61b458b7e4cbd3c90c
    Merge: 2fc6c51edab 4ae71705a01
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 31 10:44:59 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2fc6c51edabc3de4537eceb0b82cd62063ada3a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 16:36:46 2017 +0530
    
        WL#9499 - Empty the tablespace.open.* files on normal shutdown.
    
    commit 738acb7d554f97455c8dba512282c7c2e6ba9f3a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:47:21 2017 +0530
    
        WL#9499 - Fix formatting
    
    commit 28f8579a6f729af354e0c50098d16fbfa17cc253
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:25:30 2017 +0530
    
        WL#9499 - Bug fix
    
        The DELETED state was set on a copy of the data structure
    
    commit dd5bf8ea81b7023fa1980c01d89219a690160b04
    Merge: 7eeab0a994d 9c7808e1054
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 21:14:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7eeab0a994db4cf0c2e080f27ff916c778ec65f8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:50:59 2017 +0530
    
        WL#9499 - Add tests.
    
    commit ddfaf047f43587ee807599b0b80b6d01a3579e8c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:48:06 2017 +0530
    
        WL#9499 - Create tablespace bug fix
    
        If there is a checkpoint after the create tablespace is logged and the
        server crashes after writing the page initialization to the redo log. Then
        we neither have the mapping in the redo log nor in the tablespace.open.*
        files. We must update the tablespace mapping before writing the CREATE
        redo log entry so that the state is written out to disk on checkpoint.
    
    commit 29546d3ebea2991e5b86b33edddb551c924bf1db
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 17:55:28 2017 +0530
    
        WL#9499 - Remove dead code from WL#7142
    
    commit eced7a3e4437ee4bb24a12290f561437ddb15611
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 14:51:09 2017 +0530
    
        WL#9499 - Use the tablespace.open.* files in a round robin fashion.
    
    commit d8eff788eea1ad5e6c7786b9d64963524f2b2c81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:56:12 2017 +0530
    
        WL#9499 - Fix duplicate entry
    
    commit 1d04e0cf0308c35ee7498e6919eab9a11c699d52
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:55:30 2017 +0530
    
        WL#9499 - Revert last push
    
    commit 8361d3c39366d6435a895d5b64dd23615d26fc28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Jan 26 09:05:52 2017 +0530
    
        WL#9499 - Write to the tablespace.open.* files in a round robin manner.
    
    commit 3eaba629ee5b5c26a5f4e80852fee2d446f3013f
    Merge: 6642c43d735 bdc49070128
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 25 14:03:15 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6642c43d7353063a455972ab2cbc21220c16be43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 08:34:35 2017 +0530
    
        WL#9499 - Rename fil_ibd_load to fil_ibd_open_for_recovery.
    
    commit fdd1897c79b29c9e0a69c1f81d94927da06d9424
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:28:49 2017 +0530
    
        WL#9499 - Enforce const semantics on Windows for Folder::exists().
    
    commit 9394f4653e10cc5d4ab9b7b0a0b9331fd2666f49
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:08:26 2017 +0530
    
        WL#9499 - Include <array>
    
    commit c1903d28800ae0f7af69552aa669622d552346b4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Jan 21 07:49:28 2017 +0530
    
        WL#9499 - Improve scan directory handling
    
        1. Convert relative paths to absolute paths
        2. Filter out duplicates
        3. Check directories at filtering stage
    
    commit dfea237f4bef914de4067153cbf382240112c4f4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 11:11:05 2017 +0530
    
        WL#9499 - Code clean up
    
    commit c4d51bfdf1c786b1c584c0af1bde080a4f37cc5b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 07:37:06 2017 +0530
    
        WL#9499 - Update the open/rename LSN when a file is opened or renamed.
    
        Minor code cleanup.
        Add diagnostic code for debugging.
    
    commit 5e1d159b571fe6dbfe13c627a245155b82c4bbfa
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 18 10:59:54 2017 +0530
    
        WL#9499 - Filter out '*' from innodb-scan-directories
    
    commit 361f2944f1940f11dfb16dec3589d68335f5e2d8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 21:01:06 2017 +0530
    
        WL#9499 - Code cleanup
    
    commit 288d70b356721887423ca3d2d72b42da331216cd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 13:08:08 2017 +0530
    
        WL#9499 - Sync open file map to disk before checkpoint.
    
    commit 3c602d1b4089cd262200650f4b33986fc9e26531
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:18:46 2017 +0530
    
        WL#9499 - Print expected bytes instead of generic message.
    
    commit f52e0985b8cbef3891385179d35dc8c7f567146a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:07:47 2017 +0530
    
        WL#9499 - Print file size instead of generic message.
    
    commit b27b1b4b4b70e286e2c669f997b0a669f6d6034c
    Merge: bbdd1c46f1e c101ec9b557
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 16 13:19:42 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit bbdd1c46f1ef08d956ea249e1f6f4bc93d3464f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Dec 10 14:41:12 2016 +0530
    
        WL#9499 - Handle the case where the rename has already been done on recovery.
    
    commit 141bdb02b1a402e786db5d8b165b781a5d7370a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 11:59:29 2016 +0530
    
        WL#9499 - Instrumentation for debugging
    
    commit 34815bb24a1c296d9739e7602dc6ccd53c58c44c
    Merge: 41ca3732a6f 13a46b4c5ea
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 09:44:03 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 41ca3732a6ffd8dfa16762a05df6b5c6b4b550c1
    Merge: 7137edb2d2c aba34f1205d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 11:10:08 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7137edb2d2ca60cdec44600ddf3f5cbde424e7a4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 05:56:06 2016 +0530
    
        WL#9499 - Remove unused code. Move id to name mapping sync before log flush.
    
    commit 2a50067e2da2f7819781de6550e55ca14995c7ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:57:41 2016 +0530
    
        WL#9499 - Initialize the PFS file handle
    
    commit d478d3492cdb40ec02fda9c043bf29b87bae11ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:05:52 2016 +0530
    
        WL#9499 - Fix whitespace
    
    commit 061af748a5e2fde6c1577ccdabfc8a89a9f753de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:02:25 2016 +0530
    
        WL#9499 - Set must flush on file close/delete.
    
    commit ad76e2b9c7ff757f60c66821e86696d5ab757b18
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 11:43:00 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5a95946d4567dc13cf5a12d6bcdb28b19a02b5bc
    Merge: 1a0f373eb7f da23d6b8e44
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 09:27:45 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1a0f373eb7f03dc22264f91f3f6ed1fd13825de7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 13:01:41 2016 +0530
    
        WL#9499 - Readd test result file back
    
    commit 00afde093183cf850f735940245af111dce82b72
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 12:59:49 2016 +0530
    
        WL#9499 - Don't purge the files based on LWM. It won't work.
    
        We need to also ensure that there aren't any pages in the buffer pool that
        belong to a tablespace that is closed. Redo log records can be written for
        such pages.
    
    commit 3199fe255103daa42f0332b7ff9d565eefff7429
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:41:39 2016 +0530
    
        WL#9499 - Fix typo
    
    commit 351cb6c42709405a79021276f310d7b996aadd1b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:32:02 2016 +0530
    
        WL#9499 - Remove unused function
    
    commit 61cc7f6b06c5280d58217b76d7627013ddcd8338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:22:31 2016 +0530
    
        WL#9499 - Reduce the compression level.
    
    commit 48142e360ff5cfb53d5e416f3d6b92e956237923
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:21:51 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 4de4f8b31ebdff31a2f7a97a1ad211770d20cdd6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 14:07:07 2016 +0530
    
        WL#9499 - Revert ef30f0754ab22e614ac22712c348ec5f53e0f09c
    
    commit c2f77f44c43c209fad86bba568aa521a2dcbf718
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 12:20:37 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 5fccb51769a13cb9a1fc0f29a832d3b0085ad52a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:30:18 2016 +0530
    
        WL#9499 - Print a message when checkpoint is disabled.
    
    commit ef30f0754ab22e614ac22712c348ec5f53e0f09c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:17:27 2016 +0530
    
        WL#9499 - Print progress in 10% units.
    
    commit bc0ded332624fa2c8a08ebfc955a03f1a24e069c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 08:13:54 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 68ce0208cc073452f5f791faf304971dbac7194a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:38:03 2016 +0530
    
        WL#9499 - Scan directories after the mutex code is initialized.
    
    commit 21e07c8fd6b8eddf158fb79980443f6c9f6d238e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:12:23 2016 +0530
    
        WL#9499 - Introduce --innodb-checkpoint-disabled (debug)
    
        Disable checkpointing if the variable is set. This is to force recovery if the
        server is killed during a test.
    
    commit 7033c9bb5ff7641764f70823a73d747b497a0eed
    Merge: 11a6e582417 c6af7f512b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 04:00:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 11a6e582417d45a80a7f19233c2d2191a17936eb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 03:59:05 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 0a38252e65d607b59b1e9f64d0c8003cdecfecfd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 25 05:56:42 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bcf650cc92b8636f3768dcc3deb33b90b2942134
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 08:46:07 2016 +0530
    
        WL#9499 - Change the open files number back to 2.
    
    commit 99960af2825529fb45d021a34ba6c072e8caa0dc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 07:13:58 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bdb91bc0ba03e01661c50c7175d3fd123d2bcd69
    Merge: 61f3e4a5663 a545bdd6e31
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:04:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 61f3e4a5663c375cd44ee766b263281ff7f0601b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:00:20 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 072ab837d0acb4d2ed817110598554acc44ec344
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 12:06:53 2016 +0530
    
        WL#9499 - Set the IMPORT page LSN to the flushed to disk LSN
    
    commit 7f18661432f3645eb9ce76680c62508ced115fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 11:28:47 2016 +0530
    
        WL#9499 - Force a checkpoint before the crash
    
    commit 83671e9c37fa61adfa5546cabe1463a91ff02241
    Merge: cc26d5ae16e d1f811eb6e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 10:52:16 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cc26d5ae16e8d723a2519f38bfbc084c13a766c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 18:40:51 2016 +0530
    
        WL#9499 - Fix latch ordering issue
    
        Cannot hold the log sys mutex when updating the checkpoint LSN for the open
        files in fil0fil.cc.
    
    commit 4474509addfbdf91b9f0ad890a971299c594e738
    Merge: 396755e195c 0856b10cde5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 08:00:05 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 396755e195c1c8d3b2485a58175dcf56ca2cbf3f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:58:05 2016 +0530
    
        WL#9499 - Remove newline added earlier
    
    commit ab5e60ba491e52f1529c22551a936d771b8b5ef9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:57:21 2016 +0530
    
        WL#9499 - Revert a change that was added by mistake.
    
    commit 38688417713e5ef8cbb65032fa0a547ab0c25c15
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 20:44:50 2016 +0530
    
        WL#9499 - Bug fix, using an invalidated iterator.
    
    commit 4082d44f6dc4a5605562e37ccad9ac4db69344c6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 11:30:49 2016 +0530
    
        WL#9499 - Fix doxygen comment
    
    commit d5ca99e14c010a5349aea6c8cc39493b2073b9c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 15:30:12 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a25f3af10ea2893c634dc961d6f2af05efa103ec
    Merge: c8c2a7eba4c aa039b73223
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:52:51 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit c8c2a7eba4cac29ff431588daf2d6def0c0ee5a6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:39:32 2016 +0530
    
        WL#9499 - Fix problem with open files acrosss checkpoints.
    
        The problem is that we write the open file state before writing the checkpoint.
        Before this change the closed files were purged from the open state map and
        the state written to disk. The problem is that the state and mapping of a file
        opened before the last checkpoint but closed just before we write the state
        will not be in the mapping on disk. One solution is to check older files and
        retrieve the mapping from there. The solution chosen is to avoid purging
        files based on open LSN. If the file was opened before the last checkpoint
        and closed within the current checkpoint we note the state as CLOSED but
        write the mapping to disk. It will be purged at the next checkpoint, if it is
        not opened again in the mean[1;31mtime[m.
    
        Previously an attempt was made to open all files straight after reading the
        mapping from disk. With this change only the state is loaded into memory the
        files are opened on demand. Added a check to verify that the tablespace ID
        from the first page matches the expected value.
    
        Fixed tests to use this new tablespace ID verification.
    
    commit 5dc929e54b1c259f0f8104739ae1f88e9b860f73
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 12:24:40 2016 +0530
    
        WL#9499 - Remove unused code
    
    commit 528b95d70dcc05a69a98ee2a76fdfb8dae1e82fe
    Merge: d9861c40964 75f05cba753
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:14:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d9861c40964ad8fd45ee2cbbd9d94946110e8a9a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 3007ea5af68f40b85bc93098d8385ac96bcbd660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 9592996d2f17c9005262faa75dc1ade9dedbd511
    Merge: da512d5591b ac925fc91f6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Oct 19 10:34:48 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit da512d5591b3379b793d6155089e90791fe94c61
    Merge: f42e2ddd7d5 e635dfe28c0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 30 05:20:10 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f42e2ddd7d50aacae679babe71643af379b5c492
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 15:05:28 2016 +0530
    
        WL#9499 - Fix assertion, the values can be ORred.
    
    commit 94cd08960bc3801acefd4b4ff4ddb4a3e7d7e81a
    Merge: 32a68f91330 59af373321b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 11:05:21 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 32a68f9133011871bfdaba3c742f6239e0a53061
    Merge: 7857f38ebce 15555ae2165
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 21 11:23:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7857f38ebce747135e055bc8a232b649f1aad351
    Merge: 427491f63f1 b43bf88cf80
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 19 11:43:17 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 427491f63f107247c36796e66f6224d20968f104
    Merge: e7fa4c53dcf 23343687722
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 14 22:40:47 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e7fa4c53dcf01ea0e101bd8aa817698492995034
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 19:22:00 2016 +0530
    
        WL#9499 - max_lsn should work with any number of tablespace open files.
    
    commit 09775960da43d36ca64504c1298b9adff3056575
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 17:47:29 2016 +0530
    
        WL#9499 - Fix Names hash bug.
    
    commit 8430c5b34d23cb1774597707fe583dfac93fb3a8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 09:49:47 2016 +0530
    
        WL#9499 - Use std::unordered_map for name to fil_space_t* hash.
    
    commit 5e8275caf9d50dc9ba2f2dadd3b8c0fdeb9c79b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Sep 10 07:55:42 2016 +0530
    
        WL#9499 - Reduce an extra fil_sys_t::mutex call by consolidating flush request.
    
    commit b29fd1039cf0022cff36a2a2311f464f1f6dbcc5
    Merge: 6235ee4902a a150caebee6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 9 20:44:56 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6235ee4902addd1a041b33469988bb1ea870dc7a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 10:58:00 2016 +0530
    
        WL#9499 - Add debug crash points.
    
    commit bf71fbc72b3570f55c8f01dd1a440e9eff761cb6
    Merge: ce6d2246a94 d25f38e38d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 09:47:37 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit ce6d2246a94801041da0bfece74b5ffdd9e8f796
    Merge: 69adae163de f28c4b9a41e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 7 11:20:50 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 69adae163de295ef0e910752cf5f8c96b1c1114f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:33:29 2016 +0530
    
        WL#9499 - Ensure that the MLOG_FILE_OPEN is always written first to the redo
    
    commit 20d5b1ebe6c899e2a0a1d135ad4303490516ce26
    Merge: 2d7d25c145f 4f1fb936211
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:17:58 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2d7d25c145fae59af744e91fce47fe009c869dad
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 10:06:56 2016 +0530
    
        WL#9499 - Add PFS instrumentation for the tablespace open file.
    
    commit 4e14a53ad129c1adcb0a3330931878a9f24c15cc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:53:57 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a465361e74136662471d2b9c0f307799efbe7269
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:17:43 2016 +0530
    
        WL#9499 - Move the file write code to a separate method.
    
    commit 7a26ba28bf7bf94808c47cfcdb6210c4abde2587
    Merge: f49914e5e61 ed389829067
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 07:55:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f49914e5e61b846c45f7b177308cd891918619e4
    Merge: a4fab040243 16fd507b84a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 31 11:23:42 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit a4fab040243a57fb8ef55f91812604352d8b92c8
    Merge: 93019973329 dfee02dc4f5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 10:42:20 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 9301997332923921b93de4946c4824164723050c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 09:09:05 2016 +0530
    
        WL#9499 - OSX/Solaris compilers don't like the code.
    
    commit 54afa110837a054de24ccda84ddbb4ef2d0b96a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 22:55:19 2016 +0530
    
        WL#9499 - During recovery PFS instrumentation can't be accessed by the user.
    
    commit fa5c11e8cf0fbcd1852535faa74b1a04200df2e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:15:07 2016 +0530
    
        WL#9499 - Fil_Open::purge() can be called during recovery too
    
    commit d8672a978d62db42f1a12ba152693a3c0d244d83
    Merge: d4251d0ed6f 14d2a977ce8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:10:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d4251d0ed6f9df5a3acbf97ce7ba8074f126044c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:07:14 2016 +0530
    
        WL#9499 - Remove a WL#7806 test.
    
        The test doesn't really help. It uses very simplistic checks for matching
        path names. It ignores links (soft and hard) completely. Besides during
        recovery the path names will work with the original path names.
    
    commit fba6656350d0a757b2cc936b017329e7f7ce2d32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:51:53 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b522d665d10dca905420cb9119692dffac5024c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:20:30 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 3a9aca50a2e193398d626b5f75d238b5aa704e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:19:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5923cd73fc3af904220dea20b033ffcbb7892606
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:12:44 2016 +0530
    
        WL#9499 - Use custom allocators.
    
    commit 8c5acab2641cedae9542b9ad9405032abbcb4618
    Merge: 1509c43fcff 3c1319b9901
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:21:28 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1509c43fcffb9a849542ef8f3a62e66fda490fc7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:08:34 2016 +0530
    
        WL#9499 - Fix bug, should be decrement in_use, not increment.
    
    commit 0ad783d5e6e3f99817c8b839fe8521f783577d35
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 07:58:49 2016 +0530
    
        WL#9499 - Change fil_node_t::in_use into a reference counter from bool.
    
    commit 3974f1ed40bfbadcee04fa5fc2e60a50b89f930c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 22:10:24 2016 +0530
    
        WL#9499 - Remove an assertion that is no longer an invariant.
    
    commit d79f12dec7c07698f02ce2e0d0396bcd01bdc683
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 21:52:21 2016 +0530
    
        WL#9499 - Rename fil_node_t::being_extended to in_use. Fix test.
    
    commit 1d3368bcf60e2e339d5917251b51201b94dd63a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:57:38 2016 +0530
    
        WL#9499 - Fix log info messages during recovery/apply.
    
    commit d3811bd67248d3ae014f0e6475b1b49524f5c35b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:40:01 2016 +0530
    
        WL#9499 - Don't print % processed if number of records to apply is small.
    
    commit 55af670ff81170da51fbcae6832c3d6191176602
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:21:31 2016 +0530
    
        WL#9499 - Update test with new log message to check.
    
    commit 60c3d6c074ae230ab594015ed2f99e2eefcf97e0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:09:04 2016 +0530
    
        WL#9499 - Record test, because of new config parameter innodb_scan_directories.
    
    commit bd79ff06406c86758a29a28dbe5e7d494a0aa51f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:05:38 2016 +0530
    
        WL#9499 - Remove WL#7142 artefact.
    
    commit bcb753b72b2a01ba35d952cbab45e420929f2b33
    Merge: e30834ecc60 27d64e974ec
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:26:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e30834ecc60522fca8d7b156a66c0765867dea6e
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Thu Aug 25 05:54:26 2016 +0200
    
        WL#9499 - Destroy the mutex in the Fil_Open destructor.
    
    commit a396d4714bdc46626e07d22b6871be153b627bd3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:17:06 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 282ad76aaeaeb6d91bbf81fcd3315f455d9f572c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:12:33 2016 +0530
    
        WL#9499 - Protect changes to Fil_Open state with a mutex.
    
    commit d338cb9468c126ee7e3eeae3bf37b0fc966bbf53
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 07:37:49 2016 +0530
    
        WL#9499 - Fix division by zero.
    
    commit 845324f19ba0a84538b87c072f6d99514533aa25
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:28:45 2016 +0530
    
        WL#9499 - Check for UNDO tablespace names during directory scan.
    
    commit 30ed1d19389e174605fdfc0b7d55fdf544933712
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:26:08 2016 +0530
    
        WL#9499 - Conform to new naming guidelines.
    
    commit 4cf67b352d4c8131064f832ec884db6166d50e71
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 22:04:43 2016 +0530
    
        WL#9499 - Add test for the configuration variable. Add a version number to the file.
    
    commit ad9c5bca0eba1d7bf8e29cd8ebd7062aae089f90
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 21:01:56 2016 +0530
    
        WL#9499 - Code clean up
    
    commit a9e848158909645ead86759ed7ab64789d18a0cb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 15:26:02 2016 +0530
    
        WL#9499 - Print redo apply progress per tablespace
    
    commit 8cf86cf1567cabc1b03b2e8f2ec1167f3c38ce6c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 13:04:55 2016 +0530
    
        WL#9499 - Print tablespace name and % completed per tablespace
    
    commit 35ccdf32d1d048400012a80422072fb41ceb1bbd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 10:35:26 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit c978fb2e18a4e0b4a93b44fc3c75234bcdb3f1f0
    Merge: 8bde4aeb01c 0832bf660e3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 22:25:57 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 8bde4aeb01c3bcdecfb884e566f0ae28797a5b36
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 13:21:10 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 7f502be746cbe0de1a0c3a992217691b167c2fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 12:12:08 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 247bcfda6744a67cc4e53d61658ca87d206b0660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:57:44 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 04509641b086a1b0b2c591573f95957f8a2f1cd0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:50:55 2016 +0530
    
        WL#9499 - Pass the filename directly to the callback
    
    commit 3efa317825886a3ae5d4a3c771fc0770a2c5a3ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 09:39:18 2016 +0530
    
        WL#9499 - Include tchar.h on Windows
    
    commit 55b814d2c2ebdea7c16a6d87a7251ca3f6e83775
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 07:47:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit e4d203688273b562691c912cb9c7024709757490
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 22:02:02 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 31433b21dcabba0a7705eb8b1879beb1d8c36517
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 21:37:41 2016 +0530
    
        WL#9499 - Move Dir_Walker::walk implementation to os0file.cc
    
    commit 11f9016477274c5420782e365b26762067e7b99b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 18:42:28 2016 +0530
    
        WL#9499 - Fix Windows version of Dir_Walk.
    
    commit f32b88e0b1ef99f220165897db745b1dba12f86b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 13:48:03 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b91ad88d96942f1e05443001b7d1c2f6818ff6d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 14:32:25 2016 +0530
    
        WL#9499 - Initialize active ID to filename set from scanned set.
    
    commit 4a09f677ae7095aac9b07f7beccba8e60c50b065
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 13:09:05 2016 +0530
    
        WL#9499 Scan specified directories to build the ID to name mapping.
    
    commit c13b791497e322e6a5cf64ba85da52ee2cf05d45
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:46:53 2016 +0530
    
        WL#9499 - Fix check for incomplete read.
    
    commit 8a849e0288309cec7228612a62fc2bfd71b595e9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:45:04 2016 +0530
    
        WL#9499 - Fix Windows build errors
    
    commit 4fc24b654da26e8411fc45bc96f73ff70dc73e43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:12:12 2016 +0530
    
        WL#9499 - Need to include string for Windows std::wstring.
    
    commit bcb5c2b23f54776e0faaafba2472bb2555aee561
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:02:59 2016 +0530
    
        WL#9499 - On POSIX fopen() mode should be "w+b".
    
    commit b3c7def1931867633d9b8bb601317e99a06c31a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 21:23:57 2016 +0530
    
        WL#9499 - Open file in binary mode for writing.
    
        Otherwise on Windows newline (0x0A) is translated to CRLF (0x0D0A).
    
    commit 0739399cb8a384c07b4b3540b73ade482d083f4a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 20:27:11 2016 +0530
    
        WL#9499 - More error messages during mapping file read. Add a directory walker.
    
    commit 1322de0af2235bc94630f7cb22e4ead1588775ee
    Merge: f266b100e2f 8fdbb2f5f1a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:47:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f266b100e2f23e775e5e04de8d26301d7f2f1072
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:18:07 2016 +0530
    
        WL#9499 - Flush the tablespace to mapping file buffers before fsync()
    
    commit 7c92536686033c2c70e7df831d569c1cd6f871f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:32:26 2016 +0530
    
        WL#9499 - Remove unused member variable m_lsn.
    
    commit 994c4766ef712e7da668788d0bdd648cbd764982
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:25:05 2016 +0530
    
        WL#9499 - Don't crash on uncompress failure. Try the next file if any.
    
    commit a419a190cdf734e3beca08d339c6c0d307ddff5f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:21:49 2016 +0530
    
        WL#9499 - Print an error code on uncopress failure
    
    commit 77cb39000e098ba4d06873723423521e6889a7d0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:12:11 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit afc632e0ef768542a96d4d15a897cb1780825d2e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 11:34:44 2016 +0530
    
        WL#9499 - Compress the tablespace open state file.
    
    commit 568c9e758084f671007789f7b5d1c996f5df39a0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 09:12:39 2016 +0530
    
        WL#9499 - Free the buffer on return
    
    commit 0f468cf8e50b9605a9e6c4e93c818b0f876c3c29
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 08:42:38 2016 +0530
    
        WL#9499 - Remove protobuf
    
    commit e789eb175d2da90cee2d46e30b91e623546f9e96
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 18 09:59:37 2016 +0530
    
        WL#9499 - Get native HANDLE
    
    commit 6014c5853c09fee75256f9de6a86a5fc0ea18508
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:50:37 2016 +0530
    
        WL#9499 - Use _fileno() on Windows
    
    commit 61e6b4d7c033d48b775b22c4ad6d6b4858cd4cd7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:37:01 2016 +0530
    
        WL#9499 - Use buffered IO for open state file writes
    
    commit 98f40b10c15e49d9a5e14689cdb34758bdf85a05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 12:36:06 2016 +0530
    
        WL#9499 - Don't complain about corrupted encrypted pages during dblwr recovery
    
    commit c674939cbdeaa4a9996960de0fa4e74954ad6f76
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 09:21:06 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for generated sources too.
    
    commit ff68ba26aeaa27070ceeaa8db4472a9ce4daa3c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 08:33:03 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for fil/fil0fil.cc
    
    commit 445985ca11810c528567a4222cad4a7f0ce49e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 19:44:29 2016 +0530
    
        WL#9499 - Read/Write open state files using absolute paths
    
    commit b4d91d3799d94eb2677be6512752ec27dfa5e0f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 14:37:40 2016 +0530
    
        WL#9499 - Fix doxygen errors
    
    commit 8be2de3b3077c0d0f26340c9c80f7ae2247eefbc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 11:20:24 2016 +0530
    
        WL#9499 - Record test, MLOG_FILE_NAME doesn't exist anymore
    
    commit 54e64dc4a97f5bf4b5606cea1841dfc1f04fe536
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 10:41:01 2016 +0530
    
        WL#9499 - Add protobuf library to the embedded library.
    
    commit 83b0fb38283e285e1e963dd2c7c144d70b130338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 21:17:13 2016 +0530
    
        WL#9499 - Improved DBLWR and System table checks and code cleanup
    
        1. Remove dead code
        2. If some pages from the dblwr buffer were not recovered during recovery
           because of a missing tablespace id -> name mapping. Check the tablespace
           ID against the Tablespaces meta-data after recovery.
        3. Track open of the system tablespace. Check if the name of any file
           has changed. We don't rename the system tablespace.
    
    commit 5ebfba1e083f6a1d2b70946b91a02d32733c7e87
    Merge: 7a1b724c04b 0c27bf6fc44
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Mon Aug 15 11:40:07 2016 +0200
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7a1b724c04bf9d2e4aba0e58fb95dc8fc75d55c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 15:07:47 2016 +0530
    
        WL#9499 - Free deferred page memory
    
    commit 4de5d3b03670e4d2e8ebce89e8b3f104968eb3e1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:45:25 2016 +0530
    
        WL#9499 - Remove unrelated changes
    
    commit c9e83914232480501b139c36ef616798a2ac1d05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:28:19 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 6ecdb21d63ef6dd5a6aff997720178ff6510f0d5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 13 14:31:52 2016 +0530
    
        WL#9499 - Don't exit if no open state files found

[33mcommit d47167e19028788e2ae7f1b48fe2b2d5b034ad1f[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Feb 20 12:28:53 2017 +0100

    Bug#24488219: INCLUDE WHAT YOU USE
    
    Make only one canonical place to get LEX_STRING from. We had this typedef
    repeated a number of [1;31mtime[ms throughout the code base, which would cause
    IWYU to pick a random one and include e.g. sql_class.h into client code.
    
    Change-Id: I5fb63ff4d02c3ae3c1913957bf70df287f9f2289

[33mcommit 442cb305129bc470d837b4d031aaba8ebc5be085[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Mon Feb 27 14:24:43 2017 +0100

    Bug #25597667: REMOVE MY_BOOL
    
    Post-push fix: Fix [1;31mtime[mout in query_rewrite_plugins.refresh_thread

[33mcommit ca1b745ee0d7862d2ff7338d173a60215241046b[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Feb 23 09:01:25 2017 +0100

    Bug#25474239 MISC MTR TESTS FAIL WHEN CHANGING DEFAULT CHARACTER SET FOR DATABASE
    
    Patch #7
    
    To repeat:
    ./mtr --charset-for-testdb=utf8mb4 --defaults-file=include/utf8mb4_my.cnf
    
    group_by
    handler_read
    key
    key-bug17665767
    subquery
    type_[1;31mtime[mstamp
    type_[1;31mtime[mstamp2
    type_[1;31mtime[mstamp_explicit
    
    Change-Id: I3539cc62ba90b7b35658f1214fd7f3769b740de6

[33mcommit f6c7fb5117959cc53e74c4de4f8f44f19cb98397[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Fri Feb 24 02:50:27 2017 +0100

    WL#9720: SET PERSIST capture user, host and [1;31mtime[mstamp
    
    Post push fix. This patch fixes invalid read error reported by
    valgrind.

[33mcommit 725f3eef35ff11bce81f6744d151466b0b06d2e7[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Thu Feb 23 17:23:37 2017 +0000

    Bug#25443080 MAIN THREAD CPU USAGE ON MASTER DATANODE INCREASES TO 100% WITH LATENCY BURST
    
    LCP is controlled by DIH Master on one node, running on the 'main' thread.
    
    CPU usage was seen to be high there towards the end of an LCP, leading to
    increased transaction latency.
    
    Problem appears to be inefficiencies in the algorithm used by DIH Master to
    find fragment replicas to schedule for LCP, towards the end of the LCP it
    can spend a lot of [1;31mtime[m scanning over the set of all replicas.
    
    Fixes :
     - Make sure that per-node queues are made use of
       - If a fragment replica is queued, do not search for more
       - When searching for more, search for all nodes in 1 pass
     - When a node has started on all of its fragment replicas, do not
       include it in future searches
     - When all nodes have started on all of their fragment replicas,
       no need to search for more.
    
    Testcase :
     - 16 nodes, 4 LDMs/node : 64 fragments : 128 fragment replicas / table
     - 88 tables
     - No data
     - Run LCP using ALL DUMP 7099
     - Observe CPU usage and efficiency of replica search algorithms

[33mcommit 5b84c86e7b0f62a12a602a57d298719c86f4eb96[m
Author: Praveenkumar Hulakund <praveenkumar.hulakund@oracle.com>
Date:   Thu Feb 23 15:07:39 2017 +0100

    Bug#24834622 - ASSERT IN UPDATING VIEW METADATA FOR SYS SCHEMA VIEW.
    
    While updating view columns metadata, assert condition is hit
    for the date[1;31mtime[m type column with default value as bitmap
    TABLE::read_set is not set.
    
    TABLE has a bitmap read_set. A bit in this bitmap is set for a
    field of a table used in the query. But this bitmap is not set
    (for outer-most query block) while resolving derived tables.
    A flag THD::derived_tables_processing is used to indicate the
    derived table processing.
    
    DDL operation on a table, views or stored function(sf) updates
    a view columns metadata if there are any views referencing them.
    The view columns metadata is updated as below,
    
      * List all the views using table, views or sf used in the DDL
        operation and even other views dependent on view(s) already
        included in the list.
    
      * For all views in the list,
          ** Prepare query expression for a view query with the new
             definition of table/view/sf.
    
          ** Update view columns metadata using the query expression
             prepared for a view query.
    
        (In error scenarios mark view as invalid and continue with
         next view in list.)
    
    While preparing query expression for a view, if the derived
    table processing fails in a situation like missing other table,
    view or sf (while preparing the query expression of the derived
    table) then the flag THD::derived_tables_processing is not reset
    in the current code. This affects processing next view in the
    list and we end-up not setting read_set flags in TABLE. Hence
    assert condition to check bitmaps THD::read_set while accessing
    fields (of type data[1;31mtime[m in this scenario) fails.
    
    Modified code to reset THD::derived_tables_processing flag in
    in all error handling code path while resolving derived tables to
    fix this issue.

[33mcommit 910b3e97aa60842421d21b677431454ee0315ee0[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Tue Feb 21 10:28:38 2017 +0100

    WL#9720: SET PERSIST capture user, host and [1;31mtime[mstamp
    
    Post push fix. This patch fixes clang build failure and testcase
    failure for binary built with ubsan.

[33mcommit 9b6bf7a2d87363513bb5d11b5368b87f840f967f[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Tue Feb 21 09:31:31 2017 +0100

    WL#9720: SET PERSIST capture user, host and [1;31mtime[mstamp
    
    Post push fix to resolve ubsan error.

[33mcommit 30586c7aa3fc005e0c64d9c9701f165e999895ec[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Tue Feb 21 05:37:31 2017 +0100

    WL#9720: SET PERSIST capture user, host and [1;31mtime[mstamp
    WL#9763: Support option to RESET PERSIST
    
    WL#9720 introduces 3 new columns to performance_schema.variables_info table.
    SET_TIME - represents [1;31mtime[mstamp of when a system variable was changed.
    SET_USER - represents who has changed the system variable.
    SET_HOST - represents host on which the system variable was changed.
    Whenever a system variable is changed using SET statement
    performance_schema.variables_info table will get updated accordingly.
    
    WL#9763 introduces RESET PERSIST [IF EXISTS] variable; statement which lets
    variable to be removed from persistent config file mysqld-auto.cnf. This WL
    also introduces new performance_schema.persisted_variables table which will
    be an exact copy of mysqld-auto.cnf file. This enables user to see what's in
    the file at the SQL level without having to access the file itself.

[33mcommit e6bf62e5e417aba194601f81af8407009ecd4da7[m
Author: Maria Couceiro <maria.couceiro@oracle.com>
Date:   Tue Feb 7 12:11:28 2017 +0000

    WL#7318 Delayed Replication: GTID based and relative to immediate master commit
    
    Delayed replication is now applied per transaction (instead
    of per event) and is computed relative to the
    immediate_commit_[1;31mtime[mstamp (introduced in WL#7319) if both
    the immediate master and current server (slave) support
    immediate_commit_[1;31mtime[mstamp.
    If at least one of the servers does not support this
    [1;31mtime[mstamp, the delay will be computed using the old
    implementation.

[33mcommit c44cbdf0cc8b37c990fffd05f4567d016bdf608e[m
Author: Thayumanavar S <thayumanavar.x.sachithanantha@oracle.com>
Date:   Thu Feb 16 04:30:58 2017 +0100

    BUG#25444075 - YASSL REQUIRES FROM READ FUNCTION TO RETURN
                   EWOULDBLOCK, VIO RETURNS ETIMEOUT.
    
    Connection is invalidated when read [1;31mtime[mout occurs and application uses
    YaSSL.  The root cause is that yassl_recv emulates a blocking recv using the
    vio_read. vio_read returns ETIMEOUT in case of a [1;31mtime[mout. YaSSL considers
    ETIMEOUT as a critical error causing subsequent read and writes to fail.
    The fix remaps ETIMEOUT to EWOULDBLOCK in yassl_recv. This fix is provided
    by Lukasz Kotula.

[33mcommit 81622971642a6ce1236b1593d6a13f6fa498211d[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Tue Jan 10 11:48:23 2017 +0530

    Bug #25092498: NDB API PROCESS CRASH (CHECKMAGICNUMBER (THIS=0X0, B=FALSE) AT /PLATSOFTWARE/MYS
    
    checkMagicNumber() fails due to a NULL pointer being passed to it.
    This happens due to simultaneous access of theNdbObjectIdMap without
    proper synchronisation/protection.
    
    The NdbObjectIdMap object is internally expanded using realloc() when needed.
    realloc() some[1;31mtime[ms changes the memory location of the internal map object
    and the old memory object is freed.
    Hence, when one thread causes the map to expand, another thread might
    still be accessing the old location of the map. This could cause a
    segmentation fault in the thread accessing the old location.
    
    This patch adds mutex protection to theNdbObjectIdMap by reusing the
    existing mutex in NdbImpl: m_mutex.
    This mutex is already being locked before reading theNdbObjectIdMap.
    Now, the mutex is locked before theNdbObjectIdMap is expanded as well.
    We don't need to lock it before unmap() since it's guaranteed to be
    called only after map()/expand().

[33mcommit 38e0181904530de34553dc471f138f04de678b98[m
Author: Maria Couceiro <maria.couceiro@oracle.com>
Date:   Mon Jan 11 17:10:53 2016 +0000

    WL#7319 Infrastructure for GTID based delayed replication and replication lag monitoring
    
    The worklog creates the infrastructure enabling two new
    [1;31mtime[mstamps that are associated with each transaction
    (instead of event or statement) in the binary log:
    - original_commit_[1;31mtime[mstamp: microseconds since the epoch
    when the transaction was committed on the original master.
    - immediate_commit_[1;31mtime[mstamp: microseconds since the epoch
    when the transaction was committed on the immediate master.
    
    Summary of relevant points covered by this worklog:
    
    1) Two new fields, original_commit_[1;31mtime[mstamp and
    immediate_commit_[1;31mtime[mstamp, added to gtid_log_event. Commit
    [1;31mtime[m is recorded in write_gtid(), so the commit [1;31mtime[mstamp
    of a transaction is assumed to be the [1;31mtime[m of writing it to
    the binary log.
    2) has_commit_[1;31mtime[mstamps flag added to the Gtid_event
    class, indicating whether the current gtid_log_event
    includes at least the immediate_commit_[1;31mtime[mstamp. If the
    gtid_log_event does not include any commit [1;31mtime[mstamp, it
    was replicated from a server with a MySQL version lower
    than 8.0 and has to be processed accordingly.
    4) The new body of gtid_log_event consists of:
     - only original_commit_[1;31mtime[mstamp at the original server,
     since original and immediate commit [1;31mtime[mstamps are same at
     this server;
     - both original and immediate commit [1;31mtime[mstamps in any
     other 8.0+ server.

[33mcommit 389ea43bea4b0e230a35e65c648d53ff4591d95e[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Mon Feb 6 11:35:01 2017 +0000

    Bug #25306089 NDBAPI : FINALISE 'OLD' SCANS OUTSIDE OF TRANSPORTER RELATED LOCKS
    
     - The NdbRecord scan Api is optimised w.r.t the NdbRecAttr based scan Api
     - At the [1;31mtime[m of introduction, the NdbRecAttr based scan Api was
       modified to use the NdbRecord scan Api internally
     - This required that the NdbRecAttr scan Api build up a set of scan
       parameters, which are used to define an actual NdbRecord scan in a
       'finalisation' step
     - This step was put into NdbScanOperation::executeCursor() which is
       executed as part of sending a scan to the data nodes.
     - Sending is done holding various transporter-layer locks
     - NdbRecAttr scan finalisation is really a 'definition' [1;31mtime[m operation
       potentially including memory allocation, object id allocation etc
     - Moving finalisation out of sending into the preparation phase allows
       it to be done without holding locks which :
       - Reduces hold [1;31mtime[m on contended locks
       - Avoids risks of deadlocks when adding locking to finalise()
    
     - This fix moves the finalise() step into executeAsynchPrepare(), which
       is called without holding any transporter locks
     - Additionally :
       - The fix for bug#42545 is modified to cover other scenarios where
         user code error checking is insufficient - any prepared scan
         (NdbRecAttr or NdbRecord) is covered for an unguarded nextResult()
         call
       - NdbScanOperation::close() is modified to avoid waiting for signals
         from the data node regarding a scan, when none were sent.
         This improves API error handling for cases other than data node
         failure where a prepared scan is not sent.
       - A new NdbApi error code 4342 is added to catch cases where a scan
         is defined but not prepared.
       - A new testcase testNdbApi -n OldApiScanFinalise is added to show
         the mechanisms working.

[33mcommit 3b4ffa6262eb2ade87a2f8d931c2c887df0c85d5[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Wed Feb 1 11:32:49 2017 +0100

    Bug#25461627: VALGRIND WARNING WHEN UPDATING A JSON COLUMN
    
    In some situations, updating a JSON column could cause incorrect
    values to be written into the table. The problem occurs if an UPDATE
    statement updates the same JSON column twice, and the second update
    overwrites the column value with a subset of itself. For example:
    
    UPDATE t SET json_col = JSON_ARRAY(....), json_col = json_col->'$[0]'
    
    The problem is that the second update both reads and writes from the
    output buffer, since it needs to read the value that resulted from the
    first update. When reading from and writing to the buffer at the same
    [1;31mtime[m, it may overwrite parts of the buffer before it has read them,
    which could result in garbling the value.
    
    This is fixed by writing the new value to a temporary buffer first in
    the case where the input is read from the output buffer, and only copy
    it to the output buffer after all the needed data have been read.

[33mcommit baafb63b990414f64f904836704fc53f5f68d007[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Wed Feb 1 11:33:37 2017 +0100

    WL#9185 MySQL Cluster support for new DD
    
     - since the serialized table definition contains the table name
       it must be generated and saved to NDB when renaming table during
       copying alter table or rename table.
     - add debug [1;31mtime[m function which check that serialized table definition
       of table to be renamed matches

[33mcommit 39d67a4564eec741c485d12d3f661551671f1a3b[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Feb 3 10:15:07 2017 +0100

    The ATR test 'testSpj -n ScanJoinError' some[1;31mtime[ms failes
    with a 600s '[1;31mtime[mout'. Looking at the 'passed' tests, we find
    that the test could take more 9mins to complete, so the 10min
    [1;31mtime[mout is probably to low to acount for various hardware,
    
    Increase [1;31mtime[mout to 1200sec

[33mcommit 9cf8459be71c5b3218ae0c1a69d58c404d4801cb[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Feb 2 10:45:34 2017 +0100

    Bug#25437227 REMOVE #IFDEF HAVE_NDB_BINLOG
    
     - follow up fix to also remove the WITH_NDB_BINLOG
       compile [1;31mtime[m option. There is no part of storage/ndb/ or
       ha_ndbcluster that can be compiled without binlog now.

[33mcommit 0a0738ebe15d09c716372732d13f8573201db87a[m
Author: Nisha Gopalakrishnan <nisha.gopalakrishnan@oracle.com>
Date:   Wed Feb 1 15:21:38 2017 +0530

    BUG#24594140: VIEW GETS DROPPED IF ALTER VIEW FAILS WITH
                  ERRNO 1213 (ER_LOCK_DEADLOCK)
    
    Analysis:
    ========
    Views may get dropped if ALTER VIEW fails with an error
    like the deadlock error reported in the bug.
    
    Currently ALTER VIEW, drops the view and re-creates
    and is individually committed. Thus if the drop succeeds
    and CREATE fails, the view gets dropped. Also this causes
    the create [1;31mtime[m to be updated for an ALTER VIEW operation
    since it involves drop and re-create of the view.
    
    Fix:
    ===
    The ALTER view now updates the meta data in the data
    dictionary rather than DROP + RE-CREATE of view meta
    data. Hence only the last_altered [1;31mtime[m is updated
    and not the create_[1;31mtime[m.

[33mcommit 7fc4fd349d62fd73d932fa9b9ddaa9b53d5da2bf[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Tue Jan 31 20:08:44 2017 +0530

    WL#9817 : Change default query_cache_size to zero
    
    This worklog changes the default value of query_cache_size variable
    from 1048576 (1MB) to 0.
    
    The change in default value of the variable results in some test case
    changes. An explanation of test case changes.
    
    - result files are recorded to reflect the new default value for
      query_cache_size.
    
    - value of query_cache_size is backed up before changing it in the tests.
      The value is restored later in the tests.
    
    - query_rewrite_plugins.query_cache : tests invalidation of query cache.
      Test need to cache query to simulate the test conditions.
      Set query_cache_size to 1MB explicitly to enable query caching of queries.
    
    - main.query_cache_size_functionality - test value of status variables with
      query cache enabled. The value of status variable had changed as
      query_cache_size is zero from the beginning of the test case.
      Set query_cache_size to 1MB explicitly to enable query caching of queries.
    
    - main.max_statement_[1;31mtime[m - test query cache behavior with max_execution_[1;31mtime[m.
      Set query_cache_size to 1MB explicitly to enable query caching of queries.
    
    - main.mysql_client_test_qcache - tests client API with query cache.
      Set query_cache_size to 1MB explicitly to enable query caching of queries.

[33mcommit dbf65bb42412a4bcac91343e86aed63648eb74d4[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Thu Jan 26 09:31:23 2017 +0100

    Bug#25221172 - Refactor Item::field_type() type as a static property
    
    Implement a data type property as a byte field in class Item. This type field
    is retrieved using the non-virtual function data_type(). This function is a
    replacement for the current function field_type().
    
    Implement non-virtual inlined setter functions for data type as follows:
    
    set_data_type() - Set specified data type
    set_data_type_longlong() - Set properties for a longlong data type
    set_data_type_decimal() - Set properties for a decimal data type
    set_data_type_double() - Set properties for a double precision data type
    set_data_type_string() - Set properties for a variable length string type,
                             might be converted to a BLOB type internally.
    set_data_type_char() - Set properties for a fixed length char type
    set_data_type_blob() - Set properties for a long BLOB type
    set_data_type_date() - Set properties for a date type
    set_data_type_[1;31mtime[m() - Set properties for a [1;31mtime[m type
    set_data_type_date[1;31mtime[m() - Set properties for a date[1;31mtime[m type
    set_data_type_[1;31mtime[mstamp() - Set properties for a [1;31mtime[mstamp type
    set_data_type_from_result() - Set data type from one of the 5 result types
    set_data_type_from_item() - Set data type based on properties from an item
    
    Generated internal type MYSQL_TYPE_VAR_STRING is replaced with
    MYSQL_TYPE_VARCHAR. This should be a good and consistent change, as
    MYSQL_TYPE_VARCHAR is used for all columns of type VARCHAR.
    
    Removed the following type cache fields:
      Item_null_result::fld_type
      Item_param::param_type
      Item_temporal::cached_field_type
      Item_return_int::int_field_type
      Item_int_with_ref::cached_field_type
      Item_copy::cached_field_type
      Item_cache::cached_field_type
      Item_type_holder::fld_type
      Item_func_coalesce::cached_field_type
      Item_func_if::cached_field_type
      Item_func_min_max::cached_field_type
      Item_sum_hybrid::hybrid_field_type
      Item_temporal_hybrid_func::cached_field_type
    
      Most uses are replaced with the data_type() function.
    
    Changed data type for Item_sp_variable with underlying JSON argument to
    JSON, this required implementing Item_sp_variable::val_json().
    
    Renamed Item::get_real_type() to real_data_type().
    
    Test changes:
    ctype_collate:
    - Collated numeric data is sorted correctly (max_length was wrong)
    
    ctype_utf16, ctype_utf16le, ctype_utf32, ctype_utf8, ctype_utf8mb4:
    - Binary string types have decimals=31 (like other string types)
    
    gis:
    - Binary string types have decimals=31 (like other string types)
    
    innodb-2byte-collation, innodb_gis.1, innodb_gis.gis
    - Binary fields show 31 (UNDEFINED) for decimals
    
    internal_tmp_disk_storage_engine:
    - Result was too short because max_length was calculated improperly.
    
    type_temporal_fractional:
    - Decimal precision derived from UNIX_TIMESTAMP could be calculated wrongly.
    
    json_functions_innodb, json.json_no_table:
    - Type is reported as 15 (VARCHAR) instead of 253 (ancient VAR_STRING).
    
    test_service_sql_api.test_sql_commit
    - character set is changed from 63 (binary) to 8 (default numeric)
    
    test_service_sql_api.test_sql_stmt
    - data type is changed to 15 (MYSQL_TYPE_VARCHAR) for all character items,
      which is a consistent change.
    
    test_service_sql_api.test_sql_complex
    - length of variable @a (of type integer) was incorrectly set as 60
      (MAX_BIGINT_WIDTH * 3), now changed to MAX_BIGINT_WIDTH.

[33mcommit 2d0cf54f31523664a9a8dcc4161138dc8a7ceab1[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Tue Jan 24 10:38:10 2017 +0800

    WL#9532: Don't set dirty_status to METADATA_CLEAN if it's the
    second [1;31mtime[m to apply dynamic metadata, because the status could
    be already METADATA_BUFFERED.

[33mcommit 24b3e6bdc6b362528134366e4686b1407fc2c683[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Wed Jan 18 08:14:29 2017 +0100

    Bug#25413554: REMOVE DEAD STRUCT MEMBERS
    
    Remove some unused members from Date_[1;31mtime[m_format, st_lex_user,
    TABLE_LIST and KEY to reduce their size.
    
    Also remove some unused variables from mysqld.cc

[33mcommit 683c1ae6aed6dfb2701b99020ada7dec187e065d[m
Author: Thayumanavar S <thayumanavar.x.sachithanantha@oracle.com>
Date:   Wed Jan 18 11:25:36 2017 +0100

    BUG#25408557 - PPOLL(2) DOES NOT ACCEPT NEGATIVE TIMEOUT VALUE
    
    When a negative [1;31mtime[mout value is passed to vio_io_wait, we pass
    a negative value in [1;31mtime[mspec value to ppoll. This causes the
    connection to idle and abort. Negative [1;31mtime[mout value to
    vio_io_wait means the call should block indefinitely
    if no I/O event is available.
    
    The fix is to pass null value to [1;31mtime[mspec argument of ppoll
    to block indefinitely.

[33mcommit 64be9731ed4c3163870dd7e90fb09e4efa8a8634[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Tue Jan 17 07:12:01 2017 +0100

    Disable two tests in Valgrind in order to avoid [1;31mtime[mouts.
    
    Approved by Jimmy Yang <jimmy.yang@oracle.com> over IM.
    Approved by Srikanth B R <srikanth.b.r@oracle.com> over IM.

[33mcommit 6c5ee4b05600b57b90211089e3786856ede99d51[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Wed Jan 11 13:11:24 2017 +0100

    When Valgrind is used, disable test which takes too long and causes
    [1;31mtime[mout in pb2

[33mcommit c54748a1697b32d63189d93baeacef46ababfe2f[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Fri Jan 6 15:57:33 2017 +0100

    Bug#25320909 ASSERTION `THD->LEX->CURRENT_SELECT() == UNIT->FIRST_SELECT()' WITH DELETE
    
    Introduced by WL#3634 (recursive CTE).
    Before WL3634, in unit::execute(), if one of the query blocks'
    join::exec() returned an error, unit::execute() would return
    immediately, but if the fake_select_lex's join::exec() returned an
    error then we would first restore current_select() to the value it had
    when the function started, and then return.
    In WL3634, I moved the fake_select_lex's join::exec() into the same
    loop as the query blocks' join::exec() because it may be executed
    several [1;31mtime[ms. Doing this, I automatically removed the "exceptional"
    restoration of current_select(), judging that it was anyway
    unnecessary: "as a failure of join::exec() means a real problem, the
    statement is going to end in error very soon, so why restore?".
    This introduced the bug. Scenario is:
    DELETE IGNORE ... WHERE a!=(subq);
    where "subq" contains a UNION which returns more than one row.
    DELETE evaluates the scalar subq. The subq's fake_select_lex's JOIN
    sends its result to a Query_result_scalar_subquery which job is to
    fill the Item_singlerow_subselect with the JOIN's result. However if
    this item is already filled (i.e. the JOIN is finding a 2nd result
    row) the result object signals my_error(ER_SUBQUERY_1_ROW) then
    returns "error":
     bool Query_result_scalar_subquery::send_data(List<Item> &items)
     {
       Item_singlerow_subselect *it= (Item_singlerow_subselect *)item;
       if (it->assigned())  <<< already assigned a value
       {
        my_error(ER_SUBQUERY_NO_1_ROW, MYF(0));
        DBUG_RETURN(true);  <<<<<<< error
    
    There is IGNORE so my_error() only pushes a warning. Due to the
    returned "true" value, subquery's unit::execute() terminates, but as
    it's the fake_select_lex's JOIN's which failed, current_select() is
    restored() before terminating. The termination also means the 3rd row
    won't be read (that's efficient). The the subselect_union_engine gets
    the "true" return code, then the Item gets it too:
    
    longlong Item_singlerow_subselect::val_int()
    {
      DBUG_ASSERT(fixed == 1);
      if (!no_rows && !exec() && !value->null_value)
      {
        null_value= FALSE;
        return value->val_int();
      }
      else
      { <<<<<< here as exec()==true
        reset();
        return 0;
      }
    }
    
    reset() fills the Item with NULL and then "return 0" makes the error
    disappear. From the point of view of the outer statement, everything
    is said to be ok. So the DELETE uses the NULL value to evaluate its
    WHERE, then goes and delete the row in:
    which has this assertion:
     `thd->lex->current_select() == unit->first_select()'.
    Which passes.
    After the changes of WL#3634, as current_select() isn't restored, the
    assertion fails.
    
    Fix: restore current_select()
    On-the-side fix: in sql_union.cc:
           if (set_limit(thd, fake_select_lex))
    -        DBUG_RETURN(status);
    +        DBUG_RETURN(true);
    because "status" may not be true at this point.

[33mcommit cbf99b0076ff9cc51be0249ec09086a76032d87a[m
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Wed Jan 11 14:44:49 2017 +0530

    Bug#25372667: MAIN.OPT_HINTS_PFS FAILS ON PB2 OCCASIONALLY
    
    Issue:
    ------
    main.opt_hints_pfs has been failing on pb2 sporadically
    with an error saying that the maximum statement execution
    [1;31mtime[m exceeded for a query that uses the MAX_EXECUTION_TIME
    hint.
    
    Fix:
    ----
    The maximum statement execution [1;31mtime[m is exceeded only once in a
    while if pb2 is loaded. When it is loaded, the response [1;31mtime[m
    increases and determining [1;31mtime[mout values in tests can be very hard.
    The fix is to set the [1;31mtime[mout to a large value.
    
    Reviewed-by: Gleb Shchepa <gleb.shchepa@oracle.com>
    RB: 15061

[33mcommit d2ae49d1ad9cf3160bb4bfa35db742b6861775f8[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Tue Jan 10 15:53:02 2017 +0100

    Bug#25339088 REGRESSION IN SYSBENCH/POINT_SELECT DUE TO CTE WL
    
    Revert the patch for this bug.
    Because, even though testing showed it gained back all lost
    performance, something in the [1;31mtime[m window between testing and push
    changed the conditions and the pushed patch ended up losing
    performance.

[33mcommit 1e7a6a17b1629b5b7aa3837903319b203735e9eb[m
Author: Jimmy Yang <jimmy.yang@oracle.com>
Date:   Tue Jan 10 17:29:31 2017 +0800

    WL#9533: Due to run[1;31mtime[m stripes the FK info during alter table, InnoDB canno
    do proper type check and modify correspodning FK info during alter. Now,
    InnoDB always refresh new table's dict_table_t after an alter
    
    WL#9525: Set a "DD_TABLE_DATA_DIRECTORY" bit in se_private_data for table
    if it has data directory specified

[33mcommit 2847a907e13fd1ce430561df6d81b4e3bfc7c940[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Mon Jan 9 23:49:35 2017 +0530

    Bug#24755869 : MOVE MYSQL CODING GUIDELINES TO DOXYGEN
    
    It has been decided to follow the Google coding style for mysql.
    Google coding style should be used for new projects/components
    wherever possible.
    
    This patch adds the mysql coding guidelines inside code
    in doxygen comments format. Doxygen tool will create the coding
    guidelines from the comments.
    
    Exceptions in coding guidelines:
    
    i> Class names : Do not use MyClass but My_class
    
       This exception is because the server has a history of using
       My_class. It will be confusing with mixing the two
       (from a code review perspective).
       InnoDB have had freedom of choice for Class names
       and will therefore not suffer from the mix.
    
    ii> Member variables names : Do not use foo_ but
        m_foo (non-static) and s_foo (static). It is because
        this is an improvement over the Google style.
    
    Notes:
    
    i> Comment Style: Use either the // or /* */ syntax.
       // is much more common but both syntax is allowed
       for the period.
    
    ii> Doxygen comments: Use /** ... */ syntax and not ///.
    
    iii> Doxygen command: Use '@' and not '\' for doxygen commands.
    
    iv> Braces alignment, if..else indentation, spaces around '=':
    
        Mysql coding guideline traditionally places left braces aligned
        with the start of the preceding line, whereas the Google style is
        to place the left brace on the end of the previous line.
    
        Mysql coding guideline is to have no space before '='
        while assignment “foo= bar”. The Google style is have space
        around '=' in assignment "foo = bar".
    
    For new projects Google style should be followed. For old
    projects/components mysql old style should be used for [1;31mtime[m being.

[33mcommit b4d19910729e4c7442a51e6ead1c47bab2a0b214[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Jan 6 14:06:58 2017 +0100

    Bug #25358534: REMOVE UNNEEDED ZERO EXTENSIONS FROM CRC32 CODE
    
    ut_crc32() has a number of unneeded zero extensions:
    
          66:       f2 48 0f 38 f1 42 80    crc32q -0x80(%rdx),%rax
          6d:       89 c0                   mov    %eax,%eax
          6f:       f2 48 0f 38 f1 42 88    crc32q -0x78(%rdx),%rax
          76:       89 c0                   mov    %eax,%eax
          78:       f2 48 0f 38 f1 42 90    crc32q -0x70(%rdx),%rax
          7f:       89 c0                   mov    %eax,%eax
          81:       f2 48 0f 38 f1 42 98    crc32q -0x68(%rdx),%rax
          88:       89 c0                   mov    %eax,%eax
    
    (etc.)
    
    These are completely unneeded, as the crc32q extension zero-extends by itself
    even when writing to a 64-bit register. Simply change to a 64-bit type everywhere,
    which removes the zero extensions.
    
    The microbenchmarks were written to work with the new microbenchmark framework,
    which gives much more stable timings. Results (64-bit, opt, Skylake 3.4 GHz):
    
      BM_CRC32             2408 -> 1787 ns/iter [+34.8%]
      BM_BigEndianCRC32    2419 -> 1807 ns/iter [+33.9%]
    
    which is something like 0.5% in a typical sysbench run (the function goes
    down from ~3.8% to ~3.2% of CPU [1;31mtime[m used). This matches well up with theory,
    as crc32q has 3 cycles latency and mov is a bit under 1, and they are mutually
    dependent.
    
    Change-Id: I22f16d1a9cce98bcfd74e10d19ab69566b655e13

[33mcommit 5dfa8caa596ee4c213874564182b85d9fbecbff9[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Jan 4 12:37:01 2017 +0100

    Bug #24710065: SPLIT MY_GLOBAL.H
    
    Run include-what-you-use limited to adding "my_sys[1;31mtime[m.h" and then re-sorting
    the #includes (and nothing else); then remove "my_sys[1;31mtime[m.h" from my_global.h.
    
    Change-Id: Icf2f8fea2852add01f2a53b7eff32de3479b1975

[33mcommit 767f3877cc70265c0854a84e07f5a215a1239bb2[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jan 6 09:29:05 2017 +0100

    Bug#22705935 NDBAPI : SENDSIGNAL FLUSH OPTIMISATION ISSUES
    
    If signals were sent while the client process received signals
    (typically SUB_GCP_COMPLETE_ACK and TC_COMMIT_ACK), these signals
    were temporary buffered in the send buffers of the clients which
    sent them. If not explicit 'flushed', the signal would stay
    in these buffers until the client was woken up again and flushed
    its buffers. However, this could take quite a while, without any
    attempt of guarantying an upper limit of how long the signal
    could remain unsent in the local client buffers. This could
    lead to [1;31mtime[mouts and bad behaviour in the components waiting
    for these ACKs. (bug#18753341).
    
    Furthermore, the patch for Bug#23202735
    
    'CLIENT PERFORMANCE REDUCED DUE TO THREADS WOKEN UP TOO EARLY'
    
    Likely worsened the situation by removing some random client
    wakeups where the clients send buffers could have been flushed.
    
    This patch moves the responsibility of flushing messages
    sent by the receivers from each client, to (only) the
    receiver/poll_owner client. This has the advantage that
    we no longer have to wake up all clients just to have them
    flush their buffers. Instead we let the (already running)
    poll_owner client do the send buffer flushing of whatever
    was sent while it deliverd signals to the receipents.
    (in finish_poll())
    
    Note that all such signals should be 'safe-sent'
    (safe_sendSignal()) which implies that the are buffered in
    the poll_owner send buffers. Thus only the poll owner
    send buffers has to be flushed when the poll 'finish'.
    (Added asserts that there are no pending flush from the other
    'locked-clients')
    
    Explicit 'flush_send_buffers' where we flushed send buffers now
    covered by the above flush has been removed (reportConnected(),
    reportDisconnected(), complete_poll(), wait_for_input_in_loop().
    The later two were replaced with an assert that there were no
    pending flushes.
    
    That ^^ uncovered a missing flush_send_signal() in
    NdbScanOperation::nextResultNdbRecord(), where a
    'prefetch' of more scan results may have been sent, but
    not got flushed to the transporter layer. (Until we eventually
    had to poll-wait for more results)
    
    There has also been some confusion wrt. when to use the
    'safe(_noflush)_sendSignal()' or not. The method
    TransporterFacade::is_poll_owner_thread() is introduced
    as an utility to be used to 'assert' the correct usage of
    the diferent flavours of the 'sendSignal()' methods.
    See also extensive comments added as part of introducing
    this.
    
    Usage of these asserts uncovered that both
    ClusterMgr::reportConnected() and ::reportDisconnected()
    made usage of raw_sendSignal() instead of its 'safe'
    variant - corrected.

[33mcommit 44bb2e6dd187dc5917cf8cdac362ee0146c77698[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Jan 2 13:16:33 2017 +0100

    Bug #25336715: ADD AN OPTION TO RANDOMIZE LINK ORDER
    
    We keep seeing spurious performance changes that we believe are caused by lucky
    or unlucky alignment of code, and that tend to go away by themselves at a later
    stage. This commit adds a CMake flag (-DLINK_RANDOMIZE=ON) that randomizes the
    order of almost all symbols in the mysqld binary; the idea is that if a
    regression between binaries A and B (presumably at different versions) are
    detected, one can randomize both sides to test randomize(A) vs. randomize(B)
    and see if the regression still holds. If the randomized versions are the
    same, it's much more likely to be random.
    
    The randomization is reproducable, as it works by hashing the function name
    together with a seed (which can be set by -DLINK_RANDOMIZE_SEED=).
    
    It's not recommended to use this flag for regular builds, especially as it
    causes somewhere around 5% performance regression in sysbench; the default
    order (ie., just keep the order from each source code file, and link object
    files in the order they are given on the command-line) is quite good for
    reducing TLB misses, as it puts related functions together.
    
    I haven't tested actually reproducing historical spurious regressions
    with this (it would probably mean running quite large benchmarks), so it's
    somewhat experimental, but should be used next [1;31mtime[m we debug such a regression.
    Different seeds make for differences in some microbenchmarks, which is a good
    indication that it would have a real measurement effect.
    
    Change-Id: Ide109371bd99390bd79b1809d771c444ac70b837

[33mcommit d932566cbdfd349bad9b3805b84b3a28625350f6[m
Author: Jimmy Yang <jimmy.yang@oracle.com>
Date:   Wed Dec 28 17:47:24 2016 +0800

    Use NewDD FK info for creating table [1;31mtime[m InnoDB FK structure instantiation

[33mcommit 4a0450a9e33b357b59e74cbba53c7c91a92f92d2[m
Author: Priyanka Sangam <priyanka.sangam@oracle.com>
Date:   Wed Dec 28 14:58:28 2016 +0530

    Bug #24945638 STOPONERROR = 0 WITH UNCONTROLLED EXIT RESTARTS IN SAME WAY AS PREVIOUS RESTART
    
    On ndbmtd crash/shutdown, the angel sets the restart flags to
    Initial or Normal, and to Start or Nostart, depending upon
    parameters like the type of shutdown. For the case where the
    shutdown type is an uncontrolled exit and the StopOnError config
    parameter is set to false, the restart flags were not set, and
    defaulted to Initial/Start. If all the ndbmtds had uncontrolled
    crashes within a specific [1;31mtime[m interval, then all the ndbmtds were
    restarted in Initial mode and all the data was lost. Added a fix
    for the case of StopOnError=false and uncontrolled exit, to set
    the flags to Normal/Start so that ndbmtd does not lose data.
    
    In the case where the ndbmtd crashes so hard that it cannot send
    startphase information to the angel, the crash is always treated
    as a startup failure. Added a check to execute startup failure
    handling only if a valid startphase has been received from the
    client.

[33mcommit 71443c82cd019eaae0fbcc342c5c4b8474b2dc75[m
Author: Martin Sköld <Martin.Skold@oracle.com>
Date:   Thu Dec 8 09:55:14 2016 +0100

    Bug#25056856 NDB_RPL_DIST_PRIV FAILS
    
    The failures seem to be due to strict sql_mode checks for [1;31mtime[mstamp values.
    Relaxing sql_mode while running the stored procedures. This is similar to
    what is done when the tables are created during installation process.
    The sql_mode is here however set to not alllow running procedures if ndb
    is not configured (no default substition of storage engine).

[33mcommit 2a15a72996d27f7d3158b7e6fa3a4564a72f7e18[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Thu Nov 3 00:01:10 2016 +0100

    Bug#25047951 ADD BUILD TIME CHECK THAT MYSQL_SYSTEM_TABLES.SQL MATCH OUTPUT OF NDBINFO_SQL
    
    Problem:  The ndbinfo part of mysql_system_tables.sql should match the
              output of ndbinfo_sql if build with ndbcluster.
    
              Currently there are no build [1;31mtime[m enforcement of this and
              mysql_system_tables.sql and ndbinfo_sql have diverged.
    
              This can cause confusion and failures when ndbinfo is used
              since mysql_system_tables.sql might not be updated
              accordingly to ndbinfo_sql.
    
    Solution: If build with ndbcluster mysql_system_tables.sql will be patched
              into a new file using the output of ndbinfo_sql.  Then the
              original and patched mysql_systen_tables.sql will be compared
              and if not equal build will fail.  And developer are forced to
              take action to make build succeed.

[33mcommit 3b73f56899719eaf397bb85635aecee84702b78d[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Fri Nov 11 10:01:50 2016 +0100

    Bug#24909223: EXCESSIVE MEMORY USAGE BY QUERY
    
    Problem: A block nested loop some[1;31mtime[ms allocates a new record buffer
    each [1;31mtime[m it restarts reading of the inner table. Since the record
    buffers are not freed until the executing statement has completed,
    this leads to growing memory usage during the execution of the query.
    
    Fix: When reopening a handler that has already allocated a record
    buffer earlier in the same statement, reuse the previously allocated
    buffer instead of allocating a new one.

[33mcommit b0aceff637ca1757cf3959ab646735d9cc4ed896[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Thu Nov 3 00:01:10 2016 +0100

    Bug#25047951 ADD BUILD TIME CHECK THAT MYSQL_SYSTEM_TABLES.SQL MATCH OUTPUT OF NDBINFO_SQL
    
    Problem:  The ndbinfo part of mysql_system_tables.sql should match the
              output of ndbinfo_sql if build with ndbcluster.
    
              Currently there are no build [1;31mtime[m enforcement of this and
              mysql_system_tables.sql and ndbinfo_sql have diverged.
    
              This can cause confusion and failures when ndbinfo is used
              since mysql_system_tables.sql might not be updated
              accordingly to ndbinfo_sql.
    
    Solution: If build with ndbcluster mysql_system_tables.sql will be patched
              into a new file using the output of ndbinfo_sql.  Then the
              original and patched mysql_systen_tables.sql will be compared
              and if not equal build will fail.  And developer are forced to
              take action to make build succeed.

[33mcommit 7fe09ace0c1f0869d08c0dd140d5d0bd66003560[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Wed Oct 12 11:28:08 2016 +0200

    WL#9609: Replace DataBuffer with DataBuffer2.
    
    Note, release() will now release each segment at a [1;31mtime[m instead of all at one using releaseList for ArrayPool.
    
    Also Segment now also includes a magic word.
    
    In debug in_use are added for DataBuffer2 as in DataBuffer.
    
    Some code updates moved from DataBuffer to DataBuffer2.
    
    Remove implicit use of ArrayPool for DataBuffer
    
    Remove implicit of ArrayPool for LocalDataBuffer

[33mcommit 8e257e76a8b5798729fb111bb78cd4cf26980e2b[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Nov 29 12:48:57 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Microoptimize and simplify utf8mb4 parsing:
    
     - Use regular AND masks and comparisons instead of xor-ing away
       the continuation bits. GCC rewrites the xor-and-comparison tests
       to wrapping adds, which are not as easy to mix with shifts as
       ANDs are. (See also below.)
     - Use adds instead of ors, since these are equivalent and can
       some[1;31mtime[ms be rewritten as LEAs. (The compiler doesn't actually
       seem to do so in this case, though.)
     - When testing for multiple continuation bytes, read a larger
       chunk using memcpy and do all the comparisons at the same [1;31mtime[m.
       This would not be possible to do using the XOR trick.
     - When testing if we are outside the allowed range for a given number
       of UTF-8 bytes, simply test the resulting code point (after piecing
       it together) instead of doing complicated testing on each byte
       of the encoded form.
    
    In particular, this matters for three- and four-byte code points;
    one- and two-byte are generally unchanged, and ASCII is of course
    taken by the UCA scanner fast path anyway. Add a new microbenchmark
    consisting exclusively of Japanese (which is represented mainly
    using three-byte code points) to highlight the differences.
    
    Also unify the many different UTF-8 parsing routines that we have.
    
    Microbenchmarks (Skylake 3.4 GHz, 64-bit, GCC 6.2):
    
      BM_SimpleUTF8                328 -> 334 ns/iter [ -1.8%]
      BM_UTF8MB4StringLength        47 ->  47 ns/iter [  0.0%]
      BM_SimpleUTF8MB4             142 -> 142 ns/iter [  0.0%]
      BM_MixedUTF8MB4              197 -> 188 ns/iter [ +4.8%]
      BM_MixedUTF8MB4_AS_CS        643 -> 576 ns/iter [+11.6%]
      BM_JapaneseUTF8MB4           663 -> 542 ns/iter [+22.3%]
      BM_NewlineFilledUTF8MB4      171 -> 172 ns/iter [ -0.6%]
      BM_HashSimpleUTF8MB4         306 -> 306 ns/iter [  0.0%]
    
    sysbench results are neutral, since they don't test anything
    but ASCII.
    
    Change-Id: I57a72abf69d1b636d2224a1f6e0ebb1aa196296e

[33mcommit 0df79d4fda7916811d76deaeaedf1a3046505507[m
Author: V S Murthy Sidagam <venkata.sidagam@oracle.com>
Date:   Wed Nov 30 13:15:38 2016 +0530

    Bug #24343582 ASSERT: TRX_IS_REGISTERED_FOR_2PC(TRX) ON INSTALL COMPONENT
                  WITH LOG-BIN ENABLED
    Description:
    The below assertion failure is encountered while trying
    to install an example component as in the MTR test
    'main.component' on a server with binary logging enabled
    in row mode (please note that the assertion is not hit when
    the binlog format is mixed or statement).
    [ERROR] InnoDB: Assertion failure:
    ha_innodb.cc:17586:trx_is_registered_for_2pc(trx)
    
    Analysis:
    The m_ha_list is getting set by value 2, first [1;31mtime[m through
    open_component_table() and the second [1;31mtime[m through call
    handler::ha_write_row() in mysql_persistent_dynamic_loader_imp::load().
    Because of that at the [1;31mtime[m of ha_commit_trans() the
    m_scope_info[scope].m_rw_ha_count is having 2, which is not in
    the case of plugins.
    
    Fix:
    
    plugin code do call tmp_disable_binlog() before
    ha_write_row()/ha_delete_row().
    so similaly we need to call tmp_disable_binlog() in components code.

[33mcommit 4880f977236b5a33acc531bf420d503f9832781b[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Tue Nov 29 15:46:27 2016 +0100

    WL#883 non-recursive CTE
    WL#3634 recursive CTE
    
    As single patch. Adds support for:
    
     WITH query_name AS (subquery)
     SELECT * FROM query_name;
    and
     WITH RECURSIVE query_name AS (recursive subquery)
     SELECT * FROM query_name;
    
    The objects introduced after WITH are called "common table
    expressions" (CTEs). There can be several, separated with ','.
    A CTE can reference CTEs defined before it in the WITH list.
    A CTE is materialized or merged, which can be influenced with the
    Merge/No_merge hint.
    A CTE can be referenced multiple [1;31mtime[ms in the query; if it's
    materialized it's materialized only once in the query.
    
    Specific of WITH RECURSIVE:
    'recursive subquery' must be
    of the form
    SELECT ... UNION [ALL] ... SELECT ... etc
    where the union is formed of a head of SELECTs which don't reference
    query_name (are non-recursive) followed by a tail of SELECTs which
    reference it. UNION DISTINCT and UNION ALL can be used. This allows
    traversing trees, hierarchies, finding transitive closures, computing
    numbers recursively, applying algorithms...
    
    CTEs can be defined in SELECT, UPDATE, DELETE, INSERT SELECT, REPLACE
    SELECT, CREATE SELECT, CREATE VIEW.
    
    After 'query_name' one can specify column names in parentheses:
    WITH query_name(a,b) AS...
    Such feature is also added to derived tables i.e.
    FROM (SELECT ...) AS dt(a,b)
    Such feature already existed for views but is rewritten (it had a bug,
    see at the end); to support this rewrite, a column VIEW_COLUMN_NAMES
    is added to the TABLES table of the Data Dictionary; this will prevent
    on-the-fly upgrades from 8.0.0 to 8.0.1, which mgmt has approved.
    
    Like derived tables:
    - a CTE may not reference an outer table
    - functional dependencies in (non-recursive) CTEs are recognized.
    - relevant indexes are automatically added to the materialized CTE if the
    Optimizer thinks that they will speed up the top query's access to the CTE.
    
    Also fixes:
    Bug#23265335 SPECIFYING A NAME FOR VIEW'S COLUMN IN CREATE VIEW MAKES SELECT
    FAIL
    Bug#23024178 WRITES TO INNODB INTERNAL TEMPORARY TABLE DOESN'T INCREASE
    "HANDLER_WRITE"
    
    Partially fixes:
    BUG#23022426 UNION ALL STILL USES TEMPORARY TABLE WITH INSERT SELECT
    i.e. with this WL, UNION ALL doesn't create a temporary table with
    INSERT SELECT iff the UNION ALL is not the top query expression after
    INSERT (i.e. is a subquery).

[33mcommit aa1d5e96db3e1fcaed5ec7cbabfcae21f1df07a2[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Fri Nov 25 13:09:21 2016 +0100

    Bug#25152435: MOVE CLIENT/SERVER INDEPENDENT FILES FROM SQL-COMMON TO MYSYS
    
    Move my_user.c, my_[1;31mtime[m.c and pack.c from sql-common/ to mysys/
    These files do not need to be compiled separately for client
    and server and can therefore be part of the mysys library
    and be compiled only once.
    
    Also change them from .c to .cc so that C++ can be used for
    future changes in these files.

[33mcommit 4bf48e8bf0d572fafc0349a3d7e9376b781a1302[m
Author: Oystein Grovlen <oystein.grovlen@oracle.com>
Date:   Fri Nov 25 13:32:20 2016 +0100

    WL#8737 IO aware defaults for optimizer cost constants
    
    Update default values for optimizer cost constants. New values are:
    
      row_evaluate_cost             0.1
      key_compare_cost              0.05
      memory_temptable_create_cost  1.0
      memory_temptable_row_cost     0.1
      disk_temptable_create_cost    20.0
      disk_temptable_row_cost       0.5
      memory_block_read_cost        0.25
      io_block_read_cost            1.0
    
    Changes to source files:
    
    sql/opt_costconstants.cc
      Changed default values for cost constants.
    sql/sql_select.h
      Change type of JOIN_TAB::read_[1;31mtime[m from ha_rows to double since cost may now
      be lower than 1.
    sql/sql_optimizer.cc
    sql/sql_select.cc
      Removed casts when assigning to/from JOIN_TAB::read_[1;31mtime[m
    unittest/gunit/opt_costconstants-t.cc
      Updated unit tests to use new values for cost constants
    
    Changes in tests:
    
    mysql-test/include/join_cache.inc
      Added more data in one table to preserve original query plan.
    mysql-test/include/mix1.inc
      Added more data in in two tables to preserve original query plan.
    mysql-test/r/count_distinct.result
      User variable changed because plans go from BNL to ref access
    mysql-test/t/dd_is_compatibility.test
    mysql-test/r/dd_is_compatibility.result
    mysql-test/r/dd_is_compatibility_ci.result
      Lowered setting of max_join_size to make sure test still get ER_TOO_BIG_SELECT
    mysql-test/r/delete.result
      Changed join order gives more warnings
    mysql-test/r/endspace.result
      Query returned result in different order, re-recorded.
    mysql-test/r/explain.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_rqg_json.result
      Change in two query plans, updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_rqg_trad.result
      Change in one query plan, updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_small_json.result
    mysql-test/r/explain_for_connection_small_trad.result
      One query changes from table scan to ref access, due to magic constants
      added when calculating cost for tables scan. Two queries changes from
      index scan to ref access due to lower cost of doing ref access. Updated cost
      numbers in EXPLAIN JSON.
    mysql-test/r/explain_json_all.result
      Re-recorded new query plan for one query since it no longer tested
      what the original test was for. Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_json_none.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/explain_other.test
    mysql-test/r/explain_other.result
      Added more data to one table in order to preserver original query plan.
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/func_concat.result
      Changed from table scan with BNL to eq_ref access.
      The new plan is identical to the plan when the test case was added.
    mysql-test/r/greedy_optimizer.result
      Several queries got new query plan. All new query plans resulted in a
      lower number of Handler_reads. Updated Last_query_cost numbers.
    mysql-test/r/greedy_search.result
      No changes in query plans but the number of partial plans evaluated
      was changed for several queries.
    mysql-test/r/group_by.result
      Changed from table scan with BNL to ref access
    mysql-test/r/group_min_max.result
      Four queries changes from doing index scan to use range scan due to
      range scan becoming cheaper with all data in memory buffer.
    mysql-test/r/heap_hash.result
      One query changes from using join buffer to use ref access for join.
      This is what the original test used, accepted new plan.
    mysql-test/r/index_merge_innodb.result
      One query changes from ref to range. This is caused by using DS-MRR for the
      range scan. Updated cost numbers in EXPLAIN JSON.
    mysql-test/include/index_merge_intersect_dml.inc
    mysql-test/r/index_merge_intersect_dml.result
      One query changed from doing range scan on primary key to range scan on
      secondary key. Changed query to switch back to use primary key.
    mysql-test/r/index_merge_myisam.result
    mysql-test/r/innodb_explain_json_non_select_all.result
    mysql-test/r/innodb_explain_json_non_select_none.result
    mysql-test/r/internal_tmp_disk_storage_engine.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/join.test
    mysql-test/r/join.result
      Query plan changes for two queries. First fixed by increasing the range
      interval in the query. The second query changes from table scan to
      eq_ref for one table, re-recorded new query plan. Updated Last_query_cost
      numbers.
    mysql-test/r/join_cache_bka.result
      Four queries changes from using BNL to use BKA/ref access.
    mysql-test/r/join_cache_bka_nixbnl.result
      One query changes from table scan to BKA/ref access.
      One query changes join order
    mysql-test/r/join_cache_bkaunique.result
      Four queries changes from using BNL to use BKA-unique/ref access.
    mysql-test/r/join_cache_bnl.result
      Four queries changes from using BNL to use ref access due to ref access
      becoming cheaper with all data in a memory buffer.
    mysql-test/r/join_cache_nojb.result
      Changed join order for one query due to ref access becomming relatively
      less costly compared to table scan when all data is in a memory buffer.
    mysql-test/r/join_outer.result
      Changes in order of results from a few queries, re-recorded. Updated cost
      numbers in EXPLAIN JSON.
    mysql-test/r/join_outer_bka.result
    mysql-test/r/join_outer_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/key.result
      Updated Last_query_cost numbers.
    mysql-test/r/key_diff.result
      One query changes from using join buffering to ref access. The new plan
      has also been accepted as plan for this query before, so just use it.
    mysql-test/r/myisam.result
      One query changes from table scan to range scan, likely due to use of
      magic constants when calculating cost of table scan.
    mysql-test/r/myisam_explain_json_non_select_all.result
    mysql-test/r/myisam_explain_json_non_select_none.result
      Updated cost numbers in EXPLAIN JSON plus two rows estimates in explain.
    mysql-test/r/myisam_icp.result
    mysql-test/r/myisam_icp_all.result
    mysql-test/r/myisam_icp_none.result
      Changes to query plans for two bugs that was reported for InnoDB.
      Accepted changes since the plan is still the same when run with
      InnoDB.
    mysql-test/t/opt_costmodel.test
    mysql-test/r/opt_costmodel.result
    mysql-test/t/opt_costmodel_flush.test
    mysql-test/r/opt_costmodel_flush.result
      Updated to use new cost numbers, updated result files.
    mysql-test/r/opt_costmodel_restart.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/opt_hints.result
      Changes from ref access to range access. Does not affect purpose of test
    mysql-test/t/opt_hints_subquery.test
    mysql-test/r/opt_hints_subquery.result
      A lot of changes to explain output:
      -Most of the changes are from using join buffer to ref access (ok)
      -Some changes are in join order (ok)
      -Some changes are in semijoin strategy; adjusted test cases so hints
       are used according to original purpose of tests.
    mysql-test/r/order_by_all.result
    mysql-test/r/order_by_icp_mrr.result
    mysql-test/r/order_by_none.result
      Two queries joining three tables changes join order. The new query plans are
      equal to earlier query plans, so no attempt on reproducing current query
      plans.
    mysql-test/r/partition.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/partition_locking.test
    mysql-test/r/partition_locking.result
      Many queries changed from doing index scan to range scan. Adjusted
      the queries to use index scan. For the last query, the plan change
      is accepted since it is the same as the initial query plan.
    mysql-test/t/partition_pruning.test
    mysql-test/r/partition_pruning.result
      Two queries changed from table scan to range scan. Adjusted queries
      to produce same plan.
    mysql-test/r/range_all.result
    mysql-test/r/range_icp.result
    mysql-test/r/range_icp_mrr.result
    mysql-test/r/range_mrr.result
    mysql-test/r/range_mrr_cost.result
    mysql-test/r/range_none.result
    mysql-test/r/range_with_memory_limit.result
      Change in three query plans. The first is due to range scan becoming cheaper
      than table scan, and join buffering is no longer considered. The two last is
      Change in join order due to differences in cost estimate for ref access
      versus join buffering. The new plan is more similar to initial plan for
      these two queries.
    mysql-test/include/select.inc
    mysql-test/r/select_all.result
    mysql-test/r/select_all_bka.result
    mysql-test/r/select_icp_mrr.result
    mysql-test/r/select_icp_mrr_bka.result
      Two identical queries switches from using join buffering to use ref access.
      Change accepted since ref access was the original join method for these
      queries.
    mysql-test/r/select_none.result
    mysql-test/r/select_none_bka.result
    mysql-test/r/select_none_bka_nixbnl.result
      In addition to the two queries above, a third query changes from table
      scan to range scan due to range access is cheaper with all data in memory.
      Accepted new plan since range scan was the origianal plan when the bug
      was first fixed.
    mysql-test/r/select_all_bka_nixbnl.result
    mysql-test/r/select_icp_mrr_nixbnl.result
      Updated result file after adding sorted_result for two queries in select.inc
    mysql-test/t/select_safe.test
    mysql-test/r/select_safe.result
      Adjusted value for max_join_size to make query fail.
    mysql-test/t/single_delete_update.test
    mysql-test/r/single_delete_update.result
      Two limit queries changed from doing file sort to using index. The
      test assumed that is should use filesort, so increased the limit to
      produce original query plan. Needed to adjust some other parts of
      the test due to this.
    mysql-test/r/status.result
      Updated Last_query_cost numbers.
    mysql-test/r/subquery_all.result
    mysql-test/r/subquery_all_bka.result
      Five queries have changes in query plans:
      -Change from using join buffer to ref access due to ref access is less costly
       with all data in memory buffer.
      -Join order changes due to minor changes in cost estimates, the new
       plan is identical to a former plan for this query.
      -Last three queries change from using join buffering to use ref access
       due to ref access is less costly with data in memory. The query plan for
       these queries has changed several [1;31mtime[ms so no effort on reproducing
       original plan.
    mysql-test/r/subquery_all_bka_nixbnl.result
      Join order changes for one query due to minor changes in cost estimates,
      the new plan is identical to a former plan for this query.
    mysql-test/r/subquery_mat_all.result
      Several queries changes from using DuplicateWeedout to FirstMatch due
      to the cost of FirstMatch reading data is now lower compared to using
      the temporary table. The query plan for these queries have changed
      several [1;31mtime[ms so no attempt on reproducing original query plan.
    mysql-test/r/subquery_nomat_nosj.result
    mysql-test/r/subquery_nomat_nosj_bka.result
    mysql-test/r/subquery_none.result
    mysql-test/r/subquery_none_bka.result
      Join order changes for two queries due to minor changes in cost estimates.
    mysql-test/r/subquery_nomat_nosj_bka_nixbnl.result
    mysql-test/r/subquery_none_bka_nixbnl.result
      Join order change for one query due to minor changes in cost estimates.
    mysql-test/r/subquery_sj_all.result
    mysql-test/r/subquery_sj_all_bka.result
    mysql-test/r/subquery_sj_all_bka_nixbnl.result
    mysql-test/r/subquery_sj_all_bkaunique.result
      About 25 queries has changes in query plans:
      -Materialization to FirstMatch: FirstMatch becomes cheaper due to the
       cost of reading the data when it is in memory is now lower
      -Materialization to DupsWeedOut: Some of the changes are due to
       materialization and dupsweedout having the exact same cost and the change
       is caused by rounding errors. In a few cases, the cost of DupsWeedOut
       is now lower than Materialization.
      -DupsWeedout to FirstMatch: FirstMatch benefits more from having all
       data in a memory buffer
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer
    mysql-test/r/subquery_sj_dupsweed.result
    mysql-test/r/subquery_sj_dupsweed_bka.result
    mysql-test/r/subquery_sj_dupsweed_bka_nixbnl.result
    mysql-test/r/subquery_sj_dupsweed_bkaunique.result
      A few queries have changes in query plan, no changes in semi-join strategy:
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
    mysql-test/r/subquery_sj_firstmatch.result
    mysql-test/r/subquery_sj_firstmatch_bka.result
    mysql-test/r/subquery_sj_firstmatch_bkaunique.result
      A few queries have changes in query plan, no change in semi-join strategy:
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
    mysql-test/r/subquery_sj_firstmatch_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/subquery_sj_loosescan.result
    mysql-test/r/subquery_sj_loosescan_bka.result
    mysql-test/r/subquery_sj_loosescan_bka_nixbnl.result
    mysql-test/r/subquery_sj_loosescan_bkaunique.result
      A few queries have changes in query plan, no change in semi-join strategy:
      -Join order: due to changes in cost estimates, verified that current
       plan is not the same as origianal plan, so just re-recorded.
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
    mysql-test/r/subquery_sj_mat.result
    mysql-test/r/subquery_sj_mat_bka.result
    mysql-test/r/subquery_sj_mat_bka_nixbnl.result
    mysql-test/r/subquery_sj_mat_bkaunique.result
      A few queries have changes in query plan:
      -Join order: due to changes in cost estimates, verified that current
       plan is not the same as origianal plan, so just re-recorded.
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
      -One query changes from MaterializeLookup to MaterializeScan.
    mysql-test/r/subquery_sj_mat_nosj.result
      A few queries change from using join buffer to use eq_ref or ref:
      eq_ref and ref get a lower cost when all data is in a memory buffer. This
      causes changes to join order.
    mysql-test/r/subquery_sj_none.result
    mysql-test/r/subquery_sj_none_bka.result
    mysql-test/r/subquery_sj_none_bkaunique.result
      One query changes from using join buffer to use eq_ref or ref:
      eq_ref and ref get a lower cost when all data is in a memory buffer. This
      causes changes to join order.
    mysql-test/r/subquery_sj_none_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/type_blob.result
      Change from ALL to ref_or_null.  Back to plan before switch to InnoDB
    mysql-test/r/type_ranges.result
      Order of warnings changed for an INSERT INTO SELECT statement likely due
      to plan change. Re-recorded result file.
    mysql-test/r/user_var.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/engines/iuds/r/insert_calendar.result
    mysql-test/suite/engines/iuds/t/insert_calendar.test
      Different plans for MyISAM and InnoDB caused different number of warnings.
      Changed start date for range for query to avoid warnings for zero date.
    mysql-test/suite/gcol/inc/gcol_ins_upd.inc
    mysql-test/suite/gcol/r/gcol_ins_upd_innodb.result
    mysql-test/suite/gcol/r/gcol_ins_upd_myisam.result
      Added sorted_result to some queries to handle that the order of the
      result changes. This happened for the MyISAM test, the InnoDB test
      had the same order.
    mysql-test/suite/gcol/r/gcol_keys_innodb.result
    mysql-test/suite/gcol/r/gcol_keys_myisam.result
      Changed plans from table scan to index usage
    mysql-test/suite/gcol/r/gcol_select_myisam.result
      One query changes join order and switches from join buffering to ref
      access.
    mysql-test/suite/gcol/r/gcol_select_innodb.result
      One query changes from using join buffering to do ref access. This is
      caused by table scan becoming relatively more costly compared to ref
      access.
    mysql-test/suite/innodb/t/innodb_mysql.test
    mysql-test/suite/innodb/r/innodb_mysql.result
      Added extra rows to a few tables to preserve original query plan.
    mysql-test/suite/innodb/include/query_workload_itt.inc
    mysql-test/suite/innodb/r/optimizer_temporary_table.result
      Cost estimates of EXPLAIN JSON was unstable since one table was not used
      for a while and some[1;31mtime[ms its pages was flushed from buffer pool.
      Added a query that does a table scan to ensure that pages are in buffer pool.
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/innodb_gis/r/create_spatial_index.result
    mysql-test/suite/innodb_gis/r/rtree.result
    mysql-test/suite/innodb_gis/r/rtree_multi_pk.result
      Changes in query plans from full table/index scan to range scan
      Queries will now actually use a spatial index
    mysql-test/suite/innodb/r/temporary_table.result
    mysql-test/suite/innodb/r/temporary_table_optimization.result
    mysql-test/suite/innodb_zip/r/wl6469.result
    mysql-test/suite/innodb_zip/r/wl6560.result
      A few queries changes from table scan to range scan due to use of magic
      constants in the cost model for table scan.
    mysql-test/suite/innodb_fts/r/opt.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/json/r/json_agg.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/opt_trace/r/bugs_no_prot_all.result
    mysql-test/suite/opt_trace/r/bugs_ps_prot_all.result
      Updated cost estimate numbers in optimizer trace output.
      There are a few minor changes in the optimizer trace output
      and a few plan changes.
    mysql-test/suite/opt_trace/r/bugs_no_prot_none.result
    mysql-test/suite/opt_trace/r/bugs_ps_prot_none.result
    mysql-test/suite/opt_trace/r/fulltext.result
    mysql-test/suite/opt_trace/r/general2_no_prot.result
    mysql-test/suite/opt_trace/r/general2_ps_prot.result
    mysql-test/suite/opt_trace/r/general_no_prot_none.result
    mysql-test/suite/opt_trace/r/general_ps_prot_none.result
    mysql-test/suite/opt_trace/r/range_no_prot.result
    mysql-test/suite/opt_trace/r/range_ps_prot.result
      Updated cost estimate numbers in optimizer trace output.
      There are a few tiny minor change in the optimizer trace output.
    mysql-test/suite/opt_trace/r/charset.result
    mysql-test/suite/opt_trace/r/eq_range_statistics.result
    mysql-test/suite/opt_trace/r/filesort_pack.result
    mysql-test/suite/opt_trace/r/filesort_pq.result
    mysql-test/suite/opt_trace/r/general_no_prot_all.result
    mysql-test/suite/opt_trace/r/general_ps_prot_all.result
    mysql-test/suite/opt_trace/r/subquery_no_prot.result
    mysql-test/suite/opt_trace/r/subquery_ps_prot.result
    mysql-test/suite/opt_trace/r/temp_table.result
      Updated cost estimate numbers in optimizer trace output.
    mysql-test/suite/opt_trace/r/security_no_prot.result
    mysql-test/suite/opt_trace/r/security_ps_prot.result
      Updated length numbers for optimizer trace output.
    mysql-test/suite/parts/r/partition_icp.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/sysschema/r/pr_statement_performance_analyzer.result
      Changed query plans give different number for rows_examined
    mysql-test/suite/sys_vars/r/max_join_size_func.result
    mysql-test/suite/sys_vars/r/sql_big_selects_func.result
    mysql-test/suite/sys_vars/t/max_join_size_func.test
    mysql-test/suite/sys_vars/t/sql_big_selects_func.test
      Reduced value for max_join_size to make queries fail with new cost constants.
    mysql-test/suite/test_service_sql_api/r/test_sql_stmt.result
      Changed result order due to different access method
    mysql-test/suite/i_main/r/bug18932813.result
    mysql-test/suite/i_main/r/derived.result
    mysql-test/suite/i_main/r/explain_json.result
    mysql-test/suite/i_main/r/group_by.result
    mysql-test/suite/i_main/r/partition_icp.result
    mysql-test/suite/i_main/r/subquery_mat_cost_based.result
    mysql-test/suite/i_main/r/view.result
      Updated cost numbers in EXPLAIN JSON.
    .../mysql-test/suite/i_main/r/bug22671573.result
      Plan changed from table scan to range scan.
      Verified that test case still reproduce the original bug.
    .../mysql-test/suite/i_main/r/costmodel_planchange.result
      Adjust queries to still identify plan changes
    .../mysql-test/suite/i_main/t/insert.test
    .../mysql-test/suite/i_main/r/insert.result
      Added data to keep same query plan
    .../mysql-test/suite/i_main/t/subquery-bug22262843.test
    .../mysql-test/suite/i_main/r/subquery-bug22262843.result
      Added a row so that subquery materialization is still used.
    .../mysql-test/suite/i_main/t/subquery.test
    .../mysql-test/suite/i_main/r/subquery.result
      Added data to keep on query plan
      Some changes from table scan (with BNL) to ref access
      Some semijoin strategy changes that seems reasonable
    .../mysql-test/suite/i_opt_trace/include/bugs.inc
      Added analyze table to make test stable
    .../mysql-test/suite/i_opt_trace/r/bugs_no_prot.result
    .../mysql-test/suite/i_opt_trace/r/bugs_ps_prot.result
    .../mysql-test/suite/i_opt_trace/r/query_cache_trace.result
      Updated cost numbers in EXPLAIN JSON.
    .../mysql-test/suite/i_opt_trace/r/refaccess_trace.result
      One query plan goes from table scan to eq_ref
      Updated cost numbers in EXPLAIN JSON.
    
    Implemented by Olav Sandstå

[33mcommit 96abf0bd1b56b0d29acc2376d27df31610f1142c[m
Author: Arnab Ray <arnab.r.ray@oracle.com>
Date:   Fri Nov 25 16:55:38 2016 +0530

    WL#8500 Adapt MySQL Cluster to 8.0
    
    - Fix another build error on linux-x86-64bit-asan
      Fix a memory leak asan reported. This pops up at
      compile [1;31mtime[m itself since this particular binary,
      ndbinfo_sql, is run to create ndbinfo.sql

[33mcommit 078553fef87bacd89c4afee4a57344d79f8d926f[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Nov 21 16:27:20 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    We have a syntax WEIGHT_STRING(foo AS CHAR(n)), but exactly what n means
    is undocumented; it truncates or pads foo based on _something_, but it is
    very unclear what.
    
    The parameter was named “nweights”, but ignorables (having no weights)
    would count as 1, contractions (having one weight) some[1;31mtime[ms as 1
    (prefix contractions) and some[1;31mtime[ms as the real number of code points
    (postfix contractions), and expansions (having multiple weights) always
    as the real number of code points, ie., typically 1. And this is only
    UCA collations -- some collations (e.g. cp1250) just ignore the parameter
    altogether and never truncate, and some collations (e.g. tis620)
    truncate the output string instead of the input string.
    
    This is not useful behavior. Since WEIGHT_STRING() is an internal debugging
    function which doesn't change on-disk format, we can modify its meaning,
    so change it to mean number of code points unconditionally, which is what
    CHAR(n) means everywhere else. (Probably, CHAR(n) should mean graphemes,
    but this would require extensive changes everywhere, including in the storage
    layer.) The documentation should be updated accordingly.
    
    Similarly, Field_string::make_sort_key (used for CHAR(n), although not
    VARCHAR(n)) would assume strnxfrm truncated, so we could potentially output
    junk bytes in the sort key without really noticing.
    
    This is a prerequisite for dropping char_index for UCA 9.0.0 scanners,
    which don't need this information for anything except truncation.
    
    Change-Id: I07e24a1609d5cc70dbb78e1cd61825bda4658fee

[33mcommit fe5d218e891374acaf5bdda9e956c3e46cebef89[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Thu Nov 24 10:19:03 2016 +0530

    BUG#20694384 : TEST TIMEOUT BUT NO STACK TRACE ON WINDOWS
    
    Description :
    =============
    When a test [1;31mtime[ms out, MTR generates stack trace in order to
    debug the issue. We usually get this on Linux, but apparently
    not on Windows.
    
    Except when the test is too slow, a [1;31mtime[mout is most likely due
    to a deadlock. A stack trace would help to find out. With no
    stack trace it's impossible to analyze the bug.
    
    Issue :
    =======
    When a test [1;31mtime[ms out, on linux kill() command with ABRT signal
    is issued to the server process which will cause it to generate
    memory dump.
    
    Due to the limitation of perl and signal handling in windows, no
    signal is sent to the server process and no dump file is generated.
    
    Fix :
    =====
    On windows, when a test [1;31mtime[ms out 'cdb' tool is used to generate
    the dump file for server process, but there is a high risk of MTR
    hanging by calling external programs like 'cbd' in multi-threaded
    runs(i.e $parallel > 1). Currently patch is made to work with
    parallel value 1 only.
    
    Reviewed-by: Bjorn Munch <bjorn.munch@oracle.com>
    Reviewed-by: Srikanth B R <srikanth.b.r@oracle.com>
    RB: 14236

[33mcommit cd8957803411dddaa8de2b25f6a51bd8ecef7853[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Nov 18 13:11:49 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Unroll the ASCII fast path to check four bytes at a [1;31mtime[m. This is a tradeoff;
    we lose out on the cases where we have four-byte blocks with mixed ASCII/non-ASCII
    (e.g. in text with mostly ASCII but some accents) and on some relatively common
    ASCII code points outside the 0x20..0x7e range, such as newlines.
    
      BM_SimpleUTF8MB4          232 -> 146 ns/iter  [+58.9%]
      BM_MixedUTF8MB4           230 -> 276 ns/iter  [-16.7%]
      BM_MixedUTF8MB4_AS_CS     759 -> 828 ns/iter  [ -8.3%]
      BM_NewlineFilledUTF8MB4   123 -> 231 ns/iter  [-46.8%]
      BM_HashSimpleUTF8MB4      299 -> 306 ns/iter  [ -2.3%]
    
    Change-Id: I64dc2fa06482809cc2e530f2434e5c8890a4edb2

[33mcommit 825d2f17b5a8da202a6575c73e5d93eeaa2ef729[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Nov 18 12:54:25 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    When copying variable-length multibyte strings around, don't bother counting up
    all the characters if there's guaranteed to be no truncation anyway.
    This takes about 2.2% of CPU [1;31mtime[m in sysbench with utf8mb4 with
    --oltp-use-varchar-for-char. (This is too small of a difference that I can
    reliably measure it in my local sysbench runs, but I've run perf and verified
    that my_well_formed_len_utf8mb4 disappears from the profile.)
    
    Change-Id: I86c9054a5bbcc8c9f2c6151d5dbcfb90b8258d22

[33mcommit 744098bdee06b2dd77174ec6937089defe2a596d[m
Author: Srikanth B R <srikanth.b.r@oracle.com>
Date:   Mon Nov 14 15:01:58 2016 +0530

    Bug#24967869 MTR: SOME TESTS RUN ONCE EVEN IF THEY ARE GIVEN
                 MULTIPLE TIMES ON COMMAND LINE
    Issue
    -----
    A test from a non-default suite (or from a suite not present in
    those given with the --suite(s) option) runs once even if it is
    specified multiple [1;31mtime[ms on the MTR command line.
    
    Fix
    ---
    All test cases specified on the command line are collected as is,
    even if a test is specified multiple [1;31mtime[ms.
    
    The patch also includes a follow-up to Bug#24904659 to avoid MTR
    printing the message "sysctl: unknown oid 'machdep.cpu'" to its
    console on FreeBSD.
    
    Reviewed-by: Pavan Naik <pavan.naik@oracle.com>
    RB: 14511

[33mcommit 81f5784b4e32a18545eb302ea268e4a088d64bb0[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Wed Nov 16 14:51:02 2016 +0800

    Bug #22607168  ASAN: MEMORY LEAK IN CONNECT_TO_MASTER()
    
    Build with clang and -DWITH_ASAN=1 on vilma51.no.oracle.com, the
    problem can not be reproduced after repeating the following tests
    10000 [1;31mtime[ms with the --sanitize MTR option:
    rpl.rpl_row_001
    rpl.rpl_row_reset_slave
    rpl.rpl_stm_reset_slave
    rpl.rpl_stm_000001
    rpl.rpl_slave_status
    rpl.rpl_stm_mixed_mts_rec_crash_safe_small
    
    So remove these tests from mysql-test/collections/disabled-asan.list.

[33mcommit 6dec2d04761977e0537df81a24fae8e9e59ac80e[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Tue Nov 15 08:56:14 2016 -0600

    Bug #24462978: Free up 32 slots in TRX_SYS page for non-temp rsegs
    
    This is a preliminary patch for
    WL#6966-InnoDB: Flexible UNDO tablespace management
    
    There are 32 slots in the TRX_SYS page that are not being used.
    The slot numbers are reserved for rseg_ids of rollback segments
    in the temporary tablespace. The space_id & page number of these
    rollback segments will never be stored persistently.
    
    In this patch, these slots are moved to a separate in-memory array of
    rsegs so that these 32 slots in TRX_SYS can be used for durable
    rollback segments.
    
    This is a nonfunctional change which allows parts of wl9507 to be reviewed
    and tested separately with the current set of test cases so that we can be
    confident that these changes are clean.
    
    So in addition to the new container for temporary rollback segments, this
    patch contains the following, some of which are explained in WL#9507
    
    * Add and improve comments for clarity.
    * Change the preferred terminology from 'undo_log' to 'rollback segment'
    when that is what it refers to. 'Undo log' has another meaning.
    * Use an std::vector as a container for undo tablespaces so that this list
    can grow and shrink without introducing array gaps. In wl#9507, the
    translation between an rseg_id from a rollback pointer to a space_id will
    be just a simple math function since the rseg_id will be a 7-bit number
    and the undo space_id will be a reserved range of tablespace IDs.
    * Use an std::vector as a container for trx_rseg_t objects consistently.
    The purge list is already using this kind of container.
    * Reorganize srv_undo_tablespace_init() so that it can be easily expanded
    in wl#9507 by putting various tasks into their own functions.
    * Combine the functions that build rollback segments.
    * Combine the effort to construct FSP headers and rollback segments after
    an undo tablespace is created, or fixed-up from a failed truncate. This will
    make it easier to upgrade undo tablespaces on startup and add rollback
    segments when needed. The undo::Truncate class used two different vectors of
    space_ids but those vectors can be combined because they never overlap in
    usage. One is at startup and the other is during run[1;31mtime[m.
    * Introduce the class undo::Tablespace to handle the just-in-[1;31mtime[m creation
    of undo_name and undo_file_name from a space_id.  This collects this
    repeated code to one location and reduces how often it is done. This will
    be expanded further in wl9507 to handle the conversion of an undo space_id
    to an undo space_num. It will also contain a vector of rseg objects for
    each undo tablespace.
    
    Approved by Thiru in RB#13164

[33mcommit a6f313d36fa3fda2b393ca0f9dde14ab56aa3fdd[m
Author: Ole John <ole.john.aske@oracle.com>
Date:   Fri Nov 11 13:44:27 2016 +0100

     Bug #25042101 SPLIT BINLOG INJECTOR_MUTEX IN TWO, DO REQUIRED CLEANUP
    
        Remove thread_yield() in binlog injector code previously put there
        as a temp stopgap in the commit below. This used to be required
        as the injector thread held the injector_mutex > 99% of the [1;31mtime[m when
        waiting for pollEvents(). That blocked client threads either wanting to
        access the data shared from the injector thread, or needing the injector_mutex
        while waiting for injector_cond to be signaled
    
        This should not be required anymore, as:
    
        1) injector_mutex has been splitt in two separate mutexes.
        2) We changed init of the injector_event_mutex from a 'FAST' to a 'SLOW'
           mutex which has better 'farness' properties in the scheduler
    
        This also reverts the patch:
    
        commit 000394fbe3a8d7a2945fb6b483024b77e16ab20a
        Author: Ole John Aske <ole.john.aske@oracle.com>
        Date:   Fri Jan 15 09:55:05 2016 +0100
    
            Follow up patch for performance regression introduced by patch for bug#20957068
    
            Introduce some sched_yield() in the binlog-thread loops where
            the injector_mutex is held >99% if the elapsed [1;31mtime[m. The yields
            let other threads waiting to be scheduled a chance to run,
            and grab the injector_mutex when not held by the binlog-thread.

[33mcommit 77c54e547df7a872468b5c1963dc53df0edbd06e[m
Author: Viswanatham Gudipati <viswanatham.gudipati@oracle.com>
Date:   Fri Nov 11 12:05:54 2016 +0530

    wl#9489 :
    
    problem: Some testcases (listed below), under main suite, running with MyISAM as a default storage engine,
    these testcases should be run with InnoDB only.
    
    1 ddl_i18n_koi8r.test
    2 func_regexp.test
    3 func_default.test
    4 func_concat.test
    5 group_by.test
    6 func_compress.test
    7 func_like.test
    8 func_test.test
    9 type_date[1;31mtime[m.test
    10 windows.test
    11 null_key_none.test
    12 create-big.test
    13 ctype_latin1_de.test
    14 error_simulation.test
    15 ddl_i18n_utf8.test
    
    Solution: Run the testcase with InnoDB as a default storage engine and check the failure testcase if exist,
    take any one of the following option.Modify the result file based on the analysis.Fix the testcases if problem exist in the testcase and record the result file look at the wl#5656 for steps how to fix
    
    Reviewed-by: Anitha Gopi (anitha.gopi@oracle.com)
                 Chaithra (chaithra.gopalareddy@oracle.com)
                 Amit (amit.bhattacharya@oracle.com)
    
    RB: 14226

[33mcommit fe3b67f5823b4251f0a6080bdbfbd0bae72ee0ac[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Mon Nov 7 17:00:32 2016 +0100

    Bug#25056933 SPLIT LIBSQL.A TO SAVE SOME BUILD TIME ON WINDOWS
    
    Put boost geometry code in a separate library,
    and don't export those symbols to plugins.
    
    This shaves off about two minutes of the build [1;31mtime[m.
    
    Change-Id: Idb89fffb97d4729bcec4d75dc27e51ff3186ff85

[33mcommit b6eaa811eaa0deec422ec5484e5aaaaeb9abb682[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Thu Nov 3 17:26:03 2016 +0100

    changes to ndb$tc_[1;31mtime[m_track_stats

[33mcommit fb40cb4305a86ce5d3fddd6dab72e2cff8326506[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Thu Nov 3 16:52:42 2016 +0100

    Add missing ndbinfo.tc_[1;31mtime[m_track_stats view to ndbinfo_sql.
    
    tc_[1;31mtime[m_track_stats was added with
    BUG#21889652: Introduce new tc_[1;31mtime[m_track_stats table tracking latency of user transactions/operations/scans

[33mcommit 5fafe79f975f8b9a212441bd426f3b3bfca8af2d[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Wed Nov 9 15:43:32 2016 +0100

    Bug#25040390 REMOVE UNUSED PARAMETER NAMES IN ITEM MEMBER FUNCTIONS
    
    Some virtual member functions of class Item are not using their
    parameters, preventing us from enabling compile-[1;31mtime[m warnings for
    unused parameters. C++ allows the names of unused parameter names
    to be omitted in function definitions.
    
    Reviewed-by: Knut Hatlen <knut.hatlen@oracle.com>

[33mcommit 879cd7d1292c6f798a9c59b593edaedfea5b60a6[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Wed Nov 9 15:51:20 2016 +0530

    BUG#24365145 : "COLLECTING TESTS" PART OF MTR IS SLOW AND RUNS ON A SINGLE THREAD
    
    Issue :
    =======
    It seems "Collecting tests" part of MTR runs for quite some [1;31mtime[m with
    multiple suites. MTR uses the single thread to collect the tests from
    all the suites. Maybe it's worth investing some [1;31mtime[m in making it run
    in parallel.
    
    Fix :
    =====
    Spawn multiple threads to collect the tests from different test suites.
    Number of threads running/active at any [1;31mtime[m shouldn't exceed the number
    of CPUs in the machine.
    
    Reviewed-by: Bjorn Munch <bjorn.munch@oracle.com>
    Reviewed-by: Deepa Dixit <deepa.dixit@oracle.com>
    RB: 13788

[33mcommit bd8e0f34bc9dc6d004cf9ac5004213ca7128fa93[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Wed Nov 9 10:53:20 2016 +0530

    BUG##25055982 : MTR --REPORT-TIMES GIVES TOO HIGH VALUE FOR 'COLLECT' AND 'INIT'
    
    Description :
    =============
    The --report-[1;31mtime[ms option is meant to give an overview of [1;31mtime[m
    spent on different tasks. Those tasks executed by "workers" like
    basic test execution will be summed over all.
    
    But the "Collecting test cases" and "Initialization/cleanup" are
    reported with an inflated value if running with --parallel even
    though these phases are *not* done by the test workers.
    
    When the workers are started they get their copy of the %[1;31mtime[m_used
    hash where the 'collect' and 'init' already have non-zero values.
    When they report this back to the master thread, they will be added
    to the total. The end result is that they get multiplied by N + 1
    where N is the parallel value.
    
    Fix :
    =====
    Initialize the '%[1;31mtime[m_used' hash to value 0 for each worker thread.
    
    Reviewed-by: Bjorn Munch <bjorn.munch@oracle.com>
    RB: 14532

[33mcommit 0b3825f2426f7ba019b62eb481fe1a8068fecd18[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Tue Nov 8 11:36:16 2016 +0100

    Bug#25027185: TSAN: DATA RACE IN MY_TIMER_MICROSECONDS
    
    Fix data race in my_[1;31mtime[mr_microseconds() - use std::atomic
    for static variable modified by multiple threads.
    
    Also add more suppressions needed to run main.alter_table.

[33mcommit 091c63429ba682c46a68a104b1af65bc310f6a1c[m
Author: Allen Lai <zheng.lai@oracle.com>
Date:   Mon Nov 7 20:59:00 2016 +0800

    Merge the patch from Run[1;31mtime[m team for fixing a ASAN issue.

[33mcommit 9146bf9601889bc17270af473481a9d457ae0541[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Mon Oct 31 22:00:32 2016 -0500

    Bug#24916359 - Test Case table_encrypt_kill.test fails sporadically
    
    The failure would occur after a crash, after redo log recovery.
    Redo recovery would open an undo tablespace from the MLOG_FILE_NAME
    log entry.  Later in srv_undo_tablespace_init(), srv_undo_tablespace_open()
    will skip this file since it has already been opened. Instead, it used the
    previous fil_space_t object. But for some reason the node->size would
    sporadically be zero. This zero size causes the reported error during a
    later call to fil_io().
    
    The fil_space_t object created by redo log recovery has other problems.
    It uses the file name as the tablespace name, which includes the path.
    And it does not know that this is an undo tablesapce so it puts the
    object onto the LRU, which it should not be.  There may be other issues
    with this object as well.
    
    The solution is to not only flush and close that fil_space_t object but
    to also free it. This allows srv_undo_tablespaces_open() to create a new
    one correctly. It is reopened from scratch with a new fil_space_t object
    as if it was not part of redo log recovery, which is already completed by
    this [1;31mtime[m during startup.
    
    In addition, testing has shown that it is possible for the header page
    of this undo tabelspace to be in the buffer cache when the fil_space_t
    object is freed.  The presence of this page in cache can cause the file
    not to be opened upon the first page read and then an assert in fil_io()
    can be hit when the file is not yet opened.  So fil_undo_tablespace_open()
    will now call fil_space_open() after it has successfully created the
    fil_space_t and fil_node_t objects and incremented srv_undo_tablespaces_open.

[33mcommit 8b5d2a9a99eb967a61525c265edfd064fe7f2e79[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Wed May 4 09:31:26 2016 +0200

    Bug#24459890: BACKPORT FIX FOR #23195845 TO 5.7
    
    Backport (with some extra nonnull fixes) from trunk to 5.7 of:
    
      Bug#23195845: FIX COMPILE WARNINGS REPORTED BY GCC 6.1
    
      Fix compile warnings reported by recently released GCC 6.1:
    
      -Werror=misleading-indentation
      libbinlogevents/src/uuid.cpp
      rapid/plugin/x/mysqlxtest_src/mysqlx.cc
      sql/sql_update.cc
      This error had to be disabled for files using Boost.
    
      -Werror=nonnull-compare
      storage/innobase/include/dict0dict.ic
    
      -Werror=logical-op
      mysys/mf_dirname.cc
      sql/item_[1;31mtime[mfunc.cc
      sql/mysqld.cc
      vio/viosocket.cc
    
      Also fix problem in mysys/my_sync.cc where we were using
      __linux rather than the correct __linux__ symbol.
    
      (cherry picked from commit 43a1c9dca6104a35455721eddeabcc748e349bbb)
    
    Change-Id: I9580f680a4bceceb649bf61e82eac552938690b6
    (cherry picked from commit 1ae7152689c86cf53354d328d6c5fd1ad48fa9c6)

[33mcommit 6b4e97889677d442780cbee8f726ab67b8ddc4a5[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Thu Oct 13 16:17:03 2016 +0300

    Bug#24962768 DO NOT IGNORE THD PARAMETER IN RESOLVE_TYPE()
    
    Item_func_get_system_var::resolve_type(): Use thd, not current_thd.
    
    Item_func_internal_update_[1;31mtime[m::resolve_type(): Use thd, not current_thd.
    
    Item_func_internal_check_[1;31mtime[m::resolve_type(): Use thd, not current_thd.
    
    Reviewed-by: Knut Hatlen <knut.hatlen@oracle.com>

[33mcommit 01c194726c75c2ce1ef894e00e3a815ef1e25d9f[m
Author: Darshan M N <darshan.m.n@oracle.com>
Date:   Fri Oct 21 14:52:50 2016 +0530

    Bug#24658707 ASSERT: BUF0BUF.CC:2469:BUF_BLOCK_GET_STATE(BLOCK)
    == BUF_BLOCK_FILE_PAGE
    
    Issue
    =====
    The issue is that during commit_inplace_alter_table we wake up the purge
    thread and we take a btr search latch and try to disable the adaptive hash
    search system and empty the index. The purge operation happening in the
    background, when flushing the pages, tries to remove possible adaptive hash
    index on the page and it sets the the block state as BUF_BLOCK_REMOVE_HASH
    and waits on the btr search latch taken by the alter command. And in the
    alter command when we're trying to empty the hash index of the same block
    we hit the assertion ut_ad(buf_block_get_state(block) ==
    BUF_BLOCK_FILE_PAGE) as the block state was changed by the purge operation.
    Both the threads would be working on the same block at the [1;31mtime[m of
    assertion.
    
    Fix
    ===
    The workaround solution for now is to remove the debug assert.
    
    RB: 14344
    Reviewed-by: Jimmy Yang <Jimmy.Yang@oracle.com>

[33mcommit b28a1651e75ea1183ef4a32509aa29bf75e74131[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Tue Oct 11 12:33:23 2016 +0200

    Bug#24579061 UPGRADE TO BOOST 1.62.0
    
    Upgrade dependency to 1.62.0 and remove those patches for Boost 1.60.0
    that are already included in 1.62.0. Add patches to fix bugs in Boost
    1.62.0.
    
    Also add patch to boost/exception/info.hpp to fix error C4099 (type
    first declared struct, then class) in Visual Studio. Add
    BOOST_PATCHES_DIR to the include path in X plugin.
    
    Remove test case for bug #20357097 since it no longer returns an
    error, but instead takes a long [1;31mtime[m to complete.

[33mcommit f2ab5592374e7966aeb466699f434f4a19e37cad[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Thu Oct 20 10:41:01 2016 +0530

    BUG#24365145 : "COLLECTING TESTS" PART OF MTR IS SLOW AND RUNS ON A SINGLE THREAD
    
    Issue :
    =======
    It seems "Collecting tests" part of MTR runs for quite some [1;31mtime[m with
    multiple suites. MTR uses the single thread to collect the tests from
    all the suites. Maybe it's worth investing some [1;31mtime[m in making it run
    in parallel.
    
    Fix :
    =====
    Spawn multiple threads to collect the tests from different test suites.
    Number of threads running/active at any [1;31mtime[m shouldn't exceed the number
    of CPUs in the machine.
    
    Reviewed-by: Bjorn Munch <bjorn.munch@oracle.com>
    Reviewed-by: Deepa Dixit <deepa.dixit@oracle.com>
    RB: 13788

[33mcommit 66f1367047f573a58660b8370ee9130de5a1d9f2[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Tue Oct 18 17:44:21 2016 +0200

    WL#6599 - New Data Dictionary and I_S integration.
    
        This is a post-fix patch to make the ndbcluster.information_schema
        more robust and avoid that it has to be changed every[1;31mtime[m a new ndbinfo
        table is added. The purpose of the test is only to show that some
        ndbinfo tables show up when ndbcluster handler is enabled without specifying
        the entire list of tables in the result file.

[33mcommit c863738034e7bc7f539e48d0aa60711c9276ba60[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Oct 4 14:43:01 2016 +0200

    Bug #24788778: SEVERE REGRESSION IN MY_STRNXFRM() FROM MYSQL-5.5 -> 5.6
    
    MySQL 5.6 changed utf8 binary collation strxfrm() from just comparing the UTF-8
    string to converting it to UCS-2 (big-endian) and padding before compare.
    (Similarly for utf8mb4, just with UCS-3 instead, which isn't correct for
    all Unicode code points.)
    
    Both are correct (although changing it also changed the hash function, which
    might on-disk binary compatibility wrt. partitioning), but the latter makes for
    fixed-length keys, which was seemingly important for the (now discontinued)
    Falcon storage engine at the [1;31mtime[m. However, it also introduces a bottleneck
    when hashing. We add a very simple benchmark (based on the benchmark in the
    bug) and then optimize the string transformation:
    
     - Add an SSE2 version of the padding as long as we're sufficiently far away
       from the end of the string; this will be used automatically for all 64-bit
       Intel compiles (as well as 32-bit Intel compiles with -march=native or
       similar).
     - Inline the mbwc() function for the special case of my_utf8_uni.
     - Some general microoptimization.
    
    All in all, we're at about 7x the speed of before. Old version
    (trunk, 64-bit, optimized mode, GCC 6.1.1, Skylake 3.4 GHz):
    
      Done, used 1.696 seconds (1.696 us/iteration)
    
    This version:
    
      Done, used 0.242 seconds (0.242 us/iteration)
    
    The code is written to be C++98 compatible (even though a lambda would be
    much more elegant than a functor class), as it will probably want a 5.6 and 5.7
    backport. The benchmark isn't, though, as it uses std::chrono.
    
    Change-Id: I9da8c8af448bdacd6028a65c10ce232f841cdc94

[33mcommit 849fe4f7b8c224e846c0346009857aad265cedf3[m
Author: Ole John <ole.john.aske@oracle.com>
Date:   Fri Sep 30 11:01:27 2016 +0200

    Bug #24716756   IMPROVE SCALABILITY OF API RECEIVER HANDLING
    
    In order for the NDB API to process incoming signal signals, the
    threads which wants to act as receiver has to acquire the 'poll-right'
    from the transporter layer. This poll right could either be
    requested and assigned to a separate receiver thread, or each client
    thread can take the receiver role when it anyway had to wait for
    its result.
    
    When the thread being the poll owner had received a sufficient amount
    of data, it will release locks on other clients which it has taken
    while delivering signals to them. This may make them runnable again,
    and the OS-scheduler might decide that it is [1;31mtime[m to wake them up.
    This might happen at the expense of the poll owner threads, which
    then is yielded from the CPU - while still holding the 'poll-right' !
    
    This patch will release the poll-right from a thread
    before unlocking and signaling other threads. Thus the poll right
    becomes available for other threads that are actively
    executing on the CPU.
    
    This increase the concurrency in polling data of the receiver
    and should also reduce latency for clients wating for being woken
    up.

[33mcommit f76c8522ea7eef406c8f8d31cd05eea4dc1e62d9[m
Author: John David Duncan <john.duncan@oracle.com>
Date:   Thu Sep 29 21:27:32 2016 -0700

    storage/ndb/nodejs: update ReadMe and try to future-proof JS code for 7.5 release.
     Just prior to 7.5.4 release, update JavaScript code in jones-ndb
     to be compatible with what we know is coming in jones 1.x
     At the same [1;31mtime[m, update ReadMe file to encourage users to use
     jones 1.2.3, which is known to be 100% compatible with the version here.
     This is a JavaScript-only check in; zero risk to compiled code.

[33mcommit 58cf18730cd42cef542737261d97953f0bc696d8[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Sep 27 10:58:15 2016 +0200

    Bug#22320066 EVENTS_STATEMENTS_SUMMARY_BY_DIGEST: NO UNIQUE ROWS BY
    DIGEST/SCHEMA_NAME
    
    Fix for trunk (8.0)
    
    Before this fix, table events_statements_summary_by_digest
    exposed many rows for the same statement digest and schema,
    breaking the expected uniqueness of digests.
    
    The root cause is in function find_or_create_digest(),
    which does not handle duplicate inserts in the LF_HASH properly.
    
    When two different sessions execute
    the same statement for the first [1;31mtime[m,
    each session creates an entry for the statement digest.
    
    In this case, the index is maintained properly with only one entry,
    but the table data itself still contained duplicated rows, orphan.
    
    The fix is to:
    - use a pfs_lock for a statement digest record
    - free the duplicate record when duplication is detected in the unique index
    - loop in the entire buffer to find an empty record,
      so that duplicate entries do not create holes and do not cause leaks
    - honor the pfs_lock when exposing the data.
    
    With this fix, the allocation pattern is similar to other instrumentations,
    like the mutex instances for example.
    
    Tested manually with debug code added to expose the race conditions.
    Not testable by MTR scripts.

[33mcommit e6e5d07492f23fc224c94559bd470762924e3763[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Fri Sep 23 17:50:11 2016 +0200

    Post push fix for bug#23555834.
    
    Use a smaller range of hint counts.
    
    Since two nodes from different node groups could be used with very
    different frequence if a read backup enabled table are used.
    
    If then also a fully replicated is used, when it look at hint counts to
    determine which node been used less, the counts for different node groups
    can have diverged much.  The logic could end up with using one node until
    that count reaches the other, could in rare cases be 2^31 [1;31mtime[ms.
    
    This patch reduces the range used for hint counts to 1024, so within 512
    transactions two possible nodes will be able to catch up with each other
    if their counts have diverged.

[33mcommit f17266f5219f01fc32cb4cbaffc5b16ee6c29c18[m
Merge: c4067f274b2 ac7d688e410
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Thu Sep 22 12:09:29 2016 +0200

    Bug#23555834 DATA_NODE_NEIGHBOUR BYPASSES OPTIMIZED_NODE_SELECTION
    
    This patch makes set_data_node_neighbour as a way to adjust the proximity
    groups of data nodes that the ndbapi node is connected to.  After that
    the proximity groups are adjusted no logic refers to data_node_neighbour.
    
    I call the groups constructed with the Group parameter in cluster
    configurations connection sections "proximity groups" to distinguish them
    from ordinary node groups.
    
    For hinted transactions, select_node is adjusted to for a given nodelist
    first reduce the list to the nearest nodes according to the proximity
    groups.  After that the node with least hint count is choosen and hint
    count is incremented.  Hint count is a new field per node.  If the given
    node list only had one node, that is choosen without incrementing the
    hint count.
    
    The only thread synchronization I have is when calling
    set_data_node_neighbour which may rearrange the node array.
    
    For read usage of the node array no synchronization is used, which can
    cause another node to be choosen one [1;31mtime[m per thread in conjunction with
    the call to set_data_node_neighbour.  A bit ugly, but
    set_data_node_neighbour should normally only be called at initialization
    of cluster connection, before any thread starts transactions.

[33mcommit 7a2b273b411b8e6448f7d50a574002c348511991[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Sep 22 11:19:27 2016 +0200

    Patch from Run[1;31mtime[m to fix the problem that get_se_private_data was
    not called properly before open().

[33mcommit b6fa2c2a6da1e591567ace66628f7e5d8753044c[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Tue Sep 20 10:18:24 2016 +0200

    Bug #11754493: MYSQLDUMP: INCREASE DEFAULT NET TIMEOUTS AND MAX
                   ALLOWED PACKET VARIABLES
    For tables with very large records whose size exceed max-allowed-packet,
    mysqldump reports connection lost error. Fix is to introduce a new option
    --network-[1;31mtime[mout which will set max_allowed_packet, net_read_[1;31mtime[mout and
    net_write_[1;31mtime[mout to its maximum values.

[33mcommit 8f5df867ae92c2cd404af911821089f3f599e7af[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Tue Sep 20 15:17:20 2016 +0800

    WL#9525: Fill in the se_private_data, so no need to access SYS_*
    tables for DD tables.
    
    dd_open_table(): If DD tables, fill in the dd::Tablespace::id by
    calculation: dd_table_no + 2/*mysql and innodb_system tablespace*/
    + srv_undo_tablespaces/* which reside before DD tablespaces */
    
    ha_innobase::open(): If DD tables, still call dd_open_table. If
    SYS_* tables, still go original way.
    
    ha_innobase::get_se_private_data(): Fill in autoinc counter,
    se_private_id and se_private_data for dd::Index.
    
    row_ins_check_foreign_constraints(): Skip check for DD tables,
    since the FK support is still broken for now.(1)
    
    row_purge_parse_undo_rec(): To fix a server issue, which will
    crash server easily, delay the run after mysql server start
    up fully.(2) For DD tables, open it by new dd_* APIs.
    
    (1) This will result in some changes in result files for some
    TCs, re-record them temporarily. Will have to revert them
    once FK is done.
    
    (2) This will result in [1;31mtime[mout for some TCs, temporarily disable
    two of them log_file_name and log_file_system

[33mcommit be6518ae85931af6762867c9d1514d98d35eae5a[m
Author: Martin Hansson <martin.hansson@oracle.com>
Date:   Wed Aug 31 10:49:29 2016 +0200

    Bug#22991924 GCOLS: UTF16 STRING OPERATIONS GIVE DOUBLED
    \0\0 STRINGS ON EACH TABLE REBUILD
    
    When a table is being rebuilt, the generated column
    expressions are printed and re-parsed. The problem is, a
    character set conversion may occur every [1;31mtime[m. This leads to
    the string being converted over and over each [1;31mtime[m the table
    is recreated. For certain conversions, such as utf8 to
    utf16, this leads to an ever growing string. The behavior
    depends on character_set_client.
    
    The fix is to make the data dictionary always print an
    explicit character set introducer when printing out the
    generated column expression. This ensures that conversion
    only happens once.
    
    This obviously changes the results of generated columns wrt
    charset conversions after table rebuilds.
    
    Also, some regular expression in the X plugin are augmented
    to handle charset introducers.

[33mcommit 675f749e248a2055c37b3b5385ec90411ad5aa18[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Wed Sep 14 13:24:32 2016 +0200

    Bug#24661523: -DMYSQL_MAINTAINER_MODE=ON BUILD FAILURE ON MAC OS X,
                  8.0 XCODE TOOLCHAIN
    
    This patch fixes a build problem with OS X 10.11 + XCode 8.
    MacOS 10.12 adds support for the clock_get[1;31mtime[m function
    and this function is present in headers supplied with XCode 8.
    Since we only tested if the function was declared, we got
    linking errors with OS X 10.11 + XCode 8 since 10.11 does
    not include the implementation of clock_get[1;31mtime[m.
    
    The problem is fixed by replacing the check with
    CHECK_C_SOURCE_RUNS() CMake check which does linking as well.
    
    The problem originally reported in the bug report is already
    fixed in 8.0.1 by:
      Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
      Date:   Thu Aug 25 19:43:10 2016 +0530
    
        WL#6392 : Upgrade to Transactional Data Dictionary
    
        Post push fix:
    
        Compilation with clang fails with error:
        unused variable 'event_table_def'

[33mcommit 15befd736db0cc9bf9589d3fd5824f2f3fa3f092[m
Author: Martin Sköld <Martin.Skold@oracle.com>
Date:   Fri Sep 9 11:24:42 2016 +0200

    Bug#24430209 MYSQL CLUSTER DISTRIBUTED PRIVILEGES VALIDATION FAILS
    
    The table mysql.proxies_priv can some[1;31mtime[ms contain unsupported [1;31mtime[mstamps
    (0000-00-00 00:00:00) in Timestamp field. The causes altering the table
    to be stored in ndb to fail. By replacing such illegal [1;31mtime[mstamp values
     with the defined default then the table can be properly altered.

[33mcommit e40338cd40217e0a59603301c1bd489833acaa18[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Thu Sep 8 16:08:37 2016 -0700

    Bug#24571816 - FIX FOR BUG#23020280 IS NOT COMPLETE
    
    The list of module base names in the variable auto_event_names was either incomplete
    or new modules have been added or renamed since then.
    
    For BUG#23020280, I tried to list each module which might allocate memory
    with any form of "ut_malloc" or "ut_new".  Assuming I missed some, this [1;31mtime[m
    I included all unique module base names in the InnoDB codebase. This array
    increases to 183 names.

[33mcommit 42c6ed3fedeb95036dadb92b15eef586943fb095[m
Author: Martin Hansson <martin.hansson@oracle.com>
Date:   Wed Aug 31 10:49:29 2016 +0200

    Bug#22991924 GCOLS: UTF16 STRING OPERATIONS GIVE DOUBLED
    \0\0 STRINGS ON EACH TABLE REBUILD
    
    When a table is being rebuilt, the generated column
    expressions are printed and re-parsed. The problem is, a
    character set conversion may occur every [1;31mtime[m. This leads to
    the string being converted over and over each [1;31mtime[m the table
    is recreated. For certain conversions, such as utf8 to
    utf16, this leads to an ever growing string. The behavior
    depends on character_set_client.
    
    The fix is to make the data dictionary always print an
    explicit character set introducer when printing out the
    generated column expression. This ensures that conversion
    only happens once.
    
    This obviously changes the results of generated columns wrt
    charset conversions after table rebuilds.

[33mcommit d51cfa9319d3951ad999219acb7deb749389511e[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Tue Sep 6 14:39:41 2016 +0530

    Bug#24592573 : MAIN.DD_UPGRADE_TEST HAS OCCASIONAL FAILURES
                       IN VALGRIND RUNS
    
    The test case fails due to [1;31mtime[mout while restarting the server.
    Restarting the server is acutally the step where upgrade of data
    directory from 5.7 to 8.0 takes place. This step some[1;31mtime[ms
    [1;31mtime[m out when executing the test with valgrind.
    
    Disabling test in valgrind runs. Any memory issue in test
    will be monitored with ASAN builds.
    
    Reviewed-by: Erlend Dahl <erlend.dahl@oracle.com>

[33mcommit 447c4cc3c4f74003ff42304ce21f7b75bc5756a8[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Mon Sep 5 14:00:36 2016 +0200

    WL#5094 Create SQL command classes for DML statements
    
    Refined the class Sql_cmd_dml as a subclass of Sql_cmd for processing
    of SQL DML statements. Subclasses of Sql_cmd_dml are created for these
    classes of SQL statements:
    
    - SELECT
    - INSERT ... VALUES, INSERT ... SELECT
    - UPDATE (both single-table and multi-table variation)
    - DELETE (both single-table and multi-table variation)
    - DO
    - CALL
    
    Refactored processing of INSERT, UPDATE and DELETE statements for clear
    separation of preparation and execution code, as well as simplifying
    the execution logic.
    
    After this refactoring, most DML statements go through a fixed set of
    processes, each implemented using member functions, most of them virtual.
    SET statements and CREATE TABLE ... SELECT statements are still processed
    by handle_query() after this worklog, however.
    
    Preparing a statement goes through these processes:
    
    - precheck()
    - open_tables_for_query()
    - resolve_var_assignments()
    - prepare_inner() (the actual preparation code)
    - cleanup()
    
    Executing a statement goes through these processes:
    
    - set_statement_[1;31mtime[mr()
    - preparation (if not already done, otherwise precheck() and open_tables())
    - run_before_dml_hook() (if data change statement)
    - push_internal_handler() (if data change statement)
    - lock_tables()
    - query_cache.store_query()
    - execute_inner() (the actual optimization and execution code)
    - pop_internal_handler()
    - cleanup()
    - reset_statement_[1;31mtime[mr()
    
    Query_result objects are changed so that they are created for
    the duration of the statement object.

[33mcommit 5fc061ebfb82c37c8bff01f131d95facc8b331f7[m
Author: Ole John <ole.john.aske@oracle.com>
Date:   Thu Sep 1 10:30:56 2016 +0200

    Fix to make testcase more predictable.
    
    Required as a follow up for patch for bug 24481551,
    
      CONDITION SIGNALING MISSING WHEN WAITING FOR EPOCH TO BE WRITTEN TO BINLOG
    
    That patch removed delay in waiting for binlog to be written,
    such that when checking server 2 binlog our insert had not had
    the chance to reach the log yet.
    
    Thus we have to add a 100ms sleep to guarante that some [1;31mtime[m passes
    between insert ond checking binlog contents.

[33mcommit 45588143c617a372c30d4bdf5e2db8457bbd18b6[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Aug 25 14:44:34 2016 +0200

    Bug #24488219: INCLUDE WHAT YOU USE
    
    Continue running IWYU, this [1;31mtime[m on include/. Fix up a few files
    that have latent issues that are uncovered by this.
    
    Change-Id: I24e7702e7c6620396fac0653a6b9c56be3ed924d

[33mcommit 87a69538888ee880b1bfb1b2a1c33f875903a76c[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Aug 30 10:24:15 2016 +0200

    Bug#24561887 ADD NOT_SPARC_DEBUG.INC
    
    Add mtr file not_sparc_debug.inc in order to disable
    a couple of tests which typically [1;31mtime[mout after 900 seconds in debug mode.
    Also disable for UBSAN builds.
    
    Change-Id: I1eb026da9258b87281c8c3b73873eed42dd75c16

[33mcommit 094c4bc7499e36a0f92a07dbaad81935ad71d319[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Aug 22 16:17:28 2016 +0200

    Bug #24488219: INCLUDE WHAT YOU USE
    
    First small patch out of a series of many, restricted to strings/
    only to start out small.
    
    The general gist of these is to install the include-what-you-use
    tool (e.g. by “sudo apt install iwyu” in Debian), then cmake with
    
      -DCMAKE_C_COMPILER=/home/sgunders/iwyu-gcc -DCMAKE_CXX_COMPILER=/home/sgunders/iwyu-g++
    
    iwyu-gcc is a program that runs IWYU, outputs (atomically) its output
    to stdout, and then actually compiles the file using Clang to make sure
    that compilation can proceed. It looks like this:
    
      #! /bin/sh
      T=$(tempfile)
      /usr/bin/iwyu "$@" > $T
      lockfile /tmp/iwyu.lock
      cat $T
      rm -f /tmp/iwyu.lock $T
      exec /usr/bin/clang "$@"
    
    and analogously for g++, just with clang replaced by clang++.
    
    The stdout output is stored in a log file and given to fix_include:
    
      /usr/bin/fix_include --ignore_re='(extra|zlib|libedit|innobase|obj|libevent|regex|myisam|rapid/plugin/x)/' < log
    
    After that, the patch is manually inspected and corrected where needed.
    Many changes work out-of-the-box, but some patterns tend to confuse
    the tool, so it some[1;31mtime[ms needs manual correction.
    
    Change-Id: Ie194ac838c7d3b615ebb2e8b5fea68cce4b0e213

[33mcommit 2ad5e1acabf3f01245b6208b57142ea4b15800a6[m
Author: Ole John <ole.john.aske@oracle.com>
Date:   Wed Aug 24 13:27:00 2016 +0200

    Bug#23553267 DEADLOCK WHEN MDL_EXCLUSIVE ACQUIRES A GLOBAL SCHEMA LOCK (GSL)
    
    Cherry pick of the server part of the patch from mysql-5.7
    In adition this commit adds the Cluster specific part of patch
    
    NdbCluster code for acquiring a Global Schema Lock has been changed
    to not retry the GSL lock if it failed due to a [1;31mtime[mout (default 3000ms),
    *and* there is a potential for this lock request participating in a MDL-GSL
    deadlock. In these cases it select itself as a 'victim', and return
    this decission to the MDL requestor.
    
    MDL code will then either handle such a victimized GSL request either as
    a failed lock request - Which is better than staying in a deadlock state
    forever.
    
    Or, where a deadlock_handler exist in the MDL code, it will backof
    and retry the MDL+GSL locking again. (Valid for CREATE TABLE which
    was the soure for the deadlocks in the attached test case)

[33mcommit 3c0da65188fff295809afd17e3ff188641327608[m
Author: Deepthi ES <deepthi.e.s@oracle.com>
Date:   Tue Aug 23 17:11:33 2016 +0530

    Bug#23297190 : RPL_GTID_SERVER_SIGHUP AND RPL_MASTER_POS_WAIT_AFTER_STARTUP FAILS IN VALGRIND
    
    In the testcases we are restarting the master server which is taking more [1;31mtime[m
    on slow platforms like valgrind and slave fails to reconnect with
    "error reconnecting to master '$Master_Port'- retry-[1;31mtime[m: 1 retries:10".
    
    Fix :
    
    Changed master_connect_retry=30 and master-retry-count=30 on slave. Now the
    slave retries connecting after every 30 secs for 30 [1;31mtime[ms which gives
    sufficient [1;31mtime[m to reconnect to the master.

[33mcommit 94b4ff92fce9ad9a77590dc09d8ea15badcb6042[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Sat Jun 18 18:06:47 2016 +0200

    Bug #23623110: Range optimizer: Rework use_count handling.
    
    This entirely rewrites the range optimizer's treatment of use_count,
    replacing multiple layers of subtle and complicated handling with
    one simple rule: SEL_ARG::use_count counts the number of references
    from next_key_part or keys[]. (Well, there's one exception in
    and_all_keys(), but it's well-documented and localized.)
    
    In particular, this means that the logic with recursive use_counts,
    where increment_use_count() modifies the use count of every SEL_ARG
    that the current SEL_ARG tree points to recursively, goes away.
    The entire concept of adding more than one use_count at a [1;31mtime[m
    also goes away. Instead, there are two simple functions to modify
    next_key_part (release_next_key_part() and set_next_key_part())
    that automatically maintain use_count, and these are used the majority
    of the [1;31mtime[m. (Unfortunately, we still don't have compiler-assisted
    handling of correct _use_ of the use_count; it would be nice to make
    it impossible to modify a SEL_ARG with use_count > 1 without cloning
    it first, but it would probably require significant investments to
    const use in this file.) Almost all remaining tricky or unintuitive use_count
    handling has been commented, as well as general invariants preserved by
    functions.
    
    In line with the new rules, key_and() and key_or() no longer modify the
    use_count of their arguments since they don't modify anything pointing
    to them; they are now much closer to purely functional. In the same vein,
    they also don't send back the return value with use_count incremented,
    which simplifies the overall flow. There are also somewhat tighter asserts in
    place, including on the root node of the R-B tree (where we know there are bugs
    that this patch doesn't do much with).
    
    Finally, the global SEL_ARG null_element was an object of class type
    in static scope, which is a style guide violation; this has been remedied
    by replacing it with a pointer that's explicitly allocated and destroyed
    as part of normal server startup/shutdown. This fixes issues where the
    SEL_ARG destructor assert would spuriously fire when something else caused
    the server to exit.
    
    I found a preexisting issue I don't fully understand, and annotated
    it with FIXME comments, so it is not forgotten. (It goes back more than 15
    years.) Several similar ones were fixed.
    
    Change-Id: Id4941372393aef2f720cdd2ef7aa7b101d4afac6

[33mcommit ed59f25407b00fe856ba12ebd213f39fcd338924[m
Author: Mayank Prasad <mayank.prasad@oracle.com>
Date:   Mon Aug 22 17:19:27 2016 +0530

    Fix sporadic failure of idx_events_stages_current.test
    
    Issue:
            idx_events_stages_current tests depends on the entries in
            performance_schema.events_stages_current table. These entries
            are transient in nature which is causing sporadic failure.
    
    Fix:
            Increased innodb_lock_wait_[1;31mtime[mout to make sure entries in this
            table are there for longer period to avoid this sporadic failure.

[33mcommit e359ebc26ea3c193f52dbb06475137f94bd3c07c[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Wed Aug 17 09:43:37 2016 +0200

    WL#6599 - New Data Dictionary and I_S integration.
    
    Post-push patch fixing POINT_SELECT performance regression fix.
    
    The patch does following improvement in open_tables() call flow,
    
    1 We were invoking dd::Dictionary::is_system_view_name() several
      [1;31mtime[ms for a table. E.g., SELECT_LEX::add_table_to_list() would
      already know that if a TABLE_LIST is a system view. We were not
      setting TABLE_LIST->is_system_view here.  This patch sets this in
      SELECT_LEX::add_table_to_list() and avoids calls to
      dd::Dictionary::is_system_view_name() function call which goes
      throw all the system view names within the open_tables() call flow.
    
    2 We also avoid call to dd::Dictionary::is_dd_table_name().
      Basically there are two possibilities of open_tables() call seeing
      a DD tables.
    
      a) DD table being opened as part of DD operations invoking
         dd::Open_dictionary_tables_ctx::open_tables().
    
      b) DD table being opened as part of I_S system view execution.
    
      During open_table(), we need to know if a TABLE_LIST belongs to a
      DD table for several checks. Currently we do that by invoking
      dd::Dictionary::is_dd_table_name() which is a looking in a list.
      We can avoid that as described below.
    
      When open_table() is opening a DD table in case of a), the
      table_list used there is nothing but dd::Raw_table::m_table_list.
      And we are sure that this belongs to only DD tables. So, this
      patch adds a member TABLE_LIST->is_dd_table, which is set only by
      dd::Raw_table.  So the open_table() call now uses it.
    
      For b), we know that TABLE_LIST->is_system_view is marked for all
      the I_S system views. And
      TABLE_LIST->referencing_view->is_system_view would tell us that
      the TABLE_LIST is refering to a DD table. So, this avoids calls
      to dd::Dictionary::is_system_view_name().
    
    3 The function TABLE_SHARE::get_table_ref_version() is invoking
      both dd::Dictionary::is_dd_table_name() and
      dd::Dictionary::is_system_view_name().  This is a overhead.  This
      patch adds a TABLE_SHARE->table_category called
      TABLE_CATEGORY_DICTIONARY. This helps us avoid call to
      is_dd_table_name(). And use TABLE_SHARE->view_object->type() ==
      dd::enum_table_type::SYSTEM_VIEW to check if that is a system view.
    
    4 The patch does following change, that is not necessarily to
      improve the permformance. Basically the revno 56eaef86 sets
      MYSQL_OPEN_IGNORE_FLUSH flag while opening DD tables in
      Open_dictionary_tables_ctx::open_tables().  And later the revno
      11eeb00a removes this flag, expecting open_table() to set it for
      DD tables. Conceptually it looks correct to set this flag for all
      DD table at Open_dictionary_tables_ctx::open_tables() so this
      patch retain setting of this flag as done by revno 56eaef86.
      These revno are from mysql-trunk-wl6599-1 branch.

[33mcommit b435c4893f32e0c8ad197e95bd3c051dcf201f62[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Wed Aug 17 09:43:37 2016 +0200

    WL#6599 - New Data Dictionary and I_S integration.
    
    Post-push patch fixing POINT_SELECT performance regression fix.
    
    The patch does following improvement in open_tables() call flow,
    
    1 We were invoking dd::Dictionary::is_system_view_name() several
      [1;31mtime[ms for a table. E.g., SELECT_LEX::add_table_to_list() would
      already know that if a TABLE_LIST is a system view. We were not
      setting TABLE_LIST->is_system_view here.  This patch sets this in
      SELECT_LEX::add_table_to_list() and avoids calls to
      dd::Dictionary::is_system_view_name() function call which goes
      throw all the system view names within the open_tables() call flow.
    
    2 We also avoid call to dd::Dictionary::is_dd_table_name().
      Basically there are two possibilities of open_tables() call seeing
      a DD tables.
    
      a) DD table being opened as part of DD operations invoking
         dd::Open_dictionary_tables_ctx::open_tables().
    
      b) DD table being opened as part of I_S system view execution.
    
      During open_table(), we need to know if a TABLE_LIST belongs to a
      DD table for several checks. Currently we do that by invoking
      dd::Dictionary::is_dd_table_name() which is a looking in a list.
      We can avoid that as described below.
    
      When open_table() is opening a DD table in case of a), the
      table_list used there is nothing but dd::Raw_table::m_table_list.
      And we are sure that this belongs to only DD tables. So, this
      patch adds a member TABLE_LIST->is_dd_table, which is set only by
      dd::Raw_table.  So the open_table() call now uses it.
    
      For b), we know that TABLE_LIST->is_system_view is marked for all
      the I_S system views. And
      TABLE_LIST->referencing_view->is_system_view would tell us that
      the TABLE_LIST is refering to a DD table. So, this avoids calls
      to dd::Dictionary::is_system_view_name().
    
    3 The function TABLE_SHARE::get_table_ref_version() is invoking
      both dd::Dictionary::is_dd_table_name() and
      dd::Dictionary::is_system_view_name().  This is a overhead.  This
      patch adds a TABLE_SHARE->table_category called
      TABLE_CATEGORY_DICTIONARY. This helps us avoid call to
      is_dd_table_name(). And use TABLE_SHARE->view_object->type() ==
      dd::enum_table_type::SYSTEM_VIEW to check if that is a system view.
    
    4 The patch does following change, that is not necessarily to
      improve the permformance. Basically the revno 56eaef86 sets
      MYSQL_OPEN_IGNORE_FLUSH flag while opening DD tables in
      Open_dictionary_tables_ctx::open_tables().  And later the revno
      11eeb00a removes this flag, expecting open_table() to set it for
      DD tables. Conceptually it looks correct to set this flag for all
      DD table at Open_dictionary_tables_ctx::open_tables() so this
      patch retain setting of this flag as done by revno 56eaef86.
      These revno are from mysql-trunk-wl6599-1 branch.

[33mcommit bf27bdcf4cb42185f06b61842bd991a66b7d2838[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Thu Aug 18 15:36:42 2016 +0100

    23709284     WL#9018:COMPLETE CLUSTER SHUTDOWN WITH ERROR "DBTC (LINE:
    14496) 0X00000006 CHEC
    
    Remove invalid assertion about cascading_scans_count reaching zero at
    ApiCon release [1;31mtime[m.
    
    Scan closing is asynchronous w.r.t the main transaction, so subscans
    may well take some [1;31mtime[m to close after the main transaction.  This
    is designed for in the implementation, therefore the assertion is
    invalid.
    
    New testcase added to cover this scenario.

[33mcommit dc1e488b4d5f78ce9bf38e17d2634608474bf1b3[m
Author: V S Murthy Sidagam <venkata.sidagam@oracle.com>
Date:   Tue Aug 16 15:49:38 2016 +0530

    Bug#24453571 SERVER CRASHES WHEN INSTALL COMPONENT IS ISSUED, AFTER MYSQL_UPGRADE
    
    Description: mysql server crashes while running INSTALL COMPONENT, after mysql_upgrade
    
    Analysis: When the server is started with out mysql.component table in database,  mysql_persistent_dynamic_loader_imp::init() call fails with the error. Becasue open_component_table() is failing because of mysql.component table is not present.
    And later if we give INSTALL COMPONENT it will call mysql_persistent_dynamic_loader_imp::load() and it fails at
    mysql_persistent_dynamic_loader_imp::is_initialized condition because this flag is not set at init() [1;31mtime[m.
    And there is no error set along with this failure. Hence the crash at THD::send_statement_status() at the end of query exicution.
    
    Fix: In init() function pretend that the initialization succeeded and make the group_id as '0'. And also return the error messages when the is_initialized flag is checked at load()/unload() function so, that the proper error message is send to the client. By pretending the initialization it will help incase of mysql_upgrade.

[33mcommit a34fafe5cde6c52b55e5171d2db978a08e4dc6fe[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Tue Aug 16 04:44:15 2016 +0200

    WL#6599 - New Data Dictionary and I_S integration.
    
    Make main.dd_is_concurrency test work without using
    mysql_version_id, else the test case would be broken
    every[1;31mtime[m we bump the version number.

[33mcommit 4568cc7b1eb44dd15aa95a7ddb2d7d13892de755[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Thu Aug 18 09:27:00 2016 +0200

    Bug #23753319: Post-push fix.
    
    Re-record innodb.mysql_innodb which includes mix1.inc which includes
    innodb_rollback_on_[1;31mtime[mout.inc.
    
    Reviewed by Sivert Sørumgård.

[33mcommit b36429a61b18aece770fc29851b41601a0f08ce7[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Wed Aug 17 11:29:19 2016 +0200

    Bug#23106330: MISSING CHECK_STACK_OVERRUN IN JSON_BINARY::SERIALIZE_JSON_VALUE
    
    The JSON tests ran out of stack space on some platforms when running
    against a debug enabled server. Because of lacking checks for stack
    usage, the server would not detect this situation in [1;31mtime[m, and it led
    to the server exiting.
    
    The fix is twofold:
    
    1) It add calls to check_stack_overrun() before attempting to
    serialize a nested array or object in order to detect stack overruns
    up front and fail gracefully when processing deeply nested JSON
    documents. This prevents the server from exiting if it runs out of
    stack space.
    
    2) It reorganizes the code that serializes JSON document so that it is
    less stack-hungry when compiled without optimization. Specifically:
    
      a) The function json_binary::append_value() is manually inlined the
      two places it is called. This function is called recursively when
      serializing nested JSON documents, so inlining it removes one stack
      frame for each level of nesting in the document.
    
      b) The code in json_binary::serialize_json_object() that writes the
      key entries section of the object, is moved out to a separate
      function called append_key_entries(). This reduces the size of the
      stack frames for serialize_json_object(), which is called
      recursively when serializing nested objects.
    
      c) The cases for serializing opaque, date[1;31mtime[m and decimal values in
      json_binary::serialize_json_value() are moved out to separate
      functions. This reduces the stack frame size of the recursive
      serialize_json_value() function.
    
    This makes the JSON tests pass with the default stack size on more
    platforms.

[33mcommit 7cdb70c4add9cc187d139170b9e4f0bde3645501[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Wed Aug 17 16:38:42 2016 +0100

    Bug #23539805 ALL REPORT MEM SHOWS WRONG DATA DISTRIBUTIONS
    
    After SR and NR, copy fragments were not being maintained or queried.
    This led to an observable imbalance after further DML.
    
    FR tables are implemented as a a set of one or more 'main' fragments
    containing subsets of the data, and zero or more 'copy' fragments.
    Each main fragment has zero or more copyfragments, one in each
    nodegroup.
    
    The relationship between main and copyfragments is known by DIH and
    used to provide a fragment with a node-local replica to read requests
    and to provide a sequence of fragment ids to FR maintenance triggers.
    
    This relationship was generated at table creation [1;31mtime[m, but was not
    rebuilt on restarts.
    
    A new testcase ndb_fully_replicated_restart2 is added which covers :
     - Rolling node restart + System restart with node takeover
     - Node-local replica reading with > 1 NG across multiple operation types
     - Copy fragment maintenance checks
    
    Existing testcase ndb_fully_replicated_restart is modified to :
      - Use > 1 NG
      - Actually use an FR table for the test!
    
    It still has somewhat limited utility
    
    Note that despite the push of a fix for bug#23702848 there are still parts of
    the new testcase commented out due to failures.

[33mcommit 1f725ac8cdfd7480fe927097eea183776e6f1962[m
Author: V S Murthy Sidagam <venkata.sidagam@oracle.com>
Date:   Tue Aug 16 15:49:38 2016 +0530

    Bug#24453571 SERVER CRASHES WHEN INSTALL COMPONENT IS ISSUED, AFTER MYSQL_UPGRADE
    
    Description: mysql server crashes while running INSTALL COMPONENT, after mysql_upgrade
    
    Analysis: When the server is started with out mysql.component table in database,  mysql_persistent_dynamic_loader_imp::init() call fails with the error. Becasue open_component_table() is failing because of mysql.component table is not present.
    And later if we give INSTALL COMPONENT it will call mysql_persistent_dynamic_loader_imp::load() and it fails at
    mysql_persistent_dynamic_loader_imp::is_initialized condition because this flag is not set at init() [1;31mtime[m.
    And there is no error set along with this failure. Hence the crash at THD::send_statement_status() at the end of query exicution.
    
    Fix: In init() function pretend that the initialization succeeded and make the group_id as '0'. And also return the error messages when the is_initialized flag is checked at load()/unload() function so, that the proper error message is send to the client. By pretending the initialization it will help incase of mysql_upgrade.

[33mcommit 1905eb8ff92c3c6a0a2a80a1b11c9c5df32de827[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Fri Jul 15 11:46:23 2016 +0200

    Bug #23753319: !M_THD->TRANSACTION_ROLLBACK_REQUEST' AT
    THD::ATTACHABLE_TRX::INIT IN SQL/SQL_C
    
    Problem: When CREATE TABLE ... AS SELECT ... fails,
    Query_result_create::abort_result_set() would only call trans_rollback_stmt(),
    even if THD::rollback_request was true.
    
    Dropping the open table would then lead to a removal of the SDI which, in turn,
    would lead to a DD read (to obatain the tablespace object). That would result
    in the creation of another attachable transaction, which caused the assert
    since a rollback had been requested.
    
    Solution: Modify Query_result_create::abort_result_set() so that it also calls
    trans_rollback_implicit() if THD::rollback_request has been set.
    
    Test case added to innodb.innodb_[1;31mtime[mout_rollback.test since this test is
    being run with the --innodb_rollback_on_[1;31mtime[mout option, and a rollback
    request caused by a [1;31mtime[mout can be used to reproduce this issue.

[33mcommit 977de6b2995802eaf1c4852bc243cf22e0eeaf0d[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Tue Aug 16 04:44:15 2016 +0200

    WL#6599 - New Data Dictionary and I_S integration.
    
    Make main.dd_is_concurrency test work without using
    mysql_version_id, else the test case would be broken
    every[1;31mtime[m we bump the version number.

[33mcommit 361527a3b1302833b369cfd12e688b02ff0e2742[m
Author: Praveenkumar Hulakund <praveenkumar.hulakund@oracle.com>
Date:   Fri Aug 12 20:53:01 2016 +0200

    WL#7167 - Change DDL to update rows for view columns in DD.COLUMNS and other dependent values.
    
    With WL6599(Integration of IS with New Data Dictionary),
    INFORMATION_SCHEMA.COLUMNS is implemented as a view on the new
    data dictionary table mysql.columns. But only column information
    of tables is stored in the mysql.columns. Hence only columns of
    tables are listed by the INFORMATION_SCHEMA.COLUMNS table.
    Even SHOW COLUMNS lists columns of only tables.
    
    The main goal of this work log is to support INFORMATION_SCHEMA.COLUMNS
    and SHOW COLUMNS implementation to list even view columns
    information.
    
    Functional changes introduced:
    ------------------------------
    
    1. Now view columns information is stored in the data dictionary
       table mysql.columns and these rows are updated each [1;31mtime[m
       type of the column changes i.e each [1;31mtime[m when type of columns
       in the base table changes.
    
       With this change INFORMATION_SCHEMA.COLUMNS and SHOW COLUMNS
       lists columns from the view.
    
    2. If view becomes invalid then correct error warning or
       error messages are reported.
    
       Section A.c of  the WL page lists reason for becoming
       valid or invalid.
    
    3. This work log even takes care of updating mysql.tables.is_updatable,
       each [1;31mtime[m when view becomes updatable or non-updatable.
    
       With this change, INFORMATION_SCHEMA.VIEWS shows the correct IS_UPDATABLE
       state of view always.
    
    Compatibility issues:
    ------------------------
    The view can become valid or invalid on execution of account
    management statements too.  The error/warning reporting in such
    case is not handled as part of this WL. It will be handled
    as part of WL9496.
    
    Source files:
    ----------------
    Most of code changes is placed in sql/dd_sql_view.* and
    sql/dd/dd_view.*.
    
    Related worklogs:
    ------------------
    * WL#6599 - New Data Dictionary and I_S integration.
    
      This WL defines INFORMATION_SCHEMA (I_S) system view over DD
      tables, representing a I_S table. WL7167 implemented over the
      WL6599 changes. So WL#6599 and WL#7167 would be pushed together.
      They are QA'ed together.
    
    Upcoming WLs:
    ------------------
    WL#9496 - Extend view status(valid/invalid) handling to Account
              Management Statements.

[33mcommit 3b1718b8150ea92166111798c5dc6a11a0e4bfeb[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Thu Aug 11 11:16:28 2016 +0800

    BUG#24287290 BUF POOL MUTEX ORDER VIOLATION IN BUF_POOL_RESIZE
                 WITH MULTIPLE INSTANCES
    
    It's a regression of wl#8423: InnoDB: Split the buffer pool mutex.
    
    In buf_pool_resize(), we enter all buffer pool mutexes for each
    buffer pool instance. we should enter a mutex a [1;31mtime[m for all
    intances to avoid mutex violation.
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 13614

[33mcommit f2bc0f89b7f94cc8fe963d08157413a01d14d994[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Wed Aug 10 17:41:28 2016 +0200

    WL#8688: Support ability to persist SET GLOBAL settings
    
    This WL introduces an option to persist global dynamic configuration variables,
    for example like SET PERSIST innodb_flush_log_at_[1;31mtime[mout= 14;. Configuration
    variables over a connection are lost after server restart. This WL provides
    DBAs a way to store configuration variables in a persistent way and allow
    server to read and apply all those variables which are persisted during a
    restart. A new config file name mysqld-auto.cnf will be created in datadir
    when a variable is persisted. This new config file is in JSON format.
    
    In addition to the persistence we add a performance schema table called
    "variables_info" which will have an entry for all configuration variables.
    This table will also have information about where the current value came
    from and some additional information about the variable. The historical
    configuration files can be used as before.
    
    This WL provides a read only system variable named persisted-globals-load
    which provides an option to enable/disable reading of persistent config file.

[33mcommit a0c070c151552762ccb4067e91774e3e07983303[m
Author: Arnab Ray <arnab.r.ray@oracle.com>
Date:   Wed Aug 10 12:38:04 2016 +0530

    Bug #23602217:  MISSES TO USE OLDER LCP WHEN LATEST LCP IS NOT RECOVERABLE
    
    Problem:
    --------
    
    When a fragment is to be restored it can mostly use LCPs. In 7.4 there are
    upto 2 LCPs that can be recoverable. However some[1;31mtime[ms an LCP is reported
    as completed to DIH and then crashes before the last GCI written into this
    LCP has completed. In this case one of the LCPs is not restorable and the
    older LCP should be used, which was not happening thus resulting in longer
    restart [1;31mtime[ms.
    
    Fix:
    ----
    
    Ensured that the older LCP is picked up to be restored. Also added test
    coverage to check that the older LCP was picked up and there were no bugs
    in the new flow of execution.

[33mcommit e8538d14d9676ca9fb669996ec1b60481874eb49[m
Author: Mohit Joshi <mohit.joshi@oracle.com>
Date:   Tue Aug 9 15:08:23 2016 +0530

    Bug#24397674 INNODB.DOUBLEWRITE SOMETIMES SKIPS IN PB2 RUNS
    
    Problem: The above test attempts to perform crash recovery. If a checkpoint does not
    occurs during the [1;31mtime[m frame where we want to generate redo log records, the test runs.
    However, if a checkpoint occurs, the test skips because in that case we cannot test the
    recovery.
    
    Due to the above behaviour, the test some[1;31mtime[ms run and some[1;31mtime[ms skip on PB2.
    
    Fix: The fix enables the global debug variable innodb_master_thread_disabled_debug=1.
    This ensures the test always runs. In case, this debug variable is not set by the server
    because of some reasons, we have made changes in the test so that the test exits instead
    of a skip. This will notify us when the test is failing.
    
    Reviewed by: Satya Bodapati <satya.bodapati@oracle.com>
    RB: 13563

[33mcommit 7f9b14de3d63390019fb50f7fdabc1e94eb3852f[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Tue Aug 9 07:37:37 2016 +0200

    WL#8688: Support ability to persist SET GLOBAL settings
    
    This WL introduces an option to persist global dynamic configuration variables,
    for example like SET PERSIST innodb_flush_log_at_[1;31mtime[mout= 14;. Configuration
    variables over a connection are lost after server restart. This WL provides
    DBAs a way to store configuration variables in a persistent way and allow
    server to read and apply all those variables which are persisted during a
    restart. A new config file name mysqld-auto.cnf will be created in datadir
    when a variable is persisted. This new config file is in JSON format.
    
    In addition to the persistence we add a performance schema table called
    "variables_info" which will have an entry for all configuration variables.
    This table will also have information about where the current value came
    from and some additional information about the variable. The historical
    configuration files can be used as before.
    
    This WL provides a read only system variable named persisted-globals-load
    which provides an option to enable/disable reading of persistent config file.

[33mcommit 0149d31b7fd0bb0557af5a294d157510ace30a31[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Wed Aug 3 11:23:15 2016 +0530

    BUG#24350345 : ADD AN MTR OPTION --DO-SUITE TO RUNS SUITES MATCHING A REGEX
    
    Description :
    =============
    MTR has several test suites and some of them are closely related and
    start with same prefix. For eg: rpl, rpl_gtid, innodb, innodb_fts etc.
    Some[1;31mtime[ms there maybe a need to run all innodb suites or all rpl suites.
    Today all innodb or rpl suites have to be passed to --suites option. It
    will be convenient to run them them all by specifying only the prefix.
    
    Fix :
    =====
    Added a new MTR option "--do-suite=PREFIX or REGEX" which runs tests from
    suites whose name is prefixed with PREFIX or fulfills REGEX. If the suite
    name passed to --do-suite doesn't match any of the existing suites then MTR
    run is aborted.
    
    Reviewed-by: Srikanth B R <srikanth.b.r@oracle.com>
    RB: 13530

[33mcommit 1876925b3314346bacf6d364dd1a4fec22054e47[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Jun 27 11:56:57 2016 +0200

    Bug #23759968: ENABLE THE GNU GOLD LINKER
    
    Speeds up linking significantly; on my Debian 8 machine, a rebuild of a single
    unit test (which is almost all linking) is about 50% faster (33% less [1;31mtime[m).
    
    Change-Id: I981b01a34aeaa43e975337a7b93c0bb0880b0b26

[33mcommit 6c41fb311cbe31716bce945579f90a2c42dbd404[m
Author: Jimmy Yang <jimmy.yang@oracle.com>
Date:   Thu Jul 28 09:41:19 2016 +0800

    A Proof of Concept prototype that consists a few key func extracted from
    mysql-trunk-wl7141 and simplified to construct dict_table_t at the [1;31mtime[m
    of ha_innobase::open.

[33mcommit 7f0d7f93ec3c98b349a316b057ae48ef55be1c39[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Thu Jul 21 15:35:56 2016 +0200

    WL#9468: Step 2. Create a template for a stateless allocators which can be
    instantiated with callable class types that use different performance schema
    memory keys.
    
    The std::basic_string template can only be instantiated with allocators that
    are default-constructible (See
    http://gcc.gnu.org/bugzilla/show_bug.cgi?id=56437 "basic_string assumes that
    allocators are default-constructible"). So what is needed is a stateless
    allocator which can use different PSI_KEYS. In order to be stateless the
    PSI_KEYs have to be provided as template arguments. Unfortunately, this is not
    possible, as PSI_KEY values are not compile [1;31mtime[m constants.
    
    This changeset introduces a Stateless_allocator template which takes two type
    arguments that are callable objects (functors) which will be used to allocate
    and deallocate memory. This works because the callable object type is known at
    compile [1;31mtime[m, but the value of the PSI key is not resolved until the allocation
    actually happens. The drawback is that a separate Functor class has to be
    created for each PSI key which will be used with the Stateless_allocator template.

[33mcommit 1e8f4c5460b11e3b7f4d82e89ce7881b633b0869[m
Author: Elżbieta Babij <elzbieta.babij@oracle.com>
Date:   Thu Jul 21 10:25:36 2016 +0200

    Bug#24006602    INNODB.SHOW_ENGINE_STATUS FAILS BECAUSE RW-S LOCK ROUND COUNT DOES NOT INCREASE
    
    This test was introduced by rb#12420 and started failing frequently on PB2 because it was not correct.
    Some[1;31mtime[ms, when we can have lock already, we don't spin at all, hence the count does not increase. What we want to check in this test is whether the count decrease (it would take place if the counter overflow).
    
    RB#13445
    Reviewed by Kevin Lewis.

[33mcommit 8eb8c0049d26ab723afbf8551a18355640282f53[m
Author: Daniel Blanchard <daniel.blanchard@oracle.com>
Date:   Thu Jul 7 13:55:51 2016 +0100

    Bug #23509085 FAILURE IN I_INNODB.INNODB_BUG16097753 ON WINDOWS
    
    Test i_innodb.innodb_bug16097753 fails on Windows 10 and 7 as a
    consequence of the fix to BUG#22305994 TIMESTAMP DATA TYPE PRECISION
    IS NOT ACCURATE UPTO NANO SECONDS ON WINDOWS. The failure is caused
    by the difference in resolution between the timing methods used
    within the innobase and sql libraries that is introduced by the fix
    for BUG#22305994.
    
    The Windows [1;31mtime[m measurement API used for microsecond resolution by
    both the innobase and sql libraries prior to the fix for BUG#22305994
    was the GetSystemTimeAsFileTime API.  After the fix for BUG#22305994,
    the sql library uses the QueryPerformanceCounter API which has a
    higher resolution.
    
    This patch fixes the problem by introducing a new function
    ut_high_res_usec[1;31mtime[m into the innobase library that (on Windows) uses
    the QueryPerformanceCounter API in a similar fashion to its use in
    my_micro_[1;31mtime[m in the sql library.
    
    On non-Windows platforms, ut_high_res_usec[1;31mtime[m is a synonym for
    ut_usec[1;31mtime[m.
    
    Reviewed by: Sunny Bains (sunny.bains@oracle.com)
    RB: 13063

[33mcommit 1d4e796effc05fe2f0d827114481c40e9affc2c1[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Mon Jul 11 04:30:23 2016 +0530

    Bug#22681959 : SELECT ON I_S TABLES WITH CONCURRENT DDL MAY CRASH SERVER
    Bug#22285643 : I_S QUERIES OPENING TMP TABLES FROM ALTER INVALIDATES REFERENCE COUNTER
    
    Executing ALTER command and I_S queries in parallel causes asserts
    in server.
    
    - ALTER command creates temporary metadata for tables.
    - These temporary metadata in written in data dictionary mysql.tables.
    - I_S gets the table list to operate from Data dictionary.
    - Temporary tables from ALTER are also added to I_S table list.
    
    When I_S is queried in parallel to ALTER, the problem arises as follows:
    
    Case I  : Bug#22681959
    ----------------------
    The assert happens in Shared_multi_map<T>::put().
    This assert happens while querying in I_S.
    Scenario ([1;31mtime[m line) leading to this assert is:
    
      Client One                 Client Two
      (ALTER Statement)          (I_S query)
    
    - Creates temporary Table
      with name '#sql..'
    
    -                            Adds temporary Table name
                                 to table list to open
    
    -                            Tries to open temporary table.
                                 Search in the DD cache to
                                 get dd::Table object. Cache misses.
    
    -                            Create dd::Table object for temporary
                                 table by reading metadata from disk.
    
    - ALTER finishes, renames
      entry for temporary table
      from DD.
    
    -                             Tries to put dd::Table for temporary
                                  table in the cache. Assert fails.
    
    Case II : Bug#22285643
    ----------------------
    
    The assert happens in Shared_multi_map<T>::replace().
    This assert happens in ALTER command.
    Scenario ([1;31mtime[m line) leading to this assert is:
    
      Client One                 Client Two
      (ALTER Statement)          (I_S query)
    
    - Creates temporary Table
      with name '#sql..'
    
    -                            Adds temporary Table name
                                 to table list to open.
    
    -                            Acquires all dd objects for opening
                                 temporary table.
    
    - ALTER finishes. Renames
      entry for temporary table
      entry in DD.
      Tries replacing object in
      DD Cache. Hits asserts as
      another thread is using
      the object while ALTER
      is trying to drop it.
    
    Fix:
    ----
    
    Acquire Exclusive metadata lock on temporary table names during
    ALTER operation. When I_S tries to open the table, it requests
    SHARED metadata lock on table names. This will make sure
    ALTER statement is finished before I_S opens the table.

[33mcommit fc655e92e6460da928f03565209a93705ac21dfa[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Wed Jul 6 17:37:03 2016 +0800

    wl#9383 INNODB: ADD AN OPTION TO TURN OFF/ON DEADLOCK CHECKER
    
    Deadlock detection code can be expensive when a lots of threads
    wait for the same lock. Some[1;31mtime[ms, it is much more efficient to
    disable deadlock detection and rely on innodb_lock_wait_[1;31mtime[mout
    to rollback in case of deadlock.
    
    We add a new global configuration variable innodb_deadlock_detect
    to enable or disable deadlock detection, default value is ON.
    
    Reviewed-by: Satya Bodapati <satya.bodapati@oracle.com>
    Reviewed-by: Bin Su         <bin.x.su@oracle.com>
    RB: 12873

[33mcommit 8b8d4faac9a4168caaaf4a47c53597e4d0c523a7[m
Merge: 6e69de4699e 3f2dec2f84f
Author: Anitha Gopi <anitha.gopi@oracle.com>
Date:   Wed Jun 29 07:54:54 2016 +0200

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            mysql-test/t/server_startup_shutdown_[1;31mtime[m.test

[33mcommit 8418d6898ac914c191fac40aa2cfa04d2c780d86[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Fri Jun 24 06:00:11 2016 +0200

    Bug#23297169 - CONSISTENTLY USE THE DATA TYPES SPACE_ID_T AND PAGE_NO_T
    
    Disable the memcached runs for the [1;31mtime[m being, since they fail after
    the push for the above bug.
    
    Approved by Anitha Gopi <anitha.gopi@oracle.com>

[33mcommit 5abd500d22db21e1903b510cce01eb3854380608[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Mon Mar 21 08:14:26 2016 +0100

    Bug#22961128: WRONG RESULT WHEN MANIPULATING RESULT OF JSON_MERGE
    
    The DOM structure returned by JSON_MERGE could some[1;31mtime[ms have
    inconsistencies which confused functions such as JSON_SET and made
    them return wrong results.
    
    The problem was that Json_object::consume() didn't always set the
    parent pointer of the merged nodes, so that some of the merged nodes
    appeared to be root nodes even though they were not.
    
    The fix is to make Json_object::consume() set the parent pointer of
    the merged node when it has merged two object members.

[33mcommit 92e525ff0837c2a0da1f9805aba7eab9f48f9608[m
Author: Thayumanavar S <thayumanavar.x.sachithanantha@oracle.com>
Date:   Tue Jun 21 10:55:52 2016 +0530

    BUG#19502202 - SERVER SHUTDOWN HANG SEEN IN SOME INNODB
                   & RPL TESTS
    
    A MTR test binlog.binlog_xa_prepared_disconnect fails sporadically
    on PB2. When the server is shutdown during the execution of the tests,
    the shutdown of the mysql server doesn't happen within a specified
    [1;31mtime[mout thereby causing SIGABRT to be sent to the server and the test
    aborts.
    As part of the shutdown sequence, sockets are shutdown and closed in
    one thread and this shall cause the POLLHUP event to be generated for
    the sockets that are stuck in poll sleep state on another thread. The
    generation of POLLHUP from the kernel is async and not deterministic
    and [1;31mtime[m-bound.  Hence shutdown hangs and could not complete in a
    specified [1;31mtime[mout period. The patch fixes this by using ppoll in
    vio_io_wait and sending pthread_kill to the thread that is stuck
    on poll when the socket is undergoing shutdown.
    The constructor and destructor functionality to the patch was addded
    by Tor Didriksen <tor.didriksen@oracle.com>.

[33mcommit 64cc276434193f28497b2f9b942166aa925abd7f[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Mon Jun 20 17:25:00 2016 +0200

    BUG#23605817: Check [1;31mtime[mr initialised before calculating [1;31mtime[m spent in SCAN_FRAGREQ/CONF (also BUG#23306695)

[33mcommit ef99f27480d1c03a3880d4680af27fd344d68c34[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Fri Jun 17 12:33:41 2016 +0530

    BUG#12556753 : MTR TESTS FAIL WITH "MYSQLTEST FAILED BUT PROVIDED NO OUTPUT"
    
    Description :
    =============
    Few tests rpl_ps, rpl_extra_col_slave_innodb etc fail on windows
    ([1;31mtime[mout issue) at the very end with "mysqltest failed but provided
    no output" line.
    
    Issue :
    =======
    On windows when [1;31mtime[mout failure occurs, core file is not generated
    and MTR prints the above error message.
    
    Fix :
    =====
    Avoid printing the error messages for test [1;31mtime[mout failures on windows.
    
    Reviewed-by: Sayantan Dutta <sayantan.dutta@oracle.com>
    Reviewed-by: Srikanth B R <srikanth.b.r@oracle.com>
    RB:12973

[33mcommit 9c5412867c3bef6d78f55992eed26509081aed71[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Jun 14 16:54:13 2016 +0200

    Fix several failures in 'testSystemRestart -n SR_DD_n*' tests
    
    Tests where inserting into tables or updating rows at the
    max speed of the test client machines for the duration of
    each test loop.
    
    As the new vigdis servers are fastart than the machines they
    replaced, we are now able to fill the TableSpace and/or
    redo logs to their max sizes, and thus the test failes.
    
    This patch introduce a load limiting machanism which limit
    the client load to 10.000 insert/update/deletes pr sec.
    
    This should also avoid that these tests fails the next [1;31mtime[m
    the ATR test are moved to faster hardware.

[33mcommit 3a5045a048610550755ec495340e2986aea19e2f[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon Jun 13 12:20:23 2016 +0200

    Fix spurious failures in ATR test 'testTransactions'
    
    This test runs a mix of 2 different transaction T1/T2. For some
    of the testcases, the second transaction is supposed to
    be blocked by the first onw , and thus [1;31mtime[mout with either
    error 266 or 274. For other combinations, no such [1;31mtime[mouts are
    accepted.
    
    In order to reduce the elapsed [1;31mtime[m for the test, the TC transaction
    [1;31mtime[mout was reduced to 100ms (default 3000ms). That had the
    negative impact that even transaction combination not expected to
    block each other, code spriously [1;31mtime[mout.
    
    As the setting of TC txn [1;31mtime[mout was a 'global' setting, it
    also remained set after this test had completed, and thus
    could result in [1;31mtime[mouts for later ATR test cases.
    
    This patch:
    
    1) Delay setting of  the 'short [1;31mtime[mout' (100ms) to after
       The first (non-blocking( transaction is executed. Thus
       avoiding 'T1' to [1;31mtime[mout.
    
    2) Sets the 'short [1;31mtime[mout' for T2 only for T1/T2 combinations
       where T2 is expected to fail with a [1;31mtime[mout
    
    3) Set transaction [1;31mtime[mout back to 'default' as soon as the
       T2 has completed, this avoids that the short [1;31mtime[mout
       affects other transactions than the one assumed to [1;31mtime[mout.

[33mcommit 76e6ce9f5809fcf8642781ab1aacdee3a3ef86f3[m
Author: Andrei Elkin <andrei.elkin@oracle.com>
Date:   Tue May 24 12:23:13 2016 +0300

    WL#6591 Restore backup on existing GTID-aware server - make GTID_PURGED settable always
    
    The patch implements the WL agenda.
    
    Currently, it is possible to add GTIDs to GTID_PURGED only when
    GTID_EXECUTED is empty, i.e., when restoring a backup on an empty
    server. The enables to add GTIDs to GTID_PURGED at any [1;31mtime[m, even when
    GTID_EXECUTED is nonempty.
    
    The syntax of the regular assignment expressed by
    
       SET GTID_PURGED = "<gtid_set>"
    
    is augmented with an increment-like append via '+' token
    optionally specified as the first non-white space char in the beginning
    of the gtid set string:
    
       SET GTID_PURGED = "+<gtid_set>"
    
    The right hand side of the regular assigment must be a superset of the
    GTID_PURGED's current value and their set-difference must be disjoint
    with @@GLOBAL.GTID_EXECUTED.
    The right hand side of the "append" assignment set must be disjoint
    with @@GLOBAL.GTID_EXECUTED set.  In neither case it can overlap with
    the current owned GTID set.
    
    client/mysqldump is made to generate version-adoptable SET GTID_PURGED
    with the new append syntax for the new (this patch and later) server
    and the regular assignment syntax for the old (prior the patch)
    servers.

[33mcommit 1be97d669069f9d6c6dcf94345d7237f7fa3417b[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Thu Jun 9 17:53:02 2016 +0300

    Pre-requisite patch for WL#6599 "New Data Dictionary and I_S integration".
    
    Store real row format which is used for the table (as opposed to one
    that was specified explicitly through ROW_FORMAT clause in CREATE TABLE)
    in the data-dictionary TABLES table, so view-based implementation of
    I_S.TABLES can easily show it.
    
    New TABLES.ROW_FORMAT column and corresponding attribute/methods in
    dd::Table were added for this.
    
    Also added new handler::get_real_row_type(HA_CREATE_INFO) method, which
    is called to get this value at the [1;31mtime[m when dd::Table object for new
    table is built.
    
    Old handler::get_row_type() method was removed and its usage is replaced
    with new TABLE_SHARE::real_row_type member which contains real row format
    which was stored at table creation [1;31mtime[m.
    
    Special mechanism was implemented to handle the case when row format
    for MyISAM tables is changed to/from "Compressed" by external myisampack/
    myisamchk tools. When ha_myisam::open() is called we now detect discrepancy
    between row format stored in data-dictionary/TABLE_SHARE::real_row_type
    and MyISAM data/index files and report special HA_ERR_ROW_FORMAT_CHANGED
    error. SQL-layer handles this error by adjusting row format stored in
    the data-dictionary, forcing reloading of table definition and table
    re-open. This mechanism is similar to one which is used for updating
    definitions of NDB tables which were changed on different Cluster nodes.
    Test coverage was added for this functionality.
    
    Also special code was added to handle real row format when InnoDB table
    is ALTERed using INPLACE algorithm.
    
    The problem is that INPLACE algorithm implementation in InnoDB might
    choose different real row format than one that would have been choosen
    for COPY case. Since dd::Table object which includes information about
    real row format is created well before point where we make a choice
    between INPLACE and COPY it needs to be updated to reflect correct
    row format in case when INPLACE algorithm has been chosen. We allow
    InnoDB to do this by passing dd::Table object for new table version
    to handler::ha_prepare_inplace_alter_table() similarly to how it
    will be done after WL#7743 is implemented.
    
    Finally, ROW_TYPE_PAGE element of row_type enum was renamed to
    ROW_TYPE_PAGED for the sake of consistency.

[33mcommit b605c4df2f2dbbf91fd066d8ca785d4c2ad4f8b4[m
Author: Ole John <ole.john.aske@oracle.com>
Date:   Wed Jun 8 12:32:02 2016 +0200

    Bug #23553267   DEADLOCK WHEN MDL_EXCLUSIVE ACQUIRES A GLOBAL SCHEMA LOCK (GSL)
    
    This patch use the existing MDL deadlock resolution (backof and retry) mechanism already
    existing in the MDL locking code to solve a potential deadlock between
    MDL_EXC>LUSIVE and GSL locks.
    
    NdbCluster code for acquiring a Global Schema Lock has been changed
    to not retry the GSL lock if it failed due to a [1;31mtime[mout (default 3000ms),
    *and* there is a potential for this lock request participating in a MDL-GSL
    deadlock. In these cases it select itself as a 'victim', and return
    this decission to the MDL requestor.
    
    The MDL code has been changed to handle the 'victimized' case
    as a deadlock, and thus follows its existing code paths for resolving
    that.

[33mcommit bbe68617da175f9198423f33f11ed0501605dfa9[m
Author: Sreeharsha Ramanavarapu <sreeharsha.ramanavarapu@oracle.com>
Date:   Thu Jun 2 08:20:54 2016 +0530

    Bug #23212765: ASSERTION FAILED: SP_RESULT_FIELD
    
    ISSUE:
    ------
    This problem occurs under the following conditions:
    1) A function returns a json value.
    2) This function is called as part of a case statement in a
       procedure.
    
    SOLUTION:
    ---------
    Once the case_value is evaluated, it is stored in a
    Item_cache_* object. The function values are then cleaned
    up. The Item_cache_* object in turn becomes part of a
    Item_func_eq object (to test the equality with the value in
    the WHEN clause).
    
    item.h:
    While preparing the WHEN clause,
    Item_cache_json::result_type is called. This function tries
    to access the example object, which is the original object
    from which it was created. But the attributes of the
    example object have already been cleaned up after the
    function was evaluated.
    
    There is really no need for Item_cache_json::result_type to
    lookup the example object. The result type for this object
    will always be STRING_RESULT.
    
    
    item_func.cc:
    1) Item_func_sp::execute is supposed to return true only
       when there is an error. But it returns null_value flag,
       which is just wrong. Also, this leads to some incorrect
       treatment of the return value from execute() function
       in some places.
    
    2) One such place is Item_func_sp::val_json. A null value
       is treated as equivalent to an error and true is
       returned here too. This has been corrected.
    
    These changes influence whether the value_cached flag is
    set in Item_cache_json::cache_value. Here inadvertently,
    this is set to false, despite the evaluation, we will see
    incorrect behavior at a later stage.
    
    item_func.h:
    For Item_func_sp::val_str, a null value should be returned
    whether there was an error from the execute or the result
    of the function was actually a null value. Similar changes
    are made for other val_* and get_[1;31mtime[m/date functions.

[33mcommit a66f03f8eb1245d67d29832f6cb2b68ecbf617ca[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Wed Jun 1 17:20:29 2016 +0100

    WL7656 Per fragment locks info
    
    Further test stabilisation
    
     - ndbinfo_cluster_locks
       - SCAN vs other lock types - scan locks will be converted
         to READ locks by takeover ops, and whether these are issued
         or not depends on timing, data distribution etc.
         Therefore, the type of the locks is ignored in two affected
         testcases.
    
     - ndbinfo_cluster_locks + ndbinfo_locks_per_fragment
       - Testcases where sine kind of 'successful wait' is to be
         observed : Slow platforms turn this into transaction
         [1;31mtime[mout.
         Solution : Disable transaction [1;31mtime[mout where we
         do not want it.  This involved enhancing an existing
         DUMP code in DbtcMain to allow it to 'reset' the
         [1;31mtime[mout to the configured value.
    
     - ndbinfo
       - Remove existing testcase side-effect of dropping ndb$test
         as this makes test 1-shot only, not suitable for use with
         mtr --repeat
    
     Also : Remove missing newline at end of ndbinfo_init_frag_lock_count.inc
     which meant it could cause parse issues in the including
     .test file.

[33mcommit d7afcc374d3fe69812996d3a033e8e184321e296[m
Author: Daniel Blanchard <daniel.blanchard@oracle.com>
Date:   Tue May 31 17:21:02 2016 +0100

    BUG#22305994 TIMESTAMP DATA TYPE PRECISION IS NOT ACCURATE UPTO NANO SECONDS ON WINDOWS
    
    Post push fix. The queues unit test uses my_getsys[1;31mtime[m(), which now requires
    initialization via my_init() before first use on Windows.
    
    Reviewed by: Jon Olav Hauglid <jon.hauglid@oracle.com>, Tor Didriksen
    <tor.didriksen@oracle.com>
    RB: 12870

[33mcommit 372a0d75d5392bfe0f8958e9580034c9c4466716[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Wed May 25 15:17:06 2016 +0200

    Bug#23343739 7.4 MYSQLD HANGING IN SHUTDOWN (NOW IN NDB UTIL)
    
     - Mutex deadlock occured due to different mutex locking order. The
       m_start_stop_mutex in Ndb_component was being held while calling
       do_wakeup() which each componenent should imeplement. In the two
       deadlocking components it was taking the local mutex before
       signalling the wakeup condition.
       The is_stop_requested() function on the other hand, was called with
       the componenents local mutex held and trying to lock the
       m_start_stop_mutex. Thus deadlock could occur when calling
       Ndb_component::stop()
     - Fix by releasing the m_start_stop_mutex when calling the do_wakup()
       function
     - Also remove one unnecessary call to is_stop_requested() in
       Ndb_util_thread and write descriptive comment instead describing
       how Nbd_util_thread wakes up. Basically it always wait on
       the condition to make some [1;31mtime[m pass before next loop and only in
       rare cases it will wake up because it has been stopped.

[33mcommit ec1e011908f2d683bded1a66dcede6d59678da51[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Mon May 30 23:57:13 2016 +0100

    WL#7656 Per fragment locks information
    
    Three new Ndbinfo views added :
    
     - locks_per_fragment
    
       Companion table to operations_per_fragment and memory_per_fragment.
       Keyed in a similar way.
       Shows counts of lock claim requests, and their outcomes per
       fragment.  Shows total [1;31mtime[m spent waiting for locks successfully
       and unsuccessfully.
    
     - cluster_locks
    
       Companion table to cluster_operations.
       Keyed in a similar way.
       Shows current lock requests holding and waiting for locks.
       Allows stalls and deadlocks to be investigated.
    
     - server_locks
    
       Companion table to server_operations.
       Keyed in a similar way.
       Essentially a subset of cluster_operations, for transactions
       running on the local MySQLD, showing a connection id per
       transaction.
    
    The two tables are based on two underlying tables
      - ndb$frag_locks (locks_per_fragment)
      - ndb$acc_operations (cluster_locks, server_locks)
    
    Three new testcases added :
      - ndbinfo_locks_per_fragment
      - ndbinfo_cluster_locks
      - ndbinfo_server_locks

[33mcommit 2709cb6abc45a2a38ba12e8467be92f2a5801c72[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Wed May 18 10:52:28 2016 +0200

    BUG#23225768 NDBCLUSTER SHOULD USE MYSQL_MUTEX_T WRAPPER
    
    - In MySQL Server 5.7 the mutex and condition was refactored into
      three layers of mutex types available from mysys. This caused all
      ndbcluster code using pthread_mutex_t to start using the
      native_mutex_t instead. This change causes merge conflicts all the
      [1;31mtime[m and also makes it impossible to use for example
      the safe_mutex functionality which can help find cases where
      dependent locks are held or not.
    - Fix by changing to use mysql_mutex_t in ha_ndbcluster.
      The mutexes will not be performance schema instrumented at this
      [1;31mtime[m.
    - Move mutex initializers in Ndb_index_stat_thread and Ndb_util_thread
      which are "static global" to do_init() so that they are created after
      the safe mutex functionality is initialized. Corresponding
      change to deinit function.

[33mcommit aea4eebc3512a943de7ad559d89fed8ae1c577a2[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Thu May 26 12:55:04 2016 +0200

    WL#8579 Spatial Reference Systems
    
    Post push fix.
    
    Modify timing sensitive test to make sure they fully restore the
    mysql.user table with correct [1;31mtime[mstamps before finishing.

[33mcommit b7b7d4483b02d8a59bf671984669eac0ba7385b1[m
Author: Daniel Blanchard <daniel.blanchard@oracle.com>
Date:   Wed May 11 12:39:50 2016 +0100

    BUG#22305994 TIMESTAMP DATA TYPE PRECISION IS NOT ACCURATE UPTO NANO SECONDS ON WINDOWS
    
    Problem:
    my_micro_[1;31mtime[m() on Windows was implemented using
    GetSystemTimeAsFileTime which has a resolution of approx 1000
    microseconds.  This could result in duplicate SQL [1;31mtime[m stamp values,
    detectable with the innodb.[1;31mtime[mstamp test.
    
    Fix:
    Use QueryPerformanceCounter for the Windows implementation of
    my_micro_[1;31mtime[m (appropriately scaled to return a value in microseconds).
    
    Also tidied win_init_[1;31mtime[m: as support for Windows XP is now dropped,
    we can guarantee that the return value of QueryPerformanceFrequency
    will never be zero.
    
    Enable innodb.[1;31mtime[mstamp.test
    
    Note:
    Measurement of the drift of  the new my_micro_[1;31mtime[m implementation using
    QueryPerformanceCounter relative to the previous implementation that
    used GetSystemTimeAsFileTime shows a drift of approx 1 second per day.
    Thus my_micro_[1;31mtime[m should only be used for measuring relatively short
    periods between two instants.

[33mcommit 1dfc8f0641ed0ecf1f038e887c2908b100c58f21[m
Author: Andrei Elkin <andrei.elkin@oracle.com>
Date:   Fri Feb 26 19:51:28 2016 +0200

    WL#6591 Restore backup on existing GTID-aware server - make GTID_PURGED settable always
    
    The patch implements the WL agenda.
    Currently, it is possible to add GTIDs to GTID_PURGED only when
    GTID_EXECUTED is empty, i.e., when restoring a backup on an empty
    server. The enables to add GTIDs to GTID_PURGED at any [1;31mtime[m, even when
    GTID_EXECUTED is nonempty.
    
    The syntax of the regular assignment expressed by
    
       SET GTID_PURGED = "<gtid_set>"
    
    is augmented with an increment-like append via '+' token
    optionally specified as the first non-white space char in the beginning
    of the gtid set string:
    
       SET GTID_PURGED = "+<gtid_set>"
    
    The to be assigned set must be a superset of the GTID_PURGED's current value.
    The to be appended set must be disjoint from the latter.
    
    client/mysqldump is made to generate version-adoptable SET GTID_PURGED
    with the new append syntax for the new (this patch and later) server
    and the regular assignment syntax for the old (prior the patch)
    servers.

[33mcommit 05ca74b01519c7fb76f34877b4a5401a5cc705c1[m
Author: Dinesh Surya Prakash <dinesh.prakash@oracle.com>
Date:   Wed May 11 13:59:14 2016 +0530

    Bug#21098142 7.4 MYSQLD HANGING IN SHUTDOWN
    
    When we do a "shutdown" in mysqld, a deadlock occurs if there is a thread
    executing ndb_index_stat at the same [1;31mtime[m.
    
    The ndb_index_stat thread first takes a local lock and then tries to
    acquire a global lock. At the same [1;31mtime[m, the  shutdown thread takes the
    same global lock first and then tries to acquire the same local lock.
    
    Fixed the index stat code to separate the critical sections for the global
    lock and the local lock. Now the local lock is released before taking the
    global lock, so the deadlock is avoided.

[33mcommit f88fd4e0fc5d5e6f47e4bde45d00e6cd269dd02d[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Wed May 11 11:08:09 2016 +0200

    Bug#23265447 TEST_EVENT -N CREATEDROPEVENT_NF T1 [DBDICT (LINE: 18834)]
    
    The test 'test_event -n createDropEvent_NF T1' is expected to verify that
    dropEvent succeed even if master node crash at a specific [1;31mtime[m.
    
    This is tested by triggering a crash in Dbdict::execSUB_REMOVE_REF by an
    error 6125 insertion.
    
    Unfortunately it seems that the master node do not crash, or not seen
    crashing, before the test have ended.
    
    And then occasionally some other test that runs later fails instead.
    
    This patch adds a wait for the master node to stop during the test, this
    ensures that following test runs will not crash due to a late crash from
    error 6125 insertion.
    
    There can still be a failure in the test itself, this is not examined
    further in this bug which focus on removing the effect on other unrelated
    test runs.

[33mcommit 89640edfb89130cdf37ba4dec41b4395f7d361ac[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Mon Mar 14 19:33:14 2016 +0100

    Bug#22926938 ACC TABLE SCAN MAY SCAN SAME ROW TWICE
    
    While scanning a Ndb table using hash index some rows could be scanned
    twice if table grows and shrinks alternately.
    
    Each partition is a linear hash table which can expand or shrink by one
    bucket at the [1;31mtime[m during the scan.
    
    The old logic did not take into account that already scanned buckets could
    be split resulting in scanned top buckets which was later merged back.
    
    The old logic wrongly always cleared the scan state of merged back buckets.
    
    Furthermore it wrongly assumed that there could been any scanned buckets
    merged into buckets below the top bucket when scan started.
    
    This patch make sure that buckets only have the scan bit cleared when it is
    known to have undefined scan bits.

[33mcommit 1c8b6a4d8f834a740c2b9335c7968b58e7202441[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue May 10 09:26:09 2016 +0200

    Bug#23202735 CLIENT PERFORMANCE REDUCED DUE TO THREADS WOKEN UP TOO EARLY
    
    This patch fixes two issues related to threads being
    woken up when not needed, and thus resulting in unnecessary
    context switches.:
    
    1)
    Avoid API Clients waiting in the poll queue to be woked up every 10ms.
    
    The 'poll-right' is given to (only!) one of the clients waiting
    for do_poll. The rest of the clients just wait there such that
    they can be woken up when the poller delivers something to them.
    However, a max wait [1;31mtime[m of 10ms is currently enforced, such that
    they may be woken to immediately be put back to sleep. This also
    implies dequeuing and requeing in the mutex protected poll queue.
    
    Iff the client threads waiting in the poll queue are properly
    signaled when signals are delivered, there should be no need to
    wake them up regularly. This patch removes the enforced 10ms max
    wait [1;31mtime[m, and instead wait the [1;31mtime[m specified by the callee.
    
    2)
    Fix a performance problem in ::do_poll() where the polling 'clnt' does not
    check whether it has been woken up *itself* before completing the poll.
    
    It is sufficient that only some trp_client's in the poll-queue
    received data. ::do_poll will then signal these clients and
    give up its poll right, even if the max specified wait_[1;31mtime[m
    have not expired.
    
    Thus, another of the clients in the poll-queue has to be
    appointed as the new poller, and a *thread switch* is required
    to wake up that thread for more do_poll work.
    
    This patch allows do_poll() to continue polling until
    either the max specified wait_[1;31mtime[m have expired, or
    the polling client itself has been woken up (by being
    delivered what it waited for) This avoid unnecessary
    thread switches between the client threads and thus
    reduce the overhead in the API client. This results
    in a ~10% performance improvement when the client
    threads does the polling themself.
    
    This is similar to the mechanism already implemented
    in the receiverThread, which explicit request to 'stay poll owner'
    when it has been activated. We still see that having the receiverThread
    doing the poll is faster than using the client thread. However,
    we believe that most of this is due to the receiver thread allowing
    more trp_client to have delivered signals before signaling them
    vs the client threads. (256 vs 16)

[33mcommit c068516923bed2f5ddf8971e5a3380406a793831[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Mon May 9 11:45:35 2016 +0530

    Bug #21097957 IMPROVE NDB_RESTORE OUTPUT/LOGGING
    
    Added more log prints for every stage of restore.
    Also attached [1;31mtime[mstamp with the logs.

[33mcommit cab294f31e351d159e2e6d17dad32f8ab146d61b[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Fri May 6 14:05:51 2016 +0200

    WL#6378: New data dictionary
    
    Follow-up patch: Refactor Collection and Iterator
    usage in the new data dictionary code base.
    
    This patch removes the dd::Iterator interface. Dictionary
    collections instead have iterators that conform to std::iterator.
    This means that they can be used for STL algorithms and
    range-based for-loops. Instead of returning an iterator,
    type classes now return a const reference to dd::Collection
    which implements begin() and end().
    
    The patch combines dd::Base_collection and dd::Collection
    into one class. The internal std::vector now contains pointers
    to the actual Impl classes, rather than to dd::Collection_item.
    This means that dd::Collection_item could be removed. Instead,
    a typedef in the abstract type classes point to the impl class.
    
    dd::Collection_item_factory is also removed. Instead, it
    is expected that impl clases implement static restore_item()
    and clone() functions.
    
    Set and Enum elements are now stored in a single collection
    for columns and parameters. This is possible since columns
    and parameters cannot have both types at the same [1;31mtime[m.
    
    The new iterators do not support skipping of hidden items.
    Instead this is expected to be handled by the API user by
    checking is_hidden() for the individual items as needed.
    
    Partitions are no longer sorted by default. This must again
    now be handled by the API caller. This makes it possible
    to handle partitions similar to other types. The dd_partition
    unit test was removed as it only tested sorting.
    
    The patch also removes a lot of const_casts and dynamic_casts.

[33mcommit eda9201048d495932261d4ae93631ee9704a6c3d[m
Author: Annamalai Gurusami <annamalai.gurusami@oracle.com>
Date:   Thu Apr 28 12:29:00 2016 +0530

    WL#9141 InnoDB: Refactor uncompressed BLOB code to facilitate partial
    fetch/update
    
    Introduction:
    =============
    
    This is a sub worklog of "WL#8960 InnoDB: Partial Fetch and Update of BLOB".
    This worklog is the second sub worklog followed by "WL#8985 InnoDB: Refactor
    compressed BLOB code to facilitate partial fetch/update". The purpose of this
    worklog is to refactor current code so that new BLOB features can be added
    conveniently.  This worklog does to uncompressed BLOB similar to what wl#8985
    did to compressed BLOB code.
    
    Logical Changes:
    ================
    
    .  The functionality of uncompressed BLOB is provided by C-style functions.
       This will be converted to C++ classes, structs and member functions.
    .  The BLOB code will be isolated and kept in lob0lob.h and lob0lob.cc files.
       This will help in modular development of BLOB features.
    .  All references will now be LOB (large objects).
    
    Detailed Changes:
    =================
    
    . Introduced new module named lob.  It contains lob/lob0lob.cc and
      include/lob0lob.h files.
    . Added new namespace lob.
    . lob::Inserter - a new class to insert a complete uncompressed BLOB.
    . lob::zInserter - a new class to insert a complete compressed BLOB.
    . lob::InsertContext - a new class to contain contextual information for the
       insert operation.
    . lob::BaseInserter - a class that holds common state and functions useful
       for both compressed and uncompressed BLOB.  This is the base class for
       lob::Inserter and lob::zInserter.
    . lob::Deleter - a new class to destory/delete a BLOB
      (both compressed/uncompressed)
    . lob::DeleteContext - a new class to contain contextual information for the
      delete operation
    . lob::Reader - a new class to fetch a uncompressed BLOB.
    . lob::zReader - a new class to fetch a compressed BLOB.
    . lob::ReaderContext - a new class to contain contextual information for the
       fetch operation
    
    Design Rationale:
    =================
    
    There are 2 approaches that I explored - one is to have a single LOB class with
    each major operations as an member function.  For example,
    
    class LOB {
    public:
       int insert();
       int update();
       int read();
       // ..
    private:
       // ...
       Context* m_ctx;
    };
    
    But doing it this way, will make the class LOB like a kitchen sink.  It will
    end up that some member variables are used only when we are doing insert
    operation, and some other member variables are used when doing read operation
    and so on.  There won't be any cohesion b/w the member variables and member
    functions.  For one instance of the LOB class, we will most likely use only one
    operation, eg insert.  This is the reason I didn't prefer this approach.  The
    other approach is to design LOB classes around the major operations that will
    be performed, which truely reflects the way these classes will be used.
    
    The current design of LOB classes revolves around the way the major operations
    that will be performed on LOB data.  The currently supported major operations
    are insert, delete and read.  As of now all of them operate on complete LOB
    data.  For each of the major operation one new class is introduced.
    
    Inserter - for inserting LOB data.
    Reader   - for reading LOB data.
    Deleter  - for deleting LOB data.
    
    Now there are two variants to LOB data - compressed and uncompressed.  An
    insert operation or a read operation is completely depended on whether the data
    is compressed or not. But a delete operation is not that much dependant on
    this. Hence I introduced separate classes for compressed LOB.
    
    Inserter - for inserting uncompressed LOB data.
    zInserter - for inserting compressed LOB data.
    Reader   - for reading uncompressed LOB data.
    zReader   - for reading compressed LOB data.
    Deleter  - for deleting both compressed and uncompressed LOB data.
    
    At this point I noticed that there was some common code between Inserter and
    zInserter which I can factor out into a base class.  So I introduced
    BaseInserter which will contain common state and function useful for both
    Inserter and zInserter.  So the final list of main LOB classes are:
    
    Inserter - for inserting uncompressed LOB data.
    zInserter - for inserting compressed LOB data.
    BaseInserter - a base class containing common state and functions useful for
                       both Inserter and zInserter.  Inserter and zInserter derives
                       from this base class.
    Reader   - for reading uncompressed LOB data.
    zReader   - for reading compressed LOB data.
    Deleter  - for deleting both compressed and uncompressed LOB data.
    
    One point to be noted is that these classes are formed by refactoring existing
    code.  So to reduce the amount of code changes, I allowed some differences in
    the way they operate.  The Inserter and zInserter class is designed to insert
    all the LOB data of a single clustered index record.  It operates on the big
    record vector.  But the other classes (Reader, Deleter, zReader) all operate
    on a single LOB data only.  By doing it this way, I avoid significant amount
    of code changes.
    
    The main classes of the LOB module has been identified above.  To support them
    there was a need to provide context classes that will contain information needed
    for LOB operation.  Previously, the C style functions had a list of 6 or 7
    arguments.  These arguments are the context information that is necessary to provide
    the various main operations on LOB data.  For each main operation, the context
    information is identified separately.  They are as follows:
    
    InsertContext - context information for doing insert of LOB. `
    DeleteContext - context information for doing delete of LOB. `
    ReadContext   - context information for doing fetch of LOB. `
    
    The insert operation also has one special optimization - the bulk insert.
    These context classes evolved separately as I refactored one operation at a
    [1;31mtime[m.  And when I look back, I don't see any need to club them all together.
    There are some specific checks that are done only for the insert operation,
    like the redo log space check, which are captured in the InsertContext.  If
    we have a single context class, then it will contain unnecessary information
    not usable for the current operation.  Also, all these context classes are
    arrived at based on how and where it will be used.
    
    Finally, while evaluating this design, please do keep in mind that these
    classes come out of refactoring existing code.  If you look at the patch, the
    amount of code changed where LOB module is _used_ is very minimal.  I think my
    main focus was to isolate the LOB code and design a set of C++ classes which
    will make the extension of functionality easier.
    
    And the main purpose of refactoring was to enable to add partial fetch and
    partial modify/update operations.  For these purposes, I believe that this
    design is suitable.  Surely one can do more and more refactoring to achieve
    better results.  But since we are doing refactoring for a particular purpose, I
    think we should stop when our purpose will be solved.
    
    Functions Removed:
    ==================
    
    The following functions has been removed.
    
    . btr_copy_blob_prefix()
    . btr_copy_externally_stored_field_prefix_low_func()
    
    Functions Moved to lob module:
    ==============================
    
    The following functions are moved to the lob module.
    
    . btr_copy_externally_stored_field_prefix_func() and the associated
      macros.
    . btr_rec_free_updated_extern_fields()
    . btr_blob_get_part_len()
    . btr_blob_get_next_page_no()
    . btr_check_blob_fil_page_type()
    . btr_rec_free_externally_stored_fields()
    . btr_copy_externally_stored_field_prefix_func()
    . btr_copy_externally_stored_field_func()
    
    rb#11861 approved by Deb.

[33mcommit 8e49ce997af9b7b191706b3e414ca9722ed53224[m
Author: Viswanatham Gudipati <viswanatham.gudipati@oracle.com>
Date:   Thu May 5 18:08:18 2016 +0530

    Bug #22305994 : innodb_mysql.test fails frequently on PB2 machine due to TIMESTAMP data type is not accurate
    upto nano seconds on windows
    
    Problem : The innodb_mysql.test is more unstable on PB2 machines due to the reason of [1;31mtime[mstamp datatype
    column precision is not accurate on windows platform , because it is a product bug  on server side.
    
    solution: Remove the failure testcase from innodb.innodb_mysql.test and make it separate as [1;31mtime[mstamp.test and
    disable the testcase ([1;31mtime[mstamp.test) to run on windows platform, until the actual product issue is resolved.
    once the product issue is resolved by dev , he has to enable the testcase ([1;31mtime[mstamp.test) to run on Windows
    This bug will be kept open, until that [1;31mtime[m (product issue is resolved).
    
    RB : 12561

[33mcommit 3c270a5f78e8625ad5110b72f7a578a035443f5c[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Wed May 4 09:31:26 2016 +0200

    Bug#23195845: FIX COMPILE WARNINGS REPORTED BY GCC 6.1
    
    Fix compile warnings reported by recently released GCC 6.1:
    
    -Werror=misleading-indentation
    libbinlogevents/src/uuid.cpp
    rapid/plugin/x/mysqlxtest_src/mysqlx.cc
    sql/sql_update.cc
    This error had to be disabled for files using Boost.
    
    -Werror=nonnull-compare
    storage/innobase/include/dict0dict.ic
    
    -Werror=logical-op
    mysys/mf_dirname.cc
    sql/item_[1;31mtime[mfunc.cc
    sql/mysqld.cc
    vio/viosocket.cc
    
    Also fix problem in mysys/my_sync.cc where we were using
    __linux rather than the correct __linux__ symbol.

[33mcommit 3e1fc23ceba3726926584dc7b34a10e49faee42c[m
Author: Craig L Russell <craig.russell@oracle.com>
Date:   Mon Apr 25 14:02:15 2016 -0700

    Bug 23155061 - CLUSTERJ STORES WRONG VALUES FOR JAVA.SQL.TIMESTAMP FOR TIMESTAMP(N)
    
    clusterj/tie/Utility.java
    
    Change behavior of packFractionalSeconds and unpackFractionalSeconds
      TIMESTAMP(1) truncate all but tenths
      TIMESTAMP(2) truncate all but hundredths
      TIMESTAMP(3) no truncation; all values fit
      TIMESTAMP(4) truncate all but milliseconds
      TIMESTAMP(5) truncate all but milliseconds
      TIMESTAMP(6) truncate all but milliseconds
    Add debugging statements
    
    mysql-test/suite/ndb/t/clusterj.test
    
    Add [1;31mtime[mstamp2types to clusterj.test cleanup
    
    testsuite/clusterj/tie/Timestamp2AsSqlTimestampTypesTest.java
    testsuite/clusterj/Timestamp2AsSqlTimestampTypesTest.java
    
    Add test for writing and reading TIMESTAMP(n) types
      millisecond values are all stored
      TIMESTAMP and TIMESTAMP(0) all millisecond values are truncated
      microsecond values are truncated to millisecond
      java.sql.Timestamp includes getNanos and setNanos
      methods to read/write via JDBC are commented and might be
        implemented in future
    
    testsuite/clusterj/model/Timestamp2AsSqlTimestampTypes.java
    
    Model class that maps all supported [1;31mtime[mstamp(n) types
    
    main/resources/schema.sql
    
    Schema file adds [1;31mtime[mstamp2types

[33mcommit c37722d743a85fd8d582b32e568756b7670b746e[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Mon Apr 25 15:28:56 2016 +0200

    Bug#22748217 gcols: assert in Item_func_in::resolve_type
    
    Item_func_in::resolve_type() does not expect an error condition without
    a signalled return value. Unfortunately, the error setting is here so
    convoluted that a fairly large refactoring would be needed to resolve
    the problem. The error is set at the bottom of this call stack:
    
      Item_func_in::resolve_type()
        convert_constant_item()
          Item::save_in_field()
            Item_int::save_in_field_inner()
              save_int_value_in_field()
                Field_temporal::store()
                 set_warnings()
    
    Error fixed by converting assert into run[1;31mtime[m test.

[33mcommit 32a9253c4b31bf57f6c8474e45e11a84ae2b3ac8[m
Author: Srikanth B R <srikanth.b.r@oracle.com>
Date:   Mon Apr 25 14:31:07 2016 +0530

    Bug#22720753: ENABLE OR REMOVE THE DISABLED TESTS UNDER ENGINES SUITE
    
    There are several tests in the engines suite which are in disabled
    state from a long [1;31mtime[m. They have been evaluated whether they are
    required, or are removed. The tests which have been retained have
    been fixed to conform to the current behaviour.
    
    Reviewed by:
    Amit Bhattacharya <amit.bhattacharya@oracle.com>
    RB #11957

[33mcommit d03b83efe6976f86defc45fe05db1334f9a39e3d[m
Author: Karthik Kamath <karthik.kamath@oracle.com>
Date:   Tue Feb 9 12:12:37 2016 +0530

    BUG#21104464: QUERY CACHE TEST CASE TAKES A LONG TIME TO
                  EXECUTE ON INNODB STORAGE ENGINE
    
    ANALYSIS:
    =========
    The query_cache test case currently runs using MyISAM
    storage engine. When migrated to run on InnoDB storage
    engine, the test case takes a reasonably long [1;31mtime[m to
    complete.
    The increased insertions create a delay since the test case
    has been modified to use InnoDB, which incurs additional
    overhead in comparison to MyISAM.
    
    Fix:
    ====
    Some of the insert queries have been removed by ensuring that
    the query cache limit is overshot by the previous insertions.
    (The test case checks for query cache boundary conditions).

[33mcommit fa49f62995e8adaae6844cae9315781c7a432f39[m
Author: Daniel Blanchard <daniel.blanchard@oracle.com>
Date:   Fri Apr 15 11:34:24 2016 +0100

    BUG #22608247 RESULT CONTENT MISMATCH IN BINLOG.BINLOG_MYSQLBINLOG_ROW AND FRIENDS
    
    Problem:
    --------
    This is a known bug in Visual Studio 2015 C Run[1;31mtime[m (Connect#1902345)
    https://connect.microsoft.com/VisualStudio/feedback/details/1902345
    
    The bug in _read is as follows:  If...
    
    1.       you are reading from a text mode pipe,
    2.       you call _read to read N bytes,
    3.       _read successfully reads N bytes, and
    4.       the last byte read is a carriage return (CR) character,
    
    then the _read function will complete the read successfully but will
    return N-1 instead of N.  The CR or LF character at the end of the result
    buffer is not counted in the return value.
    
    The bug is fundamentally timing-sensitive because whether _read can
    successfully read N bytes from the pipe depends on how much data has been
    written to the pipe.  Changing the buffer size or changing when the buffer
    is flushed may reduce the likelihood of the problem, but it won't
    necessarily work around the problem in 100% of cases.
    
    Fix:
    ----
    The workaround is to use a binary pipe and do text mode CRLF => LF translation
    manually on the reader side.
    
    Note that this workaround should no longer be necessary when the next
    update to the Universal CRT ships, which is likely to occur around the same
    [1;31mtime[m as the Windows 10 Anniversary Update this summer (2016).
    
    Reviewed-By: Bjorn Munch <bjorn.munch@oracle.com>
    RB: 12384

[33mcommit 666756d01ccb55d2f023aeeaaa228b796690043f[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon Apr 11 12:05:30 2016 +0200

    Bug#23081045 RPL_SHOW_SLAVE_HOSTS USES TOO LOW SLAVE-NET-TIMEOUT VALUE
    
     - slave fails to connect to master due to too low slave-net-[1;31mtime[mout
       value, occurs on slower hosts or when running mysqld in valgrind.
     - fix by removing the low slave-net-[1;31mtime[mout value and instead force
       the master's dump thread to wake up and detect that slave
       disconnected by running some dummy DDL.

[33mcommit 8d5c4bc2eba3dc2eeee2822ae847c5559dbe6295[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon Apr 11 12:05:30 2016 +0200

    Bug#23081045 RPL_SHOW_SLAVE_HOSTS USES TOO LOW SLAVE-NET-TIMEOUT VALUE
    
     - slave fails to connect to master due to too low slave-net-[1;31mtime[mout
       value, occurs on slower hosts or when running mysqld in valgrind.
     - fix by removing the low slave-net-[1;31mtime[mout value and instead force
       the master's dump thread to wake up and detect that slave
       disconnected by running some dummy DDL.

[33mcommit 8f9d88745fe0823b8ccd529aade76336b71f29af[m
Author: Priyanka Sangam <priyanka.sangam@oracle.com>
Date:   Tue Apr 12 14:12:57 2016 +0530

    [PATCH] Bug #20368450   ADD DEBUGGING FOR GETTABINFOREQ QUEUEING AT DICT
    
    Optional debugging output is added to NdbApi and DICT. Ndbapi output can
    be enabled using ApiTrace>=2 in the config file for the relevant API
    'slots'. DICT output can be enabled using DictTrace>=2 in the config file
    for the relevant ndbd 'slots'. These will dump information about DICT
    wait [1;31mtime[mouts, that may help solve problems in this area.
    
    Debugging info will be output periodically until the causing condition(s)
    clear.

[33mcommit bdbcfdcaa1b33d807f824cc21b12c2d789d27d3e[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Apr 8 12:31:19 2016 +0200

    WL#8351: Use statistics to determine #objects in Ndb_free_list_t
    
    The utility 'class NdbStatistics' is added which allow
    incremental statistics to be calculated over a sliding windows
    of statistics samples.
    
    A member of type 'class NdbStatistics' is then added to
    each instance of 'template<class T> Ndb_free_list_t'
    and used to sample the max number of objects in use
    each [1;31mtime[m a peak is reached.
    
    An upper 95% percentile of objects in use is then
    calculated for the statistics window, and used to determine
    if a released objects should be stored in the free_list
    for later reuse, or returned to the heap manager (deleted)
    
    This should avoid that temporary peaks in NdbApi object
    allocated, cause a permanently increase in the memory
    footprint of the API client / mysqld.

[33mcommit 18771a83fdd45662d262c29813f9b041455f9ba8[m
Author: Darshan M N <darshan.m.n@oracle.com>
Date:   Wed Apr 6 14:18:24 2016 +0530

    Bug#22884631 FAILING ASSERTION: TRX->DUPLICATES == 0
    
    Issue:
    ======
    When server uses a TABLE* created by one thread in another,
    we generally update the trx associated in
    ha_innobase::external_lock() or the first handler call (we
    have update_thd() in many handler functions).
    
    With invalid statements like wrong number of fields for an
    insert,it is possible server opens a table using the used
    TABLE* handle, then detects the wrong fields and skips the
    external_lock() call or other handler calls like extra() or
    info().
    
    ha_innobase::end_stmt() is directly called to end the
    statement. At this [1;31mtime[m, the trx is still not updated and
    this causes the assert failure.
    
    Fix:
    ====
    In ha_innobase::end_stmt(), we first check if the
    prebuilt->trx has been updated or not. We skip the assert
    if it has not been updated.
    
    RB: 12277
    Reviewed-by: Satya Bodapati <satya.bodapati@oracle.com>

[33mcommit 5c85284546c705119123eb1079f685a4aa793710[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Wed Apr 6 12:00:39 2016 +0530

    Bug#22948828: REFACTOR USAGE OF MY_MICRO_TIME()
    
    Additional patch. Change THD::init_for_queries():
    - Remove call to set_[1;31mtime[m(). It has already been called by
      THD::init() which is always called right before init_for_queries().
    - Move replication specific code to rpl_slave.cc. Remove
      function argument which is now unused.
    - Remove call to ha_enable_transaction(). enable flag has already
      been set just before by THD ctor. No transaction has been
      started yet, so commit is not needed.
    - Remove call to XID_STATE::reset(). Transaction_info has just
      been constructed so no need to reset state.
    - Rename function to init_query_mem_roots() since it better
      reflects the remaining usage of this function.
    - Convert function documentation to doxygen.
    
    Also:
    - Make THD::init() private.

[33mcommit 0e81de87b65b61ebdd994158dbd5cbd36ef781b9[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Mar 10 10:29:56 2016 +0100

    Bug#22906839 REFACTOR NDB_BINLOG_SETUP INTO OWN CLASS
    
    The ndb_binlog_setup() code in ha_ndbcluster_binlog.cc consists of
    a couple of functions. In order to make it clear that those belong
    together we should convert them into a Ndb_binlog_setup class. This will
    allow to remove duplicated repetitive code as well as simplify the
    existing code over [1;31mtime[m.
    
    Fix by encapsulating ndb_binlog_setup(), ndbcluster_find_all_files(),
    ndbcluster_find_all_databases() and clean_away_stray_files() into a new
    Ndb_binlog_setup class. The class is then instantiated from existing
    ndb_binlog_setup() function and the new setup() function called.
    
    Add const member variables for m_thd and m_thd_ndb which are constant
    and the same for the duration of Ndb_binlog_setup's life[1;31mtime[m.
    
    Remove unnecessary usage of get_thd_ndb() and check_ndb_in_thd()

[33mcommit 1e0c2ea17796ea8835ddf611754e59cb569cf70a[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Feb 25 13:48:04 2016 +0100

    Remove unused retry_[1;31mtime[m argument from gsl_unlock_ext
    
     - Function always called with -1 which means infinite
     - Remove function argument and conditional logic
       implementing various retry options.
     - Improves code clarity and reduces obfuscation

[33mcommit f965f4340878afcf2c57c547791c16686bbf2ee7[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Tue Feb 23 13:12:49 2016 +0100

    Refactor Thd_ndb options
    
     - make Thd_ndb::options a private member variable thus requiring
       use of set/getters for accessing it.
     - Fold the Thd_ndb_options_guard into Thd_ndb thus showing where it belongs
       and at the same [1;31mtime[m giving it acess to the private member variable. This
       also allows anyone including ndb_thd_ndb.h to use the guard class.
     - This ensures type safety and improves encapsulation

[33mcommit d2493d395003c1b5bfa9401abbf3d1ac4b0381fe[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Mar 31 12:09:47 2016 +0200

    Bug#22964497 UBSAN ERROR IN BOOTSTRAP ON 32-BIT SYSTEM
    
    sql/table.cc:1303:70: run[1;31mtime[m error: signed integer overflow:
    2038469832 - -2052121112 cannot be represented in type 'int'
    
    Fix: do the address calculation with longlong rather than int

[33mcommit 56cb9efd587d3e107270e2833c3a480f7f156ca7[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Thu Mar 31 09:20:20 2016 +0300

    Post-push fix of Bug#22996442 INNODB: MAKE UNIV_DEBUG DEPEND ON DBUG_OFF, AND
    REPLACE REFERENCES TO DBUG_OFF
    
    Doxyfile: Keep UNIV_DEBUG defined.
    
    UNIV_MEMCACHED_SDI: Move the definition to api0api.h,
    and #include "config.h" so that the InnoDB Memcached plugin
    will get the same compile-[1;31mtime[m configuration. This fixes the
    debug build of the Memcached plugin.

[33mcommit 162e016044bae8942479e8bccdba3543f228e74b[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Tue Mar 15 14:32:39 2016 +0100

    Bug#22948828: REFACTOR USAGE OF MY_MICRO_TIME()
    
    Remove redundant calls to my_micro_[1;31mtime[m() to simplify code
    and reduce the usage of get[1;31mtime[mofdat(). Especially focused
    on code for handling new connections.
    
    sql/conn_handler/connection_handler_one_thread.cc
    - Removed my_micro_[1;31mtime[m() call. THD::start_u[1;31mtime[m has just been
      set by THD::THD() => THD::init(). THD::thr_create_u[1;31mtime[m is
      only needed by connection_handler_per_thread.cc
    
    sql/conn_handler/connection_handler_per_thread.cc
    - Removed my_micro_[1;31mtime[m() call. THD::start_u[1;31mtime[m has just been
      set by THD::THD() => THD::init(). Remove THD::thr_create_u[1;31mtime[m,
      we can use THD::start_u[1;31mtime[m instead.
    
    sql/event_queue.cc
    - Replaced usage of THD::set_current_[1;31mtime[m() with THD::set_[1;31mtime[m().
      THD::set_[1;31mtime[m() does the same as long as THD::user_[1;31mtime[m is NULL
      which it is for events. Allows the removal of THD::set_current_[1;31mtime[m()
    
    sql/events.cc
    - Removed THD::set_[1;31mtime[m() call. THD::set_[1;31mtime[m() has just been
      called by THD::THD() => THD::init().
    
    sql/log.cc
    - Removed default argument value for make_iso8601_[1;31mtime[mstamp()
      for clarity.
    - Reduced critical section of LOCK_logger.
    - Call my_micro_[1;31mtime[m() directly instead of the unnecessary
      THD::current_u[1;31mtime[m() wrapper.
    
    sql/log_event.cc
    - Use the existing THD::query_start() function instead of accessing
      THD::start_[1;31mtime[m directly.
    - Renamed THD::update_server_status() to THD::check_slow_query()
      since the old name was somewhat misleading.
    
    sql/sql_class.h
    - Removed THD::thr_create_u[1;31mtime[m, no longer needed.
    - Removed redundant inline keyword, added const where possible.
    - Removed THD::query_start_usec(), not used.
    - Removed THD::query_start_[1;31mtime[mval(), no longer needed.
    - Removed THD::set_current_[1;31mtime[m(), no longer needed.
    - Removed THD::is_valid_[1;31mtime[m(), code moved to sql_parse.cc
    - Renamed THD::update_server_status() to THD::check_slow_query()
      since the old name was somewhat misleading.
    
    sql/sql_connect.cc
    - Use THD::start_u[1;31mtime[m instead of removed THD::thd_create_u[1;31mtime[m
      (had the same value)
    - Removed call to THD::set_[1;31mtime[m(). Called by THD::init_for_queries()
      right afterwards anyway.
    
    sql/sql_thd_internal_api.cc
    - Removed THD::set_[1;31mtime[m() call. THD::set_[1;31mtime[m() has just been
      called by THD::THD() => THD::init().
    - Removed call to my_micro_[1;31mtime[m(). Already done by THD::set_[1;31mtime[m().

[33mcommit 29a427db00846c70d1eee2b8e5727886c0af911d[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Tue Mar 29 13:20:32 2016 +0300

    Bug#22996442 INNODB: MAKE UNIV_DEBUG DEPEND ON DBUG_OFF, AND
    REPLACE REFERENCES TO DBUG_OFF
    
    InnoDB used two independent compile-[1;31mtime[m flags that distinguish
    debug and non-debug builds, which is confusing.
    
    We replace all DBUG_OFF references in InnoDB with UNIV_DEBUG.
    Also, make ut_ad() and alias of DBUG_ASSERT().
    
    RB: 12244
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit dc0fce1d01cbece419c743781c45c8c2525195fe[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Mar 29 11:16:28 2016 +0200

    Bug#22842538 BINLOG SCHEMA DISTRIBUTION TIMEOUT AND FAILS WHEN ANOTHER MYSQL NODE START
    
    When another mysqld node is started, and joins (subscribe to)
    the schema distribution protocol, another mysqld which is
    waiting for a schema change to be distributed will [1;31mtime[mout
    during that wait. That happens as we incorrectly assumed
    that the new arriving mysqld node would also 'ack' the
    schema distribution. However, it arrived too late to be
    a participant in it.
    
    This patch fixes 3 issues all contributing to this failure:
    
    a) There is a potential race between an 'inflight'
       subscribe event, and the start of a schema distribution.
       The subscribing node might or might not take part in the
       schema distribution, and its role is actually unknown at
       the point in [1;31mtime[m where the schema operation is started by
       the coordinator.
       The set of participating servers could only be determined
       when the Coordinator acks its own schema op: If the subscribe
       event arrived before it own schema up, then the subcribing
       node is a participant.
       This patch modifies the Coordinators ack to also modifying
       the acked slock_bitmap to clear the servers *not* participating.
    
    b) check_wakeup_clients() called get_subcriber_bitmask() to get the
       current set of subscribers. However, 'self' was not included in the
       subscribers, which it always should be. Fixed this by letting
       Ndb_schema_dist_data::init() add 'own_nodeid' to subscribers.
       Furthermore, this enables us to clean up a couple of places
       where we used to add own_nodeid to the set retrieved from
       get_subscribers_bitmask().
    
    c) handle_clear_slock() copied schema->slock into
       ndb_schema_object->slock_bitmap, thereby overwriting the intersect
       done as part of a). Changed the copy to do an intersect instead.
    
    This patch also modifies several places where schema distribution
    progress is printed:
    - Always print more significant part of bitmask before the less significant.
    - Adds some formating when printing the bitmasks.
    
    Also removes a few clear of bitmasks immediately after an init,
    which is redundant as ::init() also cleared it.

[33mcommit 874d40ab4431fcad7e8ce753beb744970d1deb04[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Thu Mar 24 11:38:32 2016 +0100

    Bug#22579581 NDB_PRINT_FILE CORE DUMP ON SOLARIS
    
    An pointer to a 32 bit word was accessed via [1;31mtime[m_t pointer.
    
    On sparc-v9 this cause bus error since [1;31mtime[m_t was 64bit and word was not
    64bit aligned for File_formats::Zero_page_header::m_[1;31mtime[m.
    
    On other platforms there 64bit [1;31mtime[m_t is used, the high word of the [1;31mtime[m_t
    could be non zero resulting in bogus [1;31mtime[mstamp.

[33mcommit f6a78ae0901bde67c131e4ea633c1798d9fb423e[m
Author: Priyanka Sangam <priyanka.sangam@oracle.com>
Date:   Thu Mar 24 13:03:09 2016 +0530

    Bug #21178339: 'NDB_RESTORE -M' SOMETIMES: "FAILED TO CREATE INDEX `ENTRY_KEY$UNIQUE`" ERROR 1
    
    Unique index creation requires a DBUTIL PREPARE which is initiated
    from TRIX. DBUTIL allows only one PREPARE at a [1;31mtime[m. If a PREPARE
    request is received in DBUTIL while a PREPARE is already running,
    a PREPARE_SEIZE_ERROR is returned. This occurs if a CREATE_EVENT
    has requested a PREPARE before unique index creation. For unique
    index creation, the PREPARE_SEIZE_ERROR is not mapped to an
    equivalent error code, so an error 1 "Unknown error" is returned.
    
    Mapped PREPARE_SEIZE_ERROR to error 748 "Busy during read of event
    table". Fixed ndb_restore to retry index creation on temporary
    errors.

[33mcommit 3a82fd08d64d090a72c233dafadedeafe292acd1[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Wed Mar 23 15:40:28 2016 +0100

    WL#9096 Add thread_prio to ThreadConfig, add cpubind_exclusive and cpuset_exclusive to ThreadConfig, add support for CPU locking on FreeBSD and Windows, add support for non-exclusive CPU locking on Solaris, add support for setting thread_prio on FreeBSD and Linux using setpriority, add support for setting thread prio on Windows, add support for setting thread_prio on Solaris using FX prio class. thread_prio set to 10 on Solaris gives FX60 which is interpreted by Solaris as meaning attempt to run thread on its own CPU core. Add support for real[1;31mtime[m setting on Windows

[33mcommit 1f641f716fb1ea8097a0febbe9647ebe89ca5cf7[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Tue Mar 22 11:48:12 2016 +0100

    WL#7069: Provide data dictionary information in serialized form
    
    This worklog provides a the data dictionary information for schemas,
    tables and tablespaces in human-readable form (JSON). For storage
    engines which don't support storing the serialized dictionary
    information (SDI) in tablespaces (all SEs except Innodb), the SDI is
    written to a file in datadir.
    
    For Innodb the the SDI will be stored in a tablespace, but this
    remains disabled for now, as it depends on worklog number 7141.
    
    The SDIs can be manually edited and will be used for import and
    disaster recovery (to be provided worklog number 7524 and 7412).
    
    Note that the name of the SDI files includes the Object_id from the
    data dictionary, which is a value created by an auto-increment column
    in the corresponding data dictionary table. This in turn means that
    the name of an SDI file created by an MTR test will not necessarily be
    the same each [1;31mtime[m the test is run as it depends on how many dd
    operations have been performed on the server prior to the test being
    run. In particular it will not be same when running a test by itself as
    when running the test as part of a suite. This does not cause any
    problems, except in cases where the test includes the content of
    datadir in its output. Then a --replace_regexp must be used to make
    the output of the test stable. E.g.:
    
    --replace_regex /_[0-9]+\.SDI/_XXX.SDI/
    --list_files $MYSQLD_DATADIR/mysqltest/

[33mcommit c54d668da782b1cc7d3c6fdb67ef23d60a43e538[m
Author: Benny Wang <benny.wang@oracle.com>
Date:   Tue Mar 22 08:33:22 2016 +0100

    Fixed bug#21982792: TOO MUCH SPAM: 'GOT ERROR 1 WHEN READING TABLE'
    
    When reading one row by reference scan, there are two steps: 1) copy the
    referenced value to the indexed field 2) use the indexed field value to scan
    the index. During step 1, we might meet warnings such as a type conversion
    warnings. In strict mode, these warnings will be treated as errors. However in
    step 1, it misses to check the thd->is_error to see whether there is such kind
    of error. The missing error handling in the server results in the server goes
    forward like no error. At the same [1;31mtime[m, it will results in some abnormal
    behavior next, such as update_generated_read_fields will throw out an error
    because it checks thd->is_error(). This is unreasonable.
    
    This patch fixes such kind of problems. The thd->is_error() will be detected
    before calling update_generated_read/write fields.  The places where
    the->is_error() is checked are listed as the below:
    1. fill_record() checks after save_in_field()
    2. cp_buffer_from_ref() does after copy()
    3. copy_data_between_tables() does after invoke_do_copy()
    4. do_updates() does after invoke_do_copy()
    5. JOIN_CACHE::generate_full_extensions checks after check_match()
    
    This patch causes changes to the test results from i_main.sp. This is caused
    by the new error handling which makes the server return earlier when an error
    has occurred.

[33mcommit 3b61975885f402f87fa0e0e309e3592eb7bd4a39[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Mar 16 13:51:28 2016 +0100

    wl#7677, Yet another followup patch... sigh
    
    This [1;31mtime[m the usage of MAP_ANONYMOUS caused build break on
    osx and Windows, which seems to not support this. On windows
    as my_mmap() is not natively supported by Windows, and we
    use a my_mmap() function instead. That does not implement
    MAP_ANONYMOUS functionality. (Possibly could be implemented
    later, but that is out of scope for this patch)
    
    On osx it is ,,,, well not supported.
    
    non-ANONYMOUS mapping would have required is to create
    a file to map agains. That does not seem like a favourable
    solution for allocating this kind of buffer memory.
    
    Instead this fix let platforms not supporting ANONYMOUS mapping
    use plain malloc instead. Should not really matter much as
    long as Linux (and Solaris) use mmap().
    
    Also fixes a few compiler warnings seen on Windows.

[33mcommit 04d563f651f97d54cba0d184b590de91d1eb3209[m
Author: Tatiana Azundris Nuernberg <tatjana.nuernberg@oracle.com>
Date:   Mon Feb 29 09:15:48 2016 +0000

    Bug#16576959: MYSQL_OPTIONS4: POTENTIAL DOS VIA PRINTING TOO MUCH USELESS INFO TO ERROR LOG
    
    The client library can enrich connection data with information about
    the library version, the client's name, the OS the client is running
    on, and in fact pretty much anything it wants.  The designated
    mechanism for this is mysql_options4(), which lets the client put
    arbitrary key/value pairs on the connection info before the connection
    is made.
    
    The server outright refuses a connection when 64+ KB of these data are
    submitted. However, in practice performance schema usually reserve much
    less space (< 1 KB) for each connection's attributes. If the client submits
    more data, the connection will succeed, but a warning will be thrown
    that some attributes were discarded. (The server will provide access
    to all attributes that is has a complete copy of. We do not currently
    show how many attributes were lost on a given connection, nor do we
    show an incomplete attribute with some sort of "cut" marker -- we simply
    don't show a truncated attribute at all. That said, we do expose info
    about the total number of connections with dropped attributes.)
    
    Pre-patch, we simply logged a warning indicating that attributes were
    truncated on a connection, without giving any information beyond the
    [1;31mtime[mstamp that would allow the administrator to identify the client,
    user, or connection that lost attributes. This made debugging harder
    than it needs to be.
    
    This patch adds additional data to log entry where available, such
    as user/host, connection ID, etc., all in the hope that it will
    make debugging such instances with just the error log much easier,
    and aid cross-referencing in the presence of further logs, such as
    the general query log.
    
    It also adds a new global PFS variable,
    "Performance_schema_session_connect_attrs_longest_seen" that shows the
    size of the longest (valid, i.e. <= 64 KB) buffer we were passed, so
    the DBA may adjust the buffer, or complain to the application developer.
    
    Finally, when a valid buffer in excess of what we accept is passed,
    we will add a new attribute "_truncated" stating how many characters
    were lost (provided the configured buffer is large enough to hold
    this information). This should make it easier to identify the exact
    connection that had the questionable attribute set in the PFS,
    without having to resort to the error log.

[33mcommit d6ca4dbf11108a81ef92af259bcaf8eba71f4578[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Fri Mar 11 13:40:16 2016 +0100

    WL#6378: New data dictionary
    
    Make 'check_db_dir_existence()' static in 'sql_db.cc'.
    Use 'dd::schema_exists()' to check for schema existence.
    
    Note that this may affect error handling in two ways:
    
    1. Using 'dd::schema_exists()' will use the DD cache, and
       cache miss handling may result in "new" errors such as
       lock wait [1;31mtime[mouts or deadlocks.
    
    2. Forcefully removing the schema directory in the file
       system will not affect the meta data. Thus, replacing
       a call to 'check_db_dir_existence()' by a call to
       'dd::schema_exists()' may not result in the same
       behavior as far as error handling is concerned. This
       affects e.g. 'SHOW CREATE SCHEMA'. However, for meta
       data related operations, the new modified behavior
       may be considered more appropriate.
    
    This patch introduces the following changes:
    
    1. Remove call to 'check_db_dir_existence()' when
       initializing the data dictionary during server restart.
       Change error handling while creating the schema to handle
       a missing directory appropriately.
    
    2. Replace call to 'check_db_dir_existence()' from
       'mysql_show_create_tables()' by call to
       'dd::schema_exists()'.
    
    3. Replace call to 'check_db_dir_existence()' from
       'mysql_create_view()' by call to 'dd::schema_exists()'.
    
    4. Replace call to 'check_db_dir_existence()' from
       'mysql_rm_table_no_locks()' by call to 'dd::schema_exists()'.
    
    5. Re-locate the definition of 'check_db_dir_existence()'
       in 'sql_db.cc', make it static, and remove it from
       'sql_db.h'.
    
    Additionally, the 'main.schema' mtr test is extended by
    several test cases checking the behavior when the
    schema directory is deleted forcefully.
    
    And finally, and totally unrelated to the above, the
    patch also removes the obsolete method
    'dd::Table::get_partition_by_se_private_id()'.

[33mcommit d605b168de59dc6084290233cdf9dcf39f5f0749[m
Author: Tarique Saleem <tarique.saleem@oracle.com>
Date:   Fri Mar 11 10:40:23 2016 +0100

    Bug #20697533 EXPLAIN_FOR_CONNECTION_RQG_JSON/TRAD ARE FAILING WITH
    RESULT DIFFERENCE ON PB2
    
    There were some Result Content Mismatch Issue on the
    explain_for_connection_(rqg_json/rqg) tests. Some of the tests added in
    these were taken from RQG genereated queries which are quiet long and at
    [1;31mtime[ms shows random Explain Plans. As a fix smaller and specific queries
    are taken from these 2 tests and moved into
    explain_for_connection_small_(json/trad) tests and these 2 tests are
    deleted now.

[33mcommit 3d1febd07ea253bfde8e84afb4c50d6563f23f23[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Fri Mar 11 08:24:46 2016 +0300

    WL#7743 Work-in-progress.
    
    Removed save/reset/restore of THD::killed flag in Transaction_state.
    It was redundant because DD transaction were made immune to kill
    anyway. This also fixed main.[1;31mtime[mzone_debug test.

[33mcommit 934fbbcda8b96b6ddc6adc077ec6a88f76e58266[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Wed Mar 9 12:07:48 2016 +0100

    BUG#22884995: Problem with multiple LIST_TABLES_CONF signals, table put in list multiple [1;31mtime[ms, fix of WL#8937
    
    (cherry picked from commit 847b2e0a81a06fb685bb423524cea5ebbcded018)

[33mcommit 707fd3af81b44117f44ba91f1f307506122a4840[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Mar 10 14:29:04 2016 +0800

    Bug#21352937 - REDUCE LOG_SYS->MUTEX CONTENTION BY ALLOWING CONCURRENT
    MTR COMMIT AND LOG WRITE
    
    All mtr commits would have to wait for writing/flushing redo logs to disk
    in log_write_up_to(). The wait is unnecessary. In this patch, we introduced
    one more log buffer and one mutex.
    
    We always write logs to one log buffer, keeping the other idle. Once we
    need to flush it, we switch these two buffers, so log_write_up_to() would
    take over the to be flushed buffer and do the flush job, once the flushing
    finishes, this buffer becomes the idle one. At the mean [1;31mtime[m of flushing,
    all concurrent mtr commits would see the empty new buffer and write logs
    there, even after the flushing, logs are still writing to this buffer
    before it needs to be flushed.
    
    Let's say we have two adjacent log buffer A and B, at first, all logs are
    written to A, keeping B as empty. Once we want to flush logs in A, we will
    switch A and B, which is under the protection of current log_sys->mutex.
    Then all logs are now written to B, while A is getting flushed and becomes
    empty and idle. When B is needed to be flushed, we now switch A and B again,
    new commits will come to A, and flushing of B won't stop the concurrent
    mtr commits. And so on.
    
    The new introduced mutex is mainly used to protect the process of
    log_write_up_to().
    
    The original patch was provided by Weixiang Zhai.
    
    RB: 11142
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>

[33mcommit a237f054905342385a7ba5dfa92f8bf57e77d5b6[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Wed Mar 9 12:07:48 2016 +0100

    BUG#22884995: Problem with multiple LIST_TABLES_CONF signals, table put in list multiple [1;31mtime[ms, fix of WL#8937

[33mcommit dc72fba7a293500efa056d35c4da02a3c6395ff6[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Mon Mar 7 09:05:56 2016 +0100

    Bug#22884144: SWITCH MYSQLIMPORT AND MYSQLSHOW FROM .C TO .CC
    
    Switch client/mysqlimport and client/mysqlshow from .c to .cc.
    These were the last two remaining clients that were not .cc files.
    Switching allows the use of C++ in future bug fixes, enables
    stronger compile [1;31mtime[m checks and allows us to start removing
    extern "C" declarations in various code used by clients.

[33mcommit b26072bc26989df9ec2d2a659dde0ef8c2f0eb87[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Fri Mar 4 12:38:48 2016 +0100

    Bug#22508563: 5.7'S GENERAL LOG MISSES TAB-CHARACTER BETWEEN
                  TIMESTAMP AND THREAD_ID
    
    Add back a tab character between [1;31mtime[mstamp and thread_id in the
    general query log file. Was by mistake removed in 5.7.
    
    Patch contributed by tsubasa tanaka.

[33mcommit 25bf5b928a5863eea758af39dab2b80aa8b7fd35[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Mar 3 16:25:44 2016 +0800

    BUG#22329393 - DEADLOCK BETWEEN FILESPACE RW-LOCK AND PERSISTENT COUNTER MUTEX
    
    This deadlock happens when there are one alter table requiring rebuild and
    removing the entry from DDTableBuffer, and the other is pessimistic inserting
    a new row containing autoinc counter. To remove the entry from DDTableBuffer,
    dict_persist::mutex should be held before the pessmistic delete, which
    requests the fielspace rw-lock. At the mean[1;31mtime[m, to pessimistic insert have
    held the filespace rw-lock to do the split and dict_persist::mutex is
    requested to mark the metadata(autoinc counter) of the table has been changed
    
    The fix would make sure the dict_persist::mutex should be held before the
    filespace rw-lock, thus no deadlock. So during inserting, persisting of the
    counter which requires the dict_persist::mutex should be done at first and
    then inserting operations. This should also be applied to update.
    
    To get the mutex and write the log at first, it would require some changes
    in mtr_t including introducing a new function mlog_open_metadata(),
    so that we can write changes not related to a page to mtr buffer first and
    get it committed correctly finally.
    
    RB: 11835
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Marko Makela <marko.makela@oracle.com>

[33mcommit ff6a01a75b9ea875833d68733b79ab41ffdc8819[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Wed Mar 2 14:12:24 2016 +0100

    WL#8937: Fix for local list handling and an extra return causing scans to hang at [1;31mtime[ms

[33mcommit 3600ec7060ceaab3616123c46ffc6c698a6d117e[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Tue Mar 1 13:30:21 2016 +0100

    Bug#22700948: ASSERT IN I_RPL.RPL_CHANGE_REPOSITORY_STRESS
    
    This bug is a race condition between init_slave() and
    server_components_initialized() during server startup.
    
    During lookup in the new dictionary cache, we check that a proper
    metadata lock has been acquired. This check was only done after
    the server had been started up since no locks are required
    while the server is single threaded. Server startup was checked
    by inspecting the global mysqld_server_started variable set by
    server_components_initialized().
    
    The problem was that replication slave threads are started
    earlier by a call to the init_slave() function. These slave threads
    could then start to use the dictionary cache while the server was
    still starting.
    
    Some[1;31mtime[ms this could result in the following series of events:
    - A slave thread accesses the dictionary cache looking for a table.
    - The dictionary cache needs to inspect schema metadata, but
      decides not to take a metadata lock since the server has not
      started.
    - The server finishes starting up and executes
      server_components_initialized().
    - The dictionary cache checks that a proper metadata lock on
      the table has been taken. As a part of this, it needs to
      check the schema lock as well. Since taking this lock was
      skipped earlier, we now assert.
    
    This patch fixes the problem by only skipping checking metadata
    locks for the DD bootstrap thread (thd->is_dd_system_thread())
    instead of inspecting the global mysqld_server_started variable.
    The patch also removes dd::Schema_MDL_locker::is_lock_required() -
    we now assume that it always necessary to take a schema lock.

[33mcommit a1d8ffac62f53506e0a76aa95f15925bbcb10a5f[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Mon Feb 29 09:51:04 2016 +0100

    Bug#22824408 FIX MORE ERRORS REPORTED BY UBSAN - FOUR
    
    sql/binlog.cc
    Revert earlier patch testing gtid_state != NULL
    
    sql/handler.cc:2012
    member call on null pointer of type 'struct Gtid_state'
    This can happen during shutdown, srv_purge_coordinator_thread has a
    THD, which is to be destroyed. The server clean_up() has already done
    gtid_server_cleanup, so gtid_state == NULL.
    Fix: do gtid_server_cleanup after plugin_shutdown in clean_up()
    
    sql/parse_tree_nodes.h:1877
    load of value 13, which is not a valid value for type 'bool'
    sql/parse_tree_nodes.h:1876
    load of value 32589, which is not a valid value for type 'thr_lock_type'
    Fix: Initialize all fields of Select_lock_type in the parser
    
    sql/spatial.h sql/spatial.cc
    Suppress known issues with downcast of GIS objects.
    
    strings/ctype-simple.cc:1582
    signed integer overflow: 930496927 * 10 cannot be represented in type 'int'
    
    strings/decimal.cc:1167
    signed integer overflow: -9223372036000000000 - 854775809 cannot be represented in type 'long long int'
    
    sql/partition_info.cc:2769
    load of value 143, which is not a valid value for type 'bool'
    Fix: init got_warning in CTOR
    
    Also: disable two tests which [1;31mtime[m out.

[33mcommit 24b4f2992b731362d52e9fd36fd8652a16e83afe[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Wed Feb 24 13:53:12 2016 +0100

    Bug#22227958: ASSERT IN DD::FILL_DD_TABLE_FROM_CREATE_INFO, DDL
    
    Problem: The new DD code had added an assert which checked that the bitmask
    flags for HA_OPTION_STATS_PERSISTENT and HA_OPTION_NO_STATS_PERSISTENT could
    not be set at the same [1;31mtime[m. This is reaonable, but unfortunatly it is
    legal to supply both values, both when creating the table and when altering
    it. The same problem affects HA_OPTION_PACK_KEYS/HA_OPTION_NO_PACK_KEYS,
    HA_OPTION_CHECKSUM/HA_OPTION_NO_CHECKSUM, and HA_OPTION_DELAY_KEY_WRITE
    /HA_OPTION_NO_DELAY_KEY_WRITE.
    
    Solution: Change the parser so that it always clears both flags before
    setting any of these flags. That way there will be no visible change in behavior
    and only the last value set will be reflected in the bitfield.

[33mcommit d6d1e197f0014dd816494624a255af9a171a5e13[m
Author: Catalin Besleaga <catalin.besleaga@oracle.com>
Date:   Wed Jan 27 13:44:20 2016 +0100

    WL#8920: added uuid_to_bin, bin_to_uuid and is_uuid functions
    
    Problem
    =======
    1) The column type binary(16) is extensively used as a compact storage for
    UUID's. But in order to transform the text (human-readable) format into binary
    format, users must use some text manipulation functions like unhex() and
    replace().
    Example:
    unhex(replace('aab5d5fd-70c1-11e5-a4fb-b026b977eb28', '-', ''))
    
    2) in order to do the reverse transformation, from the binary(16) to
    human-readable format, users must use even more text manipulation functions.
    Example:
    insert(
        insert(
          insert(
            insert(hex(uuid_bin),9,0,'-'),
            14,0,'-'),
          19,0,'-'),
        24,0,'-')
    
    3) A valid UUID text must have a certain length and be made up of only certain
    characters. In MySQL there is no simple way to validate text UUIDs.
    
    4) UUIDs version 1 store the [1;31mtime[m-low at the
    beginning of the string making the index inserts very slow (since the variations
    between two consecutive generated UUIDs are very high at the beginning of the
    string).
    
    Solution:
    =========
    Introducing three new functions defined like this:
    
    F-1.1: UUID_TO_BIN(arg1) should return valid VARBINARY(16) data for any
    valid UUID-string in <arg1>. All specified UUID-formats should be supported:
    - UUID without dashes, ex 12345678123456781234567812345678
    - UUID with braces, ex {12345678-1234-5678-1234-567812345678}
    - standard UUID, ex 12345678-1234-5678-1234-567812345678,
    uppercase/lowercase letters should be accepted. For all those examples, the
    result should be a string starting with a byte of hex ASCII code 0x12, then
    another byte of code 0x34, etc. The validation will be simple, the version
    number bit will not be check, neither the point in [1;31mtime[m of the [1;31mtime[mstamp will
    not be checked. The binary data stored should be in the same order as the text.
    
    F-1.2: UUID_TO_BIN(arg1,arg2) should behave as in F-1.1 if <arg2> is FALSE. If
    instead it is true, the binary data stored should be shuffled so that the [1;31mtime[m-
    low (first group) and  [1;31mtime[m-high parts (third group) are swapped. The rest of
    the bytes will remain  in the same order as the text version. This can give
    better indexing as the rapidly-varying part is moved to the right. The function
    assumes that the UUID is v1 without complaining if it's not.
    
    F-1.3: if the function UUID_TO_BIN is called with invalid UUIDs, an error will
    be thrown.
    
    F-1.4: if the function UUID_TO_BIN is called with NULL argument for the UUID
    string, the function should return NULL without any warning/error.
    
    F-2.1 BIN_TO_UUID should return a valid UUID string for the VARBINARY(16) UUID
    provided as argument. It should be in the standard format, with downcase
    letters. The validation will be simple, it will check that the binary data has
    the size 16: the version number bit will not be tested, nor the [1;31mtime[mstamp.
    The UUID string result should have the same byte-order. This is the inverse of
    UUID_TO_BIN.
    
    F-2.2 BIN_TO_UUID(arg1,arg2) should behave as in F-2.1 if <arg2> is FALSE. If
    instead it is true, the function should return a valid UUID string having the
    [1;31mtime[m-low and [1;31mtime[m-high parts swapped back to their original position.The
    function assumes that the UUID is v1 without complaining if it's not.
    
    F-2.3: if the function BIN_TO_UUID is called with invalid arguments, an error
    will be thrown.
    
    F-2.3: if the function BIN_TO_UUID is called with NULL argument, the NULL
    value will be returned without any warnings/errors.
    
    F-3.1: IS_UUID should return TRUE for valid UUIDs. The function will only
    validate that the string is correctly formatted: correct size, if it uses the
    format with dashes- all dashes are in the right place and all the groups have
    the right amount of characters per group, if it contains curly brackets- both
    exists and are in the right place. No other validation is done.
    
    F-3.2: IS_UUID should return FALSE if the argument is not a valid UUID, and NULL
    if the argument is NULL. No warnings/errors will be thrown.

[33mcommit fe1d2285a21ac503581fc3ffea0649c715044a5d[m
Author: Pekka Nousiainen <pekka.nousiainen@oracle.com>
Date:   Thu Feb 25 19:33:03 2016 +0200

    EXECUTE_DIRECT typo using JBB instead of instance number.
    
    EXECUTE_DIRECT some[1;31mtime[ms was called with JBB (1) instead of instance
    number (0).  This caused instance-not-found crash in single-threaded
    ndbd.  Multi-threaded ndbmtd was ok because it maps instances so e.g.
    non-existent DBDIH instance 1 was mapped to instance 0.
    
    Probably introduced in wl#8937 patches.

[33mcommit 4851ece8367a90c5bcf90a8cc9a09ba0210092ef[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Wed Feb 24 16:55:01 2016 +0300

    Bug #22811659 "ACCESSES TO NEW DATA-DICTIONARY ADD CONFUSING STAGES TO P_S.EVENTS_STAGES_*.".
    
    With advent of new data-dictionary DML and DDL statements started to
    open and lock data-dictionary tables in order to read and/or update
    table meta-data.
    
    These operations on system tables are reflected in the same way as
    opening and locking of user tables in P_S.EVENTS_STAGES_* tables and
    in I_S.PROCESSLIST which can be pretty confusing.
    
    This patch solves this problem by introducing two new stages
    "Opening system tables" and "Locking system tables" to be used
    instead of "Opening tables" and "System lock" stages in cases when
    we access data-dictionary and other system tables (e.g. [1;31mtime[m zone,
    replication or log tables).

[33mcommit c988011d06ae3811ed60aaed0190617ebdfdb69c[m
Author: Sayantan Dutta <sayantan.dutta@oracle.com>
Date:   Thu Feb 25 15:11:07 2016 +0530

    Bug #21278845: MTR SHOULD ADD A TIMEOUT WHEN RUNNING CTEST FOR UNITTESTS
    
    Add --[1;31mtime[mout to ctest and also enable user to change the default setting from 120 by using env var

[33mcommit c4f0fe6cec72b155aa8a4c856ee658673ab3c576[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Mon Feb 22 14:14:56 2016 +0100

    WL#6394: Bootstrapping
    
    Squashed commit of the worklog branch. The commit messages
    of the most important commits are included below:
    
    commit dde944b0590687961b9220b072f0245170e504cd
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Wed Jan 6 14:11:47 2016 +0100
    
        WL#6394: Bootstrapping
    
        Create the DD tables in the predefined tablespace
        with the hardcoded name MYSQL_TABLESPACE_NAME,
        if present. If not present, create the DD tables
        without an explicit tablespace clause.
    
    commit e8fbdb46f1518a1b3e9331f1fcaa13d2c4102bb4
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Fri Dec 18 09:29:17 2015 +0100
    
        WL#6394: Bootstrapping
    
        Let 'innobase_dict_init()' return an out parameter
        containing meta data for the predefined tablespaces.
        For now, only dummy meta data is returned. The meta
        data is used to create dd::Tablespace objects
        that are added to the shared cache as sticky elements.
        The objects are also stored into the DD tables.
    
    commit 6d005924068b3768abd6e58df7e5f4d3c99ea231
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Tue Dec 15 16:14:09 2015 +0100
    
        WL#6394: Bootstrapping
    
        Refactor and extend the Object_table_registry. Introduce a
        template class to support registries for various types.
        Support direct hash based lookup. Rename to 'System_tables'.
        Re-implement the System_view_name_registry accordingly
        based on the same template class. Introduce a registry
        for system tablespaces.
    
    commit c898f52a6c7d7b6db222b021127d5faf315066cb
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Tue Dec 1 21:22:32 2015 +0100
    
        WL#6394: Bootstrapping
    
        Check for table existence by acquiring object also
        for dd tables during startup. Return NULL from the
        storage adapter when handling a cache miss during
        startup.
    
        Remove the registration of the system tables, i.e.
        tables like help topics, [1;31mtime[m zones etc. Since we
        handle cache misses by attachable transactions,
        these can be allowed to happen even while in the
        middle of an attachable transaction.
    
    commit 1de5d97a455cdd0fd351b031a2c27facb6cf476b
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Tue Dec 1 15:42:37 2015 +0100
    
        WL#6394: Bootstrapping
    
        Store DD table objects in the shared cache during
        server start.
    
    commit d4775df8486b7b8cf351cfdf4bf81349723cfd62
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Fri Mar 6 16:24:08 2015 +0100
    
        WL#6394: Bootstrapping
    
        Improve handling of the DD schema:
    
        1. Store the mysql dd::Schema object in the dd::Dictionary and
           make it available through access functions.
    
        2. Get the mysql dd::Schema from the dd::Dictionary to retrieve
           collation information in 'get_default_collation()'.
    
        3. Do not store the mysql dd::Schema obejct in the dictionary
           tables; do the check in 'mysql_create_db()' rater than in
           'dd_create_schema()'.
    
    commit 08bfd24bb0ba77fc1f8c982eb07d66bbf12ead32
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Fri Mar 6 16:24:07 2015 +0100
    
        WL#6394: Bootstrapping
    
        Fix two issues left after implementing step 2:
    
        1. Set THD::tx_read_only and THD::variables::tx_read_only in
           handle_bootstrap() in bootstrap.cc.
    
        2. Use 'Ed_connection::execute_direct()' to execute SQL queries
           instead of the code in 'Bootstrapper::execute_query()'.
    
    commit a6b040a844c96cc8dd04fc0360ef9ab0e2cbf8c3
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Tue Jan 6 15:43:57 2015 +0100
    
        WL#6394: Bootstrapping
    
        Add a function 'handlerton::dict_recover()' to support
        more fine grained control of the DDSE startup sequence.
    
    commit 5f34a3890e9e7f8ee193cc8e66bb23d16cebc2a6
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Mon Oct 20 22:45:29 2014 +0200
    
        WL#6394 Bootstrapping
        =====================
    
        Flush tables after reading DD table meta data from DD tables to ensure the
        actual meta data is used for opening the tables.
    
    commit 6b177effe32df24c66bee9ab9dd3b2b595754540
    Author: Marko Makela <marko.makela@oracle.com>
    Date:   Wed Oct 15 09:57:12 2014 +0300
    
        WL#6394: Cherry-pick a change from mysql-trunk-wl7141:
        r8192, marko.makela@oracle.com-20140829094333-k2nde16brvtm7s27
    
        Remove the dict_table_schema_check().
        The schema of the InnoDB persistent statistics tables will no longer
        be defined in external SQL scripts. Instead, it is hardcoded
        as part of the server bootstrap/startup, in innobase_dict_init(),
        which is part of the InnoDB source code.
    
    commit 4f63b66b9c3feda0e58e8176fa01675a6e3da3e7
    Author: Marko Makela <marko.makela@oracle.com>
    Date:   Tue Oct 14 11:58:30 2014 +0300
    
        WL#7488: Hard-code the page numbers and IDs of core DD tables.
    
        ha_innobase::get_se_private_data(): Fill in "root" and "id" attributes
        for each index, and set se_private_data for each table.
    
        InnoDB will not use se_private_id for indexes, because it is engine-wide
        unique, while InnoDB only needs it to be tablespace-wide unique.
        By allowing different tablespaces to contain overlapping IDs, we will
        allow an instant variant of IMPORT TABLESPACE in WL#7412.
    
        TODO: Use a different tablespace for DD tables (WL#7622).
        Currently, the root page numbers are incorrect here, because
        each DD table will be stored in a separate tablespace.
        In WL#7141, they are currently mapped to the system tablespace.
    
        TODO: (WL#7743/WL#7141) Assert that the attributes of InnoDB-internal
        DD objects match the Global DD objects.
    
    commit a4a4967f37320c4d74a75d6accac4c1ed208815b
    Author: Marko Makela <marko.makela@oracle.com>
    Date:   Mon Oct 13 10:21:00 2014 +0300
    
        WL#6394/WL#7488: Minor refactoring of InnoDB startup.
        This should be a non-functional change.
    
        innobase_init_abort(): Remove. There is only one call to this needed.
    
        innobase_init_files(): New function, to create or open the InnoDB files.
        This code is currently invoked at the end of innobase_init().
        The call or the code will be moved to innobase_dict_init() later,
        so that innobase_init() will only set up the main-memory data structures
        of InnoDB.
    
        TODO: Move more non-file initialization from innobase_init_files()
        to innobase_init(). Pass the dict_init_mode to the low-level code.
    
    commit 32be73abbcf28878c335fc9ded140ec1e49dc0a9
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Wed Oct 8 16:20:41 2014 +0200
    
        WL#6394 Bootstrapping
        =====================
    
        Fixes needed for merging the mysql-trunk-wl6394 tree to
        mysql-trunk-7141-7488.
    
        1. Change signature of handler::ha_get_se_private_data()
           and handler::get_se_private_data(). Use single table
           objects rather than lists.
    
        2. Call ha_get_se_private_data() after filling in the
           table object from the create info to ensure proper
           ordering of handler calls.
    
        3. Extend Object_table_definition with a version member
           to be used for submitting the appropriate parameter
           to ha_get_se_private_data().
    
        4. Various refactoring in the dd::Bootstrapper.
    
        The test rpl.rpl_mts_slave_preserve_commit_order_error is
        failing after this patch.
    
    commit 9903bb7f8b613d7e4f0eeb872c922cd0d86b6629
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Wed Oct 8 12:34:23 2014 +0200
    
        WL#6394 Bootstrapping
        =====================
    
        Fixes needed for merging the mysql-trunk-wl6394 tree to
        mysql-trunk-7141-7488.
    
        1. Add explicit primary key for the version table.
    
        2. Keep the version table from being dummy created twice
           on restart.
    
        3. Change table order, create the DDSE tables at the end.
    
    commit ee35c9ab0ca97304dd3922882f76ea582d8b99ff
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Wed Oct 8 02:57:12 2014 +0200
    
        WL#6394 Bootstrapping
        =====================
    
        Implement infrastructure for retrieving se private data
        before creating DD tables:
    
        1. Let the dd::Bootstrapper prepare dd::Table objects
           representing each DD and DDSE table.
    
        2. For installing the server, get se private data for
           all the preapred dd::Table objects, using the
           target version.
    
        3. For restarting the server:
           i)   Get the se private data for the version table
                only, using version = 0.
           ii)  Dummy create the version table to be able to
                open it.
           iii) Open the version table and read the actual
                version number.
           iv)  Get the se private data for the remaining
                tables using the actual version number.
           v)   Dummy create the DD tables to be able to read
                from them.
           vi)  Read back the stored meta data from the DD
                tables for the DD tables.
           vii) Replace the temporarily stored meta data from
                the dummy create operations by the actual
                meta data that was read.
    
        4. Create the mysql schema object and use it to prepare
           the dd::Tables in 1). Store it in the dd::Schemata
           table. Remove the populate statement for dd.schemata
           which inserts a row representing the mysql schema.
    
        5. Simplify create_dd_system_table() in table_share.cc.
           Use the prepared table object from the object table
           definnition instead of creating a dummy object.
    
        Known issues:
    
        1. There is no distinction between the core tables,
           the aux tables and the DDSE tables.
    
        2. All core, aux and DDSE tables are submitted to the
           method handler::get_se_private_data(). The table
           objects are empty with the exception of the table
           name.
    
        3. The test rpl.rpl_mts_logical_clock_recovery fails if
           the DDSE tables are created last, thus, the DDSE
           tables are created first for now.
    
        4. A mem_root issue causes problems when allocating the
           handler for getting the se_private_data. Thus, a call
           to free_root() has been commented out in the
           Bootstrapper.
    
    commit bd0fce95677b1ef6a97c9341c24873c22b7270e1
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Mon Oct 6 14:42:11 2014 +0200
    
        WL#6394 Bootstrapping
        =====================
    
        Implement infrastructure for creating tables based on
        definitions received from the DDSE.
    
        1. Remove the "non represented tables" file with the
           hard coded definitions of the dd.catalogs table as
           well as the innodb_*_stats tables.
    
        2. Add a dd::tables::Catalogs singleton representing the
           dd.catalogs table.
    
        3. Add a dd::Plugin_table_definition_impl inheriting
           Object_table_definition providing other means of
           support for maintaining the table definition.
    
        4. Add a dd::Plugin_table_impl inheriting Object_table
           as a base class for plugin tables, using an instance
           of (3) for storing the table definition.
    
        5. Modify the dd::tables::* classes to allocate the
           instance in the singleton dynamically instead of
           on the stack. Needed for uniform memory management
           in (6).
    
        6. Implement a destructor for Object_table_registry_impl
           which deletes all instances pointed to in the table
           vector.
    
        7. Move the hardcoded innodb_*_stats table definitions
           from the server to innobase_dict_init().
    
        8. Introduce a Plugin_table class in the handler to be
           used for returning table definitions from the DDSE
           to the server.
    
        9. Read the table definitions retrieved from the DDSE
           in the dd::Bootstrapper and create an instance of
           dd::Plugin_table_impl for each.
    
        10. Add the instance created in (7) to the object table
            registry.
    
    commit 1ea0f7f446ae332f352656add315739b1e0643f5
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Fri Oct 3 09:54:56 2014 +0200
    
        WL#6394 Bootstrapping
        =====================
    
        Adding infrastructure for the DD version number:
    
        1. Adding a dd.version table for storing the DD version number.
        2. Adding the dd.version table to the object table registry for
           it to be created when installing the server.
        3. Adding a method for retrieving the actual DD version number
           from the table.
        4. Adding the target DD version number and a method for
           retrieving it.
        5. Extending the start_impl() and install_impl() methods in the
           dd::Bootstrapper to make use of the DD version.
    
        Also, a number of tests had their result files re-recorded due
        to changes imposed by the existence pf the new table.
    
    commit 64bfef6f77c58e5df8291efded3fb555dae73c90
    Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
    Date:   Wed Oct 1 14:25:08 2014 +0200
    
        WL#6394 Bootstrapping
        =====================
    
        Initial extensions of the handlerton and handler APIs as described in WL#6394:
    
        1. Add handlerton::dict_init() with dummy innodb implementation.
        2. Add handler::ha_get_se_private_data() calling (3).
        3. Add virtual handler::get_se_private_data(), default implementation is to
           return false.
    
        Initial dummy modifications of the dd::Bootstrapper to call dict_init().

[33mcommit d94d6487702e19de7c500898566983ee8da78811[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Feb 18 15:33:33 2016 +0100

    Bug#22670525 NDBCLUSTER EMBEDDED FAILS TO START WITH VS2015
    
     - starting from VS2015 the function vsnprintf has been implemented
       and at the same [1;31mtime[m the _vsnprintf function seems to have changed
       slightly thus showing different behaviour causing unexpected
       differences in lengths of formatted string.
     - fix by using vsnprintf() starting from VS2015(i.e _MSCVER >= 1900)
     - no functional change unless using the newer compiler
    
    (cherry picked from commit 8322d220f15082d842a52183271f6b1ba7239c28)

[33mcommit 47c5d1c9b8f611a2820bf6fa2c90330bf850f1de[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Feb 18 15:33:33 2016 +0100

    Bug#22670525 NDBCLUSTER EMBEDDED FAILS TO START WITH VS2015
    
     - starting from VS2015 the function vsnprintf has been implemented
       and at the same [1;31mtime[m the _vsnprintf function seems to have changed
       slightly thus showing different behaviour causing unexpected
       differences in lengths of formatted string.
     - fix by using vsnprintf() starting from VS2015(i.e _MSCVER >= 1900)
     - no functional change unless using the newer compiler

[33mcommit 6fce645b7563ec5b98b08ed6deb362aa44156ce2[m
Author: Priyanka Sangam <priyanka.sangam@oracle.com>
Date:   Fri Feb 19 12:40:12 2016 +0530

    Bug #20368354 REDUCE THE DICTSIGNAL TIMEOUT (GETTABINFOREQ) FROM 7 DAYS TO MINUTES
    
    Reorganised [1;31mtime[mouts for DICT signals. Introduced short [1;31mtime[mout
    of 2 mins for parse phase signals. Retained 7-day long [1;31mtime[mout
    for remaining signals.
    1) parse phase signals: short [1;31mtime[mout
    DDL ops use schema transactions (prepare+commit), so all actual
    DICT work is done by SCHEMA_TRANS_END_REQ. All other DDL signals
    are 'parse phase' signals, which prepare work for
    SCHEMA_TRANS_END_REQ. So they should complete quickly.
    2) SCHEMA_TRANS_END_REQ: long [1;31mtime[mout
    Does all actual schema transaction work.
    3) event and subscription ops: long [1;31mtime[mout
    Executed inline, causing work to be done across nodes. Max [1;31mtime[m
    for Event/Sub ops may be dependent on other factors, e.g.
    configurable [1;31mtime[mouts.

[33mcommit ffdb1f10ee612d6dc8f7852c2dd59c0e3bacbbe1[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Tue Feb 16 14:47:04 2016 +0100

    Bug#21287823: Make Item::fix_length_and_dec() accept thread arg
    
    This patch fixes problems in code caused by not passing THD pointer
    to Item::fix_length_and_dec(), and not providing a return value from
    the function. The result is code that is more consistent and less
    prone to errors, because errors will be caught earlier than before.
    
    Summary of changes:
    
    - Item::fix_length_and_dec() is renamed to Item::resolve_type()
      ("resolve" is more exact than "fix" and "type" is more generic than
       "length_and_dec").
    
    - Item::resolve_type() is passed a THD pointer, meaning that it no longer
      needs to access current_thd.
    
    - Item::resolve_type() returns a boolean value with false meaning
      success and true meaning error.
    
    Some other changes:
    
    - Some error handling is still irregular - flagged with @todo.
    
    - convert_constant_item() is changed to return error indication.
      Conversion is indicated by new out argument.
    
    - Item_bool_func2::convert_constant_arg(): Same as convert_constant_item().
    
    - Argument check was removed from Item_bool_func2::fix_type(), since
      we know tree is consistent at this point.
    
    - reject_geometry_args() is changed to return error indication.
    
    - fix_num_length_and_dec_shared_for_case() is renamed to
      fix_num_type_shared_for_case().
    
    - Member THD was removed from Item_func_from_unix[1;31mtime[m. Use is
      replaced with current_thd. This is safer, but we hope it is
      a transitional change.
    
    - Generally, all object allocations are checked for NULL pointer.
    
    - thd->is_fatal_error is replaced with thd->is_error(), to catch
      all possible errors.
    
    - some adjustments according to coding standard applied:
      NULL instead of 0, false/true instead of 0/1.

[33mcommit c8bfd0f26f08d5b00d5390b2f1426b63481e89ac[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Tue Dec 22 13:53:12 2015 +0100

    Bug#22602142: REDUCE AMOUNT OF COPYING IN JSON FUNCTIONS
    
    Patch #3:
    
    Reduce copying in contains_wr(), used by JSON_CONTAINS.
    
    contains_wr() frequently calls Json_wrapper's [] operator or
    Json_wrapper_object_iterator::elt(), which could result in heap
    allocations. In many cases [] or elt() is called multiple [1;31mtime[ms to
    access the same element, resulting in multiple copies/allocations per
    element.
    
    The patch introduces local variables to hold the result of [] or elt()
    in cases where the same element needs to be accessed multiple [1;31mtime[ms,
    so that we don't need to allocate a new instance on each access.

[33mcommit e71ce4f45326c2d615c3c44cba540b9e050fedfb[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Tue Dec 22 09:47:55 2015 +0100

    Bug#22602142: REDUCE AMOUNT OF COPYING IN JSON FUNCTIONS
    
    Patch #1:
    
    Remove unnecessary memory allocations in JSON_SEARCH. The patch makes
    the following changes to find_matches():
    
    case Json_dom::J_STRING:
    
      - reduce the life[1;31mtime[m of the temporary std::string object
    
    case Json_dom::J_OBJECT:
    
      - don't create local copies of pair.first (a std::string) and
        pair.second (a Json_wrapper), both of which may lead to heap
        allocations when copied
    
    case Json_dom::J_ARRAY:
    
      - don't create a local copy of the Json_wrapper

[33mcommit e6cf02ad9329bd7339074efc7f0be8d05731fb77[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Wed Feb 10 10:52:57 2016 +0100

    Bug#22393309: GCOLS: CREATE TABLE CRASHES AFTER GENERATED_COLUMN::DUP_EXPR_STR
    
    Problem:
    A prepared statement's re-preparation led to a stale MEM_ROOT*
    pointer in Generated_column::m_expr_str_mem_root.
    
    Fix:
    - delete m_expr_str_mem_root
    - to be able to do that, less allocations for expr_str must be done:
    so we avoid use of expr_str as much as possible, and define with comments
    when it is really necessary. In detail:
    - when the expression's text is parsed, we don't save it into expr_str
    anymore, as parsing gives us the Item which is enough to recreate the text
    if needed (which we do in sql_show.cc for example).
    - so we don't have to persist this text for a long [1;31mtime[m, so we eliminate
    the need to cache the MEM_ROOT.
    - the text is needed, when we have just read it from the DD: we still
    store it in expr_str in TABLE_SHARE, so TABLE instantiation can parse
    it to create its expr_item.
    - other than that, code should use expr_item only.
    - expr_str was filled and used when writing to the DD; a temporary
    String is used instead, as expr_str isn't needed anymore here.
    - comments explain the subtle differences between Generated_columns
    of TABLE_SHARE and of TABLE (which already existed before this patch).
    The first gcol_expr_is_equal was already dead code so is removed.

[33mcommit 8140fae27c9352d20a0c7dcc9f7010a25bda8f9c[m
Author: Andrei Elkin <andrei.elkin@oracle.com>
Date:   Fri Jan 22 18:22:09 2016 +0200

    Bug #21255763   ASAN: MEMORY LEAK IN MYSQLBINLOG
    
    There's a bunch of stacks like
    
        #1 0x62ab04 in my_raw_malloc(unsigned long, int)
    /export/home/repo/mysql-review4/mysys/my_malloc.cc:194
        #2 0x62a90a in my_malloc
    /export/home/repo/mysql-review4/mysys/my_malloc.cc:59
        #3 0x5b3003 in mysql_init
    /export/home/repo/mysql-review4/sql-common/client.cc:2449
        #4 0x54ab0e in safe_connect()
    
    produced by mysqlbinglog with ASAN when run specific tests.
    
    The reason of the uncleaned memory turns out to be
    no matching mysql_close() that concludes the life [1;31mtime[m of 'mysql'
    struct describing connection to the server.
    This happens when mysqlbinlog is invoked with connecting to the server
    and requesting more than one binlog file.
    In such case dump_remote_log_entries() keeps calling safe_connect() per each
    file, never caring to invoke mysql_close().
    Only the final safe_connect()'s allocation effect are cleaned by the base
    code.
    That is with 2 files there's one 'mysql' connection descriptor struct
    uncleaned/deallocated.
    
    **Fixed** with invoking mysql_close() right in front of mysql_init() of
    safe_connect(). That makes possibly previously used 'mysql' be
    reclaimed prior a new one is allocated.
    
    The matching mysql_close() to the final safe_connect()/mysql_init()
    has been always provided by the base code as noted above.
    
    **Note**, that the described on the bug page stack has been fixed by
    Bug#21697461 MEMORY LEAK IN MYSQLBINLOG.

[33mcommit 28bf800e5dd4896d212f161959cab2f8cc8832c0[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Mon Feb 8 12:39:13 2016 +0100

    Bug#22681562 LEAKSANITIZER DETECTS MEMORY LEAKS IN TDE TESTS
    
    Disable tests in ASAN for the [1;31mtime[m being.
    
    Approved by Anitha Gopi <anitha.gopi@oracle.com> over IM.

[33mcommit e8a9b1d9096746373c29d761d0e85132c3a34a2c[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Mon Feb 8 11:26:30 2016 +0100

    Bug#22680868 SOME INNODB TESTS ARE FAILING ON WINDOWS AFTER THE TDE PUSH
    
    Disable tests on Windows for the [1;31mtime[m being.
    
    Approved by Anitha Gopi <anitha.gopi@oracle.com> over IM.

[33mcommit 7116de1f0eb833433532fcc2c85111d6c3b06932[m
Merge: 95d54cbdd87 82f671f7294
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Fri Feb 5 12:58:57 2016 +0100

    Merge ../push_spin[1;31mtime[m74 into mysql-5.7-cluster-7.5

[33mcommit 82f671f7294654f3766c9092d58ba2b144e63b31[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Fri Feb 5 12:58:40 2016 +0100

    BUG#22647476: Fix spin[1;31mtime[m, was converted to bool, thus spin[1;31mtime[m became 1 even when set higher

[33mcommit 34983f2fde580f852a1257b01b455ec38543ce54[m
Author: Lakshmi Narayanan Sreethar <lakshmi.narayanan.sreethar@oracle.com>
Date:   Thu Feb 4 17:29:21 2016 +0530

    Updating the ndb_addnode_restart test cases.
    
    The re-organize table step some[1;31mtime[ms runs and completes even before the
    other step could kill the nodes. This would be reported as a failure by
    the autotest. To ensure that the re-organize waits until the other step
    is about to start killing the nodes, this patch intoduces a variable -
    WaitForNodeKillStart to the test case. Now the 'alter reorganize' step
    waits until the other step starts killing the nodes by checking this
    new variable.
    
    (followup to commit 1038d067b)

[33mcommit c1f50f63ded85f312b1a461c7d36775199a877fe[m
Author: Harin Vadodaria <harin.vadodaria@oracle.com>
Date:   Wed Feb 3 14:35:53 2016 +0530

    WL#5769, WL#8821 and WL#8548
    
    WL#5769: Keyring service for MySQL
    - Added keyring service
    - Added file based keyring plugin : keyring_file
    
    WL#8821: Innodb tablespace encryption key rotation
             SQL commands
    - Added syntax and server support for master key
      rotation SQL:
      ALTER INSTANCE ROTATE INNODB MASTER KEY
    - Added support to load plugin before mandatory/built-in
      plugins using new option : --early-plugin-load
    - Added support for compile [1;31mtime[m default for
      --early-plugin-load
    
    WL#8548: InnoDB: Transparent data encryption
    - Added new option for table creation for enablin
      data encryption : ENCRYPTION="Y"/"N"
    - Added transparent data encryption using keyring service
    - Added support for master key rotation
    - Added support for import/export of encrypted tablespace

[33mcommit 47eda0636176a9ff1fc9900b45b10cd40045daa8[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Feb 3 09:38:27 2016 +0100

    Bug#22494024, addendum patch.
    
    Make added testcase deterministic by hiding output from
    'select * from ndb_schema'
    
    mysqld might not have connected to the datanodes yet at this [1;31mtime[m
    if it is 'slow'. Thus, the select may fail. (Whcih was already accepted)

[33mcommit 94a7ff56a69ec3c5fde79fdeb083ff34df1d5813[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Wed Jan 27 09:46:41 2016 +0100

    WL#8726
    
     - compiler error detected with -Werror=logical-op since "index" can't
       be both larger than zero and smaller than NO_OIF_BLOCKS at the same
       [1;31mtime[m.
    
       storage/ndb/src/common/debugger/DebuggerNames.cpp:92: error: logical
       'and' of mutually exclusive tests is always
       false [-Werror=logical-op]
          if((index < 0 && index >= NO_OF_BLOCKS) || dst[index] != 0)
                           ^
      - fix by changing to an or and removing the unnecessary parentheses
        since each condition is faulty in it's own right.
      - the parenteses was added to fix gcc 4.4 compiler warning...
    
    (cherry picked from commit 2611877853601a45ec29d8144a2eee498f81373b)

[33mcommit 705c74d9c50b33e1af1c82d3a7c1f4adc4a3a485[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Wed Jan 27 08:57:44 2016 +0100

    WL#8726
    
     - compiler error detected with -Werror=logical-op since the sorted
       variable is a bool and checking that agaginst 0 and 1 is always true.
     - once upon a [1;31mtime[m the function ha_ndbcluster::ordered_index_scan()
       had an "int sorted" argument and then it made sense to try and check
       the expected values. Now that check is useless and can be removed.
     - fix by removing the DBUG_ASSERT
    
    (cherry picked from commit f56b60bd238b3e4f2de504453c32595451bf85bf)

[33mcommit eea9aa307534ebe344c75d0a1fd31e0d6e7b3f59[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Tue Jan 26 15:34:10 2016 +0100

    Bug#22601798 LOGICAL ERROR IN DBACC::PLACEWRITEINLOCKQUEUE
    
     - compiler detected by -Werror=logical-op
     - the variable op can obviously not be equal to
       both ZUPDATE and ZDELETE at the same [1;31mtime[m.
     - fix by removing the dead branch identifed by the compiler.
    
    (cherry picked from commit 9623b0af49c4529a0ae8c5949f1dda0d4ca4c63c)

[33mcommit 1162dcf5791808fd8c968c6d2041fce709c66e6f[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Wed Jan 27 09:46:41 2016 +0100

    WL#8726
    
     - compiler error detected with -Werror=logical-op since "index" can't
       be both larger than zero and smaller than NO_OIF_BLOCKS at the same
       [1;31mtime[m.
    
       storage/ndb/src/common/debugger/DebuggerNames.cpp:92: error: logical
       'and' of mutually exclusive tests is always
       false [-Werror=logical-op]
          if((index < 0 && index >= NO_OF_BLOCKS) || dst[index] != 0)
                           ^
      - fix by changing to an or and removing the unnecessary parentheses
        since each condition is faulty in it's own right.
      - the parenteses was added to fix gcc 4.4 compiler warning...

[33mcommit 19ae5df5668b22b20b6870e3b72a942a6624c7a8[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Wed Jan 27 08:57:44 2016 +0100

    WL#8726
    
     - compiler error detected with -Werror=logical-op since the sorted
       variable is a bool and checking that agaginst 0 and 1 is always true.
     - once upon a [1;31mtime[m the function ha_ndbcluster::ordered_index_scan()
       had an "int sorted" argument and then it made sense to try and check
       the expected values. Now that check is useless and can be removed.
     - fix by removing the DBUG_ASSERT

[33mcommit af5cae58b535cd43f6fec485ed1269443c5e66ac[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Tue Jan 26 15:34:10 2016 +0100

    Bug#22601798 LOGICAL ERROR IN DBACC::PLACEWRITEINLOCKQUEUE
    
     - compiler detected by -Werror=logical-op
     - the variable op can obviously not be equal to
       both ZUPDATE and ZDELETE at the same [1;31mtime[m.
     - fix by removing the dead branch identifed by the compiler.

[33mcommit 066d61966b333fd619ccd096ac68c63725c75886[m
Author: Erik Froseth <erik.froseth@oracle.com>
Date:   Mon Dec 7 16:23:54 2015 +0100

    WL#8706 Persistent storage of Histogram data
    
    This worklog covers the work needed to store histogram data persistent. This is
    needed so that histogram data does not have to be created each [1;31mtime[m the server
    starts.
    
    We have created one new system table for storing histogram statistics;
    mysql.column_stats. The histograms will be stored in a JSON column, which
    gives us a very flexible and powerful way of storing histograms.

[33mcommit 68d5bce13ab6edac83d168b5dcebfdd2c75436de[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Mon Jan 25 15:08:53 2016 +0100

    Bug#21657078: MYSQL DOES NOT COMPILE WITH VISUAL STUDIO 2015
    
    Post-push fix: The problem was that condition variable
    [1;31mtime[mouts could in some cases (slow machines and/or short
    [1;31mtime[mouts) be infinite.
    
    When the number of milliseconds to wait is computed, the
    end [1;31mtime[m is computed before the now() [1;31mtime[m. This can result
    in the now() [1;31mtime[m being later than the end [1;31mtime[m, leading to
    negative [1;31mtime[mout. Which after conversion to unsigned becomes
    ~infinite.
    
    This patch fixes the problem by explicitly checking if we
    get negative [1;31mtime[mout and then using 0 if this is the case.

[33mcommit 08c83c543b5879a05095c8bf8cf0e413976aa13a[m
Author: Priyanka Sangam <priyanka.sangam@oracle.com>
Date:   Mon Jan 25 13:25:00 2016 +0530

    Bug#21277472 MYSQLD DOES NOT HANDLE NDBAPI TIMEOUTS CORRECTLY
    
    Fix for ndb_disconnect failure on Solaris. The previous patch
    removed the code which always overwrites the error to 4243
    while getting an index.  Removed the assert in the index opening
    code in mysqld which specifies that the error code must be
    4243. Also modified the ndb_disconnect test to handle a [1;31mtime[mout
    error.

[33mcommit 69c652997ddd13d87d58f2081bf66609024695cb[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Jan 21 15:06:35 2016 +0100

    Bug#22579037 MYSQL_CLUSTER_BACKUP_PRIVILEGES CAUSES INCORRECT DATETIME
    ON BIGENDIAN
    
     - the two grant tables mysql.tables_priv and mysql.columns_priv
       both have a Timestamp column which are known to contain an
       invalid [1;31mtime[mstamp values, see bug22579518.
     - this causes the mysql_cluster_backup_privlieges() procedure to fail
       while copying existing data from the privilege tables into so called
       backup tables.
     - the failure is new in 5.7 which has a stricter default for sql_mode.
     - fix by adding a continue handler which ignores the error since
       the rows should be copied anyway.

[33mcommit 023dd1e7ef5210548c263bd82b24a64532e33559[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Thu Jan 21 09:52:57 2016 +0100

    Bug#22551595: UPDATE WINDOWSCACHE.CMAKE FOR VS2015
    
    WindowsCache.cmake contains hardcoded results of various CMake
    checks we do during building. This is useful as running these
    tests on Windows is pretty slow.
    
    This patch updates WindowsCache.cmake now that we have
    switched to VS2015 for 5.8. Since we now have [1;31mtime[mspec on
    all platforms, our own implementation which was used <VS2015
    is removed. Missing entries in WindowsCache.cmake are also added.

[33mcommit f1fd8b7e7f6382f4ef1c83b4b7702b5773a47f9c[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jan 15 09:55:05 2016 +0100

    Follow up patch for performance regression introduced by patch for bug#20957068
    
    Introduce some sched_yield() in the binlog-thread loops where
    the injector_mutex is held >99% if the elapsed [1;31mtime[m. The yields
    let other threads waiting to be scheduled a chance to run,
    and grab the injector_mutex when not held by the binlog-thread.
    
    (cherry picked from commit 000394fbe3a8d7a2945fb6b483024b77e16ab20a)

[33mcommit ab386d5c0faf316f451a81a811dc53580a62f7f4[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jan 15 09:55:05 2016 +0100

    Follow up patch for performance regression introduced by patch for bug#20957068
    
    Introduce some sched_yield() in the binlog-thread loops where
    the injector_mutex is held >99% if the elapsed [1;31mtime[m. The yields
    let other threads waiting to be scheduled a chance to run,
    and grab the injector_mutex when not held by the binlog-thread.

[33mcommit 0f8d80fa5018ada94579ca15310cd21912665eeb[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Thu Dec 17 15:58:54 2015 +0100

    Bug#22384569: REDUCE THE SIZE OF THE JSON_WRAPPER CLASS
    
    This patch makes the following changes that reduce the size of
    Json_wrapper objects:
    
    1) Remove the unused member variable m_id.
    
    2) Move some member variables into a union, so that the objects don't
    have room for both binary and DOM values at the same [1;31mtime[m. A
    Json_wrapper either wraps a binary or a DOM, never both at the same
    [1;31mtime[m, so it is enough to have space for one representation at a [1;31mtime[m.
    
    3) Rename Json_wrapper::to_value() to to_binary(), and make it write
    the binary representation directly into a supplied String instead of
    returning a json_binary::Value. This makes the m_tmp member variable
    unused so that it can be removed. Additionally, it saves one copying
    of the binary representation when storing a value in a JSON column.

[33mcommit 736777c9bcadf083600cfb04ba38530529f35f31[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Tue Dec 15 09:17:36 2015 +0100

    Bug#22280780: MAIN.JSON FAILS ON FREEBSD AND OS X
    
    Part II.
    
    The main.json test fails with debug builds on FreeBSD and OS X because
    Json_dom::parse() runs out of stack space when processing a deeply
    nested JSON document. This patch reduces the stack usage in the
    function, so that the test again passes on those platforms.
    
    It reduces stack space usage of the Json_dom::parse() function in
    two ways:
    
    1) By reducing the number of std::unique_ptr objects used in
    Json_dom::parse().
    
    2) By reducing the size of the json_binary::Value objects.
    
    Details:
    
    On the platforms where the stack overflow is seen, std::unique_ptr
    seems to be the big contributor. The problem has only been seen with
    debug builds on FreeBSD and OS X, and only when built with clang. The
    problem was not seen before bug#22254630 replaced std::auto_ptr with
    std::unique_ptr.
    
    Json_dom::parse() is a recursive function, and it pushes a unique_ptr
    onto the stack every [1;31mtime[m it descends into the next level of the JSON
    document. The patch changes this, so that it only has one unique_ptr
    which holds the root of the document. When descending down the
    document tree, it does not add a new unique_ptr on every level.
    Instead, it adds the Json_dom nodes for subdocuments to their parent
    Json_object or Json_array immediately when they are created. Since
    Json_object and Json_array destroy all their children in their
    destructors, and the root of the document is stored in a unique_ptr,
    we know that the entire document tree will be freed if
    Json_dom::parse() returns abnormally.
    
    Another contributor to the stack usage, is the json_binary::Value
    class. There is at least one such object on the stack at each
    recursion level, and the size of the objects is greater than it needs
    to be.
    
    The patch reduces the size of the json_binary::Value objects from 56
    bytes to 24 bytes on the affected platforms. The size reduction is
    achieved by the following changes:
    
    - Use uint32 instead of size_t for m_length and m_element_count. Since
      the binary format specifies that binary JSON documents must be
      smaller than 4GB, uint32 is sufficient for storing the size.
    
    - Declare that the underlying type of the
      json_binary::Value::enum_type enumeration is uint8, so that the
      m_type member variable can fit in a single byte.
    
    - Make a union of the member variables m_data, m_int_value and
      m_double_value. A json_binary::Value object will only use one of
      those members, depending on which JSON type it represents, so there
      is no need to set aside space for all of them at once.
    
    - Reorder the member variables so that the smaller ones come at the
      end and can fill "holes" caused by alignment.

[33mcommit 08236147d603b6249e815c1fe9ae26408b92b4e2[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Wed Jan 6 10:02:59 2016 +0100

    Bug#22262843 ASSERTION FAILED: ENGINE_TYPE() != HASH_SJ_ENGINE
    
    Problem: if a query contained
     'invalid_date IN(subquery)'
    and the subquery was handled by subquery materialization, and sql_mode
    didn't contain ALLOW_INVALID_DATES, the server could exit.
    
    Analysis:
    IN(subquery) first evaluates its left argument with
    test_if_item_cache_changed() to see if it can reuse the previous
    result of IN().
    Because the left argument is a date, this evaluation calls
    Item::val_date_temporal(). The date is invalid; however that function
    unconditionally allows invalid dates (uses TIME_INVALID_DATES), so
    returns an (invalid) DATETIME value, not NULL.
    Then subquery materialization wants to look this value up in the
    index of the temporary table: this happens in
    subselect_hash_sj_engine::exec(); as the value is not NULL, the branch
    for NULL isn't taken:
      'if (item_in->left_expr->element_index(0)->null_value)'
    then it goes on to compute a key value from the value, in
    store_key_item::copy_inner which calls str_to_date[1;31mtime[m_with_warn()
    which uses TIME_INVALID_DATES *conditionally* (only if sql_mode says
    so); in our case it doesn't use this flag so NULL is returned.
    This inconsistency (non-NULL then NULL, for the same value) leads to
    an assertion failure in item_subselect.cc:
       if (s_key->null_key)
        {
          /*
            If we have materialized the subquery:
            - this NULL ref item cannot be local to the subquery (any such
            conditions was handled during materialization)
            - neither can it be outer, because this case is
            separately managed in subselect_hash_sj_engine::exec().<<<<<<<<
          */
          DBUG_ASSERT(engine_type() != HASH_SJ_ENGINE);
    
    Indeed in subselect_hash_sj_engine::exec() the NULL branch wasn't
    taken, so the logic breaks.
    
    Fix:
    NULL is the proper value, it's visible by doing a SELECT of the
    invalid date.
    The first evaluation should use TIME_INVALID_DATES conditionally. All
    other places of code which use this flag already do it conditionally,
    with one exception (get_mysql_[1;31mtime[m_from_str() which I do not feel
    entitled to change without a problematic test case).

[33mcommit 0623e30fed333b9c96c7e4d323c8aa14034b1e73[m
Author: Ajo Robert <ajo.robert@oracle.com>
Date:   Thu Jan 7 14:43:47 2016 +0530

    Bug#21770366 backport bug#21657078 to 5.5 and 5.6
    
    Problem Statement
    =========
    Fix various issues when building MySQL with Visual Studio 2015.
    
    Fix:
    =======
    - Visual Studio 2015 adds support for [1;31mtime[mspec. Add check for
      this and only use our replacement if [1;31mtime[mspec is not defined.
    - Rename lfind/lsearch to my* to avoid redefinition problems.
    - Set default value for TMPDIR to "" on Windows as P_tmpdir
      no longer exists.
    - using VS definition of snprintf if available
    - tzname are now renamed to _tzname.
    - This patch raises the minimum version required of WiX Toolkit
      to 3.8, which is required to make MSI packages with
      Visual Studio 2015
    
    (cherry picked from commit 042ac813f52e97576298dfe9ee01ff5cdf056548)

[33mcommit 5c32df02012027f583335eca723cf09face92eb7[m
Author: Ajo Robert <ajo.robert@oracle.com>
Date:   Thu Jan 7 14:36:19 2016 +0530

    Bug#21770366 backport bug#21657078 to 5.5 and 5.6
    
    Problem Statement
    =========
    Fix various issues when building MySQL with Visual Studio 2015.
    
    Fix:
    =======
    - Visual Studio 2015 adds support for [1;31mtime[mspec. Add check and
      related code to use this and only use our replacement if
      [1;31mtime[mspec is not defined.
    - Rename lfind/lsearch to my* to avoid redefinition problems.
    - Set default value for TMPDIR to "" on Windows as P_tmpdir
      no longer exists.
    - using VS definition of snprintf if available
    - tzname are now renamed to _tzname.
    
    (cherry picked from commit 86e3f8edde0c1fcb3e910195b95f80684ad0522f)

[33mcommit 71b73b6f34e7425c28ce75beaed289e652e80772[m
Author: Ajo Robert <ajo.robert@oracle.com>
Date:   Thu Jan 7 14:36:19 2016 +0530

    Bug#21770366 backport bug#21657078 to 5.5 and 5.6
    
    Problem Statement
    =========
    Fix various issues when building MySQL with Visual Studio 2015.
    
    Fix:
    =======
    - Visual Studio 2015 adds support for [1;31mtime[mspec. Add check and
      related code to use this and only use our replacement if
      [1;31mtime[mspec is not defined.
    - Rename lfind/lsearch to my* to avoid redefinition problems.
    - Set default value for TMPDIR to "" on Windows as P_tmpdir
      no longer exists.
    - using VS definition of snprintf if available
    - tzname are now renamed to _tzname.
    
    (cherry picked from commit 86e3f8edde0c1fcb3e910195b95f80684ad0522f)

[33mcommit 1b4285f9c8dec1fb8968eefc2a22f75f57619600[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Dec 22 13:07:18 2015 +0100

    Bug#22376872: FIX ERRORS REPORTED BY UBSAN
    
    Patch #4: Look for more run[1;31mtime[m errors: left shift and negation of LLONG_MIN
    
    Misc cleanup of LLONG_MIN and left-shift errors.
    
    my_[1;31mtime[m_packed_from_binary()
    left shift of negative value -4161
    
    myisampack.h
    Convert macros into functions, do all left-shifting as uint, to
    make warnings go away (my_compare.cc)
    
    regex/engine.c
    left shift of 4611686018427387904
    left shift of 1 by 63 places cannot be represented in type 'long int'
    Fix: use ulonglong rather than int/long for 'states'
    
    Item_func_neg::int_op()
    run[1;31mtime[m error: negation of -9223372036854775808 cannot be represented in type 'long long int'
    
    decimal2longlong()
    run[1;31mtime[m error: signed integer overflow: -9999999999 * 1000000000 cannot be represented in type 'long long int'
    
    Item_func_int_div::val_int()
    negation of -9223372036854775808 cannot be represented in type 'long long int'
    
    Item_func_mod::int_op()
    negation of -9223372036854775808 cannot be represented in type 'long long int'
    
    Item_func_unhex::val_str()
    Check for error before doing left-shift of -1;

[33mcommit 1f8b589cba040e9b424ef446eefb1815fb93be79[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Fri Dec 25 12:42:55 2015 +0100

    BUG#21889652: Introduce new tc_[1;31mtime[m_track_stats table tracking latency of user transactions/operations/scans

[33mcommit 3450279f946146540bff20d44a5f6c109d25a57e[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Dec 23 17:33:44 2015 +0100

    Followup patch for bug#22135584 (yet another)
    
    The previous follow up patch for this bug introduced the
    function find_epoch_to_handle(). Unfortunately that function
    did not correctly handle that we could have a 's_pOp-event'
    with an epoch number higher than the highest epoch received
    on the 'i_pOp' upto now.
    
    Thus we could end up handling an event from the s_pOp with a
    higher epoch number than we would receive the next [1;31mtime[m we
    polled for i_pOp event. This caused the schema vs binlog events
    to be handled and logged logged in the incorrect relative order
    (Which was the original problem described in this bug report)

[33mcommit aa89532413d77c5dc618a2fbb5c33765055fe212[m
Author: Maitrayi Sabaratnam <maitrayi.sabaratnam@oracle.com>
Date:   Fri Dec 18 16:20:11 2015 +0100

    Bug#22378288 - CLUSTER LOG: LATEST RESTORABLE GCI IN EVENTBUFFERSTATUS MSG IS FUZZY
    
    The definition of 'latest restorable global checkpoint' value returned in the
    'Event buffer status' message in Cluster log can be one of the following :
    the epoch which
     - is currently being consumed
     - will be consumed
     - was already consumed
     - is completely received but that has not reached the event queue yet.
    (though the report does not state which of the above cases was reported).
    
    This fix defines the 'latest restorable global checkpoint' as the one
    that is commpletely consumed by the user and thus is *the* latest
    restorable global checkpoint at *the [1;31mtime[m the report was created*.

[33mcommit 8405fb7b114e09668f31f3fbfbe499e685714300[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Fri Dec 18 09:21:49 2015 +0100

    Bug#22376872: FIX ERRORS REPORTED BY UBSAN
    
    Patch #2: Fix errors reported by Clang+UBSAN
    
    mysys/mf_qsort.cc:121:35: run[1;31mtime[m error: call to function (unknown)
    through pointer to incorrect function type 'int (*)(const void *, const void *)'
    Fix: Stop casting function pointers for my_qsort. Instead cast
    function arguments to the correct type.
    
    sql/keycaches.cc:50:5: run[1;31mtime[m error: call to function (unknown)
    through pointer to incorrect function type 'void (*)(const char *, unsigned char *)'
    Fix: Function was only called in one place. Remove function pointer
    argument and inline the function used.

[33mcommit f8bc5e83a857aeaab84a8f38ac7de3f010f67788[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Dec 16 17:14:06 2015 +0100

    Bug#22376872 FIX ERRORS REPORTED BY UBSAN
    
    Add --ubsan option to mtr, to search for ubsan reports in the server logs.
    
    mysqltest.cc
    negation of -2147483648 cannot be represented in type 'int'
    Fix: make the entire expression unsigned
    
    sql_auth_cache.h
    downcast of address which does not point to an object of type 'GRANT_TABLE'
    Fix: remove the cast
    
    item_buff.cc
    downcast of address which does not point to an object of type 'Item_field'
    Fix: remove the cast
    
    item_[1;31mtime[mfunc.cc
    downcast of address which does not point to an object of type 'Item_date_add_interval'
    Fix: move code to where it belongs: after call to Item_func::eq()
    
    item_xmlfunc.cc
    downcast of address which does not point to an object of type 'Item_func'
    Fix: dont cast to Item_func, use Item, the function may simply be 'true' or 'false'
    
    sql_base.cc
    downcast of address which does not point to an object of type 'Item_direct_view_ref'
    note: object is of type 'Item_field'
    Fix: use Item_ident, which is a common base class for the two classes.
    
    sql_resolver.cc
    downcast of address which does not point to an object of type 'Item_field'
    note: object is of type 'Item_direct_view_ref'
    Fix: call real_item() to get to the actual field.
    
    gis0sea.cc
    member call on address which does not point to an object of type 'rw_lock_t'
    note: object has invalid vptr
    Fix: the target memory was not an object, it was raw memory.
    Use copy CTOR rather than operator=()

[33mcommit 181bf45bcfd836df65d7ece461d44b6fabfa445d[m
Author: magnus.blaudd@oracle.com <>
Date:   Wed Feb 13 14:54:19 2013 +0100

    Make util thread wait binlog to setup schema_ndb
    
     - Fix problem caused by  the ndbcluster threads now starting
       at the same [1;31mtime[m which casues util thread trying to access schema_ndb
       pointer before it has been created by the binlog thread and thus return an
       ugly error during creation of the ndb_schema table.
     - In short, ndb util thread should wait until ndb binlog thread has
       created schema_ndb
    
    (cherry picked from commit 6b79e99e46a3720e05918ef385a2fcead0545e2b)

[33mcommit fb6ae19b0f80078af52e6d5aeed8e06f0beb0db5[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Thu Dec 17 10:52:44 2015 +0530

    Bug #21280428: REMOVE DEPRECATED CONFIG VARIABLES IN 7.5.
    
    - Removed config variables which have been deprecated for long [1;31mtime[m.
    
    - Changed the .ini files used by certain mtr test cases having
    the removed deprecated config variables. Modified them to use new
    parameters instead.

[33mcommit b11108e8fc114451e9b7afab45368e830c6f396e[m
Author: Lukasz Kotula <lukasz.kotula@oracle.com>
Date:   Mon Dec 14 18:53:34 2015 +0100

    Bug#21966621: USAGE OF AUTO_RW_LOCK_READ/WRITE ON ALREADY LOCKED OBJECT CAUSES DEADLOCK
    
    Fault description:
    There is an internal fault in pthread that causes a deadlock when mysql_rwlock_rdlock, mysql_rwlock_unlock functions are used in wrong way. The faulty was triggered by calling two [1;31mtime[m lock function on already locked object, following seqence:
    pthread_rwlock_t *x;
    ...
    pthread_rwlock_wrlock(x);  // R:0
    pthread_rwlock_wrlock(x);  // R:EDEADLK
    pthread_rwlock_unlock(x);
    pthread_rwlock_unlock(x);  // Fault - pthread function doesn't check if the x object is still lock, it always decrement the lock-counter which causes an underflow
    
    pthread_rwlock_wrlock(x); // Deadlock - lock counter != 0
    
    The production code wasn't checking the result returned by locking function (EDEADLK, EINVAL) and it still was relasing mutex two [1;31mtime[ms (RAII - destructor in object).
    
    Incorrect behaviour:
    The fault occured when pluging doesn't release the srv_session and leaves it to be released be server. When server is releasing the session its using Mutexed_map_thd_srv_session class to opearte on session list. Each method of this class is guarded by rwlock, thus function close_all_sessions_of_plugin_if_any() was calling Mutexed_map_thd_srv_session::do_for_all_matching (locking the mutex) and the callback was removing the session from the list by Mutexed_map_thd_srv_session::remove(second lock). Last call leaves the mutex in invalid state thus next attempt of accesing it will cause a deadlock.
    
    Fix description:
    The solution checks in constructor of Auto_rw_lock_read,Auto_rw_lock_write the result code mysql_rwlock_rdlock and if it wasn't locked then corresponding release function in destructor isn't called. The locking result could be also checked with assert to tell alert that the code is working wrongly.
    
    Reviewed-by: evgeny.potemkin@oracle.com
    RB: 10561

[33mcommit b43f5cf680bdbca0f014ee4440b7458bd252e502[m
Author: Lukasz Kotula <lukasz.kotula@oracle.com>
Date:   Mon Dec 14 18:53:34 2015 +0100

    Bug#21966621: USAGE OF AUTO_RW_LOCK_READ/WRITE ON ALREADY LOCKED OBJECT CAUSES DEADLOCK
    
    Fault description:
    There is an internal fault in pthread that causes a deadlock when mysql_rwlock_rdlock, mysql_rwlock_unlock functions are used in wrong way. The faulty was triggered by calling two [1;31mtime[m lock function on already locked object, following seqence:
    pthread_rwlock_t *x;
    ...
    pthread_rwlock_wrlock(x);  // R:0
    pthread_rwlock_wrlock(x);  // R:EDEADLK
    pthread_rwlock_unlock(x);
    pthread_rwlock_unlock(x);  // Fault - pthread function doesn't check if the x object is still lock, it always decrement the lock-counter which causes an underflow
    
    pthread_rwlock_wrlock(x); // Deadlock - lock counter != 0
    
    The production code wasn't checking the result returned by locking function (EDEADLK, EINVAL) and it still was relasing mutex two [1;31mtime[ms (RAII - destructor in object).
    
    Incorrect behaviour:
    The fault occured when pluging doesn't release the srv_session and leaves it to be released be server. When server is releasing the session its using Mutexed_map_thd_srv_session class to opearte on session list. Each method of this class is guarded by rwlock, thus function close_all_sessions_of_plugin_if_any() was calling Mutexed_map_thd_srv_session::do_for_all_matching (locking the mutex) and the callback was removing the session from the list by Mutexed_map_thd_srv_session::remove(second lock). Last call leaves the mutex in invalid state thus next attempt of accesing it will cause a deadlock.
    
    Fix description:
    The solution checks in constructor of Auto_rw_lock_read,Auto_rw_lock_write the result code mysql_rwlock_rdlock and if it wasn't locked then corresponding release function in destructor isn't called. The locking result could be also checked with assert to tell alert that the code is working wrongly.
    
    Reviewed-by: evgeny.potemkin@oracle.com
    RB: 10561

[33mcommit 8bde182a2a4ccd270b5bbe679e96029c0ccef902[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Fri Dec 11 06:55:49 2015 +0100

    Fixes to reduce noise in PB2 runs.
    
    Bug#22280780 main.json
    Bug#21907546 main.user_var
    Bug#22304322 main.locking_service
    Bug#20597049 main.partition_pruning
    
    Also don't run main.server_startup_shutdown_[1;31mtime[m in ASAN.
    
    Approved by Anitha Gopi <anitha.gopi@oracle.com> over IM.

[33mcommit 63363b68770ff3185d49563b1a217b3b9b5bdcc7[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Wed Dec 2 14:32:53 2015 +0100

    Bug#22327897: USE MORE C++11 ATOMICS IN RUNTIME CODE
    
    Follow-up to Bug#22291505. Replace usage of my_atomic* with
    C++11 atomics in run[1;31mtime[m code (with the exception of MDL).

[33mcommit 0a563574b41037b2e8107dfd02a9ef90dc37ebc7[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Tue Dec 8 12:36:05 2015 +0100

    Bug#22083791: DOXYGEN ERRORS IN RUNTIME CODE
    
    Fix various doxygen errors in code owned by the run[1;31mtime[m team.

[33mcommit 8e387cf00c9a08d87b804d373d88cbac9770c5c0[m
Author: Priyanka Sangam <priyanka.sangam@oracle.com>
Date:   Tue Dec 8 16:40:05 2015 +0530

    Bug#21277472  MYSQLD DOES NOT HANDLE NDBAPI TIMEOUTS CORRECTLY
    
    Fixes to handle [1;31mtime[mouts on signals sent by mysqld through
    ndbapi to DBDICT.
    
    ndbd error inserts and fixes:
    Fixed crash in ndbd on ndbapi [1;31mtime[mout. Connection to mysqld
    [1;31mtime[ms out, so schema transaction is released, resulting in
    invalidation of schema transaction key. Then DBDICT fails
    to set up client request due to ndbapi [1;31mtime[mout. On failure,
    DBDICT sends REF to self. REF handler for DBDICT attempts to
    find callback function based on lookup on transaction key.
    Assert fails since schema transaction key invalid. Removed
    assert and modified REF handler to skip callback instead of
    asserting if schema transaction key invalid.
    
    mysqld fixes:
    1. Added and modified error checks so that [1;31mtime[mout error
    detected and results in error return.
    2. Added error insert to reduce [1;31mtime[mout for dictionary signals
    
    ndbapi error inserts:
    Added error inserts in ndbapi to reduce dictionary signal
    [1;31mtime[mout from 7 days to 1 second.
    
    ndbapi fixes:
    1. Prevented [1;31mtime[mout error code 4008 from being overwritten by
    'not found' errors.
    2. Mapped WST_WAIT_TIMEOUT state to [1;31mtime[mout error 4008 for
    listing objects and forcing a GCP wait.
    
    ndbapi request IDs:
    Added unique request IDs to dictionary REQ signals as senderData.
    SenderData is copied to the REF or CONF in ndbd. So REF or
    CONF which is sent in reply to specific REQ should have same
    request ID in senderData. Added checks to verify that request ID
    in CONF/REF matches request ID sent in REQ. If not matching,
    CONF/REF discarded with warning.

[33mcommit b5f211744b49d620d00fdecd13d9af09ef26c15b[m
Author: Thirunarayanan Balathandayuthapani <thirunarayanan.balathandayuth@oracle.com>
Date:   Wed Dec 2 16:09:15 2015 +0530

    Bug #17479594   AVOID INTERMEDIATE COMMIT WHILE DOING
                    ALTER TABLE ALGORITHM=COPY
    
    Problem:
    =======
      During ALTER TABLE, we commit and restart the transaction
    for every 10,000 rows, so that the rollback after recovery would not take
    so long.
    
    Fix:
    ====
    Supress the undo logging during copy alter operation. If fts_index is
    present then insert directly into fts auxiliary table rather
    than doing at commit [1;31mtime[m.
    
    ha_innobase::num_write_row: Remove the variable.
    ha_innobase::write_row(): Remove the hack for committing every 10000 rows.
    row_lock_table_for_mysql(): Remove the extra 2 parameters.
    lock_get_src_table(), lock_is_table_exclusive(): Remove the function.
    
    Reviewed-by: Marko Mäkelä <marko.makela@oracle.com>
    Reviewed-by: Shaohua Wang <shaohua.wang@oracle.com>
    Reviewed-by: Jon Olav Hauglid <jon.hauglid@oracle.com>
    RB: 10419

[33mcommit 94f8e5a6dd610fbd8b858c7c4149bb2a2094edd2[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon Nov 30 09:41:27 2015 +0100

    Patch for bug#22135584
    
      BINLOG CONTAINS SCHEMA EVENTS IN INCORRECT ORDER
    
    Schema events were appended to the binlog in incorrect order
    relative to non-schema events.
    
    Root cause was that the binlog injector did not properly
    handle the case where schema events and non-schema events
    were from different epochs.
    
    This patch modifies the handling of events from the two
    different schema and non-schema event stream such that
    events are are handled one epoch at a [1;31mtime[m - starting with
    events from the lowest available epoch.
    
    Furthermore it clearifies the usage of the local 'gci'
    variable: It was used for at least 3 different purposes
    which caused confusion, and possible bugs, in the code:
    
    1) Used to hold the 'latest available GCI' when polling
       the 'i_ndb'
    
    2) Used to maintain the gci of the eventOp currently being
       handled (As retrieved from nextEvent()).
    
    3) Used as an argument to isConsistent(Uint64 &) into where
       the GCI of a possible inconsistent epoch is returned.

[33mcommit 4ca9fd75088617ed95f5bebe99c068569343c76b[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Wed Nov 11 15:01:53 2015 +0100

    Reset pointer to m_prepared_rename_key after free
    
     - the Ndb_schema_dist_data is released and may then
       be initialized again so the pointer must be reset
    
     - The ndb binlog injector thread own Ndb_schema_dist_data
       manages it's life[1;31mtime[m with the usage if init() and release()
       which may be called multiple [1;31mtime[ms when the thread decides
       to restart

[33mcommit e2cf8547183c9d7cd03499498df65b73cc9e04e3[m
Merge: 744ca6c13c7 9bfda5588e5
Author: Tatiana Azundris Nuernberg <tatjana.nuernberg@oracle.com>
Date:   Thu Nov 26 11:36:09 2015 +0000

    Merge branch 'mysql-5.7-bug21862951' into mysql-trunk-bug21862951
    
    Bug#21862951: MYSQLD_SAFE ERROR LOG TIMESTAMP DIFFERS WITH MYSQLD ERROR LOG
    
    mysqld 5.6 [1;31mtime[mstamped as per "date +'%Y-%m-%d %H:%M:%S'",
    its mysqld_safe        as per "date +'%y%m%d %H:%M:%S'".
    mysqld 5.7+ [1;31mtime[mstamps as per "date -u +%Y-%m-%dT%H:%M:%S.%06NZ",
    or optionally          as per "date +%Y-%m-%dT%H:%M:%S.%06N%:z".
    
    Support either format in mysqld_safe; default to UTC ISO8601,
    like mysqld (5.7+) does. Support --mysqld-safe-log-[1;31mtime[mstamps,
    an analog of mysqld's --log-[1;31mtime[mstamps that will be in line
    with the naming suggested in WL#8053.
    
    --mysqld-safe-log-[1;31mtime[mstamps=UTC|SYSTEM|LEGACY|HYPHEN

[33mcommit 3bbd4be0198923d7827b9cc3d85648f0daec9c47[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Mon Nov 23 10:31:57 2015 +0100

    Bug#22254109: FIX NEW C++11 COMPILATION WARNINGS IN RUNTIME CODE
    
    Fix new C++11 deprecation warnings in run[1;31mtime[m code by
    replacing std::auto_ptr with std::unique_ptr.

[33mcommit db1bde79b1b4c0bd6864f80de4e2c233aef5d025[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Mon Nov 23 08:19:51 2015 +0100

    WL#8896: Enable use of C++11 in MySQL server
    
    This patch turns on C++11 support for MySQL 5.8. This is done by
    explicitly setting -std=c++11 for GCC, Clang and Solaris Studio.
    
    In order to get a near complete level of C++11 support, the patch
    raises the minimum required version of different compilers to:
    - GCC 4.8
    - Clang 3.4
    - Solaris Studio 12.4
    
    Visual Studio minimum is still 2013. It will be raised to 2015
    in a separate patch. This will bring C++11 support on Windows
    more in line with other compilers.
    
    A consequence of using -std=c++11 for Solaris Studio is that
    we no longer link with stlport. Solaris Studio will automatically
    use the g++ run[1;31mtime[m library instead.
    
    The patch also fixes various new compilation errors and removes
    some old obsolete workarounds. Note that new deprecation errors
    (std::auto_ptr and the register keyword) are explicitly downgraded
    to warnings. It will be up to individual teams to fix these new
    warnings.
    
    RPM spec is updated to remove support for RHEL5/OL5 and to
    use compilers from Devtoolset to build on RHEL6/OL6. This is
    needed to meet new compiler version requirements.
    
    Finally the patch includes some limited testing of new C++11
    features (compiler and library).

[33mcommit 3b65e07a0d1fa659018a4a92ea5873802a98f40a[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Mon Nov 23 10:23:48 2015 +0200

    Post-fix for Bug#16400074: Fix the Bug#47453 test case.
    
    The test case was using a SLEEP to ensure that the TIMESTAMP column
    value is advancing. Now that we have microsecond [1;31mtime[mstamps (TIMESTAMP(6)),
    the sleeps are unnecessary. We also add a test for ensuring that the
    [1;31mtime[mstamp does get updated when the data is actually changing.

[33mcommit 5274e11a4c486fa2034ea3c33beae04fafa3ac0d[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Fri Nov 20 11:32:51 2015 +0100

    Fix some[1;31mtime[ms uninitialized warning
    
     - the variables "status_str", "estimated_[1;31mtime[m" and "numAttrs" where
       not initalized in the default switch case.
     - add return after the ndbrequire(false) to signal the compiler that
       the variables are never used for this case.

[33mcommit 460bb9ff014ee6efb0f93789a14b7c8c123b7fba[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Fri Nov 20 10:23:14 2015 +0100

    WL#6378: New data dictionary
    
    Re-enable a few disabled tests.
    Do manual cleanup of DD tables. This is better than waiting for
    WL#7016 for the proper fix as it means the tests can run in the
    mean[1;31mtime[m.

[33mcommit d63840a60eec2b164f3506065337c84af8a3f343[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Nov 19 13:51:05 2015 +0100

    Patch for bug#22224571
    
    The Binlog injector depends heavily on synching the
    binlog injector thread and the mysqld clients by using
    the injector_mutex and injector_cond.
    
    When distributing schema changes, the function
    ndbcluster_log_schema_op() handles the change distribution
    across the mysqld, and it finally waits on events ack'ing
    that all mysqld has acted upon the changes. This was
    implemented as a wait for the NDB_SCHEMA_OBJECT::slock_bitmap
    to be cleared, using the injector_cond / injector_mutex pair
    in a pthread_condition wait.
    
    It is the binlog injector thread which receive and handles
    the events signaling the above ::slock_bitmap changes.
    As a lock on the injector_mutex was also held when
    polling the eventBuffer, where the injector thread spend
    99.9...% of its [1;31mtime[m, it was hardly possible for the
    pthread_cond signaling of ::slock_bitmap changes to get
    through to ndbcluster_log_schema_op().
    
    This patch introduce a condition variable in each
    NDB_SCHEMA_OBJECT (NDB_SCHEMA_OBJECT::cond).
    The above conditional wait for NDB_SCHEMA_OBJECT::slock_bitmap
    to be cleared, is changed to wait on / signal
    the NDB_SCHEMA_OBJECT::cond & ::mutex pair.

[33mcommit dcb8792b371601dc5fc4e9f42fb9c479532fc7c2[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Nov 19 17:11:50 2015 +0800

    WL#6204 - InnoDB persistent max value for autoinc columns
    
    This worklog makes use of the framework introduced by WL#7816 to persist
    the autoinc counters. After this worklog there would be some behaviour
    changes or important points of autoinc counter:
    
    1. Counters of AUTO_INCREMENT should be strictly incremental, as it works
    now, when the server is running.
    
    2. Allocated counters won't be reused after the server restart normally,
    this must be guaranteed.
    
    3. Allocated counters won't be reused after the server restart from a
    crash, this can NOT be guaranteed, since we can't flush the redo logs
    immediately every[1;31mtime[m.
    
    4. Rollback of transaction won't revert the counter.
    
    5. 'ALTER TABLE' would not change the counter to a smaller value than
    current existing max counter in the table.
    
    6. If a counter is updated to some larger value than current next value,
    the larger value should be remembered and next counter should start from
    it.
    
    The persistence during DDL is not supported very well now, since some
    DDL operations are not atomic now. This would be fixed in WL#7743,
    WL#7141, and WL#7016.
    
    RB:9138
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Marko Makela <marko.makela@oracle.com>

[33mcommit da23ddc1b90ff4e781863e2094d1a554f336b150[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Tue Nov 17 12:44:45 2015 +0100

    Bug #22172389: MAIN.HELP_VERBOSE FAILING ON FREEBSD
    
    The main.help_verbose test fails frequently on FreeBSD
    due to a failure in the [1;31mtime[mr thread execution. Timers
    are used for checking max statement [1;31mtime[m, and are not
    needed if starting the server with --help. Thus, the
    initialization of the [1;31mtime[mr thread is skipped when
    starting with --help.

[33mcommit b008cf253adc534043a440ca17dabf0ff0ab0dd8[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 17 13:54:58 2015 +0100

    Patch for bug#22203672
    
     NDB REPLICATION : DEBUG BUILD GENERATES EXCESSIVE LOGS
    
    Do not write to error log when we [1;31mtime[mout in state WAIT_EVENT.
    (Affects only DEBUG compiled binaries)

[33mcommit 3d14b6ab5abc89f2c34d26214b058b6a626d7aa9[m
Author: Dmitry Shulga <dmitry.shulga@oracle.com>
Date:   Tue Nov 17 11:18:35 2015 +0600

    BUG#21749169 - asserts `error != 146' provided by wl#7158 at various places are hit
    
    This bug resulted from WL#7158. WL#7158 introduced several additional
    asserts checking that a possible error returned by storage engine isn't
    either HA_ERR_LOCK_WAIT_TIMEOUT or HA_ERR_LOCK_DEADLOCK.
    Although these error shouldn't be posed by innodb storage engine
    the following RQG grammar:
    
    query:
      DELETE FROM mysql.tables_priv WHERE user = 'u1_2' LIMIT 1 ;  |
      transaction ;
    query_init:
      SET SESSION SQL_MODE = '' ; COMMIT ;
    thread1:
      GRANT ALL ON testdb_S.t1_temp_S2 TO 'u1_2' ;
    transaction:
      START TRANSACTION WITH CONSISTENT SNAPSHOT |
      SAVEPOINT A |
      ROLLBACK WORK TO SAVEPOINT A;
    
    hit the assert DBUG_ASSERT (error != HA_ERR_LOCK_DEADLOCK).
    
    This happened only for configuration where binlog is OFF since the statement
    ROLLBACK TO SAVEPOINT released a MDL lock for the table mysql.tables_priv
    while still holding a row-level lock on the table mysql.tables_priv for
    the row being processed by the statement DELETE FROM mysql.tables_priv.
    Such release was done without taking into consideration whether Innodb
    still holding a lock or not. That led to a lock wait [1;31mtime[mout happened on
    processing the GRANT statement.
    
    To resolve this bug a storage engines are requested unconditionally (that is,
    both for configuration with and without binlog) whether it is allowed
    to release MDL lock and do it if it's true.
    
    Also the debug asserts
      DBUG_ASSERT(error != HA_ERR_LOCK_DEADLOCK)
      DBUG_ASSERT(error != HA_ERR_LOCK_WAIT_TIMEOUT)
    that were removed before WL#7158 was pushed into the tree mysql-trunk has been
    reintroduced with additional checking for if a server is running in the cluster
    environment in order to exclude its firing for cluster server since there the
    original asserts can be false.

[33mcommit f0314c1702d21de7055ab667c1733784b48a6421[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Wed Nov 4 10:33:59 2015 +0100

    Bug#21522980: Resolver: Simplify some often executed condition and expr code
    
    This is a cleanup patch for better performance and code simplification.
    
    Refactored processing of join conditions: Previously, join conditions
    were resolved by running through the leaf table list and traversing
    upwards using the embedding member until the root was reached. This
    meant that several join nodes might be visited multiple [1;31mtime[ms.
    The new implementation is a recursive function that goes top-down,
    visiting each table/join nest only once. Even though the function
    is recursive, it will be invoked only once for simple queries.
    
    Shortcut of function calls: The following functions are no longer
    called when there is no work to do:
    - setup_ftfuncs()
    - check_view_privileges()
    - setup_natural_join_row_types()
    - flatten_subqueries()
    
    Resolving of variable assignments: This used to be done for every [1;31mtime[m
    the expressions of a query block were resolved, but it is necessary
    only once per query. Separated into a new function
    resolve_var_assignments() which is called once from handle_query().
    
    Error handling: Added a few asserts for !thd->is_error(), to improve
    checking for unnoticed errors, that otherwise may cause erroneous
    execution.
    Due to adding these new checks, it was necessary to add explicit
    check for thd->is_error() in Item_sum_num::fix_fields() and
    mysql_test_select().
    
    Test change in i_main.subquery: Since join conditions now may be resolved
    in a different order, optimization may be shortcut due to
    "Impossible WHERE" for a different join nest.
    
    sysbench point select shows performance enhancement 0-1 per cent.

[33mcommit 80abe0dd9f8325d078590c9644e465b5ffb14eae[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Nov 10 10:12:46 2015 +0100

    Bug#22157531 WITH NO MORE .FRM 64K LIMIT WE CAN CREATE MASSIVE TABLES, BUT TOO SLOWLY..
    
    Problem: Creating tables with long generated columns take a looong
    [1;31mtime[m to execute. The new dictionary code ends up using String::print
    which appends characters one-by-one.
    
    Solution: reserve memory up-front, before appending chars.
    Also: fix similar issue in append_unescaped()

[33mcommit e5065ba320f0e3d2d818dc573be68e799dbfc9a1[m
Author: Olav Sandstaa <olav.sandstaa@oracle.com>
Date:   Fri Nov 6 10:04:56 2015 +0100

    Bug#22143189 OPT_COSTMODEL_RESTART FAILS RANDOMLY IN PUSHBUILD
    
    The opt_costmodel_restart tests fails some[1;31mtime[ms due to a different
    cost estimate for reading a table than expected. The cause for this
    variation is that after a restart of the server the statistics about
    how much of a table that is in the InnoDB memory buffer can vary.
    
    The failing test case was run with different cost constants for
    reading pages from the InnoDB memory buffer and from disk. To ensure
    that the same cost estimate is produced in each run, the fix for this
    problem is to adjust the cost constants for reading pages from memory
    buffer and disk to have the same value.

[33mcommit 66c05c2a4bec1f963afc547247d8eced924b785b[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Oct 29 12:21:23 2015 +0100

    Bug#22078874 GIS FILES IN SQL/ TAKE UNACCEPTABLY MANY RESOURCES TO COMPILE
    
    Problem: Some of the gis source files take long [1;31mtime[m to compile,
    and require lots of memory.
    
    Solution:
    Remove template argument CoordinateElementType from BG_models.
    It is always double anyways.
    
    Move templatized code out of item_geofunc_internal.h
    add explicit template instantions.

[33mcommit 5bb80c488b5b94d7397758f52308ee647543b0e5[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Sep 10 15:24:02 2015 +0200

    WL#8703 ndbinfo config parameter tables
    
     - rewrite the query showing join between two ndbinfo tables
       to avoid that .result file need to be updated every [1;31mtime[m a new table
       is added.

[33mcommit df4b0a0d699cde9a1e2bb4716c6b3a87355cdecb[m
Author: Dmitry Shulga <dmitry.shulga@oracle.com>
Date:   Wed Oct 21 15:03:19 2015 +0600

    BUG#12779463 - windows minidump filename should include the process id and /or [1;31mtime[mstamp.
    
    For Windows platform original behaviour of mysql server on server crash was
    to name minidump file as module_name.dmp where module_name was a name of server
    executable file. Such naming scheme doesn't take into account the fact that
    every server crash rewrite a minidump left from the previous crash so
    improtant information is lost.
    
    To fix this issue new scheme for naming minidump files has been introduced.
    Within that new scheme a process identifier is appened to the name of minidump
    file. So after this patch a name of the minidump file will look something
    like mysqld.exe.7296.dmp, where 7296 is a pid of the mysqld server.

[33mcommit 6161562e10cc0e1d94454bfe38f26faac86754a3[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Mon Oct 19 16:37:48 2015 +0200

    Fix incorrect friend declaration in class ScanNextReq
    
    Use defined 'ScanNextReq::SignalLength' instead if magic literal '4'
    when sending ScanNextReq signals.
    
    Remove obsolete NULL assignment to NdbTransaction::theScanningOp immediately
    before calling ::closeTransaction(NdbTransaction*).
    
    ::closeTransaction() will release any Ndb(Scan)Operations owned by
    it and *tehN' assigning all its Op-pointers to NULL before the
    NdbTransaction object itself is released.
    
    Fix possible memleak of IndexBound and InterpretedCode objects
    from ScanOperation if NdbScanOperation::close_impl() failed.
    
    It would then 'return -1' *before* reaching the end of the
    methode where we used to release these objecs.
    
    As these objects are not required by close_impl() itself,
    we can safely move the release code to start of ::close_impl()
    before any possible 'return' statement.
    
    Remove too strict assert when delivering a SCAN_TABREF signal.
    
    TABREF can arrive late (after the scan is closing)  in case the
    'checkMagicNumber()' test should fail,  and reject the incomming
    signal.
    
    Possible scenarios are where a scan [1;31mtime[mouts and gives up waiting.
    It will then close the scan operation and release the associated
    NdbTransaction. Later a TABREF, or any other signal, related to
    this scan can arrive 'late'
    
    NOTE: Similar 'checkMagic' mechanism are used when delivering other
    signals - *without* this assert.
    
    NdbTransaction objects are recycled in two different
    'free lists'. One are used for objects already connected
    to a specific node, the other for transactions which
    are disconnected (possible due to failures), and thus
    need a reconnect when they are reused.
    
    Add asserts which enforce this 'state-rule'

[33mcommit 2e99e1ef828faabedbce9253268d3d0424635af8[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Fri Oct 16 13:27:30 2015 +0200

    BUG#21886476: Ensure that spin[1;31mtime[mr works properly in ndbmtd

[33mcommit 0b8d749d85b5c40522663190ba0921ca7eda14a3[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Oct 15 09:35:11 2015 +0200

    Patch for bug#21809959
    
    DROPPED EVENT OPERATIONS REMOVED TOO EARLY AFTER INITIAL RESTART
    
    Several objects in the NdbEventOperationImpl is garbage collected
    based on which GCI has been consumed by the clients. This also
    includes NdbEventOperations which are dropped by dropEventOperation().
    However, as the event_op can still have referrences from buffered
    events still not consumed, we cant destruct the event_op immediately.
    First when all events having a GCI <= the 'event_op->stop_gci' has been
    consumed, the event_op can be destructed.
    
    This mechanism relies on a monotonic increasing GCI number - which
    it is not! During initial restart the GCI sequence is reset and
    starts over again from 0/0. Thus leading to both event_op
    being prematurely released, or not released at all (leaked).
    See bug report for further explanation.
    
    This patch introduce a MonotonicEpoch, containing both the GCI
    and a 'gci generation'. The 'generation' is incremented every
    [1;31mtime[m there is a restart. Comparison operators are provided
    as part of the MonotonicEpoch such that the generation is
    used to provide a monotonic increasing sequence,

[33mcommit a1703de54ab6a983f1a21ec8684dfb9705ebe535[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Mon Oct 12 15:22:13 2015 +0530

    Bug #11764714 : Adding --connect-retries and
    --connect-retry-delay options to NDB tools.
    
    When a tool is not able to connect to the cluster,
    it tries reconnecting every 5 seconds by default
    (for most tools) for a fixed number of retries.
    (12 retries in most tools)
    This patch gives the user capability to provide
    customized retry delay and number of retries by
    giving --connect-retry-delay=X and --connect-retries=Y
    options respectively.
    (X is the number of seconds after which the tool
    tries reconnecting to the cluster and
    Y is the number of [1;31mtime[ms the tool will try reconnecting
    to the cluster.)
    
    Modified ndb_opts.h file to include --connect-retry-delay
    and --connect-retries options as standard options and have
    used the values of these options instead of the respective
    hard-coded 'retry delay' and 'retries' values in the tools'
    source files.

[33mcommit fd87bb926d0a779bff4ad9050bf7d1b16e34c151[m
Author: Lakshmi Narayanan Sreethar <lakshmi.narayanan.sreethar@oracle.com>
Date:   Fri Oct 9 18:20:43 2015 +0530

    Bug#18554390 :
    DROP DATABASE NOT WORKING IN PRESENCE OF FOREIGN KEYS
    
    When a Foreign Key is dropped during a node's down[1;31mtime[m, the node crashes
    when it tries to come up and sync its schema with other nodes during the
    start phase. This is because the dropping of FK was never handled in the
    Dbdict::restartDropObj().
    
    This patch fixes it by updating that function to handle the dropped FKs
    during restart. Also added testcases.

[33mcommit 1728aaddf753e4e916fd434dfe58932c85d5ec2e[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Mon Oct 5 15:04:52 2015 +0200

    Remove potential loops starting transaction on master in testNodeRestart
    
    Some tests have started to [1;31mtime[m out on new test platform:
    testNodeRestart -n Bug20185 T1
    testNodeRestart -n Bug36245 T1

[33mcommit 957c53f02f4af83702b9e63564863cefda1085bf[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Oct 2 12:20:09 2015 +0200

    Fix for ATR failure in 'testIndex -n DeferredMixedLoadError T1 T6 T13'
    
    Inserted error should be cleared after it has been tested.
    Instead it was set again. This could cause subsequent testcases
    to fail when inserting another error on another node - Effectively
    having two different errors inserted at the same [1;31mtime[m which were
    not intended to work together.

[33mcommit 4648db17fa2bbdb7ba9dcec856dc414a470b3831[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Mon Sep 21 23:24:48 2015 +0200

    WL#8736 NDB: Run autotest from Hudson
    
    Splitting up daily-basic and daily-devel in roughly two hours suites.
    Test cases that take longer [1;31mtime[m are moved to weekly suites.

[33mcommit 47370ca64de5c8daa583e3b5add916412a251c33[m
Author: Andrei Elkin <andrei.elkin@oracle.com>
Date:   Wed Aug 19 16:27:24 2015 +0300

    Bug#19630322 MTS: WORKERS MAY NOT ADAPT TO THE MASTER VERSION
    
    There's a flaw in master server version adaptation framework in that
    MTS workers could install another execution context at [1;31mtime[m the old
    context is being used.
    This occurs when Coordinator schedules an event (CREATE TABLE query)
    and after that processes a Format Description event, and does so
    asynchronously with the Worker. That creates a race between execution
    of CREATE TABLE in the old pre-FD context and the new context
    installation to the Worker which was done by the Coordinator thread.
    
    **Fixed** with relocating the whole master
    Format_description_log_event installation
    (set_rli_description_event()), which was previously in the Coordinator
    domain, to the Worker thread.
    
    By the refined logics, when coordinator reads
    Format_description_log_event, it calls the own
    Relay_log_info::set_description_event() method. This function will
    set the "memo" flag Slave_worker::fd_change_notified=false for each
    worker (to mean reset fact of any former notification).
    The flags will be used by Coordinator as a memo to itself
    to notify (see L4 below) Workers who are scheduled with
    a first group of events that follows the new FD.
    The Worker finds (Slave_job_group::new_fd_event !=NULL) the
    notification before it has executed the first group event, to install
    the new FD into its execution context. At once the Worker conducts the
    version adaptation.
    
    The worker logics is received a small block (see L5) consisting of
    a. checking whether a new FD event is supplied, to install it and run version adaptation
       routine;
    b. the Worker is made to "intelligently" destroy "obsolete" FD instances (see
       new ulong Format_description_log_event::usage_counter and Slave_worker::set_rli_description_event(),
       An obsolete FD can also be destroyed by Coordinator when Worker has exited.
       Worker never destroy the very last read FD.
    
    As a side effect, the version adaptation made work correctly for
    a case of mysqlbinlog | mysqld aka direct binlog applying via client session.
    More importantly, the FD installation relocation fixes other potential vulnerabilities
    where being processed by Worker events may depend on a certain FD. The old mechanism
    did not protect the correct execution environment.
    
    On the low-level,
    
    L0.
    
      Format_description_log_event class is extended with
        Format_description_log_event::usage_counter
      a usage counter
      to keep track of concurrent utilization of an instance and its
      correct destruction in Relay_log_info::set_rli_description_event()
      and Slave_worker::set_rli_description_event().
    
    L1.
    
      Relay_log_info::adapt_to_master_version(Format_description_log_event *fdle)
    
      is made to work by Coordinator or SQL threads.
    
    L2.
    
      ulong Relay_log_info::adapt_to_master_version_updown()
    
      is made to be invoked by Workers too. It's extensively commented to
      hopefully make the framework understood better.
    
    L3.
    
      Slave_worker::set_rli_description_event()
    
      is refactored to made the Worker to delete stale FD.
    
    L4.
    
      Slave_worker *Log_event::get_slave_worker()
    
      the new notification logics is deployed.
      A worker can't miss a fact of FD/version change when it takes
      on following events that are bound to the FD/version through
      implied execution context.
    
    L5.
    
      slave_worker_exec_job_group()
    
      augmented with logics of checking out the new notification and
      the new FD installation including version adaptation function (L2).

[33mcommit 68c3c00b15ee55440ebe560027614ee9644d3abe[m
Author: Horst Hunger <horst.hunger@oracle.com>
Date:   Wed Sep 9 10:51:38 2015 +0200

    Replaced the sleep with a conditional wait and reduced [1;31mtime[m in plugin to stabilize test for PB

[33mcommit ff13ed0df1039d68839f0a251a52aa963bb910cc[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Thu Aug 27 16:12:54 2015 +0300

    WL#7158 "Move privilege system tables from MyISAM to transactional storage".
    
    Privilege tables now use InnoDB SE instead of MyISAM.
    
    Note that even though we switched to transactional tables user-manipulation
    statements semantics is kept backward-compatible (i.e. MyISAM-compatible)
    when possible. Particularly this means that user-manipulation statements
    which fail due to logic errors after updating some privileges are still
    committed i.e. are partially executed as before. System errors like
    errors from storage engine/OOMs are handled by full rollback as it is
    impossible to handle them in any other way (e.g. think of deadlock error).
    Error handling in ACL code was improved to support this.
    
    We also try to avoid deadlock/lock-wait [1;31mtime[mout errors which can occur
    for ordinary DML/InnoDB tables. This is achieved by user-manipulation
    statements/ACL code acquiring strong SNRW and SRO locks on privilege
    tables (i.e. by simulating table-level locking for them).
    
    This task opens path for further improvements in ACL code such as changing
    user-manipulation statements to be fully atomic.
    
    Note that we still allow creation and start up on MyISAM privilege tables
    to simplify upgrades/restoring backups from previous versions.
    
    However, we now require presence of mysql.procs_priv and proxies_priv
    privilege tables in case of upgrade (i.e. one should be upgrading at
    least from 5.5).
    
    In order to support switch to InnoDB privilege tables the following
    auxiliary changes were made:
    
    - Separate SQLCOM_SET_PASSWORD command to handle SET PASSWORD was
      introduced.
    - mtr_system_tables_data.sql was changed to create only 2 root
      accounts instead of 4. Extra accounts which were removed created
      ambiguity for host identification. This ambiguity, which surfaced
      thanks to InnoDB using different row ordering than MyISAM, caused
      many test failures.
    - Since removal of these two root accounts has created problem with
      connecting on Windows for some of the tests, mysqltest and MTR were
      changed to use named pipes as a default connection method on this
      platform (similarly to Unices).
    - Issues with Windows pipe support which were discovered after this
      switch were addressed (e.g. improved use of PFS instrumentation,
      fixed handling of connection termination).
    - Test cases were adjusted to take into account introduction of
      separate SQLCOM_SET_PASSWORD command, switch to pipes on Windows
      and extra account removal.
    - New test coverage for transactional privilege tables was added,
      specifically for handling of logic and system errors with them.
      Also some test cases were adjusted to take into account the fact
      that we now use transactional privilege tables.
    - wait_until_connected/disconnected/_again.inc were adjust to take
      into account switch to pipes and the fact that server start-up
      can now take longer on slow machines due to InnoDB doing recovery
      on privilege tables.

[33mcommit 5e2faa44fff9dd5dd464044bcf61d77c879c1eb7[m
Merge: 5ec1eb47c67 43a3d972888
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Aug 20 09:09:54 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      WL#8756  Deprecate binlog_max_flush_queue_[1;31mtime[m in 5.7
      Bug#21506237 SIG11 AT QUERY_ARENA::STRMAKE IN SQL/SQL_CLASS.H:216
      Bug#21506237 SIG11 AT QUERY_ARENA::STRMAKE IN SQL/SQL_CLASS.H:216
      Bug#21541481 MEMORY LEAK OF ALLOCATIONS MADE IN VAL_JSON_FUNC_FIELD_SUBSELECT
      Bug#21560934 CHANGE THE NAME OF JSON_APPEND() TO JSON_ARRAY_APPEND()
      Bug#21560934 CHANGE THE NAME OF JSON_APPEND() TO JSON_ARRAY_APPEND()
      Bug #21498544: mysqld --initialize should not complain about lack of ssl certs
      Bug #21498544: mysqld --initialize should not complain about lack of ssl certs
      Small change to default config for Docker-specific rpm package Syncs "official" and our own Docker images
      Bug #20201006 spamming show processlist prevents old connection threads from cleaning up.
      Bug#21451922 - FOUND A MISMATCH PAGE, EXPECT PAGE - ASSERTION
      Doxygen warnings elimination.
      - Bug#21629618: RECOVERY FAILURE: PLUGIN 'INNODB' INIT FUNCTION RETURNED ERROR
      Bug#21616585 ASSERTION FAILED: !(DECIMAL_IS_ZERO(FROM2) && FROM2->SIGN)
      Bug #20625566:   SHOW CREATE USER ALLOWS ACCESS TO OTHER USERS PASSWORD HASH
      Bug# 20625566:   SHOW CREATE USER ALLOWS ACCESS TO OTHER USERS PASSWORD HASH
      - Bug#21629618: RECOVERY FAILURE: PLUGIN 'INNODB' INIT FUNCTION RETURNED ERROR
      Bug#21557723 CAN'T USE OUTPUT OF 'SHOW CREATE TABLE' TO CREATE A NEW TABLE

[33mcommit 269be73297466853f3a19fb1b9ab3cef3642fd93[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Tue Aug 18 17:46:08 2015 +0200

    Bug#21651706 NDB.NDB_SUMA_HANDOVER FAIL DUE TO SEGMENTATION FAULT FOR GCOV RUN IN PB2 FOR 7.4
    
    ndb_mgm_get_latest_error functions are some[1;31mtime[ms used with potential null handle.
    
    This patch cherrypicks some changes making these functions not
    crashing but return dummy values instead from:
    
    commit b7b847bfa7d6ad1ba22911cb0772cb333a5deaf1
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri Apr 24 13:29:04 2015 +0200
    
        Bug#11760802 SEVERAL MGMAPI FUNCTIONS RETURN 0(SUCCESS) WHEN NO HANDLE
        OR NOT CONNECTED

[33mcommit 52042b2759926a41f4c0d84383f08ba6648ca7f7[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Mon Aug 17 19:39:03 2015 +0200

    Bug#21616263 NDB : DROPEVENTOPERATION INTERNAL RETRIES CORRUPT M_ACTIVE_OP_COUNT
    
    Count of active subscriptions for NdbEventBuffer could be
    decremented more one once if stopping subscription failed due to
    for example busy server.  Count could also fail to decrement if
    communication with data node fore example [1;31mtime[md out.
    
    This was a regression introduced with:
    commit 50a55ef9520ff0c8cb1c9e4a825f8bfec191afbd
    Author: Mauritz Sundell <mauritz.sundell@oracle.com>
    Date:   Thu Mar 19 13:50:08 2015 +0100
    
        Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS
        Bug#20561446 NDB : NDBEVENTBUFFER NEEDS MORE THREADING PROTECTION

[33mcommit 995839ae476ad715e79ce46a5cd8c562d8c2a300[m
Merge: 7771a5c1a9f 0f8300ab1e2
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Aug 17 13:58:56 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug#21640085 RECV_PARSE_LOG_REC VIOLATES ITS CONTRACT RE. INCOMPLETE RECS FOR MLOG_CHECKPOINT
      Bug#21628087 innodb_log_checkpoint_now not fully compatible with WL#7142
      Bug#21504889: MYSQLPUMP --HELP PROVIDES NO INVOCATION SYNTAX When mysqlpump is invoked with wrong options mysqlpump should provide proper invocation syntax. Fixed this issue and also fixed the same in --help output for mysqlpump.
      Bug#21335271 CANNOT SET MYSQL_FIREWALL_TRACE AT RUNTIME
      WL#7264: Included the missing test files in the main suite. func_[1;31mtime[m.test metadata.test null_key_all.test null_key_icp.test null_key_none.test update.test
      Bug #21350175: SUBQUERIES IN PROCEDURE CLAUSE OF SELECT STATEMENT CAUSES SERVER FAILURES.
      Bug#21046372: GAPS IN RETRIEVED_GTID_SET WHILE NO GAPS IN EXECUTED_GTID_SET
      BUG#19286708 REPLICATION BROKEN AFTER CREATION OF SCHEDULED EVENTS
      Bug#21625322: REMOVE UNUSED FUNCTIONS AND CONVERT GLOBAL SYMBOLS TO STATIC (PART 3)
      Bug#21046372: GAPS IN RETRIEVED_GTID_SET WHILE NO GAPS IN EXECUTED_GTID_SET
      Bug#20909880: BROKEN REPLICATION ON SQL THREAD RESTART IF GTID_MODE IS ENABLED
      Bug #19985318: DATE_FORMAT: STACK BUFFER OVERFLOW IN                INT10_TO_STR
      BUG#21134683 NATIVE PARTITIONING MOVING FILES BETWEEN WINDOWS AND LINUX
      Bug#21562212 MEMORY/PERFORMANCE_SCHEMA INSTRUMENTS SHOULD BE ALWAYS ENABLED
      Bug#21625322: REMOVE UNUSED FUNCTIONS AND CONVERT GLOBAL SYMBOLS TO STATIC (PART 3)
      BUG#21134683 NATIVE PARTITIONING MOVING FILES BETWEEN WINDOWS AND LINUX
      Bug #21376492 DIFFERENT DIGEST FOR IN FUNCTIONS WITH ONE ARGUMENT
      Bug#21625322: REMOVE UNUSED FUNCTIONS AND CONVERT GLOBAL SYMBOLS TO STATIC (PART 3)
      Bug#21613422: Assertion failed: !thd->is_error() in select_lex::prepare()
      Bug#21628058 - DICT_TABLE_HAS_INDEXED_V_COLS MISSING UNIV_INLINE IN .IC
      Disable two failing tests in Valgrind
      Add back an assert previously deleted needlessly. Approved by Marko in rb#9476.
      Followup fix to the testcase for Bug#20698468 Proved by Sunny over email
      Bug#21296553: WARNINGS SENT TO STDERR/OUT EVEN WHEN LOGGING SET TO SYSLOG
      Bug#21625471 LEGACY MYSQL_INSTALL_DB{.SH/.PL} SCRIPTS SHOULD BE REMOVED FROM SOURCE
      Fixed named_pipe.result and shm.result.
      BUG#21066592 DEFAULT LOCATION OF SOCKET FILE SHOULD NOT BE /VAR/LIB/MYSQL
      Bug#21625760 REMOVE UNUSED FUNCTIONS IN INNODB API0API.CC
      Fixed bug#21487651: GCOLS: MEMORY LEAK AFTER FAILED ALTER TABLE
      WL#7264: Fixed the test limit.test in the main suite.
      Bug#20797764: FAILED CREATE VIEW IS BINLOGGED, AND NOT FILTERED OUT
      Followup patch for bug#20698468.
      Bug #21025880 DUPLICATE UK VALUES IN READ-COMMITTED (AGAIN)
      Bug#21055139 SUBQUERY HAVING COUNT WITH GROUP BY GIVES INCORRECT RESULT
      BUG#21551464 - SEGFAULT WHILE INITIALIZING DATABASE WHEN INNODB_DATA_FILE SIZE IS SMALL
      Bug #21601696: MYSQLADMIN SHUTDOWN FAILS FOR 5.7.0 .. 5.7.8
      WL#7264:  Migrate tests that do not have any engine dependencies Final patch.
      - Bug#21569876: SEARCH_LATCH_TIMEOUT DOESN'T MAKE SENSE AFTER SUPPORTING MULTI AHI LATCH
      - Disabling test-case wl6501.test for Windows as the server restart on crash   while truncating table with fts is taking longer.   Log file downloaded from the pb2 run doesn't have any immediate reference.   Will continue to investigate it independently.

[33mcommit c42aebf1eccc88004259910bdfd7cf3418dcba04[m
Author: Mohit Joshi <mohit.joshi@oracle.com>
Date:   Mon Aug 17 15:33:11 2015 +0530

    WL#7264: Included the missing test files in the main suite.
    func_[1;31mtime[m.test
    metadata.test
    null_key_all.test
    null_key_icp.test
    null_key_none.test
    update.test
    
    Updated the common-tests.inc file with --sorted_result.

[33mcommit 679cca750585b769b0b1f42c25863e5b48eb3479[m
Merge: b42c778272e 39fa4044d80
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Sat Aug 15 21:30:41 2015 +0200

    Bug#18401324 AUTOTEST FAIL: TEST_EVENT -R 5000 -N BUG30780 T1
    
    This patch removes some possibilty for inconsistency using scan
    lock take over.
    
    Scan locks within a fragment are identified with a scan number in
    dblqh and an operation index within that scan.
    
    When a fragment switches primary replica, can be from a node crash
    or restart, new scan on the fragment will start over using low scan
    number and operation index.
    
    If an application do a scan before primary replica switch and then
    issue a scan lock take over operation after replica switch the scan
    number will now be used at the Dblqh instance that are currently
    holding the primary replica for the fragment and that instance can
    either have no such scan lock and operation will fail (no harm), or
    it can have a scan lock, but probably not for the same row.
    
    If the lock is for the wrong row, updates of the rows could now
    result in inconsistency since locking is by passed for that row.
    (Fixed by patch 4)
    
    Also, since locks can be reused several [1;31mtime[ms within a transaction,
    an already taken over lock within a transaction could mistakenly be
    over taken again by another transaction resulting in an inconsistent
    lock queue for that row since the run queue with exclusive lock may
    only contain operations from the same transaction.
    (Fixed by patch 5)
    
    This patch serie do no changes of external protocols, it only changes
    ACCKEYREQ signal within a LDM instance.

[33mcommit 39fa4044d805c8d5d29d4c3c821bad32d956e267[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Sat Aug 15 21:27:15 2015 +0200

    Only allow scan lock take over by other transaction if lock is
    unused.
    
    If one do several updates to the same row within a transaction the
    lock can be used several [1;31mtime[ms, but the lock can not be allowed to
    be used from several transactions at the same [1;31mtime[m.

[33mcommit cbb3f6c0c28ac7716e9c3824ae654b9f97fa1884[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Tue Jul 28 12:19:58 2015 +0100

    Bug#20204854       BACKUP FAILING UNDER HEAVY LOAD EXCEPT WHEN SNAPSHOTSTAR
    Bug#21362380       NDB : LOG MAXDISKWRITESPEEDCHANGES FROM ONE LDM INSTANCE
    
    Background
    
    During normal operation, data nodes attempt to maximise
    the disk write speed used for LCP and Backup while remaining
    within the bounds of the configured MinDiskWriteSpeed and
    MaxDiskWriteSpeed.
    
    In 7.4, the implementation of disk write throttling was
    changed to give each LDM thread an equal share of the total
    budget.  This allows parallel LCP to occur without exceeding
    the configured disk IO budget.
    
    However, Backup is executed by only one LDM thread, and so
    it effectively suffered a budget cut.  This results in
    slower [1;31mtime[m to backup completion, and, if the change
    rate is high enough, can result in failure to backup
    as the Backup log buffer fill rate is higher than the
    achievable write rate.
    
    Solution
    
    This patch adds a new cluster configuration parameter :
    
    BackupDiskWriteSpeedPct
    
    This parameter defaults to 50(%) and can be set between
    0(%) and 90(%).
    
    When a Backup starts, the configured percentage of the
    node's maximum write rate budget will be reserved prior
    to sharing out the remainder of the budget amongst LDM
    threads for LCP.
    
    The LDM thread running the backup will receive the whole
    write rate budget for the Backup, plus its (reduced) share
    of the write rate budget for LCP.
    
    This increased budget makes the disk write rate budget
    behave in a similar way to releases < 7.4.
    
    Additionally, a new node log message has been added which
    appears at the end of a Backup and indicates the high-water-mark
    usage of the Backup log buffer.  This can be an aid to efficiently
    configuring this parameter.
    
    Notes :
    The LDM thread with increased 'budget' is still free to
    assign the budget to LCP/Backup scan/Backup log on a
    first-come-first-served (FCFS) basis, so the bandwidth
    is not guaranteed.
    
    Reducing the budget available to LCP on the other LDM
    threads will slow the LCP for the duration of the backup.
    This can affect the amount of Redo and Undo log space
    needed.
    
    A separate bug where each LDM thread reported max speed
    changes separately has also been fixed.
    
    Example :
    
    Max write rate = 20MB/s
    Num LDMs = 4
    
    Normal case (no backup):
    
    Each LDM has a Max write rate of 20/4 = 5MB/s
    
    Backup case
    
    Node backup budget = 50% of 20MB = 10MB/s
    Node LCP budget = 20 - 10 = 10MB/s
    Per-LDM LCP budget share = 10/4 = 2.5MB/s
    
    Backup LDM thread budget : 10 + 2.5 = 12.5MB/s
    Other LDM threads budget : 2.5MB/s
    
    Total budget = 12.5 + 2.5 + 2.5 + 2.5 = 20MB/s
    
    Notes :
    
    - 50% default gives similar behavior to previous releases
    - 0% gives current behaviour
    - Increased budget is not guaranteed for Backup log - similar
    to previous releases.

[33mcommit 6242e22c102a013917a05fdc7601a0f5b70485e5[m
Author: Craig L Russell <craig.russell@oracle.com>
Date:   Sun Jul 26 20:05:50 2015 -0700

    Disable [1;31mtime[mstamp test that randomly fails with three hour [1;31mtime[m difference

[33mcommit 0123bf2ab80c5830262dc8462409469cdcab8709[m
Author: Maitrayi Sabaratnam <maitrayi.sabaratnam@oracle.com>
Date:   Wed Jul 22 16:20:20 2015 +0200

    Increase poll [1;31mtime[mout to see if it helps 'test_event -n Apiv2-check_event_queue_cleared' pass on ndb07.

[33mcommit a3b2a861b431967e17a09ebca7a8d62a7f1570b1[m
Author: Craig L Russell <craig.russell@oracle.com>
Date:   Wed Jul 15 08:20:38 2015 -0700

    Improve clusterj schema definition for [1;31mtime[mstamp types
    
    schema.sql
      change column definition for [1;31mtime[mstamp types to include explicit default
      without a default bad things result:
        the first [1;31mtime[mstamp column
          defaults to current_[1;31mtime[mstamp and on update current_[1;31mtime[mstamp
        subsequent [1;31mtime[mstamp columns
          default to 0 (bad default for strict sql mode)
      add copyright notice
    
    AbstractClusterJTest
      accommodate change to copyright notice

[33mcommit 206b7bdbc114e7505fb52d8349a4433be22caf48[m
Merge: 8358d59e0ed 7d8937daf6f
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Jul 13 19:17:19 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      BUG#21389101 ST_GEOMFROMGEOJSON: STACK OVERFLOW IN RAPIDJSON::GENERICREADER
      Bug#21383284: ASSERTION IN SELECT_LEX::SETUP_CONDS
      BUG#21303289  Removed sqlbench leftover in deb platform pkg src
      BUG#21434004   UBUNTU 15.04 REPO PACKAGES DO NOT CONTAIN ESSENTIAL SCRIPT LIKE MYSQLD_SAFE list of files being re-installed in server pkg: +usr/bin/mysqlbinlog +usr/bin/mysqld_multi +usr/bin/mysqld_safe
      Remove MCP_GLOBAL_SCHEMA_LOCK patch
      Fix syntax error in ndbinfo_sql.cpp
      Fixed mysql_ssl_rsa_setup test failing on Windows after pushing bug fix for bug#21025377
      BUG#21280816 CONNECTION PERFORMANCE REGRESSION TEST HANGS SYSBENCH
      Keep ndbinfo_sql.ccp in sync with mysql_system_tables.sql
      Remove unintentional change in variables-big.test
      Bug #20168526 YASSL: CORRUPT SSL-KEY CRASHES CLIENT
      Version change in d/changelog for DEB pkg src 5.7.9+ are non-rc releases
      - Bug#21407023: DISABLING AHI SHOULD AVOID TAKING AHI LATCH   Currently if AHI is disabled check for it was protected by AHI latch which   caused latch overhead even though the feature is not adding any value.
      Bug#21429471 - COMMUNITY/COMMERCIAL EL7 UPDATE FAILING WHEN MARIADB-BENCH.X86_64 INSTALLED
      Bug #20728894: MEMORY LEAK IN ADD_DERIVED_KEY()
      Bug #21056907: CONTENTS OF NOT REQUESTED CHAR/VARCHAR                COLUMN ARE REVEALED
      Bug #20777016: DELETE CHECKS PRIVILEGES ON THE WRONG                DATABASE WHEN USING TABLE ALIASES
      Bug #18636874 PASSWORD VALIDATE PLUGIN: DICTIONARY CHECK MISBEHAVES WITH GOOD HEX INPUT
      WL#7254 Audit API extensions
      Bug#21374104 SETUP_TIMERS INITIALIZATION ASSUMES CYCLE TIMER IS ALWAYS AVAILABLE
      Bug #20087571: 5.7 EASILY HITS ERROR 1436 (HY000): THREAD STACK OVERRUN ERRORS ON MANY EXPR'S
      Bug#21383896 DECIMAL FIELD TAKES IN VALUES FROM OTHER FIELDS
      Bug#21153489 VALGRIND ERRORS IN ITEM_BOOL_FUNC2::IS_NULL LEAD TO CRASH LATER
      Fix syntax errors in 16node-tests.txt and upgrade-tests.txt
      Bug#21337139 ATRT SILENTLY STOPS TESTING AT FIRST SYNTAX ERROR IN TEST CASE FILE
      Fix a compilation error after bc098885
      Bug#21338012 MTR MANUAL-GDB OPTION DOES NOT WORK
      Bug #21280801: VERSION TOKEN LOCKING DOES NOT WORK
      BUG#21421471 LICENSE HEADERS MISSING IN FILES
      Bug#21300774 ASSERT `!INIT_FTFUNCS(THD, SELECT_LEX)` IN JOIN::RESET AT SQL/SQL_SELECT.CC:874
      Bug#21300774 ASSERT `!INIT_FTFUNCS(THD, SELECT_LEX)` IN JOIN::RESET AT SQL/SQL_SELECT.CC:874
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      BUG#20074353 HANDLE_FATAL_SIGNAL (SIG=11) IN MY_B_WRITE | MYSYS/MF_IOCACHE.C:1597
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      Addendum 2 to bug #21034322: removed the max test due to it being different for different OSes
      Follow up fix for WL#8149 change, fix create_thd() issue and test mismatches
      Merge WL#8149 related worklogs to mysql-trunk
      Bug#21271736 UNITTEST UT0CRC32-T HANGS ON SOLARIS 10 SPARC
      Bug#21381060 A "CASE WHEN" EXPRESSION WITH NULL AND AN UNSIGNED TYPE GIVES A SIGNED RESULT
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Remove non experimental test.
      Bug#18949282 I_MAIN.MYSQL_CLIENT_TEST FAILED AT LINE 43, COMMAND $I_M_C_T
      Configure smaller redo log for test ndb.ndb_backup_rate.
      Updating the test case ndb_addnode_restart* :  The autotest testSystemRestart had an additional restart loop  in runAddNodesAndRestart function, which is not needed as there  is no change in the configuration of the cluster.  Removed that and updated the name of the funcction and added few  comments to explain the proper setup of the testcase
      Fix for WL#7763
      WL#7763, remove use of inet_ntoa from ndb parts
      Post-push test fix for Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      Bug#17493646 NDB: CALL TO MY_ERROR() LACKS ERROR CODE AND ERROR STRING ARGUMENTS
      Bug#21352763 FLEXASYNC SEGFAULTS IF FAILED TO CREATE TABLES
      BUG#21297407: Fix to ensure sending CONTINUEB with proper variables in dropTable_wait_usage
      Pushing BUG#21297407 revealed an uninited variable in Fragrecord in DBLQH (lcp_frag_ord_state, was set to LCP_QUEUED == 0 in most cases which led to crash if drop table happened before LCP had [1;31mtime[m to execute
      BUG#20981491: Fix resource issues for NR, LCP andb Backup with regard to scan numbers, BUG#21362758: Crash with holding LocalDLFifoList context over call EXECUTE_DIRECT(NEXT_SCANCONF), BUG#21370839: Ensure also ACC scans are queued in a proper manner, previous push only added test case to autotest
      BUG#20981491: Fix resource issues for NR, LCP andb Backup with regard to scan numbers, BUG#21362758: Crash with holding LocalDLFifoList context over call EXECUTE_DIRECT(NEXT_SCANCONF), BUG#21370839: Ensure also ACC scans are queued in a proper manner
      BUG#20993380: (Also BUG#69994 in community bugs), ensured that node recovery and LCP scans can continue even if user has used up all resources for user level transactions, reserved operation records and segments for necessary things during LCP and NR scans
      Fix test case testRedo -n RedoFull
      Fix testRedo -n RedoFull test case
      BUG#21297407: Speed up drop table
      Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Raise version number after cloning 7.1.36
      Raise version number after cloning 7.3.10
      Raise version number after cloning 7.4.7
      Raise version number after cloning 7.2.21
      Fixed syntax errors in daily-basic-tests.txt
      Implement required methods in clusterj-openjpa
      Bug#20504741 Improve clusterj release of byte buffers by adding a user method session.release
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7570 Remove ifdefs which are not necessary since trunk has it all
      Bug #20592110         CLUSTER CIRCULAR REPLICATION WITH IGNORE_SERVER_IDS() BROKEN BY ANONYMOUS_GTIDS
      revert change to mysql-test-run
      Bug #21326540         NDB_JOIN_PUSHDOWN TESTS UNSTABLE EXECUTE_COUNT
      Remove obsolete ifdef
      Add comment re. valgrind
      WL#6815 Adapt MySQL Cluster to 5.7
      Revert "WL#6815 Adapt MySQL Cluster to 5.7"
      Removed extra blank line in ATRT test scripts preventing tests to start (Due to ATRT bug)
      Bug #17878183       NDB CONTINUOUSLY REBOOTING DUE TO FILE NOT FOUND (DBLQH:
      Bug#17493646 NDB: CALL TO MY_ERROR() LACKS ERROR CODE AND ERROR STRING ARGUMENTS
      Increase [1;31mtime[mout for ATRT test
      Increase [1;31mtime[mout for ATRT test
      BUG#20904721, WL#8525: Fix of part9, used internal TUP pointer instead of LQH pointer when calling LQH function directly, leads to both wrong handling and some[1;31mtime[ms even a crash when index is not a used scan pointer
      Apply pollEvent_v4.patch from Ole John
      restore new scheduler & multiwait fix to bug branch
      If memcached crashes, mysql-test-run should not restart it.
      On misc. errors, print workitem to debug log
      always compile ndb memcache with DEBUG_OUTPUT
      More unified error handling
      New record_ndb_error() function where error logger keeps statistics but caller is resposnsible for writing to log file. Direct error messages to the debug log if enabled.
      The table scan code where NDB Memcache reads it configuration tables was written poorly, and could cause memcached to crash during configuration.
      revise debug messages in new scheduler
      switch default scheduler to Trondheim
      always compile ndb memcache with DEBUG_OUTPUT
      More unified error handling
      New record_ndb_error() function where error logger keeps statistics but caller is resposnsible for writing to log file. Direct error messages to the debug log if enabled.
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#11759461 NDB_CONFIG --XML --CONFIGINFO: VARIOUS UPDATES TO PARAMETERS LISTED
      Bug#11760628 DEPRECATE EXECUTEONCOMPUTER
      Bug #21270509         FAULTY COMMENT DESCRIBING NDB_MGM_NODE_STATE.CONNECT_ADDRESS IN MGMAPI.H
      Bug #21270425         MGMAPI.H SPELLING ERROR
      Bug#20617891: NDB : SUSPICIOUS HANDLING OF SIGNAL-WAIT TIMEOUT IN NDBAPI
      read configuration in a single consistent transaction
      The table scan code where NDB Memcache reads it configuration tables was written poorly, and could cause memcached to crash during configuration.
      Revert "Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000"
      Revert "Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000"
      Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      BUG#20904721: Fix for a number of asserts that assumed interpreted mode for all scans
      BUG#20727343: Fix failing ndb_dd_initial_lg test case, minor initialisation issue
      reapply bugfix in this branch. do not push this change to 7.4
      move another message from debug to detail level
      move another message from debug to detail level
      WL#8525: Part 11, don't use interpreted execution for LCPs and Backups since it is a waste of CPU resources
      BUG#20904721: Part 9: Implementing the adaptive LCP speed using bounded delay concepts and A-level signals
      more safety when Ndb::startTransaction() fails
      more safety when Ndb::startTransaction() fails
      add a more detailed debug output level to ndb memcache
      Anticipate SERVER_ERROR responses in My::Memcache.pm
      Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      Test case for Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      induce memcached to flush its log file at end of mtr testing
      BUG#20727343: Fix problems in UNDO log applier when changing log files
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Revert of prev push for bug#20957068
      Fix for Bug#20957068:
      Post merge fixes (mysql-5.6.25 via mysql-5.6-cluster-7.3 into mysql-5.6-cluster-7.4)
      Port commit to MySQL Cluster 7.3
      Port of commit to MySQL Cluster 7.3
      Port of commit to MySQL Cluster 7.3
      Port commit to MySQL Cluster 7.3
      some additional debug output re. online reconfiguration
      Test: temporarily revert recent changes
      Bug#20730053: BACKPORT BUG#19770858 TO 5.1
      Test: temporarily revert recent changes
      Bug#20734434 - SPELLING ERROR \"EMDEDDED\" IN RPM SPEC FILES
      Bug#20788853 MUTEX ISSUE IN SQL/SQL_SHOW.CC RESULTING IN SIG6. SOURCE LIKELY
      Bug#18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Bug#21270190 REMOVE UNUSED AND DANGEROUS NDBHOST_GETHOSTNAME()
      Fix compiler warnings due to hidden inherited virtual and release-unused variables.
      Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Backport of Part 2 (of 2) of fix for Bug#18390321 to 7.2 & 7.3
      bug#17638548 Try to address test failures from previous push
      Reenable usage of send threads in MTR tests.
      Part2 (of 2) fix for Bug#18390321
      Temporarily change default MTR test config to use worker thread sending (No send threads) in order to get some regression test coverage of part1 patch for bug 18390321
      Bug #17878183         NDB CONTINUOUSLY REBOOTING DUE TO FILE NOT FOUND (DBLQH: CAUSED BY ERROR 2341)
      Part1 (of 2): Fix for Bug#18390321
      bug#17638548 In NDB Memcache 7.4 use 7.3 Scheduler by default
      bug#17638548 : reset "woken" state after wakeups
      Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Fix failing ATRT testcases:
      Increase [1;31mtime[mout value for several failing 'testNodeRestart ... DD' tests.
      Fix failing testcase 'testNodeRestart -n GcpStop T1 --loops=1' :
      Added more printout to testcase 'testBasic -n Bug54986 D2' in order to aid in understanding why / where this test fails.
      Increase [1;31mtime[mout for  'testNodeRestart -n Bug27003 T1' from 1800 -> 3600sec.
      Moved unstable 'basic' tests to 'devel'.
      Fix compiler warnings in patch for bug#21185585:
      fix bug in cmakelists from previous push
      Convert test_workqueue into a TAP test
      Fix for bug#21185585
      ndb memcache: recently in CLUB testing of ndb memcache suite, 7.4 consistently passes but 7.3 has many failures.  This commit swaps the default schedulers in 7.3 and 7.4 to see if that leads to any change in the pattern of test results.
      ndb memcache: change default scheduler in 7.3
      bug#21067283 Fix inconsistent space calculations in NdbRecord
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      BUG#18234170 Foreign Constraints are lost from NDB Tables during truncate
      Bug#21184102 PATCH FOR BUG#16890703 MYSQLD STUCK IN OPN TABLES ..., LOST IN 7.3 AND UPWARD Added error check for missing database directory, added testcase
      BUG#18234170 Foreign Constraints are lost from NDB Tables during truncate
      WL#8648 NDB_SHARE lifecycle improvements
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7578 Refactor schema distribution code
      WL#8648 NDB_SHARE lifecycle improvements
      Bug#21141495 NDB_MGMD USES 90% CPU
      Remove global forward declaration of Ndb_fk_data
      BUG#20095208: Fix to make portlib not dependent of ndbgeneral
      Removed compiler warning
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Only use C++ ABI functionality if libstdc++ is being linked. Otherwise resort to protect the allocation/deallocation of the static objects using the existing connection mutex.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      Patch for bug#21109605
      Removed compiler warning
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Only use C++ ABI functionality if libstdc++ is being linked. Otherwise resort to protect the allocation/deallocation of the static objects using the existing connection mutex.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      WL#8525: BUG#20904721: Part6: Improve performance of checksum calculations, remove unnecessary ones and simplify bit toggling ones. Also solves BUG#20980229 that ensures that also header bits are included in checksum calculation.
      BUG#20904721: Fix LCP processing with heavy insert activity, part 2
      Improve multi-thread use of charsetDecoder and charsetEncoder in clusterj Utility   charsetDecoder is used only in Decimal decoding   charsetEncoder is used only in Decimal encoding   charsetDecoder and charsetEncoder are not thread-safe   use charset.decode for decoding   use charset.newEncoder().encode for encoding   avoid synchronization
      bug#20095208 - UNABLE TO STORE FRAGMENT DURING LCP. NDBFS ERROR: 2812 - DBLQH (LINE: 14305)
      bug#20095208 - UNABLE TO STORE FRAGMENT DURING LCP. NDBFS ERROR: 2812 - DBLQH (LINE: 14305)
      Bug#18753887 MYSQLD STOPPED WRITING TO BINARY LOG Modifies pollEvents to return latest_GCI as NDB_FAILURE_GCI (~(Uint64)0) in case a cluster failure has been detected. An internal flag is set in NdbEventBuffer::report_node_failure_completed and the flag is reset when the next SUB_GCP_COMPLETE_REP signal is received. Test case StallingSubscriber is extended to verify that NDB_FAILURE_GCI is returned and that polling of events is resumed after the cluster is connected again and new epochs are received.
      Bug#18753887 MYSQLD STOPPED WRITING TO BINARY LOG     Modifies pollEvents to return latest_GCI as NDB_FAILURE_GCI (~(Uint64)0)     in case a cluster failure has been detected. An internal flag is set     in NdbEventBuffer::report_node_failure_completed and the flag is     reset when the next SUB_GCP_COMPLETE_REP signal is received.     Function Ndb::isExpectingHigherQueuedEpochs is added to be used together     with pollEvents2 that checks if cluster has disconnected due to failure     causing no more events to be received.     Test case StallingSubscriber is extended to verify that NDB_FAILURE_GCI     is returned and that polling of events is resumed after the cluster     is connected again and new epochs are received.
      BUG#20904721: Part 8: Fixing the NDB scheduler to work with Bounded delay signals
      Revert last merge
      Fix multi-thread use of charsetDecoder in clusterj Utility   charsetDecoder is used only in Decimal decoding   charsetDecoder is not thread-safe
      Follow up testcase fix for MCP_BUG20701918
      MCP_BUG20701918  create-old-temporals MySQLD option
      BUG#20904721: Fix of previous push
      Fix regression in debug build caused by fix for bug#20408733.
      WL#8525: BUG#20904721: Part 4, write up description of local LCP protocol and how to handle overload situations, increase to prio level A in some cases. Also standardise naming on END_LCPREQ and END_LCPCONF and remove all usages of END_LCP_REQ and END_LCP_CONF.
      BUG#20904721: WL#8525: Part 3, use prefetch to speed up scan processing for LCP scans and also other full table scans, such as node recovery scans and user level full table scans
      WL#8525: BUG#20904721: Part 7: Ensure it's not so easy to misconfigure LCPs and Backups
      BUG#21049554: Fix OM_SYNC flag to work on all platforms, not only those that support the O_SYNC flag
      WL#8525, BUG#20904721: Part1: Avoid LCP watchdog crash when scanning many pages with LCP_SKIP records
      Fix annoying compiler warnings on Mac OS X
      Fix white space warning in clusterj
      Bug #20504741 Bug #20695155 Improve Clusterj handling of ByteBuffers to reduce direct memory footprint Fix Clusterj incompatibility with Java 7
      Backport My::Memcache.pm improvements from 7.3 This will be null-merged up
      Eliminate some compiler warnings in 3rd party memcached code for NDB Memcache This fix includes both reducing the gcc warning config in CMakeLists.txt and changing two memcached source files. No Oracle copyright is added to the changed 3rd party files.
      Clusterj Trivial bug fix for error displays
      Bug#21055643 REDUCE DEBUG PRINTOUT DURING A GAP AND IMPROVE
      Properly include m_string.h when using my_stpcpy
      Improve comments
      Cache the key_length in NDB_SHARE_KEY
      Provide type safety by using the opaque NDB_SHARE_KEY* type
      Use NDB_SHARE::key_string() instead of direct access to key member
      Move NDB_SHARE::key_length into NDB_SHARE_KEY
      Rewrite the lgive share leak name  to also use NDB_SHARE::create_key
      Move all NDB_SHARE key initialization into NDB_SHARE::creat_key()
      Fix some compiler warnings from memcached sources
      My::Memcache.pm: handle case where the last read before a [1;31mtime[mout completed the read buffer. Open a new memcache connection when trying to fetch server error stats.
      Save the prepared key in Ndb_schema_dist_data
      Rename ndbcluster_prepare_rename_share to NDB_SHARE::create_key
      Remove NDB_SHARE::mem_root and instead use my_malloc for dynamic strings
      Change ndcluster_prepare_rename_share to return newly allocated key
      Remove NDB_SHARE::old_names
      Pass the new_key as argument to ndbcluster_rename_share
      Skip ndb_ddl tests with embeddes server
      Change to allocate Ndb_CONFLICT_FN_SHARE bith my_malloc
      Make the NDB_CONFLICT_FN_SHARE an opaque type for users of ndb_share.h
      Remove useless typedefs
      Remove backwards jump into a hoop on fire
      bug#18411034: Remove an unnecessary if-statement
      Print stats for the MEM_ROOT in Ndb_event_data
      Increased the undolog file size from 256MB to 512MB and FragmentLogFileSize from 64MB to 128MB.
      bug#18411034: Assertion gci_ops && (gci == gci_ops->m_gci) failed
      bug#18411034: Assertion gci_ops && (gci == gci_ops->m_gci) failed
      bug#20553313, bug#20707694 - fix index stats query delays
      Bug#20479917 REMOVE MCP_BUG16021021
      Bug#21026199  RANDOM WARNING ORDER NDB_ONE_FRAGMENT
      Addendum to the fix for bug #20681412:
      post push minor test fix for bug:19887143
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug#20234681 HA_NDBCLUSTER USAGE OF FIND_FILES LEAK MEMORY INTO (UNRELEASED) MEM_ROOT
      Move new drop_table test to suite ndbcluster
      Bug#20728189 DROP TABLE SEGFAULTS IF FIRST STATEMENT ON A NEW CONNECTION
      Adding force_restart option to ndb_addnode_restart_setup.inc To force restart servers during retries.
      Bug#20782580: NDB REDO OVERLOAD: ABORT QUEUING REQUESTS IF OUT OF LOG SPACE
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      Added 5 autotest testcases to test node restart with following scenarios. 1. Restarting one node at a [1;31mtime[m. 2. killing two node of different groups and starting them with and without initial option. 3. Restarting a node which doesn't belongs to node group 0, and checking that it is not associated with node group 0 after restart. 4. killing four node of different groups and starting them with and without initial option. 5. Killing only the master nodes one by one and starting them without initial option.
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      Bug#11762750 TABLE NDBINFO.CONFIG_PARAMS SHOULD BE READ-ONLY (FOR NOW)
      Bug#16731538 MYSQLD CRITICAL FAILURE DURING ORDERED SELECT FROM NDBINFO.CLUSTER_OPERATIONS
      BUG#20075747 RND_INIT() ON AN OPEN SCAN IS USED TO REPOSITION THE CURSOR
      WL#7575 Remove ndbinfo's usage of other engine
      My::Memcache -- longer write [1;31mtime[mot
      My::Memcache client, fix bug in read() where desired length is 0
      Remove include/ndb_default_cluster.inc
      WL#8165 Use new records per key interface in NDB
      Fix for Bug#20954804
      Fix for Bug#20954804
      Bug#20782580: NDB REDO OVERLOAD: ABORT QUEUING REQUESTS IF OUT OF LOG SPACE
      Fix a possible crash in AutoTest when an ordered scan encounter error 4008, scan [1;31mtime[mout. One such testcase is 'testScan -n ScanRead4880'
      Bug#11760802 SEVERAL MGMAPI FUNCTIONS RETURN 0(SUCCESS) WHEN NO HANDLE OR NOT CONNECTED
      Refactoring of create partitioned table
      Revert unintentional change
      My::Memcache - do not close connection before attempting to fetch server error statistics
      MTR ndb_memcache more tweaks to [1;31mtime[mout handling
      Bug#20814396 PB2 IS SECRET ABOUT WHAT UNIT TESTS IT RUN
      Revert "Remove MCP_GLOBAL_SCHEMA_LOCK patch"
      Revert "Remove MCP_GLOBAL_SCHEMA_LOCK patch"
      Fixing the following test failures by synch'ing the error injection and the test checking the error:
      increase [1;31mtime[mouts
      Better failure handling in My::Memcache.pm
      Provide more information when an ndb_memcache test fails
      BUG#20887445: Fix so that cpuset is working in ThreadConfig, previously node log proclaimed it was working where it wasn't really working
      Fix ndbapi example programs to work on Mac OS X Yosemite
      BUG#20887445: Fix so that cpuset is working in ThreadConfig, previously node log proclaimed it was working where it wasn't really working
      Fix ndbapi example programs to work on Mac OS X Yosemite
      Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED
      Bug#20729091 - ASSERTION TYPE < NDBDICTIONARY::EVENT::TE_EMPTY FAILED
      Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS
      Bug#20762291 - POLLEVENTS2() WILL RETURN ERROR (-1) IF GIVEN WAITTIME AMILLISECONDS IS NEGATIVE
      Attempt to avoid spurious test failures. Increase read [1;31mtime[mout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Attempt to avoid spurious test failures. Increase read [1;31mtime[mout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Attempt to avoid spurious test failures. Increase read [1;31mtime[mout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Fix testIndex seg fault where index not exists when calling indexReadRecords, added check for NULL return
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      MTR ndb_memcache : still better [1;31mtime[mout handling & more verbose reporting during test runs
      Revert to older scheduler as default in 7.4 for testing
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Remove MCP_WIX
      Handle server timouts and disconnects in MTR's My::Memcache client
      Work on My::Memcache to handle server disconnects and [1;31mtime[mouts
      Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS Bug#20561446 NDB : NDBEVENTBUFFER NEEDS MORE THREADING PROTECTION
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      fix
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      NDB Memcache external_values fixes: The external_values test had a Perl bug using "==" instead of "eq", causing tests to pass even when the server produced errant responses. This patch fixes the test case and also fixes the revealed errant behavior in memcached.
      Remove MCP_WIX
      Remove MCP_WIX
      Remove MCP_WIX
      Do not change default scheduler in 7.2
      NDB Memcache: use pollEvents2() in reconfiguration waiter thread
      bug#17638548: NDB Memcached uses excessive CPU. This patch works around the underlying issue by defaulting to a new scheduler which does not make use of the NDB MultiWait APIs.
      NDB Memcached: enable "Trondheim" scheduler in 7.2
      one more solaris fix
      Fix for compiler error on Solaris
      Adapt 73 Scheduler to new online configuration manager
      one more solaris fix
      Fix for compiler error on Solaris
      Fixup from previous merge
      NDB Memcache: backport improvements into 7.2
      Backport misc. NDB memcache changes from 7.3 to 7.2
      Raise version number after cloning 7.2.20
      Raise version number after cloning 7.3.9
      Raise version number after cloning 7.4.6
      Raise version number after cloning 7.1.35
      Attempt better "htonll" portability in NDB memcache code
      BUG#20665205, fixed a part where we skipped reading of page 0 which was required to do in last file, also due to file 0, page 0 writes we can trust this page to be correct
      Add ndb specific changes for Bug#20094067: BACKPORT BUG#19683834 TO 5.5 AND 5.6
      Added ndb testcase for bug#19856162.
      Post-push fix for bug#19856162.
      Merge into cluster: WL#8354 BACKPORT DIGEST IMPROVEMENTS TO MYSQL 5.6
      Revert "Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS"
      Revert "Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS"
      Revert "Bug#20729091 - ASSERTION `TYPE < NDBDICTIONARY::EVENT::TE_EMPTY' FAILED."
      Revert "Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED"
      BUG#20665205: Fix REDO log issue
      Added autotest testcases to test addnode and restart.
      Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED
      Bug#20729091 - ASSERTION `TYPE < NDBDICTIONARY::EVENT::TE_EMPTY' FAILED.
      Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS
      Bug 20762291 - POLLEVENTS2() WILL RETURN ERROR (-1) IF GIVEN WAITTIME AMILLISECONDS IS NEGATIVE
      Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS Bug#20561446 NDB : NDBEVENTBUFFER NEEDS MORE THREADING PROTECTION
      Remove MCP_WIX
      Resurrect unintentionally remove disabled.def file

[33mcommit 949178f21272f27700d2aa0839d6c36ef7487fe4[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Jun 25 14:12:54 2015 +0300

    Don't delete index stats when dropping the index
    
    This commit reverts parts of 4e4232b.
    
    This is because, in InnoDB, when dropping an index, its pages are left
    in the buffer pool and eventually evicted via the LRU mechanism when
    they are not accessed for a long [1;31mtime[m. This eviction will try to
    decrement the number of pages for a given index and this, if the entry
    in the stats is missing, will lead to negative results. For example:
    
    (index id = 123, n pages in buffer pool = 100)
    drop index, delete the (123, 100) tuple
    some of the 100 pages gets evicted and calls dec(123), which results
    in (123, -1)
    
    In the old behavior some entries with negative values will remain
    forever in the hash, unnecessary taking space and CPU cycles during
    search for other entries.
    
    WL#7170 InnoDB buffer estimates for tables and indexes

[33mcommit fc54070f0db89126a69c7aa1930dbeb63934ace7[m
Merge: 9ab2f7b5ed2 85dae03c32c
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jun 24 10:29:14 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Change the default value of innodb_sync_debug from TRUE to FALSE, to reduce the execute [1;31mtime[m of MTR when default.
      Bug #20763179 SEGV WHEN CREATE TABLESPACE IS EXECUTED IN READ ONLY MODE
      BUG #20980691 - MTR FAILS WITH --PARALLEL IF VARDIR IS 81 CHARACTERS LONG
      Bug#21087159 : AUTO-GENERATED SSL CERTS HAVE NO CN
      BUG#20310212 PARTITION DDL- CRASH AFTER THD::NOCHECK_REGISTER_ITEM_
      Bug#20954452  GTID IS NOT RELEASED PROPERLY WHEN PS_PROTOCOL + GTID + BINLOG OFF COMBINATION
      Bug #20748502  ASSERTION `THD->VARIABLES.GTID_NEXT.TYPE== ANONYMOUS_GROUP' FAILED.
      Doxygen cleanup
      Bug#20894024 FIREWALL STILL DEPENDS ON MAX_DIGEST_SIZE OF THE P_S DIGEST
      BUG#18345363: ORDER OF APPLYING MYSQLBINLOG --DATABASE AND --REWRITE-DB IS WRONG BUG#20810442: "USE DATABSE_NAME" STATEMENTS OMITTED BY MYSQLBINLOG --REWRITE-DB OPTION
      Bug#20894024 FIREWALL STILL DEPENDS ON MAX_DIGEST_SIZE OF THE P_S DIGEST
      Bug#21246842: ASAN: MEMORY LEAK IN TEST_WL6587()
      Doxygen cleanup
      Raise version number after tagging 5.1.76
      BUG#20894024 - FIREWALL STILL DEPENDS ON MAX_DIGEST_SIZE OF THE P_S DIGEST
      Doxygen cleanup
      Removed Doxygen warnings in sql_select.cc/.h.
      Doxygen cleanup
      Bug#21300778 FREQUENT FAILURE IN I_INNODB.INNODB_BUG16417635 ON PB2
      Bug#21108296 : --SSL-CIPHER OPTION CAUSES SSL INITIALIZATION FAILURE
      Raise version number after cloning 5.5.45
      Raise version number after cloning 5.6.26
      Doxygen cleanup
      BUG#16459136 MYSQLD ON SAME HOST MAYY GET SAME SERVER_UUID
      Added per push tests for mysql-5.7-stage
      Bug#20894024 FIREWALL STILL DEPENDS ON MAX_DIGEST_SIZE OF THE P_S DIGEST
      Doxygen cleanup

[33mcommit d8da6023b6100bd348160187a9eeedd35f1c3898[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Tue Jun 16 10:45:11 2015 +0300

    Bug#21184265 ASSERT AT ALL || TRX_SYS_GET_N_RW_TRX() > 0
    
    This is a regression from the startup refactoring in WL#7488.
    We aim to create the thread for rolling back incomplete transactions
    only if there are any such transactions to roll back.
    
    The assertion some[1;31mtime[ms failed in the recovery steps of the test
    binlog.binlog_group_commit_flush_crash.
    
    The problem appears to be that the XA PREPARE transaction (internally
    created by the binlog) is accounted for in the trx_sys_get_n_rw_trx(),
    which we were checking. We should only consider those incomplete
    transactions that can be rolled back without involving other layers
    (transactions that are not in XA PREPARE state).
    
    In one observed failure, the error log output suggests that the binlog
    subsystem will have issued XA ROLLBACK for the transaction before the
    InnoDB rollback thread starts executing. The count was 1 before the XA
    ROLLBACK, and 0 after it.
    
    trx_sys_need_rollback(): Renamed from trx_sys_get_n_rw_trx(). Do not
    count transactions that are in XA PREPARE state.
    
    trx_sys_t::n_prepared_recovered_trx: Remove. This field was made redundant
    by the fix of
    Bug#20461632 QUERY CACHE IS DISABLED WHEN RECOVERED XA PREPARE
    TRANSACTIONS EXIST
    
    RB: 9306
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit be7d868239226bc8298a00a6602afbd6a27313ee[m
Merge: 2f0663425a1 6885c34d791
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Sat Jun 13 12:53:25 2015 +0200

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            sql/auth/sql_user_table.cc
            sql/item_[1;31mtime[mfunc.cc
            sql/sp.cc
            sql/sql_cache.cc
            sql/sql_class.cc
            sql/sql_partition.cc
            sql/sql_table.cc
            sql/sql_update.cc
            sql/table.cc
            sql/trigger_loader.cc

[33mcommit 87dbde022c53d393f24d181ff00e52eb5e30922c[m
Merge: 112025a48f8 5eef003ae44
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri May 15 10:46:34 2015 +0300

    Merge remote-tracking branch 'local/mysql-trunk' into mysql-trunk-wl7170
    
    * local/mysql-trunk:
      Fix Bug#20783098 INNODB_CHECKSUM_ALGORITHM=CRC32 IS NOT BYTE ORDER AGNOSTIC
      Bug#20819189: ASSERT IF .FRM EXISTS BUT NO PARTITIONED INNODB TABLE.
      Bug#20561087 : REPLACE_USER_TABLE() DOES NOT CHECK ERROR WHEN READING FROM MYSQL.USER
      Bug#20819189: ASSERT IF .FRM EXISTS BUT NO PARTITIONED INNODB TABLE.
      BUG#19706455: RESET MASTER SHOULD RESET GTID STATE AND NOT ERROR OUT WHEN BINLOG IS OFF
      Test suite cleanup
      Some cosmetic changes which had been suggested in the review of wl#2489 but had to wait for wl#5275 and wl#7870 to be pushed.
      Test cleanup
      Bug#21074643: SERVER SETS OPEN_FILES_LIMIT UNCONDITIONALLY
      Fix for build failure after pushing a767e483e9496e8427d50f59dfa4842d4895e08a
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Bug#20896539 - A QUERY DIGEST SOMETIMES CONTAIN BACKTICKS AND SOMETIMES NOT DEPENDING ON CS
      Post push cleanup
      WL#8216: Deprecate and remove the sync_frm sysvar
      PB2 failures (valgrind and result mismatch) fixes.
      Follow up patch of bug20734998 for fixing Werror failure.
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20762557, Bug#20697533 : Disabled following tests since they fail very often on PB2: main.explain_for_connection_rqg_json main.explain_for_connection_rqg_trad rpl.rpl_perfschema_applier_status
      Test commit
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      WL#8186: Deprecate conversion of pre MySQL 5.1 encoded database names
      Bug#20980885: ENSURE THAT START/STOP GROUP REPLICATION ALWAYS REQUIRE SUPER PRIVILEGE
      Partial backport from mysql-trunk to mysql.5.7 of Bug#21041451: ENABLE AND FIX ADDITONAL WARNINGS REPORTED BY CLANG in order to fix Clang 3.4 warnings in release build. No new warning options are added in the backport.
      Bug#21074358: SOME NEW 5.7 SOURCE FILES ARE D0S FORMATTED
      Bug #17818062       PERFORMANCE SCHEMA, ISSUE WITH UPPERCASE ROUTINES NAMES, PERFSCHEMA.MISC FAILS
      Bug #17818062         PERFORMANCE SCHEMA, ISSUE WITH UPPERCASE ROUTINES NAMES, PERFSCHEMA.MISC FAILS
      Bug#17832047: Crash in calculate_materialization_costs
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      Added openssl multithreading to client.
      Added openssl multithreading to client.
      Bug#20721087 UPGRADE TO BOOST 1.58.0
      Bug#20734998 FAILING ASSERTION: !CURSOR->INDEX->IS_COMMITTED()
      Bug #21047137 REMOVE -GCC FROM NAME OF SOLARIS PACKAGES/TARBALLS
      Bug#19316063: MAKE MTS WORK WITH RELAY_LOG_RECOVERY=1 WHEN GTID IS ENABLED
      Bug#21062842 : Made i_main.costmodel_plan change experimental.
      Bug# 19823076 : READ OF FREED MEMORY IN MY_MB_WC_SJIS WITH                 SOUNDS LIKE OPERATOR IN SUBQUERY
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      BUG#20743468: ASSERTION `OLD_VALUE >= 1' FAILED. | ABORT (SIG=6) IN GTID_STATE::END_ANONYMOUS_ BUG#20748502: ASSERTION `THD->VARIABLES.GTID_NEXT.TYPE== ANONYMOUS_GROUP' FAILED.
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      WL#7589: Updated the README file.
      Bug#21041451: ENABLE AND FIX ADDITONAL WARNINGS REPORTED BY CLANG
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20753620: DBUG: DICT_LOAD_FOREIGN, HA_INNOPART::CHECK, HA_INNOPART::CREATE_NEW_PARTITION
      Silence rpl.rpl_xa_survive_crash_debug in Valgrind
      Bug#21021894 : UNHELPFUL ERROR FOR MYSQL_SSL_RSA_SETUP WHEN DATADIR DOESN'T EXIST
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      Bug#21021754 - OPTION FOR MAX_STATEMENT_TIME IS MISSING
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      BUG #21063087 - MTR SHOULD PASS --INNODB_UNDO_TABLESPACES VARIABLE AT BOOTSTRAP
      BUG#20921940 DEBUG ONLY-CODE MAY HAVE SIDE EFFECTS IN HA_INNOBASE::
      - Bug#21046781: WHILE TRUNCATE UNDO-TABLESPACE FILE COULD BE CLOSED IN BACKGROUND
      BUG#21041449 ASSERT IN I_INNODB.INNODB_BUG16244691
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug #20445525 ADD A CONSISTENCY CHECK AGAINST DB_TRX_ID BEING IN THE FUTURE
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20835095 CRASH AT CREATE_REF_FOR_KEY IN SQL/SQL_SELECT.CC
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20980217 - TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE DOES NOT SHOW CORRECT INDEX NAMES
      Bug#20923066: SSL AND RSA KEY MATERIAL EXPIRATION SHOULD BE EXTENDED
      Corrected validate_password_strength and export_set functions
      Post push fix for BUG#18731252
      Bug#21046582 GEOMETRYCOLLECTION COLUMNS CAN'T STORE SUBTYPES
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      Fix for PB2 test failure.
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      - Bug#21053486: TRUNCATE_RECOVER FAILING IN MYSQL-TRUNK
      Bug#21021894 : UNHELPFUL ERROR FOR MYSQL_SSL_RSA_SETUP WHEN DATADIR DOESN'T EXIST
      Bug#20705648 - max_statement_[1;31mtime[m leaks memory on windows Bug#20705642 - max_statement_[1;31mtime[m: assertion failed: pending || thd_[1;31mtime[mr->thread_id
      Bug#20996273 ALTER USER REWRITE CAUSES DIFFERENCES ON SLAVE
      Fix to remove data dir reference
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Bug#20987568 - INCREASE STOP TIMEOUT OF COMMUNITY RPM SHUTDOWN SCRIPT /ETC/INIT.D/MYSQLD
      - Bug#21046968 : POSSIBLE RACE IN THE TRUNCATE CODE
      WL#7899: Add the tests that were accidentally omitted.
      WL#7899: InnoDB: Map compressed temporary tables to uncompressed
      Bug#20918881 CRASH WITH CENTROID - INVALID FREE
      Bug#20854952 SHOW GLOBAL VARIABLES RETURN WARNING ABOUT SQL_LOG_BIN BEING DEPRECATED
      Bug#21021670 - MISLEADING WARNING WHEN PER-QUERY STATEMENT TIME IS EXCEEDED
      Bug#20854952 SHOW GLOBAL VARIABLES RETURN WARNING ABOUT SQL_LOG_BIN BEING DEPRECATED
      Bug #20692556 : PREPARED STATEMENTS DO NOT TRACK STATUS LIKE STATISTICS
      - Bug#20023425: EMBEDDED SERVER FAILS TO BOOTSTRAP/START UP WITH   INNODB_UNDO_TABLESPACES=2
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Bug #20376498: MAX_ALLOWED_PACKET ERROR DESTROYS ORIGINAL               DATA
      BUG#20753463 HANDLE_FATAL_SIGNAL (SIG=11) IN __STRLEN_SSE2_PMINUB ON              CHANGE MASTER
      Bug#20507804 FAILING ASSERTION: TRX->READ_ONLY && TRX->AUTO_COMMIT && TRX->ISOLATION_LEVEL==1.
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      BUG#18731252 SLAVES WITH SAME SERVER_ID / SERVER_UUID COMPETE FOR              MASTER CONNECTION
      BUG#20768847 ASSERTION 0 IN HA_INNOBASE::COMMIT_INPLACE_ALTER_TABLE
      Post-push fix for BUG#20470724: SET GTID_PURGED SHOULD NOT ROTATE BINLOG
      Fixed Bug#20145024: WRONG RESULT FOR COUNT DISTINCT QUERY IN DERIVED TABLE
      Bug #20592961  'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381 - post fix
      BUG#20977779 CANNOT IMPORT TABLES CONTAINING PREFIX INDEXES
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Fix to avoid build break
      Bug#20814280 SEVERAL PERFORMANCE SCHEMA UNIT TESTS FAIL
      Bug#20814280 SEVERAL PERFORMANCE SCHEMA UNIT TESTS FAIL
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Test cleanup
      Test cleanup
      BUG#20470724: SET GTID_PURGED SHOULD NOT ROTATE BINLOG
      Bug#20748537 INNODB: FAILING ASSERTION: NODE->PCUR->REL_POS == BTR_PCUR_ON
      BUG#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bugi#20593257 FIREWALL PLUGIN LEAK PINS UNDER SPECIAL CIRCUMSTANCES
      BUG#20949314 PARTITION_HELPER::PH_RND_INIT(BOOL): ASSERTION `0' FAILED
      Fix firewall_qc broken test case when the FIREWALL_PLUGIN variable isn't set. This affected 32bit debian
      Fix firewall_qc broken test case when the FIREWALL_PLUGIN variable isn't set. This affected 32bit debian
      Bug#20963147 DECOUPLE DIGEST SIZE FROM SERVER AND PFS
      Bug #20926253 VALGRIND FAILURE IN INNODB.ALTER_MISSING_TABLESPACE
      - Bug#20023425: EMBEDDED SERVER FAILS TO BOOTSTRAP/START UP WITH   INNODB_UNDO_TABLESPACES=2
      Bug#20963147 DECOUPLE DIGEST SIZE FROM SERVER AND PFS
      Raise version number after cloning 5.6.25
      Raise version number after cloning 5.5.44
      BUG#21023683 FAILURE IN EMBEDDED I_INNODB.INNODB-ALTER
      Follow-up to BUG#20913616 - FIREWALL INTEGRATES BADLY WITH QUERY CACHE
      Bug #20914786 : MYSQL_UPGRADE FAILS WITH SHOW_COMPATIBILITY_56 = OFF
      Bug #20753378 ASSERTION `GTID_NEXT->TYPE != AUTOMATIC_GROUP || THD->OWNED_GTID.IS_EMPTY()'
      Bug #20592961  'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381
      Bug #20592961 'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381
      Bug #20753378 ASSERTION `GTID_NEXT->TYPE != AUTOMATIC_GROUP || THD->OWNED_GTID.IS_EMPTY()'
      Fix for missing test recording and test output differences on Windows.
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Bug#20913616 FIREWALL INTEGRATES BADLY WITH QUERY CACHE
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      BUG#19897405: CRASH WHILE ACCESSING VIEWS IN STORED ROUTINE               AND TABLES ARE FLUSHED
      Bug#20515155 Views: Assertion failed: is_view_or_derived() && is_merged()
      Bug #20987420 PB2 FAILURE OF TEST CASE INNODB_ZIP.INNODB_16K
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      BUG#20007583: THE EVENT_SCHEDULER USERNAME IS NOT RESERVERD.               ALLOWS PROCESSLIST VIEW.
      Windows installer in need of fixing to accommodate for WL#7307
      Bug#20768717: DEBUG BUILD FAILS WHEN USING GCC 5 DUE TO COMPILER WARNING
      post push minor test fix for bug:19887143
      BUG#20768847 ASSERTION 0 IN HA_INNOBASE::COMMIT_INPLACE_ALTER_TABLE
      - bug#20938115: innodb_undo_logs max limit should be downgraded from 126 to 94^
      Bug #20563332 : OPEN_FILES_LIMIT BINARY PUT INTO ./BIN DIRECTORY OF A BUILD?
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      Addendum to the fix for bug #20681412:
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug#20979020 - THE TRX IN DDL SHOULD ALWAYS NOT BE ROLLED BACK
      Bug#20709462: GENERATED COLUMNS NOT PRINTED CORRECTLY IN SHOW CREATE TABLE
      Bug#20583321: CRASH ON PS_THREAD_INFO / SYS USAGE
      Bug #18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Fixed failing test
      Bug#20583321: CRASH ON PS_THREAD_INFO / SYS USAGE
      Bug #19077239 mtr tests fixed.
      Bug#19077239 re-enabling disable tests mysql_secure_installation amd mysql_secure_installation_ssl
      Revert "WL#8462: test_services are plugins serving as examples for how plugin services can be tested with mtr."
      Bug #19887143 : THREAD/SQL/MAIN DOESN'T CHANGE STATE/INFO AFTER STARTUP
      WL#7895 - Add systemd support to server.
      Fixed Bug #20683741 UNZIP REQUIRED TO RUN MYSQL-TEST-RUN.PL BUT NOT CHECKED FOR BY CMAKE
      Bug#20865674-VALGRIND FAILURE IN INNODB.CREATE_TABLESPACE
      BUG#19821087 UPDATES TO INDEXED COLUMN MUCH SLOWER IN 5.7.5
      Fixed Bug #20949226: CAN ASSIGN NON-DEFAULT() VALUE TO GENERATED COLUMN
      rb8590 Fixes to sporadically failing on PB2 rpl_xa_survive_crash_debug
      WL#8462: test_services are plugins serving as examples for how plugin services can be tested with mtr.
      Bug #20681412 MYSQLD --INITIALIZE REFERS TO MYSQL_INSTALL_DB AND BOOTSTRAP
      Bug#20937654 CANNOT BUILD WITH "-DDISABLE_SHARED=ON" FOR CMAKE BECAUSE OF REWRITER PLUGIN
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      Fixed failing tests
      WL#6940 Server version token and check
      Bug #20181776 :- ACCESS CONTROL DOESN'T MATCH MOST SPECIFIC                  HOST WHEN IT CONTAINS WILDCARD
      Bug#20961660 RPL TESTS ARE FAILING WITH INNODB: UNDO TABLESPACES MUST BE READABLE!
      WL#4601: Remove fastmutex from the server sources
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      BUG#20955104: ADD UNIT TEST BINARIES AS OPTIONAL TARGETS WHEN MERGE_UNITTESTS=1
      Bug#19865673 DDL LIKE ADD INDEX IS VERY SLOW IN 5.7.5
      Bug #20294225 - INVALID MEMORY ACCESS
      Bug#20275612  MEMCACHED INNODB PLUGIN BREAKS MYSQL ENTERPRISE BACKUP
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug #18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Bug#19822257: WRONG VALUE PASSED TO --INIT-FILE OPTION CAUSES SERVER HANG
      BUG#20748570  BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      Bug#20515155 Views: Assertion failed: is_view_or_derived() && is_merged()
      Improved the way --print-defaults works.
      Bug#20615597 Assertion !thd->is_error() at st_select_lex::prepare()
      BUG#20960406  NO_PROTOCOL.INC SHOULD BE IN MYSQL-TEST/INCLUDE DIRECTORY
      WL#8165 Use new records per key interface in NDB
      Bug #20683237 BACKPORT 19817663 TO 5.1 and 5.5
      Bug #20275612 MEMCACHED INNODB PLUGIN BREAKS MYSQL ENTERPRISE BACKUP
      Bug#20895852 UNDERSIZED TMP_TABLE_SIZE - ASSERTION OR ERROR 2027 (HY000): MALFORMED PACKET
      Bug#20895852 UNDERSIZED TMP_TABLE_SIZE - ASSERTION OR ERROR 2027 (HY000): MALFORMED PACKET
      Revert "Bug#20683741 fixed."
      Revert "Updated file have_util_uz.inc under Bug Bug#20683741"
      Revert "Fixed Bug#20683741"
      WL#6940 Server version token and check
      Bug #20052580 MISSING MUTEX/LOCK IN ACL_AUTHENTICATION()
      Bug#20318154 : NEGATIVE ARRAY INDEX WRITE V2
      Bug#20952953 RPL.RPL_SLAVE_SKIP FAILS IN VALGRIND
      Bug#20952953 RPL.RPL_SLAVE_SKIP FAILS IN VALGRIND
      Fixed Bug#20683741
      Bug#20937173 CLEANUP GIS_DEBUG USELESS CODE
      WL#6940 Server version token and check
      Bug#20922238: REDUCE HEADER FILE DEPENDENCIES IN MY_SYS.H AND M_STRING.H
      BUG#20889900: UNITTESTS SHOULD START THE SERVER WITH APPROPRIATE OPTIONS
      Bug#20810627 ASSERTION: REC_PAGE_NO > 2 IN IBUF_GET_MERGE_PAGE_NOS_FUNC
      Bug#20748570 BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      WL#8017 Infrastructure for Optimizer Hints
      Fixing the query tipping points
      Modified the test to run only on 64 bit machine
      Revert accidental changes to collections/default.push
      Bug#20927239: MY_TIMER-T UNIT TEST DOES NOT WORK WITH MERGE_UNITTESTS=0
      Bug#20922238: REDUCE HEADER FILE DEPENDENCIES IN MY_SYS.H AND M_STRING.H
      Post push fix for BUG#20431860
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Bug#20748570 BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      Bug#20902791 MYSQLDUMP DUMPS SYS_SCHEMA
      Bug#20782142 PAM tests Fixed
      Updated file have_util_uz.inc under Bug Bug#20683741
      BUG#17259750 - STACK CORRUPTION IN VIO_IO_WAIT ON MAC OS X
      BUG# 20798617 - MYSQL CALLS  EXIT(MYSQLD_ABORT_EXIT) WITHOUT                 SHUTTING DOWN INNODB.
      BUG#20597821 INVALID READ OF BLOB MEMORY FREED IN ::CLEAR_BLOB_HEAP_PART
      Bug#20911624 THE SERVER CRASH WHEN TEST ST_INTERSECTS WITH ST_BUFFER
      Bug #20904893         INNODB: FIX RECENT WINDOWS 32 AND 63 BIT COMPILER WARNINGS
      Bug#20921370: NEW CLANG 3.6 WARNINGS - MUST ENABLE -WNO-UNUSED-LOCAL-TYPEDEF
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Clean up mysql-test/collections
      Enable run of default suites on daily valgrind
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Bug#20903701 FIX VALGRIND WARNINGS IN UNIT TESTS
      WL#8161: Locking service for read/write named locks
      Bug#20789078 innodb: assertion: index->id == btr_page_get_index_id(page)
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug#18486509 ASSERTION FAILED: TABLE->KEY_READ == 0 IN CLOSE_THREAD_TABLE
      WL#8161: Locking service for read/write named locks
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Fix Bug#20618309 ASSERT SLOT1->PAGE_LEVEL == SLOT2->PAGE_LEVEL, BTR_ESTIMATE_N_ROWS_IN_RANGE()
      Bug #20476395 DICT_LOAD_FOREIGNS() FAILED IN COMMIT_INPLACE_ALTER_TABLE
      Bug#20573701 DROP DATABASE ASSERT ON DEBUG WHEN OTHER FILES PRESENT IN DB FOLDER.
      Bug#20573701 DROP DATABASE ASSERT ON DEBUG WHEN OTHER FILES PRESENT IN DB FOLDER.
      Bug#20902600: REDUCE HEADER FILE DEPENDENCIES IN SP* AND EVENT* FILES
      Bug #20883256         INNODB: WARNINGS: NONNULL PARAMETER WILL EVALUATE TO 'TRUE' ON FIRST ENCOUNTER
      Bug#20888417: REMOVE FUNCTION DECLARATIONS WITHOUT DEFINITIONS
      Bug#20814396 PB2 IS SECRET ABOUT WHAT UNIT TESTS IT RUN
      WL#8161: Locking service for read/write named locks
      BUG #20414588 - REMOVE HARD-CODED AIO DISABLE FROM MTR
      Bug#20882432 INCORRECT MERGE_THRESHOLD LENGTH IN SYS_INDEXES AFTER UPGRADE, TRUNCATE, RESTART
      Clarify comment in my_global.h about where and why this header should be included.
      Dummy commit to keep the push hook happy.
      Bug#20856729: QUERY REWRITE: WRONG IFDEF SYMBOL IN SERVICE_PARSER.H
      Bug#20364862 : MYSQLADMIN PASSWORD AFFECTS EXTERNAL AUTH ACCOUNTS
      Bug#20364862 : MYSQLADMIN PASSWORD AFFECTS EXTERNAL AUTH ACCOUNTS
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Bug #19953365 MY_PRINT_DEFAULTS DOES NOT MASK PASSWORDS
      Bug#20752436: INNODB: FAILING ASSERTION: 0 IN FILE HANDLER0ALTER.CC LINE 6647
      BUG#17650326 MYSQLBINLOG PRINTS INVALID SQL FROM RELAY LOGS WHEN GTID IS ENABLED
      Bug#20350989: MYSQLBINLOG CAN'T DECODE EVENTS > ~1.6GB
      Bug#20609063 - STDOUT AND STDERR REDIRECTION ISSUES
      Bug#20752436: INNODB: FAILING ASSERTION: 0 IN FILE HANDLER0ALTER.CC LINE 6647
      Bug#20886222 MOVE THE DECLARATION OF FIL_NODE_T TO A HEADER FILE,              AND CLEAN UP COMMENTS Move the definition of the data structure fil_node_t from fil0fil.cc to fil0fil.h so that diagnostics code outside that module can access information about the files belonging to a tablespace. Also do other cleanup and formatting changes.
      Bug#20888417: REMOVE FUNCTION DECLARATIONS WITHOUT DEFINITIONS
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Test cleanup
      Convert a func comments to new the InnoDB style.
      Non-functional style fixups
      Bug#20872436 MAKE DIST BY MISTAKE COPIES FILES WITH VARIABLE EXPANSION
      Bug#20882345: MOVE CODE OUT OF HANDLER.H
      Post-merge fix for WL#7806: Remove bogus files.
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug#20615023 SIGNAL 11 IN ITEM_FIELD::RESULT_TYPE DURING 1ST EXECUTION OF PREPARED STMT
      Bug#20872436 MAKE DIST BY MISTAKE COPIES FILES WITH VARIABLE EXPANSION
      BUG 20459905 - DEADLOCK OF THREADS DETECTED! 5.7.5, 1 THREAD SQL TESTCASE, SPORADIC, IN IB_LOGF
      Bug#20863042 Stop filling mtr logs with InnoDB page dumps
      Remove a test from the experimental collection.
      Bug#20865407: DBUG_ASSERT(1) MAKES NO SENSE
      BUG#20857756: BUILD NT_SERVC.CC ONCE FOR ALL UNITTESTS ON WIN32
      Clean up the post-commit fix for Bug#20872655 debug instrumentation.
      Bug#20874411 INNODB SHUTDOWN HANGS IF INNODB_FORCE_RECOVERY>=3 SKIPPED ANY ROLLBACK
      Followup fix for BUG#20518099
      Post-commit fix or work-around for Bug#20872655 debug instrumentation.
      Post-merge fix for Bug#20872655 XA ROLLBACK IS NOT CRASH-SAFE
      Bug#20518099 - CLEANUP UNIV_INNOCHECKSUM in innodb code base
      Bug#19363615 : innodb.log_file fails very frequently on windows and solaris. Moved test from experimental to disabled state
      Raised version after tagging 5.1.74 (some commits skipped)
      Bug#20872655 XA ROLLBACK IS NOT CRASH-SAFE
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Bug#20788811 MAX_STATEMENT_TIME: ASSERTION `EXPLAIN_OTHER || UNIT->IS_OPTIMIZED()' FAILED.
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Test cleanup
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES            OF INNODB_CHECKSUM_ALGORITHM
      Bug#20104307 GTID_EXECUTED TABLE COMPRESSION THREAD MAY NOT WAKE UP
      sys_vars.innodb_compress_debug_basic requires P_S to run
      Bug#20859285: REDUCE HEADER FILE DEPENDENCIES OF SQL_CLASS.H AND TABLE.H
      Add daily and weekly collections of tests that shun --parallel.
      Bug#20578834 - INNODB READ ONLY MODE AND NON EXISTENT TMP DIR CRASHES SERVER
      Bug #20809045    BUFFER OVERFLOW IN MYSQL
      Silence rpl_xa_survive_crash_debug in Valgrind.
      Bug# 19573096: LOADING CORRUPTED GEOMETRY DATA INTO A                MYISAM TABLE CAUSES THE SERVER TO CRASH
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES                    OF INNODB_CHECKSUM_ALGORITHM
      Bug#20857979 REMOVE DEPENDENCY ON HANDLER.H FROM PFS_ENGINE_TABLE.H
      Bug#20768820 MAIN.BIGINT TEST FAILS WHEN BUILT WITH GCC 5 IN RELEASE BUILD
      Bug#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bug#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bug#20855853 MDL SUBSYSTEM ENCAPSULATION BROKEN
      Bug#20816223 test fix.
      Remove MCP_WIX
      Remove MCP_WIX
      WL#7806: Add a test case from Viswanatham Gudipati with some cleanup by me.
      Test cleanup
      WL#7806: Relax a test that started to fail due to WL#6205.
      WL#7795 PERFORMANCE SCHEMA, HISTORY PER THREAD
      WL#7795 PERFORMANCE SCHEMA, HISTORY PER THREAD
      Clean up a test case. Use slow shutdown in order to avoid generating redo log after restart, for processing old undo logs or change buffer records.
      WL#7806: Re-enable a test and work around a problem in WL#6965.
      WL#7806: Add a temporary workaround until WL#7691.
      WL#7806: Temporarily remove the fil_sys_lookup[] for user tablespaces in order to ensure that we are not masking Bug#18645050.
      WL#7806: Add a flat fil_sys_lookup[] array so that fil_spaces_lookup() can avoid acquiring fil_system->mutex when looking up the system tablespace or the undo tablespaces. This is addressing a performance regression.
      WL#7806: Correct some comments.
      Test that no redo log gets generated unexpectedly.
      Rename some tests to comply with new policy:
      Try to get a test to work on Windows.

[33mcommit f8da8f3f983b4ce002b3d0ddca6fb7784244b977[m
Merge: c9e06a98752 e2506e22dd8
Author: Mattias Jonsson <mattias.jonsson@oracle.com>
Date:   Mon May 11 16:15:11 2015 +0200

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            sql/opt_explain.cc
            sql/tz[1;31mtime[m.cc

[33mcommit adfce211f0f480a4d199ccfccce0f05cee4d021d[m
Merge: b6770efd1f2 e6f47a0e267
Author: Praveenkumar.Hulakund <praveenkumar.hulakund@oracle.com>
Date:   Fri May 8 11:11:17 2015 +0530

    Bug#20705648 - max_statement_[1;31mtime[m leaks memory on windows
    Bug#20705642 - max_statement_[1;31mtime[m: assertion failed: pending || thd_[1;31mtime[mr->thread_id
    
    Merge branch 'mysql-5.7' into mysql-trunk

[33mcommit b184ca208482f17223d42584bb788141c499e570[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Wed Apr 8 15:10:36 2015 +0200

    BUG#20857756: BUILD NT_SERVC.CC ONCE FOR ALL UNITTESTS ON WIN32
    
    When configuring with MERGE_UNITTESTS=0 to build separate executables
    for each gunit test on WIN32, the file nt_servc.cc is compiled separately for
    each executable. This adds to the compile [1;31mtime[m in this configuration.
    
    This can be avoided by creating a CMAKE object library of nt_servc.cc
    and pass this to add_executable() instead of the source file name.
    
    Fix also changes some include directives to my_global.h to allow
    compiling with MERGE_UNITTESTS=0 on WIN. The existing directive would
    pull in my_dbug.h without the proper platform magic and expose syntax
    not supported by the MS compiler.

[33mcommit c43c39e0ae1afa1c2c1f39029fcadeced335fc13[m
Merge: 4a29f6e10ca 74cb615be3c
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Fri Apr 10 13:51:23 2015 +0300

    Merge branch 'mysql-trunk-wl7806' into mysql-trunk
    
    WL#7806 InnoDB: Log-based discovery of built-in tablespaces
    
    This is follow-up to
    WL#7142 InnoDB: Simplify tablespace discovery during crash recovery
    
    We will write MLOG_FILE_NAME for all persistent tablespaces, not only
    for *.ibd files. Currently, this includes the following:
    
    * The InnoDB system tablespace (ibdata*)
    * The InnoDB undo log tablespaces (undo*)
    
    On startup, the InnoDB system tablespace and the InnoDB redo log will
    be opened. If there are redo log records to be applied since the
    latest checkpoint, any tablespaces requiring cleanup will be opened
    and recovered based on MLOG_FILE_NAME records in the redo log.
    
    If the MLOG_FILE_NAME records for the system tablespace disagree with
    the server configuration affecting the data file names for the system
    tablespace, recovery will be aborted with an error message, before
    applying any redo log.
    
    After recovery, any undo log tablespaces for which no redo log records were
    applied will be opened based on existing mechanism. The system tablespace
    will remain open at all [1;31mtime[ms.
    
    is_predefined_tablespace(): Remove. All redo-logged tablespaces will
    be treated in the same way.
    
    mtr_t::m_undo_space, mtr_t::set_undo_space(): New field and method, to
    associate an undo tablespace associate with the mini-transaction.
    
    mtr_t::m_modifies_sys_space, mtr_t::set_sys_modified(): New field and
    method, to note that the mini-transaction is modifying the system
    tablespace.
    
    mtr_t::set_spaces(): A kind of copy constructor that copies the
    information on modified tablespaces from another mini-transaction.
    
    mtr_t::is_undo_space(): A debug method to ensure that set_undo_space()
    has been called.
    
    srv_undo_tablespaces, srv_undo_tablespaces_open: Set the initial value
    to 0 on server startup, so that fil_space_belongs_in_lru() will behave
    in a predictable way during redo log apply.
    
    trx_rseg_t: Note that space,page_no are constant and need not be
    protected by mutex.
    
    fil_space_system_check(): New function, to check that MLOG_FILE_NAME
    records match the system tablespace data files.
    
    fil_space_undo_check_if_opened(): New function, to reopen possibly existing
    undo log files after redo log apply has completed.
    
    fil_name_parse(): Support undo tablespaces and multi-file system
    tablespace.

[33mcommit ca6ecd8229c53b0a139304bf6641cef6e529e61a[m
Merge: b840f9e9e35 2e91bec76f5
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Apr 8 12:35:31 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug #20590548 UNABLE TO LOGIN WITH USER WHOSE PWD CHANGED FROM 5.6.23 MYSQLADMIN IN 5.7.6
      Bug#20726413 : MYSQL_SSL_RSA_SETUP DOES NOT HAVE USER OPTION
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES                    OF INNODB_CHECKSUM_ALGORITHM
      WL#8244 Hints for subquery strategies. Part#2: Add support for SEMIJOIN/_SEMIJOIN and SUBQUERY hints
      WL#8244 Hints for subquery strategies. Part#1: Add optimizer_switch for DuplicateWeedout strategy.
      WL#7696 follow up fix, check return values.
      Fixed bug#20745142: GENERATED COLUMNS: ASSERTION FAILED: THD->CHANGE_LIST.IS_EMPTY()
      Fixed bug#20797941: WL8149:ASSERTION `!TABLE || (!TABLE->READ_SET ||                     BITMAP_IS_SET(TABLE->READ_SET
      BUG#20593808 - CRASH WITH PARTITIONED TABLES + MULTITABLE DELETE
      WL#7696 follow up fix.
      Bug#20788853 MUTEX ISSUE IN SQL/SQL_SHOW.CC RESULTING IN SIG6. SOURCE LIKELY FILL_VARIABLES
      WL#7696 followup - remove unused file
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, rerecord the test
      WL#7696 follow up fix, add INNODB_COMPRESS_DEBUG to the test.
      Bug#20840377 UNITILAISED BYTES REPORTED AT MY_WRITE.C:63
      Fixed failing tests after commit 335a53004313ab5a971cf17dea36f1dc4490db9f MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20755430 COST CONSTANT CACHE MUTEX NOT INSTRUMENTED BY PERFORMANCE SCHEMA
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      WL#7696 follow up fix.
      WL#7696 follow up fix - add INNODB_COMPRESS_DEBUG to the list
      Addendum to bug #20810928: fixed the test to reflect that COM_SHUTDOWN can be a zero-length RPC
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20678411 BROKEN MAKEFILE DEPENDENCY: SQL_YACC.YY AND LEX_TOKEN.H
      Bug #17299181    CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      BUG#20093172 LOG_STATE DECLARED VOLATILE, MISSING MEMORY BARRIERS
      BUG#20042205 RPL_GTID CHECKABLE_RWLOCK DEBUG CODE DOESN'T NEED VOLATILE              LOCK_STATE
      BUG#20042109 MYSQL_BIN_LOG::M_PREP_XIDS DOESN'T NEED TO BE VOLATILE
      BUG#20754369: BACKPORT BUG#20007583 TO 5.1
      Bug #17299181  CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      Bug#20411374:CAN NOT EXECUTE CHANGE MASTER AFTER ERROR OCCURED IN MTS MODE
      Bug#20683741 fixed.
      Bug #20814051 CREATE USER BINLOG EVENTS INCLUDE NEW ACCOUNT KEYWORD
      BUG#20510811 - RQG_ALTER_ONLINE_PART RUN INTO ASSERTION: NODE->ENTRY
      Bug#20279241 - ALTER TABLE XXX CHARACTER SET UTF8, CONVERT TO CHARACTER SET LATIN1 SHOULD FAIL
      Adapt new sql/ha_ndbcluster.cc code to use the new ER_THD() macro
      Remove MCP_GLOBAL_SCHEMA_LOCK patch
      Bug #20810928: CANNOT SHUTDOWN MYSQL USING JDBC DRIVER
      Fixed Bug #20683741.
      Test cleanup
      Bump version to 7.5.0
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20811494 SHOW_COMPATIBILITY_56 = OFF INCOMPATIBLE WITH CONNECTORS
      Bug#20531812: MEMORY CONSUMED QUICKLY WHILE EXECUTING LOOP IN PROCEDURE
      Bug#20683959 LOAD DATA INFILE IGNORES A SPECIFIC ROW SILENTLY UNDER DB CHARSET IS UTF8
      Remove MCP_BUG16021021
      Remove MCP_WIX
      Bug#20313067 CHECK TABLE REPORTS WRONG COUNT FOR SPATIAL INDEX AND OTHER GIS PROBLEMS
      Bug#20124342 MYSQL 5.6 SLAVE OUT OF MEMORY ERROR ? Problem: I/O thread on Slave with master_info_repository=TABLE settings, is leaking memory that leads to Out of memory (OOM) after some [1;31mtime[m.
      Fix merge error in mysql_system_tables_fix.sql
      Remove MCP tags for BUG16226274
      BUG#20811125 INNODB FTS: FTS_PRINT_DOC_ID PRINTS TOO MANY DEBUG INFORMATION
      Bug#20762059 - innodb_thread_concurrency=1 and queries using intrinsic temp tables, causes hang
      Create an .inc file which does slow shutdown before restarting innodb in read-only mode.
      Bug#19811953 ENVELOPE() FUNCTION RETURNS INVALID POLYGON Bug#20196720 ENVELOPE(P) RETURNS NULL FOR A NON NULL POLYGON P
      Bug #20544581         ASSERTION: REC_PAGE_NO > (ULINT) 4 - (REC_SPACE_ID != 0)
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 - Fix a merge issue.
      WL#7696 - Fix a merge issue
      WL#7696 - Fix the column ordinatlity. Messed up in a previous merge.
      WL#7696 - Fix a compilation error
      move some compression tests elsewhere until using Win32::API module is approved. Improve error detection, if there is no module, the tests will succeed, not fail as before, but the testing power will be somewhat limited.
      Bumped rpm version for oel due to respin
      Bug#20756770 MYSQL SERVER DOESN'T COMPILE AGAINST OPENSSL 1.0.1M
      Patch for Bug#17162055: SSL.CMAKE SILENTLY CHOOSES BUNDLED YASSL INSTEAD OF ERRORING FOR OLD OPENSSL VER
      Bug#20755346 EXAMPLE SCRIPT IN FIREWALL MISSES WHERE CLAUSE
      Bug#20764521 REGRESSION: FIREWALL USE GENERAL_HOST TO RESOLVE HOST
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      Resurrect unintentionally remove disabled.def file
      Resurrect unintentionally remove disabled.def file
      Bug#20651661 NDBEVENTBUFFER LEAKS GCI_OP
      Remove three files which did not properly remain
      WL#7696 - Make LZ4 decompress safe during recovery
      Remove hack to allow large number of failing tests in mtr.pl
      WL#7696 - Reset the contents of the page to NUL.
      WL#7696 - Use the double write buffer pages for compressed pages.
      WL#7696 - Fix syntax error on Windows.
      WL#7696 - Fix debug assertion.
      mysql-test/include/innodb-compress-utils.inc:   add OSD support to get allocated file size for Windows
      add the result file missing in the previous commit
      Test update:   mysql-test/suite/innodb/t/table_compress.test:     fix one failing case for 32k   mysql-test/suite/innodb/r/table_compress_2.result: make use of new     include files   mysql-test/suite/innodb/t/table_compress_3.test: new test to cover     what was not covered yet, shared tablespaces in particular   mysql-test/include/innodb-compress-verify.inc: common sequence     for compression verification   mysql-test/include/innodb-compress-utils.inc: perl compression     related utilities.     Note: OSD Windows file allocated size is not implemented yet.     The test is still expected to pass on Windows because the allocated     size is forced to the expected value.
      Bug #20536590: BACKPORT BUG #12368204 AND BUG #16953758 TO MYSQL-5.6
      WL#7696 - Code clean up. Ignore table COMPRESSION setting if set to NONE.
      WL#7696 - Minor code cleanup
      WL#7696 - Fix the punch hole size calculation.
      Bug#20712432 AUTOTEST: TESTFK FAIL IN CLEARTABLE WITH 256 REFERENCED ROW EXISTS
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#17775772 POTENTIALLY UNINITIALIZED BUFFER IN NDBOUT::PRINT* PRINTOUT   - print nothing or just empty newline instead of uninitialized buffer   - catch error with an assert in debug compile
      Bug#17775607 POTENTIALLY UNINITIALIZED BUFFER IN VNDBOUT_C PRINTOUT  - print empty newline instead of uninitialized buffer  - catch error with an assert in debug compile  - Mark vndbout_c as static and thus local to implementation Conflicts in copyright:        storage/ndb/include/util/NdbOut.hpp     storage/ndb/src/common/util/NdbOut.cpp
      Remove unused parameter ndbcluster_drop_event()
      Bug#20032381 KILLED_STATE SAVE IN NDBCLUSTER_BINLOG RETRY AT SHUTDOWN DOESN'T NEED TO BE VOLA
      Bug#20014045 MONOTONIC SPELT INCORRECTLY IN NDB CODE
      Bug#20092754:  MYSQLD CRASH (FOUND UNCOMITTED AUTOCOMMIT+RBWR TRANSACTION, COMMIT STATUS 3)
      mysql-test/suite/innodb/t/table_compress_2.test:
      Raise version number after cloning 7.4.5
      Correct MTR command for 64k run. Adiing missing "k".
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      Tetss that use innodb_compress_debug should run against debug server
      Added runs with differnt combination and page size setting for Innodb suites
      mysql-test/suite/innodb/t/table_compress.test:   Fix failure when hole punching is not available.   Now the test will be skipped instead
      Revert accidental bump of server version back to 5.6.23
      Fix a compilation warning in non-debug mode
      BUG#18949230: Removed unneeded ndbassert and fixed printout, also recorded number of real periods
      Added some extra output to ndbapi tests utilities as an aid to hunt down the AutoTest failure 'testBasic -n Bug54986 D2'
      Added log printout about invalidation of REDO log and where log head was found
      WL#6815 Adapt MySQL Cluster to 5.7
      Added autotest files for Mikaels environment, added comments about how to get file system as part of results in autotest, added comment about how to handle older git versions with autotest
      BUG#20546157: Fix problems in START_PERMREQ and START_INFOREQ that hangs node restarts when invalidation of nodes is still ongoing at node restart
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20480035 REMOVE MCP_BUG44529
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disable ndb_rpl_circular_2ch* waiting for Bug20592110
      Disable ndb_addnode_witbinlog waiting for Bug17400320
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75720: Fix platform issues with ndb_dd_dump test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      WL#7696 - Don't print a warning on Windows if SPARSE FILE attribute can't be set
      BUG#20631645: Ensure that SYSFILE->latestLCP_ID is properly up-to-date in the pause LCP protocol
      Fix regression caused by wl#7674 in testBasic -n RefreshTuple T6 D1
      Fix regression caused by wl#7674 in testDict -n Bug13416603 I2.
      Fix for Bug#20408733:
      WL#7696 - Punch hole message is Linux specific.
      WL#7696 - Backport code from mysql-trunk to mysql-5.7
      Followup fix for "Bug20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK"
      WL#6815 Adapt MySQL Cluster to 5.7
      Another follow up fix for "BUG11748566 - MYSQL SHOWS WRONG DEFAULT VALUE FOR PK IF  NOT NULL NOT SPECIFIED"
      BUG#20568586: Fix ndb_cpcd to avoid reading a closed file
      BUG#20567730: Ensure that late arriving LCP_FRAG_ORD with lastFragmentFlag set from new master are handled correctly, correct is to ignore them if such a signal arrives in idle LCP state
      Fix for bug#20538179
      BUG#20546899: Faulty ndbrequire fixed
      BUG#20553247: Fix memcpy overlapping copy issue
      BUG#20553247: Use memmove for overlapping memory copy
      Commit this fix on behalf of Pekka N:
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      BUG#19811871 VERSION NUMBR NOT SHOWN IN LOG WHEN [RE]STARTING 5.6.21 SERVICE WITH SLES11 REPO
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      Updated copyright information
      Bug#20228839: MISSING DATABASE '-D' OPTIONS FOR FEW OF THE HUGO TOOLS
      Re-enable clusterj tests disabled during 7.4.4 release.
      Bug#20593065 MULTI UPDATE RETURNS DIFFERENT DATA WITH ENGINE NDB
      This commit is a followup to the fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_[1;31mtime[m calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop [1;31mtime[mout to be configured).
      Add support for SLES12
      Merge 7.3->7.4
      Merge 7.2->7.3
      Overriding release() function from the DynamicObject class in its subclasses.
      This commit is a fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_[1;31mtime[m calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop [1;31mtime[mout to be configured).
      Reverse order of libraries used when linking the ndbapi examples
      Add small MCP for problem with Partition_handler::get_default_num_partitions
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM: fix test regression
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7549: Fix test case for removed EMPTY_LCP protocol
      BUG#20444078: Removed unneeded log printout
      BUG#20444078: Fix master takeover of COPY_GCIREQ protocol
      WL#6815 Adapt MySQL Cluster to 5.7
      Revert accidental version number change
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20528878 : P_S UNIT TEST IS FAILING
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM
      Temporarily hack mtr.pl to allow a large number of failing tests
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disabling ndb.clusterj and ndb.clusterj_jpa tests for 7.4.4 release.
      WL#6815 Adapt MySQL Cluster to 5.7
      bump version to 7.4.5
      Bump version to 7.4.5
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20281479: Entered eternal loop when starting node in MGM server due to buggy bug fix
      Fix unintentional increase in testsize by a factor of 100 of 'testBasic -n Bug54986'
      BUG#20513571: Introduce MaxSendDelay for large clusters
      Fix failing AutoTest 'testIndex -n NFNR3*'
      BUG#20512063: Moved verbose logging to only be used in verbose mode
      Add missing failure detection for 'testBasic -n Bug54986'.
      BUG#20281479: Ensure that START_ORD is properly sent from management server
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20504971: Fixed restart_info table to provide its output
      WL#6815 Adapt MySQL Cluster to 5.7
      Proper error printouts after reaching NDBT_FAILED in test cases
      Backport fix for BUG#20276462
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Updated to newest version of flexAsynch
      Patch related to bug#18401543
      BUG20308276: Don't use same list for master and participant part of takeover processing
      Fix issue in AutoTest where test are being killed by WatchDog during memory allog in startphase 0.
      BUG20276462: Fixed spelling error in error code
      BUG#20276462: Error code ZNODE_FAILURE_ERROR has no treatment in NDB API, use NODE_SHUTDOWN_ERROR instead
      WL#8148 NDB: Add git support to Autotest
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT
      Bug#20234994 JOINS ARE NOT PUSHED AFTER WL6042
      Revert "Adapt pushed joins to WL#6042"
      Fix for Bug#19053226 AUTOTEST FAIL: TESTSRBANK -N MIX -L 300 -R 15 T1
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) PART III
      Bug#20410087 GCOV COVERAGE DATA FOR NDB KERNEL IS MISSING
      WL#8294 NDB: turn on signal checksum as default
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Disabling mtr tests on 7.1 which fail because SSL certificates have expired.
      Re-recording mtr test result after ssl certificate update
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT Generated new certificates with validity upto 2029.
      Fix test client failure for AutoTest 'testNodeRestart -n ClusterSplitLatency'
      Bug#19785977:  CRASH IN NDBINDEXSCANOPERATION::SCANINDEXIMPL
      Bug#20423898 BAD TEST TESTNODERESTART -N LCPTAKEOVER CAN NOT FAIL.
      Improve ndb_rpl_circular_2ch_rep_status reliability.
      Test was random failing due to matching random binlog junk. Make false matches less likely.
      A little brute force to understand the issues with ndb_rpl_circular_2ch_rep_status
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      Experimental experiment with experimental status.
      A more standard variant of !valgrind.
      BUG#19667566 : PARTITION BY WITH COMMENT LEADS TO MYSQL SERVER REBOOT IN MYSQL CLUSTER
      Sacrifice Valgrind run to improve ndb_rpl_slave_binlog_index reliability.
      Backport of fix for bug#16209645
      Bug#17579998 TEST 'TESTNODERESTART -N GCP -L 1 T1' FAILS DUE TO MYSQLD ABORTED
      ndb_rpl_slave_binlog_index.test
      ndb_types.test contained binary raw data from 'bit' and 'binary' columns.
      Bug #20372169         NDB : INCORRECT STATUS VARIABLES NDB_LAST_COMMIT_EPOCH_[SERVER|SESSION]
      Fix of uncorrect merge (7.2 -> 7.3) of regression fix for bug#19524096
      Fix regression introduced by fix for bug#19524096.
      Fix regression introduced by fix for bug#19524096.
      Fix regression introduced by fix for bug#bug#19524096.
      Improve ndb_rpl_slave_binlog_index.test behaviour under Valgrind.
      Bug#20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK INTEGRATION
      Add some improved debugging to help understand non locally reproducable problems with ndb_binlog_last_commit_epoch testcase.
      This commit is a fix for Bug#19880969 (CLUB FOR 7.1, LINUX-RELEASE, 345 WARNINGS IN BUILD). The fix suppresses these warnings, so that the corresponding square in club becomes green rather than red.
      Bug #19306793         CORE IN NDBAPI WHEN EXTENDED EXTENSION TABLE IS CREATED IN MYSQL 7.4
      Quick fix of corrupted special comment characters. No code change.
      Updated the copyright year in README and welcome message
      Improve garbage collection of clusterj artifacts
      Updating copyright year
      Some copyright fixes to files changed in 2014
      Fixing user visible copyright years
      Fix for 7.4.3 build failures
      Fix for copy right year
      Corrected copyright year by sreedhar
      Updated README and banners to 2015
      bump version to 7.1.35
      pgmanpe pe-dump.diff pgman: dump max page entries bug#18484117 bug#19915761 bug#19958804
      pgmanpe pe-config.diff pgman: configure max page entries bug#18484117 bug#19915761 bug#19958804
      BUG#19480197, BUG#73667, BUG#74945: Ensure Local object has transferred back object to real object before calling recursive function
      Cherrypick fix which removes MCP_WL1735 from 7.4
      Cherrypick fix for bug20009152 from 7.4
      Adapt pushed joins to WL#6042
      Follow up fix for bug#20112981
      Fix for bug#20112981
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - rewrite clean_away_stray_files() to use find_files() direct rather than going via make_db_list(). - The only difference between make_db_list() and find_files() is that the information_schema database is not   return in the list of databases. But it's currently not possible  to create a NDB table in information_schema   and thus there can not be any "stray" tables there either.  - testcase added to ndb_reconnect which shows access denied when trying to create table    in information_schema  - This avoids patching the MySQL Server to make the static make_db_list() function available    to use in ha_ndbcluster_binlog and thus the MCP for make_db_list() and LOOKUP_FIELD_VALUES   can be removed. - Also remove the NDB_WITHOUT_MAKE_DB_LIST which was used for compiling ndbcluster in MySQL Server
      Remove unused TNTO_NO_REMOVE_STRAY_FILES Thd_ndb option
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#19898269, BUG#74594: Fixed wrong order of sending bitmap of LCP participants to ensure that starting node can correctly calculate the lcpOngoing flag for each fragment
      Another addendum patch for bug#20112981, adressing comment from Mikael R.
      Incremental addendum patch for bug#20112981
      Fix for bug#20112981
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#75220: Added option to use 10 and 20 LDM threads (same for NoOfLogParts)
      BUG#20215395: Bug in cluster join protocol
      Added jams to place where data nodes freezes in startup
      BUG#19590336: Preparatory patch adding lots of jam:s to DD code, also a few more more comments added
      Additions to wl#7674
      Bug#18715165, BUG#17069285
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug#20193236 SOME COMPILER WARNINGS BECAME ERRORS AFTER MERGE OF MYSQL SERVER 5.5.41
      Cherrypick from 5.6 : Bug#20009154 - FIX REGRESSION AFTER HA_FLUSH_LOGS() HOOK FOR NDB IS REMOVED.
      Bug 19895502 -  BINARY LOG GROUP COMMIT CAUSES REGRESSION FOR NDB REPLICATION.
      This commit is a followup to WL#8145 (NdbInfo : Per-fragment operations info). That WL introduced an error causing 'testScan -n Bug54945 T1' to fail: short-signal scans crashes because the attrinfo section is not available at the point where the code tries to read it to find the size of the interpreted progam. This commit fixes that by not trying to count program size for short-signal scans and lookups. Since these only happen during online upgrade, they are not important for per-fragment statistics.
      Bug #19992856 MYSQL CLUSTER TRIGGER ON DELETE FALSE POSITIVE
      This commit is a followup to the fix for bug#19976428 ("reports failing with 'out of longmessagebuffer' error"). This commit updates a regression test (testIndex/FireTrigOverload) so that it will expect the right error code (293 "Inconsistent trigger state in TC block" instead of 218 "Out of LongMessageBuffer").
      autotest auto1.diff testBasic -n Bug16834333 : fix dict cache crash
      Bug #19858151         MAKING DATA NODE SELF-EXCLUDE MECHANISM MORE ROBUST
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Updated fix for bug#20113145:
      Follow up to fix for bug#bug#20166585:
      Follow up to fix for bug#bug#20166585:
      This commit fixes bug #19976428 ("reports failing with 'out of longmessagebuffer' error"), and a set of other issues related to the pool of "Fired Trigger" records.
      Bug#17069285 : SEGMENTATION FAULT IN NDB_PRINT_FILE
      Update to recent fix where we failed to close scan cursors at the end of their life[1;31mtime[m.
      WL#7514: Fitted into infoEvent max size and decreased some too wordy log printouts
      Update 'v3' fix for bug#20166585:
      WL#7514: Fixed an incorrect assert
      Fix for various AutoTest 'testIndex ...' crashing due to excessive memory usage.
      Bug#18715165, BUG#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for: - Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT - BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      The AutoTest testcase 'testScan -n Bug54945 T1' crashed as it failed to create a transaction object which was later referred without first checking that it was created.
      Fix for crashing AutoTest: 'testNdbApi -n RecordSpecificationBackwardCompatibility'
      WL#6815  Adapt MySQL Cluster to 5.7
      Fix flexAsynch also in 7.3, backport from 7.4
      WL#7508: Parallelize synchronization of starting nodes with live nodes
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - Test fails since the two new default sql_modes  ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES   are displayed by "show create procedure"  - Update .result file to include the two new default sql_modes(as has been done in similar   places)
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      Experimental fix for several AutoTest which crash with an unreadable stack dump very early in their lifecycle, like:
      Fixed crashing AutoTest testBitfield.
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Cherrypick fix for ndb_memcache out of source from 7.4
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20135403 NDB_MEMCACHE TEST DOES NOT WORK IN OUT OF SOURCE BUILD
      Fixed crashing AutoTest: './testLimits -n ExhaustSegmentedSectionPk WIDE_2COL'
      Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT
      BUG#74594: Fixed a hang in PAUSE LCP protocol when LCP was completed between PAUSE and UNPAUSE
      Removed lots of jam noise from QMGR preventing one from seeing the bugs
      WL#6815  Adapt MySQL Cluster to 5.7
      Revert some junk lines from pfs_upfgrade*.result files
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherry-picked from mysql-5.6.22-release
      Cherry-pick from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-pick from mysql-5.5.41-release
      Added tag mysql-5.6.22
      Added tag mysql-5.5.41
      BUG#74594: Fix missing state update that causes PAUSE LCP protocol to hang
      BUG#74594: Added some more DUMP printouts for PAUSE LCP protocol
      WL#7650: Make atrt work on Mac OS X
      Removed assert / require from NDBT_ResultRow c'tor and rewrote it such that it could be constructed even if the the object is not in 'Retrieved' state.
      BUG#75007: Ensure we wait until master takeover is completed before handle LCP_COMPLETE_REP from LQH and DIH participants in the LCP protocol
      Bug#20029843 7.4.2 REGRESSION: UPGRADE_TRAFFIC FAILURES FOR 7.4 -> 7.3: Fixed incorrect conditional expressions
      Cherrypick fix for ndb_dist_priv.sql from 7.4
      WL#6815  Adapt MySQL Cluster to 5.7
      Cherrypick fix for mysql_system_tables_fix.sql from 7.4
      WL#6815 Adapt MySQL Cluster to 5.7
      Encourage MySQL to treat numeric variables as numbers so that ndb_rpl_conflict_epoch2_extra does not return incorrect results from inequality tests.
      BUG#75007: More work on ensuring that we drop the right signals of the LCP_COMPLETE_REP and LCP_FRAG_REP, a bit tricky to decide, wrote up an analysis in a comment and a fairly simple code based on this analysis
      Cherrypick fixes for ndb_alter_table_online from 7.4
      Remove usage of DEFAULT 0 for TIMESTAMP
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fixed for ndb_update_no_read from 7.4
      Turn "info" off after each section in test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fix for ndb_dd_disk2memory from 7.4
      Add missing enable_query_log comman in ndb_dd_disk2memory.test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75007: Fixed interaction with early master takeover initialisation and handling of failed node in LCP, code in new master
      BUG#75007: Handle side effect of bug fix, there are signals generated by node failure handling that must be allowed to pass through the code as they are required for node fail handling to be done properly
      Apply patch for MCP_BUG19704825to 5.7.5
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#74594: Fix of variable length in message to management server to avoid printing garbage
      BUG#75007: Ensure that we drop LCP_FRAG_REP and LCP_COMPLETE_REP that originates from a dead node. The LCP could potentially be done before this arrives due to node failure handling, these signals are some[1;31mtime[ms delayed and thus we need to take care that we can still receive them.
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Assumption that all alive nodes have participated in LCP at close down [1;31mtime[m caused havoc since we can now be alive and still not have participated in the LCP. So had to move the send of the last LCP_COMPLETE_REP backwards a bit to be able to reuse the m_participatingDIH bitmap to send to.
      remove last NDB_WITHOUT_COLUMN_FORMAT ifdef  - since all versions of MySQL Server which ndbcluster   compiles against now supports "field->column_format" and "field->storage_type" - one NDB_WITHOUT_COLUMN_FORMAT left behind(or reappeared)
      BUG#19795152: Missed essential ptrCheckGuard in upgrade/downgrade situations
      WL#7514: More printouts to log for system restart case
      BUG#18610698: New test case
      BUG19795152: Fix Software upgrade issue
      Add missing delete of Ndb instance created by testcase
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Minor tweak of jamming and of a loop
      BUG#19795217: Checked the LCP state a bit too early
      BUG#74594: Added one more cluster log event
      BUG#74594: Wrong check if LCP is idle when sending UnPause message
      bug#20045455 Improve error reporting for clusterj
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Fixed a compiler warning in new tool
      BUG#74594: Wrote an analysis tool for reading DIH Fraglist files to enable easier analysis of system restart bugs
      BUG#74594: Queued LCP_COMPLETE_REP comes from LQH, not from DIH
      BUG#74594: Fixed a typo bug in an important condition
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Added a new ndbrequire to find problem
      WL#7514: Added a bit more logging of the actual start order signal
      flexBench created its worker threads, flexBenchThread, with a stack of insufficent size. This later caused the threads to crash.
      WL#7509: Add undocumented interface to change Disk Write Speed in LCPs, change isn't persistent over restarts, useful to handle SRs where restarts are too slow
      WL#7509: Tweaked the adaptive LCP speed parameters to be a bit slower in changing
      BUG#74594: Add DUMP_STATE_ORD variant to print pause state to cluster log
      BUG#19795108: Proper fix of node restart status using the new Node Recovery Status module
      BUG#19795152: Handle Partial System restarts
      BUG#74594: Used wrong variable in non-master to decide on pauseAction
      Attempt better "htonll" portability in NDB memcache code
      Fix for bug#19390895
      BUG#74594: Ensure that we drop PAUSE_LCP_REQ signals from master if it concerns a node that already has died
      BUG#74594: Node failure in inopportune [1;31mtime[m caused crash
      BUG#74594: Decrease amount of useless jam:ing to make bugs more visible
      Bug#19642978: NDB_RESTORE CORES ON BUILT-IN PRIMARY KEY + STAGING BLOB CONVERSIONS ON SPARC
      Fix for bug#20031313  AUTOTEST CASE 'TESTDICT -N GETTABINFOREF' NEVER WORKED FOR >= 4 DATA NODES
      BUG#74594: Turned ndbrequire condition the wrong way, caused obvious crash, added a few more ndbrequires while at it
      BUG#19795152: Also NODE_FAILURE_COMPLETED and ALLOCATED_NODE_ID can be states from where a node fails from DISCONNECT_REP although the node hasn't really started its start yet.
      BUG#74594: Removed buggy ndbrequire, not correct though to possibility of delaying arrival of LCP_FRAG_REP when copying table to disk
      BUG#19795152: NdbTick_Elapsed parameters in wrong order
      BUG#19795152: Added one more acceptable state transition, ALLOCATED_NODE_ID -> ALLOCATED_NODE_ID
      BUG#74594: Missed setting lcp id in COPY_TABREQ, added ints of LCP variables on replica and fragment records, removed init of lcpStatus in INCL_NODEREQ which depended on old fact that we included when LCP was idle, now this is no longer necessary, missed init of m_lcp_start_[1;31mtime[m in including node in LCP, added a number of log prints
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#19676350 NDB_RPL_CONFLICT_EPOCH SHOWS SCHEMA DIST TIME FAST FORWARD DUE TO EINVAL
      BUG#74594: missed init of c_queued_lcp_complete_rep
      BUG#74594: Handle fromTimeQueue issues with LCP_FRAG_REP
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed stopping of pause properly in master and in non-master
      BUG#74594: Wrong assumption in START_LCP_REQ removed, fix of ndbrequire of COPY_TABREQ counter improved
      BUG#74594: Added new parameters to allocStoredReplica
      BUG#74594: Missed init of fragId and tableId in replica record, wrong assumption about m_participatingDIH in START_LCP_REQ
      BUG#74594: Missed clear of own node in NodeReceiverGroup in sending FLUSH_LCP_REP_REQ
      BUG#74594: Fixed typo
      BUG#74594: Missing inserts into signal table
      BUG#74594: Fixes for wrong assert, missing state update and wrong condition
      BUG#74594, fix for sanity check
      BUG#19795152: Fix a placement new that overwrote the node recovery [1;31mtime[mrs in debug mode, added a bit more debug code and arranged the parameters in some common functions a bit more logically
      BUG#74594: Added missing file CopyTab.hpp
      BUG#74594: Remove need for long wait for LCP to copy meta data to make restart [1;31mtime[ms more predictable and faster
      BUG#74639: Preparatory patch to handle overload bugs that is likely to be caused by higher pressure on LCPs and restarts
      BUG#19795152: Added missing file: NodeRecoveryStatusRep.hpp
      BUG#19795152: Wait for LCP start at node restart, add node recovery status table as well
      BUG#19795217: Remove EMPTY_LCP protocol from master takeover
      BUG#74594: Part 2: Fix a potential LCP stoppage
      BUG#74594: Part 1: Remove a faulty ndbrequire
      BUG#19795029: Improve logging of restarts developed in WL#7514
      BUG#19795108: Fix of node restart status for adapting speed of LCP disk write speed
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug#20007248 NDB NOT FUNCTIONAL ON POWER
      Bug#20007216 FLEXASYNC USES 32BIT MATH, LEADING TO INCORRECT SUMMARY ON POWER8
      Fix regression in AutoTest -n DropWithTakeover T1 introduced by fix for bug#19874809:
      Add missing newline before end of file in AsyncNdbContext.cpp
      Fix build failure in MCP patch for BUG19553099
      bug#20017292 Clusterj logging levels too verbose
      Bug#20009152 FIELD NAME NOT INCLUDED IN WARNING WHEN CONVERTING TO FIXED
      WL#7640  Ndb Active Active Delete-Delete handling
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Fix Club test regressions after backport of bug#19524096:
      WL#7640  Ndb Active Active Delete-Delete handling
      Provide easy way to store documents with no mapping and no schema defined   define new method on session factory: db(database_name) returns db object   db object has properties corresponding to table names     if table does not exist, create the table       if user has not mapped the table, create default table mapping and table       if user has mapped the table, use table mapping to create the table   Operations on session using non-existing table name     will now create the table if it does not exist and user has mapped the table
      Fix bad #ifdef
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Bug #19817817 TFBUFFER::VALIDATE() CONST: ASSERTION `(P->M_BYTES & 3) == 0\' FAILED
      Backport of fix for bug#19524096
      Bug#19999242 DELETEING NDB_CLUSTER_CONNECTION WITH NDB INSTANCES
      bug#19913569
      Avoid segv when closing session factory with sessions still active
      Bug #17592990: DATA MISMATCH BETWEEN C NDB API AND MYSQL CLI.
      Backport of fix for Bug#19724313
      Fix for bug#19880747:
      Fix for bug#19875663
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Fix for bug#19881025:
      This commit is an update of WL#7375 (Ndbinfo: Per-fragment memory usage reporting). Column fixed_elem_free_rows in view ndbinfo.memory_per_fragment is renamed to fixed_elem_free_count to get a more consisten naming.
      Fix for bug#19874809 :
      Added sles11 repo packages
      This commit implements WL#8145 (NdbInfo : Per-fragment operations info).
      Follow up fix for bug#18352514 fixing a build failure.
      Addendum fix for bug#18352514:
      bump version to 7.4.3
      Bug #19875710         NDB : COMMIT ACK MARKERS LEAK @ LQH IN 7.4
      BUG#19815044: Part 4, remove usage of global block variable m_pgman_ptr, it is used for parameter passing, but can in some weird situation in DBTUP it can be reassigned to a value that can cause an inconsistent database.
      BUG#19815044: Part 3, fix such that an aborted insert after a committed delete doesn't lead to that triggers for delete isn't executed by ensuring that delete_insert_flag is properly maintained
      BUG#19815044: Part 1: Improve jamming support to make it easier to read what's going on bug situations
      BUG#19815044: Add test case for it used in autotest
      BUG#19815041: Crash on abort of delete after successful delete on a disk data table
      Add global.fail_connect to test utilities
      Fix ProjectionErrorTest
      Improve error reporting for multidb tests
      big lint-fixing patch
      Fix unified_debug issue with per-file levels for C++ files Remove workaround for this in executable programs
      Converter use in DBTableHandler (fixes freeform tests for ndb)
      Big deglobalization patch. Removes many global variables (but not all).
      Move SQL.create and SQL.drop from test harness into adapters. NDB depends on MySQL for this.
      Enhance closeAllOpenSessionFactories() so it takes a callback & returns a promise
      Fix for bug#19712569
      When using node --harmony and strict mode, DBIndexHandler cannot be forward declared   and still use the function DBIndexHandler(parent, dbIndex) syntax.
      jscrund: add support for B tests with varying size varchar. (Only supported by jscrund_mysqljs crund backend).
      lint globals cleanup
      Fixes restart race causing test [1;31mtime[mout in AutoTest 'testDict -n schemaTrans'
      Return an error if writing non-Buffer data to binary columns
      Allow flexible mapping for node.js domain classes
      Fix for bug#18352514
      Fix for bug#19661543
      Remove warning introduced with patch for BUG#19236945
      Bug #19236945 ADDRESSSANITIZER BUG SHOW UP IN NDBRECATTR::RECEIVE_DATA CALLED FROM RESTORE.CPP
      bug#19793475 - NO WAIT FOR EPOCHS THAT HAVE NO DB CHANGES MADE BY THIS NDB THD TO BE IN BINLOG
      Removing the extra blank line from daily-basic-autotest-conf
      Fixed compilation error due to changed file name
      Bug#19267720:  NDB REPLICATION : DO NOT SETUP CONFLICT RESOLUTION FOR EXCEPTIONS TABLES
      formatting
      Docs work
      BUG#19795072: Fix problems related to ndbinfo tables for disk write speed
      BUG#19643174: Fix races in relation to sending TC_COMMIT_ACK and handling of complete of a transaction
      Removed compiler warnings
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000): GOT ERROR 4547 PART II
      Cherrypick from 7.4 (revno 4354): Implement status variables exposing last commit epochs for the server   and each session.
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      BUG#19724313: Handle multiple threads crashing at the same [1;31mtime[m properly
      Added missing include for previous patch Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Restore computeChecksum to computeXorChecksum that was reverted in patch for Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Merge of Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Refactoring of Packer::unpack in preparation of merging Bug#19582925
      Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      wl#7674-5 fixing errors
      wl#7674-5 fixing errors and compiler warnings
      wl#7674 Backward compatibility/new event api methods
      wl#7675 Introduce state machine for event buffering
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) : GOT ERROR 4547 : 'RecordSpecification has overlapping offsets'
      Applying the patch for regression bug#19582807 for 7.1.33 cluster release
      Improve Query documentation
      Cherrypicked
      Cherrypicked
      Bug #19582807 MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Wl#7639 Ndb Active Active Manageability improvements
      Removed compiler warnings
      WL#7642 Ndb Active Active Binlog Read Tracking: Removed uninitialized data to remove valgrind warnings
      Work on new README
      Bug #17257842     EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #19766167         NDB : VALGRIND REACHABLE MEMORY IN NDB_RPL_CONFLICT_EPOCH_TRANS
      Fix new log printouts - Use log functions of component in favour of sql_print_information - Break long lines
      In-Progress Packaging / Documentation improvements
      Iterate array rather than for/in
      Add mynode.closeAllOpenSessionFactories()
      Windows testcase fix attempt
      Follow up patch for WL#7953 Transporter handshake retry
      WL#7642 Ndb Active Active Binlog Read Tracking: Updated result for ndb_rpl_conflict_read_tracking test case to reflect new conflict counters
      WL#7640  Ndb Active Active Delete-Delete handling
      bump version to 7.3.8
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      bump version to 7.2.19
      bump version to 7.1.34
      Bug#19692387 PORT FIX FOR BUG 18770469 TO MYSQL CLUSTER 7.3
      Added ndb_print_file man pages
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug#18487960: SIG 11 on delete with index merge
      Follow up patch for WL#7953 Transporter handshake retry
      Follow up patch for WL#7953 Transporter handshake retry
      Patch 2 for WL#7953 Transporter handshake retry
      Patch 1 for WL#7953 Transporter handshake retry
      Patch 3 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 2 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 1 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      adding checksum to the cnf file
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19600834  late code review comment
      Bug #19600834 DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH)
      Bug #19600834         DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH) ...
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3
      Bug #19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3  - revert the reverted
      Bug#19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Change from mysql-5.6 to build Oracle Linux 7 RPMs
      WL#7640  Ndb Active Active Delete-Delete handling
      WL7640 Add delete-delete conflict count
      Adding ndb_print_file to spec file
      Repush of WL#7544 after 7.4.1 clone tag.
      bump version to 7.4.2
      Set version 7.4.1
      Revert WL#7544, not to be included in DMR 7.4.1
      Reorder member initializer list for thr_data to follow initialization order. This removes compiler warning introduced in fix of Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      WL#7544: Optimisations of the NDB API receiver thread in various manners. 1) Optimising method to unpack field data from TRANSID_AI signal, 2) optimised handling of trp_client locking check, 3) reorganised code in NDB API receiver thread for better performance and more readability, 4) Optimisation signal receive handler
      BUG#19451060: One more step on the way to understanding commit ack markers
      Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Fix for bug#19559313, call getPerformStateString() with a nodeId arg instead of a state argument
      Fix for Bug#19552283 :
      Update documentation to remove useProjection       Update Session.js to remove useProjection
      BUG#19552349: Avoid stack overrun by removing endless recursive call
      BUG#19451060: Further refinements of bug fix, previous ndbrequire revealed a race that could cause multiple REMOVE_MARKER_ORDs to appear for the same transaction, added long comment about this specific race variant. Left a part of the ndbrequire still to ensure that this only happens when receiving REMOVE_MARKER_ORD sent by API through TC_COMMIT_ACK and not through API failure handling
      Bug #18703922  DUMP-CODE ACTIVATED DEBUGGING ON WATCHDOG OVERLOAD ISSUES
      Bug #17730825  NDB API: POSSIBLE LEAK OF CONNECTION OBJECTS
      BUG#19524096: Converted many 4009 errors to temporary error 4035, ensured APIs can use new data nodes sooner, fixed some wrong error categories, removed no longer used errors, fixed some anomaly in communication towards the API, small improvement of restart printouts, should give autotest a much better chance to get rid of redness
      Bug #17893872         ER_DUP_ENTRY WHEN INSERTING TO AUTO-INC COLUMN ON SPARC MULTI-MASTER SETUP
      BUG#19451060: Added more descriptive information at crashes related to commit ack markers, changed name of noFired to numFired for clarity, added possibility to put last in free list to aid crash printouts
      Fix for spelling error in Win32 code
      WL#7509: Introduced more configurability of disk write speeds and added a number of new ndbinfo tables to track this new more adaptive behaviour
      WL7845: More and safer ways to print records in DBTC
      BUG#19451049: Missing call to prepareTUPKEYREQ from handle_lcp_keep, added comment about handle_lcp_keep
      bug#19124970 - PB WITH POLLEVENTS , NDBEVENTS
      Backport from 7.2
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      The Bug was due to m_out object used in NdbOut operator was not initialized/set to the output stream. Added an ndb_init() call to initialize it to output stream. Added an environmental variable $NDB_PRINT_FILE to give path to its binary in  mysql-test/mysql-test-run.pl file. Added a unit test and its result file.
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      bug#19031389 bugfix.diff bug fix
      bug#19031389 bugtest.diff bug test
      BUG#19513967: Fixed missing init of longer bitmask
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      BUG#17703874
      Bug#19202654: NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      Bug #18354165         16723708 CHANGED EVENT CATEGORY VALUES
      Clusterj windows CMakeList error
      Clusterj support for autoincrement columns http://wl.no.oracle.com/worklog/NDB-RawIdeaBin/index.pl?tid=8027
      Added missing logging.properties
      Clusterj improve maven handling for out-of-source builds
      Bug#18875137: NDB_RESTORE STILL MISSING SOME TYPE CONVERSIONS
      Fix for Bug#19414511:
      Bug #19236785  ADDRESSSANITIZER BUG IN ~NDB_MOVE_DATA Bug #73311      AddressSanitizer bug in ~Ndb_move_data
      Bug #19235428  ADDRESSSANITIZER BUG IN DATABUFFER2<SZ,POOL>::IMPORT (DBDICT::ALTERTABLE_PARSE) Bug #73310     AddressSanitizer bug in DataBuffer2<sz,Pool>::import (Dbdict::alterTable_parse)
      Bug #19235170  ADDRESSSANITIZER BUG IN DBUTIL::GET_SYSTAB_TABLEID Bug #73308  AddressSanitizer bug in DbUtil::get_systab_tableid
      Bug#11764704 : Exclude missing tables when restoring a backup  - added an option "--exclude-missing-tables" to ndb_restore tool  - when enabled, the missing tables will be added to the    exclude tables list before starting to restore.  - updated test cases accordingly.
      Revert fix merged in from 5.5.39 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert fix merged in from 5.6.20 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert quick fix for dtrace problems in release tree. New fix in CMake files will be merged in from 5.6.20.
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      This commit is a followup to the one below. It changes the fragment_num colum (in memory_per_fragment), such that it gives the global frgament id rather than a node-local sequence number. That way, it is possible to see where each fragment (or some replica of it) is located. This is consistent with the output from 'ndb_desc -pn -d <database> <table>.
      Bug 19028487 NPE when scanning rows with blob or text columns
      More fixes for bug#19053226
      Fixes for bug#19053226
      More fixes for bug#19053226
      bug#18410939 - MEMORY LEAK AT EVENT BUFFER ALLOCATING A DUMMY EVENT LIST WHEN INCONSISTENCY
      Bug #17184024         ERROR 4 IN LIBNDBCLIENT.SO.6.0.0 (3-7474573041)
      bug#19122346 fix3.diff FK use full name PP/CC/name + debug
      bug#19122346 fix2.diff fix test error from 7.3 r4203 FK_Bug18069680
      bug#19122346 fix1.diff FK use full name PP/CC/name
      ndb - RSS-DynArr256
      A new ndbapi test case: testNodeRestart -n DeleteRestart.
      Bug #18731008    NDB : AVOID MAPPING EMPTY PAGES DUE TO DELETES DURING NR Bug #18683398    MEMORY LEAK DURING ROLLING RESTART
      Bug #19193927         TC TAKEOVER TAKES TOO LONG CAUSING MANY PROBLEMS
      ndb
      Bug#19193756 MTR GENERATES TOO LONG SOCKET PATHS
      Merge from mysql-cluster-7.2.17-release
      ndb
      use primitive types
      Include stdlib.h for malloc() and free()
      Compiler issues on some Windows platforms
      Add debug to trace bug#18411034 - CRASH IN NDB-SHARE
      Updated the list of tables to be deleted after running ndb clusterj tests Added new test and the model to build specification
      Merge latest nodejs-adapter from 7.3 to 7.4
      Unconditionally disable dtrace for rpm, barfs on Oracle dtrace
      Remove superfluous -master.opt file for the removed test case ndb_mt_recv.
      Unconditionally disable dtrace for rpm-oel, barfs on Oracle dtrace
      correcting copyright headers
      Fix issues with Read/Modify/Update of NDB VO objects containing blobs.
      All NDB read results (including those containing BLOB and TEXT columns) are now ValueObjects.
      Fix bug of using Persistent<T>(x) rather than Persistent<T>::New(x)
      work on support for NdbRecord-backed ValueObjects which contain TEXT or BLOB columns.
      More TEXT tests for NDB
      less debugging output at end of test run
      Fix composition value checking
      Implement bufferForText and textFromBuffer in C++.
      rawNdbDefaultvalue does not require a full-fledged Node Buffer
      let compiler supply default destructors
      Another attempt to fix crashing bug in BlobHandler
      Expose the string encoder statistics in NdbTypeEncoder.cpp to JavaScript.
      Move v8 calls from worker thread to main JS thread
      Support TEXT columns with character set UTF-8 or ASCII. Other charsets (which require recoding) are not yet supported.
      A test file that does not export a test case now causes a warning rather than an error.  This should make it a little easier to develop new tests.
      Column Metadata API provides charsetName rather than charsetNumber
      Fix apparent bug in calculating size requirement of UTF-8 buffer
      Restore compatibility with node-mysql 2.0.0
      Fix crash on stub commit / stub rollback
      update cmake & gyp build lists
      Finish read & write BLOB implementation for NDB adapter
      Implement connection pooling for mysql adapter
      Fix tests that do not close session after running test
      Improve error reporting for connecting to database
      Add suggestion to user to maximize performance of updates
      Improve spi test error reporting
      Succesful insert into BLOB column
      Add BLOB column to stringtypes test suite & confirm that existing tests pass with a mapped (but unused) BLOB field.
      Test that storing a non-BLOB in a BINARY column gives error SQLState 22000
      Use Error SQLState 0F001 "Bad BLOB" (actually a "Locator Exception") if value intended for a BLOB column is not a Buffer.
      Initial implementation work on BLOB support for NDB adapter.
      Refactor connection handling to prepare for connection pooling
      WL#7626 Implement many-to-many relationships for Document Composition
      Don't try immediate startTransaction() unless using async api.
      Keep a single usedOperationSets array rather than one per DBSession. The array is at file scope in NdbTransactionHandler. It does not grow past 4000 elements (a literal constant). Underlying DBOperationSet native objects are freed when the wrapper is placed in the recycler array.
      Disable mysql tests for now
      Attempt to recycle DBOperationSet wrappers
      wrapPointerInObject and unwrapPointer take a v8::Handle<T> rather than a v8::Local<T>
      Improve error reporting for relationships that are null or undefined
      Test a slightly different approach to V8 wrapping
      Minor refactoring in NdbOperation
      Remove the use of "proto" in DBTableHandler
      Refactor DBTableHandler.getFields() into a simple case getFields() and a separate more complex getFieldsWithListener(). Removed the resolveDefaults option which was always set to false.
      Improve error reporting for ProjectionTest
      Improve error reporting for ProjectionTest
      Improve error reporting for test failures
      Compiler error
      Stub out NdbSession.buildReadProjectionOperation in hopes that test suite will run.
      WL#7626 Composition Implement support for one-one, one-many, and many-many relationships. Replace useProjection with implementation for find (projection, key).
      Rather than having a JavaScript wrapper for Record::setNotNull(), implicitly call setNotNull() when writing a data value in encoderWrite().
      Don't use a startTransaction() hint for unique key operations.
      In JsValueConverter for pointer types, if the JavaScript value is Null, represent it as a null pointer.
      Remove what little was left of NdbTransaction_wrapper.cpp
      move ENABLE_WRAPPER_TYPE_CHECKS define into adapter_global.h
      portability fix
      Update source file lists for gyp & CMake
      Add option free-percent
      New design for scans. This removes the previous wrapper for NdbScanOperation and ScanImpl.cpp file and consolidates all scan functions into ScanOperation. Expected: start 416 tests, pass 413, fail 2, skip 1.
      fix wrappers for boolean types
      In test driver allow --stats=query, e.g. --stats=spi/ndb/DBSession
      Add HandleScope to all toJS() template functions just to be safer from enigmatic V8 memory leaks. Provide toJS() and isWrappedPointer() specializations for type bool.
      Refactor NDB execute. This patch renames PendingOperationSet to DBOperationSet, and makes DBOperationSet the "point of contact" for JavaScript calls to begin and execute transactions. All t_basic tests now pass.
      New SPI test   begin transaction; delete (execute NoCommit) ; read deleted row ; commit.
      Minor bug fixes for passing SPI tests
      Major JavaScript logic changes in NDB adapter. NdbTransactionContext, NdbSession, NdbOperation, and NdbConnectionPool are adapted to use the call flow of DBSessionImpl and DBTransactionContext rather than the native call flow of the NDB API.
      This commit includes various small C++ fixes. The next commit includes major JavaScript logic changes. With these together, spi tests pass.
      Add new connection property ndb_sesion_concurrency Refactor initialization of NdbSession and connecting of the new NdbSession to its impl.
      Adapt DBDictionaryImpl to use DBSessionImpl rather than Ndb.
      Revise protocol for registering a transaction open / closed. Use only two calls, registerIntentToOpen() and registerTxClosed(). Always make these calls from JavaScript main thread.
      NdbTransaction is no longer wrapped for JavaScript
      Template class NativeCFunctionCall_4_
      DBSessionImpl
      Adapt AsyncNdbContext to be aware of DBTransactionContext
      executeAsync() on AsyncNdbContext is no longer wrapped for JavaScript; use executeAsync() on DBTransactionContext instead.
      Refactor DBOperationHelper:  it now takes a DBTransactionContext rather than an NdbTransaction.  it now defines operations, but does not prepare them.
      Rename addOperation() to getNextOperation()
      Add two new classes, DBTransactionContext and DBSessionImpl. These will free the JavaScript code from the start/prepare/execute cycle of Ndb and NdbTransaction, eventually allowing operations to be performed with fewer scheduled async calls and therefore less overhead.
      Adapt DBOperationHelper to the KeyOperation / ScanOperation change.
      Bug fix where the do_close flag must be associated with the transaction rather than its parent Ndb object.
      Refactor Operation and DBScanHelper into two classes called KeyOperation and ScanOperation.
      This change alllows Ndb::startTransaction() to run as a sync call in the main JS thread if we suspect that it will not block.  As a proof of concept, this allows you to measure the performance with this change; but it should not be used as-is, because the guess could be wrong, which would cause the main thread to block waiting for network I/O.
      In the common case where an async method call returns int zero, try to optimize away creating a new JavaScript value.
      Slight change to the compatibility strategy for some libuv changes.
      Combine NdbTransaction execute() and close() into a single scheduled call whenever execType is Commit or Rollback.  This saves the scheduling cost of running the close() call by itself.
      Various fixes for lint.
      Remove old stats API.
      Use new stats API in MySQL code.
      Use new stats API in NDB code.
      Revised statistics API. Now each module owns, at file scope, its own stats object. The module registers the stats object with the global statistics, which keeps a reference to it in the stats tree. This should reduce the cost of keeping statistics to practically zero.
      Delay after (rather than before) the first test iteration. This allows V8 to compile all the JavaScript code before dtrace starts running. High dtrace profiling rates caused the first iteration to run very slowly and skewed the profile towards compile [1;31mtime[ms rather than run [1;31mtime[ms.
      Optional delays both before & after jscrund run
      jscrund: add option to delay start of test run
      Add useProjection to Session   this function specifies a projection to be used for find and query operations
      Minor work on DBDictionaryImpl Contain the code for handling NdbDictionary 3-part/slashed/names in DictionaryNameSplitter class. Reformat patch indent width from 4 spaces to 2 spaces. buildDBForeignKey() takes only the fk* and must use its own private name splitter.
      Error 23000 when attempting to set a non-nullable column to null.
      Restore table which should not have been removed from test suite
      Add support for foreign key metadata
      update literal mapping test for schema
      Fix errors in test case & misc. lint errors.
      Check in test case where one operation in a batch has a data type error. This test fails for both NDB and MySQL.
      Expose NdbRecordObject::prepare() to JavaScript. This is a step towards fixing handling of encoder errors for value objects.
      Write a negative value to an unsigned int field of an NDB Value Object. This test causes the test suite to hang forever.
      Run executeAsynch() in JS main thread rather than a UV worker thread. We had seen higher latency using async ndbapi vs. sync ndbapi, but this change eliminates most of that difference.
      unused table in test suite
      Fix for compiler warning in TimestampWriter validity check
      NDB encoding-related changes.  (1) distinguish between 22003 numeric value out of range and HY000 for "value is not numeric"  (2) provide a (hopefully) faster path to encoderWrite and encoderRead by wrapping them as methods of Record
      Refactor error handling
      Attempt to optimize encodeKeyBuffer() for single-column indexes
      Fix reporting of session factory if no mappings
      Remove JsValueAdapter in loader; it is no longer needed.
      This fixes the failing "[1;31mtime[mstamp 1969" test case for NDB. Test still fails with MySQL.
      Fixes for lint test failures
      Test & fix NDB handling of encoder errors for numeric types
      Tests for numeric types
      This renames the integraltypes suite to numerictypes and adds stub tests for float, double, and decimal columns
      Test for particular expected errors rather than simply for operation failure
      Add decimal support in NdbTypeEncoders Remove JS wrapper for decimal utilities from ndb_util
      Encoders for NDB integer values: if the fast integer conversion fails, try a slow one, then test whether the result is legal.  This should allow writing valid JS string and float values to int columns.
      Improve handling of errors from NDB data type encoders
      Improve handling of data encoder errors in the ndb adapter
      fix sql_mode for mysql adapter
      Implemented test cases
      Stub out new test cases for data type casting
      If MySQLTime.valid is set to false, NdbTypeEncoder will reject the value.
      Allow user to set sql_mode in mysql adapter with a default of STRICT_ALL_TABLES
      Change console.log to udebug.log in issues/2014-03-18Test
      Add shell script to manage regular runs of jscrund
      Adapt loader to use new Batch.getOperationCount() api
      Batch: use getOperationCount()  rather than getSize()
      Add Batch.getSize() method
      Add test case for issue of bad data type for column
      Fix typo
      Add test case for issue where a TableMapping created from a literal mapping could not be used to perform operations (fixed in bzr 686).
      Changes to sample data loader after code review with Craig. This version still has lots of untested features (and combinations of features) but it can load CSV data and random data.
      Bug fix creating TableMapping from object literal
      WL#7578 Replace usage of ndb_schema_share->key with hardcoded text
      WL#7578 Move subscriber bitmaps to NDB binlog component
      WL#7578 Move the g_nodeid_map to Ndb binlog thread
      WL#7578 move clearing of subscribed to binlog thread
      WL#7578 Always expect everyone to ack the schema op
      WL#7578 Refactor schema distribution code
      WL#7578 Refactor schema distribution code
      ndb
      WL#7578 note about nodeid from global cluster connection
      WL#7578 Don't use ndb_schema_share from ack_schema_op
      Initial checkin of JavaScript data loader tool
      Remove windows line endings from ndb_schema_object.cc
      Try to reduce overhead of stats.incr() calls
      Remove the error handling in jscrund_mysqljs backend which duplicates work performed in the jscrund frontend.
      Add conditional guards around udebug log messages.
      Add conditional guards around udebug log statements.
      Improve error reporting while loading mysql node_module
      The node-mysql driver by default constructs an Error object in order to get a stack that includes the user's call to Query. This can be a performance bottleneck.

[33mcommit 018ee48617052b3806f4dd22d93242c2aa16ae3b[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Apr 8 11:52:14 2015 +0300

    Test the mysys's lockfree hash
    
    It is impossible to implement the ut_hash_interface_t using the mysys's
    lockfree hash because it requires the called to maintain a "pins" object
    on his own, in addition to the hash table itself. Thus, messup the neat
    implementation in the unit test.
    
    This commit is for historical reference and is going to be reverted.
    
    The mysys's lockfree is about 10 [1;31mtime[ms slower than the implementation in
    ut0lock_free_hash.h for the workload in the ut0lock_free_hash-t unit
    test.
    
    WL#7170 InnoDB buffer estimates for tables and indexes

[33mcommit b73ee71b072c49f7acf2a27f8dc1cbf553ee2e3a[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Mar 31 15:50:40 2015 +0300

    Extend the hash table unit test
    
    Extend the test to also (conditionally, configured at compilation [1;31mtime[m)
    test the performance of std::map and std::unordered_map.
    
    For this introduce an interface class ut_hash_interface_t which is
    implemented by ut_lock_free_hash_t and also by a simple class inside the
    unit test which uses std::map (or std::unordered_map) + a mutex.
    
    Also make the number of initially pre-allocated elements configurable as
    a parameter to the ut_lock_free_hash_t constructor.
    
    WL#7170 InnoDB buffer estimates for tables and indexes

[33mcommit 7c248ae6d0c9f976ed35b0f858cefcb67b7b1c23[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Thu Mar 26 10:50:31 2015 +0100

    Bug#20748660 THD->MDL_CONTEXT.OWNS_EQUAL_OR_STRONGER_LOCK | CREATE_INFO->TABLESPACE
    
    This is a followup refactoring after the first bugfix.
    
    The usage of the 'THD::tablespace_op' flag has been reviewed, and
    we see that the (indirect) usage in Archive and Blackhole is
    inappropriate. At the [1;31mtime[m this code was written, the 'store_lock()'
    function in InnoDB contained a code block that was evidently just
    copied to Archive (and later, to Blackhole).
    
    Thus, the remaining usage is in InnoDB (partitioned and non-
    partitioned), and in the server itself. Thus, we do the following
    refactoring:
    
    1. Remove the 'THD::tablespace_op' flag.
    2. Remove the call to 'thd_tablespace_op()' from
       Archive and Blackhole.
    3. Two new constants are added to Alter_info:
       'ALTER_DISCARD_TABLESPACE' and
       'ALTER_IMPORT_TABLESPACE'.
    4. In sql_yacc.yy, when encountering a DISCARD or
       IMPORT statement, the bit corresponding to the
       constant defined above is set in 'Alter_info::flags'.
    5. The 'thd_tablespace_op()' function is changed to
       use the 'Alter_info::flags' to decide whether we
       are doing a DISCARD or IMPORT, instead of the
       'THD::tablespace_op' flag. Additionally, it must
       verify that the SQL command is ALTER TABLE, because
       the 'Alter_info' is reset only when a new ALTER
       statement starts.
    6. The 'm_tablespace_op' member and the enum
       'enum_tablespace_op_type' are removed from the
       class 'Sql_cmd_discard_import_tablespace'. Instead,
       the 'Alter_info::flags' is used to find the
       required information.

[33mcommit a29b9d480d4533eae68fce70a9a4c78fc3fe68ff[m
Author: Praveenkumar.Hulakund <praveenkumar.hulakund@oracle.com>
Date:   Fri Mar 20 11:06:34 2015 +0530

    Bug#19894382 SERVER SIDE PREPARED STATEMENTS LEADS TO POTENTIAL OFF-BY-SECOND TIMESTAMP ON SLAVE
    
    For temporal type input parameter (as [1;31mtime[m, [1;31mtime[mstamp and date[1;31mtime[m)
    of server side prepared statement, the fractional second part
    is ignored while preparing the query string. Executing such
    query string at slave is resulting in a [1;31mtime[m value difference
    between master and server.
    
    For server prepared statement, the parameters passed for execution
    are parsed and Item_param objects are created for it. While
    preparing Item_param for temporal types [1;31mtime[m, [1;31mtime[mstamp and
    date[1;31mtime[m, precision for fractional second part's (Item_param::decimals)
    is set to "0" always. Because of which while preparing query
    string with param values, fractional second value is ignored. So
    execution of such prepared statements uses correct values but query
    string formed is incorrect. Hence difference in temporal type value
    is observed on usage of query string.
    
    Fix:
    --------
    If temporal types [1;31mtime[m, [1;31mtime[mstamp and date[1;31mtime[m has fractional
    second part then setting microseconds (6 digit) precision for
    the Item_param.

[33mcommit 8df13b04043824c8c17faa00d0d5db36df407340[m
Merge: 743385a257d f2e86f17b4c
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Mar 16 12:00:26 2015 +0200

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug#20661940 REDUCE DEPENDENCIES ON MYSQLD.H
      adding stress testcases for innodb
      WL#7704 after-push fixes with innodb_page_size=4k and 8k.
      WL#7929 GIS: Implement ST_Buffer and ST_Distance with Boost.Geometry
      Bug#20651493 INNODB FTS WITH MECAB PARSER PRINTS EMPTY ERROR MESSAG
      Bug#20239912 QUERY RESULTS ARE DIFFERENT WHEN OPENING OR CLOSING              SEMIJOIN OPTIMIZER_SWITCH
      Fixing EOL to use LF, not CRLF.
      Bug #20294206: INCORRECT CODE(OR INDENTING)
      Bug#17668844: CRASH/ASSERT AT ITEM_TYPE_HOLDER::VAL_STR IN ITEM.C
      Revert the following commit:
      Bug#20691920 SOMETHING IN TEST OPT_HINTS CAUSES ALL MEMORY TO BE CONSUMED AFTER FIX 20685187
      Remove old style spec references
      Bug#20553132 USER WITH EXPIRED PASSWORD ABLE TO EXECUTE ALTER USER .. PASSWORD EXPIRE COMMAND
      Removed support-files directory from CMakeLists.txt
      Removed old sytle rpm spec file mysql.spec.sh
      Modifying the default value to crc32 due to wl8315
      Bug #20439913 CREATE TABLE DB.TABLE LIKE TMPTABLE IS BINLOGGED INCORRECTLY - BREAKS A SLAVE
      Bug #20439913 CREATE TABLE DB.TABLE LIKE TMPTABLE IS BINLOGGED INCORRECTLY - BREAKS A SLAVE Analysis: In row based replication, Master does not send temp table information to Slave. If there are any DDLs that involves in regular table that needs to be sent to Slave and a temp tables (which will not be available at Slave), the Master rewrites the query replacing temp table with it's defintion. Eg: create table regular_table like temptable. In rewrite logic, server is ignoring the database of regular table which can cause problems mentioned in this bug.
      BUG#20597821 [Part -2] INNODB: INCORRECT DUPLICATE KEY ERROR FOR AUTOINC COLUMN
      Making couple of unstable tests experimental
      Bug#20584754: CAN'T FIND RECORD IN 'TABLE100_KEY_PK_PARTS_2_DATETIME_3'
      Bug#20533779: A TEST FOR DISTICT CLAUSE UNSTABLE ON PB2 DUE TO VARIATION IN EXPLAIN OUTPUT Problem was an update caused the explain to be affected by background pruning.
      Bug #20693114         INNODB_ZIP.16K FAILS WITH UNDO TABLESPACES = 2
      Bug#20363531 MY_GCVT PRODUCES OVERLONG DOUBLE VALUE TEXT STRING
      Fix Bug#20427694 RECORDS_IN_RANGE IS +/-1 AGNOSTIC
      WL#8159 - Include Sys Schema in MySQL 5.7
      This is a followup patch of bug#20547644 for fixing pb2 test failure.
      Disable main.opt_hints on Solaris for the [1;31mtime[m being.
      WL#7777 Integrate PFS memory instrumentation with InnoDB
      WL#8355 "Improve scalability by partitioning LOCK_grant lock."
      BUG#19077239: Moved tests from experimental to disabled state. They are failing consistently after some recent changes to trunk
      Bug#20533411 : Disabled valgrind runs of audit log tests
      Bug #20602525 ALTER USER DOES NOT VERIFY AUTH PLUGIN Whenever existing user is modified to alter the plugin attribute there should be a check to see if plugin is loaded else throw and error that plugin is not loaded.
      WL#8316 - Enabled multiple page cleaners and purge threads by default in 5.7
      WL#7704 InnoDB: Remove deprecated file format parameters in 5.8
      Bug#20684424 SHOW_COMPATIBILITY_56 SHOULD SHOULD BE OFF BY DEFAULT
      Bug#20685859 ENABLE STAGES WITH PROGRESS BY DEFAULT FOR EASE OF USE
      Bug #20551271 VALGRIND FAILURE IN THREAD_POOL.THREAD_POOL_CONNECT
      Bug#20685187 USE -STD=C99 WHEN BUILDING WITH GCC ON SOLARIS
      Bug #20551271 VALGRIND FAILURE IN THREAD_POOL.THREAD_POOL_CONNECT
      Bug#19301539 TABLE IO INSTRUMENTATION LEAK IN DSMRR
      Bug#11752665: WINDOWS SERVER X64: SO MANY COMPILER WARNINGS

[33mcommit 9f0d9f07ae3a4c4271a6bb947722279f7501ee26[m
Author: Allen.Lai <zheng.lai@oracle.com>
Date:   Wed Mar 11 09:13:40 2015 +0800

    Bug#20547644 DATA CORRUPTION CAUSED BY SOME SIMPLE SQL
    
    if there're rows in the table.  We should block adding a new geo
    column and add spatial index on it same [1;31mtime[m.
    Since currently, we don't define any default value for geometry
    datatype.
    
    Reviewed-by: Jimmy Yang<jimmy.yang@oracle.com>
    RB: 8255

[33mcommit 63f1886d148a37abf6b7ef61b89cab1776231835[m
Author: David.Zhao <david.zhao@oracle.com>
Date:   Mon Mar 9 11:07:49 2015 +0800

    WL#7929 GIS: Implement ST_Buffer and ST_Distance with Boost.Geometry
    
    Make test case result consistent on all platforms; Remove 2 test cases
    which in debug build, Boost.Geometry takes too much [1;31mtime[m to compute on
    Solaris 11.

[33mcommit dec109fa0b90b6831dd8b8f85c9ede46fe41b08d[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Feb 24 16:22:51 2015 +0100

    Bug#20565160 ASSERTION `SORT_FIELD->LENGTH >= LENGTH' FAILED
    
    If the functions 'least' or 'greatest' are used to compare
    date[1;31mtime[m(n) data and string literals, we need to re-calculate 'max_length'.
    Otherwise we may allocate too small buffer for sorting the result.

[33mcommit ef839be998f484d71a202a28a71c3ed6743e37ed[m
Author: Marek Szymczak <marek.szymczak@oracle.com>
Date:   Thu Mar 5 01:07:46 2015 +0100

    WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
    
    * NO_AUTO_CREATE_USER mode added to the default set (compiled-in) of the sql_mode global variable.
    * Server reports missing NO_AUTO_CREATE_USER mode of the sql_mode variable during boot [1;31mtime[m.
      The initial value of the sql_mode is stored in the configuration file (*.cnf).
    * Switching on and off NO_AUTO_CREATE_USER mode of the sql_mode variable reports warning.

[33mcommit fa6f397f73ce0f95b3d4558fc5a40aabad89c269[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Wed Mar 4 14:44:27 2015 +0100

    Bug#17766653 CRASH IN ADD_KEY_FIELD Bug#20558891 HANDLE_FATAL_SIGNAL (SIG=11) IN QEP_SHARED_OWNER::KEYS
    
    Problem:
    SELECT a.a FROM `t1` `a`, t1 b
    HAVING 1 NOT IN (SELECT a.a FROM `t1`);
    - We resolve the clauses of the subquery: an Item_field is created
    for 'a.a', with depended_from=select#1.
    - the subquery is inside HAVING, and as usual all columns used by
    HAVING must be Item_ref, so an Item_ref is created, with
    depended_from=select#1; this Item_ref then goes through fix_fields()
    which finds 'a.a' is also present in the SELECT list of select#1 and
    thus makes Item_ref wrap the Item_field of the SELECT list of
    select#1, which has depended_from=NULL. Note that the first Item_field
    is thus dropped.
    - So far so good.
    - in-to-exists transformation then wants to build an equality of the
    form: left_expr==right_expr; when it does so, it uses
    right_expr->real_item() for the right side of the equality; right_expr
    is the Item_ref but its real_item() is the SELECT list element of
    select#1, which has depended_from=0.
    - thus, with this real_item(), we end up with 'a.a' on the right side,
    in the WHERE clause of the subquery, with depended_from=0
    i.e. considered as a non-outer, local column, which is wrong.
    - top query is completely optimized
    - In optimization of the subquery, we then look for Keyuse-s for this
    column, which is absurd; add_key_field() reaches to reginfo.join_tab
    which is NULL (because the outer query has already been optimized, and
    WL#6042 zeroes the join_tab pointers at the end of optimization), and
    we get a problem.
    The root cause is: we use real_item().
    
    Fix:
    - I first tried to use the solution of Bug 18014565
    (substitutional_item() at line 1996 of item_subselect.cc);
    but it does not solve the problem in ps-protocol mode; indeed in that
    mode, the Item_ref being a rollbackable one (run[1;31mtime[m-created),
    substitutional_item() is equal to real_item()
    - removing real_item() isn't a solution either, for reasons explained
    in new comments in item_subselect.cc
    - So, until wl#6570 is implemented, two if()s are added, which are
    sufficient to fix all testcases of the two bug reports.

[33mcommit 5ce27f3e80636bded4b855930646f9af5b062d6a[m
Author: Debarun Banerjee <debarun.banerjee@oracle.com>
Date:   Thu Feb 19 10:46:01 2015 +0530

    BUG#20468234 - REMOVE __ATTRIBUTE__((NONNULL)) FROM INNODB
    
    Problem :
    ---------
    __attribute__((nonnull)) is forbidden by InnoDB coding guidelines, but
    there are leftovers from past [1;31mtime[ms. Some bits of code in InnoDB wrongly
    use that attribute and later use the parameter in a conditionals,
    checking if it is NULL, but the compiler could optimize those conditionals
    altogether, causing very hard to diagnose bugs.
    
    Solution :
    ----------
    Remove __attribute__((nonnull)) from all innodb files.
    
    Reviewed-by: Vasil Dimov <vasil.dimov@oracle.com>
    
    RB: 7998

[33mcommit bbdeebd1255d51da0058dc84ba031408e37cbda3[m
Author: Thayumanavar <thayumanavar.x.sachithanantha@oracle.com>
Date:   Mon Feb 16 16:46:33 2015 +0530

    BUG#20545721 - MISSING CLOSE() CALL IN MYSQLD_DAEMON.CC
    
    PROBLEM DESCRIPTION AND FIX:
    
    close(stdinfd) is missing in mysqld::run[1;31mtime[m::mysqld_daemonize().
    
    Fix is close(stdinfd) on line 102 before fork in the if part
    as well to avoid warnings being reported by fortify.
For keyword perf:
[33mcommit f4b2723a1f28fa6343e98d4aee6959565b85c9b3[m
Author: Tatiana Azundris Nuernberg <tatjana.nuernberg@oracle.com>
Date:   Thu May 10 08:41:34 2018 +0100

    Bug#27910708: DON'T GENERATE WARNINGS ABOUT SUCCESSFUL ACTIONS (DRAGNET FILTER RULES)
    
    The component log_filter_dragnet that implements a language for filter
    rules would throw errors or warnings on problems, and a note describing
    the internal representation on success, like the EXPLAIN command does.
    
    As the client unfortunately reports "x warnings" even if they're all
    notes, revealing their true nature only on SHOW WARNINGS, some users
    mistook these "warnings" to mean that something had gone wrong.
    
    To prevent this confusion, we no longer throw a note containing a
    "decompile" on success, but instead make this information available
    in a pluggable component status variable (i.e. one that exists only
    when the component in question is actually loaded) that can be queried
    when desired:
    
      SHOW STATUS LIKE "dragnet.Status";
    
      -or-
    
      SELECT variable_value AS decompiled_filter_rules
        FROM [1;31mperf[mormance_schema.global_status
       WHERE variable_name="dragnet.Status";
    
    Our tests, which make ample use of this diagnostic information, have
    been updated accordingly.

[33mcommit 3e1d7d725182c306c4e7feb439db0652d7288e1a[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Wed Apr 18 10:48:07 2018 +0530

    BUG#27872999: SET $MTR_RECORD VARIABLE INSIDE MTR CODE INSTEAD OF
                  HARD-CODING IT INSIDE A TEST
    
    Description:
    ------------
    There are few MTR tests using a local variable $RECORD to update the
    zip file contents used by the test. The variable value is set to
    either 0 or 1 in the beginning of the test, and based on its value
    either some checks are [1;31mperf[mormed (i.e when the value is set to 0) or
    the existing zip file is updated (i.e when the value is set to 1). To
    update a zip file, one has to manually modify/set the value of $RECORD
    variable to 1, run the test and then set the variable value back to 0.
    
    Fix:
    ----
    Instead of using a local variable, use --record MTR option.
    
    - Created an environment variable $MTR_RECORD inside the MTR perl
      code, set it to '1' if the MTR run is started with --record option,
      0 otherwise.
    
    - Use the $MTR_RECORD variable inside the test instead of a local
      variable.
    
    Change-Id: I6c09a0503a83e444ce3a70c40ab22116fd400e30

[33mcommit 3f3136188f1bd383f77f97823cf6ebd72d5e4d7e[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Thu May 3 10:11:10 2018 -0600

    Bug #25540277 INNODB'S MVCC HAS O(N^2) BEHAVIORS
    
    This [1;31mperf[mormance improvement was submitted by Domas Mituzas on 10-Feb-2017.
    Description: If there are multiple row versions in InnoDB, reading one row
    from PK may have O(N) complexity and reading from secondary keys may have
    O(N^2) complexity.
    
    The problem occurs when there are many pending versions of the same row,
    meaning that the primary key is the same, but a secondary key is different.
    The slowdown occurs when the secondary index is traversed. This patch
    creates a helper class for the function row_sel_get_clust_rec_for_mysql()
    which can remember and re-use cached_clust_rec & cached_old_vers so that
    rec_get_offsets() does not need to be called over and over for the
    clustered record.
    
    The patch submitted was converted to v8.0 style and structure.  The test case
    was enhanced to use multiple concurrent clients to commit 100 new record
    versions followed by a final record version so that the test case will be consistent.
    A variable length column is added to the table and the final record is shown.

[33mcommit b9b34d501f5ffdeb2ab0a570e2d741ed54a30e83[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Mon Apr 30 15:16:47 2018 +0200

    Bug#27231036 HANDLE_FATAL_SIGNAL (SIG=11) IN DIRNAME_LENGTH
    
    Post push fix for:
    storage/[1;31mperf[mschema/table_helper.cc:436:10: error: 'char* strncpy(char*, const char*, size_t)' specified bound 1024 equals destination size [-Werror=stringop-truncation]
       strncpy(safe_source_file, source_file, sizeof(safe_source_file));
    
    Change-Id: I9cd4c0823b9871ff6a802130aeb1833bb984b748

[33mcommit 9a65c73c5c15923514c236fb1239ee2c2f7524f6[m
Author: Shishir Jaiswal <shishir.j.jaiswal@oracle.com>
Date:   Mon Apr 30 17:35:36 2018 +0530

    Bug#24911117 - SUPER PRIVILEGE NO LONGER REQUIRED TO
                   DISPLAY PASSWORD HASH
    
    DESCRIPTION
    ===========
    As of now any user can view his password hash by executing
    SHOW CREATE USER. It should be viweable only if he has got
    enough privileges.
    
    ANALYSIS
    ========
    append_user_new() generates the IDENTIFIED AS '<hash>' part
    of the output to SHOW CREATE USER. The user, if issues this
    statement for himself, should be able to view the password
    hash only if he can [1;31mperf[morm SELECT on mysql.user table. If
    he can't, he should see <secret> instead of password hash.
    
    FIX
    ===
    We're now checking if or not the user is issuing the SHOW
    CREATE USER for himself in mysql_execute_command(). The
    same is captured in variable 'are_both_users_same' and
    passed to mysql_show_create_user(). If same, we now call
    check_table_access() to fetch privileges for the user and
    decide on if we need to hide the password or not. The same
    is captured in variable 'hide_password_hash'and passed to
    mysql_rewrite_create_alter_user() further to
    append_user_new() where we append either the hash or
    <secret> based on this variable.
    
    The bug was initially reported for both SHOW CREATE USER
    and SHOW GRANTS. This patch just deals with SHOW CREATE
    USER and not with the other. Reason being that SHOW GRANTS
    doesn't show the reported issue till 5.6 (as seen in matrix
    below) and from 5.7+ the IDENTIFIED BY PASSWORD clause was
    removed from it altogether.
    
                          SELF              OTHERS
    Access level
    
    [star].[star]         hash               hash
    mysql.[star]         <secret>           <secret>
    mysql.user           <secret>           Access denied
    default              <secret>           Access denied
    
    NOTE TO THE DOCUMENTATION TEAM
    ==============================
    The doc page says, "The statement requires the SELECT
    privilege for the mysql database, except to display
    information for the current user." This still holds true
    as this patch changes nothing for the case when user
    attempts to [1;31mperf[morm SHOW CREATE USER <other_user>.
    
    With this patch in effect, the documentation should be
    extended as, "For current user, the statement IDENTIFIED AS
    clause displays password hash if he can [1;31mperf[morm SELECT on
    mysql.user table. If he can't he would see <secret> instead
    of password hash.

[33mcommit e20833e4d28168b9894f8d0a2944bb1f7cbe7f57[m
Author: Neha Kumari <neha.n.kumari@oracle.com>
Date:   Mon Apr 30 09:52:29 2018 +0530

    Bug#26450129:DEAD BRANCH IN SEARCH_KEY_IN_TABLE()
    
    Problem:
    
    if (key_type & UNIQUE_KEY_FLAG && table->s->uniques)
      {
        ...
      }
    The condition (table->s->uniques) is always 0 so the if block will never be
    executed. In cases where different primary key is used on master and slave
    and if there is an Unique key present on slave then that should be used for
    lookup created index. Before this bug in above cases a TABLE_SCAN was being
    [1;31mperf[mormed which can be slower than INDEX_SCAN that will be [1;31mperf[mormed after
    the bug fix.
    
    Fix:
    Remove the condition (table->s->uniques).

[33mcommit 53dd3a1ba8e5734096574a93fe2b456fe2aeaa54[m
Author: Maria Couceiro <maria.couceiro@oracle.com>
Date:   Mon Apr 23 15:28:20 2018 +0100

    BUG#27481872 HANDLE_FATAL_SIGNAL (SIG=11) IN TRACE::FUNCTION_ENTER ON INSTALL PLUGIN
    
    Post-push fix.
    
    Problem:
    When the semisync plugin runs the deinit method, it may need to print error, but
    the error log may not have been initialized.
    
    Fix:
    When the plugin was not initialized, the deinit method does not [1;31mperf[morm
    any action.

[33mcommit 2f4b5915607f4b45ffb9d874b6eabba24fe55aa3[m
Author: Pedro Figueiredo <pedro.figueiredo@oracle.com>
Date:   Thu Apr 12 17:44:24 2018 +0100

    Bug#27442477 ASSERT `THD->GET_HA_DATA...HAS_STATE(XID_STATE::XA_ACTIVE))' AT HANDLER.CC:1396
    
    Description
    -----------
    With filter being set on slave, if non-filtered transaction comes post `XA
    ROLLBACK` then it results into ASSERTION failure
    `thd->get_ha_data(ht_arg->slot)->ha_ptr_backup == __null ||
    (thd->get_transaction()->xid_state()-> has_state(XID_STATE::XA_ACTIVE))` at
    handler.cc:1396 in trans_register_ha.
    
    Analysis
    --------
    The replication of empty XA transaction is not currently supported due to the
    "read-only optimization" covered in the X/Open XA transaction standard.
    Furthermore, the usage of replication filters together with XA transaction is
    also not supported.
    
    The assertion occurs because the data engine plugins that initialize Ha_data
    and are called upon `XA START`, are not properly called back to release
    resources, after `XA PREPARE`, due to the transaction being emptied upon
    applying replication filters. One possible reason for this is that the filtered
    statements are not skipped, instead, they are applied but with no actual impact
    either in the data engine or the binlog.
    
    In addition, the internal state of the data engine transaction is changed when
    using `*-log-info-repository=TABLE`, since the `current_thd` is used to [1;31mperf[morm
    the system tables update.
    
    All of the above leaves the replication transaction context state inconsistent
    with the data engine native transaction state, leading, either to the above
    assertion being emited or a segmentation fault being hit when the engine plugin
    tries to use the internal transaction.
    
    This problem is present in 5.7 but it got visible in 8.0.5 because of WL#10474
    making `*-log-info-repository=TABLE` the default options.
    
    Fix
    ---
    This patch doesn't solve the overall issue, dealing with XA transactions working
    together with replication filters. Instead, adds an error message warning about
    the unsupported features and adds some validations that will allow the slave to
    continue running without the stated assertion being met, although in an
    undetermined state:
    
    1. Output an error message stating the unsupported feature of using XA
       transactions together with replication filters.
    
    2. Mirror acquisition of `THD` transaction data - `detach_*` functions - when
       reliquishing the same transaction data - `attach_*` functions - and use this
       execution flow when the `Ha_trx_info` has been cleared and is `nullptr`, in
       `xa.cc: attach_native_trx()`.
    
    3. In the engine data plugin function handling attaching and detaching of the
       native transaction, allow for an empty state, meaning, include a state where
       the current `THD` doesn't have any native transaction associated - output of
       using tables to store the metadata.

[33mcommit 96057437026aca80cb563fbb5096e34b5d173441[m
Author: Pedro Figueiredo <pedro.figueiredo@oracle.com>
Date:   Thu Apr 12 17:38:59 2018 +0100

    Bug#27442477 ASSERT `THD->GET_HA_DATA...HAS_STATE(XID_STATE::XA_ACTIVE))' AT HANDLER.CC:1396
    
    Description
    -----------
    With filter being set on slave, if non-filtered transaction comes post `XA
    ROLLBACK` then it results into ASSERTION failure
    `thd->get_ha_data(ht_arg->slot)->ha_ptr_backup == __null ||
    (thd->get_transaction()->xid_state()-> has_state(XID_STATE::XA_ACTIVE))` at
    handler.cc:1396 in trans_register_ha.
    
    Analysis
    --------
    The replication of empty XA transaction is not currently supported due to the
    "read-only optimization" covered in the X/Open XA transaction standard.
    Furthermore, the usage of replication filters together with XA transaction is
    also not supported.
    
    The assertion occurs because the data engine plugins that initialize Ha_data
    and are called upon `XA START`, are not properly called back to release
    resources, after `XA PREPARE`, due to the transaction being emptied upon
    applying replication filters. One possible reason for this is that the filtered
    statements are not skipped, instead, they are applied but with no actual impact
    either in the data engine or the binlog.
    
    In addition, the internal state of the data engine transaction is changed when
    using `*-log-info-repository=TABLE`, since the `current_thd` is used to [1;31mperf[morm
    the system tables update.
    
    All of the above leaves the replication transaction context state inconsistent
    with the data engine native transaction state, leading, either to the above
    assertion being emited or a segmentation fault being hit when the engine plugin
    tries to use the internal transaction.
    
    This problem is present in 5.7 but it got visible in 8.0.5 because of WL#10474
    making `*-log-info-repository=TABLE` the default options.
    
    Fix
    ---
    This patch doesn't solve the overall issue, dealing with XA transactions working
    together with replication filters. Instead, adds an error message warning about
    the unsupported features and adds some validations that will allow the slave to
    continue running without the stated assertion being met, although in an
    undetermined state:
    
    1. Output an error message stating the unsupported feature of using XA
       transactions together with replication filters.
    
    2. Mirror acquisition of `THD` transaction data - `detach_*` functions - when
       reliquishing the same transaction data - `attach_*` functions - and use this
       execution flow when the `Ha_trx_info` has been cleared and is `nullptr`, in
       `xa.cc: attach_native_trx()`.
    
    3. In the engine data plugin function handling attaching and detaching of the
       native transaction, allow for an empty state, meaning, include a state where
       the current `THD` doesn't have any native transaction associated - output of
       using tables to store the metadata.

[33mcommit 5c9dda425c0bfc88c33ac20badccbad7d789d568[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Apr 12 09:27:13 2018 +0800

    WL#11250 - Support Instant Add Column - Regression
    
    The regression was found in SELECT - OR scenario, which was about 7%-8%
    according to QA.
    
    After testing and verification, two changes would help improve the
    [1;31mperf[mormance, and current regression is only about 1.7% in the SELECT - OR
    scenario, which should be acceptable, because overhead for checking
    instant columns are inevitable.
    
    The two changes are mainly about:
    1. Two different rec_get_nth_field for record with
    (rec_get_nth_field_instant) or without(rec_get_nth_field as is)
    instant columns. Thus for the record without instant columns, there won't
    be extra checking.
    2. Introduce a bit flag in dict_index_t to say if this is clustered index
    with some instant columns, rather than consulting with the table.
    
    From the testing, 1 saved the regression a lot, but without 2, it's not
    good enough. So it would be nice to pick both. Furthermore, with these
    two changes, there are also some small improvement in other testing
    scenarios.
    
    RB: 19392
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 4b609c4c5be0df23eebf26d4d54c3c58b07ff192[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Apr 10 14:57:18 2018 +0200

    Bug#27830283 DROP SCHEMA PERFORMANCE_SCHEMA IS ALLOWED
    
    Before this fix, the statement
      DROP SCHEMA [1;31mperf[mormance_schema;
    was allowed, resulting in a corrupted installation.
    
    The root cause is historical,
    as database creation scripts before MySQL 8.0 used
    to DROP + CREATE the [1;31mperf[mormance_schema schema
    during database installation with an external SQL script,
    so there was a valid use case for DROP SCHEMA.
    
    Starting with 8.0, initialization is done within the server,
    so that allowing DROP SCHEMA (to a user) is no longer necessary.
    
    The fix is to strengthen ACL checks for the [1;31mperf[mormance_schema,
    in PFS_internal_schema_access::check().

[33mcommit d70cf6b7605395f41ad86fbb8059cf83c52357b6[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Wed Apr 11 11:48:52 2018 +0200

    Bug #27523095: SET PERSIST MANDATORY_ROLES FAILS TO START THE SERVER
    
    Problem: During server startup when persisted variables are being set,
    error is reported as there is no enough privileges.
    
    Analysis: System variables like keyring_access, mandatory_roles need dynamic
    privileges only and not SUPER, this is with an intention to slowly get rid of
    SUPER. When these variables are persisted and later during server restart, when
    these variables are applied back on server the privilege check happens in
    corresponding check() functions. Since there is no entry in
    g_dynamic_privileges_map we report error. g_dynamic_privileges_map has a
    mapping between user and its dynamic privilege which is a reflection of
    mysql.global_grants table, in this case since it was during server startup
    phase where in THD::Security_context::m_user is empty string, thus the lookup
    into g_dynamic_privileges_map fails.
    
    Fix: Fix is to introduce a new Security_context_factory class whose primary
    functionality is to return an immutable security_context based on passed in
    user profile. User profile is this case represents a bootstrap user with only
    needed dynamic privileges. This returned security_context is further set in
    current THD. Once all needed operations are [1;31mperf[mormed, security_context is
    dropped.

[33mcommit 3b3d3ebfda7bb24355adf284819d47d58c2f65b0[m
Author: Mohit Joshi <mohit.joshi@oracle.com>
Date:   Thu Apr 5 07:34:32 2018 +0530

    WL#10928 - MTR: Improvements to --check-testcases option
    
    Description:
    ===========
    This WL focuses on improving check-testcases logic in MTR. MTR check-testcases
    [1;31mperf[morm checks just before and after the test execution to ensure there are no
    changes in the internal state of the Database.
    
    Multiple scenarios were seen where the test does not [1;31mperf[morm cleanup after itself
    eg - (check for persisted variables, check for leftover files in var/tmp dir) etc
    
    Solution:
    ========
    Below are the new checks introduced as part of WL#10928:
    
    1. check for persisted variables.
    2. check for any left behind tablespaces.
    3. check for any active/open connection.
    4. check for any left-over files.
    5. check for installed plugins/components.
    6. check for new plugin/component variables.
    7. check for new UDFs.
    
    Reviewed by:
    ===========
    Pavan Naik <pavan.naik@oracle.com>
    Srikanth B.R <srikanth.b.r@oracle.com>
    Narendra Chauhan <narendra.chauhan@oracle.com>

[33mcommit 4524b5f8da014b2d40932cc3c7095c3ac53dd282[m
Author: Annamalai Gurusami <annamalai.gurusami@oracle.com>
Date:   Wed Apr 4 20:31:40 2018 +0530

    WL#11328 InnoDB: Optimizing Small Changes to BLOBs
    
    This is a follow up worklog for WL#8960.  In WL#8960, the minimum
    change to a BLOB is a single LOB page.  Even if only a few bytes are
    modified, minimum one LOB page will be modified.  So, there is scope
    for improvement for small changes to the BLOBs.
    
    The solution provided by WL#8960 is a general solution suitable for
    all sizes of BLOBs and for all size of changes (from few bytes to even
    1GB of changes).  But it is less efficient for small changes done to
    the BLOBs.  Also, in the case of WL#8960, the old versions of BLOBs
    are stored in the BLOB itself.  Undo log format is not changed.
    
    To optimize small changes to the BLOBs, we plan to do the regular undo
    logging.  For this the undo log format needs to be changed.  When a
    BLOB is modified/updated, then we need to store the old and new
    portion of the BLOB in the undo log record.  Currently there is a
    restriction that the undo log record must fit within an undo log page.
    We need to [1;31mperf[morm our operation within that constraint.

[33mcommit 4f60979a2d6aa05338d48dbc4513eb93df6f8e2f[m
Author: Jakub Łopuszański <jakub.lopuszanski@oracle.com>
Date:   Wed Apr 4 12:46:23 2018 +0200

    BUG#27572937 USING VATS WITH SPATIAL INDEX CAN LEAD TO TRANSACTION NEVER BEING WOKEN UP
    
    - lock_use_fcfs now looks at particular lock, not just lock->trx, and checks its type. Only "regular" (non-predicate) row locks can use CATS now
    - creating a new MTR test which reproduces the most important problem
    - removal of unnecessary cleanup from MTR test
    - moving the requirement for DBUG_SYNC utility to the top of MTR file, as it wis required by all tests in that file
    - removal of lock_rec_enqueue_waiting declaration, which had no definition
    - removal of unused lock_table_get_n_locks
    - removal of unused variant of Lock_iter::for_each
    - removal of misleading comments about "next"<->"prev" for table locks which should have been removed in e47f04c145cf778b9ad47ad8957f42a6daaadd5b as part of https://clustra.no.oracle.com/orabugs/bug.php?id=21983865
    - adding ut_ad()s reflecting assumptions stated in comments or required for the code to run correctly (in particular in places which assume that a lock is not a predicate lock)
    - removal of unnecessary checking of conditions which were already checked a few lines above
    - a small optimization to RecLock::lock_add so that the loop searching for a similar lock is only [1;31mperf[mormed if we can actually use this similar lock (lock_type is not LOCK_WAIT)
    - removal of misleading comments about appending/splicing the grant list which have nothing to do with the actuall code nearby
    - removal of redundant trx argument from lock_rec_unlock_grant (it is always equal to lock->trx)
    - added some explanation for the special case for CATS in assert inside get_first_lock
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>

[33mcommit 289c9e2d8455a62bfd35b6c966b6c6371a8801db[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Fri Mar 16 10:56:21 2018 +0100

    Bug#27407745 USE UTF8MB4 FOR PERFORMANCE_SCHEMA
    
    The UTF8MB3 character set is deprecated in 8.0
    
    Migrate [1;31mperf[mormance_schema tables to UTF8MB4.
    
    In particular:
    - change UTF8 (meaning UTF8MB3) character set to UTF8MB4
    - change utf8_bin collations to utf8mb4_bin
    - change utf8_general_ci collation to the default (utf8_0900_ai_ci)
    
    Adjust all test cases accordingly.

[33mcommit f46fe72ca7b0d9120eca2926e6a53bbd7d593553[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Fri Jan 26 12:35:27 2018 +0100

    Bug #27629719: SET PERSIST STORES TRUNCATED TIMESTAMPS
    
    Increased the resolution of the peristed variables timestams to the
    maximum allowed.
    Increased the delcared resoltion of
    [1;31mperf[mormance_schema.variables_info.set_time used to display these.
    Added a test to make sure the fractional seconds are operational.
    Bumped the pfs version

[33mcommit bd8eb01b550dd97f7bcbedc2e0f9393ca8d5527c[m
Author: Debarun Banerjee <debarun.banerjee@oracle.com>
Date:   Wed Mar 14 14:04:39 2018 +0530

    BUG#27661171 INNODB: TRX->DECLARED_TO_BE_INSIDE_INNODB
    
    Problem :
    --------
    We enter innodb in partition row write to order Auto INC partition lock
    after Innodb. In Innodb we would try re-enter independently. This works
    fine as long as we have enough tickets left.
    
    While [1;31mperf[morming bulk load we could consume all innodb tickets
    [innodb_concurrency_tickets = 5000 by default] within same statement.
    If the partition write happens to consume the last ticket, we face this
    issue trying to enter once again in innobase write.
    
    Solution :
    ----------
    No need to enter innodb in partition write if there are tickets left.
    
    1. We avoid consuming the last ticket as there could be another enter
       call from innobase.
    
    2. If we enter innodb here, there is at least one more ticket left as
       the minimum value for "innodb_concurrency_tickets" is 1.
    
    Reviewed-by: Jimmy Yang <Jimmy.Yang@oracle.com>
    
    RB: 19092

[33mcommit 97cf6dd301bec0de017123ee82f2dc59fc389be7[m
Author: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
Date:   Mon Mar 19 18:45:50 2018 +0100

    Bug #27691698: UNDEFINED BEHAVIOR WHEN ACCESSING XPLUGIN STATUS VARIABLES
    
    Description:
    All tests in the x test suite give UBSAN warnings:
    storage/[1;31mperf[mschema/pfs_variable.cc:1386:9:
    runtime error: call to function
    void xpl::Server::global_status_variable_server<long long,
    &xpl::Global_status_variables::m_aborted_clients>(THD*, SHOW_VAR*, char*)
    through pointer to incorrect function type
    'int (*)(THD *, SHOW_VAR *, char *)'
    
    Reviewed-by: Lukasz Kotula <lukasz.kotula@oracle.com>
    Reviewed-by: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>
    RB:19183

[33mcommit 5757d750b30408ee477ad3d05e93acebf292723f[m
Author: Mohit Joshi <mohit.joshi@oracle.com>
Date:   Fri Mar 23 12:17:12 2018 +0530

    WL#10928 - MTR: Improvements to --check-testcases option
    
    Description:
    ===========
    This WL focuses on improving check-testcases logic in MTR. MTR check-testcases
    [1;31mperf[morm checks just before and after the test execution to ensure there are no
    changes in the internal state of the Database.
    
    Multiple scenarios were seen where the test does not [1;31mperf[morm cleanup after itself
    eg - (check for persisted variables, check for leftover files in var/tmp dir) etc
    
    Solution:
    ========
    Below are the new checks introduced as part of WL#10928:
    
    1. check for persisted variables.
    2. check for any left behind tablespaces.
    3. check for any active/open connection.
    4. check for any left-over files.
    5. check for installed plugins/components.
    6. check for new plugin/component variables.
    7. check for new UDFs.
    
    Reviewed by:
    ===========
    Pavan Naik <pavan.naik@oracle.com>
    Srikanth B.R <srikanth.b.r@oracle.com>
    Narendra Chauhan <narendra.chauhan@oracle.com>

[33mcommit 41e975467d9c986200b6a0bdaaf807b473b35cfa[m
Author: Rahul Sisondia <rahul.sisondia@oracle.com>
Date:   Wed Mar 21 11:36:04 2018 +0100

    Bug#27454299 SYSTEM USERS USING MYSQL_NATIVE_PASSWORD WHEN
                 CACHING_SHA2_PASSWORD IS DEFAULT
    
    Description
    ------------
    While fixing this bug last time I chose the 1000 iterations to generate the
    digest for these 3 system users. I assumed that they are locked users and not
    used for internal purpose.
    
    Harin however had a different opinion that we must be consistent with the
    default behavior of caching_sha2_passwprd plugin which does the 5000 iterations
    to create digests. It will be consistent and there is not really any [1;31mperf[mormance
    impact during initilzation/upgrade. Hence this change.
    
    Review:
    -------
    RB#18957

[33mcommit 4b50da702289dd230f99682a11a348486dcc0e2e[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Fri Mar 16 10:56:21 2018 +0100

    Bug#27407745 USE UTF8MB4 FOR PERFORMANCE_SCHEMA
    
    The UTF8MB3 character set is deprecated in 8.0
    
    Migrate [1;31mperf[mormance_schema tables to UTF8MB4.
    
    In particular:
    - change UTF8 (meaning UTF8MB3) character set to UTF8MB4
    - change utf8_bin collations to utf8mb4_bin
    - change utf8_general_ci collation to the default (utf8_0900_ai_ci)
    
    Adjust all test cases accordingly.

[33mcommit e97625072228ebeb24d860b695fc2ed53b7813d5[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Mar 14 09:06:19 2018 +0100

    BUG#27647918 PFS MUTEX CLASSES MAXED AT 256
    
    Before this fix, the maximum value for
    variable [1;31mperf[mormance-schema-max-mutex-classes
    is limited to 256.
    
    This limit is artificial, and prevents to add
    more instrumentation.
    
    This fix raised limits to [1;31mperf[mormance schema
    configuration variables to 1024,
    and raised the default value of
    [1;31mperf[mormance-schema-max-mutex-classes to 300.

[33mcommit 180006187e8d6ce9131d3fe598d14278975b5733[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Mar 14 15:54:39 2018 +0100

    Bug#27407745 USE UTF8MB4 FOR PERFORMANCE_SCHEMA
    
    Revert previous changes,
    restore the [1;31mperf[mormance_schema to UTF8MB3.

[33mcommit ac8d4d6d955b3f0315ad316206849395dd3ecdec[m
Author: Debarun Banerjee <debarun.banerjee@oracle.com>
Date:   Wed Mar 14 14:04:39 2018 +0530

    BUG#27661171 INNODB: TRX->DECLARED_TO_BE_INSIDE_INNODB
    
    Problem :
    --------
    We enter innodb in partition row write to order Auto INC partition lock
    after Innodb. In Innodb we would try re-enter independently. This works
    fine as long as we have enough tickets left.
    
    While [1;31mperf[morming bulk load we could consume all innodb tickets
    [innodb_concurrency_tickets = 5000 by default] within same statement.
    If the partition write happens to consume the last ticket, we face this
    issue trying to enter once again in innobase write.
    
    Solution :
    ----------
    No need to enter innodb in partition write if there are tickets left.
    
    1. We avoid consuming the last ticket as there could be another enter
       call from innobase.
    
    2. If we enter innodb here, there is at least one more ticket left as
       the minimum value for "innodb_concurrency_tickets" is 1.
    
    Reviewed-by: Jimmy Yang <Jimmy.Yang@oracle.com>
    
    RB: 19092

[33mcommit 7a689acaa65e9d602575f7aa53fe36a64a07460f[m
Author: Krzysztof Kapuścik <krzysztof.kapuscik@oracle.com>
Date:   Tue Mar 13 12:34:03 2018 +0100

    Bug#27082268 Invalid FTS sync synchronization
    
    The fix closes two issues:
    Bug #27082268 - INNODB: FAILING ASSERTION: SYM_NODE->TABLE != NULL DURING FTS SYNC
    Bug #27095935 - DEADLOCK BETWEEN FTS_DROP_INDEX AND FTS_OPTIMIZE_SYNC_TABLE
    
    Both issues were related to a FTS cache sync being done during
    operations that [1;31mperf[momed DDL actions on internal FTS tables
    (ALTER TABLE, TRUNCATE). In some cases the FTS tables and/or
    internal cache structures could get removed while still being
    used to [1;31mperf[morm FTS synchronization leading to crashes. In other
    the sync operations could not get finishes as it was waiting for
    dict lock which was taken by thread waiting for the background
    sync to be finished.
    
    The changes done includes:
    - Stopping background operations during ALTER TABLE and TRUNCATE.
    - Removal of unused code in FTS.
    - Cleanup of FTS sync related code to make it more readable and
    easier to maintain.
    
    RB#18262

[33mcommit aa81a9690dc31fec0d55947fdc610a1d682dae51[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Sat Mar 10 08:33:53 2018 +0100

    BUG#27525856: RPL_GTID.RPL_GTID_PERFSCHEMA_APPLIER_XA_STATUS FAILS SPORADICALLY
    
    Update result file for rpl_[1;31mperf[mschema_applier_xa_status_check

[33mcommit fce60a0822a28e7282f4c1179ed123a97ae7b75b[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Thu Mar 8 14:53:12 2018 +0100

    Bug #27629719: SET PERSIST STORES TRUNCATED TIMESTAMPS
    
    Increased the resolution of the peristed variables timestams to the
    maximum allowed.
    Increased the delcared resoltion of
    [1;31mperf[mormance_schema.variables_info.set_time used to display these.
    Added a test to make sure the fractional seconds are operational.
    Bumped the pfs version

[33mcommit f0ddfc9083bd1211f21f4b0bfb563132e9bd005f[m
Author: Sven Sandberg <sven.sandberg@oracle.com>
Date:   Wed Feb 28 19:44:57 2018 +0100

    BUG#27525856: RPL_GTID.RPL_GTID_PERFSCHEMA_APPLIER_XA_STATUS FAILS SPORADICALLY
    
    Problem:
    
    rpl_gtid.rpl_gtid_[1;31mperf[mschema_applier_xa_status fails sporadically on
    pushbuild.
    
    Analysis:
    
    The test executes XA PREPARE and then XA COMMIT on master.  After each
    statement, it waits for the slave to sync, and then it checks that
    [1;31mperf[mormance_schema.events_transactions_current and XA RECOVER contain
    up to date information.  The sync is done using
    WAIT_FOR_GTID_EXECUTED.  However, the information is published in
    gtid_executed before [1;31mperf[mormance_schema and XA RECOVER.  So it is
    possible that the test sees old information.
    
    Fix:
    
    Make the test wait for [1;31mperf[mormance_schema information to be up to
    date.  Then XA RECOVER is also up to date.

[33mcommit c8afbca3ae5a450b7f46d7813cdd105337779ec6[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Mar 8 14:35:39 2018 +0100

    Bug#27407745 USE UTF8MB4 FOR PERFORMANCE_SCHEMA
    
    The UTF8MB3 character set is deprecated in 8.0
    
    Migrate [1;31mperf[mormance_schema tables to UTF8MB4.
    
    Part 4: misc test cleanup.

[33mcommit adff669984f9765a662481229ebbc07276e1cce7[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Mar 7 11:07:04 2018 +0100

        Bug#27407745 USE UTF8MB4 FOR PERFORMANCE_SCHEMA
    
        The UTF8MB3 character set is deprecated in 8.0
    
        Migrate [1;31mperf[mormance_schema tables to UTF8MB4.
    
        Part 3: adjust test suite for engines/funcs

[33mcommit fcb94b35ac8fb0e715315909ab6c74f6387b05cf[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Mar 7 00:31:17 2018 +0100

    Bug#27407745 USE UTF8MB4 FOR PERFORMANCE_SCHEMA
    
    The UTF8MB3 character set is deprecated in 8.0
    
    Migrate [1;31mperf[mormance_schema tables to UTF8MB4.
    
    Part 2: adjust test suite.

[33mcommit 2236e07f78987130864c3b403d6a39033943210d[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Fri Jan 26 12:35:27 2018 +0100

    Bug#27407745 USE UTF8MB4 FOR PERFORMANCE_SCHEMA
    
    The UTF8MB3 character set is deprecated in 8.0
    
    Migrate [1;31mperf[mormance_schema tables to UTF8MB4.
    
    In particular:
    - change UTF8 (meaning UTF8MB3) character set to UTF8MB4
    - change utf8_bin collations to utf8mb4_bin
    - change utf8_general_ci collation to the default (utf8_0900_ai_ci)
    
    Adjust all test cases accordingly.

[33mcommit 86fa9d83cb6965be8f820fdc7e7e36f4332eef86[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Mar 5 16:30:12 2018 +0100

    Bug#27566220 PFS STAGE REAPPEARING WITHOUT BEING SET
    
    Before this fix,
    spurious stages can be seen in table
    [1;31mperf[mormance_schema.events_stages_current.
    
    The root cause is that some threads may terminate
    with an open stage.
    Then, later, a new thread is started,
    which reuse the same memory for the thread instrumentation.
    
    Function create_thread() in pfs_instr.cc does not
    explicitly reset the current stage,
    so a left over stage from another thread run could be seen.
    
    The fix is to reset the current stage in create_thread()
    when a new thread instrumentation is created.

[33mcommit 3a77858b4e467cded0f248dc1d70615e7048f5a9[m
Author: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>
Date:   Fri Mar 2 11:37:43 2018 +0100

    Bug#27470083 - MYSQLXCLIENT PERFORMANCE DEGRADATION CAUSE BY NAGLE'S ALGORITM
    
    X plugin client <-> server communication [1;31mperf[mormance improvements:
    1) disabling Nagle's algorithm by enabling TCP_NODELAY
    2) sending message header with payload combined in one message
    
    RB: 18994
    Reviewed by: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
    Reviewed by: Lukasz Kotula <lukasz.kotula@oracle.com>

[33mcommit b4de9f22b1b1aa8e9aac97b456ac1236737e445e[m
Author: Lukasz Kotula <lukasz.kotula@oracle.com>
Date:   Wed Feb 28 22:42:40 2018 +0100

    BUG#27463149 - SCALABILITY ISSUE WITH XPLUGINS MESSAG_BUILDER
    
    Description
    ===========
    Reception of a resultset in X Protocol consists of multiple protocol
    messages. X Plugin allocates CodedOutputStream on heap for each
    protocol message. The allocation degrades [1;31mperf[mormance:
    
    *  PFS OFF - degradation around 3% for point_select test
    *  PFS ON - degradation around 100%-300% for point_select test
    
    Fix
    ===
    The memory region for CodedOutputStream is allocated once, and for
    each message the object is created by placement new operator.
    
    RB:18975
    Reviewed-by: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>
    Reviewed-by: Andrzej Religa <andrzej.reliaga@oracle.com>

[33mcommit 79a27190c16f87733f64f9f10e9823998b072e9f[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Mar 1 14:40:41 2018 +0100

    Bug#27500610 - PERFORMANCE SCHEMA MEMORY INSTRUMENTATION CAUSES OVERHEAD
    
    Before this fix,
    
    the [1;31mperf[morance schema memory instrumentation
    could cause runtime overhead when enabled.
    
    The root cause is due to instruments with the following properties:
    - the instrument flags are 0,
      defined as per thread and not global
    - the instrumented memory is allocated / freed
      very often during execution
    - the instrumented memory can be allocated by one thread
      and freed by a different thread.
    
    Not having the global (PSI_FLAG_ONLY_GLOBAL_STAT) flag
    indicates that the [1;31mperf[mormance schema should maintain:
    - per thread stats
    - per account stats
    - per user stats
    - per host stats
    as well as global statistics.
    
    Frequent instrumentation, and memory transfer of ownership between threads,
    causes a lot of overhead when maintaining the high/low water mark.
    
    The affected code to maintain high/low water marks is:
    - PFS_thread::carry_memory_stat_delta()
    - PFS_account::carry_memory_stat_delta()
    - PFS_user::carry_memory_stat_delta()
    - PFS_host::carry_memory_stat_delta()
    
    This fix requalifies many memory instruments as global,
    with the flag PSI_FLAG_ONLY_GLOBAL_STAT.
    
    This is a fix for both:
    
    1) Correctness.
    
    Instruments that keep track of a global resource,
    for example "memory/sql/host_cache::hostname",
    are by definition global.
    Keeping per thread stats is meaningless.
    
    2) Performances.
    
    This avoids keeping track of high/low watermarks,
    and reduce overhead.
    
    Also, a minor bug was fixed in pfs_memory_claim_v1(),
    which did not honor the PSI_FLAG_ONLY_GLOBAL_STAT flag.

[33mcommit 99db4db122b87ec8fae36bd48311ea415d31eb3d[m
Author: Harin Vadodaria <harin.vadodaria@oracle.com>
Date:   Thu Mar 1 06:35:22 2018 +0100

    Bug#27306178: ERROR IN SERVER HANDSHAKE WHILE CONNECTING
                  WITH AUTH_SOCK PLUGIN USER
    
    Description: On client side, if server's default plugin is
                 different than that of client, client discards
                 packet containing scramble information. This
                 means that if server has default plugin
                 caching_sha2_password and client has default
                 plugin mysql_native_password, and if client is
                 trying to connect to server using a user with
                 plugin C (in this case auth_socket), following
                 will happen:
    
                 1. Client will discard scramble data
                 2. Client will call native_password's client
                    side authentication plugin
                 3. In client_mpvio_read_packet, client will
                    send user details to server and wait for
                    scramble
                 4. Server, having received user details, goes
                     on to process client reply and finds that
                     there are 3 plugins involved. It then
                     triggers a RESTART of authentication on
                     server side without sending anything to
                     client. As a part of restart, server uses
                     user's actual plugin (auth_socket) and
                     calls authenticate API for the same.
                 5. auth_socket plugin, having received user
                    details and connection info, [1;31mperf[morms
                    verification and sends OK/ERROR.
                 6. On client side, since client expects random
                    data of length 20 from server, native
                    plugin's authentication API will report
                    error upon receing OK/ERROR.
                 7. run_plugin_auth() won't find expected reply
                    (because OK/ERROR was already read) and
                    exit with error.
    
    Solution: In run_plugin_auth(), there is a check for
              auth-switch packet. Fix is to extend it to cover
              OK packet too.

[33mcommit f538f4b841466c9e311d369bd616e802272b2f50[m
Author: Allen Lai <zheng.lai@oracle.com>
Date:   Wed Feb 28 22:08:39 2018 +0800

    Bug#26381207 GIS INDEX CORRUPTION INNODB: INDEX MLS IS MARKED AS CORRUPTED
    
    Problem:
    The index "mls" got more row count than cluster index cuased it marked as corrupted. But the R-tree
    is valid, the problem is in the search for row counting of r-tree. From the printout, it shows
    there're 2 duplicate recs in rtree, and they're in different pages, one of them is marked as
    deleted, the other one is not, then they're all counted. Why there're dup recs? It's because
    there're overlap area in the father's MBRs. Point update in/out this overlap area caused this.
    
    Solution:
    Currently, it's not easy to fix the point update issue, since it will cause [1;31mperf[mormance issue of
    search for insert. So, here we just provide a work around fix, that is check if there're dup recs in
    counting rows of rtree. If there are, then count them as tolerate number and the mismatch count <
    tolerate number, don't report index corruption.
    
    Reviewed-By: Jimmy Yang <jimmy.yang@oracle.com>
    RB:18917

[33mcommit e00bc60bfbc4c44e6c9c6821fd10b75463af018a[m
Author: Jaideep Karande <jaideep.karande@oracle.com>
Date:   Wed Feb 28 12:25:05 2018 +0100

    Bug#27581984: GROUP_REPLICATION.GR_NOTIFICATIONS_QUORUM FAILS SPORADICALLY ON PB2
    
    Problem: Test case GROUP_REPLICATION.GR_NOTIFICATIONS_QUORUM fails sporadically
    
    Description:
    The problem is happening due to a concurrency issue between updating the
    [1;31mperf[mormance schema table(replication_group_members) and updating the
    notification tables created by the test case(gms_listener_example).
    
    The sequence of steps that causes the failures is the to the following:
    
    1 - A group with two nodes is created: N1 and N2.
    2 - Node N2 is killed creating a majority loss
    3 - The test waits until the remaining node N1 detects that the other
        node N2 is unreachable.
    4 - The notification table is truncated in order to remove notification
        events generated by the majority loss.
    5 - The group replication is stopped on node N1.
    6 - The notification events generated by the stop operation are
        verified and the following is expected:
    
        VIEW CHANGED:
        STATE CHANGED:
    
        The empty view information denotes that the node is leaving
        the group.
    
    Issue:
    There is a concurrency issue between step 3 and 4. N2 may become
    unreachable allowing the test case to skip UNREACHABLE state wait condition
    and continue with truncate of listener table.
    But there is no guarantee that all events have been broadcasted to the
    listener. So these events might be inserted in the table after it has been
    truncated thus causing the current failure.

[33mcommit c38107622d1849f5a423b5b8d2ab72f1dc129af3[m
Author: Nuno Carvalho <nuno.carvalho@oracle.com>
Date:   Fri Feb 23 15:09:24 2018 +0100

    BUG#27584694: GROUP_REPLICATION.GR_ADDMEMBER_INSERT_ON_DONOR FAILS SPORADICALLY IN PB
    
    There was a concurrency issue in the test case which [1;31mperf[morms
    updates in the donor server while the recovery is on-going and is
    expecting that these updates are transferred as part of the
    recovery. However, the recovery may finish before the updates are
    applied on the recovering member thus making the test fail.
    
    Since the locked table is t1, use it to ensure that data committed
    during recovery is eventually applied on the joiner when its status
    changes to ONLINE.

[33mcommit db3b4c462c1fb4e26e7f01141125223ffdbba54f[m
Author: Harin Vadodaria <harin.vadodaria@oracle.com>
Date:   Wed Feb 21 12:08:08 2018 +0100

    Bug#27335346: SYSBENCH CONNECT TEST SHOWS -14% REGRESSION
                  FOR ROOT USER WITOUT PASSWORD
    
    Description: Plugin lock optimization were missing for
                 caching_sha2_password. This resulted into one
                 lock/unlock per connection.
                 This impacted [1;31mperf[mormance.
    
    Solution: Lock built-in plugins at server startup and keep
              them locked till server shutdown. Also, use these
              plugin handles instead of going through
              lock/unlock at the time of connection.

[33mcommit 4cc3739a29416192b59fc552e01e0ef549689e0a[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Wed Feb 7 12:22:13 2018 +0100

    Bug #27402243: DC->FETCH_GLOBAL_COMPONENTS(DD::TABLESPACES)
                   TAKES TOO MUCH TIME WITH 1MILLION
    
    Problem: Bad [1;31mperf[mormance when fetching DD objects by first
    reading the object ids followed by uncached acquisition of
    the individual objects.
    
    Analysis: May combine the two loops and read objects based
    on the record at hand instead of just fetching the id and
    reading the object in a second loop. However, reading the
    record (with children) must be done in a separate transaction
    since we may otherwise end up opening the same index twice
    (e.g. when reading dd::Table objects), which is not supported.
    
    Solution: The fix, as indicated above, improves [1;31mperf[mormance
    of this step by about 20%. The objects being read are added
    to the auto delete structure in the dictionary client to keep
    the object ownership the same as it was before this patch.
    Thus, the fetch() method is now a member of the dictionary
    client, and both the method itself and methods calling it are
    hence now non-const.
    
    Fetching the tablespace objects is done to populate the DD
    cache in InnoDB. After fetching the objects, InnoDB is
    validating the tablespace files by opening them. This phase
    takes a considerable amount of time, and it might be considered
    whether the fetching and validation could be done on demand
    rather than up front. Bug#27556902 is filed to track this issue.
    
    Change-Id: I3202e1529bc9f9209d12415aeca12aa8c1a196bc

[33mcommit f9598a432afe345b946ff91a11ce2db4c957b823[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Feb 20 15:37:15 2018 +0100

    Bug#27545688 PFS.THREADS TABLE PROCESSLIST_STATE ENFORCES 64 CHARS FOR A 128 CHARS STAGES
    
    Before this fix, a stage with a very long name
    could cause an assert in debug mode,
    when printing column PROCESSLIST_STATE
    in table [1;31mperf[mormance_schema.threads.
    
    The root cause is the assert itself,
    it was added as a way to detect very long stage names,
    but was not placed in the proper location.
    
    A much better way would be to check the length
    of a stage EVENT_NAME when registering the stage,
    not when printing it.
    
    Given that there are likely already stages with
    long names instrumented, enforcing such limit now
    is not desirable.
    
    This fix silently truncates the stage name
    when printing the PROCESSLIST_STATE column
    in table [1;31mperf[mormance_schema.threads,
    as this is the best way to provide backward
    compatibility with the historical
    SHOW PROCESSLIST / I_S.PROCESSLIST
    behavior (with a 64 char limit on STATE),
    while keeping instrumentation with descriptive
    names in other [1;31mperf[mormance schema tables.

[33mcommit 97f52dc836ee46f2c9c47096737258004daf728e[m
Author: Ole-Hjalmar Kristensen <Ole-Hjalmar.Kristensen@oracle.com>
Date:   Tue Feb 20 15:08:27 2018 +0100

    Fix for Bug #26771524   MONOTONIC CLOCK IS MISSING IN XCOM
    
    The problem is that the internal tasks in xcom waiting for a timeout will get
    stuck if someone changes the system clock back in time.
    
    This patch creates a replacement monotonic clock function based on [1;31mperf[mormance counters
    in Windows and based on clock_gettime on Posix.

[33mcommit 295bad1b1c7be928d08e82b506b0238a8ead61fd[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Feb 20 14:48:44 2018 +0100

    Bug#27471510 PERFORMANCE_SCHEMA STATUS AND VARIABLE BY THREAD ARE NOT SAFE
    
    Patch for 8.0.
    
    Before this fix, executing:
      SELECT * FROM [1;31mperf[mormance_schema.status_by_thread
      SELECT * FROM [1;31mperf[mormance_schema.variables_by_thread
    under heavy load was unsafe.
    
    Root cause 1
    ============
    
    SELECT * from [1;31mperf[mormance_schema.status_by_thread
    inspects the status variables of running sessions.
    
    For sessions using SSL, SSL status variables are inspected.
    
    For example, the status variable "Ssl_cipher_list" is evaluated
    by executing function show_ssl_get_cipher_list()
    
    This function is implemented as follows:
    
    show_ssl_get_cipher_list()
    {
      if (thd->get_protocol()->get_ssl()) // (a)
      {
        ...
        SSL_get_cipher(thd->get_protocol()->get_ssl())); // (b)
        ...
      }
    }
    
    The problem is that evaluating
      thd->get_protocol()->get_ssl()
    to access the underlying SSL structure is unsafe,
    and subject to race conditions.
    
    The value returned in (a) can change by the time (b)
    is evaluated, for example when using prepared statements,
    because the thd->get_protocol() pointer will change
    during execution of PREPARE and EXECUTE.
    
    Fix 1
    =====
    
    thd->get_protocol()->get_ssl()
    is not a proper way to access SSL data for the session.
    
    Instead, THD::m_SSL now keeps the SSL data attached to the
    THD session.
    
    THD::m_SSL is set after the SSL connection is established,
    is reset upon disconnect,
    and is immutable during the session execution.
    
    Inspecting this attribute is safe when LOCK_thd_data is held,
    which make table [1;31mperf[mormance_schema.status_by_thread safe.
    
    Root cause 2
    ============
    
    SELECT * from [1;31mperf[mormance_schema.variables_by_thread
    inspects the variables of running sessions.
    
    In particular, variable "session_track_system_variables"
    is inspected.
    
    This variable value is stored in THD::variables.track_sysvars_ptr
    
    On the session connection,
      THD::variables.track_sysvars_ptr
    is duplicated and points to allocated memory,
    in this call:
        thd->session_sysvar_res_mgr.init(&thd->variables.track_sysvars_ptr,
    thd->charset());
    
    This is because Session_sysvar_resource_manager::init()
    modifies the THD::variables.track_sysvars_ptr pointer itself.
    
    On session disconnect,
      Session_sysvar_resource_manager::deinit()
    free the allocated memory,
    which leaves the THD::variables.track_sysvars_ptr pointer
    invalid, referencing freed memory.
    
    As soon as cleanup_variables() unlocks LOCK_thd_data,
    a race condition is possible,
    when using the now invalid THD::variables.track_sysvars_ptr pointer.
    
    Fix 2
    =====
    
    In cleanup_variables(),
    clear the offending pointer before freeing the underlying memory
    with the call to session_sysvar_res_mgr.deinit()
    
    This makes table [1;31mperf[mormance_schema.variables_by_thread safe.

[33mcommit 6be2fa0bdbbadc52cc8478b52b69db02b0eaff40[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Wed Feb 14 09:33:42 2018 +0100

    WL#10310 Redo log optimization: dedicated threads and concurrent log buffer.
    
    0. Log buffer became a ring buffer, data inside is no longer shifted.
    
    1. User threads are able to write concurrently to log buffer.
    
    2. Relaxed order of dirty pages in flush lists - no need to synchronize
       the order in which dirty pages are added to flush lists.
    
    3. Concurrent MTR commits can interleave on different stages of commits.
    
    4. Introduced dedicated log threads which keep writing log buffer:
        * log_writer: writes log buffer to system buffers,
        * log_flusher: flushes system buffers to disk.
       As soon as they finished writing (flushing) and there is new data to
       write (flush), they start next write (flush).
    
    5. User threads no longer write / flush log buffer to disk, they only
       wait by spinning or on event for notification. They do not have to
       compete for the responsibility of writing / flushing.
    
    6. Introduced a ring buffer of events (one per log-block) which are used
       by user threads to wait for written/flushed redo log to avoid:
        * contention on single event
        * false wake-ups of all waiting threads whenever some write/flush
          has finished (we can wake-up only those waiting in related blocks)
    
    7. Introduced dedicated notifier threads not to delay next writes/fsyncs:
        * log_write_notifier: notifies user threads about written redo,
        * log_flush_notifier: notifies user threads about flushed redo.
    
    8. Master thread no longer has to flush log buffer.
    
    9. Introduced dedicated log thread which is responsible for writing checkpoints.
       No longer concurrent user threads need to compete for this responsibility.
    
    10. Master thread no longer has to take care of periodical checkpoints.
        Log checkpointer thread writes checkpoint at least once per second
        (before it was once per 7 seconds).
    
    11. The following exposed system variables, can be changed in runtime now:
        * innodb_log_buffer_size,
        * innodb_log_write_ahead_size.
    
    12. Master thread measures average global cpu usage in OS.
    
    13. Introduced new exposed system variables:
        * innodb_log_wait_for_flush_spin_hwm,
        * innodb_log_spin_cpu_abs_lwm,
        * innodb_log_spin_cpu_pct_hwm.
        They control when we need to use spinning for the best [1;31mperf[mormance,
        to reduce latency which would otherwise come from communication
        between log threads and user threads. The first one is based on
        average flush time, the two others are based on cpu usage.
    
    14. Introduced new CMake option: ENABLE_EXPERIMENT_SYSVARS=0/1. System variables
        can be marked as hidden unless the experiment mode is turned on.
    
    15. There is a list of hidden new system variables for experiments with redo log.
        We skip listing them here.
    
    16. Created dedicated tester for redo log alone (as gtest).
    
    17. Created doxygen documentation for the new redo log.
    
    18. The dict_persist margin is updated when number of dirty pages is
        changed, instead of calculations on demand.
    
    19. Mechanism used to copy last incomplete block for Clone has been changed,
        because log buffer is concurrent now.
    
    20. Added more useful MONITOR counters for redo, including average lsn rate.
    
    21. Introduced sharded rw-lock to have an option to stop the world in redo,
        because log_mutex is removed.
    
    22. Invented and implemented a concurrent data structure which tracks progress
        of concurrent operations and can answer up to which point they all have been
        finished (when there is some order defined but they are allowed to be executed
        out of the order). This structure is used for concurrent writes to log buffer
        and re-used for concurrent additions to flush lists.
    
    23. Introduced a universal mechanism to wait on event, which starts with
        provided number of spin delays, then fallbacks to waits on event,
        starting at small timeout, but increasing timeout every few waits.
        This mechanism is used in communication between user and log threads,
        and in communication between different log threads.
    
    24. We slow-down redo log writer when there is no space in redo allowing
        checkpoints to progress and rescue the state of redo.
    
    25. Log buffer can be resize in runtime - the size can also be decreased.
    
    26. Simplified shutdown procedure to avoid a possible returns in logic
        to previous phases.
    
    27. Removed concept of multiple log groups.
    
    28. Relaxed conditions required for checkpoint_lsn. It can now point to
        any data byte within redo (does not need to point to a records group
        beginning).
    
    29. Windows: always use buffered IO for redo log.
    
    30. Mysql test runner received a new feature (thanks to Marcin):
        --exec_in_background.
    
    Review: RB#15134
    
    Reviewers:
        - Marcin Babij <marcin.babij@oracle.com>,
        - Debarun Banerjee <debarun.banerjee@oracle.com>.
    
    Performance tests:
        - Dimitri Kravtchuk <dimitri.kravtchuk@oracle.com>,
        - Daniel Blanchard <daniel.blanchard@oracle.com>,
        - Amrendra Kumar <amrendra.x.kumar@oracle.com>.
    
    QA and MTR tests:
        - Vinay Fisrekar <vinay.fisrekar@oracle.com>.

[33mcommit 8f5ed27f8b0d85717c54d23fcca0e47cf9409b80[m
Author: Rahul Sisondia <rahul.sisondia@oracle.com>
Date:   Wed Feb 14 10:08:43 2018 +0100

    Bug#27400095 unable to access 8.0.4 server after starting on top of 5.7.20
    database
    
    Description
    -----------
    
    This problem was reported while starting the server after in-place upgrade from
    the mysql 5.7.20 to 8.0.4 version when --skip-grant-tables options is enabled.
    
    During the investigation it turned out that starting from 8.0.4 default
    authentication plugin has been changed to chaching_sha2_password due to that
    problem could also be seen if the 8.0.4 server is started with
    --skip-grant-tables options then 8.0.4 client is unable to connect to it.
    
    This happens because caching_sha2_password client/server plugins require more
    packets interchange after the client has sent the scrambled password to the
    server.
    If server after receiving the scrambled packet from the client detects that
    --skip-grant-tables option is specified then it simply returns the CR_OK packet
    while client is expecting either fast_auth_success or
    [1;31mperf[morm_full_authentication packet.
    
    Fix:
    ---
    We now let the server continue the handshake process with the decoy user instead
    of returning the CR_OK packet to the client.  This required the following
    changes -
      1. Added a check in the find_mpvio_user method so that if acl_users are null
         then it can directly create the decoy user.
      2. In the parse_client_handshake_packet, let it set the user as decoy user
         and continue.
      3. We set the MPVIO as SUCCESS in case of --skip-grant-tables therefore if
         any error is encountered after this point will set in the diganotic_area
         as well. We must reset that in --skip-grant-tables is specified.
         This problem was discovered while testing the fix with PIPE protocol.
    
    Unrelated changes - Fixed typos in the doxygen comments.
    
    Testing :
    -------
    
    Added two new test files.
    skip_grant_protocols -
        Executes on non-windows platforms. Verifies the fix with socket protocol.
    skip_grant_protocols_windows -
        Execute on windows platform. Verifies the fix with the shared-memory
        and named-pipe protocols.
    
    Verified the scenario reported in the bug manually as it is not possible to
    write MTR test for it. Neither it is required.
    
    branch - mysql-8.0-itch  ( In progress)
    push id: 12544359
    Date - 2018-02-08 09:40:17 
    
    Report from loki-
    
    Unit tests: 100% tests passed, 0 tests failed out of 46
    --------------------------------------------------------------------------
    The servers were restarted 1458 times
    Spent 24259.968 of 1409 seconds executing testcases
    
    Completed: All 5828 tests were successful.
    
    1663 tests were skipped, 147 by the test itself.
    
    Review :
    --------
    RB#18698

[33mcommit df1ea4782f37e72549f4926515ae7d2e46dde72a[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Feb 12 15:39:23 2018 +0100

    Bug#26036912 COMPONENT MACRO DO CONFUSE CODE FORMATTERS
    
    Before this fix, all code involving macros used
    to define or implement components and services
    is extremely poorly formatted by clang-format.
    
    The root cause is that the macro themselves are
    very opaque, and obfuscate completely the code structure,
    so that clang-format can not even find basic expressions
    or statements while just reading the calling code.
    
    The fix is as follows.
    
    When a macro generates a list item, ending by a column:
    - remove the column from the macro
    - require the calling code to explicitly add the column
    
    When a macro generates a statement, ending by a semicolumn:
    - remove the semicolumn from the macro
    - require the calling code to explicitly add the semicolumn
    
    With this change, code formatted by clang-format,
    while not beeing [1;31mperf[mect, is at least workable.
    
    Details of the change:
    - END_DECLARE_COMPONENT() is now followed by ';'
    - PROVIDES_SERVICE() is now followed by ','
    - END_COMPONENT_PROVIDES() is now followed by ';'
    - REQUIRES_SERVICE() is now followed by ','
    - END_COMPONENT_REQUIRES() is now followed by ';'
    - METADATA() is now followed by ','
    - END_COMPONENT_METADATA() is now followed by ';'
    - END_SERVICE_IMPLEMENTATION() is now followed by ';'

[33mcommit 6503711f6de79b1a395d4b15da518d5954087430[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Feb 8 14:57:57 2018 +0100

    Bug#26036912 COMPONENT MACRO DO CONFUSE CODE FORMATTERS
    
    Before this fix, all code involving macros used
    to define or implement components and services
    is extremely poorly formatted by clang-format.
    
    The root cause is that the macro themselves are
    very opaque, and obfuscate completely the code structure,
    so that clang-format can not even find basic expressions
    or statements while just reading the calling code.
    
    The fix is as follows.
    
    When a macro generates a list item, ending by a column:
    - remove the column from the macro
    - require the calling code to explicitly add the column
    
    When a macro generates a statement, ending by a semicolumn:
    - remove the semicolumn from the macro
    - require the calling code to explicitly add the semicolumn
    
    With this change, code formatted by clang-format,
    while not beeing [1;31mperf[mect, is at least workable.
    
    Details of the change:
    - END_DECLARE_COMPONENT() is now followed by ';'
    - PROVIDES_SERVICE() is now followed by ','
    - END_COMPONENT_PROVIDES() is now followed by ';'
    - REQUIRES_SERVICE() is now followed by ','
    - END_COMPONENT_REQUIRES() is now followed by ';'
    - METADATA() is now followed by ','
    - END_COMPONENT_METADATA() is now followed by ';'
    - END_SERVICE_IMPLEMENTATION() is now followed by ';'

[33mcommit 7534cf0e55dbc8d6d65e7ef0b75cd07818082554[m
Author: Ricardo Ferreira E Ferreira <ricardo.e.ferreira@oracle.com>
Date:   Tue Feb 6 10:50:25 2018 +0000

    BUG#27317431: LAST_CONFLICT_FREE_TRANSACTION SHOWS DIFFERENT VALUES IN GROUP (EMPTY ON JOINER)
    
    Upon group replication, the LAST_CONFLICT_FREE_TRANSACTION of the
    [1;31mperf[mormance_schema.replication_group_member_stats table is empty
    (because that table is reset). This empty value is not broadcasted or
    accepted by the other members of the group, resulting in a wrong view
    when querying this table on the other members of the group (until
    a transaction is executed again).
    
    The underlying issue was two-fold. First, the empty transaction
    identifiers weren't being encoded in the stats message nor being
    accepted in the stats message reception callback. Second, the empty
    value was being used to signal  whether or not to send the transaction
    identifiers. Since empty values are acceptable values, they can't be
    used for this purpose. Given that the stats message is sent every second
    any way, we maintain an old copy of the transaction identifiers and only
    update them every 30 seconds (which is the original period for this
    update).

[33mcommit e3b2d4efa2cb558698bdeabed89e03f864ef28ce[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Feb 1 16:04:57 2018 +0100

    Test suite cleanup.
    
    Removed spurious spaces in VARIABLE_NAME,
    when querying [1;31mperf[mormance schema tables.

[33mcommit a9d39aedf48f2a4afb2115ea52dcf174dcaf7448[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Tue Jan 30 05:52:32 2018 +0100

    Bug #27322254: WITH PERSIST_ONLY, VARIABLE VALUE EQUALS 18446744073709547520
                   IS STORED AS -4096
    
    Problem: @@max_binlog_cache_size when persisted using PERSIST_ONLY reflects
    wrong value when [1;31mperf[mormance_schema.persisted_variables is queried. This is
    because in Item_func_get_system_var::val_str() unsigned flag for this value
    is ignored, thus ends up converting this value to a longlong.
    
    Fix: Fix is to check for unsigned_flag flag when storing the value in a
    string buffer.

[33mcommit c9f93108db385c6f6c5f8e5838725d2f5ee2145f[m
Author: Tiago Vale <tiago.vale@oracle.com>
Date:   Fri Jan 19 11:05:28 2018 +0000

    Bug#24749766 VERIFY IF ONE CAN REMOVE SLEEP() CALLS IN LEAVE() CODE
    
    Problem
    =======
    Removing the 5-second backoff the node [1;31mperf[morms when it leaves the XCom
    group resulted in segmentation faults on MTR.
    Using ASan revealed the cause to be a use-after-free.
    
    Analysis
    ========
    There are three calls to Gcs_interface_factory::cleanup on applier.cc,
    certifier.cc, and recovery.cc.
    The purpose of these calls is to clean up thread-local OpenSSL-related
    resources, but Gcs_interface_factory::cleanup also frees the GCS
    singleton.
    
    This situation can lead to use-after-free because
    Gcs_interface_factory::cleanup frees the GCS singleton whilst it is
    still in use.
    Below is a proof of the problem, taken from an ASan report.
    (TL;DR leave_group() accesses the GCS singleton after it was freed by
    Recovery_module.)
    
    ==12310==ERROR: AddressSanitizer: heap-use-after-free on address
    0x6040002b33f8 (...) thread T25
    (...)
        #2 0x7f9799010b94 in Gcs_xcom_interface::finalize()
        #3 0x7f9798f1d130 in Gcs_operations::finalize()
        #4 0x7f9798f729ae in leave_group()
        #5 0x7f9798f7476d in plugin_group_replication_stop(char**)
    (...)
    0x6040002b33f8 (...) freed by thread T43 here:
    (...)
        #4 0x7f9799011f96 in Gcs_xcom_interface::~Gcs_xcom_interface()
        #5 0x7f979900e89d in Gcs_xcom_interface::cleanup()
        #6 0x7f979900c3fc in Gcs_interface_factory::cleanup(
                               enum_available_interfaces)
        #7 0x7f979900ca03 in Gcs_interface_factory::cleanup(
                               std::__cxx11::basic_string<char,
                                                          std::char_traits<char>,
                               std::allocator<char> > const&)
        #8 0x7f9798f9af19 in Recovery_module::recovery_thread_handle()
    (...)
    
    Solution
    ========
    New GCS API
    (Gcs_interface_factory::cleanup_thread_communication_resources) whose
    purpose is to "cleanup thread-local communication resources."
    It should be called by applier.cc, certifier.cc, and recovery.cc,
    instead of Gcs_interface_factory::cleanup since the new API provides the
    desired semantics.
    
    The semantics of Gcs_interface_factory::cleanup remains "cleanup the
    GCS," as required by leave_group().
    
    Reviewed-by: Nuno Carvalho <nuno.carvalho@oracle.com>
    Reviewed-by: Tiago Jorge <tiago.jorge@oracle.com>
    RB: 18465

[33mcommit d70c51070112b037a2a6dd7225bae6b9f0a19914[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Jan 18 10:05:51 2018 +0100

    Bug#24688694 SEVERAL UNSTABLE TESTS IN SUITE PERFSCHEMA
    
    Improved test robustness for:
    - [1;31mperf[mormance_schema.innodb_is_data_locks
    
    Added checks to diagnose spurious failures.

[33mcommit 6293530c08ae558d1388c245394dc8ec3040d679[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Thu Jan 18 06:17:30 2018 +0100

    Bug#27252077: VARIABLE_SOURCE SHOWS VARIABLES AS EXPLICIT INSTEAD OF
                  PERSISTED POST INSTALL
    
    Problem: When there are static plugin variables present in any of the
    configuration file(my.cnf) and also persisted in mysqld-auto.cnf file,
    then variable_source column value in [1;31mperf[mormance_schema.variables_info
    is incorrect.
    
    Analysis: Any static variable persisted is appended to command line options
    during server startup. When plugin is installed using install plugin these
    options are read and appended to exisitng command line options. When parsing
    these options there is a logic as follows:
    1. All options between ----args-separator---- and ----persist-args-separator----
       are considered as command line options
    2. All options after ----persist-args-separator---- are considered as persisted
       options.
    However when server is completly started these args separator are removed, thus
    during install plugin in my_handle_options code we try to search for
    ----args-separator---- to identify all persisted plugin options. Since there is
    no ----args-separator---- we dont update the variable_source value.
    
    Fix: Fix is to add ----args-separator---- when handling options for install
    plugin.

[33mcommit a13e296adf6efab6c3472ee954c19354db997434[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Jan 15 15:14:24 2018 +0100

    Test cleanup,
    improved test robustness for [1;31mperf[mormance_schema.innodb_is_data_locks

[33mcommit 1bd8998f32c1a62d4e1a6066dedc428f6bb6ee87[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Jan 11 10:52:03 2018 +0100

    Bug#27184567 QUERYING REPLICATION PERFORMANCE SCHEMA TABLES VIA INDEXES
    GIVES WRONG RESULTS
    
    Before this fix,
    queries on [1;31mperf[mormance_schema.replication_* tables
    sometimes returned incorrect results (missing rows),
    in particular when the query execution path used an index.
    
    For example in particular, where clauses involving the
    CHANNEL_NAME columns failed to return rows matching
      WHERE CHANNEL_NAME = ''
    which is the default channel name.
    
    With this fix, the implementation of every index
    on every [1;31mperf[mormance_schema.replication_* table
    has been investigated, and the following bugs
    were identified and corrected.
    
    1) Column CHANNEL_NAME.
    
    Background:
    
    In the [1;31mperf[mormance schema in general,
    a record value is rarely represented by both
    - a null bit
    - a value
    
    Instead, a record value is typically represented by
    a single attribute (for example m_thread_id),
    with the special meaning that m_thread_id == 0
    represents a NULL column, not a 0 column.
    
    Bug:
    
    WHERE CHANNEL_NAME = '' does not return matching rows.
    
    Root cause:
    
    The default channel name is represented by a string,
    with a length of 0.
    
    When using an index, method
      PFS_key_name::match()
    is called to decide if a record matches the index condition.
    
    When processing a CHANNEL_NAME = '' record,
    PFS_key_name::match() considers that the record is a NULL
    column instead, so that the where clause is evaluated as
      WHERE NULL = ''
    which is false, discarding the record.
    
    Fix:
    
    Implement a new method
      PFS_key_name::match_not_null()
    which considers a record of length 0 to be an empty string,
    and use this in every index implementation involving
    a CHANNEL_NAME column.
    
    2) Column THREAD_ID
    
    Bug:
    
    Conditions
      WHERE THREAD_ID IS NULL
      WHERE THREAD_ID IS NOT NULL
    are not implemented properly,
    resulting in
    - missing matching rows
    - extra non matching rows
    
    Root cause:
    
    Some index implementations,
    for example:
      PFS_index_rpl_applier_status_by_coord_by_thread::match()
    evaluate the record THREAD_ID value,
    and discard NULL THREAD_ID as non matching,
    without even looking at the index key condition.
    
    The code causing this is:
    
        if (row.thread_id_is_null)
        {
          return false;
        }
    
    This is incorrect, because when the key search is actually
      WHERE THREAD_ID IS NULL
    records with a NULL should be matching, not discarded.
    
    Fix:
    
    Do not attempt to evaluate conditions in table index ::match() methods,
    and always delegate the index evaluation to the underlying
    key, as in:
    
        if (!m_key.match(row.thread_id))
        {
          return false;
        }
    
    This allows the PFS_key::match() logic to determine matches,
    which turns out to use a complex logic,
    to account for NULL in columns and or keys.
    
    3) Table replication_applier_status_by_worker, primary key.
    
    Bug:
    
    The primary key for this table is
      PRIMARY KEY (CHANNEL_NAME, WORKER_ID)
    aka, it has two parts.
    
    The index on the second part, WORKER_ID, is not working.
    
    Root cause:
    
    PFS_index_rpl_applier_status_by_worker_by_channel::match()
    only implements filtering for the CHANNEL_NAME part,
    as in:
    
      if (m_fields >= 1)
      {
        ... read the channel name value ...
        ... match the channel name key part ...
      }
    
    The second part
    
      if (m_fields >= 2)
      {
        ... read the worker id value ...
        ... match the worker id key part ...
      }
    
    is simply missing in the code.
    
    Fix:
    
    Implemented the second key part (WORKER_ID) in the index.
    
    3) Table replication_applier_status_by_worker, index iteration
    
    Background:
    
    This table logic is more complicated than other replications tables,
    because the table exposes at the same time:
    - data for Single Thread Slave, reporting 1 thread per channel
    - data for Multi Thread Slave, reporting many threads per channel,
      with each worker thread.
    
    Bug:
    
    table_replication_applier_status_by_worker::index_next()
    is not iterating properly for this table.
    
    Root cause:
    
    The ::index_next method implements two separate scans:
    - a scan using m_applier_pos / m_applier_next_pos
    - a scan using m_pos / m_next_pos
    
    This is flawed, as the storage engine interface in general,
    and the interactions with the optimizer in particular,
    expects only one concept of position per table.
    
    The position used was only m_pos,
    per the table constructor:
    
    table_replication_applier_status_by_worker::
      table_replication_applier_status_by_worker()
      : PFS_engine_table(&m_share, &m_pos), <-- here
        m_pos(),
        m_next_pos(),
        m_applier_pos(0),
        m_applier_next_pos(0)
    {
    }
    
    The m_applier_pos attribute was not part of the table "position".
    
    Beside, the record length ("ref length") was wrong,
    using sizeof(PFS_simple_index) while m_pos is a double index,
    causing even more bugs when iterating.
    
    Fix:
    
    Define a single position concept for this table,
    pos_replication_applier_status_by_worker.
    
    Rewrite ::index_next to only use one position, not two.
    
    Define a pos_t typedef, and use sizeof(pos_t) for "ref length".
    
    4) Table replication_connection_status, THREAD_ID index.
    
    Bug:
    
    The index by THREAD_ID is not working properly.
    For example
      WHERE THREAD_ID = <the THREAD_ID of a record>
    fails to match the record.
    
    Root cause:
    
    On one hand, the logic to build the record,
      table_replication_connection_status::make_row()
    uses:
      mi->info_thd
    to find the THREAD_ID value.
    
    On the other hand, the logic to evaluate the index,
      PFS_index_rpl_connection_status_by_thread::match()
    uses:
      mi->rli->info_thd
    to find the THREAD_ID value.
    
    This points to a different thread, and returns a
    different THREAD_ID, so that an index on THREAD_ID
    does not match its own record.
    
    Fix:
    
    PFS_index_rpl_connection_status_by_thread::match()
    uses the same logic as
    table_replication_connection_status::make_row(),
    pointing to the same thread.
    
    5) Misc code cleanup
    
    a)
    
    Systematically define a pos_t typedef per table,
    and use sizeof(pos_t) for ref length,
    to have more maintainable code and avoid
    incorrect lengths.
    
    b)
    
    Remove incorrect uses of MY_ATTRIBUTE((unused))
    
    6) Test suite
    
    Implemented missing tests,
    to enforce that tables return the same data
    with and without an index:
      [1;31mperf[mormance_schema.idx_compare_replication_*.test
    
    Systematically tested the following conditions:
    - key_part IS NULL
    - key_part IS NOT NULL
    - key_part = '' (for CHANNEL_NAME)
    - key_part != '' (for CHANNEL_NAME)
    - key_part = <expected existing value>, for example for THREAD_ID.

[33mcommit 71b0c585173257ff7a27f0cebe562f69ada2720a[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Fri Jan 12 11:14:55 2018 +0800

    Bug#26848711 - PERFORMANCE REGRESSION IN "CREATE TABLE" SPEED AND SCALABILITY IN 8.0.3
    
    The [1;31mperf[mormance regression is mainly due to that DDL logs are logged and
    flushed after every transaction commit under dict mutex and lock protection.
    So it showed that dict_operation_lock is very hot.
    
    Since it has to flush redo logs after every transaction commits, so that
    it's true crash-safe DDL, this penalty can't be avoided. However,
    after new DD, dict_operation_lock along with dict_sys mutex are not
    necessary to be held for such a long time during DDL, so we should
    try to deprecate dict_operation_lock and ask for dict_sys mutex
    as less as possible.
    
    Current patch mainly fix this issue in above way for CREATE TABLE and
    the modified code will of course affect ALTER TABLE a bit too.
    Basically, dict_operation_lock is not necessary for CREATE TABLE any more.
    And dict_sys mutex would be acquired only when dict_sys information
    is modified, such as adding new dict_table_t to cache, increase
    dict_sys->size etc. The dict_sys mutex should not be held during
    creating physical data files, etc. Once it's proper time to get rid of
    these dict lock and mutex for all DDLs, it could be possible to clean up
    dict_sys mutex further.
    
    At the meantime, since dict_sys mutex is not held during the whole
    process of CREATE TABLE, once the dict_table_t is added to global cache,
    it has to be kept in cache without eviction before writing metadata of it
    to dd::Table. So this requires some changes for
    innobase_basic_ddl::create_impl().
    
    Furthermore, in this patch, dict_table_close() doesn't have to acquire
    dict_sys mutex any more, instead it has to acquire a per-table mutex
    called dict_table_t::mutex, to prevent the race from ha_innobase::open().
    
    RB: 17608
    Reviewed by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 4e43891f2065189b6b1beeb499b0db82f4375d27[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Jan 11 16:15:16 2018 +0100

    Bug#24688694 SEVERAL UNSTABLE TESTS IN SUITE PERFSCHEMA
    
    Improved test robustness for:
    - [1;31mperf[mormance_schema.stage_mdl_function
    - [1;31mperf[mormance_schema.stage_mdl_global
    - [1;31mperf[mormance_schema.stage_mdl_table
    - [1;31mperf[mormance_schema.innodb_is_data_locks

[33mcommit a5c15f5911987b05fa926303d91376f18da5fd88[m
Author: Nuno Carvalho <nuno.carvalho@oracle.com>
Date:   Tue Jan 9 11:32:11 2018 +0100

    BUG#27016053: REGRESSION IN BINLOG_LOG_ROW INTRODUCED BY ADD_PKE
    
    Group Replication plugin is a multi or single primary replication
    solution, on which members do execute transactions optimistically
    and at commit time they decide, if conflicts happen, which must
    commit or rollback.
    The conflict detection is based on the write-sets of each
    transaction, which is collected along the transaction life when it
    does a update.
    During detailed [1;31mperf[mormance analysis it was discovered that there
    were non-optimized memory allocations and memory copy operations on
    the write-set extraction.
    
    In order to solve the [1;31mperf[mormance regression, the following actions
    were made:
     1) optimize memory allocation;
     2) reduce memory copy operations;
     3) only collect foreign key write-sets when the current table has
        foreign keys.

[33mcommit 838871ffe5b464364bd6489b389b0c438a0b69ac[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Tue Jan 9 18:13:36 2018 +1100

    Bug#26399073 - MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS
    
    Fix a [1;31mperf[mormance regression; InnoDB has a system where the [1;31mperf[mormance
    schema key is decided by FILE, and the patch that extended the basename
    function to work with both / and \ made these allocations slower (as it
    uses std::string, which can allocate on the heap).
    
    However, there is no reason whatsoever that this lookup needs to be done
    runtime in a map. Change it to use a constexpr function; it goes through
    the array linearly, but it's small and it's compile-time. The end result
    is that the compiled code stores a PSI key directly, instead of taking
    FILE, removing its path runtime and looking it up in an std::map.
    
    Improves a data loading benchmark with ~3%, in addition to the ~7%
    regression it fixes
    
    rb#18379 Approved by Bin. Fixed by Steinar.

[33mcommit 1b0a0645a2803b4a5f3bd5ada356a3edf9d1624a[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Tue Jan 9 18:13:36 2018 +1100

    Bug#26399073 - MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS
    
    Fix a [1;31mperf[mormance regression; InnoDB has a system where the [1;31mperf[mormance
    schema key is decided by FILE, and the patch that extended the basename
    function to work with both / and \ made these allocations slower (as it
    uses std::string, which can allocate on the heap).
    
    However, there is no reason whatsoever that this lookup needs to be done
    runtime in a map. Change it to use a constexpr function; it goes through
    the array linearly, but it's small and it's compile-time. The end result
    is that the compiled code stores a PSI key directly, instead of taking
    FILE, removing its path runtime and looking it up in an std::map.
    
    Improves a data loading benchmark with ~3%, in addition to the ~7%
    regression it fixes
    
    rb#18379 Approved by Bin. Fixed by Steinar.

[33mcommit de0a40aa0141dd5328b55f6daf90d1eda236e1b7[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Jan 4 16:01:56 2018 +0100

    Bug#24688694 SEVERAL UNSTABLE TESTS IN SUITE PERFSCHEMA
    
    Improved test robustness for:
    - [1;31mperf[mschema.idx_compare_ees_by_thread_by_error
    - [1;31mperf[mschema.idx_compare_events_waits_current
    - [1;31mperf[mschema.threads_history

[33mcommit 5669eaccf7381e8fea9f996d316cab953fe8e60a[m
Author: Rahul Sisondia <rahul.sisondia@oracle.com>
Date:   Wed Jan 3 12:53:43 2018 +0100

    Bug#25658586 RENAME USER THROW ERROR EVEN IF AUTHORIZATION_ID IS NOT IN
                 ROLE GRAPH
    
    Description
    -----------
    When an authId is no longer in the role graph then rename of that authid should
    be successful but it throws error at present.
    
    At the time of revoking the specified role for the specified user,
    there are two problems :
    - There is check such that if there is no edges connected to
      the auth id then it is not role id anymore. We got the
      condition in the check wrong.
    - The auth id on which edges are checked in the point#1 must
      be of the role, instead we find out the adjacent vertices of
      the user.
    - In case a user id dropped then we must update role flag of
      the connecting acl users otherwise rename after the drop
      user.
    
    Fix:
    ---
    
    - Change the condition such that role is set to true if there
      exist adjacent vertices on the specified role id.
    - Check for the adjancent vertices on the role auth id instead
      of the auth role id.
    - Added an utility function that updates the role flag on the
      ACL user and calling the method wherever needed.
    
    Testing :
    -------
    Added the test scenario reported in the bug just before the existing test
    scenario available in the role.test file. Verified the test suites execution
    on loki01.
    
    Result from Sandbox run :
    
    Unit tests: 100% tests passed, 0 tests failed out of 46
    --------------------------------------------------------
    The servers were restarted 1473 times
    Spent 25864.133 of 1459 seconds executing testcases
    
    Completed: Failed 3/5735 tests, 99.95% were successful.
    
    Failing test(s): [1;31mperf[mschema.variables_info i_innodb.table_compress_3
    i_innodb.innodb_bug14621190_debug_sync
    
    Note: Above test failures has nothing to do with this fix so we can ignore that.
    
    Review :
    ------
    RB#18236

[33mcommit 3ba677d576fb57b3de829b638f97bbb6443ed8a4[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Jan 2 11:46:09 2018 +0100

    BUG#25212799 RACE CONDITION IN PERFORMANCE SCHEMA MEMORY INSTRUMENTATION
    
    Before this fix, memory statistics collected by the [1;31mperf[mormance schema
    could be incorrect, due to race conditions.
    
    The root cause is that the code is deliberately not using locks
    to prevent races, to reduce CPU overhead at the expense of accuracy.
    
    While this is acceptable for general statistics,
    this behavior is not desirable for the memory instrumentation.
    
    The memory instrumentation keeps track of an inventory,
    so that errors could:
    - create the appearance of a memory leak, when there is none
    - hide an existing memory leak.
    - cause incorrect data to be reported, for example negative counts.
    
    With this fix, memory statistics are computed safely.
    
    The existing structure PFS_memory_stat was replaced replaced
    with structures PFS_memory_safe_stat and PFS_memory_shared_stat.
    
    PFS_memory_safe_stat is for statistics that are already accessed
    in a safe way, namely the per thread statistics where no race
    conditions can possibly occur (each thread owns its related statistics)
    
    PFS_memory_shared_stat is for statistics that are accessed
    concurrently between threads, like per account / user / host and global
    statistics. This structure uses atomics to prevent races.

[33mcommit 5905b8a19c4ee05e053eb1cfdf2b217bf96f123e[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Jan 2 15:53:57 2018 +0100

    Applied clang-format to storage/[1;31mperf[mschema.

[33mcommit e25517e73ce84e976e13faf4c6a90bb388af13b1[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Tue Dec 19 11:55:03 2017 +0100

    Bug #25677422: SET_TIME IN VARIABLES_INFO REFLECTS RESTART TIME FOR
    PERSISTED VARIABLES
    
    Post-push fix: [1;31mperf[mschema.variables_info:
     removed a timestamp from the result since it's non-deterministic.

[33mcommit 687b2eb201f64bfc6bfbc8fa22f375f0a16861dd[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Mon Dec 18 09:16:54 2017 +0100

    Bug #25677422: SET_TIME IN VARIABLES_INFO REFLECTS RESTART TIME FOR PERSISTED
                   VARIABLES
    
    Problem: [1;31mperf[mormance_schema.variables_info tables columns like SET_USER,
    SET_TIMESTAMP, SET_HOST represent when and by wholm a variable was set.
    However when a variable is persisted and after server restart, the variables
    SET_TIME instead of showing time when this variable was set, it shows the
    server restart time.
    
    Fix: Fix is to persist user/host/timestamp in mysqld-auto.cnf so that when
    this cnf file is read the values can be read and applied back on server. This
    will reflect the correct time and user for all the persisted variables. This
    fix will change the format of mysqld-auto.cnf to accomodate more details for
    all variables which are being persisted.

[33mcommit f69ee4878f4db2629d465f7ebd0b55a8480bd87d[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Fri Dec 15 11:09:27 2017 +0100

    Bug#26918495 PERFSCHEMA.SOCKET_SUMMARY_BY_INSTANCE_FUNC FAILS ON SOLARIS
    
    Abandoning test [1;31mperf[mschema.socket_summary_by_instance_func
    
    This test has been unstable since it was written.
    
    The problem is that attempting to predict the precise traffic
    on a socket caused by a given SQL statement is not realistic,
    especially considering the various encryption that can happen
    on the connection with SSL.

[33mcommit 7389285c6be5ee87558786799ba912794276d312[m
Merge: 61d80ab1ceb 553a3140822
Author: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
Date:   Thu Dec 14 17:35:46 2017 +0100

    Merge branch 'mysql-8.0' into mysql-trunk
    
    Conflicts:
            mysql-test/collections/mysql-8.0-stage.push
            mysql-test/include/mysqld--help.inc
            packaging/rpm-docker/mysql.spec.in
            packaging/rpm-fedora/mysql.spec.in
            packaging/rpm-oel/mysql.spec.in
            packaging/rpm-sles/mysql.spec.in
            rapid/plugin/x/client/mysqlxclient/xsession.h
            rapid/plugin/x/client/xconnection_impl.cc
            rapid/plugin/x/ngs/include/ngs/command_delegate.h
            rapid/plugin/x/ngs/include/ngs/error_code.h
            rapid/plugin/x/ngs/include/ngs_common/socket_interface.h
            rapid/plugin/x/ngs/ngs_common/operations_factory.cc
            rapid/plugin/x/ngs/src/client.cc
            rapid/plugin/x/ngs/src/protocol/row_builder.cc
            rapid/plugin/x/ngs/src/socket_events.cc
            rapid/plugin/x/protocol/CMakeLists.txt
            rapid/plugin/x/src/mysql_show_variable_wrapper.cc
            rapid/plugin/x/src/mysql_show_variable_wrapper.h
            rapid/plugin/x/src/mysql_variables.h
            rapid/plugin/x/src/query_formatter.cc
            rapid/plugin/x/src/query_formatter.h
            rapid/plugin/x/src/query_string_builder.cc
            rapid/plugin/x/src/query_string_builder.h
            rapid/plugin/x/src/sql_data_context.cc
            rapid/plugin/x/src/sql_data_context.h
            rapid/plugin/x/src/xpl_client.cc
            rapid/plugin/x/src/xpl_client.h
            rapid/plugin/x/src/xpl_[1;31mperf[mormance_schema.h
            rapid/plugin/x/src/xpl_plugin.cc
            rapid/plugin/x/src/xpl_server.cc
            rapid/plugin/x/src/xpl_server.h
            rapid/plugin/x/src/xpl_system_variables.h
            rapid/plugin/x/tests/driver/common/utils_string_parsing.h
            rapid/plugin/x/tests/driver/driver_command_line_options.cc
            rapid/plugin/x/tests/driver/processor/script_stack.h
            rapid/plugin/x/tests/mtr/t/admin_list_objects_docpath.test
            rapid/unittest/gunit/xplugin/test_main.cc
            rapid/unittest/gunit/xplugin/xpl/callback_command_delegate_t.cc
            rapid/unittest/gunit/xplugin/xpl/row_builder_t.cc
            rapid/unittest/gunit/xplugin/xpl/stubs/command_service.cc
            rapid/unittest/gunit/xplugin/xpl/stubs/log_subsystem.cc
            rapid/unittest/gunit/xplugin/xpl/stubs/misc.cc
            rapid/unittest/gunit/xplugin/xpl/stubs/security_context_service.cc
            rapid/unittest/gunit/xplugin/xpl/stubs/sql_session_service.cc
            rapid/unittest/gunit/xplugin/xpl/xdatetime_t.cc
            rapid/unittest/gunit/xplugin/xpl/xdecimal_t.cc

[33mcommit dc5298a335ac720718083ca2573af0720bc34bb3[m
Author: Joao Gramacho <joao.gramacho@oracle.com>
Date:   Wed Dec 6 15:44:06 2017 +0000

    WL#9452: Log Position Lock
    
    Step-7: Improve test coverage and last refinements
    --------------------------------------------------
    
    Added support to collect InnoDB LSN_checkpoint.
    
    Extended rpl.rpl_[1;31mperf[mschema_instance_log_status test case.
    
    Added test code into rpl.rpl_multi_source_channel_map_stress to query
    instance_log_status PS table while stressing MSR.
    
    Added new test case rpl.rpl_[1;31mperf[mschema_instance_log_status_blockage.
    
    Added binlog_gtid.binlog_gtid_instance_log_status_errors test case.
    
    Fixed doxygen issue (typo in code comment).

[33mcommit 798ab78cd6de38a8f642f59da4839b802163b87f[m
Author: Joao Gramacho <joao.gramacho@oracle.com>
Date:   Fri Nov 24 16:20:04 2017 +0000

    WL#9452: Log Position Lock
    
    Step-3: Introduce the new [1;31mperf[mormance schema table and a new mutex
    ------------------------------------------------------------------
    
    DBUG_SIGNAL_WAIT_FOR was moved away from sql/rpl_slave.h.
    
    A global mutex (LOCK_collect_instance_log) was created to protect
    against concurrent attempts to collect the instance logs information.
    
    Added JSON support as an output field in a [1;31mperf[mormance schema table.
    
    Added the new [1;31mperf[mormance schema table (instance_log_status).
    
    Added a test case to query the new [1;31mperf[mormance schema table.
    
    Added [1;31mperf[mschema specific test cases and updated test.pfs_check_proc()
    signature.

[33mcommit 7bb3a7131508d25b26753085de6141ef32ba7189[m
Author: Gleb Shchepa <gleb.shchepa@oracle.com>
Date:   Fri Dec 8 14:59:54 2017 +0400

    Bug#27189940: CREATE VIEW FAILS ON JSON_TABLE() IN SCHEMA-LESS CONNECTIONS
    
    Patch author: Roy Lyseng
    
    The problem is that CREATE VIEW [1;31mperf[morms a privilege check for all
    underlying tables of the view's query expression. However, the JSON
    table function is an optimizer internal table that has no entry in
    the ACL structures. Note that we already skip privilege checking for
    derived tables and assign SELECT privileges for such tables. We can
    simply extend this test to include all optimizer internal tables,
    like table functions and recursive references.
    
    We also add a bool is_internal() interface to class TABLE_LIST that is
    used for checking the privilege requirements.
    Note that we might actually use this interface more places, but that is
    beyond the scope of this bug fix.
    
    Change-Id: Ib79f1798af00f4ef1a592be2912046c5ae74b98d

[33mcommit 863aac45c8c124d8a80e505e80bd6770d94fe718[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Mon Aug 28 15:19:00 2017 +0200

    WL#9553: Upgrading the transactional data dictionary tables.
    
    This patch implements support for changing the DD table
    definitions.
    
    Overview.
    ---------
    The main changes are the following:
    
    - SE private data previously hard coded in InnoDB is now
      used only during first time server start. The meta data
      is stored in a DD table. On restart, the meta data is
      fetched from the DD table instead of InnoDB. Thus, we
      may have SE private data that can change.
    
    - During upgrade, we create the required target tables in
      a temporary schema, and migrate the meta data from the
      actual DD tables to the new target tables.
    
    - At the end of upgrade, we modify the persistently stored
      SE private data mentioned in 1) to that of the new target
      tables. We also adjust the schema ID of the target tables
      to simulate altering the schema of the tables. This way,
      we are able to switch from the old to the new DD version
      atomically. The temporary schemas are removed on next
      restart.
    
    In more detail, the patch implements the following:
    
    Performance schema.
    -------------------
    - Change in a [1;31mperf[mormance schema test: Select only the PS_VERSION
      from 'mysql.dd_properties' to avoid reflecting irrelevant meta
      data in the result file, and thus to avoid unnecessary re-recordings
      of the result file.
    
    - Minor changes in the way Plugin_table_impl is used; replaced by
      Object_table_impl for more uniform code.
    
    - Approved by Marc Alff.
    
    Handler and handlerton API and InnoDB.
    --------------------------------------
    - The handler function 'get_se_private_data()' will now be
      called only during '--initialize'. During ordinary restart,
      it will be called once to get the SE private data for the
      'mysql.dd_properties' table, which can never change. This
      is the table that stores the SE private data for the other
      DD tables.
    
    - Modify 'get_se_private_data()' to be in line with what
      'dd_write_table()' does when storing SE private data:
    
      * Store se_private_data for columns. This is now done
        for DD tables in the same way as it is done for
        user tables.
      * Extend se_private_data for indexes to also store
        table_id and space_id. Again, this is done to get
        the same set of meta data for DD tables and user
        tables.
    
      Could dd_write_table() be used to ensure consistency in the
      meta data that is stored?
    
    - At the end of upgrade, we start over DD initialization to
      do the same as for a restart. Thus, we had to provide a new
      parameter to 'get_se_private_data()' to reset the counters
      for this to work with two phases of function calls in the
      case of upgrade.
    
    - We maintain a set in InnoDB of SE private ids of the DD tables.
      This set is used this instead of the hard coded id range used
      previously.
    
    - Replace hard coded ids of tables used in the processing
      of I_S queries by name based lookup.
    
    - Change the order of the DD and DDSE tables in the System_tables
      registry to make sure the table 'innodb_dynamic_metadata' is
      created on a low table id and index id. The motivation is that
      for now, this table must stay at fixed ids because it may be
      opened by InnoDB before the DD is available.
    
    - Approved by Jimmy.
    
    Extensions of 'mysql.dd_properties' and data structures.
    --------------------------------------------------------
    - Valid key/value pairs are explicitly defined:
    
        DD_VERSION                Actual DD version.
        IS_VERSION                Actual I_S version.
        PS_VERSION                Actual P_S version.
        SDI_VERSION               Actual SDI version.
        LCTN                      L_C_T_N setting used during
                                  --initialize.
        MYSQLD_VERSION_LO         Lowest server version which has
                                  been using the data directory.
        MYSQLD_VERSION_HI         Highest server version which has
                                  been using the data directory.
        MYSQLD_VERSION            Current server version.
        MINOR_DOWNGRADE_THRESHOLD The current DD can be used by
                                  previous MRUs, unless their
                                  target DD version is less than
                                  the downgrade threshold.
        SYSTEM_TABLES             List of system tabels with
                                  definitions.
        UPGRADE_TARGET_SCHEMA     Temporary schema used during
                                  upgrade.
        UPGRADE_ACTUAL_SCHEMA     Temporary schema used during
                                  upgrade.
    
    - Simplify Object_table, Object_table_definition,
      Plugin_table_definition, their subclasses and clients.
      Remove unnecessary functions, and rename according to
      usual naming rules. Merge Object_table* and Plugin_table*
      into one class.
    
    - Version number handling does not need to be part of these
      classes, this will be handled elsewhere, so it is removed.
    
    - Object table definitions now may hold definitions of both
      the target and actual tables.
    
    - Introduce explicit enumerations for options, indexes and
      foreign keys for the DD table definitions.
    
    - Explicitly define indexes needed by foreign keys.
    
    - Use the index enumerations when creating instances of
      object keys.
    
    - A new 'DD_bootstrap_ctx' class is introduced as an aid in the
      upgrade process, but also for normal DD bootstrapping. The
      handling of the bootstrap stages is moved into this class.
    
    Changes to the current DD initialization.
    -----------------------------------------
    - Extend the bootstrapper to create target or actual tables
      depending on context.
    
    - Change the way DD objects are flushed (during --initialize) and
      synced (during restart) to avoid problems with overlapping
      ID sequences for the scaffolding and the persisted object IDs.
      This is needed since the DD tables will no more be fixed on low
      IDs.
    
    - Add a new stage before creating tables where the inert table
      'dd_properties' is opened and the version numbers etc. is read.
      Here, the actual DD table definitions are read in case of
      upgrade or minor downgrade.
    
    New handling of upgrade.
    ------------------------
    - Create two temporary schemas with unused schema names, store
      in 'dd_properties'.
    
    - Upon restart, the temporary schemas are dropped.
    
    - First initialize the meta data for the actual DD tables, and
      use this to open the actual tables.
    
    - Then create the target tables, and migrate the meta data from
      the old to the new tables.
    
    - Adjust object ids to simulate altering schema of the new
      and old DD tables at the end of DD upgrade.
    
    - Update properties for all tables, make sure removed
      tables are not reflected in the persisted properties.
    
    Add 'options' columns.
    ----------------------
    - Add a general purpose column to all DD tables that store
      DD entities (i.e.:
    
            catalogs,
            character_sets,
            collations,
            column_statistics,
            events,
            resource_groups,
            routines,
            schemata,
            st_spatial_reference_systems,
           *tables,
           *tablespaces
    
    - Plus a selection of important non-entity tables:
    
           *columns,
           *indexes,
            foreign_keys,
            triggers,
           *parameters
    
    - Tables prefixed by '*' above already have a column named
      'options' which can be used for this purpose.
    
    Miscellaneous.
    --------------
    - Set created/last altered when creating schema.
    
    - Add command line option for disabling automatic DD upgrade.
    
    - Change test for is_dd_table_name() to check for table types in the
      System_tables registry.
    
    - Change dictionary object type names for better conformity.
    
    - Remove *_type classes for the DD object classes.
    
    - Refactor object table usage
    
    Test changes.
    -------------
    - Extend dd_schema_definition_debug_c{i,s} to also record the
      CREATE TABLE statements for the DD tables.
    
    - Record new test results.
    
    - Mask out the DD version number from the SDI which is extracted
      from tablespace files in some tests.

[33mcommit cf63b24293dd605c2c171ccd65f9c58b68e29e1e[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Fri Dec 8 12:10:42 2017 +1100

    WL#8619 - InnoDB: Provide offline database portability without ISL files
    
    Summary of changes.
    
    1. Introduce --innodb-directories := "dir1;...;dirN". This is renamed
       from --innodb-scan-directories which was introduced in WL#9499.
       Currently this is not dynamic.
    2. Revert to 5.6 behaviour where we scan directories and find .ibd files.
       If you move tablespaces to a new location, add the path to
       innodb-data-directories so that InnoDB can "discover" the files on
       startup.
    3. Tablespaces can only be created under known directories. This
       eliminates the need for .isl files.
    4. Upgrade redo log format, not backward compatible
    5. Change redo log type IDs
    6. Code cleanup
    7. Shard the fil system data structures for [1;31mperf[mormance
    8. Remove WL#9499 files that were used to track open tablespaces.
    
    RB#16842 Approved by: Jimmy and Kevin.

[33mcommit d8b04cdb92b945cf7c8621291406f63798ba6420[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Fri Dec 8 12:10:42 2017 +1100

    WL#8619 - InnoDB: Provide offline database portability without ISL files
    
    Summary of changes.
    
    1. Introduce --innodb-directories := "dir1;...;dirN". This is renamed
       from --innodb-scan-directories which was introduced in WL#9499.
       Currently this is not dynamic.
    2. Revert to 5.6 behaviour where we scan directories and find .ibd files.
       If you move tablespaces to a new location, add the path to
       innodb-data-directories so that InnoDB can "discover" the files on
       startup.
    3. Tablespaces can only be created under known directories. This
       eliminates the need for .isl files.
    4. Upgrade redo log format, not backward compatible
    5. Change redo log type IDs
    6. Code cleanup
    7. Shard the fil system data structures for [1;31mperf[mormance
    8. Remove WL#9499 files that were used to track open tablespaces.
    
    RB#16842 Approved by: Jimmy and Kevin.

[33mcommit e592f604488d3caf50b0765e9d4fa0378423fd6c[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Fri Dec 8 12:10:42 2017 +1100

    WL#8619 - InnoDB: Provide offline database portability without ISL files
    
    Summary of changes.
    
    1. Introduce --innodb-directories := "dir1;...;dirN". This is renamed
       from --innodb-scan-directories which was introduced in WL#9499.
       Currently this is not dynamic.
    2. Revert to 5.6 behaviour where we scan directories and find .ibd files.
       If you move tablespaces to a new location, add the path to
       innodb-data-directories so that InnoDB can "discover" the files on
       startup.
    3. Tablespaces can only be created under known directories. This
       eliminates the need for .isl files.
    4. Upgrade redo log format, not backward compatible
    5. Change redo log type IDs
    6. Code cleanup
    7. Shard the fil system data structures for [1;31mperf[mormance
    8. Remove WL#9499 files that were used to track open tablespaces.
    
    RB#16842 Approved by: Jimmy and Kevin.

[33mcommit 9c9bdf17e2159af46ef036910a1e33fa14a5261e[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Dec 1 11:18:12 2017 +0100

    Bug #26399073: MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS [noclose]
    
    Fix a [1;31mperf[mormance regression; InnoDB has a system where the [1;31mperf[mormance
    schema key is decided by __FILE__, and the patch that extended the
    basename function to work with both / and \ made these allocations
    slower (as it uses std::string, which can allocate on the heap).
    
    However, there is no reason whatsoever that this lookup needs to be done
    runtime in a map. Change it to use a constexpr function; it goes through
    the array linearly, but it's small and it's compile-time. The end result
    is that the compiled code stores a PSI key directly, instead of taking
    __FILE__, removing its path runtime and looking it up in an std::map.
    
    Improves a data loading benchmark with ~3%, in addition to the ~7% regression
    it fixes.
    
    Change-Id: Ia536f6342278fcd6cc990053c3d2b0978e781b29

[33mcommit 11e31e18479cf06f142c9db5e12cac1775e5f51c[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Thu Dec 7 21:08:25 2017 +1100

    WL#8619 - InnoDB: Provide offline database portability without ISL files
    
    Summary of changes.
    
    1. Introduce --innodb-directories := "dir1;...;dirN"
    2. Tablespaces can only be created under known directories
    3. Upgrade redo log format, not backward compatible
    4. Change redo log type IDs
    5. Code cleanup
    6. Shard the fil system data structures - for [1;31mperf[mormance
    7. Revert to 5.6 behaviour where we scan directories and
       find .ibd files.
    8. Remove WL#9499 files that were used to track open tablespaces.

[33mcommit 2a7f51157003032675d98e0b8af698e80d1b5973[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Dec 6 16:53:17 2017 +0100

    Bug#24688694 SEVERAL UNSTABLE TESTS IN SUITE PERFSCHEMA
    
    Removed duplicated test cases from test
      [1;31mperf[mschema.idx_compare_ees_by_thread_by_error,
    which failed due to timeout.

[33mcommit 1eaa5b14f8ffb340e4d03fc5c39d4008a4e3a48f[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:52:52 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    Refactor TransporterRegistry::prepareSendTemplate() to:
    
    - Use likely/unlikely to annotate the fast path through this rather [1;31mperf[mormance
      critical code.
    
    - Remove duplicated check for 't == NULL'
    
    - Remove extra check for 'insertPtr != NULL' when 'resend work'.
      Instead return SEND_OK where we already know that getWritePtr suceeded .
    
    No functional changes.

[33mcommit 5d7eb6605a1400d90a0434446ea6e3e08437635b[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:38:57 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    and
    
    Bug#25128512 SET RR WITH >1 NG FAILS DUE TO 'WE(1) HAVE BEEN DECLARED DEAD BY 2 (VIA 4)'
    
    Patch fixes race conditions related to asynchronous disconnect / reconnect
    of the transporter while there could be other threads concurrently
    inserting signal data into the send buffers.
    
    A ::reset_send_buffer() was [1;31mperf[mormed as part of a disconnect, and
    we required the send buffers to still be empty when we later reconnect.
    When this failed, we could either hit the '!has_data_to_send' assert,
    or we received malicous data which had survived the disconnect.
    
    This patch introduce a number of changes to the Transporter implementations
    in order to fix the insufficent concurrency controll:
    
    1)
     The virtual TransporterCallback method reset_send_buffer() is
    replaced with the methods enable_send_buffer() / disable_send_buffer().
    As part of this an 'enabled' state is also introduced in each implementation
    of the TransporterCallback. This enable us to discard any thread local
    send buffers which are 'late' in being appended to a disabled transporter.
    
    1a)
     Enable and disabling of send buffers has been moved into the
    Transporter::connect* methods instead of having them in the
    TransporterRegistry::report_connect/_disconnect. The *receivers*
    are inited here as their connection state is protected by the
    poll right. However, the poll right gives no such protection
    for the send buffers. (Added a large comment about this)
    
    Thus, it feels more correct to handle
    the send buffers where the transporters are connected.
    
    1b)
     The method has_data_to_send() was removed as part of 1). As any
    'data_to_send' could later be discarded by disabling a node, it
    didn't really make sense to check for 'has_data' is it could
    immediately go away before doSend or whatever. Similar logic has
    instead been added to get_bytes_to_send_iovec(), where we with necessary
    locks held can collect (or discard) send buffer to doSend().
    
    2) Added the TransporterSendBufferHandle interface method ::isSendEnabled().
    It replace the usage if Transporter::isConnected() where this method was
    used in a 'send context'. isSendEnabled() provides us with a thread safe
    way of checking if send is enabled for a specific 'send handle'.
    
    2a) Usage of Transporter::isConnected in TransporterRegistry::prepareSend()
    is replaced with ::isSendEnabled().
    
    2b) Defined a 'synchronized' (client threads) or 'optimistic' (data nodes)
    implementation of ::isSendEnabled(). The 'synchronized' implementation
    should be the 'safe' implemetation which Transporter::isConnected() never
    was. This provides us with a thread safe way of checking the connectivity
    to a specific node. (API clients)
    
    2c) Datanodes (both mt- and non-mt) never really cared about a SEND_DISCONNECTED
    error from prepareSend() as it was ignored in the SimulatedBlock::sendSignal()
    methods. (Handled as SEND_OK together with SEND_BLOCKED). So an 'optimistic'
    ::isSendEnabled() is implemented here. (A 'synchronized' implememtation
    with have required taking a mutex, which we probably cant afford)
    Any send buffers allocated data to disabled nodes are discarded by the
    frequent doSend() calling get_bytes_to_send_iovec()

[33mcommit 9a11f17af92696bebd97f9914500aea55fcf6114[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:52:52 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    Refactor TransporterRegistry::prepareSendTemplate() to:
    
    - Use likely/unlikely to annotate the fast path through this rather [1;31mperf[mormance
      critical code.
    
    - Remove duplicated check for 't == NULL'
    
    - Remove extra check for 'insertPtr != NULL' when 'resend work'.
      Instead return SEND_OK where we already know that getWritePtr suceeded .
    
    No functional changes.

[33mcommit e4942b663f3b81e4c4669a729cd9c114dda0b7df[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:38:57 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    and
    
    Bug#25128512 SET RR WITH >1 NG FAILS DUE TO 'WE(1) HAVE BEEN DECLARED DEAD BY 2 (VIA 4)'
    
    Patch fixes race conditions related to asynchronous disconnect / reconnect
    of the transporter while there could be other threads concurrently
    inserting signal data into the send buffers.
    
    A ::reset_send_buffer() was [1;31mperf[mormed as part of a disconnect, and
    we required the send buffers to still be empty when we later reconnect.
    When this failed, we could either hit the '!has_data_to_send' assert,
    or we received malicous data which had survived the disconnect.
    
    This patch introduce a number of changes to the Transporter implementations
    in order to fix the insufficent concurrency controll:
    
    1)
     The virtual TransporterCallback method reset_send_buffer() is
    replaced with the methods enable_send_buffer() / disable_send_buffer().
    As part of this an 'enabled' state is also introduced in each implementation
    of the TransporterCallback. This enable us to discard any thread local
    send buffers which are 'late' in being appended to a disabled transporter.
    
    1a)
     Enable and disabling of send buffers has been moved into the
    Transporter::connect* methods instead of having them in the
    TransporterRegistry::report_connect/_disconnect. The *receivers*
    are inited here as their connection state is protected by the
    poll right. However, the poll right gives no such protection
    for the send buffers. (Added a large comment about this)
    
    Thus, it feels more correct to handle
    the send buffers where the transporters are connected.
    
    1b)
     The method has_data_to_send() was removed as part of 1). As any
    'data_to_send' could later be discarded by disabling a node, it
    didn't really make sense to check for 'has_data' is it could
    immediately go away before doSend or whatever. Similar logic has
    instead been added to get_bytes_to_send_iovec(), where we with necessary
    locks held can collect (or discard) send buffer to doSend().
    
    2) Added the TransporterSendBufferHandle interface method ::isSendEnabled().
    It replace the usage if Transporter::isConnected() where this method was
    used in a 'send context'. isSendEnabled() provides us with a thread safe
    way of checking if send is enabled for a specific 'send handle'.
    
    2a) Usage of Transporter::isConnected in TransporterRegistry::prepareSend()
    is replaced with ::isSendEnabled().
    
    2b) Defined a 'synchronized' (client threads) or 'optimistic' (data nodes)
    implementation of ::isSendEnabled(). The 'synchronized' implementation
    should be the 'safe' implemetation which Transporter::isConnected() never
    was. This provides us with a thread safe way of checking the connectivity
    to a specific node. (API clients)
    
    2c) Datanodes (both mt- and non-mt) never really cared about a SEND_DISCONNECTED
    error from prepareSend() as it was ignored in the SimulatedBlock::sendSignal()
    methods. (Handled as SEND_OK together with SEND_BLOCKED). So an 'optimistic'
    ::isSendEnabled() is implemented here. (A 'synchronized' implememtation
    with have required taking a mutex, which we probably cant afford)
    Any send buffers allocated data to disabled nodes are discarded by the
    frequent doSend() calling get_bytes_to_send_iovec()

[33mcommit 511c2f684fd0cf0fb386fbe6a6b2123171b5145f[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Dec 4 10:35:58 2017 +0100

    Bug#24970428 AUDIT LOG EVENTS FOR PERFORMANCE_SCHEMA.GLOBAL_VARIABLES
    
    1) Fixed the test main.audit_plugin_2.
    
    Removed references to SHOW_COMPATIBILITY_56 from test main.audit_plugin_2
    
    2) Improved logging of audit events in [1;31mperf[mormance_schema.global_variables
    
    Moved the call to
      mysql_audit_notify(MYSQL_AUDIT_GLOBAL_VARIABLE_GET)
    done in the [1;31mperf[mormance schema to method
      table_global_variables::make_row()
    so that audit events are raised only for rows returned to the SQL layer,
    instead of generating events for all materialized rows as before.
    
    This makes the following query:
      SELECT * FROM [1;31mperf[mormance_schema.global_variables
         WHERE VARIABLE_NAME = 'foo';
    generate only one audit log event,
    thanks to the index by variable name on table global_variables.

[33mcommit c0ad91bb19a43e1ed9800168a4548c456a2028c1[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Nov 30 16:23:10 2017 +0100

    Bug#27121500 PERFORMANCE_SCHEMA INDEX ON OBJECT_TYPE BROKEN
    
    Queries in [1;31mperf[mormance schema using indexes on OBJECT_TYPE
    columns do not return the correct results.
    
    The root cause is the evaluation of whether a given record
    matches or not a given key value,
    implemented in PFS_key_object_type::match().
    This code does not implement NULL checks properly.
    
    In the [1;31mperf[mormance schema, a record that has a NULL
    OBJECT_TYPE is represented with an object_type == NO_OBJECT_TYPE,
    and there are no boolean flags to mark the field as NULL.
    This works because NO_OBJECT_TYPE is not a possible value.
    
    In a key provided by a WHERE clause,
    the object type comes from the query, and can have any value,
    especially for VARCHAR columns.
    
    When a key is NULL, PFS_key_object_type::m_is_null is true,
    and the value of PFS_key_object_type::m_object_type is irrelevant.
    
    When a key is not null, but when the OBJECT_TYPE provided
    (as in WHERE OBJECT_TYPE = 'impossible')
    does not match the expected object types,
    the code converts the string to NO_OBJECT_TYPE,
    exposing the bug.
    
    The bug is that this comparison:
      m_object_type == object_type
    does not work when a key is not null but impossible,
    as it matches records that are not supposed to match.
    
    The fix is to implement PFS_key_object_type::do_match(),
    with proper checks for NULL keys and or NULL records
    before comparing the key value with the record value.
    
    Likewise for PFS_key_object_type_enum.

[33mcommit 0ecc3a1b6b61f2f39a5d23932e8e713d5e74f588[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:52:52 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    Refactor TransporterRegistry::prepareSendTemplate() to:
    
    - Use likely/unlikely to annotate the fast path through this rather [1;31mperf[mormance
      critical code.
    
    - Remove duplicated check for 't == NULL'
    
    - Remove extra check for 'insertPtr != NULL' when 'resend work'.
      Instead return SEND_OK where we already know that getWritePtr suceeded .
    
    No functional changes.

[33mcommit d6bf2b19f240e60c8c86240c61748b75b4019655[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:38:57 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    and
    
    Bug#25128512 SET RR WITH >1 NG FAILS DUE TO 'WE(1) HAVE BEEN DECLARED DEAD BY 2 (VIA 4)'
    
    Patch fixes race conditions related to asynchronous disconnect / reconnect
    of the transporter while there could be other threads concurrently
    inserting signal data into the send buffers.
    
    A ::reset_send_buffer() was [1;31mperf[mormed as part of a disconnect, and
    we required the send buffers to still be empty when we later reconnect.
    When this failed, we could either hit the '!has_data_to_send' assert,
    or we received malicous data which had survived the disconnect.
    
    This patch introduce a number of changes to the Transporter implementations
    in order to fix the insufficent concurrency controll:
    
    1)
     The virtual TransporterCallback method reset_send_buffer() is
    replaced with the methods enable_send_buffer() / disable_send_buffer().
    As part of this an 'enabled' state is also introduced in each implementation
    of the TransporterCallback. This enable us to discard any thread local
    send buffers which are 'late' in being appended to a disabled transporter.
    
    1a)
     Enable and disabling of send buffers has been moved into the
    Transporter::connect* methods instead of having them in the
    TransporterRegistry::report_connect/_disconnect. The *receivers*
    are inited here as their connection state is protected by the
    poll right. However, the poll right gives no such protection
    for the send buffers. (Added a large comment about this)
    
    Thus, it feels more correct to handle
    the send buffers where the transporters are connected.
    
    1b)
     The method has_data_to_send() was removed as part of 1). As any
    'data_to_send' could later be discarded by disabling a node, it
    didn't really make sense to check for 'has_data' is it could
    immediately go away before doSend or whatever. Similar logic has
    instead been added to get_bytes_to_send_iovec(), where we with necessary
    locks held can collect (or discard) send buffer to doSend().
    
    2) Added the TransporterSendBufferHandle interface method ::isSendEnabled().
    It replace the usage if Transporter::isConnected() where this method was
    used in a 'send context'. isSendEnabled() provides us with a thread safe
    way of checking if send is enabled for a specific 'send handle'.
    
    2a) Usage of Transporter::isConnected in TransporterRegistry::prepareSend()
    is replaced with ::isSendEnabled().
    
    2b) Defined a 'synchronized' (client threads) or 'optimistic' (data nodes)
    implementation of ::isSendEnabled(). The 'synchronized' implementation
    should be the 'safe' implemetation which Transporter::isConnected() never
    was. This provides us with a thread safe way of checking the connectivity
    to a specific node. (API clients)
    
    2c) Datanodes (both mt- and non-mt) never really cared about a SEND_DISCONNECTED
    error from prepareSend() as it was ignored in the SimulatedBlock::sendSignal()
    methods. (Handled as SEND_OK together with SEND_BLOCKED). So an 'optimistic'
    ::isSendEnabled() is implemented here. (A 'synchronized' implememtation
    with have required taking a mutex, which we probably cant afford)
    Any send buffers allocated data to disabled nodes are discarded by the
    frequent doSend() calling get_bytes_to_send_iovec()

[33mcommit cfcbe404b2ab4bd5600fa0b52246a6d6cb5c6836[m
Author: Rahul Sisondia <rahul.sisondia@oracle.com>
Date:   Fri Dec 1 09:58:40 2017 +0100

    Bug#25122897 SET DEFAULT ROLE NOT TRANSACTIONAL
    
    Description
    -----------
    When SET DEFAULT ROLE statement is executed,
    Sql_cmd_alter_user_default_role::execute() method is called.
    This method [1;31mperf[morms a few sanity checks and then alters the default roles for
    every user one by one. It means we acquire the table lock and ACL lock for every
    user, make the changes and commit them for the user. Instead, we must acquire
    the locks once, do the alter roles for all users and then commit in the end.
    
    Fix:
    ------
    - Introduced a new method named mysql_alter_or_clear_roles() which is called
      from the Sql_cmd_alter_user_default_role::execute(). The new method acquires
      the locks, alters the roles for all users according to the specified role_type
      and then commits the acl ddl changes.
    
    - Since we now need to pass the role_type in the method argument therefore, we
      had to do the forward declaration of the same in the auth_common.h . Only enum
      class can be forward declared therefore, changed the "enum role_enum" to
      "enum class role_enum" and updated the cascade effects of the same.
    
    - Removed the following 3 wrapper methods
       -  mysql_clear_default_roles
       -  mysql_alter_user_set_default_roles_all
       -  mysql_alter_user_set_default_roles
    
    Testing :
    
    Introduced a new test file 'atomic_alter_roles' that verifies the following the three scenarios
    a. SET DEFAULT ROLE 'role 1' , 'role 2' to user1 , user 2
    b. SET DEFAULT ROLE ALL to user 1, user 2
    c. SET DEFAUL ROLE NONE to user1 , user 2
    Added a new test in the existing file 'atomic_create_user' that verified the following scenario
    a. CREATE USER user 1, user 2 DEFAULT ROLE 'qa';
    
    Ctest results -
    
    100% tests passed, 0 tests failed out of 46
    Total Test time (real) =  55.21 sec
    
    > -----Original Message-----
    > From: MYSQL-PREPUSH-TESTING_WW_GRP@oracle.com [mailto:MYSQL-
    > PREPUSH-TESTING_WW_GRP@oracle.com]
    > Sent: Fri, December 1, 2017 11:08 AM
    > To: rahul.sisondia@oracle.com
    > Subject: Pre-push testing result on linux platform : mysql-trunk [ Fail ]
    >
    > Build#3844 - Changeset:
    > + 1bd963041228d62ef050722338b7d7b926b5cdc4 Bug#25122897 SET
    > DEFAULT ROLE
    > + NOT TRANSACTIONAL
    >
    > MTR    : All tests are successful
    > CHTEST : Unsuccessful
    
    Note - CHTEST failure seems uprelated to this bug fix.
    
    Review : RB#18034

[33mcommit 3c7c83a83e89131df33cb3984d68e586f9e5c659[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Nov 21 16:02:57 2017 +0100

    Bug#27124506 NEW MDL OBJECT TYPES NOT INSTRUMENTED IN PERFSCHEMA
    
    Before this fix,
    
    Metadata Lock name spaces introduced recently by new features
    were not instrumented properly with the [1;31mperf[mormance schema.
    
    In particular, the following MDL keys were not instrumented:
    - SRID
    - COLUMN_STATISTICS
    
    The root cause is the incomplete switch statement
    in PFS_object_row::make_row() which does not
    print new types of keys correctly.
    
    With this fix:
    
    1)
    
    MDL_key::SRID is supported in table metadata_locks.
    
    2)
    
    MDL_key::COLUMN_STATISTICS is supported in table metadata_locks.
    
    3)
    
    To print correctly MDL for COLUMN_STATISTICS,
    a new column COLUMN_NAME is added in table metadata_locks.
    
    The existing index on OBJECT_TYPE, OBJECT_SCHEMA, OBJECT_NAME
    has been extended to include the new COLUMN_NAME.
    
    4)
    
    MDL keys for columns are represented as:
    - SCHEMA + NAME + COLUMN for most cases,
    - or SCHEMA + NAME in some degraded cases,
    so they are more observable.
    
    Before this fix, the MDL key was:
      SHA1(SCHEMA + NAME + COLUMN),
    which was obfuscated,
    as a work around for size constraints.

[33mcommit d3c39c158eb69df11d623b8a14c87f10cc4c3686[m
Author: Tiago Alves <tiago.alves@oracle.com>
Date:   Thu Nov 23 11:18:11 2017 +0000

    BUG#27166613 Ensure ATRT waits for processes to be undefined before (re)start
    
    While CPCD is of asynchronous nature (i.e. when requesting to start a process
    does not necessarily mean the process has started when the method returns)
    ATRT assumed CPCD was syncrhonous. Hence, when ATRT restarted a process it
    could happent that it would start a process before it has completely stop
    leading to test run failures.
    
    The main change was to add logic to wait for a process to stop. This logic
    must be used after stopping a process or a set of processes.
    We did not make wait for process stop part of the stop logic to prevent
    refreshing state every time we want to stop a process and to allow stopping
    several processes in one go, and then waiting for those to finish also in
    one go.
    
    The above change additionally required that process status update is done
    via update_status method only, hence emoving wrong assumptions about the
    processes life-cycle (e.g. when saving a process, first [1;31mperf[morm stop, and
    then save its status).
    
    Additionally, we made CpcClient connection more robust by checking that
    messages are actually sent and received (prevent erroneous usage of the
    API before connection is open).
    
    Finally, added extra logging to ATRT to be able to more easily diagnose test
    failures.
    
    NOTE: There's an interesting situation when resetting processes configuration,
          we start by stopping the management nodes first and then the data nodes.
          Stopping the second last data node, causes the last data node to quit
          by itself (watchdog). We updated the logic not to fail on this scenario.
          However, a better approach would be to reverse all this logic, stopping
          first all the servers, then the data nodes, and last the mgmd nodes.

[33mcommit 2be32ee2259099ee332e2f326a4fd8e7e58e1a64[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Nov 28 16:00:54 2017 +0100

    Bug#24688694 SEVERAL UNSTABLE TESTS IN SUITE PERFSCHEMA
    
    Improved stability of test [1;31mperf[mschema.idx_compare*
    Removed tests involving OR clauses,
    as these do not use indexes anyway.

[33mcommit 490f74226dc225baa30c319e29783ad377b9865f[m
Author: Kristofer Älvring <kristofer.pettersson@oracle.com>
Date:   Mon Nov 27 13:58:38 2017 +0100

    Bug#27136346 SYSBENCH CONNECT TEST SHOWS -95% REGRESSION FOR NON-ROOT VS ROOT USER
    
    None root users experienced a 95% drop in CPU utilization due to a cache
    which is suppose to store database privileges based on user name and host
    for fast acccess. The cache is protected be a rw lock that needs to be
    checked for success. The check was inveresed so it reported failure
    on success and vice versa which ultimately caused the [1;31mperf[mormance issues
    as a write lock was taken 10 times for every connection attempt by
    internal system processes.

[33mcommit 52d3594db2feb8be1309ced2ebdcda53aa6dae63[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Sat Nov 25 20:36:38 2017 +0100

    Bug#27171283: FREQUENT BUFFER REALLOCATIONS WHEN SERIALIZING JSON
    
    When serializing a JSON value to its binary representation,
    String::reserve(size_t) is sometimes called to make sure the
    destination buffer has enough room to hold an integer or double value
    of a given size. Unfortunately, if the String needs to allocate more
    memory, this variant of reserve() only reserves the minimum amount of
    memory needed, so it is very likely that a new reallocation is needed
    shortly after. This hurts [1;31mperf[mormance, especially when serializing
    arrays with many numeric values.
    
    This patch makes the serialization use the two-argument variant of
    String::reserve() so that reallocations will increase the buffer size
    exponentially and amortize the cost of the reallocations.
    
    Microbenchmarks (64-bit, Intel Core 2 Quad 2.83GHz, GCC 7.2):
    
    BM_JsonBinarySerializeIntArray      17492816 -> 352638 ns/iter [ +4861%]
    BM_JsonBinarySerializeDoubleArray   80549060 -> 321707 ns/iter [+24938%]
    BM_JsonBinarySerializeStringArray     744725 -> 728882 ns/iter [  +2.2%]
    
    Change-Id: Icdb6316c80021043ada5467f4798028b8d44c7e4

[33mcommit 2587d0dc1d035116c0ff9fb39cc7ef307b6bd431[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Nov 23 11:42:41 2017 +0100

    Bug#24688694 SEVERAL UNSTABLE TESTS IN SUITE PERFSCHEMA
    
    Improved stability of test [1;31mperf[mschema.idx_*

[33mcommit da63541a69ea8c143a8e9466ff26e6651936f8f5[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Nov 21 12:34:36 2017 +0100

    Bug #26399073: MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS [noclose]
    
    In ut_basename_noext(), search for both / and \ on all platforms,
    not just the primary separator. Notably, when building with Ninja
    on Windows, __FILE__ can contain a mix of back- and forward slashes,
    confusing the mapping of filename to [1;31mperf[mormance schema key.
    
    Unbreaks a few InnoDB tests when running under Clang on Windows.
    
    Change-Id: I35fcae2c28ba9f1f0f403b2cb617c9fd7b4e88ee

[33mcommit 79dd88f1f608387c3ef92ea2acdc95933d695f7f[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Nov 22 10:31:00 2017 +0100

    Bug #27130109: REMOVE OPTIMIZER_TRACE COMPILATION FLAG
    
    We have a CMake flag OPTIMIZER_TRACE=0 to turn off compilation of
    optimizer trace into the binary. However, this has no visible [1;31mperf[mormance
    impact or any other known advantage (sysbench run showed less than <1%
    difference, which is probably noise), so just remove it.
    
    Change-Id: I242122607e81b7921c1b2ecbc87e3417e3e2e084

[33mcommit a960a2f77814a37bbb691b735c88d5b0b1a9d6a3[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Nov 14 11:54:31 2017 +0100

    BUG#24688694 SEVERAL UNSTABLE TESTS IN SUITE PERFSCHEMA
    
    Test script changes only.
    
    Fixed spurious failures in tests [1;31mperf[mschema.idx_compare_*
    
    In particular, changed how the actual result
    is compared to the expected result.
    
    Before this change,
    procedure index_test() was given the rows_expected
    parameter, to assess if a result set is expected or not.
    
    In case of non deterministic results,
    for example with a WHERE clause like
      thread_id > @target_thread_id
    this does not work.
    
    A better approach is to compare
    - the result without indexes
    - the result with indexes
    for a given case,
    even if the given result set is unpredictable,
    as the point if to enforce that it does not change
    when using indexes.
    
    Fixed some tests results with incorrect .result files,
    where an error was actually recorded,
    further proof that the test logic is not robust
    (as these tests actually passed).
    
    Fixing the test logic to be more robust also exposed
    an existing bug,
    added to mysql-test/suite/[1;31mperf[mschema/t/disabled.def

[33mcommit 84091e8d346f6399d72031e297250cff9e3c877c[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Tue Nov 7 09:28:21 2017 +0800

    Bug #25694140  THE IMPLEMENTATION OF QUERYING P_S.REPLICATION_APPLIER_FILTERS IS SUBOPTIMAL
    
    When querying [1;31mperf[mormance_schema.replication_applier_filters or
    [1;31mperf[mormance_schema.replication_global_applier_filters tables,
    it generates a view on the filters for every row that is
    created. This is suboptimal.
    
    We implement the best approach to make sure that the P_S view over
    the filters is generated only when the filters are changed. To
    per-channel replication filters, actually increasing counter does
    not change the structure of the P_S view. So we should hold the
    write lock of rpl_channel_filters to generate the P_S view only on
    startup, on CHANGE REPLICATION FILTER, on RESET SLAVE ALL, and on
    CHANGE MASTER to ..., then we just need to hold a read lock of
    rpl_channel_filters to read the P_S view while querying
    P_S.replication_applier_filters. To global replication filter,
    we should hold the write lock of Rpl_global_filter to generate
    its P_S view only on startup and on CHANGE REPLICATION FILTER,
    then we just need to hold a read lock of Rpl_global_filter to read
    its P_S view while querying P_S.replication_applier_global_filters.
    At the same time, we optimize the code to create a derived class
    of class Rpl_filter for global replication filter and fix a prone
    issue.

[33mcommit 5892c502b46bf0dffe6afcb6b4b079d48c46d94d[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Thu Oct 19 10:18:08 2017 +0200

    Bug#26739438: DEADLOCK ON GET_LOCK(..., 0)
    
    Problem: Concurrent calls to GET_LOCK could cause deadlock, even with
    a wait time of 0.
    
    Root cause was that MDL_context::acquire_lock() would add the ticket
    as waiter and [1;31mperf[morm deadlock detection analysis even when the wait
    time was 0.
    
    Solution: Return error immediately if lock cannot be obtained and wait
    time is 0.
    
    (cherry picked from commit c528fee7d9c8186bcc14549f62b1f835ab01c0c5)

[33mcommit 09783de0079e47ecf085a9ce5cdc1a4558bfe50f[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Thu Oct 19 10:18:08 2017 +0200

    Bug#26739438: DEADLOCK ON GET_LOCK(..., 0)
    
    Problem: Concurrent calls to GET_LOCK could cause deadlock, even with
    a wait time of 0.
    
    Root cause was that MDL_context::acquire_lock() would add the ticket
    as waiter and [1;31mperf[morm deadlock detection analysis even when the wait
    time was 0.
    
    Solution: Return error immediately if lock cannot be obtained and wait
    time is 0.

[33mcommit 8fd1171af59caf3dbe65aad83b0a9038ee564106[m
Author: Kristofer Älvring <kristofer.pettersson@oracle.com>
Date:   Wed Nov 1 10:23:58 2017 +0100

    Bug#26679935 THE RW LOCK IN CHECK_GRANT IS TAKEN EVEN IF THE SESSION HAS ACTIVE ROLES.
    
    If active roles are used, then the acl cache lock which protects the
    global acl cache doesn't need to be taken during check_grant().
    By relaxing the lock we gain some [1;31mperf[mormance and scale out capability.

[33mcommit 312a9d385f129a3803a0d2bc70e4b23ede72d30b[m
Author: Nuno Carvalho <nuno.carvalho@oracle.com>
Date:   Wed Sep 13 19:27:23 2017 +0200

    WL#11139: Remove group_replication_allow_local_disjoint_gtids_join option
    
    The option group_replication_allow_local_disjoint_gtids_join[1] was
    introduced with the purpose[2]:
      This variable is an override mechanism for a new consistency feature
      in the plugin. When you try to add to the group a server that has
      more data than the existing members, by default the joining member
      will be rejected.
      The purpose is to avoid possible recovery and run time errors in
      the plugin leading to data divergence and other issues. If you are
      sure of what you are doing, and that the extra data is safe, then
      you can use this option.
    
    The scenarios on which this can help users are:
    
     S1) Solve a broken majority asap
         * Group had 3 members in single-primary mode
         * 2 members crashed and end up with different data
           (GTID_EXECUTED) when compared with the group.
         * User wants to add one of the members (S2) to solve the
           majority loss or increase group members number to handle
           possible future member failures.
         * The member that is still on the group is the one that is the
           primary or will be elected as primary when majority is
           re-established, since is the only one ONLINE.
         * The group will be stable if a future failover does not switch
           to the S2 member.
    
    The runtime errors that may happen are that the member which did
    force the join with disjoint GTIDS, if it does a write, the changed
    rows will never be updated by other members. Certification will
    fail.
    The recovery errors that may happen are that if this member is
    chosen as donor, it will distribute the disjoint GTIDS among the new
    members and increase the likelihood of the runtime errors to happen.
    
    It must never be used unless the DBA knows exactly what she/he is
    doing or does need to solve a broken majority, on which crashed
    members suffered corruption and she/he will not [1;31mperf[morm writes on
    it. Which can already be done by resetting master and setting
    GTID_PURGED to match the GTID executed of the group if they really
    want to add the damaged server to the group.
    
    People use this option to force member join, and assume that since
    member did successfully join everything is OK. Which is not the
    case, data is inconsistent.
    
    The correct procedure to fix a majority loss is described at
    https://dev.mysql.com/doc/refman/8.0/en/group-replication-network-partitioning.html
    
    Since the trade-off between this option benefit vs danger is
    negative, we are removing this option.

[33mcommit 0e132604bec77f9c48c8dd02de871d06bdccebc3[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Wed Oct 25 23:31:02 2017 +0530

    Bug#26944731 : UPGRADE TO 8.0 FAILS: DUPLICATE SET VALUES IN TABLE FROM
                   A PERMISSIVE SQL_MODE..
    Bug#26948678 : MYSQLD: INVALID DEFAULT VALUE FOR 'CACHED_TIME'
    
    1> In-place upgrade from 5.7 fails when server is started with
       --explicit-defaults-for-timestamp=0 in creating dictionary tables
       with error: Invalid default value for 'cached_time'
    
    2> In-place upgrade from 5.7 fails irrespective of user provided sql
       mode if SET data type has duplicated values with error:
       Column <column_name> has duplicated value <value> in SET
    
    3> --initialize with --explicit-defaults-for-timestamp=0 to
       create new data directory fails in creating [1;31mperf[mormace schema
       'variables_info' table with error:
       Invalid default value for 'SET_TIME'
    
    Fix:
    -----
    1> Set explicit-defaults-for-timestamp to true for the bootstrap thread.
       Dictionary tables and [1;31mperf[mormance schema tables are created from
       bootstrap threads. This will allow dicitonary and [1;31mperf[mormace schema
       table creation by following the standard behavior for timestamp data
       type.
    
    2>  While migrating tables, mysql_prepare_create_table() is called which
        checks for duplicated value in SET data type. Error is reported for
        duplicated values only in strict sql mode. Set sql_mode to ZERO when
        populating data dictionary for in-place upgrade.

[33mcommit b25ac043da4dda40b7f0e8d36ec1bd68cca7b02d[m
Author: Athreya Permunda <athreya.permunda@oracle.com>
Date:   Fri Oct 27 12:25:07 2017 +0530

    Bug #27009386 SOME NDBAPI EXAMPLE PROGRAMS DO NOT CLEANUP DATA, TABLE BEFORE EXIT
    
    The ndbapi_array_simple and ndbapi_array_using_adapters example programs fail to run
    when tried to run more than once. This is because the program fills the respective
    table with tuples when run the first time and tries to insert the same tuples when
    run again, thus giving an error that the tuples already exist.
    code: 630, msg: Tuple already existed when attempting to insert.
    
    Fix:
    After inserting and reading the tuples of the tables, [1;31mperf[morm a cleanup, i.e., delete
    all tuples in the tables.

[33mcommit 5bf7de3af198b4ce8422d050110abb03404054bd[m
Author: Anibal Pinto <anibal.pinto@oracle.com>
Date:   Fri Oct 13 16:02:33 2017 +0200

    BUG#26883936: UNCLEAR AND DUPLICATED MESSAGE AFTER RECOVERING FROM A MAJORITY LOSS
    
    After:
      - Create two nodes
      - Kill one of them
      - Force a new configuration
    
    the following errors appear in the log:
    
    2017-09-28T05:09:43.732265Z 0 [Warning] [000000] Plugin group_replication
    reported: 'The member with address 10.0.2.15:13000 has already sent the
    stable set. Therefore discarding the second message.'
    2017-09-28T05:09:43.733539Z 0 [Warning] [000000] Plugin group_replication
    reported: 'The member with address 10.0.2.15:13000 has already sent the
    stable set. Therefore discarding the second message.'
    2017-09-28T05:09:43.735076Z 0 [Warning] [000000] Plugin group_replication
    reported: 'The member with address 10.0.2.15:13000 has already sent the
    stable set. Therefore discarding the second message.'
    2017-09-28T05:09:43.736512Z 0 [Warning] [000000] Plugin group_replication
    reported: 'The member with address 10.0.2.15:13000 has already sent the
    stable set. Therefore discarding the second message.'
    2017-09-28T05:09:43.737462Z 0 [Warning] [000000] Plugin group_replication
    reported: 'The member with address 10.0.2.15:13000 has already sent the
    stable set. Therefore discarding the second message.'
    
    This message can be logged on two situations:
      1) There is a network partition, messages are queued until the
         group is unblock, and when it is unblocked all delivered in
         batch, then the warning.
         For this scenario, network partition, we already the proper log
         messages, so this "duplicate stable set" message is not needed.
      2) There is a member sending stable set messages in loop, if that
         unlikely event happens, then everything is wrong and this
         message does not clarify nothing.
    
    Removed the message and improved certification garbage collection [1;31mperf[mormance
    message.

[33mcommit d703c5b1884fa5b87cc154fb02375431a473ca74[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Oct 11 10:41:03 2017 +0200

    Bug#17840780 PERFORMANCE_SCHEMA.SETUP_INSTRUMENTS* TESTS UNSTABLE ON PB2
    
    Improved the test [1;31mperf[mschema.setup_instruments_default robustness.
    
    Do not restart the server from within a mtr test script,
    it makes the test slow and unstable under heavy load.

[33mcommit af396f10bac47f1cf40e600d51fbd82349f17ed3[m
Author: Narendra Chauhan <narendra.chauhan@oracle.com>
Date:   Tue Oct 10 19:39:43 2017 +0530

    Bug#26945099 - RPL.RPL_REWRITE_DB_FILTER_COUNTER IS FAILING DUE TO RESULT CONTENT MISMATCH
    
    Description:
    Testcase is running query on [1;31mperf[mormance_schema.replication_applier_filters
    to check for the "REPLICATE_REWRITE_DB" filters set. But, if any other
    filters related testcase (which have CRF command) gets executed before this
    testcase, then, that can create result content mismatch in this testcase.
    
    RB: 17594

[33mcommit e46a0defd9ba6b39e15752264a4265b637d41bee[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Tue Oct 10 01:28:24 2017 +0530

    Bug#26636238 : ERROR/INPLACE UPGRADE TO READ-ONLY 8.0: PERFORMANCE SCHEMA INITIALIZATION FAILED
    
    Post push fix:
    [1;31mperf[mschema.init_pfs_from_dd fails on the ASAN build. The reason for
    failure is that server restart returns different error code than
    expected.
    
    The failure is due to an existing bug in the innodb initialization.
    If InnoDB is partially initialized and it encounters an error, InnoDB
    does not do proper cleanup required. In the test case, InnoDB is
    started with --innodb-read-only option and encounters error while trying
    to resize the log files. The default value for innodb_log_file_size
    is different in mysqld and mtr.
    
    Fix the test case by supplying the same value of innodb_log_file_size
    while restarting the server with which log files were created.

[33mcommit 2ea0012c639a904248100b8ee3aa9e634c5b54cc[m
Author: Thayumanavar S <thayumanavar.x.sachithanantha@oracle.com>
Date:   Tue Oct 10 09:16:23 2017 +0200

    BUG#26710081 - EVENTS_TRANSACTIONS_CURRENT:GTRID IS NOT
                   PROPERLY DISPLAYED.
    
    Incorrect value of XID_GTRID is reported in the
    [1;31mperf[mschema.events_transactions_current_table for XA transactions.
    This happens because if an statement in the XA transaction results
    in creating an attachable transaction as part of it's internal operation in
    querying the Data Dictionary table. The attachable transaction result in
    creating an PSI transaction handle which resets the already created transaction
    locker object in PFS.
    The fix is not to create the transaction locker object in PFS thereby not
    recording the transaction related counters for attachable transaction.
    The result files of MTR test files corresponding to transaction events
    now are similar as in MySQL 5.7. Bug# 26936457 will record attachable
    transaction events as a nested event of the master transaction in PFS.
    Certain counters like IO waits and table waits that occur as part of
    attachable transaction shall be associated with the main transaction events.

[33mcommit 4cd3aabf5b467debbc449e3c12e08e44a568a6d9[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Oct 6 17:12:05 2017 +0200

    Bug#26636238 : ERROR/INPLACE UPGRADE TO READ-ONLY 8.0: PERFORMANCE
                   SCHEMA INITIALIZATION FAILED
    
    Post-post push for
    
       Post push fix:
    
       Fix test case to check [1;31mperf[mormance schema version mismatch failure
       with --innodb-read-only instead of --read-only option.
    
    The server now exits, and ASAN detects a memory leak.
    Fix is to ignore exit status 42 from server.
    
    Change-Id: Ic5de33af081a083ec337a357f5c843f1cc2be887

[33mcommit f63cbccb7558654f571862d77f22d38cdc6ea9fe[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Oct 4 09:30:41 2017 +0200

    Bug#26897738 PERFORMANCE SCHEMA SERVICES HEADERS DEPENDENCY ON MY_CONFIG.H
    
    Before this fix,
    [1;31mperf[mormance schema related header files from
      mysql/components/services/
    would indirectly include
      include/my_config.h
    
    This dependency is not allowed,
    as it makes public (and installed) service headers
    dependent on private (and not installed)
    server build configuration headers.
    
    The fix is to re organize and clean up header files
    for [1;31mperf[mormance schema services as follows:
    
    1) Do not use "ulonglong" and similar convenience types
    provided by "my_inttypes.h",
    use plain "unsigned long long" instead.
    
    2) Do not use "my_macro.h" and C_MODE_START (aka, extern "C").
    The point of a service is to not export functions anyway,
    so the extern "C" is never needed.
    
    3) Move fragments of "my_thread.h" into
      mysql/components/services/my_thread_bits.h,
    to define basic types related to threads.
    
    4) Move fragments of "my_io.h" into
      mysql/components/services/my_io_bits.h,
    to define basic types related to file and socket I/O.
    
    With these changes, [1;31mperf[mormance schema service headers are self contained,
    without dependencies on non installed headers.

[33mcommit 83f2f808bdd958e36f3eeeb9384ab91c1c11c31a[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Sep 7 07:49:15 2017 +0200

    WL#9185 MySQL Cluster support for new DD
    
     - remove unnecessary 'free_share' and call ndbcluster_free_share()
       directly in all places.
     - add assert checking that mutext is properly held
     - remove su[1;31mperf[mlous log and dbug printouts from
       ndb_cluster_free_share()

[33mcommit 03f61247956d96bce962352db663351bd0892c39[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Oct 5 11:09:06 2017 +0200

    Bug#24688694 SEVERAL UNSTABLE TESTS IN SUITE PERFSCHEMA
    
    Improved stability of test [1;31mperf[mschema.selects

[33mcommit 74f076fe19191a7a9fc6b48aeb90c9c465a74b88[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Fri Aug 18 17:10:06 2017 +0530

    Bug #26026218 : TRANSPORTER ERROR 0X8004, 0X8023; CHECKSUM; UNSUPPORTED BYTE ORDER
    
    Checksum checking is added to the TCP Transporter using the new class + utils.
    
    doSend() obtains an array of IOVECs and attempts to send all of the data from
    them, in multiple passes.
    
    The OS may manage to send some, all or none of the data, which could result in
    IOVEC offsets changing, becoming odd etc over time.
    
    doSend() will :
      a) Check checksums for all data available in IOVECs prior to OS::send()
      b) Check checksums for all sent data afer OS::send()
    
    Obviously this adds some CPU load to the threads [1;31mperf[morming sending.

[33mcommit 43f690ee1b9cd83f32a9c77b9504b267c310ea46[m
Author: Anitha Gopi <anitha.gopi@oracle.com>
Date:   Wed Oct 4 07:52:03 2017 +0200

    Updates to default.experimental and disabled.def files
    
    * [1;31mperf[mschema.transaction_nested_events - A fix was pushed for Bug#17752288  a while back, but the test was never moved out of experimental state. Last failure was seen in Aug 2017. Enabling the test
    * innodb_fts.mecab_sjis - Filed bug and updated disabled.def
    * rpl_gtid_delete_memory_table_after_start_server : Updated with correct bug number
    * main.internal_tmp_disk_storage_engine - Filed bug and updated disabled.def

[33mcommit 7c8d3491e9de3ee1b7eca737a8707e41b2b9f4c7[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Fri Sep 29 09:34:58 2017 +0200

    Bug#26428017 VARIABLE SCOPE OF AUTOCOMMIT NOT CHANGING TO
    COMMAND_LINE/EXPLICIT/EXTRA
    
    Issue:
    
    Before this fix, table [1;31mperf[mormance_schema.variables_info
    was not reporting proper data for the autocommit system variable.
    
    In particular, the VARIABLE_SOURCE column was always COMPILED,
    even when the autocommit system variables set in command lines argument
    or in configuration files.
    
    Root cause:
    
    The root cause is specific to the --autocommit variable itself
    
    - Sys_autocommit is a Sys_var_bit
    - my_handle_options() does not support *bit* values, only booleans,
      so that my_handle_options() can not set the autocommit bit in
      THD::variables.option_bit directly
    
    To work around that, a *second* option, also named autocommit,
    was added in my_long_options[]
    
    As a result, there are *two* options named "autocommit",
    which confuses the code when keeping track of the option source.
    
    The --autocommit option source is not preserved (because it is not a system
    variable), while the @@global.autocommit system variable source is never
    updated (it is shadowed by --autocommit).
    
    Fix:
    
    Allocate a source structure for the --autocommit option,
    so that the source of --autocommit is preserved when parsing arguments.
    
    When the data is copied from --autocommit to @@global.autocommit,
    also copy the metadata (the option source)

[33mcommit aff97b83f797a8ea103e98f35c95d0ff614efb0a[m
Author: Erik Froseth <erik.froseth@oracle.com>
Date:   Fri Sep 29 08:33:30 2017 +0200

    Bug#26772858 MDL FOR COLUMN STATISTICS IS NOT PROPERLY REFLECTED IN P_S.METADATA_LOCKS
    
    Post-push fix: The test case for the fix was not stable, caused
    by some DEBUG_SYNC-actions missing. For instance, the connection
    inspecting the changes in [1;31mperf[mormance_schema.metadata_locks executed
    its SELECT against the table before the connection holding the lock
    actually had granted the lock.
    
    Change-Id: Ie89c6658680729524099af32adc13b547dc62e95

[33mcommit 483deeafa4214a43197f9f9dde1adebf399351f1[m
Author: Xing Zhang <xing.z.zhang@oracle.com>
Date:   Wed Aug 30 14:30:31 2017 +0800

    Bug #25680866: _CHARACTERSET SPECIFICATIONS HAVE LOUSY PERFORMANCE FOR SOME CHARACTER SETS
    
    Literal character set name is translated to character set number by looping
    through all_charsets array. The [1;31mperf[mormance is low and will get worse when
    we add new collations in the future.
    
    Fix:
    Change to use unordered_map to translate character set name to number.
    
    BM_LookupAllCollations   454 -> 383 ns/iter [+ 18.5%]
    BM_LookupAllCharsets     253 -> 180 ns/iter [+ 40.6%]
    
    Change-Id: I9730789ff2baa7b931a95d472c127c7192d7557a
    (cherry picked from commit d03d71be1f082d8c74487cf6787df29e8d1447c8)

[33mcommit 27856d14cf29bec3313473e8fcb22ee71052a814[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Tue Sep 26 10:02:26 2017 +0200

    Bug#26798989: Sig 11 in find_table_in_global_list
    
    The problem here is when we have a materialized derived table that
    is determined to be su[1;31mperf[mluous, thus destroy_materialized() is
    called on it. Later, the function find_table_in_global_list() is
    called to search for duplicate table names for the table to be
    updated. When it finds the derived table, it is in an inconsistent
    state (table->table != NULL but table->table->s undefined).
    
    The solution is to let be the derived table's TABLE_LIST object
    remain in a consistent state after its materialized object is deleted,
    by setting its TABLE pointer to NULL.

[33mcommit 7dfa24d57e4b7e7e7736211102c3724a3d8949b4[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Fri Sep 22 15:42:21 2017 +0530

    Bug#26636238 : ERROR/INPLACE UPGRADE TO READ-ONLY 8.0: PERFORMANCE
                   SCHEMA INITIALIZATION FAILED
    
    Post push fix:
    
    Fix test case to check [1;31mperf[mormance schema version mismatch failure
    with --innodb-read-only instead of --read-only option.

[33mcommit 82150e1a1d03a5482b97290d99b8e0e683972be6[m
Author: Anibal Pinto <anibal.pinto@oracle.com>
Date:   Thu Sep 21 18:57:16 2017 +0200

    BUG#26731317: LOAD DELAYS SWITCHING A GR NODE FROM RECOVERING TO ONLINE
    
    When a node joins a group replication group, it must [1;31mperf[morm recovery, in which
    transactions from a donor member are applied locally for state transfer.  Once
    the node has applied all the transactions, it must change state from RECOVERING
    to ONLINE to become a full-fledge member of the group.
    
    When a node has finished applying all the transactions in the back-log, it
    tests if there are still messages in the queue, and will not switch to ONLINE
    until there are none.
    
    But if there is a consistent load of transactions, a node may not get the
    opportunity to switch to ONLINE, even if it is ready, only because there are
    just a few messages circulating.
    
    To prevent the delay of the node we compare the number of transactions occurred
    is bigger than the number of initial queue size, if so we switch the member to
    ONLINE.
    
    If the queue is empty before the number of transactions is bigger than the
    queue size, the member will switch to ONLINE.

[33mcommit 0cd756f939b9f94f688cd4ee2802668e700dfbe9[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Thu Sep 21 16:59:46 2017 +0530

    Bug#26636238 : ERROR/INPLACE UPGRADE TO READ-ONLY 8.0: PERFORMANCE SCHEMA INITIALIZATION FAILED
    
    When new data directory is created OR in-place upgrade from 5.7 is
    done with --read-only option, server startup fails in creating
    [1;31mperf[mormance schema tables. Next server startup suceeds as
    mysql.dd_properties register 'PS_version=1' as soon as dictionary
    is created, before creating [1;31mperf[mormance schema tables.
    
    --read-only mode is meant only to prohibit updates from client
    connections only, and not from server internal functions.
    For example, replication slave threads can do updates with
    --read-only option.
    
    Fix:
    
    - Performance Schema tables were not created when --read-only flag is
      set: both, during initialize and upgrade stage. This fix enables it.
      Fix makes the behavior of [1;31mperf[mormance schema metadata same as we treat
      I_S metadata.
    
    - Performance Schema tables are not created when server is restarted
      and DDSE is in read only mode. The server would continue to restart.
    
    - The fix also enable information schema metadata to be updated during
      server restarts when --read-only flag is set. I_S views already gets
      created during initialize and upgrade phase irrespective of
      --read-only flag.
    
    - Current server stores the IS_version and PS_version without making
      sure if I_S/P_S tables are created. This patch fixes it to store the
      respective version in dictionary only after creation.
    
    - Changed versioning scheme of dictionary and I_S system views to be
      consistent with P_S versioning scheme.
    
    - Removed assert from InnoDB while restricts dictionary version to 1.

[33mcommit 8b9cead096ae4d70c54e989b77042b0bd5236237[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Mon Sep 18 10:18:33 2017 +0200

    Bug #26395134: SET PERSIST_ONLY HAS WRONG EFFECT ON P_S.VARIABLES_INFO
    
    Problem: SET PERSIST_ONLY sql will not change the value of a variable,
    however when executing this sql, the sql causes
    [1;31mperf[mormance_schema.variables_info.variable_source column to be changed
    to DYNAMIC which gives an impression that the variable has been changed
    at runtime which is not correct.
    
    Fix: When SET PERSIST_ONLY sql is executed do not change
    variable_source/set_user/set_time/set_host columns in
    [1;31mperf[mormance_schema.variables_info table.

[33mcommit 526c23a0ad836bff046bbe04d83aab74692854dd[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Sep 12 14:16:05 2017 +0200

    Bug#26787170 DD VERSION NUMBER NOT MAINTAINED FOR PERFORMANCE SCHEMA
    
    Before this fix, the version number for the [1;31mperf[mormance schema
    stored in the data dictionary was not consistently updated
    each time a [1;31mperf[mormance schema table DDL changes.
    
    The root causes are:
    - the version number itself is in dd code, not maintained by
      the [1;31mperf[mormance schema team, and easy to overlook.
    - there is no process in place to enforce that this version
      number is modified on schema changes,
      making it even more easy to overlook.
    
    With this fix:
    - File storage/[1;31mperf[mschema/pfs_dd_version.h
      now contains the value of the version number stored in the data dictionary
    - A new MTR test script, [1;31mperf[mschema.dd_version_check,
      is designed to break when schema changes are detected,
      acting as a reminder that the data dictionary version
      needs to be adjusted.

[33mcommit ae78676aa88d97066ba0040ded8b312705578608[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Sep 13 18:46:03 2017 +0200

    Bug#25608115 VARIABLES_INFO.SET_TIME COLUMN INITIALIZED INCORRECTLY
    
    Before this fix, the column SET_TIME
    in table [1;31mperf[mormance_schema.variables_info
    was set incorrectly.
    
    It was set to the time a user [1;31mperf[morms a SELECT query,
    instead of being the timestamp when the variable changed.
    
    The root cause is the design of the table DDL itself:
    
    - Variables that are never set, because they are immutable,
      should not have a SET_TIME.
    - The column however was declared NOT NULL,
      which forces the code to provide a value.
    
    Related issue, the SET_USER and SET_HOST column,
    while nullable according to the DDL,
    where never set to NULL.
    
    With this fix, columns SET_TIME, SET_USER, SET_HOST
    are cleaned up to work as expected for an audit trail:
    
    1) SET_TIME is nullable.
    
    2) When a variable is never set,
    columns SET_TIME, SET_USER and SET_HOST are NULL.
    
    3) When a variable is set,
    column SET_TIME is the timestamp when the value was set, not read.
    Columns SET_USER and SET_HOST are set
    to the user/host who [1;31mperf[mormed the change.

[33mcommit be7cf2c9fc2d51f193c4082b7e1aa88e7a5fd914[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Sep 12 15:01:34 2017 +0200

    Bug#25608115 VARIABLES_INFO.SET_TIME COLUMN INITIALIZED INCORRECTLY
    
    Before this fix, the column SET_TIME
    in table [1;31mperf[mormance_schema.variables_info
    was set incorrectly.
    
    It was set to the time a user [1;31mperf[morms a SELECT query,
    instead of being the timestamp when the variable changed.
    
    The root cause is the design of the table DDL itself:
    
    - Variables that are never set, because they are immutable,
      should not have a SET_TIME.
    - The column however was declared NOT NULL,
      which forces the code to provide a value.
    
    Related issue, the SET_USER and SET_HOST column,
    while nullable according to the DDL,
    where never set to NULL.
    
    With this fix, columns SET_TIME, SET_USER, SET_HOST
    are cleaned up to work as expected for an audit trail:
    
    1) SET_TIME is nullable.
    
    2) When a variable is never set,
    columns SET_TIME, SET_USER and SET_HOST are NULL.
    
    3) When a variable is set,
    column SET_TIME is the timestamp when the value was set, not read.
    Columns SET_USER and SET_HOST are set
    to the user/host who [1;31mperf[mormed the change.

[33mcommit 08b032eb674fff000a3dbd20f062047b641f7746[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Wed Sep 13 08:54:19 2017 +0800

    Bug #26729602   UPGRADE 5.7->8.0.3: REPLICATION MAY NOT START DUE TO INDEX FILE NEW DEFAULT NAME - post fix
    
    Problem 1
    =========
    main.binlog_partial_json_warnings
    2017-09-12T02:26:28.880667Z 0 [Warning] [003784] You need to use --log-bin to make --binlog-format work.
    
    Analyze 1
    =========
    The main.binlog_partial_json_warnings is reporting the above warning with --binlog_format=mixed on weekly-trunk, since it restarts the server with --binlog-row-value-options=PARTIAL_JSON --binlog-row-image=MINIMAL --skip-log-bin --skip-log-slave-updates --skip-slave-preserve-commit-order.
    
    Fix 1
    =====
    To fix the problem, suppress the warning in the test.
    
    Problem 2
    =========
    CURRENT_TEST: sys_vars.log_bin_basic
     select @@global.log_bin;
     @@global.log_bin
    -1
    +0
     select @@session.log_bin;
     ERROR HY000: Variable 'log_bin' is a GLOBAL variable
     show global variables like 'log_bin';
     Variable_name  Value
    -log_bin        ON
    +log_bin        OFF
     show session variables like 'log_bin';
     Variable_name  Value
    -log_bin        ON
    +log_bin        OFF
     select * from [1;31mperf[mormance_schema.global_variables where variable_name='log_bin';
     VARIABLE_NAME  VARIABLE_VALUE
    -log_bin        ON
    +log_bin        OFF
     select * from [1;31mperf[mormance_schema.session_variables where variable_name='log_bin';
     VARIABLE_NAME  VARIABLE_VALUE
    -log_bin        ON
    +log_bin        OFF
    
    Analyze 2
    =========
    The main.binlog_partial_json_warnings is reporting the above mismatch on weekly-trunk, since it runs test with --mysqld=--skip-log-bin --mysqld=--skip-log-slave-updates --mysqld=--skip-slave-preserve-commit-order.
    
    Fix 2
    =====
    To fix the problem, source have_log_bin.inc in the test.
    
    Problem 3
    =========
    main.binlog_partial_json_warnings
    2017-09-09T14:20:50.365565Z 0 [Warning] [003786] No argument was provided to --log-bin, and --log-bin-index was not used; so replication may break when this MySQL server acts as a master and has his hostname changed!! Please use '--log-bin=siv28-bin' to avoid this problem.
    
    Analyze 3
    =========
    The main.binlog_partial_json_warnings is reporting the above warning with --mysqld=--skip-log-bin --mysqld=--skip-log-slave-updates --mysqld=--skip-slave-preserve-commit-order on weekly-trunk, since it restarts the server with --log-bin --binlog-format=statement --binlog-row-value-options=PARTIAL_JSON --binlog-row-image=MINIMAL.
    
    Fix 3
    =====
    To fix the problem, suppress the warning in the test.

[33mcommit b8dcd63d07273e9bbb7dca5ae20eb016eb1047dc[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Sep 7 10:14:09 2017 +0200

    Bug#26666274 INFINITE LOOP IN PERFORMANCE SCHEMA BUFFER CONTAINER
    
    Problem 1
    =========
    
    Under load, the [1;31mperf[mormance schema code can execute
    an infinite loop in
      PFS_buffer_default_array::allocate()
    
    Root cause 1
    ============
    
    Consider the following loop:
    
      size_t monotonic;
      size_t monotonic_max;
    
      monotonic = m_monotonic.m_u32++;
      monotonic_max = monotonic + m_max; (a)
    
      while (monotonic < monotonic_max)
      {
        ...
        monotonic = m_monotonic.m_u32++; (b)
      }
    
      When the value of monotonic gets close to 2^32,
      the value of monotonic_max gets beyond 2^32 in (a)
      This is ok, as both variables are 64 bits integers.
    
      However, in the loop,
      m_monotonic.m_u32++ is only a 32 bits value (b),
      so that when incrementing to the next value,
      the monotonic counter will never get passed 2^32,
      and therefore will never reach monotonic_max.
    
      The while loop never ends, causing the bug.
    
    Fix 1
    =====
    
      The solution is to change m_monotonic to
      be a PFS_cacheline_atomic_size_t,
      to match the type (size_t) of monotonic and monotonic_max.
    
      With this fix, the loop works properly beyond 2^32.
    
      However, another issue was found by analysis.
    
    Problem 2:
    ==========
    
      When the value of monotonic gets close to 2^64,
      the value of monotonic_max gets beyond 2^64,
      causing an overflow, and wraps to a low integer (a).
    
      In this case, the while loop is never entered,
      because monotonic is near 2^64 and monotonic_max is near 0.
    
      The buffer is declared full, without looking at it.
    
      While theoretical (2^64 is a big value, the server needs
      to be up for a long time to get to this state),
      this can potentially lead to extra allocation
      of new container pages, consuming more memory than necessary.
    
    Fix 2
    =====
    
      Add logic that detects the overflow on monotonic_max,
      and reset the monotonic counter to 0.
    
    Misc
    ====
    
      This fix also changes several integer computations
      to use size_t, to clean up the code to avoid other overflows.

[33mcommit bd87573bc159c849f34aa8293ec43ac053cbfda0[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Sep 7 10:14:09 2017 +0200

    Bug#26666274 INFINITE LOOP IN PERFORMANCE SCHEMA BUFFER CONTAINER
    
    Problem 1
    =========
    
    Under load, the [1;31mperf[mormance schema code can execute
    an infinite loop in
      PFS_buffer_default_array::allocate()
    
    Root cause 1
    ============
    
    Consider the following loop:
    
      size_t monotonic;
      size_t monotonic_max;
    
      monotonic = m_monotonic.m_u32++;
      monotonic_max = monotonic + m_max; (a)
    
      while (monotonic < monotonic_max)
      {
        ...
        monotonic = m_monotonic.m_u32++; (b)
      }
    
      When the value of monotonic gets close to 2^32,
      the value of monotonic_max gets beyond 2^32 in (a)
      This is ok, as both variables are 64 bits integers.
    
      However, in the loop,
      m_monotonic.m_u32++ is only a 32 bits value (b),
      so that when incrementing to the next value,
      the monotonic counter will never get passed 2^32,
      and therefore will never reach monotonic_max.
    
      The while loop never ends, causing the bug.
    
    Fix 1
    =====
    
      The solution is to change m_monotonic to
      be a PFS_cacheline_atomic_size_t,
      to match the type (size_t) of monotonic and monotonic_max.
    
      With this fix, the loop works properly beyond 2^32.
    
      However, another issue was found by analysis.
    
    Problem 2:
    ==========
    
      When the value of monotonic gets close to 2^64,
      the value of monotonic_max gets beyond 2^64,
      causing an overflow, and wraps to a low integer (a).
    
      In this case, the while loop is never entered,
      because monotonic is near 2^64 and monotonic_max is near 0.
    
      The buffer is declared full, without looking at it.
    
      While theoretical (2^64 is a big value, the server needs
      to be up for a long time to get to this state),
      this can potentially lead to extra allocation
      of new container pages, consuming more memory than necessary.
    
    Fix 2
    =====
    
      Add logic that detects the overflow on monotonic_max,
      and reset the monotonic counter to 0.
    
    Misc
    ====
    
      This fix also changes several integer computations
      to use size_t, to clean up the code to avoid other overflows.

[33mcommit f51392aade9e44f3a564e2833214e8a77da51000[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Sun Aug 27 15:59:06 2017 +0300

    Follow-up to WL#6049 Meta-data locking for FOREIGN KEY tables.
    
    Fixed [1;31mperf[mschema.transaction_nested_events test failure.
    
    Changes to cache invalidation which were done as part of this
    WL resulted in less data-dictionary lookups in one of parts of
    this test.
    
    Recorded new test results after checking that they are correct.

[33mcommit 545a0ab6c49ff6cc31c60a3ebf2ff3a5b1034530[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Wed Sep 6 18:17:07 2017 +0530

    Bug#26203731 : INFORMATION_SCHEMA.TABLES TABLE STATISTICS ARE NULL
    
    In MySQL 8.0, SHOW TABLE STATUS ...  and SELECT * FROM
    INFORMATION_SCHEMA.TABLES ... do not return meaningful data for the
    fields rows, avg_row_length, data_length, max_data_length, index_length,
    data_free, update_time. Instead they return NULL. On MySQL 5.7 these
    statements return valid data. Same behavior is observed for cardinality
    column in INFORMATION_SCHEMA.STATISTICS table.
    
    New implementation of information schema in 8.0 introduces two modes for
    dynamic table statistics retrieval for information schema - `cached` and
    `latest`. In cached mode, dynamic meta-data is fetched from
    mysql.table_stats and mysql.index_stats tables. The data is populated
    and refreshed in the stats table by explicit ANALYZE command on the
    tables. If data is fetched from information schema in `cached` mode
    without first executing ANALYZE, user will get `NULL` or stale data
    for dynamic table statistics.
    
    Fix:
    
    - Implement time based caching of the dynamic metadata in mysql.table_stats
      and mysql.index_stats.
    
    - Time based caching will fetch data from Storage engines when retriving
      data for first time. User will never get NULL value.
    
    - Remove 'cached' and 'latest' modes for data fetching from information
      schema. Remove information_schema_stats variable.
    
    - Add SESSION variable `information_schema_stats_expiry` to specify the
      value of timeout for cached data.
    
    - Default value of information_schema_stats_expiry variable is 24 hours
      (86400 seconds).
    
    - If information_schema_stats_expiry is specified as ZERO, always retrieve
      latest data from storage engine.
    
    - Do not store the retrieved dynamic data in mysql.table_stats and
      mysql.index_stats if any of the following condition is satisfied:
      - information_schema_stats_expiry value is ZERO.
      - innodb_read_only is ON.
      - transaction_read_only is ON.
      - read_only is ON.
      - super_read_only is ON.
      - data is retrieved for [1;31mperf[mormance schema table.
    
    - For other values for information_schema_stats_expiry, store the data
      retrieved from storage engine in mysql.index_stats and mysql.table_stats.
      The stored data will be used for further queries on information_schema.tables
      and information_schema.statistics till data expires.
    
    - Remove internal system views TABLES_DYNAMIC, STATISTICS_DYNAMIC and
      SHOW_STATISTICS_DYNAMIC.
    
    - The metadata of columns of information schema which store dynamic
      information now depends directly on the UDF implementing them. Add
      'unsigned' flag the UDFs to maintain unsigned property of the columns.

[33mcommit eb18a7528b84bdddd945121c46734e8dd5bc4ae8[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Wed Sep 6 18:17:07 2017 +0530

    Bug#26203731 : INFORMATION_SCHEMA.TABLES TABLE STATISTICS ARE NULL
    
    In MySQL 8.0, SHOW TABLE STATUS ...  and SELECT * FROM
    INFORMATION_SCHEMA.TABLES ... do not return meaningful data for the
    fields rows, avg_row_length, data_length, max_data_length, index_length,
    data_free, update_time. Instead they return NULL. On MySQL 5.7 these
    statements return valid data. Same behavior is observed for cardinality
    column in INFORMATION_SCHEMA.STATISTICS table.
    
    New implementation of information schema in 8.0 introduces two modes for
    dynamic table statistics retrieval for information schema - `cached` and
    `latest`. In cached mode, dynamic meta-data is fetched from
    mysql.table_stats and mysql.index_stats tables. The data is populated
    and refreshed in the stats table by explicit ANALYZE command on the
    tables. If data is fetched from information schema in `cached` mode
    without first executing ANALYZE, user will get `NULL` or stale data
    for dynamic table statistics.
    
    Fix:
    
    - Implement time based caching of the dynamic metadata in mysql.table_stats
      and mysql.index_stats.
    
    - Time based caching will fetch data from Storage engines when retriving
      data for first time. User will never get NULL value.
    
    - Remove 'cached' and 'latest' modes for data fetching from information
      schema. Remove information_schema_stats variable.
    
    - Add SESSION variable `information_schema_stats_expiry` to specify the
      value of timeout for cached data.
    
    - Default value of information_schema_stats_expiry variable is 24 hours
      (86400 seconds).
    
    - If information_schema_stats_expiry is specified as ZERO, always retrieve
      latest data from storage engine.
    
    - Do not store the retrieved dynamic data in mysql.table_stats and
      mysql.index_stats if any of the following condition is satisfied:
      - information_schema_stats_expiry value is ZERO.
      - innodb_read_only is ON.
      - transaction_read_only is ON.
      - read_only is ON.
      - super_read_only is ON.
      - data is retrieved for [1;31mperf[mormance schema table.
    
    - For other values for information_schema_stats_expiry, store the data
      retrieved from storage engine in mysql.index_stats and mysql.table_stats.
      The stored data will be used for further queries on information_schema.tables
      and information_schema.statistics till data expires.
    
    - Remove internal system views TABLES_DYNAMIC, STATISTICS_DYNAMIC and
      SHOW_STATISTICS_DYNAMIC.
    
    - The metadata of columns of information schema which store dynamic
      information now depends directly on the UDF implementing them. Add
      'unsigned' flag the UDFs to maintain unsigned property of the columns.

[33mcommit f101afb46e6ff3d8b4ee5679e52555272d3b26ac[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Fri Sep 1 17:54:18 2017 +0300

    Bug#26719289 "8.0.3-RC SHOWS UP TO 25% PERFORMANCE REGRESSION WITH WL6049 PUSH".
    
    The problem was that WL6049 introduced heavy [1;31mperf[mormance regression
    for write related tests. The source of this regression was new
    process_table_fks() function. This function is called for each table
    modified by typical DML statement to determine on which tables related
    through foreign keys to table modified we need to additionally acquire
    metadata locks. This function used dd::Dictionary_client::acquire()
    method to get information about table's foreign keys and this method
    is known to be scalability bottleneck since it acquires global
    (actually per object type) lock. Additionally when validating elements
    of prelocked set for foreign keys with cascading updates or deletes we
    acquired global LOCK_open lock and locks on all table cache partitions,
    which devasted scalability for statements causing such actions.
    
    This patch solves the problem by not using dd::Dictionary_client::acquire()
    in process_table_fks() and instead relying of information about foreign
    keys caches in TABLE_SHARE object. In the most common scenario it is already
    available when we call process_tables_fks(). In another case it can be
    easily accessed through table cache which is protected by partitioned
    lock. This patch also introduces caching of necessary information about
    foreign keys in the table share. We also use this TABLE_SHARE for
    prelocking set validation when necessary and thus avoid unnecessary
    locking for statements with cascading deletes or updates.

[33mcommit 8676d8ce7b74b465a93ec175cd0caa59f2e83150[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Fri Sep 1 17:54:18 2017 +0300

    Bug#26719289 "8.0.3-RC SHOWS UP TO 25% PERFORMANCE REGRESSION WITH WL6049 PUSH".
    
    The problem was that WL6049 introduced heavy [1;31mperf[mormance regression
    for write related tests. The source of this regression was new
    process_table_fks() function. This function is called for each table
    modified by typical DML statement to determine on which tables related
    through foreign keys to table modified we need to additionally acquire
    metadata locks. This function used dd::Dictionary_client::acquire()
    method to get information about table's foreign keys and this method
    is known to be scalability bottleneck since it acquires global
    (actually per object type) lock. Additionally when validating elements
    of prelocked set for foreign keys with cascading updates or deletes we
    acquired global LOCK_open lock and locks on all table cache partitions,
    which devasted scalability for statements causing such actions.
    
    This patch solves the problem by not using dd::Dictionary_client::acquire()
    in process_table_fks() and instead relying of information about foreign
    keys caches in TABLE_SHARE object. In the most common scenario it is already
    available when we call process_tables_fks(). In another case it can be
    easily accessed through table cache which is protected by partitioned
    lock. This patch also introduces caching of necessary information about
    foreign keys in the table share. We also use this TABLE_SHARE for
    prelocking set validation when necessary and thus avoid unnecessary
    locking for statements with cascading deletes or updates.

[33mcommit c58bcf828b5f5bcd3e89d460add2dcef0494cb16[m
Author: Lukasz Kotula <lukasz.kotula@oracle.com>
Date:   Mon Aug 28 13:39:41 2017 +0200

    Bug#26258481 - STRANGE META-DATA RETURNED FOR JSON RESULTS
    
    Description
    ===========
    All fields in Mysqlx::Resultset::ColumnMetaData message are
    optional. X Plugin always sends all fields that MySQL Server
    reports. Table in mysqlx_resultset.proto defines which are
    required.
    
    Fix
    ===
    Send only required field. The change is going to improve
    network [1;31mperf[mormance and its going to limit interpretation
    of fields values that doesn't make sence with concrete
    column type.
    
    RB: 17217
    Reviewed by: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
    Reviewed-by: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>

[33mcommit 0d6022964ab926f24d2685e8701483fb6afd8f61[m
Author: Xing Zhang <xing.z.zhang@oracle.com>
Date:   Wed Aug 30 14:30:31 2017 +0800

    Bug #25680866: _CHARACTERSET SPECIFICATIONS HAVE LOUSY PERFORMANCE FOR SOME CHARACTER SETS
    
    Literal character set name is translated to character set number by looping
    through all_charsets array. The [1;31mperf[mormance is low and will get worse when
    we add new collations in the future.
    
    Fix:
    Change to use unordered_map to translate character set name to number.
    
    BM_LookupAllCollations   454 -> 383 ns/iter [+ 18.5%]
    BM_LookupAllCharsets     253 -> 180 ns/iter [+ 40.6%]
    
    Change-Id: I9730789ff2baa7b931a95d472c127c7192d7557a

[33mcommit 36f8602e4e9b2c838546bfcc401c020fdedad47c[m
Author: Dmitry Shulga <dmitry.shulga@oracle.com>
Date:   Mon Aug 28 14:43:54 2017 +0700

    Bug #26667007 -- MYSQL UPGRADE TO 8.0.3 USER WITH RELOAD GRANTED BACKUP_ADMIN WITH GRANT OPTION
    
    As part of wl9451, when a user has RELOAD privilege in 5.7 and the mysql server is
    upgraded to 8.0.3, the user is granted privilege BACKUP_ADMIN in order to be
    able to [1;31mperf[morm some backup duties.  This privilege is granted with admin
    option in all cases, regardless of whether the RELOAD was granted that way.
    
    The reason for the bug was the fact that a grant_priv column's value
    didn't take into account when inserting a record about the BACKUP_ADMIN privilege
    into the table mysql.global_grants.
    
    To fix the bug the INSERT statement in the sql script file scripts/mysql_system_tables_fix.sql
    was modified in order take into account a value of grant_priv column of the table mysql.user
    when the privilege BACKUP_ADMIN is added for a user having the RELOAD privilege assigned.
    
    Similar modification was done for the privilege XA_RECOVER_ADMIN.

[33mcommit d034d7599c4b1da891fe7ae9510b14adb7ee49df[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Aug 11 12:45:49 2017 +0200

    WL #10343: Switch GCC optimization from -O3 to -O2
    
    Change from -O3 to -O2 everywhere, for smaller binaries, faster compile
    times and generally better [1;31mperf[mormance. Mark some [1;31mperf[mormance schema
    function as force-inline to avoid [1;31mperf[mormance regressions, since they
    are important to inline despite being big.
    
    Change-Id: Ib7603f141e6974aeed7e4fde2ef7697864231ae3

[33mcommit bb0d7f4bf7e2df1d4f3849553ac50547119a51cc[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Aug 28 17:43:11 2017 +0200

    Applied clang-format (4.0.0 git)
    to storage/[1;31mperf[mschema.

[33mcommit 90042e766661382db7e167d80298463d4cfef9bb[m
Author: Dmitry Shulga <dmitry.shulga@oracle.com>
Date:   Mon Aug 28 14:43:54 2017 +0700

    Bug #26667007 -- MYSQL UPGRADE TO 8.0.3 USER WITH RELOAD GRANTED BACKUP_ADMIN WITH GRANT OPTION
    
    As part of wl9451, when a user has RELOAD privilege in 5.7 and the mysql server is
    upgraded to 8.0.3, the user is granted privilege BACKUP_ADMIN in order to be
    able to [1;31mperf[morm some backup duties.  This privilege is granted with admin
    option in all cases, regardless of whether the RELOAD was granted that way.
    
    The reason for the bug was the fact that a grant_priv column's value
    didn't take into account when inserting a record about the BACKUP_ADMIN privilege
    into the table mysql.global_grants.
    
    To fix the bug the INSERT statement in the sql script file scripts/mysql_system_tables_fix.sql
    was modified in order take into account a value of grant_priv column of the table mysql.user
    when the privilege BACKUP_ADMIN is added for a user having the RELOAD privilege assigned.
    
    Similar modification was done for the privilege XA_RECOVER_ADMIN.

[33mcommit 8546686bd0dc7b23b38af605abebb91aebbec80b[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Sun Aug 27 15:59:06 2017 +0300

    Follow-up to WL#6049 Meta-data locking for FOREIGN KEY tables.
    
    Fixed [1;31mperf[mschema.transaction_nested_events test failure.
    
    Changes to cache invalidation which were done as part of this
    WL resulted in less data-dictionary lookups in one of parts of
    this test.
    
    Recorded new test results after checking that they are correct.

[33mcommit c453a80684e613dc491b5ff1c6d90d16a81e3501[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Thu Aug 24 21:13:52 2017 +0300

    WL#6049 "Meta-data locking for FOREIGN KEY tables" and WL#11059
    "Implement INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS as a system
    views over dictionary tables."
    
    WL#6049 Meta-data locking for FOREIGN KEY tables.
    
    The primary goal of this task is to ensure that foreign keys checks,
    which are [1;31mperf[mormed by storage engine (e.g. InnoDB), do not access
    tables which are concurrently modified by DDL statements.
    
    Such an isolation of FK checks/actions from DDL statements can be
    achieved by ensuring that FKs are taken into account when we acquire
    metadata "operation-type aware" locks for DML and DDL statements.
    
    This is done by:
    
    1) Extending prelocking algorithm/process to take into account
       foreign keys and acquire metadata locks which are appropriate
       for the operations involving them (checks in parent or child
       tables take SR lock, cascading updates or deletes take SW lock,
       LOCK TABLES takes SRO or SNRW locks correspondingly).
    
    2) Changing DDL statements which add or drop foreign keys to the system
       to X lock on FK parent table before child table definition changes.
    
    3) Changing DDL statements which otherwise affect FK-related metadata
       (like RENAME TABLE on child or parent table) to acquire X lock on
       tables participating in the FK.
    
    4) Changing ALTER TABLE to acquire SU metadata lock on parent tables
       for newly added FKs so it can properly check them.
    
    The secondary goal of this task is to ensure that DDL on parent tables
    correctly updates foreign key metadata. Specifically we now correctly
    update the following metadata:
    
    I)   Name of unique constraint in parent table for the FK.
    
         Old code misused DD.FOREIGN_KEYS.UNIQUE_CONSTRAINT_ID to store
         id of supporting index for the FK in the child table. This WL replaces
         this column with VARCHAR(64) field which stores name of unique
         key in the parent table used for the FK -- UNIQUE_CONSTRAINT_NAME.
         DDL statements code was adjusted to keep this value correct on
         changes to parent table definition.
    
    II)  Referenced schema and table names (DD.FOREIGN_KEYS.REFERENCED_TABLE_SCHEMA
         and DD.FOREIGN_KEYS.REFERENCED_TABLE_NAME) during ALTER TABLE RENAME/
         RENAME TABLES on parent tables.
    
    This WL introduces some new temporary limitations:
    
    - We temporary disallow renaming of parent columns in FKs.
    
    - ALTER TABLE ... ALGORITHM=COPY acquires SRO locks on the parent
      tables for newly added FKs. This is temporary workaround for
      InnoDB SE making information about such FKs to other connections
      before DDL commit.
    
    - We disallow ALTER TABLE ... RENAME under LOCK TABLES on tables
      which have or will have foreign keys. This limitation should
      be weakened soon.
    
    WL#11059 Implement INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS as a system
             views over dictionary tables.
    
    This patch implements I_S.REFERENTIAL_CONSTRAINTS as a system view over data
    dictionary tables, and remove 5.7 code that uses a temporary
    table to represent I_S view.
    
    Following changes are made in the patch:
    
    * Define a system view over data dictionary tables representing
      I_S.REFERENTIAL_CONSTRAINTS.
    
    * Remove 5.7 code from sql_show.cc for I_S.REFERENTIAL_CONSTRAINTS.
    
    * The result file for main.information_schema_inno shows the
      unique_constraint_name as PRIMARY. This is expected change added in
      wl6049. We get 'PRIMARY' as constraint name if a key is promoted as
      primary key. If a unique key is not a primary key, then the constraint name
      does show the unique key name.
    
    * Fixed upgrade code to return just the constraint name and avoid prefixing
      the constraint schema name with it. We also check that the constraint
      name is not more than 64 characters, before continuing further.
    
    * Added ORDER BY clauses in some of I_S query to force order of
      tuple returned. Because, now the optimizer returns the rows and
      not read from temporary table as in 5.7 I_S design.
    
    * Remove part of test case in main.information_schema. Because,
    
      - The problem reported back then is only applicable for 5.7
        code.
    
      - The output of EXPLAIN ... <select on I_S system view> goes
        through optimizer and then plan return might vary.
    
    * Fixed InnoDB upgrade code, which ignored setting RESTRICT flag for
      update and delete rule.
    
    * Recorded result files with I_S column names being capitals now,
      this is expected, see wl6599 for more info.

[33mcommit 6626f76d856eb6415d1db37eccd67858cfb71096[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Thu Aug 24 21:13:52 2017 +0300

    WL#6049 "Meta-data locking for FOREIGN KEY tables" and WL#11059
    "Implement INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS as a system
    views over dictionary tables."
    
    WL#6049 Meta-data locking for FOREIGN KEY tables.
    
    The primary goal of this task is to ensure that foreign keys checks,
    which are [1;31mperf[mormed by storage engine (e.g. InnoDB), do not access
    tables which are concurrently modified by DDL statements.
    
    Such an isolation of FK checks/actions from DDL statements can be
    achieved by ensuring that FKs are taken into account when we acquire
    metadata "operation-type aware" locks for DML and DDL statements.
    
    This is done by:
    
    1) Extending prelocking algorithm/process to take into account
       foreign keys and acquire metadata locks which are appropriate
       for the operations involving them (checks in parent or child
       tables take SR lock, cascading updates or deletes take SW lock,
       LOCK TABLES takes SRO or SNRW locks correspondingly).
    
    2) Changing DDL statements which add or drop foreign keys to the system
       to X lock on FK parent table before child table definition changes.
    
    3) Changing DDL statements which otherwise affect FK-related metadata
       (like RENAME TABLE on child or parent table) to acquire X lock on
       tables participating in the FK.
    
    4) Changing ALTER TABLE to acquire SU metadata lock on parent tables
       for newly added FKs so it can properly check them.
    
    The secondary goal of this task is to ensure that DDL on parent tables
    correctly updates foreign key metadata. Specifically we now correctly
    update the following metadata:
    
    I)   Name of unique constraint in parent table for the FK.
    
         Old code misused DD.FOREIGN_KEYS.UNIQUE_CONSTRAINT_ID to store
         id of supporting index for the FK in the child table. This WL replaces
         this column with VARCHAR(64) field which stores name of unique
         key in the parent table used for the FK -- UNIQUE_CONSTRAINT_NAME.
         DDL statements code was adjusted to keep this value correct on
         changes to parent table definition.
    
    II)  Referenced schema and table names (DD.FOREIGN_KEYS.REFERENCED_TABLE_SCHEMA
         and DD.FOREIGN_KEYS.REFERENCED_TABLE_NAME) during ALTER TABLE RENAME/
         RENAME TABLES on parent tables.
    
    This WL introduces some new temporary limitations:
    
    - We temporary disallow renaming of parent columns in FKs.
    
    - ALTER TABLE ... ALGORITHM=COPY acquires SRO locks on the parent
      tables for newly added FKs. This is temporary workaround for
      InnoDB SE making information about such FKs to other connections
      before DDL commit.
    
    - We disallow ALTER TABLE ... RENAME under LOCK TABLES on tables
      which have or will have foreign keys. This limitation should
      be weakened soon.
    
    WL#11059 Implement INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS as a system
             views over dictionary tables.
    
    This patch implements I_S.REFERENTIAL_CONSTRAINTS as a system view over data
    dictionary tables, and remove 5.7 code that uses a temporary
    table to represent I_S view.
    
    Following changes are made in the patch:
    
    * Define a system view over data dictionary tables representing
      I_S.REFERENTIAL_CONSTRAINTS.
    
    * Remove 5.7 code from sql_show.cc for I_S.REFERENTIAL_CONSTRAINTS.
    
    * The result file for main.information_schema_inno shows the
      unique_constraint_name as PRIMARY. This is expected change added in
      wl6049. We get 'PRIMARY' as constraint name if a key is promoted as
      primary key. If a unique key is not a primary key, then the constraint name
      does show the unique key name.
    
    * Fixed upgrade code to return just the constraint name and avoid prefixing
      the constraint schema name with it. We also check that the constraint
      name is not more than 64 characters, before continuing further.
    
    * Added ORDER BY clauses in some of I_S query to force order of
      tuple returned. Because, now the optimizer returns the rows and
      not read from temporary table as in 5.7 I_S design.
    
    * Remove part of test case in main.information_schema. Because,
    
      - The problem reported back then is only applicable for 5.7
        code.
    
      - The output of EXPLAIN ... <select on I_S system view> goes
        through optimizer and then plan return might vary.
    
    * Fixed InnoDB upgrade code, which ignored setting RESTRICT flag for
      update and delete rule.
    
    * Recorded result files with I_S column names being capitals now,
      this is expected, see wl6599 for more info.

[33mcommit 113a94bbdbbf068625a2a830d89ca692f9ca38ad[m
Author: Pekka Nousiainen <pekka.nousiainen@oracle.com>
Date:   Wed Aug 23 12:10:56 2017 +0300

    wl#7614 optim01.diff
    
    save [1;31mperf[mormance related options

[33mcommit 84ebe8babdfd3916f8c7e604fad28c40332e6fb8[m
Author: Erik Froseth <erik.froseth@oracle.com>
Date:   Tue Aug 22 12:12:55 2017 +0200

    WL#9223
    
    Post-push fix: The test [1;31mperf[mschema.threads_history gave a different
    result in release and debug builds. The root cause for this was that
    the default size for [1;31mperf[mormance_schema_events_waits_history_long_size
    is 10000. The server creates a different number of events_waits markers in
    release and debug, and in debug it exceeds 10000 for the table
    events_waits_history_long. The result is that the [1;31mperf[mormance schema
    table starts to eat up itself, since it is implemented as a ring buffer.
    This would give a different result in the test file for release and debug
    builds.
    
    The fix is to increase the size of the variable
    [1;31mperf[mormance_schema_events_waits_history_long_size to ensure that the
    [1;31mperf[mormance schema table doesn't start to eat up itself.
    
    Change-Id: I354bc1ae48630639c947d85a5fdf3e65c4d878ed

[33mcommit 3c7f6b7e8df10d6d3759a3d5fef1ebf40c9d15a0[m
Author: Erik Froseth <erik.froseth@oracle.com>
Date:   Tue Aug 22 12:12:55 2017 +0200

    WL#9223
    
    Post-push fix: The test [1;31mperf[mschema.threads_history gave a different
    result in release and debug builds. The root cause for this was that
    the default size for [1;31mperf[mormance_schema_events_waits_history_long_size
    is 10000. The server creates a different number of events_waits markers in
    release and debug, and in debug it exceeds 10000 for the table
    events_waits_history_long. The result is that the [1;31mperf[mormance schema
    table starts to eat up itself, since it is implemented as a ring buffer.
    This would give a different result in the test file for release and debug
    builds.
    
    The fix is to increase the size of the variable
    [1;31mperf[mormance_schema_events_waits_history_long_size to ensure that the
    [1;31mperf[mormance schema table doesn't start to eat up itself.
    
    Change-Id: I354bc1ae48630639c947d85a5fdf3e65c4d878ed

[33mcommit 3e96c8108f05b16619d1e9d3ed1e65f0375c6b31[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Tue Aug 22 08:09:41 2017 +0200

    wl#10234, Reintroduce building of SPJ [1;31mperf[mormance measurement tool
    
     - skip building the tool on Windows

[33mcommit 8104adb3823e45929cf45551cd294bc7255368d8[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Sun Aug 20 07:12:58 2017 +0200

    WL#9223 Using histogram statistics in the optimizer
    
    Post-push fix: rerecord [1;31mperf[mschema.transaction_nested_events

[33mcommit 6aee469375a4eafb39d6bfe55027d0721f4c7c2c[m
Author: Sven Sandberg <sven.sandberg@oracle.com>
Date:   Sat May 6 14:33:42 2017 +0200

    WL#2955: RBR replication of partial JSON updates
    
    This worklog enables the replication of small updates of big JSON
    documents more space-efficiently.  More precisely, when using RBR, we
    will write only the modified parts of JSON documents, instead of the
    whole JSON document.
    
    The patch includes the following major components:
    
    - Implement the new option binlog_row_value_options
    
    - Implement logic to generate JSON diffs only when needed
    
      Before, JSON diffs were generated unconditionally by the optimizer.
      We changed so that JSON diffs are only generated when the option is
      enabled (unless inhibited by other options).
    
    - Implement new event type and use it when the option is enabled
    
    - Refactor: make max_row_length a private member of Row_data_memory
    
      This function was only used internally in class Row_data_memory, but
      was defined as a global function in table.cc.  Moved it to a private
      member of Row_data_memory.
    
    - Refactor: simplify pack_row and unpack_row
    
      Made several refactorings in these functions, including:
    
      New utility classes for handling null bits: When reading and writing
      a row in a row event, the logic for iterating over fields was
      interleaved with low-level bit operations to maintain a bitmap of
      null fields.  This made the code error-prone and hard to understand
      and edit.  This refactoring encapsulates the bitmap handling in
      utility classes, and simplifies pack_row / unpack_row accordingly.
    
    - Refactor: add const to integer decoder functions in pack.cc
    
      Functions in mysys/pack.cc that read from a buffer did not declare
      the buffer as const.  This patch makes net_field_length_size use a
      const parameter and makes other functions use const internally.
      Since these functions are part of the ABI, we also have to update
      include/mysql.h.pp.  (We do not const-ify pointers-to-pointers in
      function declarations, since that breaks compilation on other places
      that call the functions using non-const arguments.)
    
    - Refactor: change Json_diff_vector from a type alias to a class
    
      This was needed because extend Json_diff_vector with more member
      functions.  It also simplifies some forward declarations.
    
    - Refactor: do not overload global identifier TABLE in rpl_tblmap.h
    
      Class table_mapping in rpl_tblmap.h is used both in mysqlbinlog and
      in the server.  In the server, it maps numbers to TABLE objects.  In
      mysqlbinlog, it maps numbers to Table_map_log_event objects.  This
      was implemented by using the type name TABLE, and in mysqlbinlog use
      a typedef that makes TABLE an alias for Table_map_log_event.
    
      This patch changed rpl_tblmap.h so that it does not use the
      identifier TABLE.  Instead, it uses the new typedef Mapped_table
      that maps to TABLE in the server and to Table_map_log_event in
      mysqlbinlog.
    
    - Refactor: remove unused variable Rows_log_event::m_master_reclength
    
      There was a member variable Rows_log_event::m_master_reclength that
      was set to a (strange) value which was never read.  Removed this.
    
    - Refactor: simplify Rows_log_event::read_write_bitmaps_cmp
    
      This member function was implemented only in the base class, but had
      a switch that made it execute differently depending on the
      instance's subclass.  Changed to use a pure virtual function in the
      base class and implement the different logic in each subclass.
    
    - Implement encoder of new event format
    
      Outline of the pipeline:
    
       1. In binlog.cc:Row_data_memory, take a new argument in the
          constructor having two 'data' pointers (this constructor is used
          for Update_rows_log_event and is invoked in
          binlog.cc:THD::binlog_update_row).  This the value of the new
          server option binlog_row_value_options.  Based on this variable,
          determine if Json diffs may be used, estimate how much memory
          will be used (using the new function
          json_diff.cc:Json_diff_vector::binary_length), decide if full
          format or partial format will be used, and adjust the allocated
          memory accordingly.
    
       2. In binlog.cc:THD::binlog_update_row, pass two new arguments to
          pack_row:
    
          - row_image_type, which specifies if this is a
            Write/Update/Delete, and if it is a before-image or
            after-image.
    
          - value_options, which contains the value of
            binlog_row_value_options for update after-images.
    
       3. In rpl_record.cc:pack_row, accept the two new arguments.  If
          this is an update after-image and the bit in value_options is
          set, then determine if any column will use partial format.  If
          any column will use partial format, write the value_options
          field, followed by the partial_bits, to the output.  Otherwise,
          just write value_options=0 to the output and skip the
          value_options.
    
       4. From rpl_record.cc:pack_row, invoke the new function
          rpl_record.cc:pack_field to write a single field.  If the column
          is JSON and this is the after-image of an Update and the bit in
          value_options is set, invoke the new function
          field.cc:Field_json::pack_diff.  Otherwise, or if
          field.cc:Field_json::pack_diff returned NULL, fall back to the
          usual non-diff writer.
    
       5. In Field_json::pack_diff, determine again if this field will be
          smaller in full format or in partial format.  If full format is
          smaller, just return NULL so that rpl_record.cc:pack_field will
          write the full format.  Otherwise, invoke the new function
          json_diff.cc:Json_diff_vector::write_binary.
    
       6. In json_diff.cc:Json_diff_vector::write_binary, write the length
          using 4 bytes, followed by all the diffs.  Write each diff using
          the new function json_diff.c:Json_diff::write_binary.
    
       7. In json_diff.c:Json_diff::write_binary, write a single diff to
          the output.
    
    - Implement decoder of the new format
    
      The pipeline is now:
    
       1. Add a parameter to
          log_event.cc:Rows_log_event::unpack_current_row, which says if
          this is an after-image or not.  Set the parameter from all the
          callers in log_event.cc.
    
       2. Move Rows_log_event::unpack_current_row from log_event.h to
          log_event.cc and make it pass two new arguments to
          rpl_record.cc:unpack_row: row_image_type, which indicates if
          this is Write/Update/Delete and before-image or after-image, and
          has_value_options, which is true for Update events when
          binlog_row_value_options=PARTIAL_JSON.
    
       3. Make rpl_record.cc:unpack_row accept the two new parameters.
    
          First make a few small refactorings in rpl_record.cc:unpack_row:
    
          - Clarify some variable names and improve the comment for the
            function.
    
          - Remove comments about unpack_row being used by backup, having
            rli==NULL.  This may have been an intention at some point in
            time, perhaps in 5.1, but probably never was true.  And rli is
            unconditionally dereferenced in the main loop, so it cannot be
            NULL.  Instead assert that it is not NULL.  Also assert that
            other parameters are not NULL, as well as other preconditions.
    
          - Improve some debug trace printouts.
    
          - Return bool instead of int since the caller does not need to
            distinguish more than two different return statuses.
    
          Then implement the new logic:
    
          - When partial format is enabled, read partial_bits before the
            after-image (from within the main loop, as well as from the
            loop that consumes unused fields), and also read partial_bits
            after the before-image (after the main loop).  For the
            before-image, leave the read-position before the partial_bits.
            Use the new auxiliary function start_partial_bits_reader to
            read the value_options and initialize the Bit_reader
            accordingly, in the two places (after before-image and before
            after-image).
    
          - In order to read the correct number of bits before the
            after-image, start_partial_bits_reader needs to know the
            number of JSON columns on the master.  This is known from the
            table_map_log_event via the table_def class.  For convenience
            (and reuse in the mysqlbinlog patch), we add a member function
            rpl_utility.cc:table_def::json_column_count.  This function
            also caches the computed column count, to speed up successive
            calls (e.g. for many-row updates).
    
          - For the before-image, set the corresponding bit in the table's
            read_set, for any column having a 1 in the partial_bits.  This
            tells the engine to fetch the blob from storage (later, when
            the engine is invoked).  The blob will be needed since we have
            to apply the diff on it.
    
          - Call an auxiliary function rpl_record.cc:unpack_field to read
            each field move some special case handling for blobs into this
            function too.
    
       4. In rpl_record.cc:unpack_field, call
          field.cc:Field_json::unpack_field for partial Json fields.
    
       5. Add new function field.cc:Field_json::unpack_field, which
          invokes the new function
          json_diff.cc:Json_diff_vector::read_binary to read the
          Json_diff_vector, and the pre-existing (since WL#10570) function
          apply_json_diffs to apply the diff.
    
          The Json_diff_vector uses a new MEM_ROOT rather than the one of
          the current_thd, because that allows memory to be freed for each
          value, which saves resources e.g. in case of many-row updates.
    
          Before apply_json_diff can be invoked, we need to call
          table->mark_column_for_partial_update and
          table->setup_partial_update, in order to enable the *slave*
          server to generate JSON diffs in the *slave's* binary log.
    
       6. Add the new function json_diff.cc:Json_diff_vector:read_binary.
          This function reads the length of the field, then iterates over
          the diffs, reads each diff in turn, constructs Json_path and
          Json_wrapper/Json_dom objects, and appends them to the
          Json_diff_vector.
    
          We implement the auxiliary function net_field_length_checked,
          which reads an integer in packed format (see mysys/pack.cc),
          checking for out-of-bounds conditions.
    
    - Implement decoding and pretty-formatting of JSON diffs in mysqlbinlog
    
      mysqlbinlog outputs row events in two forms:
    
      - BINLOG statements that a server can apply.  There is nothing to
        change to make this work for the new event type.
      - "Pseudo-SQL" that humans can read, in case mysqlbinlog is invoked
        with the -v flag.  This is what the present patch implements.
    
      The pipeline in mysqlbinlog is:
    
       1. log_event.cc:Rows_log_event::print_verbose invokes
          log_event.cc:Rows_log_event::print_verbose_one_row with the new
          argument row_image_type, which indicates if this is a
          Write/Update/Delete and whether it is a before-image or
          after-image.
    
       2. In log_event.cc:log_event.cc:Rows_log_event::print_verbose_one_row
          we do two things:
    
          - Refactorings:
    
            - Use a Bit_reader to read the null bits, instead of using bit
              arithmetic.
    
            - Use safer boundary checks.  The code has a pointer to row
              data and a pointer to the end of the row data.  In C/C++, a
              pointer may point to the next byte after an allocated block
              of memory, but incrementing it further has an undefined
              result.  After reading the length of a field, the correct
              way to check that this length is not corrupt is to compare
              it with the end pointer minus the pointer to the read
              position.  (Before, it added the length to the read position
              and compared with the end pointer, but the read position
              plus the length is undefined.)
    
          - Implement the feature:
    
            - Read the value_options, if this is the after-image of a
              PARTIAL_UPDATE_ROWS_EVENT.
    
            - If value_options has the PARTIAL_JSON bit set, read the
              partial_bits.
    
            - Pass the partialness of the column as a parameter to
              log_event.cc:log_event_print_value.
    
       3. In the new function log_event_print_value, accept the new
          parameter, and in case the value is partial, call the new
          function log_event.cc:print_json_diff to parse and print the
          Json diffs.
    
       4. In the new function log_event.cc:print_json_diff, read, parse,
          and print all the diffs.
    
          The output has the form:
            JSON_<func>(
            JSON_<func>(
            ...
            JSON_<func>(@column, path[, value][,
                        path [,value][,
                        ...]]),
            ...
                        path[, value][,
                        path [,value][,
                        ...]]),
                        path[, value][,
                        path [,value][,
                        ...]])
    
          In this output format, the JSON_<func> functions appear in
          *reversed* order, whereas all the (path, value) pairs appear in
          order of appearance.  Therefore, we make two passes over the
          sequence of diffs:
    
           1. Read just the operations and store them in a vector.  Then
              print the operations in reverse order. Operations are
              printed using the new function
              log_event.cc:json_wrapper_to_string.
    
           2. Read the full diffs and output in the order of appearance.
    
       5. Add a new function log_event.cc:json_wrapper_to_string to print
          a Json_wrapper.  This ensures that the Json values are printed
          in the correct type.  JSON_<func> functions will convert SQL
          types to their JSON equivalents: for instance, the JSON function
          JSON_SET('[1, 2]', '$[0]', '[]') will set the 0th element of the
          JSON array to a string containing an open and closing square
          bracket, and not to an empty JSON array.  To account for this,
          different data types need different quoting, and to insert a
          JSON object or JSON array we need to cast the string to JSON
          first.
    
       6. To output JSON values with correct quoting for SQL strings, we use
          the existing my_b_write_quoted, but change it so that:
    
          - it uses a lookup table (computed only once) for simplicity and
            [1;31mperf[mormance;
    
          - it prints common escapes such as \n, \\ in a more
            human-readable way.
    
    - BUG#26018522: MYSQLBINLOG -V PRINTS JSON IN ROW EVENTS WRONG
      mysqlbinlog -v had two problems:
    
      P1. It only read the length of JSON objects from two bytes. But the
          length of JSON data in row events is encoded (in little endian)
          using four bytes.  Therefore, it printed the wrong data for JSON
          objects bigger than 64K.  This also caused subsequent errors.
    
      P2. It only dumped the raw bytes of the buffer (quoted).  But row
          events contain a binary format for JSON, so the output was not
          useful.
    
      We fix these two problems as follows:
    
      F1. Read the length from four bytes.
    
      F2. Link mysqlbinlog with the parts of the server that can parse
          binary JSON and format it in human-readable form.  This includes
          three files:
          - json_binary.cc can parse the binary JSON format.
          - json_dom.cc can format human-readable JSON.
          - sql_time.cc is used by json_dom.cc to format time and date.
          All these files contain code that mysqlbinlog does not need and
          which needs to link with more parts of the server (e.g. THD).  To
          avoid link problems we put such code inside #ifdef MYSQL_SERVER.
    
    - Created a new test suite for tests that should not be
      parallelized by MTR because they require many mysqlds.
    
      The new suite contains test cases requiring many (6 or more) mysqlds
      in a replication topology. Running those test cases with
      "--parallel" > 1 may exhaust the test host I/O resources. So, this
      new suite should run only with "--parallel=1".

[33mcommit db5dd4fc337c24d556312e9234a08f5b103cf557[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Sat Aug 19 10:00:30 2017 +0200

    WL#9830 PERFORMANCE_SCHEMA DIGEST QUERY SAMPLE
    
    Post push fix,
    resolved UBSAN failures when calling memcpy with NULL,
    seen in test [1;31mperf[mschema.start_server_zero_digest_sql_length.

[33mcommit f4442838be86ec00123fb17752e6be8a97b7181b[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Fri Aug 18 09:15:39 2017 +0200

    WL#9814 Implement INFORMATION_SCHEMA system views for FILES/PARTITIONS
    
    This patch implements I_S.PARTITIONS as a system view over data
    dictionary tables, and remove 5.7 code that uses a temporary
    table to represent I_S view.
    
    Following changes are made in the patch:
    
    * Define a system view over data dictionary tables representing
      I_S.PARTITIONS.
    
    * Add following new dictionary columns to store utf8 string version.
    
      mysql.table_partitions.description_utf8 representing
      I_S.PARTITIONS.DESCRIPTION
    
      mysql.tables.subpartition_expression_utf8 representing
      I_S.PARTITIONS.SUBPARTITION_EXPRESSION
    
      mysql.tables.partition_expression_utf8 representing
      I_S.PARTITIONS.PARTITION_EXPRESSION
    
    * Make dd::info_schema::Statistics_cache implementation to
      consider not just schema_name and table_name for cache key, but
      also include partition name. This is required now because we
      now cache per partition dynamic statistics with this WL.
    
    * Make dd::info_schema::Statistics_cache implementation to cache
      the table checksum value. This value is computed only for
      partitions.
    
    * Make implementation of Statistics_cache::read_stat_by_open_table()
      to fetch per partition dynamic table statistics.
    
    * If a partition is not found when fetching dynamic table
      statistics, then we will report a warning and continue
      processing new rows.  This might happen when I_S system view
      execution starts and later the partition table is ALTERed. A
      test case parts.partition_debug_sync_innodb is updated to cover
      this scenario.
    
    * Change definition of internal sql functions to accept partition
      name.This is used to calculate the per partition statistics.
    
      We currently read the statistics for partitioned table by
      opening the table. We can probably improve the [1;31mperf[mormance for
      InnoDB partitioned tables, by calling SE api's that read just
      the statistics. This is not done as of now.
    
    * Introduce internal sql function
      INTERNAL_GET_PARTITION_NODEGROUP() to fetch
      I_S.PARTITIONS.NODEGROUP value from
      mysql.table_partitions.options.
    
    * There is no consumer of function expr_to_string() requesting
      the string in hex form. So, the patch modifies it to return
      only string.
    
    * Remove 5.7 code from sql_show.cc for I_S.PARTITIONS.
    
    * Added ORDER BY clauses in some of I_S query to force order of
      tuple returned. Because, now the optimizer returns the rows and
      not read from temporary table as in 5.7 I_S design.
    
    * Remove part of test case in main.information_schema. Because,
    
      - The problem reported back then is only applicable for 5.7
        code.
    
      - The output of EXPLAIN ... <select on I_S system view> goes
        through optimizer and then plan return might vary.
    
    * We now show 1024 character of partition comment string, unlike just 80
      characters shown in 5.7 by I_S.

[33mcommit 10cdd222abb9f1093295a282339520d7f63d427b[m
Author: Jimmy Yang <jimmy.yang@oracle.com>
Date:   Wed Aug 16 19:53:40 2017 +0200

    Add order by in [1;31mperf[mschema/t/selects.test to make test more stable

[33mcommit 338bdac57f3a775928493dd53de3fd8067ca68ce[m
Author: Alfranio Correia <alfranio.correia@oracle.com>
Date:   Tue Aug 8 20:29:55 2017 +0100

    WL#10200: Change GCS/XCOM to have dynamic debugging and tracing
    
    The goal of this WL is to allow users to dynamically filter out debugging and
    tracing messages per sub-system (i.e. GCS, XCOM, etc) without a noticeable
    impact on [1;31mperf[mormance in production. Currently, it is extremely hard to trace
    bugs in production because the error log does not provide detailed information
    on the execution and enabling debug and trace requires a different build and
    deployment.
    
    Two different logging infrastructures are created. One to report error,
    warning and information messages and another one for debugging and tracing.
    The error, warning and information messages will be sent to the sink that is
    currently provided by the server.
    
    Debug and trace messages will be sent to a different sink which must be prepared
    to handle a possible high rate of logging messages. Specifically, debug and
    trace will be stored in GCS_DEBUG_TRACE file which will be located in the
    MySQL's data directory and will have the following permissions: same owner and
    group that files created by MySQL have and -rw-r-----.
    
    Users with super privileges will be giving the ability to dynamically
    enable debugging and tracing in production at their convenience as follows:
    
    SET GLOBAL group_replication_communication_debug_options = "..."

[33mcommit 88dedf5ec580b060380f6bb7e05c5392c7ba9fb6[m
Author: Darshan M N <darshan.m.n@oracle.com>
Date:   Wed Aug 2 21:26:25 2017 +0530

    WL#9536 Fixed pb2 failures
    
    This patch fixes a few pb2 failures
    
    1. main.mdl_tablespace test failure - test was waiting on a wait event in
       [1;31mperf[mormance_schema.event_waits_history_long which used to get removed from
       the table quicklty because of the increased number of PS events resulting
       in a timeout. Moved the TRUNCATE TABLE event_waits_history_long statement
       to truncate the table just before we allow ALTER to continue which moves
       the event from events_current table to events_history_long.
    
    2. main.information_schema - GROUP_CONCAT() in a query needed to be ordered
       to avoid result content mismatch error.
    
    3. main.dd_string - needed to record the test case.

[33mcommit 34a9bad08cb29410db399f098f828ed6ce907908[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Thu Aug 3 10:28:25 2017 +0200

    Bug#25526439: Assertion failed: is_fixed_or_outer_ref(this)
    Bug#25071305: Assertion failed: first_execution || !tl->is_view_or_derived() ...
    Bug#24716127: Incorrect behavior by insert statement with "on duplicate ..."
    
    This is a combined fix for three regression bugs in INSERT resolving
    that came after WL#5094 refactoring.
    
    The main problem here is about bad sequence of resolver actions, as
    WL#5094 introduced one sequence for all INSERT syntax that proved to
    be insufficient. The problem was that apply_local_transforms() was
    sometimes not [1;31mperf[mormed for subqueries in the INSERT ... ON DUPLICATE KEY
    UPDATE clause.
    
    It is necessary to know one implementation detail in order to grasp the
    full problem: Subqueries on INSERT ... VALUES clauses and subqueries in
    ON DUPLICATE KEY UPDATE clauses are attached to the last query block of
    the query expression of the INSERT statement, even though they are not
    actually referenced from this query block. And apply_local_transforms()
    will only be applied to subquery objects when called from an outermost
    query block.
    
    The solution is to identify three distinct cases for ON DUPLICATE KEY
    UPDATE resolving, with their required resolver sequences:
    
    1. INSERT INTO t ... VALUES ... ON DUPLICATE KEY UPDATE ...
       - Resolve VALUES expressions.
       - Resolve ON DUPLICATE KEY UPDATE expressions.
       - Call apply_local_transforms() on outer-most query block, which
         will include any subqueries in VALUES expressions.
    
    2. INSERT INTO t ... SELECT <non-union> ON DUPLICATE KEY UPDATE ...
       - Resolve SELECT query block, but do not call apply_local_transforms().
       - Combine context for SELECT query block and INSERT table
         (if the query block is non-grouped).
       - Resolve ON DUPLICATE KEY UPDATE expressions.
       - Call apply_local_transforms() on outer-most query block.
    
    3. INSERT INTO t ... SELECT ... UNION ... ON DUPLICATE KEY UPDATE ...
       - Resolve ON DUPLICATE KEY UPDATE expressions.
         (the outer query block may stay unresolved because there are no
          references into it).
       - Resolve the query expression, include calling apply_local_transforms()
         which will also include any subqueries in ON DUPLICATE KEY UPDATE
         clauses.
    
    In addition, we have extended with two new subquery context types:
    CTX_INSERT_VALUES and CTX_INSERT_UPDATE. They are used to generally
    provide more information about the parsing process, and in particular
    make it possible to build AST without outer references from subqueries
    in INSERT ... VALUES statements and in INSERT ... ON DUPLICATE KEY UPDATE
    statements.

[33mcommit 11f3d562b7889debbe7ed7fe626653f216243a21[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Mon Jul 31 15:09:16 2017 +0530

    WL#9644 : Enable event_scheduler by default
    
    Post push fix:
    
    - sys_vars.event_scheduler_basic.test changes processlist_user and
      processlist_host in [1;31mperf[mormance_schema.threads table. These values
      do not get reset at the end of the test. This can lead to sporadic
      failure for the tests following the test.
    
      Similar sporadic failure was observed where [1;31mperf[mormance schema maintains
      an invalid entry in [1;31mperf[mormance_schema.objects_summary_global_by_type
      even after the event is dropped by event scheduler.
    
      Reported Bug#26533649 and Bug#26549155 for the [1;31mperf[mormance schema
      framework. Restart server at the end of test to fix the sporadic failures.

[33mcommit 41455b9bee50e5206046f9adb094339784908d2c[m
Author: Darshan M N <darshan.m.n@oracle.com>
Date:   Sun Jul 30 18:47:31 2017 +0200

    WL#9536 Fixed another set of pb2 failures
    
    1) rpl_half_atomic_ddl_no_binlog test failure - recorded test results
    
    2) main.mdl_tablespace test failure - test was waiting on a wait event in
       [1;31mperf[mormance_schema.event_waits_history which used to get removed from the
       table quicklty because of the increased number of PS events resulting in
       a timeout. Fixed the issue by using [1;31mperf[mormance_schema.event_waits_history_long
       which has more size than history and truncating this table before using it.

[33mcommit 3bb9625e8d0a233d5d71994e4f3dd5e6751ab927[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Fri Jul 28 18:48:59 2017 +0200

    Build cleanup, when compiling without [1;31mperf[mormance schema.

[33mcommit 4d0cfa0a818da906a6c51f2379f15704c990b5a4[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Mon Jul 17 18:53:34 2017 +0530

    WL#9644 : Enable event_scheduler by default
    
    Post push fix:
    1> Event related [1;31mperf[mormance schema tests failed
       sporadically on the wait condition to validate
       the content of events_statements_history_long
       table and successful execution of event. With
       event scheduler always ON by default, the content
       of events_statements_history_long will depend on the
       previous tests executed by mtr.
    
       Fixed test case by deleting the contents of
       events_statements_history_long table using TRUNCATE TABLE
       command in the beginning of the test case. Turn off the
       event scheduler after one execution of event and switch it
       ON after the cleanup by the test.
    
    2> rpl.rpl_trx_boundary_parser_warning.test was failing due
       to not able to find the expected output in error log.
       The test case is hard coded to find the error in error log
       based on the execution of specified events from binlog.
       With event scheduler ON, the output changes sporadically
       by event scheduler thread. Turned off event scheduler for
       the test.

[33mcommit 2599c27cac144751cfcdce801acf7a353ccb0e05[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Tue Jul 11 07:25:54 2017 +0300

    Bug #26334869 "MAIN.MDL_TABLESPACE FAILING FREQUENTLY ON GCOV AND VALGRIND ON DAILY-TRUNK".
    
    Reverted change to mdl_tablespace.test which was introduced by WL7743
    "New data dictionary: changes to DDL-related parts of SE API" and
    which made it unstable under load.
    
    Usage of [1;31mperf[mormance_schema.events_waits_history_long instead of
    events_waits_history in this test seems to be unnecessary with
    current code and made the test unstable since the contents of the
    former table can be easily affected by server's background
    activities.

[33mcommit a050b76b735c0d3036fa1a4b966eb4a3476cb2f6[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Jul 10 20:30:09 2017 +0200

    Merge cleanup.
    
    Fix build warnings,
    fix build when compiling without the [1;31mperf[mormance schema instrumentation.

[33mcommit 035ccac08081dfb0b73bb0221e5f819a7aab7428[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Tue Jul 4 20:14:58 2017 +0200

    WL#9764 PERFORMANCE_SCHEMA SERVICE FOR COMPONENTS
    
    Further stabilization of [1;31mperf[mschema.pfs_example_lifecycle

[33mcommit 41c28c31d2cb1e9ca7bda31eaaf4daaf9a260a17[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Jul 3 10:53:52 2017 +0200

    Bug#26162562 DISABLING PERFORMANCE_SCHEMA.SETUP_OBJECT DROP TABLE STATS
    
    Before this fix,
    
    when a table instrumentation is disabled,
    due to edits in table [1;31mperf[mormance_schema.setup_objects,
    the following actions were executed:
    - the table lock statistics were discarded
    - the index statistics were discarded
    - the index names, stored with the per index stats, were lost.
    
    The root cause is logic present in
    PFS_table_share::refresh_setup_object_flags(),
    which explicitly destroyed lock and index stats.
    
    Note that the table statistics were implemented with the following model:
    - either a table is enabled, and stats are preserved,
    - or a table is disabled, and stats are dropped.
    
    This model however was not consistently implemented,
    as statistics could still be allocated even for disabled table,
    for example in find_or_create_table_share().
    
    With this fix, the old model is abandoned,
    as the behavior is inconsistent with other instrumentations,
    and cause undesirable side effects for index names.
    
    The new model is as follows:
    - enabling / disabling instrumentation for tables
      no longer destroys associated statistics.
    
    As a result,
    - index names are preserved once found,
      so that index statistics no longer show spurious "index N" names.
    - statistics are preserved instead of being truncated
      when a table is disabled.
    - visiting table statistics searches data deeper,
      no longer stopping if a table instrumentation is disabled.

[33mcommit 4fc2403d4d43f7aaccecad68fd2bee1ce4470af3[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Jul 3 15:07:09 2017 +0200

    Bug#26357806 SESSION_CONNECT_ATTRS.PROCESSLIST_ID SHOULD BE BIGINT
    UNSIGNED
    
    Patch for 8.0 only.
    
    Before this fix, columns:
    - [1;31mperf[mormance_schema.session_connect_attrs.PROCESSLIST_ID
    - [1;31mperf[mormance_schema.session_account_connect_attrs.PROCESSLIST_ID
    
    are of type INT.
    
    This is incorrect, as column threads.PROCESSLIST_ID
    is a BIGINT UNSIGNED.
    
    The root cause is the incomplete change introduced by
      Bug#14664453 THREAD_ID SHOULD BE BIGINT(21) UNSIGNED IN PERFORMANCE_SCHEMA
    to migrate thread and processlist ids from 32 bit to 64 bits.
    
    With this fix, columns
    - [1;31mperf[mormance_schema.session_connect_attrs.PROCESSLIST_ID
    - [1;31mperf[mormance_schema.session_account_connect_attrs.PROCESSLIST_ID
    are changed to the proper type.

[33mcommit aa9004200c346abae379ca4503eaf899ccca17d2[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Jun 30 14:44:41 2017 +0200

    Bug #26377058: CREATE DECIMAL MICROBENCHMARKS
    
    The bin2dec/dec2bin code is an important part of some DBT-3 queries.
    Add some microbenchmarks to keep their [1;31mperf[mormance in check.
    
    Example microbenchmarks on my Skylake 3.4 GHz:
    
      GCC 4.8, -O3:   BM_Decimal2Bin_10_2    26 ns/iter
      GCC 6.3, -O3:   BM_Decimal2Bin_10_2    24 ns/iter
      GCC 7.1, -O3:   BM_Decimal2Bin_10_2    25 ns/iter
      GCC 4.8, -O2:   BM_Decimal2Bin_10_2    22 ns/iter
      GCC 6.3, -O2:   BM_Decimal2Bin_10_2    21 ns/iter
      GCC 7.1, -O2:   BM_Decimal2Bin_10_2    23 ns/iter
    
      GCC 4.8, -O3:   BM_Bin2Decimal_10_2    19 ns/iter
      GCC 6.3, -O3:   BM_Bin2Decimal_10_2    19 ns/iter
      GCC 7.1, -O3:   BM_Bin2Decimal_10_2    20 ns/iter
      GCC 4.8, -O2:   BM_Bin2Decimal_10_2    19 ns/iter
      GCC 6.3, -O2:   BM_Bin2Decimal_10_2    19 ns/iter
      GCC 7.1, -O2:   BM_Bin2Decimal_10_2    19 ns/iter
    
    Change-Id: Ibb87319a9ff80e4b36f1b472358de7eb38c63b9a

[33mcommit edc1189ea00df6199092f23510e768a99200e194[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Jun 26 11:06:08 2017 +0200

    Bug#26136994 TABLE COULD BE DROPPED AND RECREATED DIFFERENTLY IN PFS
    
    Before this fix, the privileges in the [1;31mperf[mormance schema
    allowed the user to:
    - CREATE any [1;31mperf[mormance schema table
    - DROP / TRUNCATE any [1;31mperf[mormance schema table
    
    Allowing these operations was necessary for the
    install and upgrade SQL scripts.
    
    With the recent implementation of:
    WL#7900 New DD: Support flexible creation
      and versioning of virtual P_S tables
    WL#8879 PERFORMANCE SCHEMA, TABLE PLUGIN
    
    the table creation is no longer done using a SQL CREATE TABLE statement,
    but embedded in the server code itself.
    
    As a result, allowing CREATE and DROP on [1;31mperf[mormance schema tables
    is no longer necessary, and privileges can be more restrictive.
    
    With this fix,
    - CREATE TABLE is never allowed to a user,
    - DROP TABLE is never allowed to a user,
    - TRUNCATE TABLE is only allowed for tables that supports truncation.

[33mcommit 06b2dcc73ab19dabf6e16658b9b6e53fddefbf5a[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Sat Jun 17 16:27:12 2017 +0200

    Bug#25418534: JSON_EXTRACT USING WILDCARDS TAKES FOREVER
    
    Patch #4:
    
    Move handling of auto-wrapping to the handling of array path legs, so
    that we don't pay the cost of checking if auto-wrapping should be
    [1;31mperf[mormed for every path leg.
    
    Microbenchmarks (64-bit, Intel Core i7-4770 3.4 GHz, GCC 6.3):
    
    BM_JsonDomSearchEllipsis              22608 ns/iter [+12.5%]
    BM_JsonDomSearchEllipsis_OnlyOne      16169 ns/iter [ +9.8%]
    BM_JsonDomSearchKey                     129 ns/iter [ -0.8%]
    BM_JsonBinarySearchEllipsis          230855 ns/iter [ +1.1%]
    BM_JsonBinarySearchEllipsis_OnlyOne  223140 ns/iter [ +1.3%]
    BM_JsonBinarySearchKey                   86 ns/iter [  0.0%]
    
    Change-Id: I2a233ee7b5a709a1388a370cb96126b17d59595b

[33mcommit e29bf522abd3b70eb738cf87c2912e4e5ee02674[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Sat Jun 17 16:20:38 2017 +0200

    Bug#25418534: JSON_EXTRACT USING WILDCARDS TAKES FOREVER
    
    Patch #3:
    
    find_child_doms() has two kinds of duplicate elimination. One for
    removing duplicates that occur due to multiple ellipses, and one for
    removing duplicates that occur due to auto-wrapping on results
    returned by an ellipsis.
    
    The first kind of duplicate elimination is [1;31mperf[mormed by maintaining a
    sorted set of results. The second kind [1;31mperf[morms a linear search of the
    results to see if the value is already in the result vector.
    
    This patch consolidates this code so that they both use the first kind
    of duplicate elimination. It also makes sure that duplicate
    elimination for auto-wrapping only happens for paths that could
    produce duplicates (only if the auto-wrapping path leg comes after an
    ellipsis path leg).
    
    This is just a code cleanup. The microbenchmark results are
    indistinguishable from noise.
    
    Microbenchmarks (64-bit, Intel Core i7-4770 3.4 GHz, GCC 6.3):
    
    BM_JsonDomSearchEllipsis              25443 ns/iter [+1.0%]
    BM_JsonDomSearchEllipsis_OnlyOne      17757 ns/iter [+0.7%]
    BM_JsonDomSearchKey                     128 ns/iter [ 0.0%]
    BM_JsonBinarySearchEllipsis          233469 ns/iter [-0.9%]
    BM_JsonBinarySearchEllipsis_OnlyOne  226089 ns/iter [-1.5%]
    BM_JsonBinarySearchKey                   86 ns/iter [ 0.0%]
    
    Change-Id: Ia62916098096032adf9f2ecc70a42c845f625c1c

[33mcommit fbc878cc5880e5629f182fbd12b570ed513f728c[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Mon Jun 19 11:21:36 2017 +0200

    Bug#25418534: JSON_EXTRACT USING WILDCARDS TAKES FOREVER
    
    Patch #0:
    
    Add microbenchmarks that measure the [1;31mperf[mormance of Json_wrapper::seek().
    
    Change-Id: I1a5990eea93667c9119f1637701852bd752fc896

[33mcommit 3ea6ece3105a0420fbe0e3fa86019505888bc392[m
Author: Thirunarayanan Balathandayuthapani <thirunarayanan.balathandayuth@oracle.com>
Date:   Fri Jun 23 10:15:07 2017 +0530

    Bug#26197113 SLOW DYNAMIC TABLE STATISTICS RETRIVAL FROM I_S AFTER MYSQL-TRUNK-META-SYNC PUSH
    
    Analysis:
    
    If the table is not present in the cache then opening the table
    takes lot of time and it leads to slow [1;31mperf[mormance in information
    schema queries.
    
    Following changes are done to fix the issue,
    
    InnoDB changes:
    
    - Instead of opening the table, InnoDB can fetch the stats
      information from innodb_table_stats and innodb_index_stats.
    
    - Fetch the record from innodb_table_stats using db_name, table name
      and it will give information about n_rows, clustered index_size and
      sum of other index size.
    
    - Fetch the space id from Tablespace SE private data for
      general/system tablespace (or) Fetch the space id using db_name,
      table_name from fil_space_t hash.
    
    - Use the space_id to calculate the available length in the
      tablespace.
    
    - Maximum value of autoincremnt fetched from innodb_dynamic_metadata
      using table id and autoincrement fetched from table_se_private data.
    
    - Cardinality can be fetched from innodb_index_stats table using
      db_name, table name, index name and column offset.
    
    - If the table doesn't have persistent stats then InnoDB loads
    the table from the disk.
    
    Server changes:
    
    - Supply mysql.tablespaces.se_private_data to internal functions
      INTERNAL_*(), which is used by SE to read the SE specific tablespace
      metadata when fetching table dynamic statistics. E.g., InnoDB would
      read the SE specific space_id from se_private_data column.
    
    - INFORMATION_SCHEMA.TABLES system view is now joined with
      mysql.tablespaces, to get the mysql.tablespaces.se_private_data for a
      table.
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Bin Su <bin.x.su@oracle.com>
    Reviewed-by: Praveenkumar Hulakund <praveenkumar.hulakund@oracle.com>
    RB: 16467

[33mcommit f70ea5b86024be897a4d2f427fc569c9ec86c09a[m
Author: Debarun Banerjee <debarun.banerjee@oracle.com>
Date:   Fri Jun 23 11:06:12 2017 +0530

        WL#9209: InnoDB: Clone local replica
        ====================================
        Create a server plugin that can be used to retrieve a snapshot
        of the running system. Here we would support syntax to take a
        physical Snapshot of the database and store it in same
        machine/node where the database server is running.
    
        We should be able to start mysqld server on the cloned directory
        and access data. The clone operation should work with concurrent
        DMLs on the database.
    
        INSTALL PLUGIN clone SONAME 'mysql_clone.so';
        CLONE LOCAL DATA DIRECTORY [=] 'data_dir';
        UNINSTALL plugin clone;
    
        Review: rb#15068
    
        WL#9212: InnoDB: Monitor Clone status
        =====================================
        Support metadata view in [1;31mperf[mormance schema to monitor progress
        of an ongoing clone operation. A clone operation might take time
        to clone the entire database. Administrator can view the current
        status and percentage of clone operation completed by querying
        this view in local and remote server.
    
        EVENT_NAME = "statement/sql/clone"
        EVENT_NAME = "stage/sql/clone (file copy)"
        EVENT_NAME = "stage/sql/clone (page copy)"
        EVENT_NAME = "stage/sql/clone (redo copy)"
    
        Review: rb#14160
    
        Merged from mysql-trunk-wl8953 [3db0acef]

[33mcommit df5c7956bb106edd16304219faaf5e67099fe7a9[m
Author: Thirunarayanan Balathandayuthapani <thirunarayanan.balathandayuth@oracle.com>
Date:   Fri Jun 23 10:15:07 2017 +0530

    Bug#26197113 SLOW DYNAMIC TABLE STATISTICS RETRIVAL FROM I_S AFTER MYSQL-TRUNK-META-SYNC PUSH
    
    Analysis:
    
    If the table is not present in the cache then opening the table
    takes lot of time and it leads to slow [1;31mperf[mormance in information
    schema queries.
    
    Following changes are done to fix the issue,
    
    InnoDB changes:
    
    - Instead of opening the table, InnoDB can fetch the stats
      information from innodb_table_stats and innodb_index_stats.
    
    - Fetch the record from innodb_table_stats using db_name, table name
      and it will give information about n_rows, clustered index_size and
      sum of other index size.
    
    - Fetch the space id from Tablespace SE private data for
      general/system tablespace (or) Fetch the space id using db_name,
      table_name from fil_space_t hash.
    
    - Use the space_id to calculate the available length in the
      tablespace.
    
    - Maximum value of autoincremnt fetched from innodb_dynamic_metadata
      using table id and autoincrement fetched from table_se_private data.
    
    - Cardinality can be fetched from innodb_index_stats table using
      db_name, table name, index name and column offset.
    
    - If the table doesn't have persistent stats then InnoDB loads
    the table from the disk.
    
    Server changes:
    
    - Supply mysql.tablespaces.se_private_data to internal functions
      INTERNAL_*(), which is used by SE to read the SE specific tablespace
      metadata when fetching table dynamic statistics. E.g., InnoDB would
      read the SE specific space_id from se_private_data column.
    
    - INFORMATION_SCHEMA.TABLES system view is now joined with
      mysql.tablespaces, to get the mysql.tablespaces.se_private_data for a
      table.
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Bin Su <bin.x.su@oracle.com>
    Reviewed-by: Praveenkumar Hulakund <praveenkumar.hulakund@oracle.com>
    RB: 16467

[33mcommit 6b34713cd8529106d32eae684cda6f4984ce82eb[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Jun 21 12:49:57 2017 +0200

    wl#10234, Fix initial ('firsteExec') parallelism calculation ([1;31mperf[mormance patch)
    
    When there is no valid parallism statistics available,
    we start by scaning only a single node-local fragment.
    This will give us a sample of the selectivity such that
    further scan parallelism can be estimated.
    
    However, this WL set introduced new logic which
    increased the parallelism to > 1 if we otherwise could
    have exceeded the MAX_PARALLEL_OP_PER_SCAN pr fragment.
    
    This logic incorrectly took effect also when we had choosen
    to sample only a single fragment. Thus breaking the initial
    sampling logic.

[33mcommit 6d0d6630b26ef51825e95f4eea42c67f3d11565c[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Jun 21 12:40:41 2017 +0200

    wl#10234, fix fragment enumeration skew. ([1;31mperf[mormance patch)
    
    To avoid that all SPJ blocks requested fragment scans
    on the same sub-set of fragments, while other were
    idle, a different 'skew' is used wjen setting up the
    fragment lists on the different SPJ's.
    
    This was previously set up such that a skew of '1'
    was used between the different SPJ.
    
    With these WL that has to change such that the number
    of multi-fragments assigned to each SPJ is used in
    the skew calculation.

[33mcommit 6c082925cdd391763a89b581203c31ad3e7bddea[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri May 19 09:17:50 2017 +0200

    wl#10234, Reintroduce building of SPJ [1;31mperf[mormance measurement tool
    
    spj_[1;31mperf[mormance_test.cpp was one of the tools originaly used
    when developing the SPJ feature. It turns out that building of this
    tool was disabled when we switched to using cmake.
    
    Patch reintroduce build of this tool and also extend it to
    be able to test Scan-Scan spj queries. (Spj queries where
    both the root node and its childs are scans)

[33mcommit 84ff6252483723ee417c7a08a015f41df9f55352[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Thu May 11 09:01:13 2017 +0200

    WL#10302: When [1;31mperf[morming system restart we can sometimes start from an old GCI, in this case we need to update the m_max_completed_gci at reception of CNTR_START_CONF since no GCPs will be executed during a SR. Fixed a bug in lgman.cpp introduced by WL#10302, after this it is better understood how the LGMAN actually uses head and tail.

[33mcommit f1abe85a4d71c535f98a5a3f92f7e32317000bf1[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Thu May 4 11:36:19 2017 +0200

    WL#8069: LCP scanned bit was set and not reset when the partition was empty when the LCP scan started, fixed by ensuring that we [1;31mperf[morm scan even if the partition is empty and there have been pages in it at the LCP scan start

[33mcommit fb0076a6b3e25bf1ad7495e7c250527b952a143e[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Tue May 2 08:23:46 2017 +0200

    WL#8069
    Fixed bug in DIH where we assumed that no LCP could have been saved
    and still no LCP valid found. With 8069 we report LCP completed much
    later, so this means that this is a [1;31mperf[mectly legitimate event.
    
    We kept around some checks that we didn't start an LCP with a queue.
    This kept around check was buggy, so removed it and replaced it with
    a simple check at start of LCP that queue is empty.
    
    Fixed one bug previously with handling of skipped pages, however this
    meant that the variable all_parts got to be always false and we entered
    into the Partial LCP code. The partial LCP code needed to initialise the
    m_tableId in the scan record, but we also needed to always set the
    all_parts to true to ensure that we don't use the Partial LCP code just
    yet. Will require some fixing later on when adding Partial LCP for real.

[33mcommit 0fec89959db11b7b4fc1f2ab16a91ca1b01c9e7d[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Fri Jun 9 09:16:49 2017 +0200

    Bug#25908290 FEW TESTS FAILING WITH ERROR "SHUTDOWN_SERVER" FAILED WITH ERROR 2. MY_ERRNO=175 [noclose]
    
    Disable for Valgrind
    
    innodb_undo.trunc_multi_client_01
    innodb_undo.trunc_multi_client_02
    innodb_undo.truncate
    [1;31mperf[mschema.init_pfs_from_dd
    main.table_definition_cache_functionality
    
    in order to avoid noise.

[33mcommit 56c807fb5dea912c95f0cdb5ec40e3bec00c37e0[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Jun 7 14:28:47 2017 +0200

    Bug#26193630 INCREASE PERFORMANCE_SCHEMA_MAX_MUTEX_CLASSES
    
    Increase [1;31mperf[mormance-schema-max-mutex-classes
    default value from 220 to 250.
    
    This is needed to account for new instrumentation added in 8.0

[33mcommit 129aca97f926414a479d01b71b364656d93d4b76[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Wed Jun 7 08:57:07 2017 +0200

    Bug #25563891: OPTION SET BY !INCLUDE OR !INCLUDEDIR SHOWED AS 'COMPILED'
                   IN P_S.VARIABLES_INFO.
    Bug #25608115: VARIABLES_INFO.SET_TIME COLUMN INITIALIZED INCORRECTLY
    Bug #25776940: SERVER NOT COMING UP WHEN VARIBLES SET WITH PERSIST&RESTARTED
                   WITH SKIP-GRANT-TA
    
    Problem: P_S.variables_info table: VARIABLE_SOURCE column is not reflected
             with correct values for variables which are specified in config file
             as part of include directive file.
    Fix:     default_paths is a hash map which keeps track of all standard paths
             with respective variable source enum values. Since include directives
             can be specified in cnf and login config files, we add the new path
             specified as part of include dir in this hash map along with appropriate
             enum value. This update will cause ps.variables_info.variable_source
             column to be populated with correct values.
    Test:    Added the new testcase to persisted_variables_extended.test.
    
    Problem: When event_scheduler variable is persisted and server is restarted
             with --skip-grants-tables option then server does not start and
             instead reports error as below:
             2017-03-24T08:50:13.127995Z 2 [ERROR] Failed to set persisted options.
             2017-03-24T08:50:13.128091Z 0 [ERROR] Setting persistent options failed.
             This error is not allowing end user to understand what the problem is.
    Fix:     Fix is to report some meaningfull error so that user can take necessary
             actions to overcome the error.
    Test:    Did manual test and i see that proper error message is reported.
    
    Problem: [1;31mperf[mormance_schema.variables_info table SET_TIME columns default value
             is not set to server startup time, instead set to time when first
             SELECT is executed on this table.
    Fix:     Intialize this columns default value to server startup time.
    Test:    Added the new testcase to persisted_variables_extended.test.

[33mcommit 6de594adf488add4514884d18c337745b1d227fb[m
Author: Joao Gramacho <joao.gramacho@oracle.com>
Date:   Tue Mar 7 12:05:46 2017 +0000

    WL#10406: Improve usability when receiver thread is waiting
              for disk space
    
    Step 1
    ======
    
    This patch replaced the requirement to access Master_info format
    description event from Master_info->data_lock to relay_log->LOCK_log.
    
    It also changed the locking order at queue_event() to
    relay-log->LOCK_log, Master_info->data_lock.
    
    It made the SQL thread not rely on the relay log LOCK_log to be
    stopped anymore.
    
    Step 2
    ======
    
    Truncating the relay log in correct event boundaries
    ----------------------------------------------------
    
    This patch introduced the MYSQL_BIN_LOG::truncate_relaylog_file(). This
    function is called after errors writing events to the relay log, passing
    the relay log end pos (the end of the last known successfully written
    event) to minimize the possibility of the applier thread to read a
    partial (bad) event.
    
    Displaying "Waiting for disk space" on status
    ---------------------------------------------
    
    This patch introduced enter_stage_hook to make my_write() able to set
    the current thread stage as "Waiting for disk space" before calling
    wait_for_free_space() function and restoring the previous thread stage
    after the function call.
    
    This will make any thread waiting for disk space on my_write() to report
    this information not only in error logs but also in thread status
    interfaces ([1;31mperf[mormance schema tables, SHOW SLAVE STATUS, etc.).
    
    WL related bug fixes
    ====================
    
    BUG#26111422 ASSERTION `IS_OPEN()' FAILED AT
                 MYSQL_BIN_LOG::TRUNCATE_RELAYLOG_FILE
    
    Problem
    -------
    
    The replica server is trying to truncate a closed relay log file when an
    unrecoverable error occurred while rotating the relay log.
    
    Analysis
    --------
    
    In the case of an unrecoverable error when rotating the relay log, the
    server will take the configured BINLOG_ERROR_ACTION.
    
    When BINLOG_ERROR_ACTION=ABORT_SERVER, the server will be shutdown.
    
    When BINLOG_ERROR_ACTION=IGNORE_ERROR, the server will close the relay
    log. The only way of recovering the closed relay log is to restart the
    whole server.
    
    The code at truncate_relaylog_file() is asserting that the relay log was
    opened when called to prevent trying to truncate a closed relay log.
    
    Fix
    ---
    
    Because of the possibility of calling the function after an error
    rotating the relay log, the truncate_relaylog_file() function should
    not assert that the relay log is open and also should take no action
    when the relay log was closed.
    
    BUG#26161405 EXECUTING STOP SLAVE WHEN IO_THREAD IS "WAITING FOR DISK
                 SPACE" CAUSES PROBLEMS
    
    Problems
    -------
    
    STOP SLAVE [IO_THREAD] will set mi->abort_slave flag and will wait until
    the I/O thread to be stopped.
    
    When the I/O thread is waiting for disk space, the mi->abort_slave
    signal will not be checked by the I/O thread until finishing queuing the
    current event. So, "STOP SLAVE" will be blocked (until STOP SLAVE
    timeout with an error).
    
    Also, any thread waiting for disk space at "my_write" (thread that used
    the MY_WAIT_IF_FULL flag) could report itself as "Waiting for disk
    space".
    
    Shutting down the server while having an I/O thread waiting for disk
    space would hang the server without accepting new connections until disk
    space be freed.
    
    Fixes
    -----
    
    STOP SLAVE [IO_THREAD] throws a warning message into the server error
    log recommending either to free some disk space or to use 'KILL' to
    abort I/O thread operation.
    
    Only the relay log related operations will change the thread status to
    "Waiting for disk space". A new flag was used to signal the my_write
    function to change the thread status.
    
    Shutting down the server while having an I/O thread waiting for disk
    space will make the I/O thread to be killed, truncating the current
    relay log file if possible.
    
    Fixed a doxygen issue at MYSQL_BIN_LOG::truncate_relaylog_file().
    
    Fixed an issue in "[1;31mperf[mormance_schema.threads" that was not showing
    "Waiting for disk space" at PROCESSLIST_STATE field.

[33mcommit ec6e3d08a25d134482a8be5862d0ebe002c63eb3[m
Author: Vitor Oliveira <vitor.s.p.oliveira@oracle.com>
Date:   Fri Jun 2 14:34:49 2017 +0200

    WL#9838 Group Replication: Flow-control fine tuning
    
    Before this worklog GR's flow-control mechanism depended on heuristics
    that left little control to the user, other then enabling/disabling it
    and setting the queue thresholds. WL#9838 allows the user to have more
    control over flow-control settings, with new options to control:
    
        The minimum flow-control quota that can be assigned to a member,
        it is no longer restricted to being 5% of the lowest flow-control
        thresholds.
    
        The minimum recovering flow-control quota: different from the
        minimum flow-control quota in that it applies only to members
        entering the group, so that the members entering the group don't
        excessively affect throughput.
    
        The maximum cluster commit quota: in order to keep the group
        operating within a safe throughput range (to improve on predictable
        behaviour and balance between members).
    
        The proportion of the quota that is assigned to each member: it not
        longer needs to be divided equaly by the writer members, to support
        scenarios where one member is supposed to write more then others.
    
        The flow-control period: allows flow-control to run less often than
        once per second when the commit rate is very low and not enough
        transactions are executed per second to give the heuristics enough
        data to work properly.
    
        The percentage of the quota reserved for catch-up when flow-control
        is released: the constants in the code, 10% and 50% of the quota
        respectively, can now be tuned to properly reduce variations that
        are presently seem in the throughput when the system is close to
        exhausting its free capacity.
    
    In addition, participation in flow-control becomes optional, so that
    some members can be ignored by other members if they require so. This
    allows members to remain in the group while [1;31mperf[morming maintenance
    tasks, at the cost of having the garbage collection in GR become less
    effective as members stop applying transactions that are being sent to
    the group.

[33mcommit 341a5f582bcb42fcd6217b185f8abf514efe8efb[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Fri Jun 2 12:46:22 2017 +0200

    WL#8879 PERFORMANCE_SCHEMA, TABLE PLUGIN
    
    This patch implements following two API's which are required by
    WL#8879.
    
      dd::create_native_table(THD*, Plugin_table*);
      dd::drop_native_table(THD*, Plugin_table*);
    
    These APIs would be invoked by the new table plugin server added
    by WL#8879. The API's just updates the DD tables and do not make
    calls to [1;31mperf[mormance_schema engine. The patch does,
    
    - The PS tables are created during plugin initialization.
    
    - The PS tables are dropped during plugin deinitialization.
    
    - INSTALL and UNINSTALL implementation is modified to do atomic
      updates. I.e., if the command fails, the plugin PS table metadata
      are rollback.
    
    - Makes INSTALL/UNINSTALL COMPONENT commands to enable component
      initialization phase to invoke dd::create_native_table() and
      dd::drop_native_table() APIs.
    
    - Change Plugin_table to store schema name.
    
    - Change Plugin_table_definition_impl to return current schema name.
    
    - When a PS table is created, the API create_native_table() changed
      the autocommit mode to off, without checking if there is already
      a transaction started. Due to this, the InnoDB table operations
      are first done in autocommit ON mode and then in autocommit OFF.
      This causes InnoDB to rollback some operations and hence leaves
      DD in in-consistent state. The result is that the server startup
      fails.
    
      The fix is to move commit the transaction at the end of component
      /plugin initialization phase during server startup. The server
      shutdown does not remove PS table metadata from DD, so the server
      shutdown component/plugin deinitialization code does not need to
      commit the transaction.
    
    - If a server is crashed, and restarted without a given plugin,
      the meta data will still be present, there is not side effect.

[33mcommit 75d9631a0b88d34be5bf982537bb7392cbd752b5[m
Author: Jaideep Karande <jaideep.karande@oracle.com>
Date:   Thu Jun 1 19:26:26 2017 +0530

    WL#10380: Group Replication: Monitoring improvements
    
    Description:
    This worklog goal is to improve Group Replication by introducing additional
    columns in existing [1;31mperf[mormance schema.
    
    Schema after code changes:
    
    For table - [1;31mperf[mormance_schema.replication_group_member_stats
    New suggested columns:
    Field          Type     Null Key  Default Description
    MEMBER_ROLE    char(64) NO        NULL    Member role in a group; can be any of
    the PRIMARY or SECONDARY
    MEMBER_VERSION char(64) NO        NULL    The MySQL version of the member.
    NOTE: Columns will be added in same sequence as listed above.
    
    For table - [1;31mperf[mormance_schema.replication_group_member_stats
    New suggested columns:
    Field                                      Type                Null  Key
    Default  Description
    COUNT_TRANSACTIONS_REMOTE_IN_APPLIER_QUEUE bigint(20) unsigned NO         NULL
    Transactions waiting apply, received from group.
    COUNT_TRANSACTIONS_REMOTE_APPLIED          bigint(20) unsigned NO         NULL
    Transactions applied, received from group.
    COUNT_TRANSACTIONS_LOCAL_PROPOSED          bigint(20) unsigned No         NULL
    Number of local transaction requested by member to Group Replication Plugin for
    commit.
    COUNT_TRANSACTIONS_LOCAL_ROLLBACK          bigint(20) unsigned No         NULL
    Number of transaction originated from local member but rolledback at GROUP level
    NOTE: Columns will be added in same sequence as listed above.

[33mcommit e6b35b1ca1a59300564b115e759ba80c7e73d6cc[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Thu Jun 1 13:10:36 2017 +0200

    WL#8881 Performance Schema, Resource Control
    
    Follow-up fix to [1;31mperf[mschema.service_pfs_notification

[33mcommit f1091a39a4083278c3b91b3f2693b08d37c26b0d[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue May 30 14:30:29 2017 +0200

    Bug#26166852 TSAN: DATA RACE IN CLEANUP_INSTRUMENTS
    
    TSAN reports cleanup/shutdown of [1;31mperf[mormance schema.
    
    Fix: use std::atomic<pointer> rather than raw pointer for
    global_instr_class_memory_array
    
    Change-Id: I2d0ec2633a35ab8813018c5c7dd8ee4e09c34cd5

[33mcommit 9f3e545dd751b78451b1550280a03cddb4c9b84b[m
Author: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
Date:   Thu Apr 27 19:19:13 2017 +0200

    WL#9807: X Protocol Crud.Insert with upsert
    
    The UPSERT command is a very useful operation that allows [1;31mperf[morming
    an insert or update, depending on whether the record already exists or
    not, in a single step, atomically.
    MySQL supports the ON DUPLICATE KEY UPDATE extension to INSERT,
    which has this behaviour, and should be used for implementation.
    
    Approved-by: Vinay Fisrekar <vinay.fisrekar@oracle.com>

[33mcommit 67a2ec3597ac9c13c286979021f6554714c108dc[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Fri May 12 09:45:31 2017 +0200

    Bug#25858461: FAILURE TO DROP DATAFILE FROM TABLESPACES WITH MULTIPLE DATAFILES
    
    Problem: It was not possible to drop a tablespace file from a general
    tablespace which had more than one tablespace file.
    
    Root cause was that when a tablespace file is dropped, all tablespace
    files with a higher ordinal position will have their ordinal position
    decremented by one. Since the ordinal position is part of the PK of
    TABLESPACE_FILES, the store following the drop would result in an
    pk-update of the files which had their ordinal position decremented.
    
    But pk-updates are not supported by the store-implementation in
    dd::Weak_object_impl as it searches for the new key and only [1;31mperf[morms
    an update if this key is found. When the key itself is being updated
    searching for the new key is wrong and could cause the wrong tuple to
    be updated, or as in this case, a new tuple to be inserted without
    deleting the tuple with the old key. In this case such an insert was
    rejected because both the old and the new tuple had the same value for
    TABLESPACE_FILES.file_name, and there is a unique constraint on this
    column.
    
    Solution: When dropping a tablespace file, all the files must be
    dropped from TABLESPACE_FILES first, and then the remaining files (that
    were not supposed to be dropped) must be re-insterted with the correct
    PK and file_name, so that duplicates are avoided.
    
    (cherry picked from commit a6de211c736f49a74ad433f7651b629552c9115d)

[33mcommit c54a40ee843b63315abe3a87cb4875e260327799[m
Author: Daniel Blanchard <daniel.blanchard@oracle.com>
Date:   Mon May 22 11:55:44 2017 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO
    UTF8MB4
    
    Post-push fix: Improve [1;31mperf[mormance of my_charpos_mb4 for single byte per
    character strings.
    
    Microbenchmarks (64bit Intel Xeon CPU E5-2690 2.89GHz MSVC 2015)
    
      BM_SimpleUTF8MB4            249 ns/iter [  +3.2%]
      BM_UTF8MB4StringLength       14 ns/iter [+428.6%]
      BM_MixedUTF8MB4             390 ns/iter [  -0.3%]
      BM_MixedUTF8MB4_AS_CS      1276 ns/iter [   0.0%]
      BM_JapaneseUTF8MB4         1229 ns/iter [  -2.4%]
      BM_NewlineFilledUTF8MB4     371 ns/iter [   0.0%]
      BM_HashSimpleUTF8MB4        345 ns/iter [  +0.9%]
      BM_Hungarian_AS_CS         6236 ns/iter [  -0.2%]
    
    Change-Id: Ib09a6679b0d8c5ea6583d8a61216184c0f9004cd

[33mcommit 0836f5c62d6c436eb34bb9ddd88d7c7bc6c12401[m
Author: Dmitry Shulga <dmitry.shulga@oracle.com>
Date:   Sat May 13 16:52:15 2017 +0700

    WL#7900 -- New DD: Support flexible creation and versioning of virtual P_S tables
    
    This worklog provides support for:
      * retrieving P_S table definitions from [1;31mperf[mormance schema engine
        and
      * for versioning of P_S table definitions.
    
    To implement it the following modifications are done within the worklog:
    
      * A version of [1;31mperf[mormance schema supported by server is stored in the table
        mysql.dd_properties as a value of property with the name "PS_version";
    
      * For every created P_S table a boolean property with the name
        "server_p_s_table" and the value "true" is stored in the column "options" of
        the table mysql.tables;
    
      * The P_S tables are recreated only in case a value of the property PS_version
        stored in Data Dictionary is different from the version of [1;31mperf[mormance schema
        supported by server;
    
      * To recreate P_S tables, the "old" P_S tables are dropped and new ones
        are created;
    
      * To drop "old" P_S tables the metadata about all P_S tables stored in DD are
        fetched and those tables that contains the property with name
        "server_p_s_table" are dropped;
    
      * New P_S tables to be created are supplied by [1;31mperf[mormance schema storage
        engine;
    
      * Every P_S table is defined in terms of instance of the class Plugin_table
        and embedded into server code;
    
      * The class Plugin_table is used to produce SQL statements for creation of
        P_S tables;
    
      * The classes Plugin_table, Plugin_table_impl were modified to allow optional
        setting of tablespace name for a table being created;
    
      * DDL SQL-statements for creation of server P_S tables were removed from
        the file mysql_system_tables.sql.

[33mcommit cecf4ed4982ce58dd6d31d733d070225e81430b7[m
Author: Joao Gramacho <joao.gramacho@oracle.com>
Date:   Fri Mar 10 15:49:37 2017 +0000

    BUG#25694813 INSTRUMENTATION IS ALWAYS ENABLED FOR REPLICATION P_S
                 STATUS TABLES
    
    Problem
    -------
    
    New fields were added by WL#7374 to following PS replication tables:
    - replication_connection_status;
    - replication_applier_status_by_coordinator;
    - replication_applier_status_by_worker.
    
    The fields are related to GTID monitoring. They have information about
    when a GTID was committed on the original master and on the immediate
    master, when a GTID transaction started being processed by the I/O
    thread (connection_status), by the MTS coordinator and by the worker
    threads. There is also the timing information about the last processed
    transaction of the three replication thread types.
    
    For [1;31mperf[mormance reasons, if this new information is not needed, users
    should be able to disable the instrumentation that populates the new
    table fields. However, in the current implementation, this
    instrumentation is always enabled.
    
    Fix
    ---
    
    The replication monitoring introduced by WL#7374 now depends on
    [1;31mperf[mormance schema being enabled on the server.
    
    When [1;31mperf[mormance schema is not enabled in the server, the replication
    status tables will not collect local timing information. All
    START_*_TIMESTAMP and END_*_TIMESTAMP will be zero for the new queued,
    buffered and applied transactions.
    
    We replaced all extra Relay_log_info locking just for ensuring GTID
    information atomicity by a new atomic locking mechanism just for the
    GTID information.
    
    Note: this fix made also some [1;31mperf[mormance schema tables as "perpetual":
    - replication_applier_configuration;
    - replication_applier_status;
    - replication_applier_status_by_coordinator;
    - replication_applier_status_by_worker;
    - replication_connection_configuration;
    - replication_connection_status;
    
    Those tables should be able to present content even when [1;31mperf[mormance
    schema is disabled on server.

[33mcommit 4aeffd5b8591d7db2ce0383a661351bf3c2aa334[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Fri May 12 09:45:31 2017 +0200

    Bug#25858461: FAILURE TO DROP DATAFILE FROM TABLESPACES WITH MULTIPLE DATAFILES
    
    Problem: It was not possible to drop a tablespace file from a general
    tablespace which had more than one tablespace file.
    
    Root cause was that when a tablespace file is dropped, all tablespace
    files with a higher ordinal position will have their ordinal position
    decremented by one. Since the ordinal position is part of the PK of
    TABLESPACE_FILES, the store following the drop would result in an
    pk-update of the files which had their ordinal position decremented.
    
    But pk-updates are not supported by the store-implementation in
    dd::Weak_object_impl as it searches for the new key and only [1;31mperf[morms
    an update if this key is found. When the key itself is being updated
    searching for the new key is wrong and could cause the wrong tuple to
    be updated, or as in this case, a new tuple to be inserted without
    deleting the tuple with the old key. In this case such an insert was
    rejected because both the old and the new tuple had the same value for
    TABLESPACE_FILES.file_name, and there is a unique constraint on this
    column.
    
    Solution: When dropping a tablespace file, all the files must be
    dropped from TABLESPACE_FILES first, and then the remaining files (that
    were not supposed to be dropped) must be re-insterted with the correct
    PK and file_name, so that duplicates are avoided.

[33mcommit c9dc288fdaac234dcc47650462466c2bb7a8fd72[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Thu May 11 17:10:17 2017 +0100

    Bug #24829435   NDB : NDBTABLE::GETCOLUMN(CONST CHAR*) IS INEFFICIENT
    
    The getColumn functionality in the NdbApi dictionary is used to
    map from a column name to a column object.
    This can be used explicitly by users, or implicitly as part of
    passing a column name to an NdbApi function.
    The current implementation uses a linear search of an array of
    strings (column names), whose cost scales O(n) in the number of
    columns.  This has been seen to waste cpu in real-world NdbApi
    applications.
    It is possible for applications to lookup column objects or ids
    upfront, and then use them which gives O(1) access to a column
    object.
    However to improve the experience of users using column name strings
    at runtime, a column name hash is implemented.  This should give
    ~O(1) lookup [1;31mperf[mormance from name strings to column objects.
    
    It is still recommended to [1;31mperf[morm name->object/id lookups upfront,
    but the cost of doing them at runtime is reduced.
    
    A new test is added to testNdbApi which can be used to show
    that column lookup [1;31mperf[mormance is independent of the #columns.

[33mcommit 5bd13ce35f321cc27e391266cc4c9156e41c69c8[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu May 11 12:06:00 2017 +0200

    Bug #25997748: MIGRATE FROM HASH TO STD::UNORDERED_MAP
    
    Post-push fix for [1;31mperf[mschema.memory_aggregate_32bit
    
    Change-Id: I9f28e81f48c8f3106d5d22ff3e58bcf89cb52c56

[33mcommit 600bb29d9da71963a07ba259693e82c133734d3e[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Wed May 10 10:42:38 2017 +0200

    WL#8500 Adapt MySQL Cluster to 8.0
    
     - problem with DBUG_ASSERT detecting that same xid
       is used in subsequent queries when schema distribution
       participant run queries to [1;31mperf[morm the same DDL queries
       as on the schema dist client/coordinator.
     - fix by setting a new query_id before calling
         Ed_connection::execute_query()
     - remove old setting of query_id to 0

[33mcommit 51ba6abb994fa4f2fbd0703709e6202308cfbd17[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Wed Apr 26 10:46:12 2017 +0200

    WL#8500 Adapt MySQL Cluster to 8.0
    
     - fix ndb_rpl_circular_2ch_rep_status.result, variable names
       from [1;31mperf[mormance_schema are no longer in upper case

[33mcommit 749d0c169ec7fa57004d2354ddb2e2721311d71d[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Apr 20 10:53:47 2017 +0200

    WL#8500 Adapt MySQL Cluster to 8.0
    
     - fix result of ndb_index to accept new explain output
       from group by query, optimizer have changed
     - fix result of ndb_index_unique to accept new explain
       output, the "Using where" clause is gone.
     - fix result of ndb_index_unique to mixed case when querying
       [1;31mperf[mormance_schema.session_status

[33mcommit a8fcfa52a47e08685e48eea17c2916d9511a6476[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Apr 20 10:36:05 2017 +0200

    WL#9185 MySQL Cluster support for new DD
    
     - hardcode protection against dropping the [1;31mperf[mormance_schema database
       on participant mysqld(s). This has originally been protected by the
       check for "local tables" but until this has been reimplemented
       it can be hardcoded.

[33mcommit eecdf6a61b3af51f2f048059ffab3195fc83b352[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon Apr 10 13:52:48 2017 +0200

    WL#8500 Adapt MySQL Cluster to 8.0
    
     - fix ndb_join_pushdown_*.result
     - different explain outputs caused by WL#s implementing
       descending indexes, causing "Using filesort" to be removed for
       some queries and "asc" to be appended to explain output
     - different explain outputs caused by WL#s implementing
       optimizer cost model adjustments causing cost estimates to change
     - variable names from [1;31mperf[mormance_schema are no longer in upper case

[33mcommit a90f62b4681180c7c99f8265e57d9228db17f879[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon Apr 10 12:09:24 2017 +0200

    WL#8500 Adapt MySQL Cluster to 8.0
    
     - add testcase for checking output from [1;31mperf[mormance_schema status
       variables.
     - add testcase for checking output from [1;31mperf[mormance_schema variables.

[33mcommit 7e66c32964d596b6f5b12adddfec4ed9a62729e6[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue May 9 11:55:11 2017 +0200

    WL#9344: Logging services: error messages
    
    Filter out [1;31mperf[mormance-schema-error-size in --help tests.
    
    Change-Id: Ic90fe93ec5f9652c33ea373062406cd71d0556af

[33mcommit 6544eec0dc17266a44bdd27546bbe71310653b6a[m
Author: Allen Lai <zheng.lai@oracle.com>
Date:   Thu Apr 20 16:16:28 2017 +0800

    wl#9534 InnoDB_New_DD: Instantiate InnoDB in-memory metadata with  newDD objects
    wl#9530 InnoDB_New_DD: FTS index support for newDD
    
    Followup patch for fixing failures in UBSAN and no[1;31mperf[m build.
    
    Approved by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit ea4913b403db72f26565520f68686b385872e7d2[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Apr 19 15:56:31 2017 +0200

    Bug #25917702: USE C++11 THREAD-LOCAL STORAGE INSTEAD OF MY_THREAD_LOCAL
    
    Remove all use of my_thread_local_*, except for in NDB and [1;31mperf[mormance schema,
    which will have their own patches.
    
    Change-Id: I84a5ac687a951672107ca6f556303f4e4894db66

[33mcommit 2bf852b2ced78c2f40730f2aa0f88b794dfd8193[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Apr 12 12:26:14 2017 +0200

    Bug #25909342: USE C++11 THREAD-LOCAL STORAGE FOR CURRENT_THD
    
    Our current implementation of current_thd uses mysys' my_thread_* API, which
    maps onto pthreads (at least for Linux/UNIX). C++11 supports native TLS,
    which means we just need two simple MOV instructions to do a TLS fetch
    instead of a full shared library call; the interface is also much simpler.
    We probably don't have a lot of [1;31mperf[mormance gain, since we don't pick out
    current_thd all that often, but it's a nice cleanup to do nevertheless.
    
    There are still some uses of the my_thread_* API, particularly in PFS;
    cleaning this up is for a later patch.
    
    Change-Id: Ia16e0c1ccfa52af815882bcddd1eb3be80f77c61

[33mcommit e07873e062c2cfbbf31ce8e87be1aa5dc4dd6db0[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Mar 29 17:42:58 2017 +0200

    Bug#25800933 BROKEN CONCURRENCY CONTROL WHEN UPDATING 'M_NODE_TOTAL_SEND_BUFFER_SIZE'
    
    The node internal scheduler (mt.cpp) collect statistics about its own
    progress and its outstanding work. One such statistics being collected is
    the amount of outstanding 'send-bytes' which is being collected in
    send_buffer::m_node_total_send_buffer_size. This may later be
    used by the send thread scheduler, which use amount of outstanding sends
    as a metric to self tune its send [1;31mperf[mormance vs latency.
    
    In order to reduce lock contention on the internal send buffers, they
    have been split in two thr_send_buffer parts: the 'm_buffer' and
    'm_sending' buffers - each of them are protected by their own mutex.
    'm_node_total_send_buffer_size' was maintained to reflect the total size
    in these two send buffers.
    
    It turns out that we were not consistent regarding which mutex we
    used in updating 'm_node_total_send_buffer_size':
    
     - In link_thread_send_buffers() we locked send_buffer::m_buffer_lock
     - In bytes_sent() we locked send_buffer::m_send_lock
     - In reset_send_buffer() we locked both.
    
    Thus there is effectively no concurrency protection of
    'm_node_total_send_buffer_size'.
    
    This patch replace m_node_total_send_buffer_size with the two
    seperate 'm_buffered_size' and 'm_sending_size' which keeps
    track of respective size of the two buffers. These new counters
    are updated under protection of the two different mutexes
    protecting each of the send buffers.
    
    mt_get_send_buffer_bytes() will add these together to get the
    total size. This method is already documented as doing an
    unprotected 'get' of the buffer seize, which should be OK as
    we can do with a buffer size being slightly off. As the
    concurrency controll is now fixed , the updates will be
    correct, and the value will not 'drift' over time.

[33mcommit a5c09ab75a71230c50b7bf567f4d29559ed02441[m
Author: Maria Couceiro <maria.couceiro@oracle.com>
Date:   Thu Mar 23 15:54:10 2017 +0000

    BUG#25041396 --LOG-BIN MARKS MANY PERFORMANCE SCHEMA TABLES INVALID
    
    Problem:
    When a [1;31mperf[mormance_schema table was dropped or does not
    have the expected structure, and later the server was
    restarted with binlog enabled, it marked all [1;31mperf[mormance
    schema tables encountered after the first error as invalid.
    
    Analysis:
    The method decide_log_format would return with an error if
    there was any currently active error and the table was not
    to be replicated (as it is the case with P_S tables).
    This error was being generated when checking the P_S tables
    upon restart. However, it is sufficient to print the error
    to the log, because the check is not supposed to return
    any error.
    
    Fix:
    Since checking the [1;31mperf[mormance schema at server start is not
    supposed to generate an error, it is safe to clear the error
    in case there is one.

[33mcommit 66fbbd68a62882b6870a5f328ba48163e3af24d5[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Mon Mar 20 09:19:32 2017 +0100

    Bug#24296291: FIX -WUNUSED-PARAMETER WARNINGS
    
    Patch #20: Fix -Wunused-parameter warnings with various non-default
    build options such as without [1;31mperf[mormance schema, with openssl,
    with innodb memcached, with ndb and without profiling.

[33mcommit 2dcb152a2889c5e9e285e73e8a04dc6ecfe1350f[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Mar 22 09:54:18 2017 +0100

    Change [1;31mperf[mormance schema defaults.
    
    WL#9625 Enable PFS memory instrumentation by default
    
    WL#9628 Enable PFS transaction instrumentation by Default
    
    WL#9629 Enable PFS MDL instrumentation by Default

[33mcommit 68a9602202e2e5bce18ddcabf012b797f02b40cf[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Mar 21 13:30:30 2017 +0100

    WL#9721 Remove libmysqld embedded server in 8.0
    
    Test suite cleanup for [1;31mperf[mschema, sysschema.

[33mcommit c5f663e74f914505efa1c8c676149ad5e0a8ad8c[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Tue Mar 21 12:38:05 2017 +0100

    WL#8963: Support for partial update of JSON in the optimizer
    WL#9192: Add JSON_STORAGE_SIZE / JSON_STORAGE_FREE functions
    
    This commit introduces infrastructure in the optimizer to help the
    storage engines [1;31mperf[morm partial update of JSON values more
    efficiently. Partial update can be [1;31mperf[mormed for UPDATE statements
    such as
    
      UPDATE t SET json_col = JSON_SET(json_col, '$.path', 'abc')
    
    or
    
      UPDATE t SET json_col = JSON_REPLACE(json_col, '$.path', 'xyz')
    
    if the new value can be added to the JSON document by overwriting the
    old value at the modified path. This is possible if the new value does
    not require more storage space than the value that is replaced, or if
    there is sufficiently unused spaced around the replaced value to add
    the new value without increasing the size of the JSON document.
    
    When partial update is possible, a list of differences between the
    original document and the updated document is made available to the
    storage engine, so that it can write only the few bytes that actually
    changed, instead of rewriting the entire document, thereby reducing
    the amount of I/O.
    
    No storage engine takes advantage of this information for now.

[33mcommit 282d15d8bb03095ebb6ef286b8466bd0c8278bb5[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Fri Mar 10 12:55:20 2017 +0100

    WL#10344: Remove disabling of strict aliasing optimization (GCC)
    
    This patch re-enables the strict aliasing optimization when building
    the server with GCC or Clang. Sysbench tests have shown a 0-4%
    [1;31mperf[mormance increase - especially for single-threaded tests.
    
    -fno-strict-aliasing is still used when building NDB or
    InnoDB memcached.
    
    The patch also fixes a few recently introduced strict-aliasing
    build warnings in mysqlpump.

[33mcommit e39a7576f253ae486f4933e3f68d7cfdfc52ead2[m
Author: Andrei Elkin <andrei.elkin@oracle.com>
Date:   Fri Mar 10 14:13:39 2017 +0200

    WL9175 post-push: ASAN memory leak in Query_log_event.
    
    In WL-included builds ASAN run witnessed missed ~Query_log_event invocation.
    The destruct-or was not called due to the WL's changes in the error propagation
    that specifically affect LC MTS.
    The failure is exposed in particular by rpl_trigger as the following
    stack:
    
      #0 0x9ecd98 in __interceptor_malloc (/export/home/pb2/test/sb_2-22611026-1489061390.32/mysql-commercial-8.0.1-dmr-linux-x86_64-asan/bin/mysqld+0x9ecd98)
      #1 0x2b1a245 in my_raw_malloc(unsigned long, int) obj/mysys/../../mysqlcom-pro-8.0.1-dmr/mysys/my_malloc.cc:209:12
      #2 0x2b1a245 in my_malloc obj/mysys/../../mysqlcom-pro-8.0.1-dmr/mysys/my_malloc.cc:72
      #3 0x2940590 in Query_log_event::Query_log_event(char const*, unsigned int, binary_log::Format_description_event const*, binary_log::Log_event_type) obj/sql/../../mysqlcom-pro-8.0.1-dmr/sql/log_event.cc:4343:46
      #4 0x293d235 in Log_event::read_log_event(char const*, unsigned int, char const**, Format_description_log_event const*, bool) obj/sql/../../mysqlcom-pro-8.0.1-dmr/sql/log_event.cc:1686:17
      #5 0x293b96f in Log_event::read_log_event()
      #6 0x2a2a1c9 in next_event(Relay_log_info*)
    
    Previously before the WL
    Mts_submode_logical_clock::wait_for_workers_to_finish() had not
    returned any error even when Coordinator thread is killed.
    
    The WL patch needed to refine such behavior, but at doing so
    it also had to attend log_event.cc::schedule_next_event() to register
    an error to follow an existing pattern.
    While my_error() does not take place the killed Coordinator continued
    scheduling, ineffectively though - no Worker gets engaged (legal case
    of deferred scheduling), and without noticing its killed status up to
    a point when it resets the event pointer in
    apply_event_and_update_pos():
    
      *ptr_ev= NULL; // announcing the event is passed to w-worker
    
    The reset was intended for an assigned Worker to [1;31mperf[morm the event
    destruction or by Coordinator itself when the event is deferred.
    As neither is the current case the event gets unattended for its termination.
    
    In contrast in the pre-WL sources the killed Coordinator does find a Worker.
    However such Worker could be already down (errored out and exited), in
    which case apply_event_and_update_pos() reasonably returns an error and executes
    
      delete ev
    
    in exec_relay_log_event() error branch.
    
    **Fixed** with deploying my_error() call in log_event.cc::schedule_next_event()
    error branch which fits to the existing pattern.
    THD::is_error() has been always checked by Coordinator before any attempt to
    reset *ptr_ev= NULL. In the errored case Coordinator does not reset and
    destroys the event itself in the exec_relay_log_event() error branch pretty similarly to
    how the pre-WL sources do.
    
    Tested against rpl_trigger and rpl suites to pass.
    
    Approved on rb#15667.

[33mcommit e3e1cd11d46dca1e0d528584ed9b314a1d96a48b[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Fri Mar 3 23:15:46 2017 +0800

    Wl#7361 MSR: per-channel replication filters
    
    There are per-channel and global replication filters. Each channel uses
    *only* its own per-channel replication filters to filter the event
    stream. It never uses global replication filters to filter the event
    stream. (A new channel would copy global replication filters to its
    per-channel replication filters if there are no per-channel replication
    filters and there are global replication filters on the filter type
    when it is being configured.)
    
    The per-channel replication filters and global replication filters can
    be configured in two ways:
    A) startup options: --replicate-*
    B) SQL commands: CHANGE REPLICATION FILTER
    
    Additionally, behavior for the following statements needs to be specified:
    C) RESET SLAVE [ALL] [FOR CHANNEL]
    D) SHOW SLAVE STATUS [FOR CHANNEL]
    
    Query, troubleshoot, monitor replication filters and do statistics:
    E) CREATE A NEW [1;31mperf[mormance_schema.replication_applier_filters
    
    Show the global replication filters:
    F) CREATE A NEW [1;31mperf[mormance_schema.replication_applier_global_filters
    
    A) Startup options: --replicate-*
    =================================
    
    The current startup options are extended by allowing to specify channel_name in
    filter variable to configure per-channel replication filters as follows.
      --replicate-do-db=<channel_name>:<database_id>
      --replicate-ignore-db=<channel_name>:<database_id>
      --replicate-do-table=<channel_name>:<table_id>
      --replicate-ignore-table=<channel_name>:<table_id>
      --replicate-rewrite-db=<channel_name>:<db1->db2>
      --replicate-wild-do-table=<channel_name>:<table regexid>
      --replicate-wild-ignore-table=<channel_name>:<table regexid>
    
    ---- Syntax ----
    
    Each command line parameter optionally takes a channel_name followed by a colon,
    further followed by the filter specification. Note that the first colon is
    interpreted as a separator, others are literal colons.
    
    ---- Semantics ----
    
    Without specifying channel_name in filter variable, the startup options
    shall act on the default channel. See below.
    
      --replicate-do-db=:<database_id>
      --replicate-ignore-db=:<database_id>
      --replicate-do-table=:<table_id>
      --replicate-ignore-table=:<table_id>
      --replicate-rewrite-db=:<from_db>-><to_db>
      --replicate-wild-do-table=:<table regex>
      --replicate-wild-ignore-table=:<table regex>
    
    Without specifying channel_name and a followed 'colon' in filter variable, the
    startup options shall configure the global replication filters. See below.
      --replicate-do-db=<database_id>
      --replicate-ignore-db=<database_id>
      --replicate-do-table=<table_id>
      --replicate-ignore-table=<table_id>
      --replicate-rewrite-db=<from_db>-><to_db>
      --replicate-wild-do-table=<table regex>
      --replicate-wild-ignore-table=<table regex>
    
    If the user specifies a per-channel replication filter through a command-line
    option (or in a configuration file) for a slave replication channel which
    does not exist as of now (i.e not present in slave info tables yet), then
    the per-channel replication filter is discarded with the following warning:
      "There are per-channel replication filter(s) configured for channel '%.192s'
    which does not exist. The filter(s) have been discarded."
    
    If the user specifies a per-channel replication filter through a command-line
    option (or in a configuration file) for group replication channels
    'group_replication_recovery' and 'group_replication_applier' which is
    disallowed, then the per-channel replication filter is discarded with
    the following warning:
      "There are per-channel replication filter(s) configured for group replication
    channel '%.192s' which is disallowed. The filter(s) have been discarded."
    
    How global and per-channel replication filters work together?
    - Any global replication filter option will add the filter to global
      replication filters on the filter type, not add the filter to every
      channel on the filter type.
    - Any per-channel replication filter option will add the filter to
      per-channel replication filters of the specified channel on the
      filter type.
    - Every slave replication channel will copy global replication filters
      to its per-channel replication filters if there are no per-channel
      replication filters and there are global replication filters on the
      filter type when it is being configured.
    
    Example: Suppose channels '' and 'ch1' exist before the server starts,
      the command line options --replicate-do-db=db1
      --replicate-do-db=ch1:db2 --replicate-do-db=db3
      --replicate-ignore-db=db4 --replicate-ignore-db=:db5
      would result in:
        global replication filters: do_db=db1,db3, ignore_db=db4
        default channel: do_db=db1,db3 ignore_db=db5
        ch1: do_db=db2 ignore_db=db4
    
    Note: GROUP REPLICATION channels should not be configurable using
      --replicate* nor CHANGE REPLICATION FILTER, and should not inherit
      from global filters.
    
    BTW: if user specifies multiple replicate-rewrite-db=FROM->TO options
    having the same FROM database, all are added together (put into the
    rewrite_do list) and the first one takes affect. The global replication
    filters and per-channel filters have the same behavior in the worklog.
    So there is no change on this, since a channel uses either global or
    per-channel rewrite filters on a filter type.
    
    B) SQL commands: CHANGE REPLICATION FILTER
    ==========================================
    
    Dynamic replication filters are currently settable using the
    CHANGE REPLICATION FILTER statement. We extend this command to
    introduce dynamic replication filters per channel, by allowing
    a FOR CHANNEL <channel_name> clause as follows.
    
    ---- Syntax ----
    
    CHANGE REPLICATION FILTER filter [, filter...] [FOR CHANNEL <channel_name>]
    
    filter:
        REPLICATE_DO_DB = (db_list)
      | REPLICATE_IGNORE_DB = (db_list)
      | REPLICATE_DO_TABLE = (tbl_list)
      | REPLICATE_IGNORE_TABLE = (tbl_list)
      | REPLICATE_WILD_DO_TABLE = (wild_tbl_list)
      | REPLICATE_WILD_IGNORE_TABLE = (wild_tbl_list)
      | REPLICATE_REWRITE_DB = (db_pair_list)
    
    ---- Semantics ----
    
    1) If an explicit FOR CHANNEL clause is provided, the statement acts on that
       configured slave replication channel removing any existing replication
       filter if it has the same filter type as one of specified replication
       filters, and replacing them with the specified ones. Filter types that
       were not explicitly listed in the statement are not modified. The statement
       is disallowed with an error 'ER_SLAVE_CONFIGURATION' on slave replication
       channel if it is not configured. The statement is disallowed with an error
       'ER_SLAVE_CHANNEL_OPERATION_NOT_ALLOWED' on group replication channels.
    
    2) CHANGE REPLICATION FILTER filter [, filter...] with no FOR CHANNEL clause
       does the following, both for every configured slave replication channel's
       per-channel filter and for the global replication filters: For every filter
       type, if the filter type is listed in the statement, then any existing
       filter rules of that type are replaced by the filter rules specified in
       the statement, otherwise the old value of the type is retained. The
       statement does not act on group replication channels, because replication
       filters on group replication channels are disallowed. For example,
    
    C. SQL COMMAND: RESET SLAVE [ALL] [FOR CHANNEL]
    ===============================================
    
    1) "RESET SLAVE FOR CHANNEL '<channel_name>'" does not remove the replication
       channel specified by 'FOR CHANNEL' clause, so it shall retain replication
       filters of the channel. It throws an error 'ER_SLAVE_CHANNEL_DOES_NOT_EXIST'
       if the channel does not exist. So this statement is not changed by the worklog.
    
    2) "RESET SLAVE" does not remove any replication channel, so it shall retain
       all per-channel replication filters and all global replication filters.
       So this statement is not changed by the worklog.
    
    3) "'RESET SLAVE ALL FOR CHANNEL '<channel_name>'" removes the replication
       channel specified by 'FOR CHANNEL' clause, so it shall remove all
       per-channel replication filters of the channel if the channel exists.
       Then SELECT * FROM [1;31mperf[mormance_schema.replication_applier_filters
       and SHOW SLAVE STATUS proves there's no channel anymore and therefore
       its replication filters are gone too. It still throws an error
       'ER_SLAVE_CHANNEL_DOES_NOT_EXIST' if the channel does not exist as before.
    
    4) "RESET SLAVE ALL" with no FOR CHANNEL clause removes all replication
       channels, so it shall remove all per-channel replication filters but
       does not touch all global replication filters. When the new empty
       channel is being configured, it therefore uses the global replication
       filters (copies all global replication filters to its own per-channel
       replication filters). A user who wants to remove all global and
       per-channel filters can use the statement: CHANGE REPLICATION FILTER
       Replicate_Do_DB = (), Replicate_Ignore_DB = (),
       Replicate_Do_Table = (), Replicate_Ignore_Table = (),
       Replicate_Wild_Do_Table = (), Replicate_Wild_Ignore_Table = (),
       Replicate_Rewrite_DB = ().
    
    D. SQL COMMAND: SHOW SLAVE STATUS [FOR CHANNEL <channel_name>]
    ==============================================================
    
    SHOW SLAVE STATUS FOR CHANNEL <channel_name> shall show per-channel
    replication filters for the specified channel, or throw an error
    'ER_SLAVE_CHANNEL_DOES_NOT_EXIST' if the channel does not exist.
    SHOW SLAVE STATUS with no FOR CHANNEL clause shall show the
    per-channel replication filters on every channel.
    
    E. CREATE A NEW [1;31mperf[mormance_schema.replication_applier_filters
    ==============================================================
    
    We shall introduce a new dedicated P_S table to display per-channel
    replication filters for usability. So create and maintain the new
    P_S table with the following columns:
      1) Channel_name: the name of the channel;
      2) Filter_name: REPLICATE_DO_DB, REPLICATE_IGNORE_DB,
                      REPLICATE_DO_TABLE, REPLICATE_IGNORE_TABLE,
                      REPLICATE_WILD_DO_TABLE, REPLICATE_WILD_IGNORE_TABLE,
                      REPLICATE_REWRITE_DB;
      3) Filter_rule: The values that user has configured with startup
                      options: --replicate-* or through CHANGE REPLICATION
                      FILTER command (This also includes empty set when user
                      unsets the rules).
      4) Configured_by: ENUM(STARTUP_OPTIONS, CHANGE_REPLICATION_FILTER,
                        STARTUP_OPTIONS_FOR_CHANNEL,
                        CHANGE_REPLICATION_FILTER_FOR_CHANNEL); (These
                        enumeration constants are the most self-descriptive
                        set of identifiers, and supporting all the use
                        cases: U1. Reflect the configured commands;
                        U2. Determine if the filter has been persisted;
                        U3. Debugging by a confused user, or learn the
                        logic of default filters by playing with
                        different ways to set them.)
      5) Active_since: Timestamp of when the configuration took place;
                       (To a new channel copying the global replication filters as
                        its own per-channel filters, set 'active_since'
                        to channel creation time.)
      6) Counter: the hit counter of the filter since last configuration;
    
      Note: (4) and (5) are important to troubleshooting. (6) is more about
      statistics (and monitoring).
    
    F) CREATE A NEW [1;31mperf[mormance_schema.replication_applier_global_filters
    ======================================================================
    
    We shall introduce a new dedicated P_S table to display all global
    replication filters for usability. So create and maintain the new
    P_S table with the following columns:
      1) Filter_name: REPLICATE_DO_DB, REPLICATE_IGNORE_DB,
                      REPLICATE_DO_TABLE, REPLICATE_IGNORE_TABLE,
                      REPLICATE_WILD_DO_TABLE, REPLICATE_WILD_IGNORE_TABLE,
                      REPLICATE_REWRITE_DB;
      2) Filter_rule: The values that user has configured with startup
                      options: --replicate-* or through CHANGE REPLICATION
                      FILTER command (This also includes empty set when user
                      unsets the rules).
      3) Configured_by: ENUM(STARTUP_OPTIONS, CHANGE_REPLICATION_FILTER);
      4) Active_since: Timestamp of when the configuration took place;

[33mcommit 201b2b20d110bc35ddf699754571cb0c064a3f72[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Fri Mar 3 12:40:55 2017 +1100

    Squashed commit of the following:
    
    WL#9499 - InnoDB: Replace MLOG_FILE_NAME with MLOG_FILE_OPEN
    
    Fix the [1;31mperf[mormance issues introduced by WL#7142 and its followup WL#7806.
    
    1. Revert WL#7142 and WL#7806 changes, keep some of the tests to test
       the behaviour that was introduced by the two WLs
    2. Change the tests that rely on the above two WLs behaviour
    3. Use std::unordered_map instead of the homebrew hash table for the recovery
       code and space ID to name mapping
    4. Split the redo log hash table key from <space, page> -> apply records to
       <space> -> apply records
    5. Addition of two new system files (tablespaces.open.1 and tablespaces.open.2)
    
       - Rename MLOG_FILE_NAME to MLOG_FILE_OPEN
       - Remove the two pass recovery code, make it a single pass
       - Track file open, close and rename
       - Write and fsync the tracking state to disk on checkpoint and rename.
       Uses the files in #5 in a round robin fashion
    
    Introduce --innodb-scan-directories="path1;...pathN". Scan the paths for
    .ibd files to open during recovery. This option can be used if the files in #5
    above are corrupt or missing. You should not use this if you move files around.
    While they can be recovered the data dictionary will not be updated and it
    will cause issues during runtimg.
    
    rb#13686 Approved by Satya and Shaohua
    
    commit af3dc1301a768c01b971d14ad07549d6ef470fe6
    Merge: ac37b926e6a 4d81939d63a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Mar 3 11:16:10 2017 +1100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit ac37b926e6ad85b6c4e3d7880b905d082f1674be
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 23:12:24 2017 +1100
    
        WL#9499 - Fix test
    
    commit 2b05df7ffa592da9b19cec7ba31c04795a1cdfc0
    Merge: 3c79f3aee51 71b3bbff153
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 20:34:10 2017 +1100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 3c79f3aee51858b1859f4e8711883a85867c417a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 18:16:35 2017 +1100
    
        WL#9499 - Add an mtr tst
    
    commit 2c7496246c0e95e25c62ceb6fe5c1875f693ffac
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 17:34:50 2017 +1100
    
        WL#9499 Fix bugs
    
        1. Fix a memory leak, call mem_heap_free() instead of mem_heap_empty()
        2. Use a reference instead of copy by value during dblwr traversing
        3. Use absolute path names for tablespace.open.* files
    
    commit fbf87161f3c93979e5abe424fbe0678fdc32159e
    Merge: 517cf3a7bf0 c2b504664ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:39:32 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 517cf3a7bf0490c3168fed020e3096ec500e0a85
    Merge: 4786f93ad8a 5e974fd0ea4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:24:25 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Additional change is to call recv_recovery_from_checkpoint_finish() on abort.
        Instead of recv_sys_free().
    
    commit 4786f93ad8a25506a2a1f6e9d1207256a34b3665
    Merge: 5dc35e05b5f 275245cce32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:43:27 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 5dc35e05b5f2da95c36e191350e9c7087be72194
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:42:40 2017 +0100
    
        WL#9499 Free recv resources on abort
    
    commit bed693070395923ededba736f1c7102b8eb21e95
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 18:34:50 2017 +0100
    
        WL#9499 - Test cannot be run with Valgrind
    
    commit c5d423228ddf58b17866ff8be289dba4a19205d2
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:30:39 2017 +0100
    
        WL#9499 - Remove const
    
    commit ac42498506b4dffb22e74282d0ce037fe3acf977
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:00:30 2017 +0100
    
        WL#9499 - Clean up code
    
    commit bc48077cab9c3ccb1b2797c365fe0940c269a785
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 16:01:09 2017 +0100
    
        WL#9499 - Revert unrelated change
    
    commit 8b2bb0f6d6254b3cfde168d41356400009db12f4
    Merge: eb9b294ba78 153a79ff35d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:43:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit eb9b294ba786800f9e397cd87f01c4f4976edddb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:29:56 2017 +0100
    
        WL#9499 - Remove debug message
    
    commit abae66ad591854ee67a5013f3209be2f82e4d9bf
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 17:04:10 2017 +0100
    
        WL#9499 - Test only works in debug mode.
    
    commit 71ebea70391ef295bed49ee06a8b872f15ecfe97
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:18:08 2017 +0100
    
        WL#9499 - Update to mtr test from Matthias
    
    commit f108a5b92fc476c70c49e4937496b32d9d5d031f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:13:04 2017 +0100
    
        WL#9499 - Increment redo log version number
    
    commit 4439c83a4d3edd6e511706ccf9936770ed29e593
    Merge: fa459186b90 05923bef41d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 09:54:18 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit fa459186b90d7a5ddcba7e3c6c7a9871d0dce793
    Merge: 14ac4f81d84 b401f17e70d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 20:02:40 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 14ac4f81d84bec23a7be210504ca0be93619bf11
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 16:44:57 2017 +0100
    
        WL#9499 - Update from Matthias
    
    commit ed3191a9fc951151fd7d758a527e7ab81530b3f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:16:11 2017 +0100
    
        WL#9499 - Revert change pushed by nmistake
    
    commit 8c0edb998867bf557f6c86410552d6d123892000
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:11:21 2017 +0100
    
        WL#9499 - Don't redo log MLOG_FILE_OPEN until startup is complete
    
    commit 3b503ea1d3f89c0f7e3677d3b56f249c7ebff506
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:37:04 2017 +0100
    
        WL#9499 - Add tests
    
    commit 47af7bd6eec10eac55633d7c4cf54afe607f3649
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:00:30 2017 +0100
    
        WL#9499 - Fix compile problem
    
    commit a8b9a8c6ccb15e2be5ce5db5fa0bce24b86d2c87
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:51:05 2017 +0100
    
        WL#9499 Remove dead code
    
    commit b1dba474486ad10b61029b2ef4e6a91ea67dcea8
    Merge: 3cf9e9eb3e8 a4271026201
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:49:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 3cf9e9eb3e86e4c8f4d44cb79d3f7c456ea7d671
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 18 07:53:43 2017 +0530
    
        WL#9499 - Remove suggestion to use force recovery
    
        --innodb-scan-directories is a safer option for the user. Force recovery should
        be the absolute last resort.
    
    commit 4104c4bfd606270650aac95a9a724e106fe835c5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 09:00:47 2017 +0530
    
        WL#9499 - Fix error message
    
        User can try --innodb-scan-directories="..." if the tablespaces.open.* files
        are corrupt or unreadable.
    
    commit 19ab12e54923b070a0b4ffc76b9fe97ac54ad3cc
    Merge: 50b3a95e446 f0f51c410bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 05:22:57 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Replace readdir_r() with readdir(), compiler complains that readdir_r() is
        deprecated and recommends replacing it with readdir().
    
    commit 50b3a95e446b91853fc35716b63bdc173221d01f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:55:33 2017 +0530
    
        WL#9499 - Fix test
    
    commit 45d202ae0fa35aa3aced55cc1933aeefa33837de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:32:56 2017 +0530
    
        WL#9499 - Remove redundant test
    
    commit 48fe691b97735e5144e9d439a0adbf721b2dc554
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:18:11 2017 +0530
    
        WL#9499 - Add DEBUG sync points
    
    commit d986f4e04a9eb6c2c76d61cd4afe9541d77b34bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:03:50 2017 +0530
    
        WL#9499 - Remove PB2 control file
    
    commit 5af7dca9c305bd366ad2b5c3de26a870e913af4a
    Merge: 74022f50a5f 23a0e71aa3d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 15 09:05:05 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 74022f50a5ff7cb2801c0712601f8a467b409a28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 14 10:31:00 2017 +0530
    
        WL#9499 - Fix test
    
    commit f6188175ee62040ac6a844a5c54787839dff6155
    Merge: 24c867aab14 19ca7c6a5d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 13 12:37:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 24c867aab14556188503aac495f60d89ba3d26ec
    Merge: cb64b8c7f9f a4de6ab549e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 4 06:41:23 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cb64b8c7f9fa9ca05033a9d6f6193cf141746310
    Merge: 17c6c41da0a 88dbc4f4511
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:48:12 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 17c6c41da0afe3fc78843b75fa02578dab29a0ca
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:46:34 2017 +0530
    
        WL#9499 - Add a test for scan directories.
    
        The use case is where the location of the files is not changed but the
        tablespaces.open.* files are missing.
    
    commit 79cc52f1bd82dc65932eacbc9aa14a47e4196572
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 18:01:50 2017 +0530
    
        WL#9499 - If open fails space will be null.
    
    commit 22ea5f31ecc1fa0db8abd57d4a46578e5f891c9a
    Merge: f5b69930f95 853a52cf5a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 12:14:41 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f5b69930f95192ddfdb3ca170024a5c7e3416076
    Merge: 40a4c32f2c4 b18872ed4a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 2 13:54:24 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 40a4c32f2c42b584539a14cbc1ba0d4f0fe7d3c9
    Merge: b1d1923d37c d071c0e7a0b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 1 13:48:33 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit b1d1923d37c3d23a9f701a61b458b7e4cbd3c90c
    Merge: 2fc6c51edab 4ae71705a01
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 31 10:44:59 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2fc6c51edabc3de4537eceb0b82cd62063ada3a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 16:36:46 2017 +0530
    
        WL#9499 - Empty the tablespace.open.* files on normal shutdown.
    
    commit 738acb7d554f97455c8dba512282c7c2e6ba9f3a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:47:21 2017 +0530
    
        WL#9499 - Fix formatting
    
    commit 28f8579a6f729af354e0c50098d16fbfa17cc253
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:25:30 2017 +0530
    
        WL#9499 - Bug fix
    
        The DELETED state was set on a copy of the data structure
    
    commit dd5bf8ea81b7023fa1980c01d89219a690160b04
    Merge: 7eeab0a994d 9c7808e1054
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 21:14:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7eeab0a994db4cf0c2e080f27ff916c778ec65f8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:50:59 2017 +0530
    
        WL#9499 - Add tests.
    
    commit ddfaf047f43587ee807599b0b80b6d01a3579e8c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:48:06 2017 +0530
    
        WL#9499 - Create tablespace bug fix
    
        If there is a checkpoint after the create tablespace is logged and the
        server crashes after writing the page initialization to the redo log. Then
        we neither have the mapping in the redo log nor in the tablespace.open.*
        files. We must update the tablespace mapping before writing the CREATE
        redo log entry so that the state is written out to disk on checkpoint.
    
    commit 29546d3ebea2991e5b86b33edddb551c924bf1db
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 17:55:28 2017 +0530
    
        WL#9499 - Remove dead code from WL#7142
    
    commit eced7a3e4437ee4bb24a12290f561437ddb15611
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 14:51:09 2017 +0530
    
        WL#9499 - Use the tablespace.open.* files in a round robin fashion.
    
    commit d8eff788eea1ad5e6c7786b9d64963524f2b2c81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:56:12 2017 +0530
    
        WL#9499 - Fix duplicate entry
    
    commit 1d04e0cf0308c35ee7498e6919eab9a11c699d52
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:55:30 2017 +0530
    
        WL#9499 - Revert last push
    
    commit 8361d3c39366d6435a895d5b64dd23615d26fc28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Jan 26 09:05:52 2017 +0530
    
        WL#9499 - Write to the tablespace.open.* files in a round robin manner.
    
    commit 3eaba629ee5b5c26a5f4e80852fee2d446f3013f
    Merge: 6642c43d735 bdc49070128
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 25 14:03:15 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6642c43d7353063a455972ab2cbc21220c16be43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 08:34:35 2017 +0530
    
        WL#9499 - Rename fil_ibd_load to fil_ibd_open_for_recovery.
    
    commit fdd1897c79b29c9e0a69c1f81d94927da06d9424
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:28:49 2017 +0530
    
        WL#9499 - Enforce const semantics on Windows for Folder::exists().
    
    commit 9394f4653e10cc5d4ab9b7b0a0b9331fd2666f49
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:08:26 2017 +0530
    
        WL#9499 - Include <array>
    
    commit c1903d28800ae0f7af69552aa669622d552346b4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Jan 21 07:49:28 2017 +0530
    
        WL#9499 - Improve scan directory handling
    
        1. Convert relative paths to absolute paths
        2. Filter out duplicates
        3. Check directories at filtering stage
    
    commit dfea237f4bef914de4067153cbf382240112c4f4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 11:11:05 2017 +0530
    
        WL#9499 - Code clean up
    
    commit c4d51bfdf1c786b1c584c0af1bde080a4f37cc5b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 07:37:06 2017 +0530
    
        WL#9499 - Update the open/rename LSN when a file is opened or renamed.
    
        Minor code cleanup.
        Add diagnostic code for debugging.
    
    commit 5e1d159b571fe6dbfe13c627a245155b82c4bbfa
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 18 10:59:54 2017 +0530
    
        WL#9499 - Filter out '*' from innodb-scan-directories
    
    commit 361f2944f1940f11dfb16dec3589d68335f5e2d8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 21:01:06 2017 +0530
    
        WL#9499 - Code cleanup
    
    commit 288d70b356721887423ca3d2d72b42da331216cd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 13:08:08 2017 +0530
    
        WL#9499 - Sync open file map to disk before checkpoint.
    
    commit 3c602d1b4089cd262200650f4b33986fc9e26531
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:18:46 2017 +0530
    
        WL#9499 - Print expected bytes instead of generic message.
    
    commit f52e0985b8cbef3891385179d35dc8c7f567146a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:07:47 2017 +0530
    
        WL#9499 - Print file size instead of generic message.
    
    commit b27b1b4b4b70e286e2c669f997b0a669f6d6034c
    Merge: bbdd1c46f1e c101ec9b557
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 16 13:19:42 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit bbdd1c46f1ef08d956ea249e1f6f4bc93d3464f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Dec 10 14:41:12 2016 +0530
    
        WL#9499 - Handle the case where the rename has already been done on recovery.
    
    commit 141bdb02b1a402e786db5d8b165b781a5d7370a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 11:59:29 2016 +0530
    
        WL#9499 - Instrumentation for debugging
    
    commit 34815bb24a1c296d9739e7602dc6ccd53c58c44c
    Merge: 41ca3732a6f 13a46b4c5ea
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 09:44:03 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 41ca3732a6ffd8dfa16762a05df6b5c6b4b550c1
    Merge: 7137edb2d2c aba34f1205d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 11:10:08 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7137edb2d2ca60cdec44600ddf3f5cbde424e7a4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 05:56:06 2016 +0530
    
        WL#9499 - Remove unused code. Move id to name mapping sync before log flush.
    
    commit 2a50067e2da2f7819781de6550e55ca14995c7ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:57:41 2016 +0530
    
        WL#9499 - Initialize the PFS file handle
    
    commit d478d3492cdb40ec02fda9c043bf29b87bae11ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:05:52 2016 +0530
    
        WL#9499 - Fix whitespace
    
    commit 061af748a5e2fde6c1577ccdabfc8a89a9f753de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:02:25 2016 +0530
    
        WL#9499 - Set must flush on file close/delete.
    
    commit ad76e2b9c7ff757f60c66821e86696d5ab757b18
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 11:43:00 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5a95946d4567dc13cf5a12d6bcdb28b19a02b5bc
    Merge: 1a0f373eb7f da23d6b8e44
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 09:27:45 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1a0f373eb7f03dc22264f91f3f6ed1fd13825de7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 13:01:41 2016 +0530
    
        WL#9499 - Readd test result file back
    
    commit 00afde093183cf850f735940245af111dce82b72
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 12:59:49 2016 +0530
    
        WL#9499 - Don't purge the files based on LWM. It won't work.
    
        We need to also ensure that there aren't any pages in the buffer pool that
        belong to a tablespace that is closed. Redo log records can be written for
        such pages.
    
    commit 3199fe255103daa42f0332b7ff9d565eefff7429
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:41:39 2016 +0530
    
        WL#9499 - Fix typo
    
    commit 351cb6c42709405a79021276f310d7b996aadd1b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:32:02 2016 +0530
    
        WL#9499 - Remove unused function
    
    commit 61cc7f6b06c5280d58217b76d7627013ddcd8338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:22:31 2016 +0530
    
        WL#9499 - Reduce the compression level.
    
    commit 48142e360ff5cfb53d5e416f3d6b92e956237923
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:21:51 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 4de4f8b31ebdff31a2f7a97a1ad211770d20cdd6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 14:07:07 2016 +0530
    
        WL#9499 - Revert ef30f0754ab22e614ac22712c348ec5f53e0f09c
    
    commit c2f77f44c43c209fad86bba568aa521a2dcbf718
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 12:20:37 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 5fccb51769a13cb9a1fc0f29a832d3b0085ad52a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:30:18 2016 +0530
    
        WL#9499 - Print a message when checkpoint is disabled.
    
    commit ef30f0754ab22e614ac22712c348ec5f53e0f09c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:17:27 2016 +0530
    
        WL#9499 - Print progress in 10% units.
    
    commit bc0ded332624fa2c8a08ebfc955a03f1a24e069c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 08:13:54 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 68ce0208cc073452f5f791faf304971dbac7194a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:38:03 2016 +0530
    
        WL#9499 - Scan directories after the mutex code is initialized.
    
    commit 21e07c8fd6b8eddf158fb79980443f6c9f6d238e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:12:23 2016 +0530
    
        WL#9499 - Introduce --innodb-checkpoint-disabled (debug)
    
        Disable checkpointing if the variable is set. This is to force recovery if the
        server is killed during a test.
    
    commit 7033c9bb5ff7641764f70823a73d747b497a0eed
    Merge: 11a6e582417 c6af7f512b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 04:00:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 11a6e582417d45a80a7f19233c2d2191a17936eb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 03:59:05 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 0a38252e65d607b59b1e9f64d0c8003cdecfecfd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 25 05:56:42 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bcf650cc92b8636f3768dcc3deb33b90b2942134
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 08:46:07 2016 +0530
    
        WL#9499 - Change the open files number back to 2.
    
    commit 99960af2825529fb45d021a34ba6c072e8caa0dc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 07:13:58 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bdb91bc0ba03e01661c50c7175d3fd123d2bcd69
    Merge: 61f3e4a5663 a545bdd6e31
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:04:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 61f3e4a5663c375cd44ee766b263281ff7f0601b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:00:20 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 072ab837d0acb4d2ed817110598554acc44ec344
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 12:06:53 2016 +0530
    
        WL#9499 - Set the IMPORT page LSN to the flushed to disk LSN
    
    commit 7f18661432f3645eb9ce76680c62508ced115fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 11:28:47 2016 +0530
    
        WL#9499 - Force a checkpoint before the crash
    
    commit 83671e9c37fa61adfa5546cabe1463a91ff02241
    Merge: cc26d5ae16e d1f811eb6e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 10:52:16 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cc26d5ae16e8d723a2519f38bfbc084c13a766c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 18:40:51 2016 +0530
    
        WL#9499 - Fix latch ordering issue
    
        Cannot hold the log sys mutex when updating the checkpoint LSN for the open
        files in fil0fil.cc.
    
    commit 4474509addfbdf91b9f0ad890a971299c594e738
    Merge: 396755e195c 0856b10cde5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 08:00:05 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 396755e195c1c8d3b2485a58175dcf56ca2cbf3f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:58:05 2016 +0530
    
        WL#9499 - Remove newline added earlier
    
    commit ab5e60ba491e52f1529c22551a936d771b8b5ef9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:57:21 2016 +0530
    
        WL#9499 - Revert a change that was added by mistake.
    
    commit 38688417713e5ef8cbb65032fa0a547ab0c25c15
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 20:44:50 2016 +0530
    
        WL#9499 - Bug fix, using an invalidated iterator.
    
    commit 4082d44f6dc4a5605562e37ccad9ac4db69344c6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 11:30:49 2016 +0530
    
        WL#9499 - Fix doxygen comment
    
    commit d5ca99e14c010a5349aea6c8cc39493b2073b9c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 15:30:12 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a25f3af10ea2893c634dc961d6f2af05efa103ec
    Merge: c8c2a7eba4c aa039b73223
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:52:51 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit c8c2a7eba4cac29ff431588daf2d6def0c0ee5a6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:39:32 2016 +0530
    
        WL#9499 - Fix problem with open files acrosss checkpoints.
    
        The problem is that we write the open file state before writing the checkpoint.
        Before this change the closed files were purged from the open state map and
        the state written to disk. The problem is that the state and mapping of a file
        opened before the last checkpoint but closed just before we write the state
        will not be in the mapping on disk. One solution is to check older files and
        retrieve the mapping from there. The solution chosen is to avoid purging
        files based on open LSN. If the file was opened before the last checkpoint
        and closed within the current checkpoint we note the state as CLOSED but
        write the mapping to disk. It will be purged at the next checkpoint, if it is
        not opened again in the meantime.
    
        Previously an attempt was made to open all files straight after reading the
        mapping from disk. With this change only the state is loaded into memory the
        files are opened on demand. Added a check to verify that the tablespace ID
        from the first page matches the expected value.
    
        Fixed tests to use this new tablespace ID verification.
    
    commit 5dc929e54b1c259f0f8104739ae1f88e9b860f73
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 12:24:40 2016 +0530
    
        WL#9499 - Remove unused code
    
    commit 528b95d70dcc05a69a98ee2a76fdfb8dae1e82fe
    Merge: d9861c40964 75f05cba753
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:14:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d9861c40964ad8fd45ee2cbbd9d94946110e8a9a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 3007ea5af68f40b85bc93098d8385ac96bcbd660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 9592996d2f17c9005262faa75dc1ade9dedbd511
    Merge: da512d5591b ac925fc91f6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Oct 19 10:34:48 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit da512d5591b3379b793d6155089e90791fe94c61
    Merge: f42e2ddd7d5 e635dfe28c0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 30 05:20:10 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f42e2ddd7d50aacae679babe71643af379b5c492
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 15:05:28 2016 +0530
    
        WL#9499 - Fix assertion, the values can be ORred.
    
    commit 94cd08960bc3801acefd4b4ff4ddb4a3e7d7e81a
    Merge: 32a68f91330 59af373321b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 11:05:21 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 32a68f9133011871bfdaba3c742f6239e0a53061
    Merge: 7857f38ebce 15555ae2165
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 21 11:23:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7857f38ebce747135e055bc8a232b649f1aad351
    Merge: 427491f63f1 b43bf88cf80
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 19 11:43:17 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 427491f63f107247c36796e66f6224d20968f104
    Merge: e7fa4c53dcf 23343687722
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 14 22:40:47 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e7fa4c53dcf01ea0e101bd8aa817698492995034
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 19:22:00 2016 +0530
    
        WL#9499 - max_lsn should work with any number of tablespace open files.
    
    commit 09775960da43d36ca64504c1298b9adff3056575
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 17:47:29 2016 +0530
    
        WL#9499 - Fix Names hash bug.
    
    commit 8430c5b34d23cb1774597707fe583dfac93fb3a8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 09:49:47 2016 +0530
    
        WL#9499 - Use std::unordered_map for name to fil_space_t* hash.
    
    commit 5e8275caf9d50dc9ba2f2dadd3b8c0fdeb9c79b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Sep 10 07:55:42 2016 +0530
    
        WL#9499 - Reduce an extra fil_sys_t::mutex call by consolidating flush request.
    
    commit b29fd1039cf0022cff36a2a2311f464f1f6dbcc5
    Merge: 6235ee4902a a150caebee6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 9 20:44:56 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6235ee4902addd1a041b33469988bb1ea870dc7a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 10:58:00 2016 +0530
    
        WL#9499 - Add debug crash points.
    
    commit bf71fbc72b3570f55c8f01dd1a440e9eff761cb6
    Merge: ce6d2246a94 d25f38e38d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 09:47:37 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit ce6d2246a94801041da0bfece74b5ffdd9e8f796
    Merge: 69adae163de f28c4b9a41e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 7 11:20:50 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 69adae163de295ef0e910752cf5f8c96b1c1114f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:33:29 2016 +0530
    
        WL#9499 - Ensure that the MLOG_FILE_OPEN is always written first to the redo
    
    commit 20d5b1ebe6c899e2a0a1d135ad4303490516ce26
    Merge: 2d7d25c145f 4f1fb936211
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:17:58 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2d7d25c145fae59af744e91fce47fe009c869dad
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 10:06:56 2016 +0530
    
        WL#9499 - Add PFS instrumentation for the tablespace open file.
    
    commit 4e14a53ad129c1adcb0a3330931878a9f24c15cc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:53:57 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a465361e74136662471d2b9c0f307799efbe7269
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:17:43 2016 +0530
    
        WL#9499 - Move the file write code to a separate method.
    
    commit 7a26ba28bf7bf94808c47cfcdb6210c4abde2587
    Merge: f49914e5e61 ed389829067
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 07:55:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f49914e5e61b846c45f7b177308cd891918619e4
    Merge: a4fab040243 16fd507b84a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 31 11:23:42 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit a4fab040243a57fb8ef55f91812604352d8b92c8
    Merge: 93019973329 dfee02dc4f5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 10:42:20 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 9301997332923921b93de4946c4824164723050c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 09:09:05 2016 +0530
    
        WL#9499 - OSX/Solaris compilers don't like the code.
    
    commit 54afa110837a054de24ccda84ddbb4ef2d0b96a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 22:55:19 2016 +0530
    
        WL#9499 - During recovery PFS instrumentation can't be accessed by the user.
    
    commit fa5c11e8cf0fbcd1852535faa74b1a04200df2e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:15:07 2016 +0530
    
        WL#9499 - Fil_Open::purge() can be called during recovery too
    
    commit d8672a978d62db42f1a12ba152693a3c0d244d83
    Merge: d4251d0ed6f 14d2a977ce8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:10:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d4251d0ed6f9df5a3acbf97ce7ba8074f126044c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:07:14 2016 +0530
    
        WL#9499 - Remove a WL#7806 test.
    
        The test doesn't really help. It uses very simplistic checks for matching
        path names. It ignores links (soft and hard) completely. Besides during
        recovery the path names will work with the original path names.
    
    commit fba6656350d0a757b2cc936b017329e7f7ce2d32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:51:53 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b522d665d10dca905420cb9119692dffac5024c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:20:30 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 3a9aca50a2e193398d626b5f75d238b5aa704e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:19:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5923cd73fc3af904220dea20b033ffcbb7892606
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:12:44 2016 +0530
    
        WL#9499 - Use custom allocators.
    
    commit 8c5acab2641cedae9542b9ad9405032abbcb4618
    Merge: 1509c43fcff 3c1319b9901
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:21:28 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1509c43fcffb9a849542ef8f3a62e66fda490fc7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:08:34 2016 +0530
    
        WL#9499 - Fix bug, should be decrement in_use, not increment.
    
    commit 0ad783d5e6e3f99817c8b839fe8521f783577d35
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 07:58:49 2016 +0530
    
        WL#9499 - Change fil_node_t::in_use into a reference counter from bool.
    
    commit 3974f1ed40bfbadcee04fa5fc2e60a50b89f930c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 22:10:24 2016 +0530
    
        WL#9499 - Remove an assertion that is no longer an invariant.
    
    commit d79f12dec7c07698f02ce2e0d0396bcd01bdc683
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 21:52:21 2016 +0530
    
        WL#9499 - Rename fil_node_t::being_extended to in_use. Fix test.
    
    commit 1d3368bcf60e2e339d5917251b51201b94dd63a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:57:38 2016 +0530
    
        WL#9499 - Fix log info messages during recovery/apply.
    
    commit d3811bd67248d3ae014f0e6475b1b49524f5c35b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:40:01 2016 +0530
    
        WL#9499 - Don't print % processed if number of records to apply is small.
    
    commit 55af670ff81170da51fbcae6832c3d6191176602
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:21:31 2016 +0530
    
        WL#9499 - Update test with new log message to check.
    
    commit 60c3d6c074ae230ab594015ed2f99e2eefcf97e0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:09:04 2016 +0530
    
        WL#9499 - Record test, because of new config parameter innodb_scan_directories.
    
    commit bd79ff06406c86758a29a28dbe5e7d494a0aa51f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:05:38 2016 +0530
    
        WL#9499 - Remove WL#7142 artefact.
    
    commit bcb753b72b2a01ba35d952cbab45e420929f2b33
    Merge: e30834ecc60 27d64e974ec
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:26:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e30834ecc60522fca8d7b156a66c0765867dea6e
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Thu Aug 25 05:54:26 2016 +0200
    
        WL#9499 - Destroy the mutex in the Fil_Open destructor.
    
    commit a396d4714bdc46626e07d22b6871be153b627bd3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:17:06 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 282ad76aaeaeb6d91bbf81fcd3315f455d9f572c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:12:33 2016 +0530
    
        WL#9499 - Protect changes to Fil_Open state with a mutex.
    
    commit d338cb9468c126ee7e3eeae3bf37b0fc966bbf53
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 07:37:49 2016 +0530
    
        WL#9499 - Fix division by zero.
    
    commit 845324f19ba0a84538b87c072f6d99514533aa25
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:28:45 2016 +0530
    
        WL#9499 - Check for UNDO tablespace names during directory scan.
    
    commit 30ed1d19389e174605fdfc0b7d55fdf544933712
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:26:08 2016 +0530
    
        WL#9499 - Conform to new naming guidelines.
    
    commit 4cf67b352d4c8131064f832ec884db6166d50e71
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 22:04:43 2016 +0530
    
        WL#9499 - Add test for the configuration variable. Add a version number to the file.
    
    commit ad9c5bca0eba1d7bf8e29cd8ebd7062aae089f90
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 21:01:56 2016 +0530
    
        WL#9499 - Code clean up
    
    commit a9e848158909645ead86759ed7ab64789d18a0cb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 15:26:02 2016 +0530
    
        WL#9499 - Print redo apply progress per tablespace
    
    commit 8cf86cf1567cabc1b03b2e8f2ec1167f3c38ce6c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 13:04:55 2016 +0530
    
        WL#9499 - Print tablespace name and % completed per tablespace
    
    commit 35ccdf32d1d048400012a80422072fb41ceb1bbd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 10:35:26 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit c978fb2e18a4e0b4a93b44fc3c75234bcdb3f1f0
    Merge: 8bde4aeb01c 0832bf660e3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 22:25:57 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 8bde4aeb01c3bcdecfb884e566f0ae28797a5b36
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 13:21:10 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 7f502be746cbe0de1a0c3a992217691b167c2fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 12:12:08 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 247bcfda6744a67cc4e53d61658ca87d206b0660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:57:44 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 04509641b086a1b0b2c591573f95957f8a2f1cd0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:50:55 2016 +0530
    
        WL#9499 - Pass the filename directly to the callback
    
    commit 3efa317825886a3ae5d4a3c771fc0770a2c5a3ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 09:39:18 2016 +0530
    
        WL#9499 - Include tchar.h on Windows
    
    commit 55b814d2c2ebdea7c16a6d87a7251ca3f6e83775
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 07:47:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit e4d203688273b562691c912cb9c7024709757490
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 22:02:02 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 31433b21dcabba0a7705eb8b1879beb1d8c36517
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 21:37:41 2016 +0530
    
        WL#9499 - Move Dir_Walker::walk implementation to os0file.cc
    
    commit 11f9016477274c5420782e365b26762067e7b99b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 18:42:28 2016 +0530
    
        WL#9499 - Fix Windows version of Dir_Walk.
    
    commit f32b88e0b1ef99f220165897db745b1dba12f86b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 13:48:03 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b91ad88d96942f1e05443001b7d1c2f6818ff6d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 14:32:25 2016 +0530
    
        WL#9499 - Initialize active ID to filename set from scanned set.
    
    commit 4a09f677ae7095aac9b07f7beccba8e60c50b065
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 13:09:05 2016 +0530
    
        WL#9499 Scan specified directories to build the ID to name mapping.
    
    commit c13b791497e322e6a5cf64ba85da52ee2cf05d45
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:46:53 2016 +0530
    
        WL#9499 - Fix check for incomplete read.
    
    commit 8a849e0288309cec7228612a62fc2bfd71b595e9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:45:04 2016 +0530
    
        WL#9499 - Fix Windows build errors
    
    commit 4fc24b654da26e8411fc45bc96f73ff70dc73e43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:12:12 2016 +0530
    
        WL#9499 - Need to include string for Windows std::wstring.
    
    commit bcb5c2b23f54776e0faaafba2472bb2555aee561
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:02:59 2016 +0530
    
        WL#9499 - On POSIX fopen() mode should be "w+b".
    
    commit b3c7def1931867633d9b8bb601317e99a06c31a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 21:23:57 2016 +0530
    
        WL#9499 - Open file in binary mode for writing.
    
        Otherwise on Windows newline (0x0A) is translated to CRLF (0x0D0A).
    
    commit 0739399cb8a384c07b4b3540b73ade482d083f4a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 20:27:11 2016 +0530
    
        WL#9499 - More error messages during mapping file read. Add a directory walker.
    
    commit 1322de0af2235bc94630f7cb22e4ead1588775ee
    Merge: f266b100e2f 8fdbb2f5f1a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:47:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f266b100e2f23e775e5e04de8d26301d7f2f1072
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:18:07 2016 +0530
    
        WL#9499 - Flush the tablespace to mapping file buffers before fsync()
    
    commit 7c92536686033c2c70e7df831d569c1cd6f871f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:32:26 2016 +0530
    
        WL#9499 - Remove unused member variable m_lsn.
    
    commit 994c4766ef712e7da668788d0bdd648cbd764982
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:25:05 2016 +0530
    
        WL#9499 - Don't crash on uncompress failure. Try the next file if any.
    
    commit a419a190cdf734e3beca08d339c6c0d307ddff5f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:21:49 2016 +0530
    
        WL#9499 - Print an error code on uncopress failure
    
    commit 77cb39000e098ba4d06873723423521e6889a7d0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:12:11 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit afc632e0ef768542a96d4d15a897cb1780825d2e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 11:34:44 2016 +0530
    
        WL#9499 - Compress the tablespace open state file.
    
    commit 568c9e758084f671007789f7b5d1c996f5df39a0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 09:12:39 2016 +0530
    
        WL#9499 - Free the buffer on return
    
    commit 0f468cf8e50b9605a9e6c4e93c818b0f876c3c29
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 08:42:38 2016 +0530
    
        WL#9499 - Remove protobuf
    
    commit e789eb175d2da90cee2d46e30b91e623546f9e96
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 18 09:59:37 2016 +0530
    
        WL#9499 - Get native HANDLE
    
    commit 6014c5853c09fee75256f9de6a86a5fc0ea18508
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:50:37 2016 +0530
    
        WL#9499 - Use _fileno() on Windows
    
    commit 61e6b4d7c033d48b775b22c4ad6d6b4858cd4cd7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:37:01 2016 +0530
    
        WL#9499 - Use buffered IO for open state file writes
    
    commit 98f40b10c15e49d9a5e14689cdb34758bdf85a05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 12:36:06 2016 +0530
    
        WL#9499 - Don't complain about corrupted encrypted pages during dblwr recovery
    
    commit c674939cbdeaa4a9996960de0fa4e74954ad6f76
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 09:21:06 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for generated sources too.
    
    commit ff68ba26aeaa27070ceeaa8db4472a9ce4daa3c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 08:33:03 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for fil/fil0fil.cc
    
    commit 445985ca11810c528567a4222cad4a7f0ce49e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 19:44:29 2016 +0530
    
        WL#9499 - Read/Write open state files using absolute paths
    
    commit b4d91d3799d94eb2677be6512752ec27dfa5e0f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 14:37:40 2016 +0530
    
        WL#9499 - Fix doxygen errors
    
    commit 8be2de3b3077c0d0f26340c9c80f7ae2247eefbc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 11:20:24 2016 +0530
    
        WL#9499 - Record test, MLOG_FILE_NAME doesn't exist anymore
    
    commit 54e64dc4a97f5bf4b5606cea1841dfc1f04fe536
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 10:41:01 2016 +0530
    
        WL#9499 - Add protobuf library to the embedded library.
    
    commit 83b0fb38283e285e1e963dd2c7c144d70b130338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 21:17:13 2016 +0530
    
        WL#9499 - Improved DBLWR and System table checks and code cleanup
    
        1. Remove dead code
        2. If some pages from the dblwr buffer were not recovered during recovery
           because of a missing tablespace id -> name mapping. Check the tablespace
           ID against the Tablespaces meta-data after recovery.
        3. Track open of the system tablespace. Check if the name of any file
           has changed. We don't rename the system tablespace.
    
    commit 5ebfba1e083f6a1d2b70946b91a02d32733c7e87
    Merge: 7a1b724c04b 0c27bf6fc44
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Mon Aug 15 11:40:07 2016 +0200
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7a1b724c04bf9d2e4aba0e58fb95dc8fc75d55c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 15:07:47 2016 +0530
    
        WL#9499 - Free deferred page memory
    
    commit 4de5d3b03670e4d2e8ebce89e8b3f104968eb3e1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:45:25 2016 +0530
    
        WL#9499 - Remove unrelated changes
    
    commit c9e83914232480501b139c36ef616798a2ac1d05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:28:19 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 6ecdb21d63ef6dd5a6aff997720178ff6510f0d5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 13 14:31:52 2016 +0530
    
        WL#9499 - Don't exit if no open state files found

[33mcommit 983a6d9445d05a55c172485ac356122bacfdb760[m
Author: Maria Couceiro <maria.couceiro@oracle.com>
Date:   Tue Feb 7 10:12:47 2017 +0000

    WL#7374 Performance schema tables to monitor replication lags and queue
    
    This worklog implements the monitoring of replication lags using the
    replication P_S tables.
    The new monitoring information added consists of the GTID, the original
    and the immediate commit timestamps of the transaction that is currently
    being processed (plus the corresponding start processing timestamp) and
    of the last to be processed (plus the corresponding start and end
    processing timestamps) in each of these three tables:
    - [1;31mperf[mormance_schema.replication_connection status
    - [1;31mperf[mormance_schema.replication_applier_status_by_coordinator
    - [1;31mperf[mormance_schema.replication_applier_status_by_worker
    
    All timestamp fields in these three tables have microseconds precision,
    including last_error_timestamp and last_heartbeat_timestamp.
    The field 'last_seen_transaction' in table
    [1;31mperf[mormance_schema.replication_applier_status_by_worker was replaced by
    'applying_transaction' and 'last_applied_transaction'.

[33mcommit 6e7d1aafc981bc5f58d135ea591ab897bc2e7bb2[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Mar 1 17:24:05 2017 +0100

    WL#9721 Remove libmysqld embedded server in 8.0
    
    Cleaned up the [1;31mperf[mormance schema test suite.

[33mcommit dbd2ca2f6e14ce0ec19e743eb2f0cfdb20df6573[m
Author: Joao Gramacho <joao.gramacho@oracle.com>
Date:   Tue Nov 1 06:45:39 2016 +0000

    WL#8599: Reduce contention in IO and SQL threads
    
    (Step 1)
    
    This patch introduces the changes for the worklog related to making the
    slave applier to read from the relay log the same way the Binlog_sender
    does from the binary log (using a non-shared IO_CACHE, not relying on
    relay_log->LOCK_log even when reading from the "hot" relay log file).
    
    Made binlog_end_pos atomic
    --------------------------
    
    The MYSQL_BIN_LOG::binlog_end_pos was refactored to be atomic. From the
    Binlog_sender perspective, this would allow reducing the amount of
    acquirements of binary log LOCK_binlog_end_pos. With this change, both
    binary and relay log files readers don't need to acquire the
    LOCK_binlog_end_pos while checking if they reached the end of the "hot"
    log file. They only need to acquire the LOCK_binlog_end_pos if they are
    actually going to wait for updates.
    
    @ sql/binlog.h:
    
    Renamed binlog_end_pos to atomic_binlog_end_pos and made it atomic.
    
      At MYSQL_BIN_LOG::get_binlog_end_pos(), we removed the assertion of
      the ownership of the LOCK_binlog_end_pos, as it is not necessary since
      the binlog_end_pos variable become atomic.
    
    @ sql/rpl_binlog_sender.cc
    
      Refactored Binlog_sender::wait_new_events() to first check if the
      waiting is really needed (if the binary log was not updated before the
      acquirement of LOCK_binlog_end_pos), and then, only if the
      Binlog_sender really need to wait, to enter the
      stage_master_has_sent_all_binlog_to_slave stage and wait for updates
      on the binary log.
    
    Removed the relay_log->LOCK_log usage from next_event()
    -------------------------------------------------------
    
    The slave applier was refactored to not use the relay_log->LOCK_log when
    reading events from the "hot" relay log file.
    
    It was introduced a new PSI mutex key(MYSQL_RELAY_LOG::LOCK_log_end_pos)
    to instrument the LOCK_binlog_end_pos on relay log files.
    
    @ mysql-test/suite/[1;31mperf[mschema/r/relaylog.test
    
      The test case had to be recorded again after the addition of the new
      PSI mutex key.
    
    @ sql/mysqld.(cc|.h)
    
    Introduced the new "MYSQL_RELAY_LOG::LOCK_log_end_pos" PSI mutex key.
    
    In order to make the slave applier to not need to acquire
    relay_log->LOCK_log when reading from the "hot" relay log, the slave
    receiver now opens the relay log with the same flags as the binary log
    files are opened: O_WRONLY. This lead to many changes in the slave code.
    
    The rli->ign_master_log_* that relied on relay_log->LOCK_log are now
    being protected by the relay_log->LOCK_binlog_end_pos. This change was
    needed in order to guarantee that the updated generated by events
    ignored by the receiver thread would be properly handled by the applier
    regardless relay_log->LOCK_log.
    
    @ sql/binlog.h
    
      The MYSQL_BIN_LOG::update_binlog_end_pos() function is now also used
      for the relay log. The function was refactored to remove the relay log
      specific code. It also has now a new parameter to tell the function
      that the LOCK_binlog_end_pos was acquired by the caller.
    
      MYSQL_BIN_LOG::after_append_to_relay_log(),
      MYSQL_BIN_LOG::append_event() and MYSQL_BIN_LOG::append_buffer()
      function were renamed to MYSQL_BIN_LOG::after_write_to_relay_log(),
      MYSQL_BIN_LOG::write_event() and MYSQL_BIN_LOG::write_buffer()
      respectively.
    
    @ sql/binlog.cc
    
      At MYSQL_BIN_LOG::open(), there is no distinction about binary or
      relay log with respect to the flags used to open the IO_CACHE.
    
      At MYSQL_BIN_LOG::open_binlog(), replaced a check for the relay log
      that were relying on the io_cache_type to actually check if it is a
      relay log or not.
    
      At MYSQL_BIN_LOG::after_write_to_relay_log(), replaced the function
      used to get the actual file position from my_b_append_tell() to
      my_b_tell(). Also, instead of just signaling the update of the log
      file, this function also cleanup the rli->ign_master_log_name_end.
    
      MYSQL_BIN_LOG::write_event() is now asserting that the log_file.type
      is WRITE_CACHE.
    
      MYSQL_BIN_LOG::write_buffer() is now asserting that the log_file.type
      is WRITE_CACHE. It is also calling my_b_write() to write the buffer
      into the relay log IO_CACHE.
    
      MYSQL_BIN_LOG::wait_for_update_relay_log() was refactored to rely on
      LOCK_binlog_end_pos instead of LOCK_log and was moved to
      sql/rpl_slave.cc as wait_new_relaylog_events().
    
      At MYSQL_BIN_LOG::close, replaced a check for the relay log that were
      relying on the io_cache_type to actually check if it is a relay log or
      not.
    
    @ sql/log_event.cc
    
      Log_event::write_header() now calculates the event
      common_header->log_pos by using my_b_tell() as there is no IO_CACHE
      with SEQ_READ_APPEND type anymore.
    
    @ sql/rpl_rli.h
    
      It was removed the IO_CACHE *cur_log as it is not needed anymore.
    
      It was also removed the cur_log_old_open_count variable.
    
    @ sql/rpl_rli.cc
    
      Relay_log_info::Relay_log_info() now initialize the relay_log using
      the WRITE_CACHE cache type. It was added the initialization of the
      key_RELAYLOG_LOCK_log_end_pos that now is used by the relay log.
    
      It was removed any reference to relay_log->LOCK_log at
      Relay_log_info::init_relay_log_pos() function.
    
    @ sql/rpl_slave.cc
    
      The write_ignored_events_info_to_relay_log() function now relies on
      LOCK_binlog_end_pos instead of LOCK_log.
    
      At queue_event(), there is a rli->relay_log.lock_binlog_end_pos() call
      every time the rli->ign_master_log_* variables are going to be
      handled.
    
      It was created the relay_log_space_verification() static function with
      all the code related to relay log space verification that was inside
      the next_event() function.
    
      The major changes in this step were done at the next_event() static
      function. It doesn't use the relay_log->LOCK_log anymore, and rely on
      relay_log->LOCK_binlog_end_pos when reaching the "hot" relay log file
      boundaries. The function now only reads and event from the relay log
      file if the log is not "hot" or if current reading position is less
      than the binlog_end_pos.
    
      Introduced the wait_new_relaylog_events() function.
    
    @ mysql-test/suite/rpl/t/rpl_relay_log_locking(.test|.result)
    
      It was created a test case that relies on debug instrumentation to
      block the receiver thread while queuing an event and ensure that the
      applier thread is capable of reading from the relay log up to the last
      queued event.
    
    Other references
    ----------------
    
    This patch also fixed:
    
    BUG#25321231: TUNING THE LOG_LOCK CONTENTION FOR IO_THREAD AND
                  SQL_THREAD IN RPL_SLAVE.CC
    
    (Step 2)
    
    This patch made channels retrieved_gtid_sets to use their own
    sid_map/sid_lock and created a class to avoid locking when checking the
    current server GTID_MODE to be used Master_info and Binlog_sender.
    
    Gtid_mode_copy class
    --------------------
    
    Any operation needing to check the current server GTID_MODE would
    acquire the global_sid_lock in order to read the GTID_MODE. This is a
    very fast operation (just to access a server global variable), but while
    done by many concurrent threads it might generate impact, mostly on
    commit operations that acquire the global_sid_lock exclusively.
    
    Also, when the server is committing a group of transactions, as the
    global_sid_lock is acquired for writing, any operation trying to check
    the server GTID_MODE will have to be held.
    
    GTID_MODE is a global variable that should not be changed often, but
    the access to it is protected by any of the four locks described at
    enum_gtid_mode_lock.
    
    Every time a channel receiver thread connects to a master, every time
    a Gtid_log_event or an Anonymous_gtid_log_event is queued by a receiver
    thread, or is going to be sent by the Binlog_sender to a receiver, there
    must be checked if the current GTID_MODE is compatible with the
    operation.
    
    There are some places where the verification is [1;31mperf[mormed while
    already holding one of the above mentioned locks, but there are other
    places that rely on no specific lock and, in this case, will rely on the
    global_sid_lock, blocking any other GTID operation relying on the
    global_sid_map for writing (like a group of transactions being
    committed).
    
    In order to avoid acquiring lock to check a variable that is not
    changed often, we introduced a global (atomic) counter of how many times
    the GTID_MODE was changed since the server startup.
    
    The Gtid_mode_copy class was implemented to hold a copy of the last
    GTID_MODE to be returned without the need of acquiring locks if the
    local GTID mode counter has the same value as the global atomic counter.
    
    @ sql/mysqld.cc
    
      Introduced the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/rpl_gtid_misc.cc
    
      Declared the global atomic _gtid_mode_counter.
    
    @ sql/rpl_gtid.h
    
      Declared the external atomic _gtid_mode_counter.
    
      Defined DEFAULT_GTID_MODE as GTID_MODE_OFF.
    
      Introduced the Gtid_mode_copy class.
    
    @ sql/rpl_binlog_sender.h
    
      Inherited from Gtid_mode_copy to the Binlog_sender class.
    
    @ sql/rpl_binlog_sender.cc
    
      Replaced the calls to get_gtid_mode() by get_gtid_mode_from_copy().
    
    @ sql/rpl_slave.cc
    
      At recover_relay_log(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At init_recovery(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At start_slave_threads(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At get_master_version_and_clock(), replaced the call to
      get_gtid_mode() by get_gtid_mode_from_copy().
    
      At queue_event(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
    @ sql/sys_vars.cc
    
      Incremented the _gtid_mode_counter when GTID_MODE is changed. Also,
      made the GTID_MODE global variable to have DEFAULT_GTID_MODE as its
      default value.
    
    Retrieve_gtid_sets with their own SID maps/SID locks
    ----------------------------------------------------
    
    Any GTID set operation relying on a given SID map (and its respective
    lock) will be blocked by any other operation (in any other GTID set)
    holding the SID lock for writing.
    
    All server GTID state sets (lost_gtids, executed_gtids,
    gtids_only_in_table, previous_gtids_logged and owned_gtids) rely on the
    global SID map (and on the global SID lock). So, when GTIDs are
    committed in the server, the updates on the GTID state lock the SID map
    for writing to prevent other threads to [1;31mperf[morm updates on the GTID
    state (or read from it while it is being updated). The side effect of
    this way of avoiding other threads to read from or update a GTID set is
    blocking any other GTID activity in other GTID sets relying on the same
    SID map/SID lock. So, before this patch, the replication receiver
    threads had their Retrieved_Gtid_Set relying on the global SID map/lock.
    In this way, when a group commit was updating the GTIDs of the committed
    transactions, any replication receiver trying to queue a Gtid_log_event
    or finishing queuing a Gtid transaction had to wait for the group commit
    to unlock the global SID lock. Also, a group commit trying to lock the
    global SID lock for writing was waiting to all receiver threads queuing
    GTIDs to finish before having being granted with the lock ownership.
    
    The global SID lock on the cases described above is taken for doing
    small operations, and there is no significant impact on server
    [1;31mperf[mormance in a slave server replicating using a single replication
    channel with medium to large transactions and without using MTS. But
    when the slave is scaled to have many replication channels and/or
    replicating many small transactions and using MTS, the impact of the
    concurrency in the global SID lock becomes noticeable.
    
    This patch is making all receiver threads to rely on their own
    (individual) SID maps and locks.
    
    @ sql/binlog.cc
    
      The MYSQL_BIN_LOG::init_gtid_sets() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      The MYSQL_BIN_LOG::open_binlog() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      The MYSQL_BIN_LOG::reset_logs() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      MYSQL_BIN_LOG::after_write_to_relay_log() now uses only the relay log
      sid_lock.
    
    @ sql/log_event.cc
    
      Previous_log_event should assert that the SID map of the GTID set
      passed as parameter is locked (is it not the global_sid_lock for relay
      log events).
    
    @ sql/mysqld.h
    
      Declared the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/mysqld.cc
    
      At gtid_server_init(), initialized the global _gtid_mode_counter.
    
      Introduced the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/rpl_channel_service_interface.cc
    
      The channel_get_last_delivered_gno() function now uses the relay log
      sid_lock.
    
      The channel_wait_until_apply_queue_applied() was refactored to avoid
      blocking both the relay log sid_lock and the global_sid_lock while
      waiting for the condition.
    
    @ sql/rpl_gtid.h
    
      Enabled the declaration of Sid_map::clear() regardless of compiler
      directives.
    
      Declared a new static function Sid_map::get_new_sid_map() to
      retrieve a new empty SID map with its own SID lock.
    
      Declared the Gtid_set::clear_set_and_sid_map() function that takes
      care of cleaning the SID map after cleaning the GTID set.
    
    @ sql/rpl_gtid_set.cc
    
      Introduced the Gtid_set::clear_set_and_sid_map() function that takes
      care of cleaning the SID map after cleaning the GTID set.
    
    @ sql/rpl_gtid_sid_map.cc
    
      Removed the compiler directives preventing the compilation of
      Sid_map::clear().
    
    @ sql/rpl_rli.h
    
      Made the (retrieved) gtid_set a pointer.
    
      Added function to get the GTID set SID map (get_sid_map()) and SID
      lock (get_sid_lock()).
    
      Changed add_logged_gtid() function to use the relay log SID map and
      lock.
    
      Declared a new wait_for_gtid_set() function receiving a char*
      parameter instead of a String*.
    
    @ sql/rpl_rli.cc
    
      Refactored the gtid_set initialization on Relay_log_info constructor
      and cleaned up the GTID set, SID map and lock on destructor.
    
      Introduced the new wait_for_gtid_set() function receiving a char*
      parameter instead of a String* and refactored the wait_for_gtid_set()
      that receives a String* to call the new introduced one.
    
      Added some assertions at Relay_log_info::wait_for_gtid_set() to ensure
      that the GTID set to wait is relying on global_sid_map or has no SID
      map.
    
      Relay_log_info::purge_relay_logs() now uses the relay log SID lock and
      also clears the relay log SID map when cleaning the retrieved GTID
      set.
    
      Relay_log_info::rli_init_info now uses the relay log SID lock.
    
      Relay_log_info::add_gtid_set() now uses the relay log SID lock.
    
    @ sql/rpl_slave.cc
    
      The recover_relay_log() function now uses the relay log SID lock and
      also clears the relay log SID map when cleaning the retrieved GTID
      set.
    
      The show_slave_status() functions were refactored to use the relay log
      SID lock when dealing with the retrieved GTID sets.
    
      The request_dump() function now uses the relay log SID lock when
      dealing with the retrieved GTID set.
    
      The queue_event() function now uses the relay log SID lock when
      dealing with GTIDs of received Gtid_log_events.
    
    @ storage/[1;31mperf[mschema/table_replication_connection_status.cc
    
      The table_replication_connection_status::make_row() function was
      refactored to use the relay log SID lock when dealing with the
      retrieved GTID sets.
    
    (Step 3)
    
    This patch moved the call to flush_master_info() that was done by the
    I/O thread after a successful call to queue_event() to inside the
    queue_event() function, in order to take a ride in the already locked
    mi->data_lock and relay_log->LOCK_log.
    
    This will avoid acquiring the above mentioned locks twice for every
    successful event queued.
    
    It also added a new parameter to flush_master_info() to opt the flush of
    the relay log. Previous approach was leading to flush the relay log
    twice per event.
    
    @ sql/rpl_channel_service_interface.cc
    
      Specified the new queue_event() parameter to not flush master info
      after queuing the event.
    
    @ sql/rpl_slave.h
    
      Changes flush_master_info() declaration by adding a new parameter
      telling the function if it needs to acquire the required locks or if
      the locks are already acquired and a new parameter telling the
      function if it needs to flush the relay log.
    
      Declared QUEUE_EVENT_RESULT enum with the possible results of the
      queue_event() function.
    
      Changes queue_event() declaration to return QUEUE_EVENT_RESULT and
      also to support a new parameter telling the function to also flush
      master info on after an event be successfully queued.
    
    @ sql/rpl_slave.cc
    
      The flush_master_info() function was changed to not acquire the
      relay_log->LOCK_log always, but rely on the need_lock parameter to do
      so. It was also changed to only flush the relay log based on the new
      flush_relay_log parameter. This will prevent flushing the relay log
      twice when queuing events.
    
      On handle_slave_io(), refactored the calls to queue_event() and
      flush_master_info() to use the new implemented parameters.
    
      Refactored queue_event() function to return QUEUE_EVENT_RESULT, and to
      flush master info without the need of flushing the relay log in the
      case of a successful event be queued.
    
    Added test cases to improve code coverage:
    
    - rpl_write_ignored_events: ensure the ignored events not yet consumed
      by the slave are taken into account by the SQL thread if the I/O
      thread is stopped before the SQL thread consumed the ignored events
      info.
    
    - rpl_write_ignored_events_fail_writing_rotate: ensure I/O behavior
      when failures happen while writing the ignored events info to the
      relay log.
    
    Also commented an unreachable code to make gcov happy.
    
    Added test cases to verify that receiver threads GTID sets do not rely on
    global SID anymore.
    
    rpl_multi_source_block_receiver: checks that receiver thread receiving GTIDs
    (and adding them to its retrieved GTID set) can apply GTIDs from a server UUID
    that doesn't belong to the global SID map yet.
    
    rpl_line_topology_receiver_block: checks that receiver thread on slave
    receiving GTIDs (and adding them to its retrieved GTID set) can have other
    servers replicating from it.

[33mcommit 0bbe8f73f9ea9cb2966dc7f1fbc0a15281eeb4b9[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Tue Feb 28 10:48:45 2017 +0100

    Squashed commit of the following:
    
    WL#9499 - InnoDB: Replace MLOG_FILE_NAME with MLOG_FILE_OPEN
    
    Fix the [1;31mperf[mormance issues introduced by WL#7142 and its followup WL#7806.
    
    1. Revert WL#7142 and WL#7806 changes, keep some of the tests to test
       the behaviour that was introduced by the two WLs
    2. Change the tests that rely on the above two WLs behaviour
    3. Use std::unordered_map instead of the homebrew hash table for the recovery
       code and space ID to name mapping
    4. Split the redo log hash table key from <space, page> -> apply records to
       <space> -> apply records
    5. Addition of two new system files (tablespaces.open.1 and tablespaces.open.2)
    
     - Rename MLOG_FILE_NAME to MLOG_FILE_OPEN
     - Remove the two pass recovery code, make it a single pass
     - Track file open, close and rename
     - Write and fsync the tracking state to disk on checkpoint and rename.
       Uses the files in #5 in a round robin fashion
    
    Introduce --innodb-scan-directories="path1;...pathN". Scan the paths for
    .ibd files to open during recovery. This option can be used if the files in #5
    above are corrupt or missing. You should not use this if you move files around.
    While they can be recovered the data dictionary will not be updated and it
    will cause issues during runtimg.
    
    rb#13686 Approved by Satya and Shaohua
    
    commit fbf87161f3c93979e5abe424fbe0678fdc32159e
    Merge: 517cf3a7bf0 c2b504664ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:39:32 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 517cf3a7bf0490c3168fed020e3096ec500e0a85
    Merge: 4786f93ad8a 5e974fd0ea4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:24:25 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Additional change is to call recv_recovery_from_checkpoint_finish() on abort.
        Instead of recv_sys_free().
    
    commit 4786f93ad8a25506a2a1f6e9d1207256a34b3665
    Merge: 5dc35e05b5f 275245cce32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:43:27 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 5dc35e05b5f2da95c36e191350e9c7087be72194
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:42:40 2017 +0100
    
        WL#9499 Free recv resources on abort
    
    commit bed693070395923ededba736f1c7102b8eb21e95
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 18:34:50 2017 +0100
    
        WL#9499 - Test cannot be run with Valgrind
    
    commit c5d423228ddf58b17866ff8be289dba4a19205d2
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:30:39 2017 +0100
    
        WL#9499 - Remove const
    
    commit ac42498506b4dffb22e74282d0ce037fe3acf977
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:00:30 2017 +0100
    
        WL#9499 - Clean up code
    
    commit bc48077cab9c3ccb1b2797c365fe0940c269a785
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 16:01:09 2017 +0100
    
        WL#9499 - Revert unrelated change
    
    commit 8b2bb0f6d6254b3cfde168d41356400009db12f4
    Merge: eb9b294ba78 153a79ff35d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:43:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit eb9b294ba786800f9e397cd87f01c4f4976edddb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:29:56 2017 +0100
    
        WL#9499 - Remove debug message
    
    commit abae66ad591854ee67a5013f3209be2f82e4d9bf
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 17:04:10 2017 +0100
    
        WL#9499 - Test only works in debug mode.
    
    commit 71ebea70391ef295bed49ee06a8b872f15ecfe97
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:18:08 2017 +0100
    
        WL#9499 - Update to mtr test from Matthias
    
    commit f108a5b92fc476c70c49e4937496b32d9d5d031f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:13:04 2017 +0100
    
        WL#9499 - Increment redo log version number
    
    commit 4439c83a4d3edd6e511706ccf9936770ed29e593
    Merge: fa459186b90 05923bef41d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 09:54:18 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit fa459186b90d7a5ddcba7e3c6c7a9871d0dce793
    Merge: 14ac4f81d84 b401f17e70d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 20:02:40 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 14ac4f81d84bec23a7be210504ca0be93619bf11
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 16:44:57 2017 +0100
    
        WL#9499 - Update from Matthias
    
    commit ed3191a9fc951151fd7d758a527e7ab81530b3f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:16:11 2017 +0100
    
        WL#9499 - Revert change pushed by nmistake
    
    commit 8c0edb998867bf557f6c86410552d6d123892000
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:11:21 2017 +0100
    
        WL#9499 - Don't redo log MLOG_FILE_OPEN until startup is complete
    
    Date:   Wed Feb 22 09:54:18 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit fa459186b90d7a5ddcba7e3c6c7a9871d0dce793
    Merge: 14ac4f81d84 b401f17e70d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 20:02:40 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 14ac4f81d84bec23a7be210504ca0be93619bf11
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 16:44:57 2017 +0100
    
        WL#9499 - Update from Matthias
    
    commit ed3191a9fc951151fd7d758a527e7ab81530b3f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:16:11 2017 +0100
    
        WL#9499 - Revert change pushed by nmistake
    
    commit 8c0edb998867bf557f6c86410552d6d123892000
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:11:21 2017 +0100
    
        WL#9499 - Don't redo log MLOG_FILE_OPEN until startup is complete
    
    commit 3b503ea1d3f89c0f7e3677d3b56f249c7ebff506
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:37:04 2017 +0100
    
        WL#9499 - Add tests
    
    commit 47af7bd6eec10eac55633d7c4cf54afe607f3649
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:00:30 2017 +0100
    
        WL#9499 - Fix compile problem
    
    commit a8b9a8c6ccb15e2be5ce5db5fa0bce24b86d2c87
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:51:05 2017 +0100
    
        WL#9499 Remove dead code
    
    commit b1dba474486ad10b61029b2ef4e6a91ea67dcea8
    Merge: 3cf9e9eb3e8 a4271026201
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:49:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 3cf9e9eb3e86e4c8f4d44cb79d3f7c456ea7d671
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 18 07:53:43 2017 +0530
    
        WL#9499 - Remove suggestion to use force recovery
    
        --innodb-scan-directories is a safer option for the user. Force recovery should
        be the absolute last resort.
    
    commit 4104c4bfd606270650aac95a9a724e106fe835c5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 09:00:47 2017 +0530
    
        WL#9499 - Fix error message
    
        User can try --innodb-scan-directories="..." if the tablespaces.open.* files
        are corrupt or unreadable.
    
    commit 19ab12e54923b070a0b4ffc76b9fe97ac54ad3cc
    Merge: 50b3a95e446 f0f51c410bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 05:22:57 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Replace readdir_r() with readdir(), compiler complains that readdir_r() is
        deprecated and recommends replacing it with readdir().
    
    commit 50b3a95e446b91853fc35716b63bdc173221d01f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:55:33 2017 +0530
    
        WL#9499 - Fix test
    
    commit 45d202ae0fa35aa3aced55cc1933aeefa33837de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:32:56 2017 +0530
    
        WL#9499 - Remove redundant test
    
    commit 48fe691b97735e5144e9d439a0adbf721b2dc554
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:18:11 2017 +0530
    
        WL#9499 - Add DEBUG sync points
    
    commit d986f4e04a9eb6c2c76d61cd4afe9541d77b34bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:03:50 2017 +0530
    
        WL#9499 - Remove PB2 control file
    
    commit 5af7dca9c305bd366ad2b5c3de26a870e913af4a
    Merge: 74022f50a5f 23a0e71aa3d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 15 09:05:05 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 74022f50a5ff7cb2801c0712601f8a467b409a28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 14 10:31:00 2017 +0530
    
        WL#9499 - Fix test
    
    commit f6188175ee62040ac6a844a5c54787839dff6155
    Merge: 24c867aab14 19ca7c6a5d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 13 12:37:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 24c867aab14556188503aac495f60d89ba3d26ec
    Merge: cb64b8c7f9f a4de6ab549e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 4 06:41:23 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cb64b8c7f9fa9ca05033a9d6f6193cf141746310
    Merge: 17c6c41da0a 88dbc4f4511
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:48:12 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 17c6c41da0afe3fc78843b75fa02578dab29a0ca
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:46:34 2017 +0530
    
        WL#9499 - Add a test for scan directories.
    
        The use case is where the location of the files is not changed but the
        tablespaces.open.* files are missing.
    
    commit 79cc52f1bd82dc65932eacbc9aa14a47e4196572
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 18:01:50 2017 +0530
    
        WL#9499 - If open fails space will be null.
    
    commit 22ea5f31ecc1fa0db8abd57d4a46578e5f891c9a
    Merge: f5b69930f95 853a52cf5a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 12:14:41 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f5b69930f95192ddfdb3ca170024a5c7e3416076
    Merge: 40a4c32f2c4 b18872ed4a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 2 13:54:24 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 40a4c32f2c42b584539a14cbc1ba0d4f0fe7d3c9
    Merge: b1d1923d37c d071c0e7a0b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 1 13:48:33 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit b1d1923d37c3d23a9f701a61b458b7e4cbd3c90c
    Merge: 2fc6c51edab 4ae71705a01
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 31 10:44:59 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2fc6c51edabc3de4537eceb0b82cd62063ada3a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 16:36:46 2017 +0530
    
        WL#9499 - Empty the tablespace.open.* files on normal shutdown.
    
    commit 738acb7d554f97455c8dba512282c7c2e6ba9f3a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:47:21 2017 +0530
    
        WL#9499 - Fix formatting
    
    commit 28f8579a6f729af354e0c50098d16fbfa17cc253
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:25:30 2017 +0530
    
        WL#9499 - Bug fix
    
        The DELETED state was set on a copy of the data structure
    
    commit dd5bf8ea81b7023fa1980c01d89219a690160b04
    Merge: 7eeab0a994d 9c7808e1054
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 21:14:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7eeab0a994db4cf0c2e080f27ff916c778ec65f8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:50:59 2017 +0530
    
        WL#9499 - Add tests.
    
    commit ddfaf047f43587ee807599b0b80b6d01a3579e8c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:48:06 2017 +0530
    
        WL#9499 - Create tablespace bug fix
    
        If there is a checkpoint after the create tablespace is logged and the
        server crashes after writing the page initialization to the redo log. Then
        we neither have the mapping in the redo log nor in the tablespace.open.*
        files. We must update the tablespace mapping before writing the CREATE
        redo log entry so that the state is written out to disk on checkpoint.
    
    commit 29546d3ebea2991e5b86b33edddb551c924bf1db
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 17:55:28 2017 +0530
    
        WL#9499 - Remove dead code from WL#7142
    
    commit eced7a3e4437ee4bb24a12290f561437ddb15611
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 14:51:09 2017 +0530
    
        WL#9499 - Use the tablespace.open.* files in a round robin fashion.
    
    commit d8eff788eea1ad5e6c7786b9d64963524f2b2c81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:56:12 2017 +0530
    
        WL#9499 - Fix duplicate entry
    
    commit 1d04e0cf0308c35ee7498e6919eab9a11c699d52
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:55:30 2017 +0530
    
        WL#9499 - Revert last push
    
    commit 8361d3c39366d6435a895d5b64dd23615d26fc28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Jan 26 09:05:52 2017 +0530
    
        WL#9499 - Write to the tablespace.open.* files in a round robin manner.
    
    commit 3eaba629ee5b5c26a5f4e80852fee2d446f3013f
    Merge: 6642c43d735 bdc49070128
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 25 14:03:15 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6642c43d7353063a455972ab2cbc21220c16be43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 08:34:35 2017 +0530
    
        WL#9499 - Rename fil_ibd_load to fil_ibd_open_for_recovery.
    
    commit fdd1897c79b29c9e0a69c1f81d94927da06d9424
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:28:49 2017 +0530
    
        WL#9499 - Enforce const semantics on Windows for Folder::exists().
    
    commit 9394f4653e10cc5d4ab9b7b0a0b9331fd2666f49
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:08:26 2017 +0530
    
        WL#9499 - Include <array>
    
    commit c1903d28800ae0f7af69552aa669622d552346b4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Jan 21 07:49:28 2017 +0530
    
        WL#9499 - Improve scan directory handling
    
        1. Convert relative paths to absolute paths
        2. Filter out duplicates
        3. Check directories at filtering stage
    
    commit dfea237f4bef914de4067153cbf382240112c4f4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 11:11:05 2017 +0530
    
        WL#9499 - Code clean up
    
    commit c4d51bfdf1c786b1c584c0af1bde080a4f37cc5b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 07:37:06 2017 +0530
    
        WL#9499 - Update the open/rename LSN when a file is opened or renamed.
    
        Minor code cleanup.
        Add diagnostic code for debugging.
    
    commit 5e1d159b571fe6dbfe13c627a245155b82c4bbfa
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 18 10:59:54 2017 +0530
    
        WL#9499 - Filter out '*' from innodb-scan-directories
    
    commit 361f2944f1940f11dfb16dec3589d68335f5e2d8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 21:01:06 2017 +0530
    
        WL#9499 - Code cleanup
    
    commit 288d70b356721887423ca3d2d72b42da331216cd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 13:08:08 2017 +0530
    
        WL#9499 - Sync open file map to disk before checkpoint.
    
    commit 3c602d1b4089cd262200650f4b33986fc9e26531
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:18:46 2017 +0530
    
        WL#9499 - Print expected bytes instead of generic message.
    
    commit f52e0985b8cbef3891385179d35dc8c7f567146a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:07:47 2017 +0530
    
        WL#9499 - Print file size instead of generic message.
    
    commit b27b1b4b4b70e286e2c669f997b0a669f6d6034c
    Merge: bbdd1c46f1e c101ec9b557
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 16 13:19:42 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit bbdd1c46f1ef08d956ea249e1f6f4bc93d3464f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Dec 10 14:41:12 2016 +0530
    
        WL#9499 - Handle the case where the rename has already been done on recovery.
    
    commit 141bdb02b1a402e786db5d8b165b781a5d7370a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 11:59:29 2016 +0530
    
        WL#9499 - Instrumentation for debugging
    
    commit 34815bb24a1c296d9739e7602dc6ccd53c58c44c
    Merge: 41ca3732a6f 13a46b4c5ea
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 09:44:03 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 41ca3732a6ffd8dfa16762a05df6b5c6b4b550c1
    Merge: 7137edb2d2c aba34f1205d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 11:10:08 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7137edb2d2ca60cdec44600ddf3f5cbde424e7a4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 05:56:06 2016 +0530
    
        WL#9499 - Remove unused code. Move id to name mapping sync before log flush.
    
    commit 2a50067e2da2f7819781de6550e55ca14995c7ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:57:41 2016 +0530
    
        WL#9499 - Initialize the PFS file handle
    
    commit d478d3492cdb40ec02fda9c043bf29b87bae11ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:05:52 2016 +0530
    
        WL#9499 - Fix whitespace
    
    commit 061af748a5e2fde6c1577ccdabfc8a89a9f753de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:02:25 2016 +0530
    
        WL#9499 - Set must flush on file close/delete.
    
    commit ad76e2b9c7ff757f60c66821e86696d5ab757b18
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 11:43:00 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5a95946d4567dc13cf5a12d6bcdb28b19a02b5bc
    Merge: 1a0f373eb7f da23d6b8e44
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 09:27:45 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1a0f373eb7f03dc22264f91f3f6ed1fd13825de7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 13:01:41 2016 +0530
    
        WL#9499 - Readd test result file back
    
    commit 00afde093183cf850f735940245af111dce82b72
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 12:59:49 2016 +0530
    
        WL#9499 - Don't purge the files based on LWM. It won't work.
    
        We need to also ensure that there aren't any pages in the buffer pool that
        belong to a tablespace that is closed. Redo log records can be written for
        such pages.
    
    commit 3199fe255103daa42f0332b7ff9d565eefff7429
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:41:39 2016 +0530
    
        WL#9499 - Fix typo
    
    commit 351cb6c42709405a79021276f310d7b996aadd1b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:32:02 2016 +0530
    
        WL#9499 - Remove unused function
    
    commit 61cc7f6b06c5280d58217b76d7627013ddcd8338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:22:31 2016 +0530
    
        WL#9499 - Reduce the compression level.
    
    commit 48142e360ff5cfb53d5e416f3d6b92e956237923
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:21:51 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 4de4f8b31ebdff31a2f7a97a1ad211770d20cdd6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 14:07:07 2016 +0530
    
        WL#9499 - Revert ef30f0754ab22e614ac22712c348ec5f53e0f09c
    
    commit c2f77f44c43c209fad86bba568aa521a2dcbf718
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 12:20:37 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 5fccb51769a13cb9a1fc0f29a832d3b0085ad52a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:30:18 2016 +0530
    
        WL#9499 - Print a message when checkpoint is disabled.
    
    commit ef30f0754ab22e614ac22712c348ec5f53e0f09c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:17:27 2016 +0530
    
        WL#9499 - Print progress in 10% units.
    
    commit bc0ded332624fa2c8a08ebfc955a03f1a24e069c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 08:13:54 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 68ce0208cc073452f5f791faf304971dbac7194a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:38:03 2016 +0530
    
        WL#9499 - Scan directories after the mutex code is initialized.
    
    commit 21e07c8fd6b8eddf158fb79980443f6c9f6d238e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:12:23 2016 +0530
    
        WL#9499 - Introduce --innodb-checkpoint-disabled (debug)
    
        Disable checkpointing if the variable is set. This is to force recovery if the
        server is killed during a test.
    
    commit 7033c9bb5ff7641764f70823a73d747b497a0eed
    Merge: 11a6e582417 c6af7f512b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 04:00:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 11a6e582417d45a80a7f19233c2d2191a17936eb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 03:59:05 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 0a38252e65d607b59b1e9f64d0c8003cdecfecfd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 25 05:56:42 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bcf650cc92b8636f3768dcc3deb33b90b2942134
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 08:46:07 2016 +0530
    
        WL#9499 - Change the open files number back to 2.
    
    commit 99960af2825529fb45d021a34ba6c072e8caa0dc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 07:13:58 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bdb91bc0ba03e01661c50c7175d3fd123d2bcd69
    Merge: 61f3e4a5663 a545bdd6e31
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:04:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 61f3e4a5663c375cd44ee766b263281ff7f0601b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:00:20 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 072ab837d0acb4d2ed817110598554acc44ec344
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 12:06:53 2016 +0530
    
        WL#9499 - Set the IMPORT page LSN to the flushed to disk LSN
    
    commit 7f18661432f3645eb9ce76680c62508ced115fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 11:28:47 2016 +0530
    
        WL#9499 - Force a checkpoint before the crash
    
    commit 83671e9c37fa61adfa5546cabe1463a91ff02241
    Merge: cc26d5ae16e d1f811eb6e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 10:52:16 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cc26d5ae16e8d723a2519f38bfbc084c13a766c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 18:40:51 2016 +0530
    
        WL#9499 - Fix latch ordering issue
    
        Cannot hold the log sys mutex when updating the checkpoint LSN for the open
        files in fil0fil.cc.
    
    commit 4474509addfbdf91b9f0ad890a971299c594e738
    Merge: 396755e195c 0856b10cde5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 08:00:05 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 396755e195c1c8d3b2485a58175dcf56ca2cbf3f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:58:05 2016 +0530
    
        WL#9499 - Remove newline added earlier
    
    commit ab5e60ba491e52f1529c22551a936d771b8b5ef9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:57:21 2016 +0530
    
        WL#9499 - Revert a change that was added by mistake.
    
    commit 38688417713e5ef8cbb65032fa0a547ab0c25c15
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 20:44:50 2016 +0530
    
        WL#9499 - Bug fix, using an invalidated iterator.
    
    commit 4082d44f6dc4a5605562e37ccad9ac4db69344c6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 11:30:49 2016 +0530
    
        WL#9499 - Fix doxygen comment
    
    commit d5ca99e14c010a5349aea6c8cc39493b2073b9c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 15:30:12 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a25f3af10ea2893c634dc961d6f2af05efa103ec
    Merge: c8c2a7eba4c aa039b73223
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:52:51 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit c8c2a7eba4cac29ff431588daf2d6def0c0ee5a6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:39:32 2016 +0530
    
        WL#9499 - Fix problem with open files acrosss checkpoints.
    
        The problem is that we write the open file state before writing the checkpoint.
        Before this change the closed files were purged from the open state map and
        the state written to disk. The problem is that the state and mapping of a file
        opened before the last checkpoint but closed just before we write the state
        will not be in the mapping on disk. One solution is to check older files and
        retrieve the mapping from there. The solution chosen is to avoid purging
        files based on open LSN. If the file was opened before the last checkpoint
        and closed within the current checkpoint we note the state as CLOSED but
        write the mapping to disk. It will be purged at the next checkpoint, if it is
        not opened again in the meantime.
    
        Previously an attempt was made to open all files straight after reading the
        mapping from disk. With this change only the state is loaded into memory the
        files are opened on demand. Added a check to verify that the tablespace ID
        from the first page matches the expected value.
    
        Fixed tests to use this new tablespace ID verification.
    
    commit 5dc929e54b1c259f0f8104739ae1f88e9b860f73
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 12:24:40 2016 +0530
    
        WL#9499 - Remove unused code
    
    commit 528b95d70dcc05a69a98ee2a76fdfb8dae1e82fe
    Merge: d9861c40964 75f05cba753
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:14:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d9861c40964ad8fd45ee2cbbd9d94946110e8a9a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 3007ea5af68f40b85bc93098d8385ac96bcbd660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 9592996d2f17c9005262faa75dc1ade9dedbd511
    Merge: da512d5591b ac925fc91f6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Oct 19 10:34:48 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit da512d5591b3379b793d6155089e90791fe94c61
    Merge: f42e2ddd7d5 e635dfe28c0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 30 05:20:10 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f42e2ddd7d50aacae679babe71643af379b5c492
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 15:05:28 2016 +0530
    
        WL#9499 - Fix assertion, the values can be ORred.
    
    commit 94cd08960bc3801acefd4b4ff4ddb4a3e7d7e81a
    Merge: 32a68f91330 59af373321b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 11:05:21 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 32a68f9133011871bfdaba3c742f6239e0a53061
    Merge: 7857f38ebce 15555ae2165
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 21 11:23:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7857f38ebce747135e055bc8a232b649f1aad351
    Merge: 427491f63f1 b43bf88cf80
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 19 11:43:17 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 427491f63f107247c36796e66f6224d20968f104
    Merge: e7fa4c53dcf 23343687722
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 14 22:40:47 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e7fa4c53dcf01ea0e101bd8aa817698492995034
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 19:22:00 2016 +0530
    
        WL#9499 - max_lsn should work with any number of tablespace open files.
    
    commit 09775960da43d36ca64504c1298b9adff3056575
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 17:47:29 2016 +0530
    
        WL#9499 - Fix Names hash bug.
    
    commit 8430c5b34d23cb1774597707fe583dfac93fb3a8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 09:49:47 2016 +0530
    
        WL#9499 - Use std::unordered_map for name to fil_space_t* hash.
    
    commit 5e8275caf9d50dc9ba2f2dadd3b8c0fdeb9c79b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Sep 10 07:55:42 2016 +0530
    
        WL#9499 - Reduce an extra fil_sys_t::mutex call by consolidating flush request.
    
    commit b29fd1039cf0022cff36a2a2311f464f1f6dbcc5
    Merge: 6235ee4902a a150caebee6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 9 20:44:56 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6235ee4902addd1a041b33469988bb1ea870dc7a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 10:58:00 2016 +0530
    
        WL#9499 - Add debug crash points.
    
    commit bf71fbc72b3570f55c8f01dd1a440e9eff761cb6
    Merge: ce6d2246a94 d25f38e38d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 09:47:37 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit ce6d2246a94801041da0bfece74b5ffdd9e8f796
    Merge: 69adae163de f28c4b9a41e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 7 11:20:50 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 69adae163de295ef0e910752cf5f8c96b1c1114f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:33:29 2016 +0530
    
        WL#9499 - Ensure that the MLOG_FILE_OPEN is always written first to the redo
    
    commit 20d5b1ebe6c899e2a0a1d135ad4303490516ce26
    Merge: 2d7d25c145f 4f1fb936211
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:17:58 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2d7d25c145fae59af744e91fce47fe009c869dad
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 10:06:56 2016 +0530
    
        WL#9499 - Add PFS instrumentation for the tablespace open file.
    
    commit 4e14a53ad129c1adcb0a3330931878a9f24c15cc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:53:57 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a465361e74136662471d2b9c0f307799efbe7269
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:17:43 2016 +0530
    
        WL#9499 - Move the file write code to a separate method.
    
    commit 7a26ba28bf7bf94808c47cfcdb6210c4abde2587
    Merge: f49914e5e61 ed389829067
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 07:55:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f49914e5e61b846c45f7b177308cd891918619e4
    Merge: a4fab040243 16fd507b84a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 31 11:23:42 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit a4fab040243a57fb8ef55f91812604352d8b92c8
    Merge: 93019973329 dfee02dc4f5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 10:42:20 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 9301997332923921b93de4946c4824164723050c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 09:09:05 2016 +0530
    
        WL#9499 - OSX/Solaris compilers don't like the code.
    
    commit 54afa110837a054de24ccda84ddbb4ef2d0b96a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 22:55:19 2016 +0530
    
        WL#9499 - During recovery PFS instrumentation can't be accessed by the user.
    
    commit fa5c11e8cf0fbcd1852535faa74b1a04200df2e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:15:07 2016 +0530
    
        WL#9499 - Fil_Open::purge() can be called during recovery too
    
    commit d8672a978d62db42f1a12ba152693a3c0d244d83
    Merge: d4251d0ed6f 14d2a977ce8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:10:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d4251d0ed6f9df5a3acbf97ce7ba8074f126044c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:07:14 2016 +0530
    
        WL#9499 - Remove a WL#7806 test.
    
        The test doesn't really help. It uses very simplistic checks for matching
        path names. It ignores links (soft and hard) completely. Besides during
        recovery the path names will work with the original path names.
    
    commit fba6656350d0a757b2cc936b017329e7f7ce2d32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:51:53 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b522d665d10dca905420cb9119692dffac5024c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:20:30 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 3a9aca50a2e193398d626b5f75d238b5aa704e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:19:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5923cd73fc3af904220dea20b033ffcbb7892606
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:12:44 2016 +0530
    
        WL#9499 - Use custom allocators.
    
    commit 8c5acab2641cedae9542b9ad9405032abbcb4618
    Merge: 1509c43fcff 3c1319b9901
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:21:28 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1509c43fcffb9a849542ef8f3a62e66fda490fc7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:08:34 2016 +0530
    
        WL#9499 - Fix bug, should be decrement in_use, not increment.
    
    commit 0ad783d5e6e3f99817c8b839fe8521f783577d35
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 07:58:49 2016 +0530
    
        WL#9499 - Change fil_node_t::in_use into a reference counter from bool.
    
    commit 3974f1ed40bfbadcee04fa5fc2e60a50b89f930c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 22:10:24 2016 +0530
    
        WL#9499 - Remove an assertion that is no longer an invariant.
    
    commit d79f12dec7c07698f02ce2e0d0396bcd01bdc683
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 21:52:21 2016 +0530
    
        WL#9499 - Rename fil_node_t::being_extended to in_use. Fix test.
    
    commit 1d3368bcf60e2e339d5917251b51201b94dd63a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:57:38 2016 +0530
    
        WL#9499 - Fix log info messages during recovery/apply.
    
    commit d3811bd67248d3ae014f0e6475b1b49524f5c35b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:40:01 2016 +0530
    
        WL#9499 - Don't print % processed if number of records to apply is small.
    
    commit 55af670ff81170da51fbcae6832c3d6191176602
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:21:31 2016 +0530
    
        WL#9499 - Update test with new log message to check.
    
    commit 60c3d6c074ae230ab594015ed2f99e2eefcf97e0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:09:04 2016 +0530
    
        WL#9499 - Record test, because of new config parameter innodb_scan_directories.
    
    commit bd79ff06406c86758a29a28dbe5e7d494a0aa51f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:05:38 2016 +0530
    
        WL#9499 - Remove WL#7142 artefact.
    
    commit bcb753b72b2a01ba35d952cbab45e420929f2b33
    Merge: e30834ecc60 27d64e974ec
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:26:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e30834ecc60522fca8d7b156a66c0765867dea6e
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Thu Aug 25 05:54:26 2016 +0200
    
        WL#9499 - Destroy the mutex in the Fil_Open destructor.
    
    commit a396d4714bdc46626e07d22b6871be153b627bd3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:17:06 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 282ad76aaeaeb6d91bbf81fcd3315f455d9f572c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:12:33 2016 +0530
    
        WL#9499 - Protect changes to Fil_Open state with a mutex.
    
    commit d338cb9468c126ee7e3eeae3bf37b0fc966bbf53
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 07:37:49 2016 +0530
    
        WL#9499 - Fix division by zero.
    
    commit 845324f19ba0a84538b87c072f6d99514533aa25
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:28:45 2016 +0530
    
        WL#9499 - Check for UNDO tablespace names during directory scan.
    
    commit 30ed1d19389e174605fdfc0b7d55fdf544933712
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:26:08 2016 +0530
    
        WL#9499 - Conform to new naming guidelines.
    
    commit 4cf67b352d4c8131064f832ec884db6166d50e71
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 22:04:43 2016 +0530
    
        WL#9499 - Add test for the configuration variable. Add a version number to the file.
    
    commit ad9c5bca0eba1d7bf8e29cd8ebd7062aae089f90
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 21:01:56 2016 +0530
    
        WL#9499 - Code clean up
    
    commit a9e848158909645ead86759ed7ab64789d18a0cb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 15:26:02 2016 +0530
    
        WL#9499 - Print redo apply progress per tablespace
    
    commit 8cf86cf1567cabc1b03b2e8f2ec1167f3c38ce6c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 13:04:55 2016 +0530
    
        WL#9499 - Print tablespace name and % completed per tablespace
    
    commit 35ccdf32d1d048400012a80422072fb41ceb1bbd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 10:35:26 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit c978fb2e18a4e0b4a93b44fc3c75234bcdb3f1f0
    Merge: 8bde4aeb01c 0832bf660e3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 22:25:57 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 8bde4aeb01c3bcdecfb884e566f0ae28797a5b36
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 13:21:10 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 7f502be746cbe0de1a0c3a992217691b167c2fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 12:12:08 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 247bcfda6744a67cc4e53d61658ca87d206b0660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:57:44 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 04509641b086a1b0b2c591573f95957f8a2f1cd0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:50:55 2016 +0530
    
        WL#9499 - Pass the filename directly to the callback
    
    commit 3efa317825886a3ae5d4a3c771fc0770a2c5a3ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 09:39:18 2016 +0530
    
        WL#9499 - Include tchar.h on Windows
    
    commit 55b814d2c2ebdea7c16a6d87a7251ca3f6e83775
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 07:47:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit e4d203688273b562691c912cb9c7024709757490
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 22:02:02 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 31433b21dcabba0a7705eb8b1879beb1d8c36517
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 21:37:41 2016 +0530
    
        WL#9499 - Move Dir_Walker::walk implementation to os0file.cc
    
    commit 11f9016477274c5420782e365b26762067e7b99b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 18:42:28 2016 +0530
    
        WL#9499 - Fix Windows version of Dir_Walk.
    
    commit f32b88e0b1ef99f220165897db745b1dba12f86b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 13:48:03 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b91ad88d96942f1e05443001b7d1c2f6818ff6d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 14:32:25 2016 +0530
    
        WL#9499 - Initialize active ID to filename set from scanned set.
    
    commit 4a09f677ae7095aac9b07f7beccba8e60c50b065
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 13:09:05 2016 +0530
    
        WL#9499 Scan specified directories to build the ID to name mapping.
    
    commit c13b791497e322e6a5cf64ba85da52ee2cf05d45
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:46:53 2016 +0530
    
        WL#9499 - Fix check for incomplete read.
    
    commit 8a849e0288309cec7228612a62fc2bfd71b595e9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:45:04 2016 +0530
    
        WL#9499 - Fix Windows build errors
    
    commit 4fc24b654da26e8411fc45bc96f73ff70dc73e43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:12:12 2016 +0530
    
        WL#9499 - Need to include string for Windows std::wstring.
    
    commit bcb5c2b23f54776e0faaafba2472bb2555aee561
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:02:59 2016 +0530
    
        WL#9499 - On POSIX fopen() mode should be "w+b".
    
    commit b3c7def1931867633d9b8bb601317e99a06c31a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 21:23:57 2016 +0530
    
        WL#9499 - Open file in binary mode for writing.
    
        Otherwise on Windows newline (0x0A) is translated to CRLF (0x0D0A).
    
    commit 0739399cb8a384c07b4b3540b73ade482d083f4a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 20:27:11 2016 +0530
    
        WL#9499 - More error messages during mapping file read. Add a directory walker.
    
    commit 1322de0af2235bc94630f7cb22e4ead1588775ee
    Merge: f266b100e2f 8fdbb2f5f1a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:47:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f266b100e2f23e775e5e04de8d26301d7f2f1072
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:18:07 2016 +0530
    
        WL#9499 - Flush the tablespace to mapping file buffers before fsync()
    
    commit 7c92536686033c2c70e7df831d569c1cd6f871f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:32:26 2016 +0530
    
        WL#9499 - Remove unused member variable m_lsn.
    
    commit 994c4766ef712e7da668788d0bdd648cbd764982
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:25:05 2016 +0530
    
        WL#9499 - Don't crash on uncompress failure. Try the next file if any.
    
    commit a419a190cdf734e3beca08d339c6c0d307ddff5f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:21:49 2016 +0530
    
        WL#9499 - Print an error code on uncopress failure
    
    commit 77cb39000e098ba4d06873723423521e6889a7d0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:12:11 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit afc632e0ef768542a96d4d15a897cb1780825d2e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 11:34:44 2016 +0530
    
        WL#9499 - Compress the tablespace open state file.
    
    commit 568c9e758084f671007789f7b5d1c996f5df39a0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 09:12:39 2016 +0530
    
        WL#9499 - Free the buffer on return
    
    commit 0f468cf8e50b9605a9e6c4e93c818b0f876c3c29
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 08:42:38 2016 +0530
    
        WL#9499 - Remove protobuf
    
    commit e789eb175d2da90cee2d46e30b91e623546f9e96
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 18 09:59:37 2016 +0530
    
        WL#9499 - Get native HANDLE
    
    commit 6014c5853c09fee75256f9de6a86a5fc0ea18508
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:50:37 2016 +0530
    
        WL#9499 - Use _fileno() on Windows
    
    commit 61e6b4d7c033d48b775b22c4ad6d6b4858cd4cd7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:37:01 2016 +0530
    
        WL#9499 - Use buffered IO for open state file writes
    
    commit 98f40b10c15e49d9a5e14689cdb34758bdf85a05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 12:36:06 2016 +0530
    
        WL#9499 - Don't complain about corrupted encrypted pages during dblwr recovery
    
    commit c674939cbdeaa4a9996960de0fa4e74954ad6f76
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 09:21:06 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for generated sources too.
    
    commit ff68ba26aeaa27070ceeaa8db4472a9ce4daa3c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 08:33:03 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for fil/fil0fil.cc
    
    commit 445985ca11810c528567a4222cad4a7f0ce49e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 19:44:29 2016 +0530
    
        WL#9499 - Read/Write open state files using absolute paths
    
    commit b4d91d3799d94eb2677be6512752ec27dfa5e0f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 14:37:40 2016 +0530
    
        WL#9499 - Fix doxygen errors
    
    commit 8be2de3b3077c0d0f26340c9c80f7ae2247eefbc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 11:20:24 2016 +0530
    
        WL#9499 - Record test, MLOG_FILE_NAME doesn't exist anymore
    
    commit 54e64dc4a97f5bf4b5606cea1841dfc1f04fe536
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 10:41:01 2016 +0530
    
        WL#9499 - Add protobuf library to the embedded library.
    
    commit 83b0fb38283e285e1e963dd2c7c144d70b130338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 21:17:13 2016 +0530
    
        WL#9499 - Improved DBLWR and System table checks and code cleanup
    
        1. Remove dead code
        2. If some pages from the dblwr buffer were not recovered during recovery
           because of a missing tablespace id -> name mapping. Check the tablespace
           ID against the Tablespaces meta-data after recovery.
        3. Track open of the system tablespace. Check if the name of any file
           has changed. We don't rename the system tablespace.
    
    commit 5ebfba1e083f6a1d2b70946b91a02d32733c7e87
    Merge: 7a1b724c04b 0c27bf6fc44
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Mon Aug 15 11:40:07 2016 +0200
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7a1b724c04bf9d2e4aba0e58fb95dc8fc75d55c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 15:07:47 2016 +0530
    
        WL#9499 - Free deferred page memory
    
    commit 4de5d3b03670e4d2e8ebce89e8b3f104968eb3e1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:45:25 2016 +0530
    
        WL#9499 - Remove unrelated changes
    
    commit c9e83914232480501b139c36ef616798a2ac1d05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:28:19 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 6ecdb21d63ef6dd5a6aff997720178ff6510f0d5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 13 14:31:52 2016 +0530
    
        WL#9499 - Don't exit if no open state files found

[33mcommit 30586c7aa3fc005e0c64d9c9701f165e999895ec[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Tue Feb 21 05:37:31 2017 +0100

    WL#9720: SET PERSIST capture user, host and timestamp
    WL#9763: Support option to RESET PERSIST
    
    WL#9720 introduces 3 new columns to [1;31mperf[mormance_schema.variables_info table.
    SET_TIME - represents timestamp of when a system variable was changed.
    SET_USER - represents who has changed the system variable.
    SET_HOST - represents host on which the system variable was changed.
    Whenever a system variable is changed using SET statement
    [1;31mperf[mormance_schema.variables_info table will get updated accordingly.
    
    WL#9763 introduces RESET PERSIST [IF EXISTS] variable; statement which lets
    variable to be removed from persistent config file mysqld-auto.cnf. This WL
    also introduces new [1;31mperf[mormance_schema.persisted_variables table which will
    be an exact copy of mysqld-auto.cnf file. This enables user to see what's in
    the file at the SQL level without having to access the file itself.

[33mcommit d34d68e74eb7656a7bcff9f306167a9b5d3c2ec0[m
Author: Hans H Melby <hans.h.melby@oracle.com>
Date:   Fri Jan 20 09:26:04 2017 +0100

    BUG #23280574 ASSERTION FAILED: !NO_DATA(NBYTES) IN GEOMETRY::WKB_PARSER::SKIP_UNSAFE()
    
    Applying the following queries:
    
    set sql_mode="";
    do st_exteriorring(convert(geometrycollection(point(1,1)) using utf8mb4));
    
    Causes an assertion failure due to an operation being [1;31mperf[mormed on a WKB
    string believed to be longer than it really is due to its header content.
    
    Solution: In Gis_geometry_collection::scan_header_and_create,
    check that POINT geometries are long enough before setting the mflags.nbytes
    variable. Also, as an additional safety measure, change skip_unsafe() to skip()
    in the Gis_geometry_collection::get_data_size() function. This will cause the
    function to return due to lack of data before attempting to [1;31mperf[morm an
    operation on an invalid geometry.
    
    A test case is added in the main.gis test file
    
    Change-Id: I04e4a3ded06ada75d907ae08e2c4a98a5cecb741

[33mcommit 334f8d5045fbf3275e7a619ce2a85c927b8fdf7c[m
Author: Anitha Gopi <anitha.gopi@oracle.com>
Date:   Fri Feb 10 03:21:59 2017 +0100

    Bug #24688694   SEVERAL UNSTABLE TESTS IN SUITE PERFSCHEMA
    
    Disabled [1;31mperf[mschema.idx_metadata_locks which is failing very frequently.
    
    Reviewed by : Erlend.Dahl@oracle.com

[33mcommit bd265c4d4c69b7641d353ecd50fe0378d4b87075[m
Merge: 1f746206f2a 7e114949f6a
Author: Jimmy Yang <jimmy.yang@oracle.com>
Date:   Thu Feb 9 18:25:35 2017 +0800

    Merge branch 'mysql-trunk' into mysql-trunk-meta-sync
    
    Conflicts:
            mysql-test/suite/i_innodb/t/disabled.def
            mysql-test/suite/i_innodb/t/innodb_bug17305626.test
            mysql-test/suite/i_innodb/t/innodb_bug17463290.test
            mysql-test/suite/i_innodb/t/strict_mode-bug20144839.test
            mysql-test/suite/i_main/t/bug13418638.test
            mysql-test/extra/rpl_tests/rpl_split_statements.test
            mysql-test/extra/rpl_tests/rpl_split_statements_debug.test
            mysql-test/r/create.result
            mysql-test/r/create_ps_protocol.result
            mysql-test/r/dd_debug.result
            mysql-test/r/dd_schema_definition_debug_ci.result
            mysql-test/r/dd_schema_definition_debug_cs.result
            mysql-test/r/dd_stages.result
            mysql-test/r/drop_debug.result
            mysql-test/r/group_min_max_ps_protocol.result
            mysql-test/r/mysqld--help-notwin.result
            mysql-test/r/mysqld--help-win.result
            mysql-test/r/partition_explicit_prune.result
            mysql-test/r/partition_locking.result
            mysql-test/r/partition_locking_ps_protocol.result
            mysql-test/r/table_definition_cache_functionality.result
            mysql-test/suite/binlog/t/disabled.def
            mysql-test/suite/funcs_1/r/is_statistics.result
            mysql-test/suite/funcs_1/r/is_statistics_ci.result
            mysql-test/suite/funcs_1/t/is_statistics.test
            mysql-test/suite/innodb/r/create_tablespace.result
            mysql-test/suite/innodb/r/innodb.result
            mysql-test/suite/innodb/r/innodb_force_recovery.result
            mysql-test/suite/innodb/r/innodb_misc1.result
            mysql-test/suite/innodb/t/innodb_bug-13628249.test
            mysql-test/suite/innodb/t/innodb_force_recovery.test
            mysql-test/suite/innodb_zip/r/16k.result
            mysql-test/suite/parts/inc/partition_exchange.inc
            mysql-test/suite/parts/r/partition_exchange_innodb.result
            mysql-test/suite/[1;31mperf[mschema/r/alter_table_progress.result
            mysql-test/suite/rpl_gtid/r/rpl_gtid_split_statements_debug.result
            mysql-test/suite/rpl_gtid/t/rpl_gtid_split_statements_debug.test
            mysql-test/suite/rpl_nogtid/r/rpl_no_gtid_split_statements_debug.result
            mysql-test/suite/rpl_nogtid/r/rpl_row_ignorable_event.result
            mysql-test/suite/rpl_nogtid/t/rpl_no_gtid_split_statements_debug.test
            mysql-test/t/dd_debug.test
            mysql-test/t/dd_stages.test
            mysql-test/t/drop_debug.test
            mysql-test/t/no_binlog_gtid_next_partially_failed_stmts.test
            rapid/plugin/group_replication/tests/mtr/t/disabled.def
            sql/binlog.cc
            sql/dd/cache/dictionary_client.h
            sql/dd/dd_table.cc
            sql/dd/dd_upgrade.cc
            sql/dd/dd_view.cc
            sql/dd/dd_view.h
            sql/dd/impl/bootstrapper.cc
            sql/dd/impl/cache/dictionary_client.cc
            sql/dd/impl/properties_impl.h
            sql/dd/impl/system_registry.cc
            sql/dd/impl/types/partition_impl.h
            sql/dd/types/index.h
            sql/dd_sql_view.cc
            sql/dd_table_share.cc
            sql/dd_table_share.h
            sql/field.cc
            sql/handler.h
            sql/item_func.cc
            sql/partitioning/partition_handler.h
            sql/share/errmsg-utf8.txt
            sql/sql_base.cc
            sql/sql_partition_admin.cc
            sql/sql_rename.cc
            sql/sql_rename.h
            sql/sql_table.cc
            sql/sql_table.h
            sql/sql_tablespace.cc
            sql/sql_truncate.cc
            sql/sql_view.cc
            sql/sql_yacc.yy
            storage/innobase/dict/dict0stats_bg.cc
            storage/innobase/handler/ha_innodb.cc
            storage/innobase/handler/ha_innodb.h
            storage/innobase/handler/ha_innopart.cc
            storage/innobase/handler/ha_innopart.h
            storage/innobase/handler/handler0alter.cc
            storage/innobase/pars/pars0sym.cc
            storage/innobase/row/row0uins.cc
            storage/innobase/row/row0umod.cc
            storage/innobase/srv/srv0srv.cc
            storage/innobase/trx/trx0roll.cc
            unittest/gunit/base_mock_handler.h
            unittest/gunit/dd_cache-t.cc

[33mcommit 4a14fb77732a8e9cb2bed1ac70bfa6004644bdab[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Feb 8 16:53:37 2017 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Post-push fix: Add a missing inline declaration that would cause [1;31mperf[mormance
    regressions on the string length microbenchmark with -O2 (instead of -O3).
    
    Change-Id: I6a576557606ff1aafed1f51340b578028c80227e

[33mcommit 7e114949f6a464df74b17d272e5cd644ca9893c8[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Wed Feb 8 10:37:17 2017 +0530

    BUG#24806741 : MTR: INTRODUCE "EXPR" COMMAND
    
    Description :
    =============
    MTR cannot do basic math operations like +, -, /, *, %, &&, || etc.
    Current way is to invoke SQL command to do these operations. But using
    mysqld server for these basic operations is slow and not right.
    
    Fix :
    =====
    Introduced new MTR command 'expr' to [1;31mperf[morm basic mathematical
    operations.
    
    "--expr $<var_name>= <operand1> <operator> <operand2>"
    
    Both <operand1> and <operand2> should be valid MTR variables. 'expr'
    command supports only binary operators that operates on two operands
    and manipulates them to return a result.
    
    E.g:
    
    --let $val1= 10
    --let $var2= 20
    --expr $res= $var1 + $var2
    --echo $res
    
    Following mathemiatical operators are supported.
    
    1 Arithmetic Operators
      1.1 Addition
      1.2 Subtraction
      1.3 Multiplication
      1.4 Division
      1.5 Modulo
    
    2 Logical Operators
      2.1 Logical AND
      2.2 Logical OR
    
    3 Bitwise Operators
      3.1 Binary AND
      3.2 Binary OR
      3.3 Binary XOR
      3.4 Binary Left Shift
      3.5 Binary Right Shift
    
    NOTE
    1. Non-integer operand is truncated to integer value for operations
       that dont support non-integer operand.
    2. If the result is an infinite value, then expr command will return
       'inf' keyword to indicate the result is infinity.
    3. Division by 0 will result in an infinite value and expr command
       will return 'inf' keyword to indicate the result is infinity.
    
    Reviewed-by: Deepa Dixit <deepa.dixit@oracle.com>
    Reviewed-by: Srikanth B R <srikanth.b.r@oracle.com>
    RB: 14788

[33mcommit b4777fa549df1b7e37743455c0066c11ea26bec0[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Wed Feb 1 10:01:05 2017 +0100

    WL#9185 MySQL Cluster support for new DD
    
     - when [1;31mperf[morming inplace alter table, serialize the table
       definition from data dictionary and save it as extra metadata
       in NDB's dictionary.
     - rename inplace_alter_frm() to inplace_set_sdi_and_alter_in_ndb()
     - reorganize inplace_set_sdi_and_alter_in_ndb() to be a static
       helper function which does not use anything from ha_ndbcluster

[33mcommit 08967b87d6b3519306f525ec938e1351bb91bdf0[m
Author: Allen Lai <zheng.lai@oracle.com>
Date:   Thu Jan 26 09:45:10 2017 +0100

    Fixed test case [1;31mperf[mschema.alter_table_progress by recording new result file.

[33mcommit 3fe49d455680e74d2e7c18348d8ac5cee6127fc0[m
Author: Srikanth B R <srikanth.b.r@oracle.com>
Date:   Wed Jan 25 11:12:27 2017 +0530

    Bug#25447553 FEW PERFSCHEMA.IDX_COMPARE_* TESTS FAIL DUE TO LIMIT OF
                 100 ON P_S_USERS_SIZE
    
    Issue
    -----
    The default_mysqld.cnf file used by MTR includes 'loose-[1;31mperf[mormance-
    schema-users-size=100' which effectively limits the number of users
    stored in the [1;31mperf[mormance schema users/accounts tables to 100 and
    doesn't record any user/account created further. As a result, few
    [1;31mperf[mschema.idx_compare_* tests fail when run after a test which
    creates connections with around 100 users on an MTR worker (eg:
    main.server_offline_5) as these tests add users and validate if
    they are reflected in the preformance schema.
    
    Fix
    ---
    Clean-up residual entries(from previous test runs on the worker) in
    [1;31mperf[mormance_schema 'users' and 'accounts' tables for the failing
    tests.
    
    Reviewed-by: Chris Powers  <chris.powers@oracle.com>
    Reviewed-by: Mayank Prasad <mayank.prasad@oracle.com>
    RB: 15197

[33mcommit 3d307e5e2ee246443920bf0d2431de6fa7e30eb3[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Sat Jan 21 06:41:32 2017 +0100

    WL#9494 Implement INFORMATION_SCHEMA system views for ROUTINES/TRIGGERS/EVENTS
    
    This WL should implements following INFORMATION_SCHEMA
    tables as system view over data dictionary tables.  This
    implements WL#6599 Phase 2) activities from
    "HLS/3) Development plan".
    
    This patch does following,
    
    A) Implement following tables as system views:
    
      INFORMATION_SCHEMA.TRIGGERS
      INFORMATION_SCHEMA.ROUTINES
      INFORMATION_SCHEMA.PARAMETERS
      INFORMATION_SCHEMA.EVENTS
    
    B) Implements following SHOW commands over system views
       defined in A)
    
      SHOW TRIGGERS
      SHOW PROCEDURE/FUNCTION
      SHOW EVENTS
    
    C) Implements following UDFs used by A) to check access on the
       objects to be displayed.
    
      CAN_ACCESS_TRIGGER() - Checks if user has access on trigger.
      CAN_ACCESS_ROUTINE() - Checks if user has access on routine.
      CAN_ACCESS_EVENT() - Checks if user has access on event.
    
    D) Adds new data dictionary tables columns to stored data
       type in string form.  This is similar to
       mysql.columns.data_type_utf8.
    
      mysql.routines.result_data_type_utf8
      mysql.parameters.data_type_utf8
      mysql.routines.result_data_type_utf8
    
    Notes:
    
    - Removed related old INFORMATION_SCHEMA code.
    
    - There are no dynamic information schema columns whose
      values are read from storage engine in I_S tables in the
      scope of this WL.  So, the 'information_schema_stats'
      variable would not play any role in implementation of this
      WL.
    
    - Compatibility differences are same as we have see in
      WL#6599.  Some of them applies to this WL are 6.b, 6.c, 6.d,
      6.g listed under Section 6.
    
    - The Bug#24420809 gets fixed by the implementation. We
      will not be able to reproduce the problem and hence we
      have removed the test case.
    
    - A scenario in test Bug#12828477 could be used to present
      [1;31mperf[mormance gain from this WL. Probably useful when we
      plan to benchmark.
    
    - In 5.7 SHOW TRIGGERS skips displaying triggers whose
      trigger body is possibily corrupt. However, we know that
      I_S.ROUTINES does not skip the routine entries whose body
      might be corrupt. So, this WL tries to keep the behavior
      consistent and makes SHOW TRIGGERS to display triggers
      even in case when their body is corrupted. Note that, with
      the introduction of data dictionary the triggers/routine
      body is stored in transactional InnoDB engine the
      possiblity of corruption is avoided. So, this change
      would not be really be seen, until DD is corrupt.
    
      With this change, SHOW TRIGGERS in the test
      main.trigger-compat-debug now displays the trigger entries
      even if trigger body seem to be corrupted now.
    
    - This WL introduces changes in the DD tables. Since we do
      not yet support upgrading the DD, this means that a new
      server will not run successfully on an old data directory.

[33mcommit 485545bb2bf2c5c22ea7e59101e61ecd38e26842[m
Author: Mohit Joshi <mohit.joshi@oracle.com>
Date:   Tue Jan 17 11:56:43 2017 +0530

    Bug#25166686::REMOVE ALL THE REDUNDANT .INC FILES FROM MTR
    
    Description:
    It is noticed that there are a lot of redundant inc files which
    are not being used by any of the MTR tests. Also, there are several
    inc files which are included in the test but are not needed
    anymore.
    
    Fix:
    
    Below inc files are not being used by any test and hence removed:
    
    1.  include/check_key_reads.inc
    2.  include/check_key_req.inc
    3.  include/commandline_option_test.inc
    4.  include/config_file_option_test.inc
    5.  include/explain.inc
    6.  include/finish_option_test.inc
    7.  include/have_binlog_checksum_off.inc
    8.  include/have_dynamic_loading.inc
    9.  include/have_shm.inc
    10. include/init_option_test.inc
    11. include/not_blackhole.inc
    12. include/show_partition_checksums.inc
    13. include/show_partition_contents.inc
    14. include/test_outfile.inc
    
    Below are a few inc files which are used in MTR tests but are no more needed.
    Hence these inc files along with their references from all MTR tests have been
    removed.
    
    1. have_symlink.inc
    2. have_[1;31mperf[mschema.inc
    3. have_innodb.inc
    
    Note: include/not_valgrind_server.inc is not being used by any MTR test but
    still not removed as this was introduced as part of Bug#22447330
    
    Reviewed by:
    Parveez Baig <parveez.baig@oracle.com>
    Deepa Dixit <deepa.dixit@oracle.com>

[33mcommit bb1676c02a12b8ddfe7de0c36fcace97acac8a52[m
Merge: 80746ba3743 e0809670eff
Author: Jimmy Yang <jimmy.yang@oracle.com>
Date:   Tue Jan 17 13:00:57 2017 +0800

    Merge branch 'mysql-trunk-wl7743-wip-3' into mysql-trunk-meta-sync-merge3
    
    Conflicts:
            mysql-test/suite/i_innodb/t/disabled.def
            mysql-test/collections/default.push
            mysql-test/include/excludenoskip.list
            mysql-test/r/create_ps_protocol.result
            mysql-test/r/dd_schema_definition_debug_ci.result
            mysql-test/r/dd_schema_definition_debug_cs.result
            mysql-test/r/dd_stages.result
            mysql-test/r/group_min_max_ps_protocol.result
            mysql-test/r/mysqld--help-win.result
            mysql-test/r/partition_explicit_prune.result
            mysql-test/r/partition_locking.result
            mysql-test/r/partition_locking_ps_protocol.result
            mysql-test/suite/funcs_1/r/is_statistics.result
            mysql-test/suite/funcs_1/r/is_statistics_ci.result
            mysql-test/suite/innodb/r/create_tablespace_32k.result
            mysql-test/suite/innodb/r/create_tablespace_4k.result
            mysql-test/suite/innodb/r/create_tablespace_64k.result
            mysql-test/suite/innodb/r/create_tablespace_8k.result
            mysql-test/suite/innodb/r/innodb-system-table-view_cs.result
            mysql-test/suite/innodb/r/innodb.result
            mysql-test/suite/innodb_zip/r/16k.result
            mysql-test/suite/[1;31mperf[mschema/r/alter_table_progress.result
            mysql-test/suite/[1;31mperf[mschema/t/disabled.def
            mysql-test/suite/[1;31mperf[mschema/t/statement_digest_long_query.test
            mysql-test/t/disabled.def
            sql/binlog.cc
            sql/dd/dd_table.cc
            sql/dd/impl/system_registry.cc
            sql/item_create.cc
            sql/sql_partition_admin.cc
            sql/sql_table.cc
            sql/sql_truncate.cc
            storage/innobase/api/api0api.cc
            storage/innobase/dict/dict0dict.cc
            storage/innobase/dict/dict0load.cc
            storage/innobase/dict/dict0stats_bg.cc
            storage/innobase/fsp/fsp0sysspace.cc
            storage/innobase/fts/fts0fts.cc
            storage/innobase/fts/fts0opt.cc
            storage/innobase/handler/ha_innodb.cc
            storage/innobase/handler/ha_innopart.cc
            storage/innobase/handler/handler0alter.cc
            storage/innobase/handler/i_s.cc
            storage/innobase/include/dict0mem.h
            storage/innobase/log/log0recv.cc
            storage/innobase/pars/pars0pars.cc
            storage/innobase/row/row0ftsort.cc
            storage/innobase/row/row0import.cc
            storage/innobase/row/row0ins.cc
            storage/innobase/row/row0sel.cc
            storage/innobase/row/row0upd.cc
            storage/innobase/srv/srv0srv.cc
            storage/innobase/srv/srv0start.cc
            storage/innobase/sync/sync0debug.cc
            storage/innobase/trx/trx0trx.cc

[33mcommit 41e628dda2869a0411a9f5fce9a01ccb9767e4be[m
Author: Praveenkumar Hulakund <praveenkumar.hulakund@oracle.com>
Date:   Fri Jan 13 12:25:26 2017 +0100

    BUG#24751177: ASSERTION `STRLEN(DB_NAME) <= (64*3) && STRLEN(TABLE_NAME) <= (64*3)' FAILED.
    
    EXPLAIN/DESCRIBE of a table where the database name or the table
    name is beyond the maximum supported length, an assert is triggered
    in the debug build instead of reporting an error. In case of non
    debug build, appropriate error is displayed.
    
    During EXPLAIN/DESCRIBE, the temporary tables are processed
    first followed by the regular tables. So we look up for the
    temporary tables in the THD's temporary table list first. But
    validation of database name and table name is done later in the
    add_table_to_list(). Hence assert conditions to check length of
    the table or db name while [1;31mperf[morming the look up in the temporary
    table list failed.
    
    In the current code, schema table implementation is used if
    table is a temporary table or else new information schema
    implementation(introduced by WL6599) is used. But [1;31mperf[morming a
    look up in temporary table list before validating db and table
    name looks incorrect.
    
    As part of this patch, refactored code to validate db and table
    name before [1;31mperf[morming table look up in temporary table list to
    fix this issue.
    
    Code refactoring involves following changes,
    
    1) SHOW COLUMNS/SHOW INDEX implementation is moved to the new
       style,
       1.1 Parse_tree_node is introduced for the SHOW COLUMNS/SHOW
           INDEX statements.
    
       1.2 The decision of choosing schema table or new information
           schema implementation is moved to the contextualization
           stage.
            1.2.1 At this stage, table used in statement is validated
                  first in add_table_to_list() and then lookup
                  in temporary table list is [1;31mperf[mormed.
    
       1.3 Sql_cmd_show is implemented to execute action for these
           statements.
    
    2)  mysql_test_show() is cleaned up to remove the dead code.

[33mcommit 9d684300ed3ec95e8a982447fb1bb777923ec360[m
Merge: cafce7e68eb 3ffa7622228
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Wed Jan 11 13:49:08 2017 +0300

    Merge remote-tracking branch 'origin/mysql-trunk' into mysql-trunk-wl7743-wip-3
    
    Conflicts:
            storage/blackhole/ha_blackhole.cc
            storage/blackhole/ha_blackhole.h
            storage/example/ha_example.cc
            storage/example/ha_example.h
            storage/heap/ha_heap.cc
            storage/heap/ha_heap.h
            storage/myisam/ha_myisam.cc
            storage/myisam/ha_myisam.h
            storage/[1;31mperf[mschema/ha_[1;31mperf[mschema.cc
            storage/[1;31mperf[mschema/ha_[1;31mperf[mschema.h

[33mcommit d2ae49d1ad9cf3160bb4bfa35db742b6861775f8[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Tue Jan 10 15:53:02 2017 +0100

    Bug#25339088 REGRESSION IN SYSBENCH/POINT_SELECT DUE TO CTE WL
    
    Revert the patch for this bug.
    Because, even though testing showed it gained back all lost
    [1;31mperf[mormance, something in the time window between testing and push
    changed the conditions and the pushed patch ended up losing
    [1;31mperf[mormance.

[33mcommit 2942aa5dc461b3a96348ab77727237c6915acc67[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Sat Jan 7 14:57:49 2017 +0100

    Bug#25339088 REGRESSION IN SYSBENCH/POINT_SELECT DUE TO CTE WL
    
    The WL added 4 integers and one pointer to TABLE_SHARE (one of those
    integers was actually moved from TABLE). This caused a repeatable 4% drop
    in [1;31mperf[mormance in sysbench's point_select test.
    Fix: replace those 5 members with a single pointer to a separate
    structure specific ot internal temporary tables; other tables
    logically shouldn't reserve room for useless information.
    This fully regains the lost [1;31mperf[mormance.
    As the struct is specific of tmp tables, removed the "tmp" word
    from members' names.
    Do initialization of the structure in init_tmp_table_share; adding a
    new argument to that latter function, with default NULL; using that
    opportunity to make the previous argument (MEM_ROOT*), added by the
    CTE WL, have a similar default, so most calls become shorter (as they
    were before the CTE WL).
    Limiting to max 1024 references to a single CTE so that we can use a
    short type (uint16) for handler_count to have a small struct (and this
    limit makes sense anyway). Adding error message and test of this limit.

[33mcommit 52692f4fd754ab701995d536a0f7e71bb7ecadf9[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Fri Jan 6 04:30:11 2017 +0100

    Bug#24688694 SEVERAL UNSTABLE TESTS IN SUITE PERFSCHEMA
    
    Disable [1;31mperf[mschema.stage_mdl_table

[33mcommit 44bb2e6dd187dc5917cf8cdac362ee0146c77698[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Jan 2 13:16:33 2017 +0100

    Bug #25336715: ADD AN OPTION TO RANDOMIZE LINK ORDER
    
    We keep seeing spurious [1;31mperf[mormance changes that we believe are caused by lucky
    or unlucky alignment of code, and that tend to go away by themselves at a later
    stage. This commit adds a CMake flag (-DLINK_RANDOMIZE=ON) that randomizes the
    order of almost all symbols in the mysqld binary; the idea is that if a
    regression between binaries A and B (presumably at different versions) are
    detected, one can randomize both sides to test randomize(A) vs. randomize(B)
    and see if the regression still holds. If the randomized versions are the
    same, it's much more likely to be random.
    
    The randomization is reproducable, as it works by hashing the function name
    together with a seed (which can be set by -DLINK_RANDOMIZE_SEED=).
    
    It's not recommended to use this flag for regular builds, especially as it
    causes somewhere around 5% [1;31mperf[mormance regression in sysbench; the default
    order (ie., just keep the order from each source code file, and link object
    files in the order they are given on the command-line) is quite good for
    reducing TLB misses, as it puts related functions together.
    
    I haven't tested actually reproducing historical spurious regressions
    with this (it would probably mean running quite large benchmarks), so it's
    somewhat experimental, but should be used next time we debug such a regression.
    Different seeds make for differences in some microbenchmarks, which is a good
    indication that it would have a real measurement effect.
    
    Change-Id: Ide109371bd99390bd79b1809d771c444ac70b837

[33mcommit d450ab5d679b68951c4ee2232cf785f63caab21f[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Wed Dec 14 11:45:01 2016 +0530

    WL#9711 : Remove *.require files
    
    Description :
    =============
    In MTR we have *.require files to [1;31mperf[morm checks. But these require
    files are not necessary to [1;31mperf[morm a check and adds an extra overhead.
    Instead of using require files, the check for the condition can be
    implemented in corresponding inc files.
    
    E.g:
    
    1) have_debug_sync.inc
    ----------------------
    require r/have_debug_sync.require;
    disable_query_log;
    let $value=query_get_value(SHOW VARIABLES LIKE 'debug_sync', Value, 1);
    eval SELECT ('$value' LIKE 'ON %') AS debug_sync;
    enable_query_log;
    
    2) have_debug_sync.require
    --------------------------
    debug_sync
    1
    
    The way this works is that '--require' causes the result of the next
    query to be written to a temporary file and then there is a file
    comparison of the temporary file and, in this case,
    have_debug_sync.require.
    
    This sounds much slower than it could be. And also there are issues on
    Windows where a test can fail simply because of line ending differences.
    
    This WL removes all these require files and implements the check in
    the corresponding inc file. If '--require' command is used in any of
    the test file/inc file, MTR will error out with a deprecation message.
    
    E.g:
    
    Modified have_debug_sync.inc
    ----------------------------
    let $have_debug_sync= query_get_value(SHOW VARIABLES LIKE 'debug_sync', Value, 1);
    if ($have_debug_sync == 'No such row')
    {
      skip Test requires 'have_debug_sync';
    }
    
    Reviewed-by: Anitha Gopi <anitha.gopi@oracle.com>
    Reviewed-by: Deepa Dixit <deepa.dixit@oracle.com>
    Reviewed-by: Magnus Blåudd <magnus.blaudd@oracle.com>
    RB: 14686

[33mcommit 7aae987b29448c47ed97fad23769a99308b742ca[m
Author: Aakanksha Verma <aakanksha.verma@oracle.com>
Date:   Wed Dec 7 15:41:50 2016 +0530

    Bug #14025581 FILE IO INSTRUMENTATION DISABLED IN PERFORMANCE SCHEMA FOR INNODB
    
    Post Push fix for [1;31mperf[mormance regression on windows trunk.
    
    Reviewed by : Jimmy Yang <Jimmy.Yang@oracle.com>

[33mcommit 075acb08ad5ebaf3425ab3c3bcfd2c38252854f3[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Dec 1 11:15:54 2016 +0100

    Bug #24526123 ADAPTIVE SEND ALGORITHM IS BROKEN
    
    The 'adaptive send strategy' was physically removed from the
    code as part of the 'ATC-patches' and 'forceSend' enforce
    independent of which kind of 'send' was specified.
    
    This patch reintroduce an improved version of the adaptive
    send algorithm. Performance test shows that it [1;31mperf[morms equal
    with the 'force*send' for a lower number ( <= ~20) of client
    threads, and [1;31mperf[morms increasingly better with higher number
    of threads.
    
    Details from the patch:
    
    part 1:
        Introduce the TransporterFacade member 'NodeBitmask m_active_nodes'
        which is a bitmap of all m_send_buffers[MAX_NODES] having
        '::m_node_active == true'
    
        Replace the loop(s) iterating m_send_biffers[] from
        1..MAX_NODES to instead iterate the set bits in m_active_nodes.
    
    Part2:
        Introduce the TransporterFacade member
        'Uint32 m_poll_waiters'. Keep track of number of trp_clients
        waiting in the receiver poll queue.
    
        Will later be used as a metric to measure the API
        activity level in the adaptive send algorithm.
    
    Part3:
        Fix const correctness in methods related to 'send'
    
    Part4:
        Introduce the trp_client member
        'NodeBitmask m_flushed_nodes_mask' containing the set
        of nodes this trp_client has flushed, but possibly unsent,
        messages to.
    
    Part5:
        Introduce the TransporterFacade::TFSendBuffer member
        'Uint32 m_flushed_cnt'. Will count the number of 'flush' to
        this buffer which has not yet been sent.
    
        Will later be used as a metric to the adaptive flush
        algorithm to decide whether a message should be sent immediately,
        or if we should wait for possible some more messages to the
        same node to become available.
    
    Part6: refactor:
    
        - Refactor the common 'send to all nodes' loop found in
          both the send thread and in ::do_forceSend() into the
          new method try_send_all().
    
        - Factored out the 'send part' from ::flush_and_send_buffer()
          into the new method ::try_send_buffer()
    
        - Entirely removed the method flush_and_send_buffer().
          Replaced with first calling flush_send_buffer(),
          then try_send_all()
    
        - Introduced the new TransporterFacade member
          'NodeBitmask m_has_data_nodes' which maintain the set
          of datanodes having 'more_data' to be sent. These will
          need attention from the send thread.
    
        - Refactor the send thread to take advantage of new methods
          and members above. Instead of sending to all 'active'
          nodes in each iteration, it will now only send to the
          nodes which 'has_data' - Except every 'sendThreadWaitMillisec'
          where it will also include all 'active' nodes.
    
        - Refactor trp_client::do_forceSend() to take advantage
          of new members above. No functional change (yet)
    
    Part7:
        Introduce NdbCondition_ComputeAbsTime_ns()
    
        The existing NdbCondition_ComputeAbsTime() takes a millisecond
        argument to calculate an 'AbsTime' for the conditional wait
        to wait until. The adaptive send algorithm will need
        an 'AbsTime' caculation with at least micro second resolution.
    
    Part8:
        Introduce the adaptive send
        algorithm. Change trp_client::do_forceSend() to
        use the send type specified instead of always 'forceSend'.
    
        See patch itself for fairly extensive comments about
        how the adaptive send is implemented.

[33mcommit 8e00e0159d06331dc238601b51bb45ed87597b81[m
Author: Christopher Powers <chris.powers@oracle.com>
Date:   Wed Nov 30 12:29:51 2016 -0600

    Bug#24519021 FEW XA TESTS FAIL IN WAIT_COND'N.INC AS VIEW ON P_S.THREADS...
    
    Follow-up to original fix a545bdd6e310cbf9:
    1. variables_by_thread: Remove index increment in rnd_pos() -- has no effect
    2. events_waits_*: Return HA_ERR_RECORD_DELETED if make_row() fails -- detected
                       by daily-trunk/solaris11/rqg_[1;31mperf[mormance_schema 2016-11-23

[33mcommit 1884289a0f9949aabda55a611c01abdd5794e1de[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Wed Nov 30 10:37:48 2016 +0100

    Bug #22655287: MYSQLDUMP GENERATES INVALID SCRIPT DUE TO DDL ON DICTIONARY TABLES
    Problem: mysqldump/mysqlpump when used to dump mysql database, system metadata
    tables mysql.innodb_table_stats, mysql.innodb_index_stats are also dumped, thus
    causing error during restore. This error is due to DDL operation [1;31mperf[mormed on these
    tables.
    Fix: Fix is to avoid DDL statements on these tables and dump only data rows.

[33mcommit 7c24e9bd619304dd7655f4fee4ef52a238d25d13[m
Author: Daniel Blanchard <daniel.blanchard@oracle.com>
Date:   Fri Nov 25 12:55:56 2016 +0000

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO
    UTF8MB4
    
    Windows specific [1;31mperf[mormance improvement: htons is not as efficient
    compiled with MSVC as the platform intrinsic _byteswap_ushort.
    
    Benchmark results (Intel Xeon @2.89GHz, CL 19.0 /O2):
    
    sysbench goes from 3611 -> 3861 tps (+6.9%).
    
    Change-Id: Idb6f93a5d41a32358a46eadd9ec68ece2056c296

[33mcommit 4bf48e8bf0d572fafc0349a3d7e9376b781a1302[m
Author: Oystein Grovlen <oystein.grovlen@oracle.com>
Date:   Fri Nov 25 13:32:20 2016 +0100

    WL#8737 IO aware defaults for optimizer cost constants
    
    Update default values for optimizer cost constants. New values are:
    
      row_evaluate_cost             0.1
      key_compare_cost              0.05
      memory_temptable_create_cost  1.0
      memory_temptable_row_cost     0.1
      disk_temptable_create_cost    20.0
      disk_temptable_row_cost       0.5
      memory_block_read_cost        0.25
      io_block_read_cost            1.0
    
    Changes to source files:
    
    sql/opt_costconstants.cc
      Changed default values for cost constants.
    sql/sql_select.h
      Change type of JOIN_TAB::read_time from ha_rows to double since cost may now
      be lower than 1.
    sql/sql_optimizer.cc
    sql/sql_select.cc
      Removed casts when assigning to/from JOIN_TAB::read_time
    unittest/gunit/opt_costconstants-t.cc
      Updated unit tests to use new values for cost constants
    
    Changes in tests:
    
    mysql-test/include/join_cache.inc
      Added more data in one table to preserve original query plan.
    mysql-test/include/mix1.inc
      Added more data in in two tables to preserve original query plan.
    mysql-test/r/count_distinct.result
      User variable changed because plans go from BNL to ref access
    mysql-test/t/dd_is_compatibility.test
    mysql-test/r/dd_is_compatibility.result
    mysql-test/r/dd_is_compatibility_ci.result
      Lowered setting of max_join_size to make sure test still get ER_TOO_BIG_SELECT
    mysql-test/r/delete.result
      Changed join order gives more warnings
    mysql-test/r/endspace.result
      Query returned result in different order, re-recorded.
    mysql-test/r/explain.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_rqg_json.result
      Change in two query plans, updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_rqg_trad.result
      Change in one query plan, updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_small_json.result
    mysql-test/r/explain_for_connection_small_trad.result
      One query changes from table scan to ref access, due to magic constants
      added when calculating cost for tables scan. Two queries changes from
      index scan to ref access due to lower cost of doing ref access. Updated cost
      numbers in EXPLAIN JSON.
    mysql-test/r/explain_json_all.result
      Re-recorded new query plan for one query since it no longer tested
      what the original test was for. Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_json_none.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/explain_other.test
    mysql-test/r/explain_other.result
      Added more data to one table in order to preserver original query plan.
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/func_concat.result
      Changed from table scan with BNL to eq_ref access.
      The new plan is identical to the plan when the test case was added.
    mysql-test/r/greedy_optimizer.result
      Several queries got new query plan. All new query plans resulted in a
      lower number of Handler_reads. Updated Last_query_cost numbers.
    mysql-test/r/greedy_search.result
      No changes in query plans but the number of partial plans evaluated
      was changed for several queries.
    mysql-test/r/group_by.result
      Changed from table scan with BNL to ref access
    mysql-test/r/group_min_max.result
      Four queries changes from doing index scan to use range scan due to
      range scan becoming cheaper with all data in memory buffer.
    mysql-test/r/heap_hash.result
      One query changes from using join buffer to use ref access for join.
      This is what the original test used, accepted new plan.
    mysql-test/r/index_merge_innodb.result
      One query changes from ref to range. This is caused by using DS-MRR for the
      range scan. Updated cost numbers in EXPLAIN JSON.
    mysql-test/include/index_merge_intersect_dml.inc
    mysql-test/r/index_merge_intersect_dml.result
      One query changed from doing range scan on primary key to range scan on
      secondary key. Changed query to switch back to use primary key.
    mysql-test/r/index_merge_myisam.result
    mysql-test/r/innodb_explain_json_non_select_all.result
    mysql-test/r/innodb_explain_json_non_select_none.result
    mysql-test/r/internal_tmp_disk_storage_engine.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/join.test
    mysql-test/r/join.result
      Query plan changes for two queries. First fixed by increasing the range
      interval in the query. The second query changes from table scan to
      eq_ref for one table, re-recorded new query plan. Updated Last_query_cost
      numbers.
    mysql-test/r/join_cache_bka.result
      Four queries changes from using BNL to use BKA/ref access.
    mysql-test/r/join_cache_bka_nixbnl.result
      One query changes from table scan to BKA/ref access.
      One query changes join order
    mysql-test/r/join_cache_bkaunique.result
      Four queries changes from using BNL to use BKA-unique/ref access.
    mysql-test/r/join_cache_bnl.result
      Four queries changes from using BNL to use ref access due to ref access
      becoming cheaper with all data in a memory buffer.
    mysql-test/r/join_cache_nojb.result
      Changed join order for one query due to ref access becomming relatively
      less costly compared to table scan when all data is in a memory buffer.
    mysql-test/r/join_outer.result
      Changes in order of results from a few queries, re-recorded. Updated cost
      numbers in EXPLAIN JSON.
    mysql-test/r/join_outer_bka.result
    mysql-test/r/join_outer_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/key.result
      Updated Last_query_cost numbers.
    mysql-test/r/key_diff.result
      One query changes from using join buffering to ref access. The new plan
      has also been accepted as plan for this query before, so just use it.
    mysql-test/r/myisam.result
      One query changes from table scan to range scan, likely due to use of
      magic constants when calculating cost of table scan.
    mysql-test/r/myisam_explain_json_non_select_all.result
    mysql-test/r/myisam_explain_json_non_select_none.result
      Updated cost numbers in EXPLAIN JSON plus two rows estimates in explain.
    mysql-test/r/myisam_icp.result
    mysql-test/r/myisam_icp_all.result
    mysql-test/r/myisam_icp_none.result
      Changes to query plans for two bugs that was reported for InnoDB.
      Accepted changes since the plan is still the same when run with
      InnoDB.
    mysql-test/t/opt_costmodel.test
    mysql-test/r/opt_costmodel.result
    mysql-test/t/opt_costmodel_flush.test
    mysql-test/r/opt_costmodel_flush.result
      Updated to use new cost numbers, updated result files.
    mysql-test/r/opt_costmodel_restart.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/opt_hints.result
      Changes from ref access to range access. Does not affect purpose of test
    mysql-test/t/opt_hints_subquery.test
    mysql-test/r/opt_hints_subquery.result
      A lot of changes to explain output:
      -Most of the changes are from using join buffer to ref access (ok)
      -Some changes are in join order (ok)
      -Some changes are in semijoin strategy; adjusted test cases so hints
       are used according to original purpose of tests.
    mysql-test/r/order_by_all.result
    mysql-test/r/order_by_icp_mrr.result
    mysql-test/r/order_by_none.result
      Two queries joining three tables changes join order. The new query plans are
      equal to earlier query plans, so no attempt on reproducing current query
      plans.
    mysql-test/r/partition.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/partition_locking.test
    mysql-test/r/partition_locking.result
      Many queries changed from doing index scan to range scan. Adjusted
      the queries to use index scan. For the last query, the plan change
      is accepted since it is the same as the initial query plan.
    mysql-test/t/partition_pruning.test
    mysql-test/r/partition_pruning.result
      Two queries changed from table scan to range scan. Adjusted queries
      to produce same plan.
    mysql-test/r/range_all.result
    mysql-test/r/range_icp.result
    mysql-test/r/range_icp_mrr.result
    mysql-test/r/range_mrr.result
    mysql-test/r/range_mrr_cost.result
    mysql-test/r/range_none.result
    mysql-test/r/range_with_memory_limit.result
      Change in three query plans. The first is due to range scan becoming cheaper
      than table scan, and join buffering is no longer considered. The two last is
      Change in join order due to differences in cost estimate for ref access
      versus join buffering. The new plan is more similar to initial plan for
      these two queries.
    mysql-test/include/select.inc
    mysql-test/r/select_all.result
    mysql-test/r/select_all_bka.result
    mysql-test/r/select_icp_mrr.result
    mysql-test/r/select_icp_mrr_bka.result
      Two identical queries switches from using join buffering to use ref access.
      Change accepted since ref access was the original join method for these
      queries.
    mysql-test/r/select_none.result
    mysql-test/r/select_none_bka.result
    mysql-test/r/select_none_bka_nixbnl.result
      In addition to the two queries above, a third query changes from table
      scan to range scan due to range access is cheaper with all data in memory.
      Accepted new plan since range scan was the origianal plan when the bug
      was first fixed.
    mysql-test/r/select_all_bka_nixbnl.result
    mysql-test/r/select_icp_mrr_nixbnl.result
      Updated result file after adding sorted_result for two queries in select.inc
    mysql-test/t/select_safe.test
    mysql-test/r/select_safe.result
      Adjusted value for max_join_size to make query fail.
    mysql-test/t/single_delete_update.test
    mysql-test/r/single_delete_update.result
      Two limit queries changed from doing file sort to using index. The
      test assumed that is should use filesort, so increased the limit to
      produce original query plan. Needed to adjust some other parts of
      the test due to this.
    mysql-test/r/status.result
      Updated Last_query_cost numbers.
    mysql-test/r/subquery_all.result
    mysql-test/r/subquery_all_bka.result
      Five queries have changes in query plans:
      -Change from using join buffer to ref access due to ref access is less costly
       with all data in memory buffer.
      -Join order changes due to minor changes in cost estimates, the new
       plan is identical to a former plan for this query.
      -Last three queries change from using join buffering to use ref access
       due to ref access is less costly with data in memory. The query plan for
       these queries has changed several times so no effort on reproducing
       original plan.
    mysql-test/r/subquery_all_bka_nixbnl.result
      Join order changes for one query due to minor changes in cost estimates,
      the new plan is identical to a former plan for this query.
    mysql-test/r/subquery_mat_all.result
      Several queries changes from using DuplicateWeedout to FirstMatch due
      to the cost of FirstMatch reading data is now lower compared to using
      the temporary table. The query plan for these queries have changed
      several times so no attempt on reproducing original query plan.
    mysql-test/r/subquery_nomat_nosj.result
    mysql-test/r/subquery_nomat_nosj_bka.result
    mysql-test/r/subquery_none.result
    mysql-test/r/subquery_none_bka.result
      Join order changes for two queries due to minor changes in cost estimates.
    mysql-test/r/subquery_nomat_nosj_bka_nixbnl.result
    mysql-test/r/subquery_none_bka_nixbnl.result
      Join order change for one query due to minor changes in cost estimates.
    mysql-test/r/subquery_sj_all.result
    mysql-test/r/subquery_sj_all_bka.result
    mysql-test/r/subquery_sj_all_bka_nixbnl.result
    mysql-test/r/subquery_sj_all_bkaunique.result
      About 25 queries has changes in query plans:
      -Materialization to FirstMatch: FirstMatch becomes cheaper due to the
       cost of reading the data when it is in memory is now lower
      -Materialization to DupsWeedOut: Some of the changes are due to
       materialization and dupsweedout having the exact same cost and the change
       is caused by rounding errors. In a few cases, the cost of DupsWeedOut
       is now lower than Materialization.
      -DupsWeedout to FirstMatch: FirstMatch benefits more from having all
       data in a memory buffer
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer
    mysql-test/r/subquery_sj_dupsweed.result
    mysql-test/r/subquery_sj_dupsweed_bka.result
    mysql-test/r/subquery_sj_dupsweed_bka_nixbnl.result
    mysql-test/r/subquery_sj_dupsweed_bkaunique.result
      A few queries have changes in query plan, no changes in semi-join strategy:
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
    mysql-test/r/subquery_sj_firstmatch.result
    mysql-test/r/subquery_sj_firstmatch_bka.result
    mysql-test/r/subquery_sj_firstmatch_bkaunique.result
      A few queries have changes in query plan, no change in semi-join strategy:
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
    mysql-test/r/subquery_sj_firstmatch_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/subquery_sj_loosescan.result
    mysql-test/r/subquery_sj_loosescan_bka.result
    mysql-test/r/subquery_sj_loosescan_bka_nixbnl.result
    mysql-test/r/subquery_sj_loosescan_bkaunique.result
      A few queries have changes in query plan, no change in semi-join strategy:
      -Join order: due to changes in cost estimates, verified that current
       plan is not the same as origianal plan, so just re-recorded.
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
    mysql-test/r/subquery_sj_mat.result
    mysql-test/r/subquery_sj_mat_bka.result
    mysql-test/r/subquery_sj_mat_bka_nixbnl.result
    mysql-test/r/subquery_sj_mat_bkaunique.result
      A few queries have changes in query plan:
      -Join order: due to changes in cost estimates, verified that current
       plan is not the same as origianal plan, so just re-recorded.
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
      -One query changes from MaterializeLookup to MaterializeScan.
    mysql-test/r/subquery_sj_mat_nosj.result
      A few queries change from using join buffer to use eq_ref or ref:
      eq_ref and ref get a lower cost when all data is in a memory buffer. This
      causes changes to join order.
    mysql-test/r/subquery_sj_none.result
    mysql-test/r/subquery_sj_none_bka.result
    mysql-test/r/subquery_sj_none_bkaunique.result
      One query changes from using join buffer to use eq_ref or ref:
      eq_ref and ref get a lower cost when all data is in a memory buffer. This
      causes changes to join order.
    mysql-test/r/subquery_sj_none_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/type_blob.result
      Change from ALL to ref_or_null.  Back to plan before switch to InnoDB
    mysql-test/r/type_ranges.result
      Order of warnings changed for an INSERT INTO SELECT statement likely due
      to plan change. Re-recorded result file.
    mysql-test/r/user_var.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/engines/iuds/r/insert_calendar.result
    mysql-test/suite/engines/iuds/t/insert_calendar.test
      Different plans for MyISAM and InnoDB caused different number of warnings.
      Changed start date for range for query to avoid warnings for zero date.
    mysql-test/suite/gcol/inc/gcol_ins_upd.inc
    mysql-test/suite/gcol/r/gcol_ins_upd_innodb.result
    mysql-test/suite/gcol/r/gcol_ins_upd_myisam.result
      Added sorted_result to some queries to handle that the order of the
      result changes. This happened for the MyISAM test, the InnoDB test
      had the same order.
    mysql-test/suite/gcol/r/gcol_keys_innodb.result
    mysql-test/suite/gcol/r/gcol_keys_myisam.result
      Changed plans from table scan to index usage
    mysql-test/suite/gcol/r/gcol_select_myisam.result
      One query changes join order and switches from join buffering to ref
      access.
    mysql-test/suite/gcol/r/gcol_select_innodb.result
      One query changes from using join buffering to do ref access. This is
      caused by table scan becoming relatively more costly compared to ref
      access.
    mysql-test/suite/innodb/t/innodb_mysql.test
    mysql-test/suite/innodb/r/innodb_mysql.result
      Added extra rows to a few tables to preserve original query plan.
    mysql-test/suite/innodb/include/query_workload_itt.inc
    mysql-test/suite/innodb/r/optimizer_temporary_table.result
      Cost estimates of EXPLAIN JSON was unstable since one table was not used
      for a while and sometimes its pages was flushed from buffer pool.
      Added a query that does a table scan to ensure that pages are in buffer pool.
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/innodb_gis/r/create_spatial_index.result
    mysql-test/suite/innodb_gis/r/rtree.result
    mysql-test/suite/innodb_gis/r/rtree_multi_pk.result
      Changes in query plans from full table/index scan to range scan
      Queries will now actually use a spatial index
    mysql-test/suite/innodb/r/temporary_table.result
    mysql-test/suite/innodb/r/temporary_table_optimization.result
    mysql-test/suite/innodb_zip/r/wl6469.result
    mysql-test/suite/innodb_zip/r/wl6560.result
      A few queries changes from table scan to range scan due to use of magic
      constants in the cost model for table scan.
    mysql-test/suite/innodb_fts/r/opt.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/json/r/json_agg.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/opt_trace/r/bugs_no_prot_all.result
    mysql-test/suite/opt_trace/r/bugs_ps_prot_all.result
      Updated cost estimate numbers in optimizer trace output.
      There are a few minor changes in the optimizer trace output
      and a few plan changes.
    mysql-test/suite/opt_trace/r/bugs_no_prot_none.result
    mysql-test/suite/opt_trace/r/bugs_ps_prot_none.result
    mysql-test/suite/opt_trace/r/fulltext.result
    mysql-test/suite/opt_trace/r/general2_no_prot.result
    mysql-test/suite/opt_trace/r/general2_ps_prot.result
    mysql-test/suite/opt_trace/r/general_no_prot_none.result
    mysql-test/suite/opt_trace/r/general_ps_prot_none.result
    mysql-test/suite/opt_trace/r/range_no_prot.result
    mysql-test/suite/opt_trace/r/range_ps_prot.result
      Updated cost estimate numbers in optimizer trace output.
      There are a few tiny minor change in the optimizer trace output.
    mysql-test/suite/opt_trace/r/charset.result
    mysql-test/suite/opt_trace/r/eq_range_statistics.result
    mysql-test/suite/opt_trace/r/filesort_pack.result
    mysql-test/suite/opt_trace/r/filesort_pq.result
    mysql-test/suite/opt_trace/r/general_no_prot_all.result
    mysql-test/suite/opt_trace/r/general_ps_prot_all.result
    mysql-test/suite/opt_trace/r/subquery_no_prot.result
    mysql-test/suite/opt_trace/r/subquery_ps_prot.result
    mysql-test/suite/opt_trace/r/temp_table.result
      Updated cost estimate numbers in optimizer trace output.
    mysql-test/suite/opt_trace/r/security_no_prot.result
    mysql-test/suite/opt_trace/r/security_ps_prot.result
      Updated length numbers for optimizer trace output.
    mysql-test/suite/parts/r/partition_icp.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/sysschema/r/pr_statement_[1;31mperf[mormance_analyzer.result
      Changed query plans give different number for rows_examined
    mysql-test/suite/sys_vars/r/max_join_size_func.result
    mysql-test/suite/sys_vars/r/sql_big_selects_func.result
    mysql-test/suite/sys_vars/t/max_join_size_func.test
    mysql-test/suite/sys_vars/t/sql_big_selects_func.test
      Reduced value for max_join_size to make queries fail with new cost constants.
    mysql-test/suite/test_service_sql_api/r/test_sql_stmt.result
      Changed result order due to different access method
    mysql-test/suite/i_main/r/bug18932813.result
    mysql-test/suite/i_main/r/derived.result
    mysql-test/suite/i_main/r/explain_json.result
    mysql-test/suite/i_main/r/group_by.result
    mysql-test/suite/i_main/r/partition_icp.result
    mysql-test/suite/i_main/r/subquery_mat_cost_based.result
    mysql-test/suite/i_main/r/view.result
      Updated cost numbers in EXPLAIN JSON.
    .../mysql-test/suite/i_main/r/bug22671573.result
      Plan changed from table scan to range scan.
      Verified that test case still reproduce the original bug.
    .../mysql-test/suite/i_main/r/costmodel_planchange.result
      Adjust queries to still identify plan changes
    .../mysql-test/suite/i_main/t/insert.test
    .../mysql-test/suite/i_main/r/insert.result
      Added data to keep same query plan
    .../mysql-test/suite/i_main/t/subquery-bug22262843.test
    .../mysql-test/suite/i_main/r/subquery-bug22262843.result
      Added a row so that subquery materialization is still used.
    .../mysql-test/suite/i_main/t/subquery.test
    .../mysql-test/suite/i_main/r/subquery.result
      Added data to keep on query plan
      Some changes from table scan (with BNL) to ref access
      Some semijoin strategy changes that seems reasonable
    .../mysql-test/suite/i_opt_trace/include/bugs.inc
      Added analyze table to make test stable
    .../mysql-test/suite/i_opt_trace/r/bugs_no_prot.result
    .../mysql-test/suite/i_opt_trace/r/bugs_ps_prot.result
    .../mysql-test/suite/i_opt_trace/r/query_cache_trace.result
      Updated cost numbers in EXPLAIN JSON.
    .../mysql-test/suite/i_opt_trace/r/refaccess_trace.result
      One query plan goes from table scan to eq_ref
      Updated cost numbers in EXPLAIN JSON.
    
    Implemented by Olav Sandstå

[33mcommit ec901d6e14e9076b9ad30272d38ae895b5a21547[m
Author: V S Murthy Sidagam <venkata.sidagam@oracle.com>
Date:   Thu Nov 24 13:50:43 2016 +0530

    Bug #24528148 UNPRIVILEGED USER ABLE TO LOAD COMPONENTS TO MYSQL.COMPONENT
    
    Description: As per wl#4102, there is provision to register components
    to mysql.component table but here privileges are not working.
    Unprivileged user can able to load/unload these components
    
    Analysis: While loading the components, we are opening the
    mysql.component table.
    But we are not checking the table access privilege for
    the user. This is the causes the bug.
    
    Fix: Added access privilege call before opening the
    msql.component table. And moved down the
    mysql_dynamic_loader_imp::load and
    mysql_dynamic_loader_imp::unload
    calls after the open_component_table() because we need
    to first check the access privilege before [1;31mperf[morming
    load/unload operations.

[33mcommit 825d2f17b5a8da202a6575c73e5d93eeaa2ef729[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Nov 18 12:54:25 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    When copying variable-length multibyte strings around, don't bother counting up
    all the characters if there's guaranteed to be no truncation anyway.
    This takes about 2.2% of CPU time in sysbench with utf8mb4 with
    --oltp-use-varchar-for-char. (This is too small of a difference that I can
    reliably measure it in my local sysbench runs, but I've run [1;31mperf[m and verified
    that my_well_formed_len_utf8mb4 disappears from the profile.)
    
    Change-Id: I86c9054a5bbcc8c9f2c6151d5dbcfb90b8258d22

[33mcommit bf35e69bac352f89b22522eb08ca1ad06cf3c9de[m
Author: Bjorn Munch <bjorn.munch@oracle.com>
Date:   Thu Nov 17 13:01:20 2016 +0100

    Bug #25083555 SOME TESTS FAIL WITH DEBUG SERVER ON SOLARIS WHEN BUILT WITH DEVELOPER STUDIO
    
    Follow-up fix: [1;31mperf[mschema.statement_digest_long_query needs to be
    skipped also for non-debug sparc but then need to make some
    amendements so it can "espace" --no-skip.

[33mcommit b81c7809eee873e68c6451ef1f170310f4035ef1[m
Merge: 8d1bf4cf11b 2121d2884ca
Author: Allen Lai <zheng.lai@oracle.com>
Date:   Thu Nov 17 16:17:19 2016 +0800

    Merge branch 'mysql-trunk-wl7743-wip-3' into mysql-trunk-meta-sync-merge
    
    Conflicts:
            mysql-test/r/create.result
            mysql-test/r/dd_is_gcov.result
            mysql-test/r/dd_schema_definition_debug_cs.result
            mysql-test/r/dd_stages.result
            mysql-test/suite/[1;31mperf[mschema/r/alter_table_progress.result
            mysql-test/t/dd_is_gcov.test
            sql/dd/impl/cache/dictionary_client.cc
            sql/item_create.cc

[33mcommit c6895416ddda3306202960573d7892defc4d3ce0[m
Author: Neha Kumari <neha.n.kumari@oracle.com>
Date:   Thu Nov 17 11:22:14 2016 +0530

    Squashed commit of the following:
    
    commit fcf3dec9fa4e5f7b27080dd09d609adf818cfec5
    Merge: e32d692 efab2bf
    Author: Neha Kumari <neha.n.kumari@oracle.com>
    Date:   Thu Nov 17 10:24:03 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9110
    
    commit 931cf237071e582234902f2ff3e1d5bc47727ce9
    Merge: ff0f870 506e96d
    Author: Neha Kumari <neha.n.kumari@oracle.com>
    Date:   Tue Nov 15 11:39:45 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9110
    
        Additional:
        The test mysqld--help-win, mysqld--help-notwin needed to be
        recorded again as the [1;31mperf[mormance-schema-error-size is
        incremented due to the introduction of a new error message by WL#9110.
    
    commit 4d6be5ce262dfa66c2474062ef3b8e58f62fe764
    Author: Neha Kumari <neha.n.kumari@oracle.com>
    Date:   Wed Aug 24 12:31:01 2016 +0530
    
        WL#9110: Add RESET MASTER TO x to allow specification of binlog file number
    
        We have a "RESET MASTER" command in replication, what happens on execution of
        this command is it deletes all binary log files listed in the
        index file, resets the binary log index file to be empty, and creates
        a new binary log file with index as 000001.
    
        With this extension to RESET MASTER, user will be able to specify
        which binary log file index number to start from once the reset happens,
        instead of startint from 000001.
    
        This can be used to simplify the failover process and make it more efficient,
        by replacing FLUSH BINARY LOGS + PURGE BINARY LOGS TO x with a single
        RESET MASTER TO x command.
    
        This won't have any affect on the old command RESET MASTER, it will
        still behave as before.

[33mcommit 98d5f8a4e1f38c88c3eb14eebb1138d3b4581a23[m
Merge: 2121d2884ca 4602dd45b86
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Wed Nov 16 10:10:22 2016 +0300

    Merge branch 'mysql-trunk' into mysql-trunk-wl7743-wip-3
    
    Conflicts:
            mysql-test/include/commit.inc
            mysql-test/r/commit_1innodb.result
            mysql-test/r/create.result
            mysql-test/r/create_ps_protocol.result
            mysql-test/r/group_min_max_ps_protocol.result
            mysql-test/r/partition_explicit_prune.result
            mysql-test/r/partition_locking.result
            mysql-test/r/partition_locking_ps_protocol.result
            mysql-test/suite/[1;31mperf[mschema/r/alter_table_progress.result
            sql/dd/dd_schema.cc
            sql/dd/dd_table.cc
            sql/sql_table.cc

[33mcommit 3acdff634e9d7f64e191cc2de1025dc6b7a11583[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Mon Nov 14 09:50:11 2016 +0800

    There are sixteen result files which do not have corresponding test file. See below.
    
    mysql-test/r/rpl_colSize.result
    mysql-test/r/rpl_extraColmaster_innodb.result
    mysql-test/r/rpl_extraColmaster_myisam.result
    mysql-test/suite/rpl/r/rpl000001.a.result
    mysql-test/suite/rpl/r/rpl000001.b.result
    mysql-test/suite/rpl/r/rpl_gtid_stm_insert_delayed.result
    mysql-test/suite/rpl/r/rpl_mixed_row_innodb.result
    mysql-test/suite/rpl/r/rpl_parallel_fallback.result
    mysql-test/suite/rpl/r/rpl_[1;31mperf[mschema_applier_status.result
    mysql-test/suite/rpl/r/rpl_row_err_ignoredtable.result
    mysql-test/suite/rpl/r/rpl_row_loaddata_m.result
    mysql-test/suite/rpl/r/rpl_row_multi_query.result
    mysql-test/suite/rpl/r/rpl_show_slave_status_nonblocking.result
    mysql-test/suite/rpl/r/rpl_show_slave_status_nonblocking_debug.result
    mysql-test/suite/sys_vars/r/rpl_recovery_rank_basic_32.result
    mysql-test/suite/sys_vars/r/rpl_recovery_rank_basic_64.result
    
    Delete these result files from the suite, since they are unavailable.

[33mcommit a6f313d36fa3fda2b393ca0f9dde14ab56aa3fdd[m
Author: Ole John <ole.john.aske@oracle.com>
Date:   Fri Nov 11 13:44:27 2016 +0100

     Bug #25042101 SPLIT BINLOG INJECTOR_MUTEX IN TWO, DO REQUIRED CLEANUP
    
        Remove thread_yield() in binlog injector code previously put there
        as a temp stopgap in the commit below. This used to be required
        as the injector thread held the injector_mutex > 99% of the time when
        waiting for pollEvents(). That blocked client threads either wanting to
        access the data shared from the injector thread, or needing the injector_mutex
        while waiting for injector_cond to be signaled
    
        This should not be required anymore, as:
    
        1) injector_mutex has been splitt in two separate mutexes.
        2) We changed init of the injector_event_mutex from a 'FAST' to a 'SLOW'
           mutex which has better 'farness' properties in the scheduler
    
        This also reverts the patch:
    
        commit 000394fbe3a8d7a2945fb6b483024b77e16ab20a
        Author: Ole John Aske <ole.john.aske@oracle.com>
        Date:   Fri Jan 15 09:55:05 2016 +0100
    
            Follow up patch for [1;31mperf[mormance regression introduced by patch for bug#20957068
    
            Introduce some sched_yield() in the binlog-thread loops where
            the injector_mutex is held >99% if the elapsed time. The yields
            let other threads waiting to be scheduled a chance to run,
            and grab the injector_mutex when not held by the binlog-thread.

[33mcommit cd1efb89ab105fb369e00a37db0372bfae5ce80e[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Fri Nov 4 15:22:10 2016 +0100

    Bug#24464763 MOST PERFSCHEMA.*_IO TESTS FAIL IF GIS.SRS RUNS BEFORE THEM ON
    THE WORKER
    
    This is a test script fix only, to improve test robustness.
    
    Before this fix, some tests failed with spurious diff related to
      Performance_schema_rwlock_instances_lost
    in the result file.
    
    This is due to the MTR suite default configuration,
    default_mysqld.cnf, which uses a fixed number of instrumented objects:
    for some combinations of tests, the number of items actually instrumented
    during the test payload can exceed artificial limits set in the test cnf.
    
    The fix is to relax limits on the number of instrumented objects,
    and rely on [1;31mperf[mormance schema buffers scaling automatically
    based on the load.
    
    Adjusted the test results accordingly.

[33mcommit f870e3db270c668666a0775d88f7e90e513d68ed[m
Author: Abhishek Ranjan <abhishek.ar.ranjan@oracle.com>
Date:   Fri Nov 4 12:07:31 2016 +0530

    Bug#24805140 : UPGRADE TO 8.0.1 FROM 5.7 FAILS IN SP PARSING
    
    Post push fix:
    main.dd_upgrade_test.test fails when mtr passes --log-bin option
    to the server. Failure is in executing 'show session status' command.
    At server startup, when checking structure of [1;31mperf[mormance schema tables,
    server tries to decide the format for binary logging in lock_tables().
    At this point, if there is an existing error in DA, successive P_S tables
    are marked invalid. This causes error in executing 'show session status'
    command which internally uses '[1;31mperf[mormance_schema'.'session_status' table.
    
    Fix:
    Add --loose-skip-log-bin option in the test case when starting the
    server for upgrade.

[33mcommit 8571fd1b569bb6d04be92914084b747d3a45b4b1[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Oct 11 15:42:31 2016 +0200

    Bug#24826541 TABLE PERFORMANCE_SCHEMA.DATA_LOCKS IS MISSING RECORDS
    
    Tests involving [1;31mperf[mormance_schema.lock_data have been found
    to be unstable.
    After analysis, several issues, both in the server code and the test
    scripts, have been identified, fixed by this patch.
    
    ISSUE #1
    ========
    
    When SELECT * from [1;31mperf[mormance_schema.data_locks
    is executed, the code in table_data_locks::rnd_next()
    extracts rows from innodb, using a restartable scan,
    using an iterator:
      PSI_engine_data_lock_iterator *it= ...
    
    Assume that for example the first call to
      it->scan();
    returns 10 rows, and a subsequent call returns 5 more rows.
    
    Before this fix,
    - the data container after first call contains rows [0] .. [9]
    - the ::rnd_next loop with m_index_2 at positions [0] .. [9]
    - all the rows for the first scan are returned properly
    - the data container after second call contains rows [0] .. [5]
    - the ::rnd_next loop with m_index_2 at positions [10] .. [14]
    - rows for the second scan are missed
    
    The root cause is the discrepancy in "index":
    - the data container uses relative positions in each scan
    - the m_index_2 loop in rnd_next uses absolute positions
    
    With this fix, restartable scans keep rows numbered in absolute,
    with PFS_data_lock_container::m_logical_row_index.
    The container is not cleared, but only truncated with ::shrink(),
    during the scan, to preserve row numbering.
    
    ISSUE #2
    ========
    
    Because of restartable scans, locks are not returned always in the same
    order from a select, as two transactions can be returned
    in the same or in different scans.
    
    As a result, tests scripts need to use an ORDER BY clause
    on SELECT, to have a stable output.
    
    This fix corrected the test scripts.
    
    ISSUE #3
    ========
    
    Using SELECT ... ORDER BY cause the optimizer to use
    table_data_locks::rnd_pos(), after a filesort.
    
    This code path is longer from a plain table scan,
    and exposed further bugs:
    
    ISSUE #3-1
    ----------
    
    Lock rows exported by a scan can not be fetched back,
    because of incorrect filtering on the lock heap_no.
    
    A given LOCK_REC structure is not associated with a
    single heap_no, but with a -- set of -- heap_no.
    
    When [1;31mperf[morming a table scan,
    Innodb_data_lock_iterator::scan_trx()
    is called with filter = false,
    and iterate properly on heap_no,
    using:
      heap_no = lock_rec_find_set_bit(lock);
      heap_no = lock_rec_find_next_set_bit(lock, heap_no);
    
    When called for a fetch however, with filter = true,
    the code failed to look for the entire set of heap_no,
    and only considered the first in the set.
    
    This fix now iterate properly on all heap_no
    when using a filter with filter_heap_id.
    
    ISSUE #3-2
    ----------
    
    Transactions exported by a scan can not be fetched back,
    because of incorrect iteration on the trx list in innodb.
    
    The "transaction list" in innodb is a complex structure,
    made of two lists (trx_list, mysql_trx_list).
    
    To iterate properly, the code must use the get_next_trx()
    helper, instead of using UT_LIST_GET_NEXT().
    
    The code in fetch_trx_in_trx_list() has been fixed to iterate
    on the proper transaction list.
    
    ISSUE #3-3
    ----------
    
    Transactions exported by a scan can not be fetched back,
    because of incorrect values for the transaction id.
    
    The problem is that trx->id may, or may not,
    be a valid transaction id.
    
    In particular, some transactions in read only mode
    can have a trx->id of 0.
    
    See comments in trx_get_id_for_print() for details.
    
    The code exported a lock with a value for engine_lock_id,
    that contained a (fabricated) transaction id value.
    
    On a subsequent fetch, after parsing the value of engine_transaction_id
    to find a trx id, fetch_trx_in_trx_list() failed to locate the transaction,
    because the code was comparing the fabricated value with a zero trx->id
    
    The fix is to always use trx_get_id_for_print(trx), and never use trx->id
    directly, when exporting data in a scan, or fetching a particular row from
    rnd_pos().
    
    ISSUE #4
    --------
    
    In the test scripts, replying on column LOCK_DATA
    in table [1;31mperf[mormance_schema.data_locks may cause spurious failures.
    This column can be NULL, in case the innodb storage engine
    purged data from the server memory to disk: this is a documented limitation.
    
    Relaxed the use of LOCK_DATA in test cases.

[33mcommit 92ba97686080f2115d03fc2b2512498129cfa6f5[m
Merge: c46f4244f92 d98536ef01c
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Fri Oct 14 22:52:29 2016 +0300

    Merge branch 'mysql-trunk' into mysql-trunk-wl7743-wip-3
    
    Conflicts:
            mysql-test/include/commit.inc
            mysql-test/r/commit_1innodb.result
            mysql-test/suite/innodb/r/innodb.result
            mysql-test/suite/[1;31mperf[mschema/r/alter_table_progress.result
            sql/dd/dd_table.cc
            sql/dd/dd_table.h
            sql/dd/dd_upgrade.cc
            sql/dd/impl/types/table_impl.cc
            sql/dd/impl/types/table_impl.h
            sql/handler.cc
            sql/handler.h
            sql/sql_insert.h
            sql/sql_table.cc
            storage/[1;31mperf[mschema/ha_[1;31mperf[mschema.cc

[33mcommit 741acc33b80bd4747f55bb71d23c6d20df91fffa[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Oct 12 14:02:00 2016 +0200

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Refactor the scanners so that we can inline mb_wc in the UCA collation,
    like we do in the UTF-8 binary collations.
    
    First and foremost, the split between “scanner” and “scanner handler”
    is now gone; the data belongs squarely in the scanner, which is a full class
    with its own private member functions and most of the state kept private.
    This allows us to more easily templatize them on mb_wc.
    
    Second, the scanner classes are now templatized on mb_wc, so that we can
    specialize them for the important case of utf8mb4, instead of calling it
    through a function pointer.
    
    Note that since the private member functions are no longer “static”,
    we need to convince GCC a bit harder (ie., using the “always_inline”
    attribute) for the bigger ones to actually be inlined, which matters
    for overall [1;31mperf[mormance.
    
    Microbenchmarks (Skylake 3.4 GHz, 64-bit, optimized) are significantly
    improved in terms of throughput:
    
      Microbenchmarks.BM_SimpleUTF8MB4   1737 -> 1404 ns/iter  (+23.7%)
      Microbenchmarks.BM_MixedUTF8MB4     722 ->  609 ns/iter  (+18.6%)
    
    sysbench variability is rather high, but longer runs indicate we've gone
    from 5527 -> 6117 tps (+10.7%).
    
    Change-Id: Id9125af181db1b6976c288e38009b73e2bce6980

[33mcommit f2eac501e476a65e136486f11d26fa99ad6b25e5[m
Merge: 75180fbb011 4d2f44c0a38
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Oct 12 22:24:51 2016 +0200

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Null merge
    
    Conflicts:
      storage/[1;31mperf[mschema/table_helper.cc
      storage/[1;31mperf[mschema/table_helper.h

[33mcommit 75180fbb0116b5df9fa06dbbf16fe56dbe68adf2[m
Author: Christopher Powers <chris.powers@oracle.com>
Date:   Wed Oct 12 13:06:38 2016 -0500

    Bug#24519021 FEW XA TESTS FAIL IN WAIT_COND'N.INC AS VIEW ON P_S.THREADS DOESNT RETURN RESULT
    
    This is a regression from WL#6616 Performance Schema, Indexes. Under high
    stress conditions, [1;31mperf[mormance_schema.threads may attempt to materialize a
    row representing a thread that is being disconnected, resulting in an error
    similar to "At line 41: Query 'SELECT count(*) = 0 FROM v_processlist WHERE
    PROCESSLIST_ID = 17' didn't return a result set
    
    The fix is for table_threads::make_row() to return a row only if the state of
    the thread has not changed.

[33mcommit 8b3b6d3342233d42e4dfef25af3e4d311a2d68fa[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Oct 12 18:50:47 2016 +0200

    Bug#22313205 PERFORMANCE_SCHEMA STATUS AND VARIABLES TABLES DO NOT HANDLE
    CHARSET PROPERLY
    
    Tables like [1;31mperf[mormance_schema.session_variables can print string values.
    
    Before this fix, string values expressed in a character set different
    than UTf8 would be truncated or incorrect.
    
    This affects for example system variables expressed using
    the file system character set, like character_sets_dir.
    
    With the following options:
    --character-set-filesystem=latin1
    --character-sets-dir=<value in latin1 here>
    the value for character-sets-dir is printed incorrectly,
    because the latin1 value is printed as UTF8.
    
    The root cause is that string values for system variables are
    represented as a binary buffer internally, but the associated
    CHARSET_INFO is lost, later assumed to be UTF8.
    
    The fix is to preserve (CHARSET_INFO, string value, string value length)
    together when representing a system variable in the [1;31mperf[mormance schema,
    and use the proper character set when populating the [1;31mperf[mormance_schema
    table.

[33mcommit ba5ca306e3ab5b9e16b69450478378d9fca06c52[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Aug 16 09:56:29 2016 +0200

    WL#8741 Varlen keys for sorting JSON values
    
    WL#8539 allowed to sort JSON values. However, in order to limit scope and reduce
    various risks it was done in suboptimal way. This WL aims to provide better
    [1;31mperf[mormance for sorting/grouping JSON values by using variable length sort keys
    for them.

[33mcommit 751c37e454ccbf4b1edcd70a98bde80bef31ed82[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Oct 5 14:58:07 2016 +0300

    Fix Bug#24666839 INNODB'S ESTIMATE FOR ROWS-IN-TABLE CAN RETURN ROWS=1 DUE TO A RACE CONDITION
    
    Previously, when copying stats around, we did:
    
    1. reset all stats of table T
    2. copy the stats from a dummy table object into T
    
    We only did 1. because during 2. we may skip some indexes which could
    then remain uninitialized in T. The problem is that between 1. and 2. the
    stats could be read without taking any locks (if ha_innobase::info() is
    called with HA_STATUS_NO_LOCK) which could lead to reading the zeroed
    stats which almost certainly do not describe the table well (too wrong).
    
    The solution is to avoid 1. and directly overwrite the existing stats in
    2. and in addition, if the index is to be skipped, then reset its stats,
    as what would have been done by 1.
    
    Still, this could cause an inconsistent stats read by
    ha_innobase::info(HA_STATUS_NO_LOCK) - it could read partially the old
    stats and partially the new stats. This is acceptable because:
    * The stats are an approximation and not exact/precise numbers,
      occasionally reading outdated stats should not cause problems
    * Doing any locking in ha_innobase::info(HA_STATUS_NO_LOCK) was
      tested and causes [1;31mperf[mormance regressions.
    
    RB: 14204
    Reviewed by: Satya Bodapati <satya.bodapati@oracle.com>

[33mcommit b70ff12a3423921aae6daeded2a6570404acb0ab[m
Author: Venkatesh Duggirala <venkatesh.duggirala@oracle.com>
Date:   Wed Sep 28 11:19:01 2016 +0530

    Bug#24746530 PERFORMANCE_SCHEMA_MUTEX_INSTANCES_LOST=8 WHEN GROUP
    REPLICATION IS ENABLED.
    
    Problem: When the group replication plugin is enabled, we are unable
    to see few psi mutexes in the [1;31mperf[mormance schema.setup_instruments
    table.
    
    Analysis: PFS_MAX_MUTEX_CLASS is declared as 200 and when the group
    replication plugin is enabled, the number of psi mutexes is more
    than this limit, hence we are loosing the mutexes. The same can be
    viewed from Performance_schema_mutex_instances_lost variable.
    
    Fix: Increase the limit to another safe limit , i.e., 220.

[33mcommit 2fdda40d1afecc665d53483ad7c9f6614b9874ca[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Sep 20 08:36:33 2016 +0200

    Bug#24673238 MAKE "SMALL" UNIT TESTS INDEPENDENT OF PERFORMANCE SCHEMA
    
    All the "small" unit tests can be built/linked (mostly) standalone.
    Make them independent of [1;31mperf[mormance schema as well, by
    adding misc DISABLE_PSI_ compile flags.
    
    Change-Id: I8418e24fd2ea1fb8628f7ee11c28b369bf8b0c8f

[33mcommit f3cdffcf25c7ce118293d088a40acc29903fc35b[m
Merge: 3deb809acb4 df3358b08df
Author: Craig L Russell <craig.russell@oracle.com>
Date:   Mon Sep 19 15:34:05 2016 -0700

    Merge ../mysql-5.6-cluster-7.4 into mysql-5.7-cluster-7.5
    
    Fix [1;31mperf[mormance issue with clusterj logger

[33mcommit df3358b08dfe5152f04a5f426380a48e85fe5e5d[m
Merge: 4b2611fb1b8 9f78883277b
Author: Craig L Russell <craig.russell@oracle.com>
Date:   Mon Sep 19 15:33:23 2016 -0700

    Merge ../mysql-5.6-cluster-7.3 into mysql-5.6-cluster-7.4
    
    Fix [1;31mperf[mormance issue with clusterj logging

[33mcommit 9f78883277bd2199ecf6578ec093fc07aeecfdb5[m
Author: Craig L Russell <craig.russell@oracle.com>
Date:   Mon Sep 19 15:29:48 2016 -0700

    Fix [1;31mperf[mormance bug in clusterj logging
      creating new objects creates more log records than it needs to
    
    Constants.java
      add environment variable to choose LoggerFactory
    
    DomainFieldHandlerImpl.java
      add guard for logger.debug calls
    
    LoggerFactoryService.java
      allow loading user-defined class for LoggerFactory
    
    ColumnImpl.java
      add guard for logger.debug calls
    
    DeMinimisLoggerFactory.java
      minimalist logger factory
    
    DeMinimisLogger.java
      minimalist logger

[33mcommit 2bb0216eec4386d6d3338a5f6784005044711118[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Sep 13 16:04:54 2016 +0200

    WL#6657 PERFORMANCE_SCHEMA LOCK_DATA
    
    Implemented tables
    - [1;31mperf[mormance_schema.data_locks
    - [1;31mperf[mormance_schema.data_lock_waits

[33mcommit d85f5353d76e32b61464f85e9f093d5ea2e0085a[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Fri Sep 2 08:38:05 2016 +0200

    Bug #24481933: STD::BASIC_STRING INSTANTIATION W/ PFS INSTRUMENTATION FOR THE DD
    
    Patch 5: Change the dd::String_type and dd::Stringstream_type aliases to the
    new instantiations which will allocate memory with PFS instrumentation.
    
    Adds an mtr test which [1;31mperf[morms sanity checks on the instrumentation. The exact
    numbers will differ between platforms.
    
    This patch completes the planned work for this bugid.

[33mcommit 90bc7e343745c71f6d48d945c33ca2d21639c730[m
Merge: b772aaf065c 5f34df2c938
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Thu Sep 1 13:15:11 2016 +0300

    Merge remote-tracking branch 'origin/mysql-trunk' into mysql-trunk-wl7743-wip-3
    
    Problems related to view columns info in I_S, upgrade and some others are
    not solved. Corresponding tests were disabled.
    
    Conflicts:
            mysql-test/include/commit.inc
            mysql-test/r/commit_1innodb.result
            mysql-test/r/create.result
            mysql-test/r/dd_debug.result
            mysql-test/r/dd_schema_definition_ci.result
            mysql-test/r/dd_schema_definition_cs.result
            mysql-test/r/group_min_max.result
            mysql-test/r/mysqld--help-notwin.result
            mysql-test/r/partition_locking.result
            mysql-test/suite/innodb/r/innodb-system-table-view_ci.result
            mysql-test/suite/innodb/r/innodb-system-table-view_cs.result
            mysql-test/suite/innodb/r/innodb.result
            mysql-test/suite/innodb/r/partition.result
            mysql-test/suite/innodb/t/partition.test
            mysql-test/suite/[1;31mperf[mschema/r/alter_table_progress.result
            mysql-test/t/dd_debug.test
            mysql-test/t/partition_explicit_prune.test
            sql/dd/dd_table.cc
            sql/dd/dd_table.h
            sql/dd/impl/tables/tables.cc
            sql/dd/impl/types/table_impl.cc
            sql/dd/types/table.h
            sql/dd_table_share.h
            sql/handler.h
            sql/share/errmsg-utf8.txt
            sql/sql_base.cc
            sql/sql_insert.cc
            sql/sql_insert.h
            sql/sql_rename.cc
            sql/sql_table.cc
            sql/sql_view.cc
            sql/table.cc
            storage/blackhole/ha_blackhole.cc
            storage/csv/ha_tina.cc
            storage/example/ha_example.cc
            storage/federated/ha_federated.cc
            storage/myisammrg/ha_myisammrg.cc

[33mcommit 05e2386eccd32b6b444b900c9f8a87a1d8d531e9[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Aug 30 11:59:39 2016 +0200

    Bug#22551677 SIGNAL 11 IN LF_PINBOX_PUT_PINS
    
      Before this fix, the following query:
        SET GLOBAL offline_mode = ON
      could cause the server to crash.
    
      The root cause is actually complex, as described below.
    
      1)
    
      A session A is connected, and [1;31mperf[morming network io,
      typically waiting for the next command to execute.
      The [1;31mperf[mormance schema socket instrumentation is enabled,
      so that pfs_start_socket_wait() / pfs_end_socket_wait()
      are executed.
    
      2)
    
      A session B executes SET GLOBAL offline_mode = ON,
      which terminates session A.
      In particular, session B forcefully closes the socket used by session A.
    
      3)
    
      Session A and session B are different threads, but they both
      execute [1;31mperf[mormance schema instrumented code against the same socket.
    
      4)
    
      Because a socket is "owned" by a thread,
      the instrumentation in pfs_start/end_socket_wait()
      uses the same PFS_thread (of thread A) in both thread A and B.
      This leads to race conditions when using member m_events_waits_current.
    
      5)
    
      Because PFS_thread::m_events_waits_current can be damaged with race conditions,
      the m_events_waits_current pointer can point outside of the waits array.
      Using this pointer to populate current waits can damage other members
      of the PFS_thread structure, most notably LF_HASH pins.
    
      6)
    
      Upon thread disconnect, using a corrupted LF_HASH pin when calling
      lf_hash_put_pins leads to a crash.
    
    ---
    
      The fix for this issue is to use the current thread, not the socket owner,
      in the [1;31mperf[mormance schema socket instrumenttion.
    
      Also, asserts have been added to detect similar failures.
      With the asserts, the original issue,
      which was spurious and only occured rarely,
      is not detected systematically.

[33mcommit ed59f25407b00fe856ba12ebd213f39fcd338924[m
Author: Mayank Prasad <mayank.prasad@oracle.com>
Date:   Mon Aug 22 17:19:27 2016 +0530

    Fix sporadic failure of idx_events_stages_current.test
    
    Issue:
            idx_events_stages_current tests depends on the entries in
            [1;31mperf[mormance_schema.events_stages_current table. These entries
            are transient in nature which is causing sporadic failure.
    
    Fix:
            Increased innodb_lock_wait_timeout to make sure entries in this
            table are there for longer period to avoid this sporadic failure.

[33mcommit e359ebc26ea3c193f52dbb06475137f94bd3c07c[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Wed Aug 17 09:43:37 2016 +0200

    WL#6599 - New Data Dictionary and I_S integration.
    
    Post-push patch fixing POINT_SELECT [1;31mperf[mormance regression fix.
    
    The patch does following improvement in open_tables() call flow,
    
    1 We were invoking dd::Dictionary::is_system_view_name() several
      times for a table. E.g., SELECT_LEX::add_table_to_list() would
      already know that if a TABLE_LIST is a system view. We were not
      setting TABLE_LIST->is_system_view here.  This patch sets this in
      SELECT_LEX::add_table_to_list() and avoids calls to
      dd::Dictionary::is_system_view_name() function call which goes
      throw all the system view names within the open_tables() call flow.
    
    2 We also avoid call to dd::Dictionary::is_dd_table_name().
      Basically there are two possibilities of open_tables() call seeing
      a DD tables.
    
      a) DD table being opened as part of DD operations invoking
         dd::Open_dictionary_tables_ctx::open_tables().
    
      b) DD table being opened as part of I_S system view execution.
    
      During open_table(), we need to know if a TABLE_LIST belongs to a
      DD table for several checks. Currently we do that by invoking
      dd::Dictionary::is_dd_table_name() which is a looking in a list.
      We can avoid that as described below.
    
      When open_table() is opening a DD table in case of a), the
      table_list used there is nothing but dd::Raw_table::m_table_list.
      And we are sure that this belongs to only DD tables. So, this
      patch adds a member TABLE_LIST->is_dd_table, which is set only by
      dd::Raw_table.  So the open_table() call now uses it.
    
      For b), we know that TABLE_LIST->is_system_view is marked for all
      the I_S system views. And
      TABLE_LIST->referencing_view->is_system_view would tell us that
      the TABLE_LIST is refering to a DD table. So, this avoids calls
      to dd::Dictionary::is_system_view_name().
    
    3 The function TABLE_SHARE::get_table_ref_version() is invoking
      both dd::Dictionary::is_dd_table_name() and
      dd::Dictionary::is_system_view_name().  This is a overhead.  This
      patch adds a TABLE_SHARE->table_category called
      TABLE_CATEGORY_DICTIONARY. This helps us avoid call to
      is_dd_table_name(). And use TABLE_SHARE->view_object->type() ==
      dd::enum_table_type::SYSTEM_VIEW to check if that is a system view.
    
    4 The patch does following change, that is not necessarily to
      improve the permformance. Basically the revno 56eaef86 sets
      MYSQL_OPEN_IGNORE_FLUSH flag while opening DD tables in
      Open_dictionary_tables_ctx::open_tables().  And later the revno
      11eeb00a removes this flag, expecting open_table() to set it for
      DD tables. Conceptually it looks correct to set this flag for all
      DD table at Open_dictionary_tables_ctx::open_tables() so this
      patch retain setting of this flag as done by revno 56eaef86.
      These revno are from mysql-trunk-wl6599-1 branch.

[33mcommit b435c4893f32e0c8ad197e95bd3c051dcf201f62[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Wed Aug 17 09:43:37 2016 +0200

    WL#6599 - New Data Dictionary and I_S integration.
    
    Post-push patch fixing POINT_SELECT [1;31mperf[mormance regression fix.
    
    The patch does following improvement in open_tables() call flow,
    
    1 We were invoking dd::Dictionary::is_system_view_name() several
      times for a table. E.g., SELECT_LEX::add_table_to_list() would
      already know that if a TABLE_LIST is a system view. We were not
      setting TABLE_LIST->is_system_view here.  This patch sets this in
      SELECT_LEX::add_table_to_list() and avoids calls to
      dd::Dictionary::is_system_view_name() function call which goes
      throw all the system view names within the open_tables() call flow.
    
    2 We also avoid call to dd::Dictionary::is_dd_table_name().
      Basically there are two possibilities of open_tables() call seeing
      a DD tables.
    
      a) DD table being opened as part of DD operations invoking
         dd::Open_dictionary_tables_ctx::open_tables().
    
      b) DD table being opened as part of I_S system view execution.
    
      During open_table(), we need to know if a TABLE_LIST belongs to a
      DD table for several checks. Currently we do that by invoking
      dd::Dictionary::is_dd_table_name() which is a looking in a list.
      We can avoid that as described below.
    
      When open_table() is opening a DD table in case of a), the
      table_list used there is nothing but dd::Raw_table::m_table_list.
      And we are sure that this belongs to only DD tables. So, this
      patch adds a member TABLE_LIST->is_dd_table, which is set only by
      dd::Raw_table.  So the open_table() call now uses it.
    
      For b), we know that TABLE_LIST->is_system_view is marked for all
      the I_S system views. And
      TABLE_LIST->referencing_view->is_system_view would tell us that
      the TABLE_LIST is refering to a DD table. So, this avoids calls
      to dd::Dictionary::is_system_view_name().
    
    3 The function TABLE_SHARE::get_table_ref_version() is invoking
      both dd::Dictionary::is_dd_table_name() and
      dd::Dictionary::is_system_view_name().  This is a overhead.  This
      patch adds a TABLE_SHARE->table_category called
      TABLE_CATEGORY_DICTIONARY. This helps us avoid call to
      is_dd_table_name(). And use TABLE_SHARE->view_object->type() ==
      dd::enum_table_type::SYSTEM_VIEW to check if that is a system view.
    
    4 The patch does following change, that is not necessarily to
      improve the permformance. Basically the revno 56eaef86 sets
      MYSQL_OPEN_IGNORE_FLUSH flag while opening DD tables in
      Open_dictionary_tables_ctx::open_tables().  And later the revno
      11eeb00a removes this flag, expecting open_table() to set it for
      DD tables. Conceptually it looks correct to set this flag for all
      DD table at Open_dictionary_tables_ctx::open_tables() so this
      patch retain setting of this flag as done by revno 56eaef86.
      These revno are from mysql-trunk-wl6599-1 branch.

[33mcommit 8463d4898ff8b6ea211c04bd4851a15a907955d4[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Wed Aug 10 15:04:27 2016 +0200

    WL#7069: Followup. Avoid looking up dd::INVALID_OBJECT_ID in the DD
    
    dd::INVALID_OBJECT_ID does not identify a valid object, but when acquiring a DD
    object by id this is not explicitly checked and since the object is guaranteed
    not to be in the cache, a query of the DD table will always be [1;31mperf[mormed before
    concluding that there is no such object.
    
    This overhead is avoided if acquire_tablespace() in sdi_tablespace.cc checks
    the table's tablespace id and returns early if it is dd::INVALID_OBEJCT_ID.
    
    Reviewed by Sivert Sørumgård

[33mcommit 2e8bc4fbf2b9d418b39ea6f1fb9d9231fffc5efb[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Wed Aug 17 12:11:04 2016 +0200

    WL#7069: Followup. Avoid running [1;31mperf[m unit test in debug builds, and reduce
    number of iterations in optimized builds.
    
    There is not much point in running a [1;31mperf[m test in debug mode, and there is no
    point in wasting cpu on many iterations unless benchmarking.
    
    Patch reviewed by Tor Didriksen.

[33mcommit 0a10fc8b5ca0f7eac1c952f9ab0ee1720360b728[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Fri Aug 12 17:45:09 2016 +0200

    WL#6599 - New Data Dictionary and I_S integration.
    
    This WL defines INFORMATION_SCHEMA (I_S) system view over DD tables,
    representing a I_S table. This will eliminate the need of preparing a
    temporary table for each I_S table during execution and enable faster
    execution of I_S queries.
    
    A. Functional changes introduced:
    ---------------------------------
    A.1) Implements following I_S tables as a system view.
    
      CHARACTER_SETS
      COLLATIONS
      COLLATION_CHARACTER_SET_APPLICABILITY
      SCHEMATA
      TABLE_NAMES
      TABLES
      VIEWS
      COLUMNS
      STATISTICS
      KEY_COLUMN_USAGE
      TABLE_CONSTRAINTS
    
    A.2) Implements following SHOW commands to use A.1).
    
      SHOW CHARSET
      SHOW COLLATION
      SHOW DATABASES
      SHOW TABLES
      SHOW TABLE STATUS
      SHOW COLUMNS
      SHOW KEYS/INDEXES
      SHOW STATISTICS
      DESCRIBE
    
    A.3)
      Introduces a session variable 'information_schema_stats' that
      enables use to decide how to get the table/index dynamic
      statistics. Setting it to 'latest' would get latest statistics
      from storage engine. And setting it to 'cached' would get
      statistics stored in mysql.table_stats/index_stats. These are two
      new DD tables introduced by this WL. These tables are updated
      when user runs ANALYZE TABLE on a table. For more details see HLS
      2.1.4) and 2.1.12).
    
    A.4) Introduced following new DD columns, see HLS 2.1.8) for more
         details.
    
      COLUMNS.COLUMN_KEY
      COLUMNS.COLUMN_TYPE
      COLUMNS.DEFAULT_VALUE_UTF8
      TABLES.ROW_FORMAT
    
    A.5)
      Implements special handling for SHOW COLUMNS/KEYS for temporary
      tables as the meta data of temporary tables are not stored in DD.
    
    A.6)
      I_S tables are temporary tables on 5.7. This make them
      possible to access under LOCK TABLE mode with explicitly
      locking I_S tables. Now with this WL, the query execution
      procedure fails to process I_S system view as the under laying DD
      table are not locked.
    
      So, this WL makes the SQL server to open the DD tables used by
      a I_S system view without requiring them to be locked explicitly.
    
    B. Performance improvements:
    ----------------------------
    
    See mysql wiki page WL6599_I_S_[1;31mperf[mormance_with_data_dictionary
    for more details. (HLS section 5)
    
    C. Compatibility issues:
    ------------------------
    There are few differences in the way mysql server would behave
    after this WL. The detailed list of these change in behavior is
    listed under HLS section 6).
    
    D. Source files:
    ----------------
    Most of code changes are placed in sql/dd/info_schema folder.
    
    * Refer code in sql/dd/info_schema/show.* to know how SHOW
      commands are implemented.
    
    * Refer code in sql/dd/info_schema/stats.* to know how the
      retrieval of dynamic statistics are implemented.
    
    E. Related WL's and Bugs:
    -------------------------
    
    * WL#7167 Change DDL to update rows for view columns in
      DD.COLUMNS and other dependent values.
    
      I_S.COLUMNS will get column meta data for views from
      mysql.columns. The view's column meta data are stored in
      mysql.columns by this WL. The WL takes care of enabling several
      test cases that is disabled by this WL#6599. So WL#6599 and
      WL#7167 would be pushed together. They are QA'ed together.
    
    * WL#7464 - InnoDB: provide a way to do non-locking reads.
      This WL enables execution of I_S queries do to non-locking reads.
    
    * WL#8232 - New data-dictionary: change approach to table
                row_format and index algorithm validation/handling
    
    Upcoming WL:
    * WL#9494   Implement INFORMATION_SCHEMA system views for
                SP/TRIGGERS/EVENTS/REFERENTIAL_CONSTRAINTS
    
    * WL#9495   Update schema tables of dynamic plugins into data
                dictionary.
    
    The following bugs would be fixed by this WL:
      Bug#11748044
      Bug#13878164
    
    F. Disabled tests:
    ------------------
    
    thread_pool.thread_pool_i_s : Would be fixed by WL#9495.
    i_innodb.innodb_bug14150372 : WL6599_INNODB_SPORADIC

[33mcommit 1c2a30991442f399719978fc9af616ab470b5aa4[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Thu Aug 11 13:59:55 2016 +0800

    Followup: BUG#24287290 BUF POOL MUTEX ORDER VIOLATION IN BUF_POOL_RESIZE
              WITH MULTIPLE INSTANCES
    
    Fix sys_vars.all_vars and [1;31mperf[mschema.show_sanity failures on pb2.

[33mcommit f2bc0f89b7f94cc8fe963d08157413a01d14d994[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Wed Aug 10 17:41:28 2016 +0200

    WL#8688: Support ability to persist SET GLOBAL settings
    
    This WL introduces an option to persist global dynamic configuration variables,
    for example like SET PERSIST innodb_flush_log_at_timeout= 14;. Configuration
    variables over a connection are lost after server restart. This WL provides
    DBAs a way to store configuration variables in a persistent way and allow
    server to read and apply all those variables which are persisted during a
    restart. A new config file name mysqld-auto.cnf will be created in datadir
    when a variable is persisted. This new config file is in JSON format.
    
    In addition to the persistence we add a [1;31mperf[mormance schema table called
    "variables_info" which will have an entry for all configuration variables.
    This table will also have information about where the current value came
    from and some additional information about the variable. The historical
    configuration files can be used as before.
    
    This WL provides a read only system variable named persisted-globals-load
    which provides an option to enable/disable reading of persistent config file.

[33mcommit e8538d14d9676ca9fb669996ec1b60481874eb49[m
Author: Mohit Joshi <mohit.joshi@oracle.com>
Date:   Tue Aug 9 15:08:23 2016 +0530

    Bug#24397674 INNODB.DOUBLEWRITE SOMETIMES SKIPS IN PB2 RUNS
    
    Problem: The above test attempts to [1;31mperf[morm crash recovery. If a checkpoint does not
    occurs during the time frame where we want to generate redo log records, the test runs.
    However, if a checkpoint occurs, the test skips because in that case we cannot test the
    recovery.
    
    Due to the above behaviour, the test sometimes run and sometimes skip on PB2.
    
    Fix: The fix enables the global debug variable innodb_master_thread_disabled_debug=1.
    This ensures the test always runs. In case, this debug variable is not set by the server
    because of some reasons, we have made changes in the test so that the test exits instead
    of a skip. This will notify us when the test is failing.
    
    Reviewed by: Satya Bodapati <satya.bodapati@oracle.com>
    RB: 13563

[33mcommit 5ada0790cffc36738ad5d4f7cbdcb338c45811b5[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Aug 8 18:40:45 2016 +0200

    BUG#24365418 DROP_TABLE_SHARE LEAVES GLOBAL_TABLE_SHARE_CONTAINER AS FULL
    
    Before this fix, [1;31mperf[mormance schema instrumentation associated with a table
    may not always be recovered during DROP TABLE, leading to memory leaks.
    
    The root cause is function drop_table_share(),
    which calls directly:
      pfs->m_lock.allocated_to_free();
    bypassing the container logic.
    
    This marks the record itself as free, but leaves behind:
    - the container page ::m_full flag,
    - the overall container ::m_full flag.
    
    The proper fix is to call:
      global_table_share_container.deallocate(pfs);
    instead, which maintains integrity.

[33mcommit 7f9b14de3d63390019fb50f7fdabc1e94eb3852f[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Tue Aug 9 07:37:37 2016 +0200

    WL#8688: Support ability to persist SET GLOBAL settings
    
    This WL introduces an option to persist global dynamic configuration variables,
    for example like SET PERSIST innodb_flush_log_at_timeout= 14;. Configuration
    variables over a connection are lost after server restart. This WL provides
    DBAs a way to store configuration variables in a persistent way and allow
    server to read and apply all those variables which are persisted during a
    restart. A new config file name mysqld-auto.cnf will be created in datadir
    when a variable is persisted. This new config file is in JSON format.
    
    In addition to the persistence we add a [1;31mperf[mormance schema table called
    "variables_info" which will have an entry for all configuration variables.
    This table will also have information about where the current value came
    from and some additional information about the variable. The historical
    configuration files can be used as before.
    
    This WL provides a read only system variable named persisted-globals-load
    which provides an option to enable/disable reading of persistent config file.

[33mcommit 140e3444b79ab1be69f988e98939a4a0ef0ba1e7[m
Author: Maitrayi Sabaratnam <maitrayi.sabaratnam@oracle.com>
Date:   Thu Aug 4 10:36:18 2016 +0200

    Bug#23028418 - RESTARTING DATA NODE CRASHES CLUSTER; NDBREQUIRE FAILS WHEN CREATING DICT TABLE
    
    When a data node has insufficient redo during a System Restart(SR), it
    does not participate in the SR until after the other nodes have
    started.  Then it [1;31mperf[morms a Takeover of its fragments from the
    started nodes in its nodegroup.  During this takeover the node still
    considers that it is involved in a System Restart (SR), but it is more
    akin to a Node Restart (NR), as the cluster is running and accepting
    user transactions, DDL operations etc...
    
    In SR scenarios, table creation handling in DIH has a different
    behaviour than normal, as table 'creation' is related to reloading
    table definition data from disk on the Master node.  During NR /
    Takeover, table creation can occur on non-master nodes due to user
    activity.  However, the mechanism in DIH to determine how to handle
    takeover assumes that if the restart type is 'System Restart', then
    any table creation must be SR related.
    
    The solution is to add an extra check to this SR special case path to
    look at whether the running node is the Master node and use that to
    determine the difference between SR and (SR+Takeover).

[33mcommit fc0c40631f36b2ea9337e67a1c181a8b3f24b9cb[m
Author: Anushree Prakash B <anushree.prakash.b@oracle.com>
Date:   Wed Aug 3 11:39:18 2016 +0530

    Bug #17180985 : GRANT AND SET PASSWORD FUNCTIONS ACTING
                    INCONSISTENTLY ON INVALID USERS
    
    Description:
    Changing the password using GRANT command updates the
    password for an invalid user and changes it to a valid one.
    
    Analysis:
    Setting a password for users can be done by using SET
    PASSWORD function or GRANT function with IDENTIFIED BY
    clause.  The SET PASSWORD uses change_password module
    to [1;31mperf[morm the operation whereas the GRANT function
    uses replace_user_table.
    
    The behaviour for change_password is as expected. It reads
    the user from ACL, makes the operations and then updates
    the table. Since the user is not loaded in ACL, error
    is thrown at the first stage itself.
    
    However, replace_user_table reads the user from the table
    itself, updates the table and then checks with ACL.
    The table is updated first and then the error is thrown.
    This results in making an invalid user appear as a valid
    one.
    
    Fix:
    The fix for this issue is to [1;31mperf[morm a check for a valid
    user in replace_user_table before updating the table fields.
    If the user is not valid, we shouldn't proceed further with
    updation and simply return an error.

[33mcommit 8d5089b714b8f768c4a62389e638ab5e1f95814f[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Tue Aug 2 15:20:08 2016 -0700

    Bug #23020280: INNODB_BUG56143.TEST FAILURE
    - COUNT_ALLOC IN MEMORY_SUMMARY_GLOBAL_BY_EVENT_NAME IS NOT 0
    
    This patch is more complete than the last one since it adds 13 modules that contain
    some form of the case insensitive grep for "ut_malloc", "ut_alloc" and "ut_new".
    The previous patch that was reverted missed 5 modules and it caused a regression
    on PB2 because a [1;31mperf[mormance schema array size was no longer large enough.
    Here, PFS_MAX_MEMORY_CLASS is increased to 350 from 320 so that there is
    more room for new modules.

[33mcommit 9724f2bf888701640e960eeb1a1bd137e074079b[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Wed Jul 27 11:52:29 2016 -0600

    Bug #23020280: INNODB_BUG56143.TEST FAILURE
          - COUNT_ALLOC IN MEMORY_SUMMARY_GLOBAL_BY_EVENT_NAME IS NOT 0
    
    According to the following comment in ut0new.h, we need to include basenames
    into the list called auto_event_names, found in ut_new.cc, for every InnoDB
    code file that uses a form of "ut_new" or "ut_malloc" to allocate memory.
    This patch adds 6 base names that were found to be missing.
    
    /** Keys for registering allocations with [1;31mperf[mormance schema.
    Pointers to these variables are supplied to PFS code via the pfs_info[]
    array and the PFS code initializes them via
    PSI_MEMORY_CALL(register_memory)().
    mem_key_other and mem_key_std are special in the following way (see also
    ut_allocator::get_mem_key()):
    * If the caller has not provided a key and the file name of the caller is
      unknown, then mem_key_std will be used. This happens only when called from
      within std::* containers.
    * If the caller has not provided a key and the file name of the caller is
      known, but is not amongst the predefined names (see ut_new_boot()) then
      mem_key_other will be used. Generally this should not happen and if it
      happens then that means that the list of predefined names must be extended.
    Keep this list alphabetically sorted. */

[33mcommit 7f0d7f93ec3c98b349a316b057ae48ef55be1c39[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Thu Jul 21 15:35:56 2016 +0200

    WL#9468: Step 2. Create a template for a stateless allocators which can be
    instantiated with callable class types that use different [1;31mperf[mormance schema
    memory keys.
    
    The std::basic_string template can only be instantiated with allocators that
    are default-constructible (See
    http://gcc.gnu.org/bugzilla/show_bug.cgi?id=56437 "basic_string assumes that
    allocators are default-constructible"). So what is needed is a stateless
    allocator which can use different PSI_KEYS. In order to be stateless the
    PSI_KEYs have to be provided as template arguments. Unfortunately, this is not
    possible, as PSI_KEY values are not compile time constants.
    
    This changeset introduces a Stateless_allocator template which takes two type
    arguments that are callable objects (functors) which will be used to allocate
    and deallocate memory. This works because the callable object type is known at
    compile time, but the value of the PSI key is not resolved until the allocation
    actually happens. The drawback is that a separate Functor class has to be
    created for each PSI key which will be used with the Stateless_allocator template.

[33mcommit 7a7aae9118297f80bea0c617f72128f84d9f682c[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Wed Jul 13 09:09:15 2016 +0200

    Bug#24286064: JSON MEMORY USAGE MISSING FROM THE MEMORY SUMMARY TABLES
    
    Information about JSON memory usage was missing from [1;31mperf[mormance
    schema's memory summary tables.
    
    Fix: Add the missing entry for JSON in the all_server_memory array.
    This entry got lost when WL#7909 was merged from 5.7 to trunk.

[33mcommit 01f23f4b4ad48a75d519c1c44b2eedf00127a03e[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Tue Jul 5 13:02:44 2016 +0200

    WL#7069: Followup: Extend deserialization to handle both const and non-const cross reference pointers
    
    Problem: The functions overloads lookup_opx_reference(Sdi_rcontext*, T**. uint) would not bind their second argument to &var where the type of var is const T*.
    
    Solution: Change the function so that it returns T* and let the templated
    calling function [1;31mperf[morm the assignment. Since the calling function is
    templated, overloading must still be used to select the correct version of the
    function. Since it is not possible to overload on return value, a dummy
    const T* argument must be added to the signature. This works because const T*
    will bind to both a T* and const T* (unlike T** or const T**).

[33mcommit 878aa4d389cc953d9c457a4413a17b462a2c71b4[m
Author: Thayumanavar S <thayumanavar.x.sachithanantha@oracle.com>
Date:   Tue Jul 5 12:07:19 2016 +0530

    BUG#22244911 - VIO_IO_WAIT ON MAC OSX USES SELECT
    
    vio_io_wait on Mac OS X uses select. This limits the fd
    values it can work up to 1024.  This patch makes use of
    kqueue event notification facility on Mac OS X and FreeBSD
    kernels. The Kqueue event notification provides a scalable
    event-driven I/O notification and it supports nanosecond
    resolution. The patch uses a kqueue per vio struct. The
    patch also shows [1;31mperf[mormance improvements on Mac OS X
    compared to the previous I/O wait mechanism.

[33mcommit dd6c46bb8f6f9f098e1978f90303d0726e28d0c9[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Fri Jun 10 09:30:22 2016 +0200

    Bug#23540008 SAFE GUARD FOR CHARSET_INFO RETURNED FROM GET_CHARSET
    
    When executing a SELECT from tables:
    - [1;31mperf[mormance_schema.events_statements_current
    - [1;31mperf[mormance_schema.events_statements_history
    - [1;31mperf[mormance_schema.events_statements_history_long
    
    the code reads data that can be concurrently written to.
    
    This race condition is expected ([1;31mperf[mormance schema data buffers are lock
    less), but the code is not robust enought.
    
    In particular, the character set for the sql query text may be invalid.
    
    Before this fix, this condition could cause a crash.
    
    With this fix, reading an invalid character set will truncate the SQL
    TEXT column.

[33mcommit 3c61bcae3ce7f597861e4562331d14b5e449bc8d[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Jun 1 15:35:57 2016 +0200

    Bug#23336542 DIGEST AVAILABLE IN EVENTS_STATEMENT_CURRENT ONLY AFTER STMT
    COMPLETES
    
    Before this fix, columns DIGEST and DIGEST_TEXT
    in table [1;31mperf[mormance_schema.events_statements_current
    were populated only after the end of statement execution.
    
    With this fix, these columns are available just after parsing,
    before the statement execution itself starts.
    
    This change is critical for monitoring applications,
    which need the current statement digest during the statement execution.
    
    The logic that populates these columns was moved
    - from pfs_end_statement_v1()
    - to pfs_digest_end_v1()

[33mcommit 2709cb6abc45a2a38ba12e8467be92f2a5801c72[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Wed May 18 10:52:28 2016 +0200

    BUG#23225768 NDBCLUSTER SHOULD USE MYSQL_MUTEX_T WRAPPER
    
    - In MySQL Server 5.7 the mutex and condition was refactored into
      three layers of mutex types available from mysys. This caused all
      ndbcluster code using pthread_mutex_t to start using the
      native_mutex_t instead. This change causes merge conflicts all the
      time and also makes it impossible to use for example
      the safe_mutex functionality which can help find cases where
      dependent locks are held or not.
    - Fix by changing to use mysql_mutex_t in ha_ndbcluster.
      The mutexes will not be [1;31mperf[mormance schema instrumented at this
      time.
    - Move mutex initializers in Ndb_index_stat_thread and Ndb_util_thread
      which are "static global" to do_init() so that they are created after
      the safe mutex functionality is initialized. Corresponding
      change to deinit function.

[33mcommit 86da46bfa34e45fd1a7d29b6be8999c99e336f5e[m
Author: John David Duncan <john.duncan@oracle.com>
Date:   Thu May 26 21:42:06 2016 -0700

    wl#9048 NDB Support for MySQL Server access to VIRTUAL GENERATED columns
    
    Squashed commit of the following:
    
    commit f893c00ca96267e0fbd759da33fa534058ab9236
    Merge: 3647279 da63d14
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 25 14:13:02 2016 -0700
    
        Merge ../working/wl9048 into mysql-5.7-cluster-7.5-wl9048
    
    commit da63d14ede4b9746fbac6ffd57828b6f12050c0c
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 25 14:11:31 2016 -0700
    
        Improve comments in Ndb_table_map header
    
    commit 0e43d0ee423b7a2d1f51beeef4d11f7a2e034b93
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 25 13:53:39 2016 -0700
    
        suite/gcol: apply changes based on ReviewBoard #11355 comments for wl#9048
    
    commit 0d28cd9c8f3f4955b09e25876c8b26935e912688
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 25 11:23:21 2016 -0700
    
        wl#9048: Ndb_table_map now wraps a const NdbDictionary::Table *
        (or a null pointer, in the CREATE TABLE use case) and its getColumn()
        method.
    
    commit e65f75b67fe4aa11f71f1797debdd9cfb506ccee
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 24 21:13:40 2016 -0700
    
        suite gcol_ndb cosmetic change
    
    commit 3647279b996e633afd13cec0a9c74b32335bcc72
    Merge: 9819c67 21f36a0
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 24 19:46:51 2016 -0700
    
        Merge ../working/wl9048 into mysql-5.7-cluster-7.5-wl9048
    
    commit 21f36a07b2f2cc7060316bcfefb2c436c62722f7
    Merge: 2c30e80 07cb5b3
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 24 19:46:37 2016 -0700
    
        Merge branch 'mysql-5.7-cluster-7.5' of /Users/jdd/git-work-trees/working/../mysql into mysql-5.7-cluster-7.5-wl9048
    
    commit 9819c6795dab4925c0cf109668c4380eef69faf1
    Merge: 2149fb0 07cb5b3
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 24 19:45:09 2016 -0700
    
        Merge branch 'mysql-5.7-cluster-7.5' into mysql-5.7-cluster-7.5-wl9048
    
    commit 2c30e8003047d777218527320d760433140e273c
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 24 19:43:46 2016 -0700
    
        wl#9048: improve test case in ndb_rpl to test replication for both stored and virtual gcol
    
    commit 2149fb089d31173bf584497bfdf5c13f94a657e3
    Merge: a7a5d8a 5fd29e7
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 24 18:30:44 2016 -0700
    
        Merge ../working/wl9048 into mysql-5.7-cluster-7.5-wl9048
    
    commit 5fd29e784aae1b39a15e2c6e2886b223502b30a0
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 23 21:56:45 2016 -0700
    
        one additional --sorted-result in suite/gcol/inc
    
        merge me
    
    commit a7a5d8a2cae436998302c59939c05ab254ae4c6d
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 23 21:56:45 2016 -0700
    
        one additional --sorted-result in suite/gcol/inc
    
    commit 6143a23090c8e7ee62588b9c4fc8dd799e3f97c0
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 23 14:27:02 2016 -0700
    
        wl#9048 add more test cases for joins
    
    commit cbd012ea92e60286fc11546cb7acf32bb2cddc0d
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 23 14:11:15 2016 -0700
    
        wl#9048: Rather than creating an Ndb_table_map on the stack for each joined table, use the existing m_table_map from each table's handler
    
    commit bfa42ed1625aff9541750042e1afe0e84f8f2c98
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Fri May 20 12:50:28 2016 -0700
    
        wl#9048: fix bitmasks in several more places
    
    commit cf46dc1bf7e1ef9045d901cb9dacf9c788fb845c
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Fri May 20 11:50:03 2016 -0700
    
        wl#9048: Optimize Ndb_table_map constructor in trivial case.
    
    commit 3645679ad6eaf7f123aeb8f7c5f87ce46ecafde6
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Fri May 20 11:48:44 2016 -0700
    
        wl#9048: In create_pushed_join() use a correct Ndb_table_map for each joined table.
    
    commit 1b7679e7dc9f3fa64bebb2fb76090888fbce3f36
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 17 13:52:14 2016 -0700
    
        wl#9048 update result file
    
    commit 7729cf0e40331ded1499be6c88102a9aa71e87c2
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 17 13:45:52 2016 -0700
    
        wl#9048 misc. style revisions
    
    commit 5aa5cff8c520f3c97e270689102b05176c68bf32
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 17 13:44:22 2016 -0700
    
        wl#9048 renaming.
         Rename m_col_id_map to m_table_map
         Rename Ndb_table_map::rewrite_bitmap() to Ndb_table_map::get_column_mask()
    
    commit 44ca4f096131534a0aa4e5391279115c460ac0bc
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 17 13:40:21 2016 -0700
    
        wl#9048: additional SELECT tests
    
    commit 3be4a9f5a8048bc86064d6c50177ba8436089cc2
    Merge: 41de158 7c3e740
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 17 09:29:09 2016 -0700
    
        Merge branch 'mysql-5.7-cluster-7.5' into mysql-5.7-cluster-7.5-wl9048
    
    commit 41de1589c6ed8c8f92dbe4232492effedbe199ce
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 17 09:27:43 2016 -0700
    
        wl#9048: work on gcol_select_ndb test failures
    
    commit d168833d032208b639021b5d35490390da18d201
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 16 11:43:12 2016 -0700
    
        Two more cases in suite/gcol/ where results must be sorted for NDB
    
    commit f425e3a92a64c68058fd41091e1d58f33d270a92
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Fri May 13 13:57:29 2016 -0700
    
        Add mtr collection for testing of this branch
    
    commit dd3f3195594e62cd2fab791945f72064b4c953c3
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Fri May 13 13:52:22 2016 -0700
    
        wl#9048 -- some revisions after code review.
        Not all of this is meant to be kept.
    
    commit b5249c28f3ac9b5b4a3afa5da3380b197112c7bf
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:44 2016 +0200
    
        WL#9048
    
         - add and fix comments
    
    commit dbee585185197bb6787dd1635d573fcbf9785864
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:43 2016 +0200
    
        wl#9048
    
         - data type questions.
    
    commit bce6e2c46f910fe2b2690a5cec9e39f076810a6e
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:42 2016 +0200
    
        wl#9048
    
         - move variables to scope where they are used.
         - would actually prefer if they were only in the for loop scope.
    
    commit 4e7b0672de339b772ca81a5a004b099648f36169
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:41 2016 +0200
    
        wl#9048
    
         - const fixes
    
    commit 70e2411ef4f1948ea1d086c5847d080d04733d8f
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:40 2016 +0200
    
        wl#9048
    
         - remove the almost unused operator[]
         - think it should go since there are two mappings which can be
           [1;31mperf[mormed and without calling a function it's hard to know which
           one.
         - clearer code if we call a function.
    
    commit e35b5042209ccdd4c786ffdb36b7e36f047d973f
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:39 2016 +0200
    
        wl#9048
    
         - add TABLE* which could be used to check functions
           calls programatically.
         - Perhaps only needed for DBUG compile?
         - Perhaps not _all_ properties need to be stored and instead we can
            look them up from m_table. For example m_trivial?
         - we should of course not add it if not used...
    
    commit a6086095a520c5651d13748215383873e6ce9660
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:38 2016 +0200
    
        wl#9048
    
         - initialize member variables early and make them const
    
    commit 501042a8d60379ecd558bf86da0450db6e8acb67
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:37 2016 +0200
    
        wl#9048
    
         - remove Ndb_table_map::init()
    
    commit b3cb28577376aee9e70b3854fd60350841ae933c
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:36 2016 +0200
    
        wl#9048
    
         - remove default constructor for Ndb_table_map, instead create
           the m_col_id_map* from ::open() and close() when it's well known
           which TABLE* to use.
         - should make us detect if the Ndb_table_map is used from
           not open'ed ha_ndbcluster(since m_col_id_mape will be NULL).
         - didn't remember syntax for how to use operator[] from pointer
         - also allows the constructor to be changed to make much more things
        const.
         - think we might even be able to save a pointer to TABLE* to allow
        checking field->stored_in_db etc.
         - starting to see Ndb_table_map more as a wrapper around TABLE
    
    commit 9ca68d82c864a6b8b509a2664a60dde18a5c2569
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:35 2016 +0200
    
        wl#9048
    
         - use stack allocated Ndb_table_map in ha_ndbcluster::create()
         - should try to use ha_ndbcluster member variables only between open()
            and close() and the handler is not open when calling create().
         - trying to make ha_ndcluster::create() a const function at least.
         - yes, I know it already uses m_table and m_tabname etc. but if we
           could get this new code to work without m_col_id_map it would be
           nice.
    
    commit 2a9787158764ef299b37a36366a024d62d6dd41f
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:34 2016 +0200
    
        wl#9048
    
         - remove unused parameter for create_table_set_up_partition_info()
    
    commit 9649b13cedecc88ecd1d27b01ff25763d6e9b884
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:33 2016 +0200
    
        wl#9048
    
         - don't use ha_ndbcluster_glue.h which we intend to remove
           as it includes and exposes too much
         - reduce interface of Ndb_table_map, forward declare usage of TABLE
           and onlky include parts which are really used in the implementation
    
    commit 801461babfaa30cbc0303b963131e810d6419317
    Merge: bb268ec a438906
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Fri May 13 12:06:04 2016 -0700
    
        Merge branch 'mysql-5.7-cluster-7.5' of /Users/jdd/git-work-trees/working/../mysql into mysql-5.7-cluster-7.5-wl9048
    
    commit bb268ec306860367aee7dc07e2c1c9b20f610c10
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Thu May 12 13:49:14 2016 -0700
    
        More result sorting in gcol_view test
    
    commit d277c141023e0ead16322e41433975b0ec214c72
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Thu May 12 12:45:11 2016 -0700
    
        wl#9048: Add test case for various NDB column layouts
        including generated, blob, hidden pk, and char(0) columns
    
    commit f1340826d9fc9812c3c8f1e074ca612aca2d775c
    Merge: 1b701d8 45c99c3
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Thu May 12 11:33:21 2016 -0700
    
        Merge branch 'mysql-5.7-cluster-7.5' of /Users/jdd/git-work-trees/working/../mysql into mysql-5.7-cluster-7.5-wl9048
    
    commit 1b701d84265dff9947a3639a10975b6cfac6132f
    Merge: 0a94d97 b708ebf
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 11 10:13:39 2016 -0700
    
        Merge branch 'mysql-5.7-cluster-7.5' of /Users/jdd/git-work-trees/working/../mysql into mysql-5.7-cluster-7.5-wl9048
    
    commit 0a94d975a159f78f2c7701de769f6e7ce130ad15
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 10 16:28:20 2016 -0700
    
        revert bug where table->s->fields was wrongly changed to table->s->stored_fields
    
    commit f8a39d1a422e31b682b7b91d26fb379bbd161fc7
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 10 15:19:59 2016 -0700
    
        wl#9048: In suite/gcol_ndb add tests based on suite/gcol/inc/
    
    commit 804a19d5bcd858109b5ab066da29214a65820ac3
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 10 15:16:50 2016 -0700
    
        wl#9048: Add "ORDER BY" and "--sorted_result" in suite/gcol as needed for tests have repeatable results in NDB.
    
    commit 14e7129ccd3a1e990c2397e2fce839f9e4505362
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 10 15:13:21 2016 -0700
    
        wl#9048 Fix crashing bug in online ALTER TABLE where generated columns are present.
        The binlog injector thread must call lex_start(thd) to initialize lexer so that
        it can parse the SQL expressions for generated columns.
    
    commit 8f818e9abec7d24d47730845097bfbb28ca468a5
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 10 15:11:58 2016 -0700
    
        wl#9048: Move TableMap class from ha_ndbcluster to new ndb_table_map.h|cc files.
    
    commit ab62f7ed23cac892d08e5602cb01b0708bcb72fd
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 9 15:25:22 2016 -0700
    
        wl#9048: in suite/gcol/ add "ORDER BY" needed to make results deterministic for NDB.
    
    commit 1e8f6221cca79e2b5ee0673c305c9ae924d4a735
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 9 14:17:02 2016 -0700
    
        Add dbug output to ndb_set_record_specification
    
    commit abdb3459f09e368b75909f708bae8257bc9a4510
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 9 14:11:39 2016 -0700
    
        wl#9048: when using a MySQL bitmask with NdbRecord, rewrite it if necessary to compensate for virtual columns
    
    commit 871f30bc39e227aa0d3361fb38587e2ffff2a7b0
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Thu May 5 14:01:20 2016 -0700
    
        wl#9048: add ORDER BY to all table scans in gcol_colum_def_options test
    
    commit e32186e61eda39ad0121c4c931cf3d58c6b6045b
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Thu May 5 13:22:14 2016 -0700
    
        wl#9048: adapt gcol test suite
        Some ALTER TABLE statements return error 1846 from NDB vs. error 1845 from MyISAM
    
    commit 8d94baf585541c7eceb7d8e60d385f3cea6de57f
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Thu May 5 12:00:30 2016 -0700
    
        wl#9048 BLOB handling: more checks for virtual columns
    
    commit 12a0e2982d4f2adcc1d67cc8b5027e40f22f542f
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 4 13:41:52 2016 -0700
    
        wl#9048 reclength vs. stored_rec_length
        stored_rec_length is the length of stored columns only in MySQL's record buffer.
        MySQL lays out the buffer with all stored columns first, then all virtual columns.
        This patch takes a conservative approach: in the case of copying data from NDB
        to MySQL, we only copy stored_rec_length bytes; but when using the length as
        an allocation size, we assume we need to allocate enough space for both stored
        and virtual columns.
        This also fixes one more case of virtual fields not being computed in MRR results.
    
    commit 5970f5a031c6c91351217b08ae94c4f8775dca3d
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 4 12:16:08 2016 -0700
    
        wl#9048: Support ALTER TABLE
        Note that online ALTER TABLE where the resulting table contains a virtual gcol
        is currently disabled due to crashing bug in NDB binlog injector thread.
    
    commit cc1ab4e2b8f044af6fcb447f5a8caf829e8087c0
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 4 11:59:32 2016 -0700
    
        wl#9048: Check for virtual fields in NDB binlog code
    
    commit 00a34d25c31c3cc01329a03aa60da267ef1abf78
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 4 10:06:30 2016 -0700
    
        wl#9048 update generated columns when reading in MRR and SPJ queries.
        Here we call update_generated_read_fields() from the NDB handler,
        though it is normally called from higher levels in the server, because
        these code paths are not shared with any other storage engines.
    
    commit c634530390abc8f6099169d7da9553b2def45637
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 4 10:00:06 2016 -0700
    
        wl#9048: check whether a query field is a virtual generated column in MRR and SPJ query plans.
    
    commit e0b762b57c47281d870e34a1e3b6d30c1beab831
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 4 09:56:26 2016 -0700
    
        wl#9048: Check for virtual fields and use TableMap to relate field number to column number
    
    commit 9b4faa95263ff34341f9d8d14e06f78013858d7f
    Merge: 3375e48 24d181f
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 4 09:34:45 2016 -0700
    
        Merge branch 'mysql-5.7-cluster-7.5' of /Users/jdd/git-work-trees/working/../mysql into mysql-5.7-cluster-7.5-wl9048
    
    commit 3375e48c9236982025b2fca9a89647d9b7444161
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 3 14:05:02 2016 -0700
    
        wl#9048: fix calculation of column number for hidden pk
    
    commit 1d7d830685361769c3c58dff5324c524cce01b5b
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 3 14:01:14 2016 -0700
    
        wl#9048: Handle virtual columns in CREATE TABLE
    
    commit db97a0019d4a57670a01004b625172861a634624
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 3 13:44:26 2016 -0700
    
        wl#9048 Create TableMap class.  http://rb.no.oracle.com/rb/r/12582
        Map between NDB column id and MySQL field id.
    
    commit 4c6f56537d11251bf778feda1879dc6d8de658b9
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 3 11:41:30 2016 -0700
    
        wl#9048: Commit gcol_ndb and ndb_rpl tests from original wl#8818 patch
        This creates suite gcol_ndb with some basic tests for stored generated columns
        and adds a simple generated column replication test to suite ndb_rpl.
        This commit does *not* include the ha_ndbcluster.cc implementation of stored
        generated columns from wl#8818, which is quite small and will be included
        in the wl#9048 implementation.
    
    commit 3a2cfc9b2175f6e5064499bddb8dff2a557e8483
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 3 11:17:57 2016 -0700
    
        wl#9048 Changes to mysql-test/suite/gcol/ -- http://rb.no.oracle.com/rb/r/11355/
        Update gcol suite for better reuse with NDB

[33mcommit 1c8b6a4d8f834a740c2b9335c7968b58e7202441[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue May 10 09:26:09 2016 +0200

    Bug#23202735 CLIENT PERFORMANCE REDUCED DUE TO THREADS WOKEN UP TOO EARLY
    
    This patch fixes two issues related to threads being
    woken up when not needed, and thus resulting in unnecessary
    context switches.:
    
    1)
    Avoid API Clients waiting in the poll queue to be woked up every 10ms.
    
    The 'poll-right' is given to (only!) one of the clients waiting
    for do_poll. The rest of the clients just wait there such that
    they can be woken up when the poller delivers something to them.
    However, a max wait time of 10ms is currently enforced, such that
    they may be woken to immediately be put back to sleep. This also
    implies dequeuing and requeing in the mutex protected poll queue.
    
    Iff the client threads waiting in the poll queue are properly
    signaled when signals are delivered, there should be no need to
    wake them up regularly. This patch removes the enforced 10ms max
    wait time, and instead wait the time specified by the callee.
    
    2)
    Fix a [1;31mperf[mormance problem in ::do_poll() where the polling 'clnt' does not
    check whether it has been woken up *itself* before completing the poll.
    
    It is sufficient that only some trp_client's in the poll-queue
    received data. ::do_poll will then signal these clients and
    give up its poll right, even if the max specified wait_time
    have not expired.
    
    Thus, another of the clients in the poll-queue has to be
    appointed as the new poller, and a *thread switch* is required
    to wake up that thread for more do_poll work.
    
    This patch allows do_poll() to continue polling until
    either the max specified wait_time have expired, or
    the polling client itself has been woken up (by being
    delivered what it waited for) This avoid unnecessary
    thread switches between the client threads and thus
    reduce the overhead in the API client. This results
    in a ~10% [1;31mperf[mormance improvement when the client
    threads does the polling themself.
    
    This is similar to the mechanism already implemented
    in the receiverThread, which explicit request to 'stay poll owner'
    when it has been activated. We still see that having the receiverThread
    doing the poll is faster than using the client thread. However,
    we believe that most of this is due to the receiver thread allowing
    more trp_client to have delivered signals before signaling them
    vs the client threads. (256 vs 16)

[33mcommit eda9201048d495932261d4ae93631ee9704a6c3d[m
Author: Annamalai Gurusami <annamalai.gurusami@oracle.com>
Date:   Thu Apr 28 12:29:00 2016 +0530

    WL#9141 InnoDB: Refactor uncompressed BLOB code to facilitate partial
    fetch/update
    
    Introduction:
    =============
    
    This is a sub worklog of "WL#8960 InnoDB: Partial Fetch and Update of BLOB".
    This worklog is the second sub worklog followed by "WL#8985 InnoDB: Refactor
    compressed BLOB code to facilitate partial fetch/update". The purpose of this
    worklog is to refactor current code so that new BLOB features can be added
    conveniently.  This worklog does to uncompressed BLOB similar to what wl#8985
    did to compressed BLOB code.
    
    Logical Changes:
    ================
    
    .  The functionality of uncompressed BLOB is provided by C-style functions.
       This will be converted to C++ classes, structs and member functions.
    .  The BLOB code will be isolated and kept in lob0lob.h and lob0lob.cc files.
       This will help in modular development of BLOB features.
    .  All references will now be LOB (large objects).
    
    Detailed Changes:
    =================
    
    . Introduced new module named lob.  It contains lob/lob0lob.cc and
      include/lob0lob.h files.
    . Added new namespace lob.
    . lob::Inserter - a new class to insert a complete uncompressed BLOB.
    . lob::zInserter - a new class to insert a complete compressed BLOB.
    . lob::InsertContext - a new class to contain contextual information for the
       insert operation.
    . lob::BaseInserter - a class that holds common state and functions useful
       for both compressed and uncompressed BLOB.  This is the base class for
       lob::Inserter and lob::zInserter.
    . lob::Deleter - a new class to destory/delete a BLOB
      (both compressed/uncompressed)
    . lob::DeleteContext - a new class to contain contextual information for the
      delete operation
    . lob::Reader - a new class to fetch a uncompressed BLOB.
    . lob::zReader - a new class to fetch a compressed BLOB.
    . lob::ReaderContext - a new class to contain contextual information for the
       fetch operation
    
    Design Rationale:
    =================
    
    There are 2 approaches that I explored - one is to have a single LOB class with
    each major operations as an member function.  For example,
    
    class LOB {
    public:
       int insert();
       int update();
       int read();
       // ..
    private:
       // ...
       Context* m_ctx;
    };
    
    But doing it this way, will make the class LOB like a kitchen sink.  It will
    end up that some member variables are used only when we are doing insert
    operation, and some other member variables are used when doing read operation
    and so on.  There won't be any cohesion b/w the member variables and member
    functions.  For one instance of the LOB class, we will most likely use only one
    operation, eg insert.  This is the reason I didn't prefer this approach.  The
    other approach is to design LOB classes around the major operations that will
    be [1;31mperf[mormed, which truely reflects the way these classes will be used.
    
    The current design of LOB classes revolves around the way the major operations
    that will be [1;31mperf[mormed on LOB data.  The currently supported major operations
    are insert, delete and read.  As of now all of them operate on complete LOB
    data.  For each of the major operation one new class is introduced.
    
    Inserter - for inserting LOB data.
    Reader   - for reading LOB data.
    Deleter  - for deleting LOB data.
    
    Now there are two variants to LOB data - compressed and uncompressed.  An
    insert operation or a read operation is completely depended on whether the data
    is compressed or not. But a delete operation is not that much dependant on
    this. Hence I introduced separate classes for compressed LOB.
    
    Inserter - for inserting uncompressed LOB data.
    zInserter - for inserting compressed LOB data.
    Reader   - for reading uncompressed LOB data.
    zReader   - for reading compressed LOB data.
    Deleter  - for deleting both compressed and uncompressed LOB data.
    
    At this point I noticed that there was some common code between Inserter and
    zInserter which I can factor out into a base class.  So I introduced
    BaseInserter which will contain common state and function useful for both
    Inserter and zInserter.  So the final list of main LOB classes are:
    
    Inserter - for inserting uncompressed LOB data.
    zInserter - for inserting compressed LOB data.
    BaseInserter - a base class containing common state and functions useful for
                       both Inserter and zInserter.  Inserter and zInserter derives
                       from this base class.
    Reader   - for reading uncompressed LOB data.
    zReader   - for reading compressed LOB data.
    Deleter  - for deleting both compressed and uncompressed LOB data.
    
    One point to be noted is that these classes are formed by refactoring existing
    code.  So to reduce the amount of code changes, I allowed some differences in
    the way they operate.  The Inserter and zInserter class is designed to insert
    all the LOB data of a single clustered index record.  It operates on the big
    record vector.  But the other classes (Reader, Deleter, zReader) all operate
    on a single LOB data only.  By doing it this way, I avoid significant amount
    of code changes.
    
    The main classes of the LOB module has been identified above.  To support them
    there was a need to provide context classes that will contain information needed
    for LOB operation.  Previously, the C style functions had a list of 6 or 7
    arguments.  These arguments are the context information that is necessary to provide
    the various main operations on LOB data.  For each main operation, the context
    information is identified separately.  They are as follows:
    
    InsertContext - context information for doing insert of LOB. `
    DeleteContext - context information for doing delete of LOB. `
    ReadContext   - context information for doing fetch of LOB. `
    
    The insert operation also has one special optimization - the bulk insert.
    These context classes evolved separately as I refactored one operation at a
    time.  And when I look back, I don't see any need to club them all together.
    There are some specific checks that are done only for the insert operation,
    like the redo log space check, which are captured in the InsertContext.  If
    we have a single context class, then it will contain unnecessary information
    not usable for the current operation.  Also, all these context classes are
    arrived at based on how and where it will be used.
    
    Finally, while evaluating this design, please do keep in mind that these
    classes come out of refactoring existing code.  If you look at the patch, the
    amount of code changed where LOB module is _used_ is very minimal.  I think my
    main focus was to isolate the LOB code and design a set of C++ classes which
    will make the extension of functionality easier.
    
    And the main purpose of refactoring was to enable to add partial fetch and
    partial modify/update operations.  For these purposes, I believe that this
    design is suitable.  Surely one can do more and more refactoring to achieve
    better results.  But since we are doing refactoring for a particular purpose, I
    think we should stop when our purpose will be solved.
    
    Functions Removed:
    ==================
    
    The following functions has been removed.
    
    . btr_copy_blob_prefix()
    . btr_copy_externally_stored_field_prefix_low_func()
    
    Functions Moved to lob module:
    ==============================
    
    The following functions are moved to the lob module.
    
    . btr_copy_externally_stored_field_prefix_func() and the associated
      macros.
    . btr_rec_free_updated_extern_fields()
    . btr_blob_get_part_len()
    . btr_blob_get_next_page_no()
    . btr_check_blob_fil_page_type()
    . btr_rec_free_externally_stored_fields()
    . btr_copy_externally_stored_field_prefix_func()
    . btr_copy_externally_stored_field_func()
    
    rb#11861 approved by Deb.

[33mcommit 48b67d94619aa11b3081accb90fbcb8d2c689826[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue May 3 11:57:06 2016 +0200

    Bug#23104498 MEMORY FOR 'SCALABLE_BUFFER' IS NOT SHOWN IN SHOW ENGINE
    STATUS
    
    Before this fix,
    - SHOW ENGINE PERFORMANCE_SCHEMA STATUS
    - SELECT * FROM [1;31mperf[mormance_schema.memory_summary_global_by_event_name
    would report conflicting data for the total memory used in the [1;31mperf[mormance
    schema.
    
    The root cause is the memory for the scalable buffer pages,
    instrumented as memory/[1;31mperf[mormance_schema/scalable_buffer.
    This memory is missing from show engine status.
    
    With this fix,
    SHOW ENGINE PERFORMANCE_SCHEMA STATUS
    now includes the mising memory,
    printed as "(pfs_buffer_scalable_container).memory"

[33mcommit 58187639671bf5266bd755dc84d2649b7296d664[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Tue May 3 08:53:02 2016 +0200

    WL#9250: Split LOCK_thd_list and LOCK_thd_remove mutexes
    
    This patch splits the LOCK_thd_list and LOCK_thd_remove
    mutexes into 8 instances. The THD list these mutexes protect
    is also split into 8. Same with the related COND_thd_list
    condition variable.
    
    This is done to remove the currently dominating mutex
    bottleneck for connect/disconnect [1;31mperf[mormance.
    
    The patch also reduces two critical sections for
    LOCK_global_system_variables for the same reason.
    
    More details below.
    
    - include/mysql/thread_pool_priv.h
    Remove unused arguments
    
    - mysql-test/t/connect_debug.test
    Remove test that is hard to rewrite now that the THD
    list is partitioned. Depending on the previous tests run
    by the server instance, a given THD might end up in different
    partitions and make it hard to block SHOW PROCESSLIST at
    the right place.
    
    - sql/sql_class.cc
    Move locking of LOCK_global_system_variables from THD:init()
    to plugin_thdvar_init(). This means that we can avoid having
    this mutex locked when calling cleanup_variables() on
    connection local (i.e. not global) system variables.
    
    - sql/sql_plugin.cc
    In alloc_and_copy_thd_dynamic_variables() only lock
    LOCK_global_system_variables after memory allocation (realloc)
    has been done. This part accesses global_variables_dynamic_size
    which is protected by LOCK_system_variables_hash, not
    LOCK_global_system_variables.

[33mcommit c6ba5fad2d2322e1a49bb88cefd71e5bf0f2bac9[m
Author: Ole John <ole.john.aske@oracle.com>
Date:   Thu Apr 28 11:29:08 2016 +0200

    Bug #22986823 HIGH CPU USAGE FOR ~NDB
    
    Patch fixes a problem with 'unfairness' in how
    TransporterRegistry::[1;31mperf[mormReceive() receives and delivers
    signals from the different transporters.
    
    Received data is 'unpacked' before being delivered to its
    trp_client. In order to reduce the context switch overhead
    between treads (or trp_clients), we attempt to deliver multiple
    signals to the trp_clients before waking them up. This is
    implemented as an array of trp_client* which has to
    be signaled after the Transporter polling has completed.
    
    If this array is filled to its maks size, we have
    to interupt the transporter polling and wakeup the trp_clients
    before resuming our activity.
    
    However, when [1;31mperf[mormReceive() resumed, it started over again
    on the first Transporter (from the node with the lowest NodeId).
    Thus, with sufficient traffic, we could end up in a situation
    where [1;31mperf[mormReceive always is interupted before we have received
    from all Transporters. This could effectively block all
    communication from the higher numbered NodeId
    
    For this particular bug it caused the destruction of
    Ndb objects to become stuck as ::close_clnt() required
    the (high numbered) API-client to send a signal to itself.
    This signal was (almost) never delivered as ::[1;31mperf[mormReceive()
    was interupted while receiving from the lower numbered data nodes.

[33mcommit 24a705ddf1833c3e8808110065cdf3f5b9e230b5[m
Merge: fcf02b21346 f6e20fb027f
Author: Evgeny Potemkin <evgeny.potemkin@oracle.com>
Date:   Tue Apr 26 15:30:39 2016 +0400

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            mysql-test/r/opt_hints_pfs.result
            mysql-test/suite/[1;31mperf[mschema/r/digest_table_full.result
            mysql-test/suite/[1;31mperf[mschema/r/rpl_gtid_func.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_low_digest.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_low_digest_sql_length.result
            mysql-test/suite/[1;31mperf[mschema/r/statement_digest.result
            mysql-test/suite/[1;31mperf[mschema/r/statement_digest_consumers.result
            mysql-test/suite/[1;31mperf[mschema/r/statement_digest_long_query.result
            mysql-test/suite/query_rewrite_plugins/r/digest_collision.result
            mysql-test/suite/query_rewrite_plugins/r/optional_columns.result
            mysql-test/suite/query_rewrite_plugins/r/verbose.result

[33mcommit bd406e06cf58e7a92ec3f5ecbd85fda696520dc1[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Tue Mar 29 12:06:56 2016 +0200

    Fix broken no[1;31mperf[mschema build:
    sql/auth/sql_authentication.cc:870:27:
    error: unused variable 'auth_info' [-Werror=unused-variable]

[33mcommit 5d12902d0219dac4a07f165c1d5f9d920a242c4d[m
Merge: 31800389d3a ceb93f9c89f
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Thu Mar 24 10:14:21 2016 +0300

    Merge remote-tracking branch 'origin/mysql-trunk' into mysql-trunk-wl7743-wip-3
    
    Conflicts:
            mysql-test/include/commit.inc
            mysql-test/r/commit_1innodb.result
            mysql-test/r/create.result
            mysql-test/r/dd_stages.result
            mysql-test/r/partition_explicit_prune.result
            mysql-test/r/partition_locking.result
            mysql-test/suite/[1;31mperf[mschema/r/alter_table_progress.result
            mysql-test/t/disabled.def
            mysql-test/t/partition_explicit_prune.test
            sql/dd/dd_table.cc
            sql/dd/dd_tablespace.cc
            storage/myisammrg/ha_myisammrg.cc

[33mcommit 1f641f716fb1ea8097a0febbe9647ebe89ca5cf7[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Tue Mar 22 11:48:12 2016 +0100

    WL#7069: Provide data dictionary information in serialized form
    
    This worklog provides a the data dictionary information for schemas,
    tables and tablespaces in human-readable form (JSON). For storage
    engines which don't support storing the serialized dictionary
    information (SDI) in tablespaces (all SEs except Innodb), the SDI is
    written to a file in datadir.
    
    For Innodb the the SDI will be stored in a tablespace, but this
    remains disabled for now, as it depends on worklog number 7141.
    
    The SDIs can be manually edited and will be used for import and
    disaster recovery (to be provided worklog number 7524 and 7412).
    
    Note that the name of the SDI files includes the Object_id from the
    data dictionary, which is a value created by an auto-increment column
    in the corresponding data dictionary table. This in turn means that
    the name of an SDI file created by an MTR test will not necessarily be
    the same each time the test is run as it depends on how many dd
    operations have been [1;31mperf[mormed on the server prior to the test being
    run. In particular it will not be same when running a test by itself as
    when running the test as part of a suite. This does not cause any
    problems, except in cases where the test includes the content of
    datadir in its output. Then a --replace_regexp must be used to make
    the output of the test stable. E.g.:
    
    --replace_regex /_[0-9]+\.SDI/_XXX.SDI/
    --list_files $MYSQLD_DATADIR/mysqltest/

[33mcommit 0471130d1f7a8d5ce946c8dc3462e71599d6df3d[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Tue Mar 22 12:43:36 2016 +0100

    Bug#22579927 THE NDBCLUSTER TEST SUITE BROKEN FOR REGULAR USERS
    
     - followup fix which revert the usage [1;31mperf[mormance_schema to
       read session_status since p_s is not available in embedded mode
     - instead turn on show_compatibility_56 for not embedded to enable
       the information_schema.session_status table
    
    (cherry picked from commit 0c1860fa9058e6e8d5db8e10a46fd9b9a7c08f18)

[33mcommit cf61875ec206919195e99c447b35a37b0902283f[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Tue Mar 22 12:43:36 2016 +0100

    Bug#22579927 THE NDBCLUSTER TEST SUITE BROKEN FOR REGULAR USERS
    
     - followup fix which revert the usage [1;31mperf[mormance_schema to
       read session_status since p_s is not available in embedded mode
     - instead turn on show_compatibility_56 for not embedded to enable
       the information_schema.session_status table

[33mcommit f553348323ea99e80c578faaa6874472fd937fe5[m
Author: Dinesh Surya Prakash <dinesh.prakash@oracle.com>
Date:   Tue Mar 22 12:21:26 2016 +0530

    Bug#21441297  INVALIDATTRINFO RETURNED FROM EXECTUX_BOUND_INFO WHILE SCANNING
    
    When we [1;31mperf[morm "analyze" command in a table with index, ndbmtd crashes
    and throws "InvalidAttrInfo" error due to corruption in the signal.
    
    The problem was there in the Trix block.Here we use stack variable in
    building up a signal, hence it goes out of scope when the signal is
    refereed in other modules. As the memory is invalid it gives a crash
    when signal is de-refereed in other modules.
    
    Code was modified such that the signal is now build with pooled
    variable.As this is a global variable too it can be refereed in other
    modules.

[33mcommit c270da5563afd620b67267e530c6e38219e381bd[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Mar 18 09:45:08 2016 +0100

    Disabled the testcase ndbcluster.pushed_join.test when
    running 'embedded'.
    
    The testcase used the [1;31mperf[mschema tables not being available
    for embedded.

[33mcommit 04d563f651f97d54cba0d184b590de91d1eb3209[m
Author: Tatiana Azundris Nuernberg <tatjana.nuernberg@oracle.com>
Date:   Mon Feb 29 09:15:48 2016 +0000

    Bug#16576959: MYSQL_OPTIONS4: POTENTIAL DOS VIA PRINTING TOO MUCH USELESS INFO TO ERROR LOG
    
    The client library can enrich connection data with information about
    the library version, the client's name, the OS the client is running
    on, and in fact pretty much anything it wants.  The designated
    mechanism for this is mysql_options4(), which lets the client put
    arbitrary key/value pairs on the connection info before the connection
    is made.
    
    The server outright refuses a connection when 64+ KB of these data are
    submitted. However, in practice [1;31mperf[mormance schema usually reserve much
    less space (< 1 KB) for each connection's attributes. If the client submits
    more data, the connection will succeed, but a warning will be thrown
    that some attributes were discarded. (The server will provide access
    to all attributes that is has a complete copy of. We do not currently
    show how many attributes were lost on a given connection, nor do we
    show an incomplete attribute with some sort of "cut" marker -- we simply
    don't show a truncated attribute at all. That said, we do expose info
    about the total number of connections with dropped attributes.)
    
    Pre-patch, we simply logged a warning indicating that attributes were
    truncated on a connection, without giving any information beyond the
    timestamp that would allow the administrator to identify the client,
    user, or connection that lost attributes. This made debugging harder
    than it needs to be.
    
    This patch adds additional data to log entry where available, such
    as user/host, connection ID, etc., all in the hope that it will
    make debugging such instances with just the error log much easier,
    and aid cross-referencing in the presence of further logs, such as
    the general query log.
    
    It also adds a new global PFS variable,
    "Performance_schema_session_connect_attrs_longest_seen" that shows the
    size of the longest (valid, i.e. <= 64 KB) buffer we were passed, so
    the DBA may adjust the buffer, or complain to the application developer.
    
    Finally, when a valid buffer in excess of what we accept is passed,
    we will add a new attribute "_truncated" stating how many characters
    were lost (provided the configured buffer is large enough to hold
    this information). This should make it easier to identify the exact
    connection that had the questionable attribute set in the PFS,
    without having to resort to the error log.

[33mcommit b2391d418895b481823179a23d4642576906b0e3[m
Author: Tatiana Azundris Nuernberg <tatjana.nuernberg@oracle.com>
Date:   Thu Mar 10 07:09:53 2016 +0000

    Bug#20955496: PREPARED STATEMENTS ABSURDLY SLOW DUE TO INEFFICIENT QUERY CREATIO
    N FOR LOGGING
    
    Be smarter about creating the log lines for prepared statement
    (where needed); in the pathological case of a prepared statement
    with the maximum of allowed substitutions, and very large string
    values for the variables, replacing placeholders with values
    mal[1;31mperf[morms; patch rectifies by constructing the line using appends
    instead.

[33mcommit b2c6ba625ff745e6ec5198b32deefb32d117a8d6[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Feb 29 16:47:27 2016 +0100

        Bug#22809694 PERFORMANCE_SCHEMA ON EMBEDDED BUILDS FOR SHOW STATUS
    
        Before this fix, the [1;31mperf[mormance schema was not available
        for embedded builds, in libmysqld.
    
        This is an issue for SHOW STATUS and SHOW VARIABLES
        statements, which can only be supported with
        show_compatibility_56=on.
    
        With this fix, the [1;31mperf[mormance_schema is available
        for embedded builds.
    
        Note that only a subset is supported,
        with no instrumentation collected.
    
        With this fix,
        - SHOW GLOBAL STATUS
        - SHOW GLOBAL VARIABLES
        - SHOW SESSION STATUS
        - SHOW SESSION VARIABLES
        can now be executed using only the [1;31mperf[mormance_schema tables,
        even in embedded builds.
    
        This clears the path to remove
        - the corresponding INFORMATION_SCHEMA implementation,
        - the show_compatibility_56 variable itself.

[33mcommit 31154f9ef5c095d00318aa8da9f5549a7033a522[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Feb 29 10:58:04 2016 +0100

    Bug#22809694 PERFORMANCE_SCHEMA ON EMBEDDED BUILDS FOR SHOW STATUS
    
    Before this fix, the [1;31mperf[mormance schema was not available
    for embedded builds, in libmysqld.
    
    This is an issue for SHOW STATUS and SHOW VARIABLES
    statements, which can only be supported with
    show_compatibility_56=on.
    
    With this fix, the [1;31mperf[mormance_schema is available
    for embedded builds.
    
    Note that only a subset is supported,
    with no instrumentation collected.
    
    With this fix,
    - SHOW GLOBAL STATUS
    - SHOW GLOBAL VARIABLES
    - SHOW SESSION STATUS
    - SHOW SESSION VARIABLES
    can now be executed using only the [1;31mperf[mormance_schema tables,
    even in embedded builds.
    
    This clears the path to remove
    - the corresponding INFORMATION_SCHEMA implementation,
    - the show_compatibility_56 variable itself.

[33mcommit d7e8178298a91a0bde94ec33cddb2c69eea1f5ff[m
Author: Venkatesh Duggirala <venkatesh.duggirala@oracle.com>
Date:   Fri Feb 26 19:34:55 2016 +0530

    BUG#17018343 SLAVE CRASHES WHEN APPLYING ROW-BASED BINLOG ENTRIES IN CASCADING
    REPLICATION
    
    Problem: In RBR mode, merge table updates are not successfully applied on a cascading
    replication.
    
    Analysis & Fix: Every type of row event is preceded by one or more table_map_log_events
    that gives the information about all the tables that are involved in the row
    event. Server maintains the list in RPL_TABLE_LIST and it goes through all the
    tables and checks for the compatibility between master and slave. Before
    checking for the compatibility, it calls 'open_tables()' which takes the list
    of all tables that needs to be locked and opened. In RBR, because of the
    Table_map_log_event , we already have all the tables including base tables in
    the list. But the open_tables() which is generic call takes care of appending
    base tables if the list contains merge tables. There is an assumption in the
    current replication layer logic that these tables (TABLE_LIST type objects) are always
    added in the end of the list. Replication layer maintains the count of
    tables(tables_to_lock_count) that needs to be verified for compatibility check
    and runs through only those many tables from the list and rest of the objects
    in linked list can be skipped. But this assumption is wrong.
    open_tables()->..->add_children_to_list() adds base tables to the list immediately
    after seeing the merge table in the list.
    
    For eg: If the list passed to open_tables() is t1->t2->t3 where t3 is merge
    table (and t1 and t2 are base tables), it adds t1'->t2' to the list after t3.
    New table list looks like t1->t2->t3->t1'->t2'. It looks like it added at the
    end of the list but that is not correct. If the list passed to open_tables()
    is t3->t1->t2 where t3 is merge table (and t1 and t2 are base tables), the new
    prepared list will be t3->t1'->t2'->t1->t2. Where t1' and t2' are of
    TABLE_LIST objects which were added by add_children_to_list() call and replication
    layer should not look into them. Here tables_to_lock_count  will not help as the
    objects are added in between the list.
    
    Fix: After investigating add_children_list() logic (which is called from open_tables()),
    there is no flag/logic in it to skip adding the children to the list even if the
    children are already included in the table list. Hence to fix the issue, a
    logic should be added in the replication layer to skip children in the list by
    checking whether  'parent_l' is non-null or not. If it is children, we will skip 'compatibility'
    check for that table.
    
    Also this patch is not removing 'tables_to_lock_count' logic for the [1;31mperf[mormance issues
    if there are any children at the end of the list, those can be easily skipped directly by
    stopping the loop with tables_to_lock_count check.

[33mcommit 7724de09fd18b3baeb5951e60fb395cf1f7a3f8f[m
Merge: c9991600f81 4851ece8367
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Thu Feb 25 13:59:44 2016 +0300

    Merge branch 'mysql-trunk' into mysql-trunk-wl7743-wip-3
    
    Conflicts:
            mysql-test/suite/[1;31mperf[mschema/r/alter_table_progress.result

[33mcommit d212ff3b16ba0a0ef5b66975f0be48d0949287c2[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Mon Feb 22 08:23:41 2016 +0100

    Bug#22728306: REMOVE ATTRIBUTE UNUSED WHERE THE VARIABLE/FUNCTION IS ACTUALLY USED
    
    Post-push fix: Fix warning in no[1;31mperf[mschema build.

[33mcommit eb36f39500de47d3bad6c80b52e09a6bb3b25239[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Thu Feb 18 13:41:06 2016 +0200

    Bug#22755053 REMOVE INNODB_DISABLE_RESIZE_BUFFER_POOL_DEBUG
    
    The debug variable innodb_disable_resize_buffer_pool_debug was
    introduced in a workaround in MySQL 5.7.6:
    
    Bug#20461123: SIGNIFICANTLY INCREASED TIME IN VALGRIND TESTS
    
    The root cause was fixed by removing the buf_block_align() calls in
    
    Bug#22709463 LATCHING ORDER VIOLATION IN BUF_BLOCK_ALIGN() DEBUG CALLS
    
    We will remove the variable innodb_disable_resize_buffer_pool_debug.
    
    Also, remove the variable buf_chunk_map_ref and simplify
    buf_pool_resize(), now that lookups cannot be [1;31mperf[mormed concurrently
    with buffer pool resizing.
    
    RB: 11851
    Reviewed-by: Annamalai Gurusami <annamalai.gurusami@oracle.com>

[33mcommit 6f44a52f02f31453a6ed494f0371334489a4a47c[m
Merge: 267befb88a5 03889a71f5b
Author: Martin Hansson <martin.hansson@oracle.com>
Date:   Thu Feb 18 11:34:23 2016 +0100

    Merge remote-tracking branch 'origin/mysql-trunk' into mysql-trunk-wl8083
    
    Conflicts:
            mysql-test/r/opt_hints_pfs.result
            mysql-test/suite/[1;31mperf[mschema/r/digest_table_full.result
            mysql-test/suite/[1;31mperf[mschema/r/rpl_gtid_func.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_low_digest.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_low_digest_sql_length.result
            mysql-test/suite/[1;31mperf[mschema/r/statement_digest.result
            mysql-test/suite/[1;31mperf[mschema/r/statement_digest_consumers.result
            mysql-test/suite/[1;31mperf[mschema/r/statement_digest_long_query.result
            mysql-test/suite/query_rewrite_plugins/r/digest_collision.result
            mysql-test/suite/query_rewrite_plugins/r/optional_columns.result
            mysql-test/suite/query_rewrite_plugins/r/verbose.result
            sql/parse_tree_nodes.cc
            sql/sql_rewrite.cc
            sql/sql_yacc.yy

[33mcommit 03889a71f5bdea0cbd6fd6039a4d2d4ce1c5c2f1[m
Merge: ea14c409096 e6713b856e5
Author: Evgeny Potemkin <evgeny.potemkin@oracle.com>
Date:   Thu Feb 18 13:49:21 2016 +0400

    Merge branch 'mysql-5.7-wl9124' into mysql-trunk
    
    Conflicts:
            mysql-test/r/opt_hints_pfs.result
            mysql-test/suite/[1;31mperf[mschema/r/digest_table_full.result
            mysql-test/suite/[1;31mperf[mschema/r/rpl_gtid_func.result
            mysql-test/suite/[1;31mperf[mschema/r/statement_digest.result
            mysql-test/suite/[1;31mperf[mschema/r/statement_digest_consumers.result
            mysql-test/suite/[1;31mperf[mschema/r/statement_digest_long_query.result
            mysql-test/suite/query_rewrite_plugins/r/digest_collision.result
            mysql-test/suite/query_rewrite_plugins/r/optional_columns.result

[33mcommit ecb58cb5367b05c79e2040cd5322e72613919474[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon Feb 15 22:37:30 2016 +0100

    bug#22615274: API CRASHES WITH SIGNAL 6 AT TRANSPORTERFACADE.CPP LINE 2170
    
    Follow up patch for this bug:
    
    The previous patch introduced setting of the m_open_close_mutex
    from TransporterFacade::expand_clnt() and
    TransporterFacade::[1;31mperf[morm_close_clnt().
    
    These methods are called from ::deliver_signal() which may already
    have locked the trp_client::m_mutex.
    
    Both TransporterFacade::open_clnt() and TransporterFacade::close_clnt()
    are also locking these mutexes. However, they took the mutex locks
    in the opposite order 1) m_open_close_mutex, 2) trp_client::m_mutex.
    
    That resulted in a possible deadlock on these mutexes between
    a thread waiting for open/close in a do_poll-loop, and the
    thread doing deliver_signal() to the same client.
    
    This patch ensures that the lock order of these mutexes are:
    
    1) Lock trp_client::m_mutex.
    2) Lock m_open_close_mutex.

[33mcommit dac54df4e9aff3da9143955fc33876d17e0350d9[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Feb 11 15:05:40 2016 +0100

    Bug#22615274: API CRASHES WITH SIGNAL 6 AT TRANSPORTERFACADE.CPP LINE 2170
    
    Root cause for this bug was a misconseption of how
    TransporterFacade::do_poll() worked: The sequence of
    'poll' calls needed related to do_poll() are:
    
    - ::start_poll()
    - 'construct signal' -> raw_sendSignal()
    - 'do_forceSend()
    - **do_poll()**
    - complete_poll()
    
    That has led us to belive that do_poll() would force *this* thread
    to grab the poll-right and [1;31mperf[morm the transporter poll, whicheventually should
    end up in ::trp_deliver_signal() calling
    TransporterFacade::expand_clnt().
    
    However, as it turned out, all do_poll() does for us is
    to ensure that *some thread* will get the poll-right. That
    could be this thread if no other had the poll-right, or it
    could be someone else already holding it.
    
    That ripped away the foundation for how the m_open_close_mutex
    was used to protect the TransporterFacade::m_threads members.
    We used to grab that lock early in TransporterFacade::open_clnt(),
    and held it across do_poll() while waiting for the EXPAND_CLNT
    signal to be executed. However, if another thread had the
    poll right and executed that signal for us, that broke down
    the entire open_close_mutex protection 'protocol'.
    
    This patch temporary unlocks the m_open_close_mutex while ::open_clnt
    wait for the EXPAND_CLNT signal to be executed. The thread
    executing that signal will then grab the lock instead in
    TransporterFacade::expand_clnt().
    
    A similar defect in the m_open_close_mutex protection was
    also identified in TransporterFacade::close_clnt().
    That is also fixed by this patch.

[33mcommit 602d2ca8232c93718e50d761fd52d412ba94eab4[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Wed Feb 10 22:58:49 2016 +0300

    Removed unnecessary code from mysql_rename_view().
    
    Follow-up for WL#6390 "Use new DD API for handling non-partitioned
    tables."
    
    With new data-dictionary we no longer need to prepare additional
    TABLE_LIST object for view in order to [1;31mperf[morm its rename. Updating
    view in data-dictionary is sufficient.

[33mcommit 37ece93a2cb1df691e038752d96448050219bc51[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Feb 8 14:49:01 2016 +0100

    Build cleanup
    
    Fixed build warnings when compiling without [1;31mperf[mormance schema

[33mcommit 86966fe181c5a1fcba66a45821f7fa562de6a263[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Fri Feb 5 15:06:01 2016 +0100

    Build cleanup ([1;31mperf[mormance schema)

[33mcommit ef65782f74f56e727208253ed1a7575521fc60b6[m
Author: Arnab Ray <arnab.r.ray@oracle.com>
Date:   Thu Feb 4 17:08:28 2016 +0530

    Bug #22647379:  FAILURE TO BUILD NDB UNIT TESTS DUE TO MYTAP LINK FAILURE
    
    The unit tests for NDB were built regardless of the WITH_UNIT_TESTS
    switch. After commit 084a9547b7e69188d74b1207d673dc00e0e884c5
    for Bug #22246885, the tests depend on the mytap library which is
    only built if the MySQL unittests are built. Thus, a link failure
    occurs when the build is [1;31mperf[mormed without unit tests.
    
    A check for the WITH_UNIT_TESTS switch was included in the
    NDB_ADD_TEST macro. Now the NDB unittests are built only
    when requested.

[33mcommit 4ec415a43c1447cef2e330cf1c73cbf5b6548dfd[m
Author: Srikanth B R <srikanth.b.r@oracle.com>
Date:   Thu Jan 28 12:23:33 2016 +0530

    WL#8983 - QUALIFY PERFSCHEMA SUITE WITH DIFFERENT BINLOG
              MODES AND ADD TO WEEKLY PUSHBUILD RUN
    
        An MTR run has been added to the pb2 default.weekly
    collection file as a part of WL#8794 due to which tests
    from the [1;31mperf[mormance schema suite( [1;31mperf[mschema ) will be
    run with binary logging enabled in mixed mode on weekly
    -trunk.
    
    Reviewed by:
    Anitha Gopi    <anitha.gopi@oracle.com>
    Tarique Saleem <tarique.saleem@oracle.com>
    RB: 11307

[33mcommit 80d8904bb3b786a990cadf6cf639fc5781221de5[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Fri Jan 22 18:42:11 2016 +0100

    Bug #22477849: DD DOES NOT CLEAR THE CACHE MEM PROPERLY
    
    Execute two dummy 'SHOW' statements prior to starting [1;31mperf[mormance
    schema data recording in '[1;31mperf[mschema.privilege_table_io' to avoid
    non-deterministic results due to cache misses/hits for the two
    tables being accessed by the 'SHOW' statements ('global_status'
    and 'global_variables').

[33mcommit 3e518c63af7e5f6e64ee6bef78b1f88a3a595502[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Jan 21 12:41:10 2016 +0100

    Bug#22579927 THE NDBCLUSTER TEST SUITE BROKEN FOR REGULAR USERS
    
     - when developer ran mtr.pl --suite=ndbcluster the testcase
       ndbcluster.pushed_join failed. This was not detected by PB since
       the default.push-ndbcluster file had been modified to run the
       ndbcluster test suite with some additional arguments. The normal
       developer(regular user) should not need to know about such special
       arguments to run the ndbcluster test suite. The change to
       default.push.ndbcluster has been reverted.
     - fix by rewriting test case to use the new [1;31mperf[mormance_schema
       table for querying the session scope status variables. The
       information_schema table is being removd in the future.
    
    (cherry picked from commit 1ca040832c2117881bc5ad5a3f14ad0f983c8ce2)

[33mcommit 22cd9025c6e67e10cadf69f3ca66fadddd752b03[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Jan 21 12:41:10 2016 +0100

    Bug#22579927 THE NDBCLUSTER TEST SUITE BROKEN FOR REGULAR USERS
    
     - when developer ran mtr.pl --suite=ndbcluster the testcase
       ndbcluster.pushed_join failed. This was not detected by PB since
       the default.push-ndbcluster file had been modified to run the
       ndbcluster test suite with some additional arguments. The normal
       developer(regular user) should not need to know about such special
       arguments to run the ndbcluster test suite. The change to
       default.push.ndbcluster has been reverted.
     - fix by rewriting test case to use the new [1;31mperf[mormance_schema
       table for querying the session scope status variables. The
       information_schema table is being removd in the future.

[33mcommit 87b570ca652d97b36a4f8311d9a6fd2814fac783[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jan 15 12:36:03 2016 +0100

    Another follow up patch for [1;31mperf[mormance regression introduced by patch for bug#20957068
    
    Previous patch introduce the usage of the non-portable sched_yield().
    This patch change that to use pthread_yield() which is defined in
    include/my_pthread().
    
    (cherry picked from commit c7a844a8e373633c4a3e91be7af3f789d19d4fbb)

[33mcommit f1fd8b7e7f6382f4ef1c83b4b7702b5773a47f9c[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jan 15 09:55:05 2016 +0100

    Follow up patch for [1;31mperf[mormance regression introduced by patch for bug#20957068
    
    Introduce some sched_yield() in the binlog-thread loops where
    the injector_mutex is held >99% if the elapsed time. The yields
    let other threads waiting to be scheduled a chance to run,
    and grab the injector_mutex when not held by the binlog-thread.
    
    (cherry picked from commit 000394fbe3a8d7a2945fb6b483024b77e16ab20a)

[33mcommit edb538c4b1ba2db8599d06c0f45e7ae858fb6360[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jan 15 12:36:03 2016 +0100

    Another follow up patch for [1;31mperf[mormance regression introduced by patch for bug#20957068
    
    Previous patch introduce the usage of the non-portable sched_yield().
    This patch change that to use pthread_yield() which is defined in
    include/my_pthread().

[33mcommit ab386d5c0faf316f451a81a811dc53580a62f7f4[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jan 15 09:55:05 2016 +0100

    Follow up patch for [1;31mperf[mormance regression introduced by patch for bug#20957068
    
    Introduce some sched_yield() in the binlog-thread loops where
    the injector_mutex is held >99% if the elapsed time. The yields
    let other threads waiting to be scheduled a chance to run,
    and grab the injector_mutex when not held by the binlog-thread.

[33mcommit b1b1afd291dd7f57a1fabfd7ae514073d83df573[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Jan 14 10:04:04 2016 +0100

    Refactor [1;31mperf[mormance schema code and unit tests,
    to avoid dependency on class THD.
    
    This helps to build unit tests with clang -WWITH_UBSAN.

[33mcommit eef9ce1bc81b7b1cfe3fbe38f79c13c9fc495a67[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Wed Dec 23 12:45:51 2015 +0100

    Bug#22098258: Refactor the multi-dimensional ref_pointer_array into 5 individual arrays
    
    This is a prerequisite for WL#6570: Refactor DML statement preparation
    
    The ref_pointer_array is an array of references to item objects that is
    shared between the resolver struct and the optimizer struct. It is
    created during resolving in five slices. The first of these slices is
    populated during resolving, whereas the remaining four slices are
    populated during optimization. The array is used during execution using
    a technique that involves copying slices of the array on top of slice zero.
    
    The ref_pointer_array is used together with Item_ref objects to
    reference a varying set of other Item objects during execution.
    Each Item_ref object contains a ref field which is a pointer to a pointer
    to an Item. It is set to point to one cell in slice zero of the
    ref_pointer_array. By copying another slice over slice zero, the
    Item_ref will actually point to a different Item.
    
    There are several problems with this structure:
    
    1. The sharing between resolver and optimizer means it is impossible to
    have multiple query execution plans for a single query.
    
    2. By allocating the array as a multi-dimensional array, the size of the
    array must be determined before allocation. This forces us to make some
    conservative estimates about the size of the array.
    
    3. By letting Item_ref::ref point to a cell of the array, the array must
    be fixed during preparation, optimization and execution. It has to be
    allocated up front and all five slices must be allocated, even though
    simple queries only need slice zero.
    
    4. The copying of slices means that the plan is modified during
    execution. This prevents us from sharing plans
    between concurrently executing sessions. It is probably possible to use
    it when creating a multi-thread plan, but it forces us to [1;31mperf[morm the
    copying in lock-step. Query plans for individual threads are not
    independent.
    
    This subtask will address item 1 and partially item 2 above. It lays the
    groundwork for addressing the remaining items.
    
    Splitting the array
    -------------------
    
    The main task is to split the array from being a multi-dimensional array
    to an array with five elements that each may reference an array of item
    pointers. This array is kept in class JOIN and is named ref_items.
    
    Slice zero of the existing array is allocated during resolving and is
    kept in class SELECT_LEX with the name base_ref_items. During
    optimization, slice zero of JOIN::ref_items is set to point to this array.
    
    Modifications to class SELECT_LEX
    ---------------------------------
    
    - The class used for ref_pointer_array is renamed from Ref_ptr_array to
      Ref_item_array, since it is an array of references to Item objects.
    
    - The array references ref_pointer_array and ref_ptrs are replaced with
      base_ref_items, which only contains slice zero of the previous ref array.
    
    - The function ref_ptr_array_slice() is no longer necessary, since we
      now have individual arrays of item references instead of a
      multi-dimensional array.
    
    - setup_base_ref_items() is a new function that creates slice zero of
      the ref array.
    
    Modifications to class JOIN
    ---------------------------
    
    Instead of structures with hard-coded names such as tmp_all_fields1,
    tmp_all_fields2, where 1 resp. 2 is a step number, these structures are
    now placed in an array that is indexed with slice numbers. We have also
    given symbolic names to slice numbers: There are five slices, slice
    number zero is the base slice, slice 1, 2 and 3 are associated with
    handling of the first, second and third temporary table, respectively,
    and slice 4 is used to save the original contents of slice zero.
    By using symbolic names, it has become easy to rearrange the slices.
    We have taken advantage of that to make the "save" slice number four
    instead of one, so that the temporary tables are related to
    corresponding fixed slice numbers 1, 2 and 3.
    
    - ref_items contains what used to be ref_pointer_array. The difference
      is that it is an array with pointers to one-dimensional arrays instead
      of being a multi-dimensional array.
    
    - tmp_all_fields is an array of field list pointers which replace the
      previous lists tmp_all_fields1, tmp_all_fields2 and tmp_all_fields3.
    
    - tmp_fields_list is an array of field list pointers which replace the
      existing lists tmp_fields_list1, tmp_fields_list2 and tmp_fields_list3.
    
    - current_ref_item_slice denotes the number of the slice of ref items
      that currently reside in slice zero of ref_items.
    
    - copy_ref_item_slice() has been modified to take slice numbers as
      arguments instead of arrays. (The exception is ROLLUP processing,
      which still needs to operate on pointers to ref item arrays).
    
    - alloc_ref_item_slice() allocates a slice of the ref item array, by
      supplying a slice number between 1 and 4.
    
    - set_ref_item_slice() copies one of the slices to slice zero and sets
      current_ref_item_slice accordingly.
    
    Modifications to class QEP_TAB (executor.h)
    -------------------------------------------
    
    - ref_array_pointer is replaced with ref_item_slice.

[33mcommit 4faa75dced5789a891ebfa2ae7a8f46e311dc8bf[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Dec 16 16:01:36 2015 +0100

    Patch for bug#22361695: NDB_SHARE PREMATURELY DESTRUCTED BY BINLOG RESTART,DUE TO INCORRECT REF COUNTING
    
    Patch change ndbcluster_get_share() such that an addition ref count
    is added when a share is created and inserted into the ndbcluster_open_tables
    hash structure. (In addition to a reference already made by get'ting
    the share)
    
    ha_ndbcluster::create() and ndbcluster_create_binlog_setup(),
    (called through ha_ndbcluster::open()) are the only places where
    *_get_share() is called with 'create_if_not_exists=TRUE'. These
    are changed such that the get'ed share reference is freed upon
    completion. However, **the ref count from the created entry into
    ndbcluster_open_tables remains**.
    
    This guarantes that even if the binlog thread deletes all
    entries in ndbcluster_open_tables during a restart, a possible
    concurrent ::create() or ::open() will keep a ref to a valid  share
    intil they unref it themself.
    
    The semantics wrt. 'share::state == NSS_DROPPED' and the share
    being in either the 'dropped-' or 'open-tables' hash has also
    cleaned up. Previously there were possible to set a share tp
    NSS_DROPPED state without removing it from the open_tables
    list and/or unref'ing it. ndbcluster_mark_share_dropped()
    has now been enhanced to take care of all of this.
    
    The binlog code has also been improved a couple of places
    where the temporary share ref was released prior
    to all local share tasks were [1;31mperf[mormed. Other places
    comments has been added describing which ref we intend to free
    with each free_share() (The rule is to always free temporary share
    ref last)
    
    free_share() has also been replaced with ndbcluster_mark_share_dropped()
    where the intention was to free the share reference from
    ndbcluster_open_tables hash.

[33mcommit 701e1e690a7f37a4a06bfb410aeccfad5dcc8d9c[m
Author: Darshan M N <darshan.m.n@oracle.com>
Date:   Wed Dec 16 10:14:46 2015 +0530

    Bug#21501098 DOXYGEN ERRORS IN INNODB - Part 2
    
    Issue:
    ======
    The errors in the doxygen formatting used in innodb prevents
    PB2 to [1;31mperf[morm a clean doxygen build for mysql-trunk
    
    Fix:
    ====
    Fixed the broken doxygen syntaxes
    
    Reviewed-by: Kevin Lewis <kevin.lewis@oracle.com>
    RB: 10791

[33mcommit 8ac10614859e2f9dc4dba3b18644b239e6a728cf[m
Author: Darshan M N <darshan.m.n@oracle.com>
Date:   Mon Dec 14 10:44:54 2015 +0530

    Bug#21501098 DOXYGEN ERRORS IN INNODBBug#21501098 DOXYGEN
    ERRORS IN INNODB
    
    Issue:
    ======
    The errors in the doxygen formatting used in innodb prevents
    PB2 to [1;31mperf[morm a clean doxygen build for mysql-trunk
    
    Fix:
    ====
    Fixed the broken doxygen syntaxes
    
    Reviewed-by: Kevin Lewis <kevin.lewis@oracle.com>
    RB: 10791

[33mcommit 57d3afdf208c6c9a90b0caffe01025eed874c5b3[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Dec 11 07:42:11 2015 +0100

    Bug#22344435 CLEANUP USAGE OF MY_HASH_INIT
    
    This is a followup to Bug#22285674 CLEANUP USAGE OF MY_HASH_GET_KEY
    
    Remove key_offset from my_hash_init() and struct st_hash.
    It was mostly unused. The only use cases were in connection with
    'offsetof' for some structs. Rewrote those cases to use
    hash_get_key_function callbacks instead.
    
    Remove growth_size from my_hash_init. It was mostly unused. The linear
    growth for dynamic_array is bad for [1;31mperf[mormance anyways
    (see e.g. Bug#22239803) A later patch will substitute some C++ vector
    with exponential growth for the C-style dynamic_array.
    
    Rename the typedef for the 'free' function of st_hash. It frees hash
    elements, not hash keys. Remove all the C-style casts for this callback.
    
    Remove some wrong use cases of MYF(0) to my_hash_init.
    
    Also: do value initialization of print_event_info struct in
    mysqlbinlog.cc in order to get rid of some valgrind warnings.
    
    Also: change #if NOT_YET to #ifdef NOT_YET in ndb_version.h,
    *lots* of compiler warnings gone.

[33mcommit 1b461a6f4d0e9ebf46d5273a8a95bd4afded65c2[m
Merge: fe51dbedd66 4359db86c29
Author: Marek Szymczak <marek.szymczak@oracle.com>
Date:   Thu Dec 10 12:42:33 2015 +0100

    Bug#21458192 AUDIT API DOES NOT GENERATE EVENTS OF THE 'MYSQL_AUDIT_TABLE_ACCESS_CLASS' CLASS
    
    Problem
    =======
    Audit API defined events of the 'MYSQL_AUDIT_TABLE_ACCESS_CLASS' class were not generated.
    
    Solution
    ========
    Following events of the 'MYSQL_AUDIT_TABLE_ACCESS_CLASS' class are generated during execution of
    the listed queries:
    
    - MYSQL_AUDIT_TABLE_ACCESS_READ
      - SELECT
      - INSERT ... SELECT (table referenced in the SELECT clause)
      - UPDATE ... WHERE (tables referenced in the WHERE clause)
      - REPLACE ... SELECT (tables referenced in the SELECT clause)
      - HANDLER ... READ
    - MYSQL_AUDIT_TABLE_ACCESS_INSERT
      - INSERT
      - INSERT ... SELECT (table referenced in the INSERT clause)
      - REPLACE
      - REPLACE ... SELECT (table referenced in the REPLACE clause)
      - LOAD DATA INFILE
      - LOAD XML INFILE
    - MYSQL_AUDIT_TABLE_ACCESS_UPDATE
      - UPDATE
      - UPDATE ... WHERE (table or tables referenced in the UPDATE clause)
    - MYSQL_AUDIT_TABLE_ACCESS_DELETE
      - DELETE
      - TRUNCATE
    
    Queries executed from stored procedures or triggers generate exact table access events
    as executed separately.
    Execution of the prepared statement generate events depending on the content of the statement.
    Every event of a given subtype for a table is generated only once during a single query
    or subquery.
    
    Table access event generation does not reflect real I/O operation on a given table. Events are
    generated before the tables are being accessed. Events are also generated, when no real table
    access takes place, but there was intention to do so during preparing tables before the
    execution takes place.
    
    Events are not generated for temporary tables, views, information schema and [1;31mperf[mormance
    schema tables.
    
    Reviewers
    =========
    Marc Alff <marc.alff@oracle.com>
    Ramil Kalimullin <ramil.kalimullin@oracle.com>

[33mcommit b76311987954218ee31511b9db14383bc4b93423[m
Author: Erik Froseth <erik.froseth@oracle.com>
Date:   Wed Dec 2 16:34:45 2015 +0100

    Bug#22299664 REGRESSION, ASSERTION FAILED: !THD->IS_ERROR() WITH ROW() + SPATIAL FUNCTIONS
    
    Problem: An assertion could be raised during resolving if one of the
    arguments to the function ROW() raised an error. This assert was added
    as a part of the fix for "Bug#21522980 RESOLVER: SIMPLIFY SOME OFTEN
    EXECUTED CONDITION AND EXPRESSION CODE".
    
    Fix: Check if an error was raised by one of the arguments (check
    thd->is_error()), and return error before trying to resolve the next
    argument. The error could be raised by calling "item->is_null()", which
    in this case would call Item_geometry_func::is_null(). This override
    was found to be su[1;31mperf[mluous, as the base implementation
    Item_func::is_null() will do the correct thing anyways.

[33mcommit 7ad19a5c9700fb1edcdd3a223999f6ed978a85c4[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Wed Dec 2 12:15:41 2015 +0100

    Bug#22291505: SWITCH FROM MYSYS ATOMICS TO C++11 ATOMICS IN
                  CONNECT/DISCONNECT CODE
    
    This patch replaces the usage of my_atomic_* in connect/disconnect
    code with C++11 atomics. This simplifies code (no need to remember
    to use my_atomic functions every access, not limited to int32/int64).
    This also avoid the potential [1;31mperf[mormance issue from the fact that
    the my_atomic version of load is really a store.

[33mcommit f0314c1702d21de7055ab667c1733784b48a6421[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Wed Nov 4 10:33:59 2015 +0100

    Bug#21522980: Resolver: Simplify some often executed condition and expr code
    
    This is a cleanup patch for better [1;31mperf[mormance and code simplification.
    
    Refactored processing of join conditions: Previously, join conditions
    were resolved by running through the leaf table list and traversing
    upwards using the embedding member until the root was reached. This
    meant that several join nodes might be visited multiple times.
    The new implementation is a recursive function that goes top-down,
    visiting each table/join nest only once. Even though the function
    is recursive, it will be invoked only once for simple queries.
    
    Shortcut of function calls: The following functions are no longer
    called when there is no work to do:
    - setup_ftfuncs()
    - check_view_privileges()
    - setup_natural_join_row_types()
    - flatten_subqueries()
    
    Resolving of variable assignments: This used to be done for every time
    the expressions of a query block were resolved, but it is necessary
    only once per query. Separated into a new function
    resolve_var_assignments() which is called once from handle_query().
    
    Error handling: Added a few asserts for !thd->is_error(), to improve
    checking for unnoticed errors, that otherwise may cause erroneous
    execution.
    Due to adding these new checks, it was necessary to add explicit
    check for thd->is_error() in Item_sum_num::fix_fields() and
    mysql_test_select().
    
    Test change in i_main.subquery: Since join conditions now may be resolved
    in a different order, optimization may be shortcut due to
    "Impossible WHERE" for a different join nest.
    
    sysbench point select shows [1;31mperf[mormance enhancement 0-1 per cent.

[33mcommit 3d4c759bd8aa9e980c644b45c740ab127693e581[m
Merge: 2ceadfa708c 400c10b4ce4
Author: Christopher Powers <chris.powers@oracle.com>
Date:   Mon Nov 9 23:04:44 2015 +0100

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            mysql-test/suite/[1;31mperf[mschema/r/show_plugin.result

[33mcommit 6d4978b5b272891c3fd7a8141a8d267bdb4df527[m
Author: Darshan M N <darshan.m.n@oracle.com>
Date:   Thu Nov 5 14:59:30 2015 +0530

    Bug#21501098 DOXYGEN ERRORS IN INNODBBug#21501098 DOXYGEN ERRORS IN INNODB
    
    Issue:
    ======
    The errors in the doxygen formatting used in innodb prevents PB2 to [1;31mperf[morm
    a clean doxygen build for mysql-trunk
    
    Fix:
    ====
    Fixed the broken doxygen syntaxes.
    
    Reviewed-by: Kevin Lewis <kevin.lewis@oracle.com>
    RB: 10791

[33mcommit 31350e8ab15179acab5197fa29d12686b1efd6ef[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Tue Nov 3 13:27:06 2015 +0530

    WL#6378 New data dictionary (umbrella).
    
    A. Overview:
    ------------
    This big patch introduces data dictionary (DD) schema in MySQL
    server. Some of the main benefits of this is,
    
    * The .FRM files are gone, and all dictionary changes will
      now happen in the dictionary schema stored in InnoDB.
    
    * Builds a base platform enabling us to improve [1;31mperf[mormance of
      INFORMATION_SCHEMA queries, which can be implemented as a view.
    
    * This patch enables a forthcoming incremental patch that would
      remove internal dictionary table of InnoDB. Enables,
       - There by eliminate inconsistencies between .FRM files and
         InnoDB tables.
       - Remove file system dependencies (lower-case-table-names).
       - Single repository of meta data for Server, SE and Plugins.
       - Eliminate meta data redundancy.
    
    * Remove db.opt and rely on dictionary tables.
    
    B. Work logs:
    -------------
    The WL#6378 is the umbrella WL tracking all dependent WL's. This
    patch contains implementation of following dependent WL's,
    
    * Worklogs that deal with just DD API framework:
    
      WL#6379 - Schema definitions for new DD.
                This important WL defines the central data dictionary
                table definitions.
    
      WL#6380 - Formulate framework for API for DD.
    
      WL#7284 - Implement common code for different DD APIs.
      WL#6385 - Define and Implement API for Schema.
      WL#6382 - Define and Implement API for Table objects.
      WL#6389 - Implementation of common View API.
      WL#6387 - Define and Implement API for Tablespaces.
      WL#7630 - Define and Implement API for Table Partition Info
      WL#8150 - Dictionary object cache.
      WL#7770 - Develop GUNIT test framework and guidelines for DD API.
      WL#7771 - Make sure errors are properly handled in DD API.
    
    * Worklogs that change server code invoking DD API's:
    
      WL#6390 - Use new DD API for handling non-partitioned tables.
      WL#7836 - Use new DD API for handling partitioned tables.
      WL#6394 - Bootstrapping the new data dictionary.
      WL#7784 - Store temporary table meta data in memory.
      WL#8542 - Server shutdown procedure with new data dictionary
      WL#7593 - New data dictionary: don't hold LOCK_open while
                reading table definition.
      WL#7464 - InnoDB: provide a way to do non-locking reads
                This is pre-requisite for WL#6599.
    
    C. Tips to DD API users:
    ------------------------
    * Refer code in sql/dd/dd_schema.* to quickly learn how to write
      code using DD API and update dictionary tables.
    
      Refer sql/dd/cache/dictionary_client.h to get overview on what
      is Dictionary_client and Auto_release interface.
    
      Interested can refer to sql/dd_table_share.{h,cc} which
      implements mapping between the TABLE_SHARE and the dd::Table DD
      object.
    
    * Overview of the directory structure and source files introduced
      by this patch is as following,
    
      DD user exposed files:-
    
      sql/dd/        - Top level directory containing most of DD code.
      sql/dd/*.h     - Headers that you need to operate on DD.
      sql/dd/types/  - Contains headers to operate on single
                       dictionary object.
      sql/dd/dd_*.cc - Contains MySQL server and DD API framework
                       glue code. E.g., Code that updates to DD tables
                       upon table creation/alter table/drop table and
                       so on.
      sql/dd/cache/  - Contains implementation of DD Object cache.
    
      Implementation that is hidden to DD user:-
    
      sql/dd/impl/   - Contains implementation of DD API's.
      sql/dd/impl/cache/  - Contains implementation of DD object cache
                            operations.
                             E.g., dd::cache::Dictionary_client
      sql/dd/impl/types/  - Contains implementation of DD user object
                            operations. E.g., dd:Table, dd::View etc.
      sql/dd/impl/tables/ - Contains implementation of DD table
                            operations. E.g., dd::tables::* classes
                            that abstracts operations on a DD table.
      sql/dd/impl/raw/    - Contains implementation of generic
                            operations on all DD tables.
    
    * The code related to .FRM handle is removed. So, the following
      files are removed,
        sql/datadict.h
        sql/datadict.cc
        sql/discover.h
        sql/discover.cc
        sql/unireg.h
        sql/unireg.cc
    
    D. New configuration variables and startup options:
    ---------------------------------------------------
    * Introduced a new option "--install-server", behaving like
      "--bootstrap", but additionally creating the dictionary tables.
      Note that the --install-server is a temporary workaround until
      MTR use --initialize.
    
    * The existing "--bootstrap" option behaves like before as far
      as possible, but note that the changes in plugin initialization
      means that e.g. InnoDB must be able to start, the DD must be
      able to start, etc., for bootstrap to enter the stage where SQL
      commands are actually executed.
    
    * The mysql_install_db and the mysql_test_run scripts are modified
      to use the new "--install-server" option.
    
    * The cmake script create_initial_db.cmake.in is also changed to
      use --install-server rather than --bootstrap.
    
    * WL#8150 adds server options schema_definition_cache,
      tablespace_definition_cache and stored_program_definition_cache
      size. These define the DD object cache size for respective DD
      objects.
    
    E. Upcoming improvements
    -----------------------
    * WL#6599 New Data Dictionary and I_S integration
      Information schema queries will be execute faster as this WL
      would make information schema tables as a view on top of DD
      tables.
    
    * WL#7743 New data dictionary: changes to DDL-related parts of SE API
      - Support atomic/crash-safe DDL.
      - Support auxiliary columns (InnoDB-specific)
      - Support auxiliary tables (needed for InnoDB FTS)
    
    * WL#6394 - Bootstrapping the new data dictionary.
      - Improvements in bootstrap procedure supporting removal of
        InnoDB dictionary.
    
    * WL#7896 Use DD API to work with triggers.
      - Will remove use of .TRN and .TRG files and start using
        mysql.triggers DD table.
    
    * Additional system tables are to be moved from MyISAM
      WL#7897 Use DD API to work with stored routines
      - Will remove mysql.proc MyISAM table and use mysql.routines
        InnoDB dictionary table.
    
      WL#7898 Use DD API to work with events.
      - Will remove mysql.event MyISAM table and use mysql.events
        InnoDB dictionary table.
    
    * WL#6391: Hide DD system tables from user.
      - Will hide direct access to DD system tables from user.
    
    F. Permanent changes in behavior.
    ---------------------------------------------
    * Since the .frm files are gone, you will not be able to copy
      .FRMs/data files and move them around. We will address this
      when we finish the implementation of new import, based on
      serialized dictionary information, see WL#7069.
    
    * Related to the above is the fact that --innodb-read-only
      option does not currently work. In 5.7, meta-data would be
      written to .FRM files and not be affected by the option, but
      now as meta-data is written to InnoDB tables, we must
      reconsider the semantics of this option.
    
    * The setting of the system variable 'lower_case_table_names'
      determines the collation of e.g. the 'name' column in the table
      storing the meta data for tables. This collation is decided once
      and for all when the dictionary table is created. Thus, we do
      not support changing 'lower_case_table_names' afterwards.
    
    * Character sets and collation tables are populated at initial
      boot, and for every subsequent startup, unless the server or
      the dictionary storage engine (InnoDB) is started in read
      only mode.
    
    G. Intermediate limitations in functionality:
    ---------------------------------------------
    * Tests on upgrade/downgrade will not work, and will be
      temporarily disabled. QA will also have to temporarily postpone
      any upgrade tests, until we have completed the upgrade tool
      (WL#6392) from 5.7 to 5.8. We are working towards building a
      intermediate solution for system QA.
    
    * Some InnoDB tests related to recovery of TRUNCATE are
      disabled. But n-test can be run as long as you are not trying to
      recover TRUNCATE. The tests will be enabled when we push the
      bundle of WLs(7141/7016/7743), which will move the storing of
      InnoDB DD to the common data dictionary, and make DDL atomic.
      Until which recovery after killing the server will also not
      work.
    
    * MySQL Cluster cannot be used with this version of the server.
    
    H. Disabled tests:
    ------------------
    Apart from test that are disabled due to above functionality that
    does not work now. Additionally we have temporarily disabled a
    few other tests, which might be a bit challenging for bug fixing
    in trunk in very restricted areas of the code. Refer
    sql/dd/mtr_readme.txt to see which exact test cases are disabled.

[33mcommit 92115de5772220f1da1cd49cbaeecd2c4890e658[m
Author: Darshan M N <darshan.m.n@oracle.com>
Date:   Fri Oct 30 12:29:11 2015 +0530

    Bug#22007765 DOXYGEN ERRORS IN PARTITION
    
    Issue:
    ======
    Missing documentation in the partition code prevents PB2 to [1;31mperf[morm a clean doxygen build for mysql-trunk.
    
    Fix:
    ====
    Added the missing documentation.
    
    Reviewed-by: Kevin Lewis <kevin.lewis@oracle.com>
    RB: 10794

[33mcommit 4a344b8954e712e6f2cdc26ebe0ff1a825fd74e3[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Oct 22 12:25:30 2015 +0200

    WL#6815 Adapt MySQL Cluster to 5.7
    
     - fix even more explains which show varying partitions on
       different platforms (as expected)
     - remove useless explain which is su[1;31mperf[mlous when the
       number of pruned scans are checked by comparing
       stats variables.

[33mcommit 4a1c797b3ea0ce408e7574229a40974cfff3f888[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Tue Oct 20 14:11:13 2015 +0200

    WL#6815 Adapt MySQL Cluster to 5.7
    
     - fix more explains which show varying partitions on
       different platforms (as expected)
     - remove useless explain which is su[1;31mperf[mlous when the
       number of pruned scans are checked by comparing
       stats variables.

[33mcommit 8c9920a61732c605c49de13cdeb21574e7f4d6b1[m
Merge: 83fb2673fc9 a3428e63485
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Oct 12 12:38:16 2015 +0200

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            sql/sql_class.cc
            storage/[1;31mperf[mschema/pfs_visitor.cc

[33mcommit 0b035fc5c83aa3b47fa533e05fedd8146f693bf6[m
Author: Sreeharsha Ramanavarapu <sreeharsha.ramanavarapu@oracle.com>
Date:   Mon Jun 29 08:23:39 2015 +0530

    Bug #20238729: ILLEGALLY CRAFTED UTF8 SELECT PROVIDES NO
                   WARNINGS
    
    Issue:
    -----
    No warning is delivered when MYSQL is unable to interpret
    a character with the given charset.
    
    SOLUTION:
    ---------
    Check is now [1;31mperf[mormed to test whether each character can
    be interpreted with the relevant charset. Failing which, a
    warning is raised.
    
    (cherry picked from commit 4df6e517ed11a9072346d9a76f11aba327ab8844)

[33mcommit 2e82007e3522ed3b9ed0cfaf7414aee3c3d8ebcb[m
Author: Maitrayi Sabaratnam <maitrayi.sabaratnam@oracle.com>
Date:   Thu Oct 1 17:48:11 2015 +0200

    Bug#21554676 - USING DROPEVENT METHOD WITH FORCE INDICATOR
    
    While [1;31mperf[morming dropEvent, if the coordinator dbdict crashes after
    Sumas have removed the subscriptions and returned execSUB_REMOVE_CONF,
    but beore the coordinator deletes the event from the systable, the
    dropped event will dangle in the sysTable. This will cause any
    following drop or create event with the same name to fail with '1419
    Subscription already dropped' or '746 Event name already exists'.
    
    The fix is: dict ignores Suma error 'SubRemoveRef::AlreadyDropped' and
    delete the event from sysTable.

[33mcommit 54886337698a55ee1d1761ee3de6b0c58dc62320[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Sep 29 15:09:38 2015 +0200

    Patch for bug#21660947
    
    Reseting of 'm_latestGCI' was previously based on detecting
    that 'm_active_op_counts' reached zero. Setting this to zero
    after an initial restart is essential as the restart resets the GCI
    sequence and start over from 0/0 (or close to).
    
    If m_latestGCI is not reset after such an initial restart, we
    will reject epochs from after the restart as duplicates of
    already completed epochs - see 'bug-subject'.
    
    Depending on the order the client application [1;31mperf[morms
    drop of failed event ops, and re-create of new ones, we might never
    reach the state 'm_active_op_count==0'. Thus this can not be
    used as a criteria for when to reset m_latestGCI.
    
    This patch reset m_latestGCI *only* as part of handling a CLUSTER_FAILURE.
    As part of this failure handling we will already empty
    the GCI containers, added comments and asserts about that.
    The patch add clearing of m_latestGCI and m_latest_complete_GCI
    after handling the failure. There should be no need to distinguise
    between initial and non-initial restarts at this point: The
    GCI containers will be empty anyway and no more events will arrive
    from before the failure.
    
    The init_gci_containers() has been cleaned up to do only that ->
    'init the Gci_container', (and the known_gci vector describing its contents)
    
    The previous clearing and reset of 'complete data' has been moved
    out to the calle instead, where required.
    
    Note: A CLUSTER_FAILURE must *not* clear the complete date, as that
    would have cleared the just created failure event.

[33mcommit 03e1b740017ec80916bb90876109fe8a50ec150b[m
Merge: 2de63b28ac9 15f1d8f0f67
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Sep 23 18:07:53 2015 +0200

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            storage/innobase/srv/srv0srv.cc
            storage/[1;31mperf[mschema/pfs_buffer_container.h

[33mcommit d1bf3e2de253f38509de111c927d00b917f219d2[m
Author: Menelaos Karavelas <menelaos.karavelas@oracle.com>
Date:   Fri Sep 4 13:55:30 2015 +0300

    Bug#21689998 ST_UNION() RETURNS AN INVALID GEOMETRYCOLLECTION
    
    The bug is due to the way Boost.Geometry handles linear geometries that have
    spikes when [1;31mperf[morming the difference and intersection set operations with
    areal geometries. By default Boost.Geometry discards spikes present in linear
    geometries, which can easily result to set operation results that are invalid
    (linestring with topological dimension 0 instead of 1).
    
    Fix: deactivate the removal of spikes present in linear geometries when [1;31mperf[morming
    the difference(L,A) and intersection(L,A) set operations.
    
    Note: The Boost.Geometry related patch that is part of this commit has been submitted for
    inclusion to Boost.Geometry; it has not been reviewed yet, so it may change as part of the
    Boost.Geometry reviewing process.

[33mcommit a9bc5e62c5a3e3619151d85b47468ecab62d6736[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Tue Aug 25 16:26:06 2015 +0100

    Avoid processing DISCONNECT_REP twice (bug#21683144)
    
    ClusterMgr assumes that reportConnected() /
    reportDisconnected() will be serialised w.r.t.
    each other, but this is not the case where a
    node with [1;31mperf[mormState==CONNECTING is
    transitioned to DISCONNECTING.
    
    In this case it is possible for it to then
    transition to DISCONNECTED, and
    reportDisconnected() to be called without a
    preceding call to reportConnected().
    
    This was causing assertion failures on a
    pre-decrement assert on noOfConnectedNodes.
    It may have had other bad effects with assertions
    off.
    
    The solution chosen here is to only process
    DISCONNECT_REP if reportConnected() was processed
    - e.g. if the connection succeeded.  If the
    connection did not succeed then the ClusterMgr
    has no real state to cleanup.

[33mcommit a3479c1bbfbff9347c72d5064bcd3f0c22b62dbb[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Fri Aug 21 08:45:41 2015 +0100

    Bug#21656153: REDUCE HEADER FILE DEPENDENCIES IN MYSQLD.H
    
    Remove unneccessary header dependencies from mysqld.h
    Remove declarations from mysqld.h which have no defintions.
    Remove declarations from mysqld.h where they can be made
    static in mysqld.cc instead.
    Remove [1;31mperf[mormance schema keys for mutexes/rwlocks/files that no
    longer exist.

[33mcommit ea9fbce9662dd964a61f52c8487f7c92a1be4c1e[m
Merge: 2ade5d44f6d ea8639ef9b5
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Aug 12 07:42:49 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      1. Added new tables added in [1;31mperf[mormance schema space. 2. Added extra tests for show_compatibility_56
      CSV engine refactoring
      Bug#21522888: DATA RACE ON SAFE MUTEX MP->FILE
      Bug #18979515: HANG/INFINITE LOOP IN                ITEM_SUM::CLEAN_UP_AFTER_REMOVAL
      Fix compilation failure in mysql-trunk from bug#21529012 fix
      - Bug#21529012: ASSERTION: INDEX->PAGE != 0XFFFFFFFF BTR_CUR_SEARCH_TO_NTH_LEVEL

[33mcommit 54f74c22d54e3d810ee30720c951b59917c44b6a[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Aug 5 15:30:40 2015 +0300

    Simplify the extension of the lock free hash
    
    Serialize the code that copies entries from one array to the next one(s)
    and then frees the unused array. This has a [1;31mperf[mormance impact only on a
    workload that does an aggressive grow (uncommon), but is much simpler
    and thus easier to maintain.
    
    WL#7170 InnoDB buffer estimates for tables and indexes

[33mcommit ed44bd284a130ffcf442f89dcbce1ce9887aaa9b[m
Author: Ramil Kalimullin <ramil.kalimullin@oracle.com>
Date:   Wed Aug 5 11:52:40 2015 +0400

    Bug #19902868: MYSQL MAY NOT CALL SE DELETE_TABLE METHOD WITH DYNAMIC PLUGINS
    
    Problem: [1;31mperf[morming DROP/TRUNCATE/RENAME TABLE commands, server resolved storage engine (SE) reading its legacy_db_type from .FRM file (see dev.mysql.com/doc/internals/en/frm-file-format.html), which is not suitable for dynamic SE.
    
    Fix: resolve dynamic SE by its name from .FRM file.
    
    Details: sql/datadict.cc: dd_frm_type_and_se() function introduced. It reads .FRM file and resolves both dynamic and static SEs in case of FRMTYPE_TABLE. dd_frm_type() function is limited to check only .FRM type.
    We no longer will silently remove in DROP TABLES/DROP DATABASE .FRM files which have too old version or wrong .FRM magic.

[33mcommit ff9079730bde766b83c8bb2da6afb1a672f719c5[m
Merge: 6e9259e6b4b 90612519559
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Aug 3 10:03:27 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug #21239299 MYSQL CRASHED BECAUSE OF FLUSH_ALL
      Bug #20909518: HANDLE_FATAL_SIGNAL (SIG=11) IN                FIND_USED_PARTITIONS | SQL/OPT_RANGE.CC:3884
      Bug #20909518: HANDLE_FATAL_SIGNAL (SIG=11) IN                FIND_USED_PARTITIONS | SQL/OPT_RANGE.CC:3884
      Bug# 18195972 CODE CLEANUP RELATED TO BLOB OWNERSHIP AND INHERITANCE
      Bug#21442376 : Fixing syntax error in disabled.def
      Add mysqlpump man page
      BUG#21457699 AUDIT API 'MYSQL_AUDIT_GLOBAL_VARIABLE_SET' EVENT DOESN'T CARRY NEW VALUE INFO
      Bug#21211187 CRASH IN JOIN::UPDATE_DEPEND_MAP Bug#21292102 CRASH IN GET_SORT_BY_TABLE()
      Bug#21139402 ASSERTION FAILED: LENGTH > 0 && KEYPARTS != 0, CRASH IN JOIN::OPTIMIZE_KEYUSE
      BUG#21349028: BACKPORT PATCH FOR BUG#16621582 TO MYSQL-5.6
      Bug#21139722: Assertion failed: !(used_tables() & ((table_map) 1) << size...))
      BUG#21458066 AUDIT API SHOULD SUPPRESS ABORTING ON MYSQL_AUDIT_COMMAND
      Bug#21507796 - ASSERT IN ROW_SEL_CONVERT_MYSQL_KEY_TO_INNOBASE WITH REPLACE GENERATED COLUMN
      Bug# 21348684 SIGABRT DURING RESIZING THE INNODB BUFFER POOL ONLINE WITH MEMORY FULL CONDITION
      Bug #21520379 ASSERT AT BTR_FREE_EXTERNALLY_STORED_FIELD IN BTR0CUR.CC
      Bug#21442376 : Disabled [1;31mperf[mschema.no_threads on windows
      Bug#21507072: SIG 11 IN TABLE_LIST::MAP AT SQL/TABLE.H:2463
      Bug#21528683 SLOWDOWN CAUSED BY MEMSET IN SQL_DIGEST_STORAGE.RESET()
      Bug #21348684 SIGABRT DURING RESIZING THE INNODB BUFFER POOL ONLINE WITH MEMORY FULL CONDITION
      BUG#21405865 - LOG WARNING WHEN A DISABLED STORAGE ENGINE                IS SET BY RELATED SYS VAR.
      BUG#20481175 - ALTER ADD FTS INDEX ASSERT TRX->DICT_OPERATION_LOCK_MODE == 0 || TRX->DICT_OP...
      Fix#Bug 21478287 - FAILING ASSERTION: TEMPL->ICP_REC_FIELD_NO != ((ULINT)(-1))
      Bug #21348684 SIGABRT DURING RESIZING THE INNODB BUFFER POOL ONLINE WITH MEMORY FULL CONDITION
      Bug#21162525: ASSERT `! IS_SET() || M_CAN_OVERWRITE_STATUS' AT SQL_ERROR.CC:444
      Bug#21442624 INCORRECT RESULT FROM JSON_SET WITH AUTO-WRAPPING
      Bug#21442624 INCORRECT RESULT FROM JSON_SET WITH AUTO-WRAPPING
      Bug#21512842: Sig 11 in check_column_grant_in_table_ref
      Doxygen cleanup
      Bug #20796566   ERROR: INSERT BUFFER INSERT FAIL CANNOT                       INSERT INDEX RECORD
      Bug#21442878 INCORRECT RETURN STATUS FROM ITEM_JSON_TYPECAST::VAL_JSON() ON PARSE ERRORS
      BUG #20980691 - MTR FAILS WITH --PARALLEL IF VARDIR IS 81 CHARACTERS LONG post fix
      BUG #20980691 - MTR FAILS WITH --PARALLEL IF VARDIR IS 81 CHARACTERS LONG
      Bug#20821550 : ADD MYSQL_GET_PARAMETERS FUNCTIONALITY TO MYSQL_GET_OPTION()
      BUG#21429854 ST_DIFFERENCE : ASSERTION FAILURE IN SPATIAL.CC FILE BUG#21436139 CRASH/ASSERTION FAILED: INVALID OPERATOR< IN ALGORITHM(3014) : BUG#21441991 CRASH AFTER UNINITIALIZED VALUE IN LESS_SEG_FRACTION_OTHER_OP
      Limit innodb_v_basic.test to server with pagesize under 16k. Since we do not support create compress table with > 16k page size
      BUG#19641963 RPL.RPL_SEMI_SYNC_GROUP_COMMIT_DEADLOCK FAILS WITH              ASSERT IN MTS CODE
      Bug#21472872 WRONG RESULTS CAUSED BY PATH LEG POPPING IN JSON FUNCTIONS
      Bug#21472872 WRONG RESULTS CAUSED BY PATH LEG POPPING IN JSON FUNCTIONS
      Bug#21507334: ASSERTION `0' IN BOOL SHOW_SLAVE_STATUS_SEND_DATA AT RPL_SLAVE.CC
      Bug#21446772 INNODB: DROP TABLESPACE DOES NOT DELETE ISL FILES
      Bug #21446772         INNODB: DROP TABLESPACE DOES NOT DELETE ISL FILES
      Bug#21419888 INNODB: CANNOT CREATE A TABLESPACE ON A DRIVE ROOT IN WINDOWS
      Doxygen cleanup
      Bug #18195972 CODE CLEANUP RELATED TO BLOB OWNERSHIP AND INHERITANCE
      Doxygen cleanup
      Bug#21216067 ASSERTION FAILED ROW_UPD_SEC_INDEX_ENTRY (INNOBASE/ROW/ROW0UPD.CC:2103)
      Fixed failure on pb2
      BUG#19641963 RPL.RPL_SEMI_SYNC_GROUP_COMMIT_DEADLOCK FAILS WITH              ASSERT IN MTS CODE
      BUG#19641963 RPL.RPL_SEMI_SYNC_GROUP_COMMIT_DEADLOCK FAILS WITH              ASSERT IN MTS CODE
      Fixed bug#21469535: VALGRIND ERROR (CONDITIONAL JUMP) WHEN INSERT ROWS INTO A PARTITIONED TABLE
      Doxygen cleanup.
      Doxygen cleanup
      Bug#21487833: DBUG_ABORT() IN JSON_WRAPPER::MAKE_HASH_KEY WITH ORDERED JSON
      Update docker package names
      Update docker package names
      BUG#20894024 - FIREWALL STILL DEPENDS ON MAX_DIGEST_SIZE OF THE P_S DIGEST

[33mcommit 4d9b2454078528dd0dfb13c5548aecf73d794787[m
Author: Anitha Gopi <anitha.gopi@oracle.com>
Date:   Fri Jul 31 02:35:53 2015 +0200

    Bug#21442376 : Disabled [1;31mperf[mschema.no_threads on windows

[33mcommit 206b7bdbc114e7505fb52d8349a4433be22caf48[m
Merge: 8358d59e0ed 7d8937daf6f
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Jul 13 19:17:19 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      BUG#21389101 ST_GEOMFROMGEOJSON: STACK OVERFLOW IN RAPIDJSON::GENERICREADER
      Bug#21383284: ASSERTION IN SELECT_LEX::SETUP_CONDS
      BUG#21303289  Removed sqlbench leftover in deb platform pkg src
      BUG#21434004   UBUNTU 15.04 REPO PACKAGES DO NOT CONTAIN ESSENTIAL SCRIPT LIKE MYSQLD_SAFE list of files being re-installed in server pkg: +usr/bin/mysqlbinlog +usr/bin/mysqld_multi +usr/bin/mysqld_safe
      Remove MCP_GLOBAL_SCHEMA_LOCK patch
      Fix syntax error in ndbinfo_sql.cpp
      Fixed mysql_ssl_rsa_setup test failing on Windows after pushing bug fix for bug#21025377
      BUG#21280816 CONNECTION PERFORMANCE REGRESSION TEST HANGS SYSBENCH
      Keep ndbinfo_sql.ccp in sync with mysql_system_tables.sql
      Remove unintentional change in variables-big.test
      Bug #20168526 YASSL: CORRUPT SSL-KEY CRASHES CLIENT
      Version change in d/changelog for DEB pkg src 5.7.9+ are non-rc releases
      - Bug#21407023: DISABLING AHI SHOULD AVOID TAKING AHI LATCH   Currently if AHI is disabled check for it was protected by AHI latch which   caused latch overhead even though the feature is not adding any value.
      Bug#21429471 - COMMUNITY/COMMERCIAL EL7 UPDATE FAILING WHEN MARIADB-BENCH.X86_64 INSTALLED
      Bug #20728894: MEMORY LEAK IN ADD_DERIVED_KEY()
      Bug #21056907: CONTENTS OF NOT REQUESTED CHAR/VARCHAR                COLUMN ARE REVEALED
      Bug #20777016: DELETE CHECKS PRIVILEGES ON THE WRONG                DATABASE WHEN USING TABLE ALIASES
      Bug #18636874 PASSWORD VALIDATE PLUGIN: DICTIONARY CHECK MISBEHAVES WITH GOOD HEX INPUT
      WL#7254 Audit API extensions
      Bug#21374104 SETUP_TIMERS INITIALIZATION ASSUMES CYCLE TIMER IS ALWAYS AVAILABLE
      Bug #20087571: 5.7 EASILY HITS ERROR 1436 (HY000): THREAD STACK OVERRUN ERRORS ON MANY EXPR'S
      Bug#21383896 DECIMAL FIELD TAKES IN VALUES FROM OTHER FIELDS
      Bug#21153489 VALGRIND ERRORS IN ITEM_BOOL_FUNC2::IS_NULL LEAD TO CRASH LATER
      Fix syntax errors in 16node-tests.txt and upgrade-tests.txt
      Bug#21337139 ATRT SILENTLY STOPS TESTING AT FIRST SYNTAX ERROR IN TEST CASE FILE
      Fix a compilation error after bc098885
      Bug#21338012 MTR MANUAL-GDB OPTION DOES NOT WORK
      Bug #21280801: VERSION TOKEN LOCKING DOES NOT WORK
      BUG#21421471 LICENSE HEADERS MISSING IN FILES
      Bug#21300774 ASSERT `!INIT_FTFUNCS(THD, SELECT_LEX)` IN JOIN::RESET AT SQL/SQL_SELECT.CC:874
      Bug#21300774 ASSERT `!INIT_FTFUNCS(THD, SELECT_LEX)` IN JOIN::RESET AT SQL/SQL_SELECT.CC:874
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      BUG#20074353 HANDLE_FATAL_SIGNAL (SIG=11) IN MY_B_WRITE | MYSYS/MF_IOCACHE.C:1597
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      Addendum 2 to bug #21034322: removed the max test due to it being different for different OSes
      Follow up fix for WL#8149 change, fix create_thd() issue and test mismatches
      Merge WL#8149 related worklogs to mysql-trunk
      Bug#21271736 UNITTEST UT0CRC32-T HANGS ON SOLARIS 10 SPARC
      Bug#21381060 A "CASE WHEN" EXPRESSION WITH NULL AND AN UNSIGNED TYPE GIVES A SIGNED RESULT
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Remove non experimental test.
      Bug#18949282 I_MAIN.MYSQL_CLIENT_TEST FAILED AT LINE 43, COMMAND $I_M_C_T
      Configure smaller redo log for test ndb.ndb_backup_rate.
      Updating the test case ndb_addnode_restart* :  The autotest testSystemRestart had an additional restart loop  in runAddNodesAndRestart function, which is not needed as there  is no change in the configuration of the cluster.  Removed that and updated the name of the funcction and added few  comments to explain the proper setup of the testcase
      Fix for WL#7763
      WL#7763, remove use of inet_ntoa from ndb parts
      Post-push test fix for Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      Bug#17493646 NDB: CALL TO MY_ERROR() LACKS ERROR CODE AND ERROR STRING ARGUMENTS
      Bug#21352763 FLEXASYNC SEGFAULTS IF FAILED TO CREATE TABLES
      BUG#21297407: Fix to ensure sending CONTINUEB with proper variables in dropTable_wait_usage
      Pushing BUG#21297407 revealed an uninited variable in Fragrecord in DBLQH (lcp_frag_ord_state, was set to LCP_QUEUED == 0 in most cases which led to crash if drop table happened before LCP had time to execute
      BUG#20981491: Fix resource issues for NR, LCP andb Backup with regard to scan numbers, BUG#21362758: Crash with holding LocalDLFifoList context over call EXECUTE_DIRECT(NEXT_SCANCONF), BUG#21370839: Ensure also ACC scans are queued in a proper manner, previous push only added test case to autotest
      BUG#20981491: Fix resource issues for NR, LCP andb Backup with regard to scan numbers, BUG#21362758: Crash with holding LocalDLFifoList context over call EXECUTE_DIRECT(NEXT_SCANCONF), BUG#21370839: Ensure also ACC scans are queued in a proper manner
      BUG#20993380: (Also BUG#69994 in community bugs), ensured that node recovery and LCP scans can continue even if user has used up all resources for user level transactions, reserved operation records and segments for necessary things during LCP and NR scans
      Fix test case testRedo -n RedoFull
      Fix testRedo -n RedoFull test case
      BUG#21297407: Speed up drop table
      Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Raise version number after cloning 7.1.36
      Raise version number after cloning 7.3.10
      Raise version number after cloning 7.4.7
      Raise version number after cloning 7.2.21
      Fixed syntax errors in daily-basic-tests.txt
      Implement required methods in clusterj-openjpa
      Bug#20504741 Improve clusterj release of byte buffers by adding a user method session.release
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7570 Remove ifdefs which are not necessary since trunk has it all
      Bug #20592110         CLUSTER CIRCULAR REPLICATION WITH IGNORE_SERVER_IDS() BROKEN BY ANONYMOUS_GTIDS
      revert change to mysql-test-run
      Bug #21326540         NDB_JOIN_PUSHDOWN TESTS UNSTABLE EXECUTE_COUNT
      Remove obsolete ifdef
      Add comment re. valgrind
      WL#6815 Adapt MySQL Cluster to 5.7
      Revert "WL#6815 Adapt MySQL Cluster to 5.7"
      Removed extra blank line in ATRT test scripts preventing tests to start (Due to ATRT bug)
      Bug #17878183       NDB CONTINUOUSLY REBOOTING DUE TO FILE NOT FOUND (DBLQH:
      Bug#17493646 NDB: CALL TO MY_ERROR() LACKS ERROR CODE AND ERROR STRING ARGUMENTS
      Increase timeout for ATRT test
      Increase timeout for ATRT test
      BUG#20904721, WL#8525: Fix of part9, used internal TUP pointer instead of LQH pointer when calling LQH function directly, leads to both wrong handling and sometimes even a crash when index is not a used scan pointer
      Apply pollEvent_v4.patch from Ole John
      restore new scheduler & multiwait fix to bug branch
      If memcached crashes, mysql-test-run should not restart it.
      On misc. errors, print workitem to debug log
      always compile ndb memcache with DEBUG_OUTPUT
      More unified error handling
      New record_ndb_error() function where error logger keeps statistics but caller is resposnsible for writing to log file. Direct error messages to the debug log if enabled.
      The table scan code where NDB Memcache reads it configuration tables was written poorly, and could cause memcached to crash during configuration.
      revise debug messages in new scheduler
      switch default scheduler to Trondheim
      always compile ndb memcache with DEBUG_OUTPUT
      More unified error handling
      New record_ndb_error() function where error logger keeps statistics but caller is resposnsible for writing to log file. Direct error messages to the debug log if enabled.
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#11759461 NDB_CONFIG --XML --CONFIGINFO: VARIOUS UPDATES TO PARAMETERS LISTED
      Bug#11760628 DEPRECATE EXECUTEONCOMPUTER
      Bug #21270509         FAULTY COMMENT DESCRIBING NDB_MGM_NODE_STATE.CONNECT_ADDRESS IN MGMAPI.H
      Bug #21270425         MGMAPI.H SPELLING ERROR
      Bug#20617891: NDB : SUSPICIOUS HANDLING OF SIGNAL-WAIT TIMEOUT IN NDBAPI
      read configuration in a single consistent transaction
      The table scan code where NDB Memcache reads it configuration tables was written poorly, and could cause memcached to crash during configuration.
      Revert "Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000"
      Revert "Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000"
      Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      BUG#20904721: Fix for a number of asserts that assumed interpreted mode for all scans
      BUG#20727343: Fix failing ndb_dd_initial_lg test case, minor initialisation issue
      reapply bugfix in this branch. do not push this change to 7.4
      move another message from debug to detail level
      move another message from debug to detail level
      WL#8525: Part 11, don't use interpreted execution for LCPs and Backups since it is a waste of CPU resources
      BUG#20904721: Part 9: Implementing the adaptive LCP speed using bounded delay concepts and A-level signals
      more safety when Ndb::startTransaction() fails
      more safety when Ndb::startTransaction() fails
      add a more detailed debug output level to ndb memcache
      Anticipate SERVER_ERROR responses in My::Memcache.pm
      Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      Test case for Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      induce memcached to flush its log file at end of mtr testing
      BUG#20727343: Fix problems in UNDO log applier when changing log files
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Revert of prev push for bug#20957068
      Fix for Bug#20957068:
      Post merge fixes (mysql-5.6.25 via mysql-5.6-cluster-7.3 into mysql-5.6-cluster-7.4)
      Port commit to MySQL Cluster 7.3
      Port of commit to MySQL Cluster 7.3
      Port of commit to MySQL Cluster 7.3
      Port commit to MySQL Cluster 7.3
      some additional debug output re. online reconfiguration
      Test: temporarily revert recent changes
      Bug#20730053: BACKPORT BUG#19770858 TO 5.1
      Test: temporarily revert recent changes
      Bug#20734434 - SPELLING ERROR \"EMDEDDED\" IN RPM SPEC FILES
      Bug#20788853 MUTEX ISSUE IN SQL/SQL_SHOW.CC RESULTING IN SIG6. SOURCE LIKELY
      Bug#18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Bug#21270190 REMOVE UNUSED AND DANGEROUS NDBHOST_GETHOSTNAME()
      Fix compiler warnings due to hidden inherited virtual and release-unused variables.
      Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Backport of Part 2 (of 2) of fix for Bug#18390321 to 7.2 & 7.3
      bug#17638548 Try to address test failures from previous push
      Reenable usage of send threads in MTR tests.
      Part2 (of 2) fix for Bug#18390321
      Temporarily change default MTR test config to use worker thread sending (No send threads) in order to get some regression test coverage of part1 patch for bug 18390321
      Bug #17878183         NDB CONTINUOUSLY REBOOTING DUE TO FILE NOT FOUND (DBLQH: CAUSED BY ERROR 2341)
      Part1 (of 2): Fix for Bug#18390321
      bug#17638548 In NDB Memcache 7.4 use 7.3 Scheduler by default
      bug#17638548 : reset "woken" state after wakeups
      Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Fix failing ATRT testcases:
      Increase timeout value for several failing 'testNodeRestart ... DD' tests.
      Fix failing testcase 'testNodeRestart -n GcpStop T1 --loops=1' :
      Added more printout to testcase 'testBasic -n Bug54986 D2' in order to aid in understanding why / where this test fails.
      Increase timeout for  'testNodeRestart -n Bug27003 T1' from 1800 -> 3600sec.
      Moved unstable 'basic' tests to 'devel'.
      Fix compiler warnings in patch for bug#21185585:
      fix bug in cmakelists from previous push
      Convert test_workqueue into a TAP test
      Fix for bug#21185585
      ndb memcache: recently in CLUB testing of ndb memcache suite, 7.4 consistently passes but 7.3 has many failures.  This commit swaps the default schedulers in 7.3 and 7.4 to see if that leads to any change in the pattern of test results.
      ndb memcache: change default scheduler in 7.3
      bug#21067283 Fix inconsistent space calculations in NdbRecord
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      BUG#18234170 Foreign Constraints are lost from NDB Tables during truncate
      Bug#21184102 PATCH FOR BUG#16890703 MYSQLD STUCK IN OPN TABLES ..., LOST IN 7.3 AND UPWARD Added error check for missing database directory, added testcase
      BUG#18234170 Foreign Constraints are lost from NDB Tables during truncate
      WL#8648 NDB_SHARE lifecycle improvements
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7578 Refactor schema distribution code
      WL#8648 NDB_SHARE lifecycle improvements
      Bug#21141495 NDB_MGMD USES 90% CPU
      Remove global forward declaration of Ndb_fk_data
      BUG#20095208: Fix to make portlib not dependent of ndbgeneral
      Removed compiler warning
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Only use C++ ABI functionality if libstdc++ is being linked. Otherwise resort to protect the allocation/deallocation of the static objects using the existing connection mutex.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      Patch for bug#21109605
      Removed compiler warning
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Only use C++ ABI functionality if libstdc++ is being linked. Otherwise resort to protect the allocation/deallocation of the static objects using the existing connection mutex.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      WL#8525: BUG#20904721: Part6: Improve [1;31mperf[mormance of checksum calculations, remove unnecessary ones and simplify bit toggling ones. Also solves BUG#20980229 that ensures that also header bits are included in checksum calculation.
      BUG#20904721: Fix LCP processing with heavy insert activity, part 2
      Improve multi-thread use of charsetDecoder and charsetEncoder in clusterj Utility   charsetDecoder is used only in Decimal decoding   charsetEncoder is used only in Decimal encoding   charsetDecoder and charsetEncoder are not thread-safe   use charset.decode for decoding   use charset.newEncoder().encode for encoding   avoid synchronization
      bug#20095208 - UNABLE TO STORE FRAGMENT DURING LCP. NDBFS ERROR: 2812 - DBLQH (LINE: 14305)
      bug#20095208 - UNABLE TO STORE FRAGMENT DURING LCP. NDBFS ERROR: 2812 - DBLQH (LINE: 14305)
      Bug#18753887 MYSQLD STOPPED WRITING TO BINARY LOG Modifies pollEvents to return latest_GCI as NDB_FAILURE_GCI (~(Uint64)0) in case a cluster failure has been detected. An internal flag is set in NdbEventBuffer::report_node_failure_completed and the flag is reset when the next SUB_GCP_COMPLETE_REP signal is received. Test case StallingSubscriber is extended to verify that NDB_FAILURE_GCI is returned and that polling of events is resumed after the cluster is connected again and new epochs are received.
      Bug#18753887 MYSQLD STOPPED WRITING TO BINARY LOG     Modifies pollEvents to return latest_GCI as NDB_FAILURE_GCI (~(Uint64)0)     in case a cluster failure has been detected. An internal flag is set     in NdbEventBuffer::report_node_failure_completed and the flag is     reset when the next SUB_GCP_COMPLETE_REP signal is received.     Function Ndb::isExpectingHigherQueuedEpochs is added to be used together     with pollEvents2 that checks if cluster has disconnected due to failure     causing no more events to be received.     Test case StallingSubscriber is extended to verify that NDB_FAILURE_GCI     is returned and that polling of events is resumed after the cluster     is connected again and new epochs are received.
      BUG#20904721: Part 8: Fixing the NDB scheduler to work with Bounded delay signals
      Revert last merge
      Fix multi-thread use of charsetDecoder in clusterj Utility   charsetDecoder is used only in Decimal decoding   charsetDecoder is not thread-safe
      Follow up testcase fix for MCP_BUG20701918
      MCP_BUG20701918  create-old-temporals MySQLD option
      BUG#20904721: Fix of previous push
      Fix regression in debug build caused by fix for bug#20408733.
      WL#8525: BUG#20904721: Part 4, write up description of local LCP protocol and how to handle overload situations, increase to prio level A in some cases. Also standardise naming on END_LCPREQ and END_LCPCONF and remove all usages of END_LCP_REQ and END_LCP_CONF.
      BUG#20904721: WL#8525: Part 3, use prefetch to speed up scan processing for LCP scans and also other full table scans, such as node recovery scans and user level full table scans
      WL#8525: BUG#20904721: Part 7: Ensure it's not so easy to misconfigure LCPs and Backups
      BUG#21049554: Fix OM_SYNC flag to work on all platforms, not only those that support the O_SYNC flag
      WL#8525, BUG#20904721: Part1: Avoid LCP watchdog crash when scanning many pages with LCP_SKIP records
      Fix annoying compiler warnings on Mac OS X
      Fix white space warning in clusterj
      Bug #20504741 Bug #20695155 Improve Clusterj handling of ByteBuffers to reduce direct memory footprint Fix Clusterj incompatibility with Java 7
      Backport My::Memcache.pm improvements from 7.3 This will be null-merged up
      Eliminate some compiler warnings in 3rd party memcached code for NDB Memcache This fix includes both reducing the gcc warning config in CMakeLists.txt and changing two memcached source files. No Oracle copyright is added to the changed 3rd party files.
      Clusterj Trivial bug fix for error displays
      Bug#21055643 REDUCE DEBUG PRINTOUT DURING A GAP AND IMPROVE
      Properly include m_string.h when using my_stpcpy
      Improve comments
      Cache the key_length in NDB_SHARE_KEY
      Provide type safety by using the opaque NDB_SHARE_KEY* type
      Use NDB_SHARE::key_string() instead of direct access to key member
      Move NDB_SHARE::key_length into NDB_SHARE_KEY
      Rewrite the lgive share leak name  to also use NDB_SHARE::create_key
      Move all NDB_SHARE key initialization into NDB_SHARE::creat_key()
      Fix some compiler warnings from memcached sources
      My::Memcache.pm: handle case where the last read before a timeout completed the read buffer. Open a new memcache connection when trying to fetch server error stats.
      Save the prepared key in Ndb_schema_dist_data
      Rename ndbcluster_prepare_rename_share to NDB_SHARE::create_key
      Remove NDB_SHARE::mem_root and instead use my_malloc for dynamic strings
      Change ndcluster_prepare_rename_share to return newly allocated key
      Remove NDB_SHARE::old_names
      Pass the new_key as argument to ndbcluster_rename_share
      Skip ndb_ddl tests with embeddes server
      Change to allocate Ndb_CONFLICT_FN_SHARE bith my_malloc
      Make the NDB_CONFLICT_FN_SHARE an opaque type for users of ndb_share.h
      Remove useless typedefs
      Remove backwards jump into a hoop on fire
      bug#18411034: Remove an unnecessary if-statement
      Print stats for the MEM_ROOT in Ndb_event_data
      Increased the undolog file size from 256MB to 512MB and FragmentLogFileSize from 64MB to 128MB.
      bug#18411034: Assertion gci_ops && (gci == gci_ops->m_gci) failed
      bug#18411034: Assertion gci_ops && (gci == gci_ops->m_gci) failed
      bug#20553313, bug#20707694 - fix index stats query delays
      Bug#20479917 REMOVE MCP_BUG16021021
      Bug#21026199  RANDOM WARNING ORDER NDB_ONE_FRAGMENT
      Addendum to the fix for bug #20681412:
      post push minor test fix for bug:19887143
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug#20234681 HA_NDBCLUSTER USAGE OF FIND_FILES LEAK MEMORY INTO (UNRELEASED) MEM_ROOT
      Move new drop_table test to suite ndbcluster
      Bug#20728189 DROP TABLE SEGFAULTS IF FIRST STATEMENT ON A NEW CONNECTION
      Adding force_restart option to ndb_addnode_restart_setup.inc To force restart servers during retries.
      Bug#20782580: NDB REDO OVERLOAD: ABORT QUEUING REQUESTS IF OUT OF LOG SPACE
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      Added 5 autotest testcases to test node restart with following scenarios. 1. Restarting one node at a time. 2. killing two node of different groups and starting them with and without initial option. 3. Restarting a node which doesn't belongs to node group 0, and checking that it is not associated with node group 0 after restart. 4. killing four node of different groups and starting them with and without initial option. 5. Killing only the master nodes one by one and starting them without initial option.
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      Bug#11762750 TABLE NDBINFO.CONFIG_PARAMS SHOULD BE READ-ONLY (FOR NOW)
      Bug#16731538 MYSQLD CRITICAL FAILURE DURING ORDERED SELECT FROM NDBINFO.CLUSTER_OPERATIONS
      BUG#20075747 RND_INIT() ON AN OPEN SCAN IS USED TO REPOSITION THE CURSOR
      WL#7575 Remove ndbinfo's usage of other engine
      My::Memcache -- longer write timeot
      My::Memcache client, fix bug in read() where desired length is 0
      Remove include/ndb_default_cluster.inc
      WL#8165 Use new records per key interface in NDB
      Fix for Bug#20954804
      Fix for Bug#20954804
      Bug#20782580: NDB REDO OVERLOAD: ABORT QUEUING REQUESTS IF OUT OF LOG SPACE
      Fix a possible crash in AutoTest when an ordered scan encounter error 4008, scan timeout. One such testcase is 'testScan -n ScanRead4880'
      Bug#11760802 SEVERAL MGMAPI FUNCTIONS RETURN 0(SUCCESS) WHEN NO HANDLE OR NOT CONNECTED
      Refactoring of create partitioned table
      Revert unintentional change
      My::Memcache - do not close connection before attempting to fetch server error statistics
      MTR ndb_memcache more tweaks to timeout handling
      Bug#20814396 PB2 IS SECRET ABOUT WHAT UNIT TESTS IT RUN
      Revert "Remove MCP_GLOBAL_SCHEMA_LOCK patch"
      Revert "Remove MCP_GLOBAL_SCHEMA_LOCK patch"
      Fixing the following test failures by synch'ing the error injection and the test checking the error:
      increase timeouts
      Better failure handling in My::Memcache.pm
      Provide more information when an ndb_memcache test fails
      BUG#20887445: Fix so that cpuset is working in ThreadConfig, previously node log proclaimed it was working where it wasn't really working
      Fix ndbapi example programs to work on Mac OS X Yosemite
      BUG#20887445: Fix so that cpuset is working in ThreadConfig, previously node log proclaimed it was working where it wasn't really working
      Fix ndbapi example programs to work on Mac OS X Yosemite
      Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED
      Bug#20729091 - ASSERTION TYPE < NDBDICTIONARY::EVENT::TE_EMPTY FAILED
      Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS
      Bug#20762291 - POLLEVENTS2() WILL RETURN ERROR (-1) IF GIVEN WAITTIME AMILLISECONDS IS NEGATIVE
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Fix testIndex seg fault where index not exists when calling indexReadRecords, added check for NULL return
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      MTR ndb_memcache : still better timeout handling & more verbose reporting during test runs
      Revert to older scheduler as default in 7.4 for testing
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Remove MCP_WIX
      Handle server timouts and disconnects in MTR's My::Memcache client
      Work on My::Memcache to handle server disconnects and timeouts
      Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS Bug#20561446 NDB : NDBEVENTBUFFER NEEDS MORE THREADING PROTECTION
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      fix
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      NDB Memcache external_values fixes: The external_values test had a Perl bug using "==" instead of "eq", causing tests to pass even when the server produced errant responses. This patch fixes the test case and also fixes the revealed errant behavior in memcached.
      Remove MCP_WIX
      Remove MCP_WIX
      Remove MCP_WIX
      Do not change default scheduler in 7.2
      NDB Memcache: use pollEvents2() in reconfiguration waiter thread
      bug#17638548: NDB Memcached uses excessive CPU. This patch works around the underlying issue by defaulting to a new scheduler which does not make use of the NDB MultiWait APIs.
      NDB Memcached: enable "Trondheim" scheduler in 7.2
      one more solaris fix
      Fix for compiler error on Solaris
      Adapt 73 Scheduler to new online configuration manager
      one more solaris fix
      Fix for compiler error on Solaris
      Fixup from previous merge
      NDB Memcache: backport improvements into 7.2
      Backport misc. NDB memcache changes from 7.3 to 7.2
      Raise version number after cloning 7.2.20
      Raise version number after cloning 7.3.9
      Raise version number after cloning 7.4.6
      Raise version number after cloning 7.1.35
      Attempt better "htonll" portability in NDB memcache code
      BUG#20665205, fixed a part where we skipped reading of page 0 which was required to do in last file, also due to file 0, page 0 writes we can trust this page to be correct
      Add ndb specific changes for Bug#20094067: BACKPORT BUG#19683834 TO 5.5 AND 5.6
      Added ndb testcase for bug#19856162.
      Post-push fix for bug#19856162.
      Merge into cluster: WL#8354 BACKPORT DIGEST IMPROVEMENTS TO MYSQL 5.6
      Revert "Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS"
      Revert "Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS"
      Revert "Bug#20729091 - ASSERTION `TYPE < NDBDICTIONARY::EVENT::TE_EMPTY' FAILED."
      Revert "Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED"
      BUG#20665205: Fix REDO log issue
      Added autotest testcases to test addnode and restart.
      Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED
      Bug#20729091 - ASSERTION `TYPE < NDBDICTIONARY::EVENT::TE_EMPTY' FAILED.
      Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS
      Bug 20762291 - POLLEVENTS2() WILL RETURN ERROR (-1) IF GIVEN WAITTIME AMILLISECONDS IS NEGATIVE
      Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS Bug#20561446 NDB : NDBEVENTBUFFER NEEDS MORE THREADING PROTECTION
      Remove MCP_WIX
      Resurrect unintentionally remove disabled.def file

[33mcommit 86027c00d1dbc9161fa4a8ca0c5dcc416005c8d3[m
Author: Ramil Kalimullin <ramil.kalimullin@oracle.com>
Date:   Thu Jul 9 12:54:04 2015 +0400

    Bug #19917521: MEMORY LEAK WITH STRING THREAD VARIABLE THAT SET MEMALLOC FLAG
    
    Post-push fix: [1;31mperf[mschema.show_plugin result adjusted.

[33mcommit 9039f36cc09ed834323245e2992c8312d3aec733[m
Merge: ea07cbb220e 3ea559787e7
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jul 7 21:58:36 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug#21068487 - INNODB: PREVENT RELATIVE ISL PATHS UNDER THE DATADIR
      Bug#21068487 - INNODB: PREVENT RELATIVE ISL PATHS UNDER THE DATADIR
      Bug #20868496: MYSQL_UPGRADE IN 5.7.7+ REPAIR LOOKS USER TABLES IN TEST WHEN LOAD FROM 50/51/55
      Bug#21376546 - ALTER TABLE DESTROYS CONTENT OF INDEXED VIRTUAL COLUMN
      Bug#17763238: MYSQL_UPDATE CRASH WHEN SUBSTITUTE_FOR_BEST_EQUAL_FIELD               RETURNS NULL CONDS
      Bug #19779113   INNODB REFUSES STARTUP WITH INNODB_FORCE_RECOVERY>3
      WL#7755 mysqlpump: Extend mysqldump functionalities. Post-push fix: Convert files to UNIX format.
      Bug#21328041: STREAMLINE THE INITIALIZATION OF THE ERROR LOG
      WL#8149  B-tree Index Support on non-materialized virtual columns
      Bug#21143151 ASSERTION FAILED: BITMAP_IS_CLEAR_ALL(&SORT_FORM->TMP_SET)
      Update release version for 5.7.9
      Bug #21306319: HARMONIZE MAX_EXECUTION_TIME HINT WITH MAX_STATEMENT_TIME Bug #21306392: REMOVE OLD-STYLE MAX_STATEMENT_TIME HINT (REPLACE WITH MAX_EXECUTION_TIME)
      Updated for 5.7.9
      Raise version number after cloning 5.7.8-rc
      BUG#21303289  Adding lost SECURE_FILE_PRIV_EMBEDDED in previous commit for the bug Modified file cmake/install_layout.cmake
      BUG#21303289  REMOVE SQLBENCH ON ALL DEBIAN AND UBUNTU PLATFORMS
      WL8406 Remove sql-bench
      WL#7755: Extend mysqldump functionalities. Temporary fix for mysqlpump test hang issue.
      WL#7755: mysqlpump: Extend mysqldump functionalities
      WL#8596 Turn STRICT_MODE submodes ON by Default
      Code change so session_tracker_trx_state passes with --valgrind
      Fix valgrind error introduced by WL#8149 checkin
      Followup:BUG#21245805 HA_INNOBASE::RECORDS_IN_RANGE() RETURNS CONSTANT FOR SPATIAL INDEXES
      BUG#21305976
      Bug#21328041: STREAMLINE THE INITIALIZATION OF THE ERROR LOG
      Bug#21328041: STREAMLINE THE INITIALIZATION OF THE ERROR LOG
      Run all Valgrind tests on daily/weekly
      WL#2284: Increase the length of a user name
      WL#2284: Increase the length of a user name
      Bug#20563954 - INNODB: SUPPORT MOVING A WHOLE DATADIR WITH GENERAL TABLESPACES. Bug#19896685 - INNODB: RECOGNIZE DIFFERENT PATH STRINGS THAT POINT TO THE SAME LOCATION Bug#20555168 - INNODB: MAKE GENERAL TABLESPACES PORTABLE FROM WINDOWS TO UNIX Bug#21068487 - INNODB: PREVENT RELATIVE ISL PATHS UNDER THE DATADIR
      WL#8596 Turn STRICT_MODE submodes ON by Default
      WL#8596 Turn STRICT_MODE submodes ON by Default
      WL#7755: mysqlpump: Extend mysqldump functionalities
      WL#6631: Detect transaction boundaries
      WL#8540: Support IF [NOT] EXISTS clause in CREATE/DROP USER
      Adjust two test results due to previous WL#8149 checkin
      WL#8149  B-tree Index Support on non-materialized virtual columns WL#8114  Don't store virtual generated columns in database WL#8227  Support SEs to create index on virtual generated columns WL#8481  Callback for computation of virtual column index values from InnoDB purge threads All 4 worklogs are to support virtual column and virtual index on such columns.
      WL#8594 - PROVIDE AN OPTION TO REJECT USER TABLE CREATION UNDER SPECIFIED STORAGE ENGINES.
      BUG#21245805 HA_INNOBASE::RECORDS_IN_RANGE() RETURNS CONSTANT FOR SPATIAL INDEXES
      Revert "Bug #21024340: 2nd attempt"
      Revert "Addendum to bug #21024340: fixed the unit tests"
      Revert "Bug #21024340: Resolved the congestion on the zeroth mutex in the"
      Revert "Bug#21024340: split the plugin mutex"
      WL#7755: mysqlpump: Fixed conflicts.
      WL#7755: mysqlpump: Extend mysqldump functionalities   Mysqlpump is a new client utility similar to mysqldump, however mainly   focussed to improve the [1;31mperf[mormance of taking dumps. This new tool   would achieve the following:   1. Provides basic functionality of mysqldump.   2. Allows to take dumps in parallel using multiple threads and queues      which can be configured using command line options.   3. Allows various object filtering options which can be used to specify      what databases or database objects to be included or excluded from      dump.   4. Allows the dump files to be compressed using LZ4 or ZLIB library.   5. Provides an option to watch progress of dump.
      WL#8596 Turn STRICT_MODE submodes ON by Default
      WL#7755: mysqlpump: Extend mysqldump functionalities   Mysqlpump is a new client utility similar to mysqldump, however mainly   focussed to improve the [1;31mperf[mormance of taking dumps. This new tool   would achieve the following:   1. Provides basic functionality of mysqldump.   2. Allows to take dumps in parallel using multiple threads and queues      which can be configured using command line options.   3. Allows various object filtering options which can be used to specify      what databases or database objects to be included or excluded from      dump.   4. Allows the dump files to be compressed using LZ4 or ZLIB library.   5. Provides an option to watch progress of dump.
      Bug#21238614 ST_BUFFER(LINESTRING) MAY PRODUCE AN INVALID POLYGON
      WL #2284: Increase the length of a user name
      WL#7340 IO aware cost estimate function for data access
      BUG#21283343 FAIL WITH INNODB_UNDO_TABLESPACES SET TO 2 AFTER WL#7943
      RQG json redefine: Adaptations for utf8mb4 charset and utf8mb4_bin  collation, as it is the only one fully compatible with the JSON  implementation.
      Bug#18487951 - QUERY_CACHE_MIN_RES_UNIT SET TO ZERO, CRASHES IN QUERY_CACHE::FIND_BIN
      Post-push fixes to BUG#21095969: test only.
      Bug#21362781 ADD ST_NUMINTERIORRING ALIAS FOR ST_NUMINTERIORRINGS
      WL#7755: mysqlpump: Extend mysqldump functionalities
      BUG#21305976
      BUG#21305976: REPORT RELAY_LOG_FILE AND RELAY_LOG_POS ON RELAY-LOG-RECOVERY.
      Bug #16555723: REPLICATION CONNECTION SHOULD SET PROGRAM_NAME ATTRIBUTE
      Bug#21355202: PROVIDE ACCESS TO SERVER REPORT_HOST AND REPORT_PORT VARS TO GROUP REPLICATION
      Followup:BUG#21245805 HA_INNOBASE::RECORDS_IN_RANGE() RETURNS CONSTANT FOR SPATIAL INDEXES
      WL#7909: Server side JSON functions
      WL#7755: mysqlpump: Extend mysqldump functionalities   Mysqlpump is a new client utility similar to mysqldump, however mainly   focussed to improve the [1;31mperf[mormance of taking dumps. This new tool   would achieve the following:   1. Provides basic functionality of mysqldump.   2. Allows to take dumps in parallel using multiple threads and queues      which can be configured using command line options.   3. Allows various object filtering options which can be used to specify      what databases or database objects to be included or excluded from      dump.   4. Allows the dump files to be compressed using LZ4 or ZLIB library.   5. Provides an option to watch progress of dump.
      WL#7909: Server side JSON functions
      Bug#21024340: fixed a platform dependency
      Bug #21024340: Resolved the congestion on the zeroth mutex in the array by making sure the right THD reference is used in as many places as possible. Modified some of the function to take and pass down the THD as appropriate, while still not adding the plugin to thd->lex->plugins. THD=0 was used mostly to denote the above. Manually verified that the audit log operations don't cause congestion anymore.
      Addendum to bug #21024340: fixed the unit tests
      Bug #21024340: 2nd attempt
      WL#7709 : Add server-side option to require secure transport
      Bug#21109896 POLYGON INTERSECTION POLYGON CAN'T PRODUCE LINESTRINGS AS RESULTS
      Bug #16555723: REPLICATION CONNECTION SHOULD SET PROGRAM_NAME ATTRIBUTE
      Bug 16555730 - FEDERATED SHOULD DEFINE CONNECTION ATTRIBUTES TO IDENTIFY ITSELF
      Bug #20238729: ILLEGALLY CRAFTED UTF8 SELECT PROVIDES NO                WARNINGS
      Bug#21109896 POLYGON INTERSECTION POLYGON CAN'T PRODUCE LINESTRINGS AS RESULTS
      Bug#21095969 related: adapting the fixes test to 5.7.
      Bug#21095969 RPL+LOCK_WAIT_TIMEOUT: BOOL TRANS_CHECK_STATE ASSERTS `THD->GET_TRANSACTION().
      Bug #20920851         ASSERTION `IS_STARTED()' IN HA_TRX_INFO::NEXT() AT TRANSACTION_INFO.H:138
      WL#7909: Server side JSON functions
      InnoDB General Tablespace Portability
      Bug#19929832 EVENTS_STATEMENTS_HISTORY SHOWS ERRORS=0 WHEN THERE ARE ERRORS
      BUG#21304682: VALGRIND ERRORS IN DEBUG PRINTOUTS FOR REPLICATION CODE
      Added mecab plugin
      BUG#21245805 HA_INNOBASE::RECORDS_IN_RANGE() RETURNS CONSTANT FOR SPATIAL INDEXES
      Bug#21341481 INCREASE LIBMYSQLCLIENT PATCH NUMBER FOR EACH SERVER RELEASE
      Bug#21238614 ST_BUFFER(LINESTRING) MAY PRODUCE AN INVALID POLYGON
      WL#6631: Detect transaction boundaries
      WL#7909: Server side JSON functions
      Bug#21192879 : FAILED SET PASSWORD STILL HAS CONSEQUENCES
      WL#7909: Server side JSON functions
      WL#7909: Server side JSON functions WL#8132: JSON datatype and binary storage format WL#8170: Expression analyzer for GC WL#8249: JSON comparator WL#8539: Ordering of scalar JSON values
      BUG#21111229 RESET SLAVE ALL BEHAVES DIFFERENT FOR DEFAULT AND              NON-DEFAULT CHANNELS BUG#21107331 RESET SLAVE ALL DOESN'T RESETS SLAVE_RETRIED_TRANSACTIONS
      Bug#18487951 - QUERY_CACHE_MIN_RES_UNIT SET TO ZERO, CRASHES IN QUERY_CACHE::FIND_BIN
      WL#8505: Transformed the query rewrite plugins to audit plugins
      WL#7909: Server side JSON functions WL#8132: JSON datatype and binary storage format WL#8170: Expression analyzer for GC WL#8249: JSON comparator WL#8539: Ordering of scalar JSON values
      BUG#21127308: REPLICATION THREAD STATUSES NOT SHOWN IN PERFORMANCE_SCHEMA
      Bug#21139522 PREPARED STATEMENT EXPLAIN DELETE .. WITH STRICT MODE VIOLATION              FLATLINES
      Doxygen cleanup.
      Build cleanup.
      Bug#21326013: PROVIDE ACCESS TO SERVER AUTO-INCREMENT VARIABLES TO GROUP REPLICATION
      BUG#21283343 FAIL WITH INNODB_UNDO_TABLESPACES SET TO 2 AFTER WL#7943
      BUG#21111229 RESET SLAVE ALL BEHAVES DIFFERENT FOR DEFAULT AND              NON-DEFAULT CHANNELS BUG#21107331 RESET SLAVE ALL DOESN'T RESETS SLAVE_RETRIED_TRANSACTIONS
      Bug#21238614 ST_BUFFER(LINESTRING) MAY PRODUCE AN INVALID POLYGON
      BUG#21348278: ENABLE SLAVE PARALLEL APPLIER RECOVERY GTID BASED
      BUG#21348278: ENABLE SLAVE PARALLEL APPLIER RECOVERY GTID BASED
      Bug #20581228: MYSQLD --HELP --VERBOSE TRIES TO LOCK FILES
      Post-push fix: Bug#20865683 IF AUTOCOMMIT=OFF AND GTID_NEXT='UUID:NO', GTID_MODE SWITCHING SHOULD BE BLOCKED
      Bug#21355630: MYSQL_CONFIG_EDITOR ASSUMES SIGNED CHAR
      Bug#20928289: DEFAULT CMAKE EXCLUDES UTF8_5624_1 CHARSET,               REQUIRED FOR MAIN.CTYPE_LDML
      Update docker package names
      Fixing bug208866059 post-push failure in rpl_wl6292.
      Bug#21324507 INNODB: ASSERT(DICT_TF_GET_REC_FORMAT(TABLE->FLAGS) != REC_FORMAT_COMPRESSED
      Bug#21286221: DEBUG SERVER CRASHES ON RESET SLAVE WITH               LOCKED VERSION TOKEN
      Doxygen cleanup
      Bug#20865683 IF AUTOCOMMIT=OFF AND GTID_NEXT='UUID:NO', GTID_MODE SWITCHING SHOULD BE BLOCKED

[33mcommit 3089aec6866cb1d3a49fa67e600272a55ccd28b7[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Fri Jul 3 18:15:40 2015 +0530

    WL#7755: mysqlpump: Extend mysqldump functionalities
      Mysqlpump is a new client utility similar to mysqldump, however mainly
      focussed to improve the [1;31mperf[mormance of taking dumps. This new tool
      would achieve the following:
      1. Provides basic functionality of mysqldump.
      2. Allows to take dumps in parallel using multiple threads and queues
         which can be configured using command line options.
      3. Allows various object filtering options which can be used to specify
         what databases or database objects to be included or excluded from
         dump.
      4. Allows the dump files to be compressed using LZ4 or ZLIB library.
      5. Provides an option to watch progress of dump.

[33mcommit 35e38980e7b5242706b5068f071f88f731978781[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Fri Jul 3 14:21:53 2015 +0530

    WL#7755: mysqlpump: Extend mysqldump functionalities
      Mysqlpump is a new client utility similar to mysqldump, however mainly
      focussed to improve the [1;31mperf[mormance of taking dumps. This new tool
      would achieve the following:
      1. Provides basic functionality of mysqldump.
      2. Allows to take dumps in parallel using multiple threads and queues
         which can be configured using command line options.
      3. Allows various object filtering options which can be used to specify
         what databases or database objects to be included or excluded from
         dump.
      4. Allows the dump files to be compressed using LZ4 or ZLIB library.
      5. Provides an option to watch progress of dump.

[33mcommit 885a6c9640ced2c9bb0145aa85bfbf64d4748b9b[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Jul 2 09:42:18 2015 +0200

    Build cleanup.
    
    Fixed inconsistent prototypes for storage/[1;31mperf[mschema/pfs.cc.

[33mcommit e86e02c72be3c44ffe7af5cee431804131cc6fc4[m
Merge: e2755c4ba68 08d0525c06e
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Jun 18 10:45:50 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug#21250947: ASAN: MEMORY LEAK IN MYSQLSLAP
      WL#6416 InnoDB: Remove the use of *.isl files
      Bug#21052754 ADD SHOW ENGINE INNODB MUTEX FUNCTIONALITY
      Bug#21198064 GEOMETRY CONSTRUCTION FUNCTIONS ALLOWS INVALID WKT
      Bug#21250562: ASAN: MEMORY LEAK IN MYSQLCHECK Bug#21253653: ASAN: MEMORY LEAK IN MYSQLSHOW
      Bug#19660891 HANDLE_FATAL_SIGNAL (SIG=11) IN QUEUE_INSERT
      BUG#20887920  ADD SUPPORT FOR UBUNTU 15.04 IN MYSQL 5.7
      BUG#20887920  ADD SUPPORT FOR UBUNTU 15.04 IN MYSQL 5.6
      Bug#21262883 - MYSQL-SYSTEMD-START SCRIPT ERROR WHEN USING OPTION DATADIR OR SIMILAR
      BUG#20582189 - INNODB.DOUBLEWRITE FAILS DUE TO DATABASE CORRUPTION
      Followup: BUG#19363615 INNODB.LOG_FILE FAILS SPORADICALLY ON PB2
      Bug#21250876: ASAN: MEMORY LEAK IN MYSQL_INSTALL_DB
      - Bug#21153684: AVOID FALSE CACHE LINE SHARING FOR MOST CRITICAL BLOCK OF THE   CODE (BUF_BLOCK_T)
      Merge of Martin's Doxyfile into Marc's
      Fixing [1;31mperf[mschema.sanity_check test case.
      Fixing [1;31mperf[mschema.sanity_check test case.
      Bug #20229614 : OR CONDITIONS ON MULTI-COLUMN INDEX MAY NOT                 USE ALL INDEX COLUMNS TO FILTER ROWS
      Bug#21242541 - RW-LOCKS SHOULD ONLY BE CREATED ON THE HEAP
      Fix build break in previous push
      WL#6799 - Add super_read_only option.
      Merging test case results for WL#6799.
      BUG#20451386 SQL THREAD CRASH: LOG-SLAVE-UPDATES OFF, RELAY LOG ENDS              WITH GTID_LOG_EVENT
      Bug#21172963 ASSERTION `PARAM.SORT_LENGTH != 0' FAILED IN SQL/FILESORT.CC:361
      Bug#21246964: ASAN: MEMORY LEAK IN PROCESS_ALL_TABLES() Bug#21247377: ASAN: MEMORY LEAK IN SHOW_VARIABLE_QUERY_EXTRACTOR / RUN_SQL_FIX_PRIVILEGE_TABLES() Bug#21253535: ASAN: MEMORY LEAK IN MYSQL_UPGRADE
      Add packaging scripts for docker builds
      Updated CMakeLists.txt to include rpm-docker directory
      Bug#21255860: ASAN: MEMORY LEAK IN QUEUE UNIT TEST
      Updated CMakeLists.txt to include rpm-docker directory
      Bug#21041451: ENABLE AND FIX ADDITONAL WARNINGS REPORTED BY CLANG
      Bug#21251627 ASSERT `ORDER == __NULL && !SELECT_DISTINCT' AT JOIN::REPLACE_INDEX_SUBQUERY
      BUG#19988193: ASSERTION `(*TABLES)->REGINFO.LOCK_TYPE >= TL_READ' FAILED IN LOCK_EXTERNAL BUG#21198646: ASSERTION FAILED: (*TABLES)->REGINFO.LOCK_TYPE >= TL_READ FILE LOCK.CC, LINE 356
      Add packaging scripts for docker builds
      Add packaging scripts for docker builds
      WL8397 - Increase table_open_cache_instances compiled default
      - Bug#21252519 INNODB: FAILING ASSERTION: INDEX != __NULL
      Bug#21192857: ASSERTION FAILED: KEYINFO_ARRAY.SIZE() == 0, FILE OPT_HINTS.CC:280
      Follow-up fix for Bug#21252241 - WL#7816 INTRODUCED LATCHING ORDER VIOLATION IN TRUNK, WHEN INNODB_SYNC_DEBUG=1
      Bug#21254964: FIX TYPO 'UNITIALIZED' TO 'UNINITIALIZED'
      Bug#21097485: *insert_table_ref && (*insert_table_ref)->is_insertable
      Bug #21140039 ASSERTION FAILED: !FIRST_QEP_TAB->TABLE()->NO_KEYREAD MATCH AGAINST.....
      Bug #21094069 FOREIGN KEYS WITH SPECIAL CHARS IN PARENT DB NAME: FALSE CONSTRAINT VIOLATIONTS *
      Rework the test case [1;31mperf[mschema.status_reprepare to be more robust
      Bug#21184265 ASSERT AT ALL || TRX_SYS_GET_N_RW_TRX() > 0

[33mcommit 8885b57de867e16aafe628b068959aca1bd670df[m
Author: Todd Farmer <todd.farmer@oracle.com>
Date:   Tue Jun 16 17:17:39 2015 -0600

    Fixing [1;31mperf[mschema.sanity_check test case.

[33mcommit 864219aa88cf91e0aa74c0a800705fd3ca288651[m
Author: Anitha Gopi <anitha.gopi@oracle.com>
Date:   Tue Jun 16 03:24:51 2015 +0200

    BUG#21252802 TESTS INTRODUCED BY WL#7729 ARE UNSTABLE ON PB2
    
    Moved following unstable tests to experimental state:
    audit_log.audit_log_protocols
    [1;31mperf[m_schema.connection_type_win
    [1;31mperf[m_schema.connection_type_notwin

[33mcommit de9a769735e116451124d5d3a6fd220ecb0493fb[m
Merge: 7ec8eeb97ba 44885dff05e
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Jun 15 13:16:17 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      BUG#20136704 --SLAVE-PRESERVE-COMMIT-ORDER CAUSES SLAVE TO DEADLOCK AND              BREAK FOR SOME QUERIE
      Bug#21140088 MATCH AGAINST: ASSERTION FAILED: !TABLE || (!TABLE->READ_SET || BITMAP_IS_SET
      Fixed index_merge_myisam test.
      BUG#15866285 FAILING ASSERTION: DICT_TF2_FLAG_IS_SET (INDEX->TABLE, DICT_TF2_TEMPORARY)
      Bug#21178589: REMOVE UNUSED FUNCTIONS AND CONVERT               GLOBAL SYMBOLS TO STATIC (LIBSQL)
      Bug#21052754 ADD SHOW ENGINE INNODB MUTEX FUNCTIONALITY
      Bug#21214354: REMOVE USELESS CASTS
      Bug#21178589: REMOVE UNUSED FUNCTIONS AND CONVERT                GLOBAL SYMBOLS TO STATIC (LIBSQL)
      Bug #19929435 DROP DATABASE HANGS WITH MALFORMED TABLE
      Code Cleanup found while working on Tablespace Portability
      Bug#21052754 ADD SHOW ENGINE INNODB MUTEX FUNCTIONALITY
      Bug#21246941 REMOVE BUILD/BUILD_MCCGE.SH FROM THE 5.7 SOURCE TREE
      Bug#21245718: KEY_MEMORY_KEY_CACHE IS DEFINED TWICE
      WL#7816 - InnoDB: Persist the "corrupted" flag in the data dictionary
      Bug#21139707 ASSERTION FAILED: !(DECIMAL_IS_ZERO(FROM1) && FROM1->SIGN)
      Followup:BUG#20856397 MYSQLD --HELP --VERBOSE TAKES 50 SECONDS ON UNLOADED SYSTEM
      Bug#21052754 ADD SHOW ENGINE INNODB MUTEX FUNCTIONALITY
      Bug#19900900 ASSERTION `!CHECK_DATETIME_RANGE(LTIME)' FAILED TIME_TO_LONGLONG_DATETIME_PACKED
      Bug #20953265 INNODB: FAILING ASSERTION: RESULT != FTS_INVALID
      Bug#21052754 ADD SHOW ENGINE INNODB MUTEX FUNCTIONALITY
      Bug#21052754 ADD SHOW ENGINE INNODB MUTEX FUNCTIONALITY
      Bug#21052754 ADD SHOW ENGINE INNODB MUTEX FUNCTIONALITY
      Bug#20712720 CRASH IN _ZN22REPLICATION_THREAD_API18INITIALIZE_CHANNEL
      Bug#21052754 ADD SHOW ENGINE INNODB MUTEX FUNCTIONALITY
      Bug#21038929 SINGLE-TABLE SCALAR SUBQUERY WITH LIMIT AND ORDER BY GIVES WRONG RESULTS
      Bug#21038929 SINGLE-TABLE SCALAR SUBQUERY WITH LIMIT AND ORDER BY GIVES WRONG RESULTS
      Update result file missed in previous commit for Bug#21140067 fix.
      Follow-up:BUG#20856397 MYSQLD --HELP --VERBOSE TAKES 50 SECONDS ON UNLOADED SYSTEM
      Bug#21198396 REINTRODUCE ADAPTIVE HASH INDEX FIELD PREFIXES TO SPEED UP SEQUENTIAL INSERTS
      Test cleanup
      Bug#21052754 ADD SHOW ENGINE INNODB MUTEX FUNCTIONALITY
      BUG#20856397 MYSQLD --HELP --VERBOSE TAKES 50 SECONDS ON UNLOADED SYSTEM
      Bug#21052754 ADD SHOW ENGINE INNODB MUTEX FUNCTIONALITY
      Bug#21052754 ADD SHOW ENGINE INNODB MUTEX FUNCTIONALITY
      Bug#19055268 ASSERT `!TABLE || (!TABLE->READ_SET || BITMAP_IS_SET(TABLE->READ_SET,...) FAILED
      Bug#19055268 ASSERT `!TABLE || (!TABLE->READ_SET || BITMAP_IS_SET(TABLE->READ_SET,...) FAILED
      Bug#21140067 EXPLAIN .. MATCH AGAINST: ASSERTION FAILED: TO <= END
      Bug 21052754 ADD SHOW ENGINE INNODB MUTEX FUNCTIONALITY
      Bug 21052754 ADD SHOW ENGINE INNODB MUTEX FUNCTIONALITY
      BUG#19363615 INNODB.LOG_FILE FAILS SPORADICALLY ON PB2
      NDB cluster build break
      Build cleanup
      Bug#17243619 NEGATIVE VALUES FOR LOW COLUMNS  IN MEMORY_SUMMARY_GLOBAL_BY_EVENT_NAME
      Consolidate the RQG concurrency tests
      Doxygen configuration file
      Fix broken build with [1;31mperf[mormance schema disabled.
      WL#7729 MTR Tests fixed
      Bug#21130285 MISSING MLOG_FILE_NAME RECORD FOR UNDO OR USER TABLESPACE
      Bug #21229433         NON PFS BUILDS COMPILATION ISSUE.
      Bug#20929568 PREPARED STATEMENTS NOT NORMALIZED

[33mcommit c6734b42cf15141405825b56367f4bf6850679ba[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Sat Jun 13 15:46:05 2015 +0200

    Bug#21178589: REMOVE UNUSED FUNCTIONS AND CONVERT
                  GLOBAL SYMBOLS TO STATIC (LIBSQL)
    
    Post-push fix: Fix compiler warning about unused functions
    when building without [1;31mperf[mormance schema.

[33mcommit 1715a216adea2fca6891cd63bb31ad3dfafc6cc2[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Wed Jun 10 15:46:08 2015 +0200

    Fix broken build with [1;31mperf[mormance schema disabled.

[33mcommit 448bbcb5f2b77bf647ab9227986348cb8d8b746e[m
Merge: 289d4db5ef3 44cb4493e7c
Author: Christopher Powers <chris.powers@oracle.com>
Date:   Sat Jun 6 08:10:55 2015 +0200

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            sql/sql_class.cc
            sql/sql_class.h
            storage/[1;31mperf[mschema/pfs_instr.cc
            storage/[1;31mperf[mschema/unittest/stub_global_status_var.h

[33mcommit 289d4db5ef31b709da498feba9b7960582d04ebe[m
Merge: 1bdccb22d66 128450091ea
Author: Christopher Powers <chris.powers@oracle.com>
Date:   Sat Jun 6 06:29:59 2015 +0200

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            mysql-test/suite/[1;31mperf[mschema/r/start_server_off.result

[33mcommit de3af2b19385cec46f4e10e7a92916d43a6a548c[m
Merge: 581b3c80d93 a52c584c207
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jun 2 11:32:05 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug #18591145: SOME MONOTONICALLY INCREASING STATUS VARIABLES DICREASES UNEXPECTEDLY
      BUG#20887920 ADD SUPPORT FOR DEBIAN 8 AND UBUNTU 15.04 IN MYSQL 5.6
      wl#7943 - Fix merge error where non-debug builds break.
      wl#7943 - InnoDB: Implement Information_Schema.Files
      Bug #18591145: SOME MONOTONICALLY INCREASING STATUS VARIABLES DICREASES UNEXPECTEDLY
      Bug #18194196: OPTIMIZER EXECUTES STATEMENT INPERFORMANT
      Fixed build warnings
      Bug#20834483 - ASSERTION: TABLE->SPACE == FIL_SPACE_GET_ID_BY_NAME( TABLE->TABLESPACE())
      Test blocked from running on windows
      Bug #20755059 PROVIDE SOME PROGRESS STATUS TO KNOW HOW MANY TESTS ARE COMPLETED OR REMAINING
      Bug #20602572: EXPIRED-PASSWORD MESSAGE IS OUT OF DATE.
      Followup:BUG#20637494 ASSERTION IN RE-CREATING CORRUPTED INNODB FULLTEXT INDEX
      Bug #20535517 INCORRECT HANDLING OF UNSIGNED NOT NULL INTEGERS IN               INNODB_MEMCACHED
      Bug #21025587: SSL EVEN ENABLED FOR UNIX SOCKETS FOR NO GOOD REASON
      Bug#21156155 UNION GEOMETRY TYPE: UNITIALIZED VALUE IN ITEM_TYPE_HOLDER::JOIN_TYPES
      Raise version number after tagging 5.1.75
      bug#20985298: [1;31mperf[mormance fix ahi by splitting the single search system mutex  into n parts.
      Followup:BUG#20637494 ASSERTION IN RE-CREATING CORRUPTED INNODB FULLTEXT INDEX
      WL#7488 - Followup fix, destroy mutexes on shutdown.
      Bug#20949117: Remove obsolete code from UNION processing
      Fixed link issue with building without [1;31mperf[mormance schema
      Bug#20949117: Remove obsolete code from UNION processing
      Bug#21153716 ST_CONVEXHULL RETURNS WRONG RESULT
      BUG#20637494 ASSERTION IN RE-CREATING CORRUPTED INNODB FULLTEXT INDEX
      Remove an #include of a removed empty file.
      WL#7488: InnoDB startup refactoring
      Remove an #include of a removed empty file.
      Bug #20929339 : PREPARED STATEMENTS NOT RECORDED BY FIREWALL
      - bug#20985298: [1;31mperf[mormance fix ahi by splitting the single search system mutex   into n parts.
      Post-push fix: Deleting an empty file(uuid.cc) left after WL#7440
      Adjust tests after addition of system variable INNODB_ADAPTIVE_HASH_INDEX_PARTS
      Bug#17846865 HANDLER READING INDEX ON GEOMETRY COLUMN CRASH
      Test cleanup for 32bit / release
      - bug#20985298: [1;31mperf[mormance fix ahi by splitting the single search system mutex   into n parts.
      Final patch with test services plugind for 5.7
      Bugi#20593257 FIREWALL PLUGIN LEAK PINS UNDER SPECIAL CIRCUMSTANCES

[33mcommit 75d1452d2e8f0161f63e4c985acc7ccd72d34f8c[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Thu May 28 14:59:55 2015 +0200

    Bug#20949117: Remove obsolete code from UNION processing
    
    After the last refactoring work in preparation and optimization,
    there are some unused code blocks in sql_union.cc.
    This bug fix eliminates those code blocks completely and [1;31mperf[morms
    some simple additional refactoring.
    
    - Added an interface st_select_lex_unit::is_simple() that wraps
      testing for !(is_union() || fake_select_lex)
    
    - Cleaned up global_parameters() a bit: Only ORDER BY/LIMIT/OFFSET
      should be accessed through it, otherwise use fake_select_lex.
    
    - Initialization of JOIN::do_send_rows was moved from optimization to
      execution, since it is used only in the latter.
    
    - st_select_lex_unit::prepare() has mostly cosmetic changes and improved
      comments. Call to set_current_select() eliminated for error case.
    
    - Deleted unused function Query_result::reset_offset_limit_cnt
    
    - st_select_lex_unit::optimize() had an unused code block started with
      if (sl == global_parameters() && is_union()).
      It was unused because global_parameters() always return the "fake" object
      for a UNION query. Besides, with the introduction of
      Query_result_union_direct, LIMIT/OFFSET handling is correct without
      adjusting offset_limit_cnt and select_limit_cnt.
    
    - An equivalent code block is removed from st_select_lex_unit::execute().
      Variable rows_at_start was found to be redundant.
      Calls to set_current_select() were removed in error case.
      offset_limit_cnt did not need to be assigned here, since it is done
      in set_limit().
      Call info(HA_STATUS_VARIABLE) was moved to a more logical place
      (used to get row count from temporary table used by UNION).
      add_rows was never assigned so it could be removed:
      sl->join->calc_found_rows is never true for a query block that is
      part of a UNION (either braces=true or m_select_limit=HA_POS_ERROR,
      see JOIN::optimize()), search for comment "Calculate found rows if".
      join->examined_rows is reset in JOIN::exec() so assignment is deleted.
    
    - Added more extensive tests for LIMIT and OFFSET to limit.test

[33mcommit c5ebfbb8fff41108e3fc85e935f6edfa159fa210[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed May 27 15:19:24 2015 +0200

    Bug#20914786 : MYSQL_UPGRADE FAILS WITH SHOW_COMPATIBILITY_56 = OFF
    
    This is a rework on the previous fix for mysl_upgrade.
    
    mysql_upgrade can -- not -- use [1;31mperf[mormance_schema tables
    to read the server version,
    or use SHOW VARIABLES that rely on the same tables,
    because these tables might not even be installed (by the upgrade script)
    yet.
    
    Use
      SELECT @@global.version
      SELECT @@global.datadir
    which is robust and also works for in place upgrades.

[33mcommit 504ab9a2356025eb35ae383bde84063005f8ee7b[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed May 27 15:19:24 2015 +0200

    Bug#20914786 : MYSQL_UPGRADE FAILS WITH SHOW_COMPATIBILITY_56 = OFF
    
    This is a rework on the previous fix for mysl_upgrade.
    
    mysql_upgrade can -- not -- use [1;31mperf[mormance_schema tables
    to read the server version,
    or use SHOW VARIABLES that rely on the same tables,
    because these tables might not even be installed (by the upgrade script)
    yet.
    
    Use
      SELECT @@global.version
      SELECT @@global.datadir
    which is robust and also works for in place upgrades.

[33mcommit 87dbde022c53d393f24d181ff00e52eb5e30922c[m
Merge: 112025a48f8 5eef003ae44
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri May 15 10:46:34 2015 +0300

    Merge remote-tracking branch 'local/mysql-trunk' into mysql-trunk-wl7170
    
    * local/mysql-trunk:
      Fix Bug#20783098 INNODB_CHECKSUM_ALGORITHM=CRC32 IS NOT BYTE ORDER AGNOSTIC
      Bug#20819189: ASSERT IF .FRM EXISTS BUT NO PARTITIONED INNODB TABLE.
      Bug#20561087 : REPLACE_USER_TABLE() DOES NOT CHECK ERROR WHEN READING FROM MYSQL.USER
      Bug#20819189: ASSERT IF .FRM EXISTS BUT NO PARTITIONED INNODB TABLE.
      BUG#19706455: RESET MASTER SHOULD RESET GTID STATE AND NOT ERROR OUT WHEN BINLOG IS OFF
      Test suite cleanup
      Some cosmetic changes which had been suggested in the review of wl#2489 but had to wait for wl#5275 and wl#7870 to be pushed.
      Test cleanup
      Bug#21074643: SERVER SETS OPEN_FILES_LIMIT UNCONDITIONALLY
      Fix for build failure after pushing a767e483e9496e8427d50f59dfa4842d4895e08a
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Bug#20896539 - A QUERY DIGEST SOMETIMES CONTAIN BACKTICKS AND SOMETIMES NOT DEPENDING ON CS
      Post push cleanup
      WL#8216: Deprecate and remove the sync_frm sysvar
      PB2 failures (valgrind and result mismatch) fixes.
      Follow up patch of bug20734998 for fixing Werror failure.
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20762557, Bug#20697533 : Disabled following tests since they fail very often on PB2: main.explain_for_connection_rqg_json main.explain_for_connection_rqg_trad rpl.rpl_[1;31mperf[mschema_applier_status
      Test commit
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      WL#8186: Deprecate conversion of pre MySQL 5.1 encoded database names
      Bug#20980885: ENSURE THAT START/STOP GROUP REPLICATION ALWAYS REQUIRE SUPER PRIVILEGE
      Partial backport from mysql-trunk to mysql.5.7 of Bug#21041451: ENABLE AND FIX ADDITONAL WARNINGS REPORTED BY CLANG in order to fix Clang 3.4 warnings in release build. No new warning options are added in the backport.
      Bug#21074358: SOME NEW 5.7 SOURCE FILES ARE D0S FORMATTED
      Bug #17818062       PERFORMANCE SCHEMA, ISSUE WITH UPPERCASE ROUTINES NAMES, PERFSCHEMA.MISC FAILS
      Bug #17818062         PERFORMANCE SCHEMA, ISSUE WITH UPPERCASE ROUTINES NAMES, PERFSCHEMA.MISC FAILS
      Bug#17832047: Crash in calculate_materialization_costs
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      Added openssl multithreading to client.
      Added openssl multithreading to client.
      Bug#20721087 UPGRADE TO BOOST 1.58.0
      Bug#20734998 FAILING ASSERTION: !CURSOR->INDEX->IS_COMMITTED()
      Bug #21047137 REMOVE -GCC FROM NAME OF SOLARIS PACKAGES/TARBALLS
      Bug#19316063: MAKE MTS WORK WITH RELAY_LOG_RECOVERY=1 WHEN GTID IS ENABLED
      Bug#21062842 : Made i_main.costmodel_plan change experimental.
      Bug# 19823076 : READ OF FREED MEMORY IN MY_MB_WC_SJIS WITH                 SOUNDS LIKE OPERATOR IN SUBQUERY
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      BUG#20743468: ASSERTION `OLD_VALUE >= 1' FAILED. | ABORT (SIG=6) IN GTID_STATE::END_ANONYMOUS_ BUG#20748502: ASSERTION `THD->VARIABLES.GTID_NEXT.TYPE== ANONYMOUS_GROUP' FAILED.
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      WL#7589: Updated the README file.
      Bug#21041451: ENABLE AND FIX ADDITONAL WARNINGS REPORTED BY CLANG
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20753620: DBUG: DICT_LOAD_FOREIGN, HA_INNOPART::CHECK, HA_INNOPART::CREATE_NEW_PARTITION
      Silence rpl.rpl_xa_survive_crash_debug in Valgrind
      Bug#21021894 : UNHELPFUL ERROR FOR MYSQL_SSL_RSA_SETUP WHEN DATADIR DOESN'T EXIST
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      Bug#21021754 - OPTION FOR MAX_STATEMENT_TIME IS MISSING
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      BUG #21063087 - MTR SHOULD PASS --INNODB_UNDO_TABLESPACES VARIABLE AT BOOTSTRAP
      BUG#20921940 DEBUG ONLY-CODE MAY HAVE SIDE EFFECTS IN HA_INNOBASE::
      - Bug#21046781: WHILE TRUNCATE UNDO-TABLESPACE FILE COULD BE CLOSED IN BACKGROUND
      BUG#21041449 ASSERT IN I_INNODB.INNODB_BUG16244691
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug #20445525 ADD A CONSISTENCY CHECK AGAINST DB_TRX_ID BEING IN THE FUTURE
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20835095 CRASH AT CREATE_REF_FOR_KEY IN SQL/SQL_SELECT.CC
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20980217 - TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE DOES NOT SHOW CORRECT INDEX NAMES
      Bug#20923066: SSL AND RSA KEY MATERIAL EXPIRATION SHOULD BE EXTENDED
      Corrected validate_password_strength and export_set functions
      Post push fix for BUG#18731252
      Bug#21046582 GEOMETRYCOLLECTION COLUMNS CAN'T STORE SUBTYPES
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      Fix for PB2 test failure.
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      - Bug#21053486: TRUNCATE_RECOVER FAILING IN MYSQL-TRUNK
      Bug#21021894 : UNHELPFUL ERROR FOR MYSQL_SSL_RSA_SETUP WHEN DATADIR DOESN'T EXIST
      Bug#20705648 - max_statement_time leaks memory on windows Bug#20705642 - max_statement_time: assertion failed: pending || thd_timer->thread_id
      Bug#20996273 ALTER USER REWRITE CAUSES DIFFERENCES ON SLAVE
      Fix to remove data dir reference
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Bug#20987568 - INCREASE STOP TIMEOUT OF COMMUNITY RPM SHUTDOWN SCRIPT /ETC/INIT.D/MYSQLD
      - Bug#21046968 : POSSIBLE RACE IN THE TRUNCATE CODE
      WL#7899: Add the tests that were accidentally omitted.
      WL#7899: InnoDB: Map compressed temporary tables to uncompressed
      Bug#20918881 CRASH WITH CENTROID - INVALID FREE
      Bug#20854952 SHOW GLOBAL VARIABLES RETURN WARNING ABOUT SQL_LOG_BIN BEING DEPRECATED
      Bug#21021670 - MISLEADING WARNING WHEN PER-QUERY STATEMENT TIME IS EXCEEDED
      Bug#20854952 SHOW GLOBAL VARIABLES RETURN WARNING ABOUT SQL_LOG_BIN BEING DEPRECATED
      Bug #20692556 : PREPARED STATEMENTS DO NOT TRACK STATUS LIKE STATISTICS
      - Bug#20023425: EMBEDDED SERVER FAILS TO BOOTSTRAP/START UP WITH   INNODB_UNDO_TABLESPACES=2
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Bug #20376498: MAX_ALLOWED_PACKET ERROR DESTROYS ORIGINAL               DATA
      BUG#20753463 HANDLE_FATAL_SIGNAL (SIG=11) IN __STRLEN_SSE2_PMINUB ON              CHANGE MASTER
      Bug#20507804 FAILING ASSERTION: TRX->READ_ONLY && TRX->AUTO_COMMIT && TRX->ISOLATION_LEVEL==1.
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      BUG#18731252 SLAVES WITH SAME SERVER_ID / SERVER_UUID COMPETE FOR              MASTER CONNECTION
      BUG#20768847 ASSERTION 0 IN HA_INNOBASE::COMMIT_INPLACE_ALTER_TABLE
      Post-push fix for BUG#20470724: SET GTID_PURGED SHOULD NOT ROTATE BINLOG
      Fixed Bug#20145024: WRONG RESULT FOR COUNT DISTINCT QUERY IN DERIVED TABLE
      Bug #20592961  'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381 - post fix
      BUG#20977779 CANNOT IMPORT TABLES CONTAINING PREFIX INDEXES
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Fix to avoid build break
      Bug#20814280 SEVERAL PERFORMANCE SCHEMA UNIT TESTS FAIL
      Bug#20814280 SEVERAL PERFORMANCE SCHEMA UNIT TESTS FAIL
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Test cleanup
      Test cleanup
      BUG#20470724: SET GTID_PURGED SHOULD NOT ROTATE BINLOG
      Bug#20748537 INNODB: FAILING ASSERTION: NODE->PCUR->REL_POS == BTR_PCUR_ON
      BUG#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bugi#20593257 FIREWALL PLUGIN LEAK PINS UNDER SPECIAL CIRCUMSTANCES
      BUG#20949314 PARTITION_HELPER::PH_RND_INIT(BOOL): ASSERTION `0' FAILED
      Fix firewall_qc broken test case when the FIREWALL_PLUGIN variable isn't set. This affected 32bit debian
      Fix firewall_qc broken test case when the FIREWALL_PLUGIN variable isn't set. This affected 32bit debian
      Bug#20963147 DECOUPLE DIGEST SIZE FROM SERVER AND PFS
      Bug #20926253 VALGRIND FAILURE IN INNODB.ALTER_MISSING_TABLESPACE
      - Bug#20023425: EMBEDDED SERVER FAILS TO BOOTSTRAP/START UP WITH   INNODB_UNDO_TABLESPACES=2
      Bug#20963147 DECOUPLE DIGEST SIZE FROM SERVER AND PFS
      Raise version number after cloning 5.6.25
      Raise version number after cloning 5.5.44
      BUG#21023683 FAILURE IN EMBEDDED I_INNODB.INNODB-ALTER
      Follow-up to BUG#20913616 - FIREWALL INTEGRATES BADLY WITH QUERY CACHE
      Bug #20914786 : MYSQL_UPGRADE FAILS WITH SHOW_COMPATIBILITY_56 = OFF
      Bug #20753378 ASSERTION `GTID_NEXT->TYPE != AUTOMATIC_GROUP || THD->OWNED_GTID.IS_EMPTY()'
      Bug #20592961  'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381
      Bug #20592961 'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381
      Bug #20753378 ASSERTION `GTID_NEXT->TYPE != AUTOMATIC_GROUP || THD->OWNED_GTID.IS_EMPTY()'
      Fix for missing test recording and test output differences on Windows.
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Bug#20913616 FIREWALL INTEGRATES BADLY WITH QUERY CACHE
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      BUG#19897405: CRASH WHILE ACCESSING VIEWS IN STORED ROUTINE               AND TABLES ARE FLUSHED
      Bug#20515155 Views: Assertion failed: is_view_or_derived() && is_merged()
      Bug #20987420 PB2 FAILURE OF TEST CASE INNODB_ZIP.INNODB_16K
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      BUG#20007583: THE EVENT_SCHEDULER USERNAME IS NOT RESERVERD.               ALLOWS PROCESSLIST VIEW.
      Windows installer in need of fixing to accommodate for WL#7307
      Bug#20768717: DEBUG BUILD FAILS WHEN USING GCC 5 DUE TO COMPILER WARNING
      post push minor test fix for bug:19887143
      BUG#20768847 ASSERTION 0 IN HA_INNOBASE::COMMIT_INPLACE_ALTER_TABLE
      - bug#20938115: innodb_undo_logs max limit should be downgraded from 126 to 94^
      Bug #20563332 : OPEN_FILES_LIMIT BINARY PUT INTO ./BIN DIRECTORY OF A BUILD?
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      Addendum to the fix for bug #20681412:
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug#20979020 - THE TRX IN DDL SHOULD ALWAYS NOT BE ROLLED BACK
      Bug#20709462: GENERATED COLUMNS NOT PRINTED CORRECTLY IN SHOW CREATE TABLE
      Bug#20583321: CRASH ON PS_THREAD_INFO / SYS USAGE
      Bug #18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Fixed failing test
      Bug#20583321: CRASH ON PS_THREAD_INFO / SYS USAGE
      Bug #19077239 mtr tests fixed.
      Bug#19077239 re-enabling disable tests mysql_secure_installation amd mysql_secure_installation_ssl
      Revert "WL#8462: test_services are plugins serving as examples for how plugin services can be tested with mtr."
      Bug #19887143 : THREAD/SQL/MAIN DOESN'T CHANGE STATE/INFO AFTER STARTUP
      WL#7895 - Add systemd support to server.
      Fixed Bug #20683741 UNZIP REQUIRED TO RUN MYSQL-TEST-RUN.PL BUT NOT CHECKED FOR BY CMAKE
      Bug#20865674-VALGRIND FAILURE IN INNODB.CREATE_TABLESPACE
      BUG#19821087 UPDATES TO INDEXED COLUMN MUCH SLOWER IN 5.7.5
      Fixed Bug #20949226: CAN ASSIGN NON-DEFAULT() VALUE TO GENERATED COLUMN
      rb8590 Fixes to sporadically failing on PB2 rpl_xa_survive_crash_debug
      WL#8462: test_services are plugins serving as examples for how plugin services can be tested with mtr.
      Bug #20681412 MYSQLD --INITIALIZE REFERS TO MYSQL_INSTALL_DB AND BOOTSTRAP
      Bug#20937654 CANNOT BUILD WITH "-DDISABLE_SHARED=ON" FOR CMAKE BECAUSE OF REWRITER PLUGIN
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      Fixed failing tests
      WL#6940 Server version token and check
      Bug #20181776 :- ACCESS CONTROL DOESN'T MATCH MOST SPECIFIC                  HOST WHEN IT CONTAINS WILDCARD
      Bug#20961660 RPL TESTS ARE FAILING WITH INNODB: UNDO TABLESPACES MUST BE READABLE!
      WL#4601: Remove fastmutex from the server sources
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      BUG#20955104: ADD UNIT TEST BINARIES AS OPTIONAL TARGETS WHEN MERGE_UNITTESTS=1
      Bug#19865673 DDL LIKE ADD INDEX IS VERY SLOW IN 5.7.5
      Bug #20294225 - INVALID MEMORY ACCESS
      Bug#20275612  MEMCACHED INNODB PLUGIN BREAKS MYSQL ENTERPRISE BACKUP
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug #18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Bug#19822257: WRONG VALUE PASSED TO --INIT-FILE OPTION CAUSES SERVER HANG
      BUG#20748570  BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      Bug#20515155 Views: Assertion failed: is_view_or_derived() && is_merged()
      Improved the way --print-defaults works.
      Bug#20615597 Assertion !thd->is_error() at st_select_lex::prepare()
      BUG#20960406  NO_PROTOCOL.INC SHOULD BE IN MYSQL-TEST/INCLUDE DIRECTORY
      WL#8165 Use new records per key interface in NDB
      Bug #20683237 BACKPORT 19817663 TO 5.1 and 5.5
      Bug #20275612 MEMCACHED INNODB PLUGIN BREAKS MYSQL ENTERPRISE BACKUP
      Bug#20895852 UNDERSIZED TMP_TABLE_SIZE - ASSERTION OR ERROR 2027 (HY000): MALFORMED PACKET
      Bug#20895852 UNDERSIZED TMP_TABLE_SIZE - ASSERTION OR ERROR 2027 (HY000): MALFORMED PACKET
      Revert "Bug#20683741 fixed."
      Revert "Updated file have_util_uz.inc under Bug Bug#20683741"
      Revert "Fixed Bug#20683741"
      WL#6940 Server version token and check
      Bug #20052580 MISSING MUTEX/LOCK IN ACL_AUTHENTICATION()
      Bug#20318154 : NEGATIVE ARRAY INDEX WRITE V2
      Bug#20952953 RPL.RPL_SLAVE_SKIP FAILS IN VALGRIND
      Bug#20952953 RPL.RPL_SLAVE_SKIP FAILS IN VALGRIND
      Fixed Bug#20683741
      Bug#20937173 CLEANUP GIS_DEBUG USELESS CODE
      WL#6940 Server version token and check
      Bug#20922238: REDUCE HEADER FILE DEPENDENCIES IN MY_SYS.H AND M_STRING.H
      BUG#20889900: UNITTESTS SHOULD START THE SERVER WITH APPROPRIATE OPTIONS
      Bug#20810627 ASSERTION: REC_PAGE_NO > 2 IN IBUF_GET_MERGE_PAGE_NOS_FUNC
      Bug#20748570 BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      WL#8017 Infrastructure for Optimizer Hints
      Fixing the query tipping points
      Modified the test to run only on 64 bit machine
      Revert accidental changes to collections/default.push
      Bug#20927239: MY_TIMER-T UNIT TEST DOES NOT WORK WITH MERGE_UNITTESTS=0
      Bug#20922238: REDUCE HEADER FILE DEPENDENCIES IN MY_SYS.H AND M_STRING.H
      Post push fix for BUG#20431860
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Bug#20748570 BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      Bug#20902791 MYSQLDUMP DUMPS SYS_SCHEMA
      Bug#20782142 PAM tests Fixed
      Updated file have_util_uz.inc under Bug Bug#20683741
      BUG#17259750 - STACK CORRUPTION IN VIO_IO_WAIT ON MAC OS X
      BUG# 20798617 - MYSQL CALLS  EXIT(MYSQLD_ABORT_EXIT) WITHOUT                 SHUTTING DOWN INNODB.
      BUG#20597821 INVALID READ OF BLOB MEMORY FREED IN ::CLEAR_BLOB_HEAP_PART
      Bug#20911624 THE SERVER CRASH WHEN TEST ST_INTERSECTS WITH ST_BUFFER
      Bug #20904893         INNODB: FIX RECENT WINDOWS 32 AND 63 BIT COMPILER WARNINGS
      Bug#20921370: NEW CLANG 3.6 WARNINGS - MUST ENABLE -WNO-UNUSED-LOCAL-TYPEDEF
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Clean up mysql-test/collections
      Enable run of default suites on daily valgrind
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Bug#20903701 FIX VALGRIND WARNINGS IN UNIT TESTS
      WL#8161: Locking service for read/write named locks
      Bug#20789078 innodb: assertion: index->id == btr_page_get_index_id(page)
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug#18486509 ASSERTION FAILED: TABLE->KEY_READ == 0 IN CLOSE_THREAD_TABLE
      WL#8161: Locking service for read/write named locks
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Fix Bug#20618309 ASSERT SLOT1->PAGE_LEVEL == SLOT2->PAGE_LEVEL, BTR_ESTIMATE_N_ROWS_IN_RANGE()
      Bug #20476395 DICT_LOAD_FOREIGNS() FAILED IN COMMIT_INPLACE_ALTER_TABLE
      Bug#20573701 DROP DATABASE ASSERT ON DEBUG WHEN OTHER FILES PRESENT IN DB FOLDER.
      Bug#20573701 DROP DATABASE ASSERT ON DEBUG WHEN OTHER FILES PRESENT IN DB FOLDER.
      Bug#20902600: REDUCE HEADER FILE DEPENDENCIES IN SP* AND EVENT* FILES
      Bug #20883256         INNODB: WARNINGS: NONNULL PARAMETER WILL EVALUATE TO 'TRUE' ON FIRST ENCOUNTER
      Bug#20888417: REMOVE FUNCTION DECLARATIONS WITHOUT DEFINITIONS
      Bug#20814396 PB2 IS SECRET ABOUT WHAT UNIT TESTS IT RUN
      WL#8161: Locking service for read/write named locks
      BUG #20414588 - REMOVE HARD-CODED AIO DISABLE FROM MTR
      Bug#20882432 INCORRECT MERGE_THRESHOLD LENGTH IN SYS_INDEXES AFTER UPGRADE, TRUNCATE, RESTART
      Clarify comment in my_global.h about where and why this header should be included.
      Dummy commit to keep the push hook happy.
      Bug#20856729: QUERY REWRITE: WRONG IFDEF SYMBOL IN SERVICE_PARSER.H
      Bug#20364862 : MYSQLADMIN PASSWORD AFFECTS EXTERNAL AUTH ACCOUNTS
      Bug#20364862 : MYSQLADMIN PASSWORD AFFECTS EXTERNAL AUTH ACCOUNTS
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Bug #19953365 MY_PRINT_DEFAULTS DOES NOT MASK PASSWORDS
      Bug#20752436: INNODB: FAILING ASSERTION: 0 IN FILE HANDLER0ALTER.CC LINE 6647
      BUG#17650326 MYSQLBINLOG PRINTS INVALID SQL FROM RELAY LOGS WHEN GTID IS ENABLED
      Bug#20350989: MYSQLBINLOG CAN'T DECODE EVENTS > ~1.6GB
      Bug#20609063 - STDOUT AND STDERR REDIRECTION ISSUES
      Bug#20752436: INNODB: FAILING ASSERTION: 0 IN FILE HANDLER0ALTER.CC LINE 6647
      Bug#20886222 MOVE THE DECLARATION OF FIL_NODE_T TO A HEADER FILE,              AND CLEAN UP COMMENTS Move the definition of the data structure fil_node_t from fil0fil.cc to fil0fil.h so that diagnostics code outside that module can access information about the files belonging to a tablespace. Also do other cleanup and formatting changes.
      Bug#20888417: REMOVE FUNCTION DECLARATIONS WITHOUT DEFINITIONS
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Test cleanup
      Convert a func comments to new the InnoDB style.
      Non-functional style fixups
      Bug#20872436 MAKE DIST BY MISTAKE COPIES FILES WITH VARIABLE EXPANSION
      Bug#20882345: MOVE CODE OUT OF HANDLER.H
      Post-merge fix for WL#7806: Remove bogus files.
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug#20615023 SIGNAL 11 IN ITEM_FIELD::RESULT_TYPE DURING 1ST EXECUTION OF PREPARED STMT
      Bug#20872436 MAKE DIST BY MISTAKE COPIES FILES WITH VARIABLE EXPANSION
      BUG 20459905 - DEADLOCK OF THREADS DETECTED! 5.7.5, 1 THREAD SQL TESTCASE, SPORADIC, IN IB_LOGF
      Bug#20863042 Stop filling mtr logs with InnoDB page dumps
      Remove a test from the experimental collection.
      Bug#20865407: DBUG_ASSERT(1) MAKES NO SENSE
      BUG#20857756: BUILD NT_SERVC.CC ONCE FOR ALL UNITTESTS ON WIN32
      Clean up the post-commit fix for Bug#20872655 debug instrumentation.
      Bug#20874411 INNODB SHUTDOWN HANGS IF INNODB_FORCE_RECOVERY>=3 SKIPPED ANY ROLLBACK
      Followup fix for BUG#20518099
      Post-commit fix or work-around for Bug#20872655 debug instrumentation.
      Post-merge fix for Bug#20872655 XA ROLLBACK IS NOT CRASH-SAFE
      Bug#20518099 - CLEANUP UNIV_INNOCHECKSUM in innodb code base
      Bug#19363615 : innodb.log_file fails very frequently on windows and solaris. Moved test from experimental to disabled state
      Raised version after tagging 5.1.74 (some commits skipped)
      Bug#20872655 XA ROLLBACK IS NOT CRASH-SAFE
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Bug#20788811 MAX_STATEMENT_TIME: ASSERTION `EXPLAIN_OTHER || UNIT->IS_OPTIMIZED()' FAILED.
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Test cleanup
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES            OF INNODB_CHECKSUM_ALGORITHM
      Bug#20104307 GTID_EXECUTED TABLE COMPRESSION THREAD MAY NOT WAKE UP
      sys_vars.innodb_compress_debug_basic requires P_S to run
      Bug#20859285: REDUCE HEADER FILE DEPENDENCIES OF SQL_CLASS.H AND TABLE.H
      Add daily and weekly collections of tests that shun --parallel.
      Bug#20578834 - INNODB READ ONLY MODE AND NON EXISTENT TMP DIR CRASHES SERVER
      Bug #20809045    BUFFER OVERFLOW IN MYSQL
      Silence rpl_xa_survive_crash_debug in Valgrind.
      Bug# 19573096: LOADING CORRUPTED GEOMETRY DATA INTO A                MYISAM TABLE CAUSES THE SERVER TO CRASH
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES                    OF INNODB_CHECKSUM_ALGORITHM
      Bug#20857979 REMOVE DEPENDENCY ON HANDLER.H FROM PFS_ENGINE_TABLE.H
      Bug#20768820 MAIN.BIGINT TEST FAILS WHEN BUILT WITH GCC 5 IN RELEASE BUILD
      Bug#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bug#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bug#20855853 MDL SUBSYSTEM ENCAPSULATION BROKEN
      Bug#20816223 test fix.
      Remove MCP_WIX
      Remove MCP_WIX
      WL#7806: Add a test case from Viswanatham Gudipati with some cleanup by me.
      Test cleanup
      WL#7806: Relax a test that started to fail due to WL#6205.
      WL#7795 PERFORMANCE SCHEMA, HISTORY PER THREAD
      WL#7795 PERFORMANCE SCHEMA, HISTORY PER THREAD
      Clean up a test case. Use slow shutdown in order to avoid generating redo log after restart, for processing old undo logs or change buffer records.
      WL#7806: Re-enable a test and work around a problem in WL#6965.
      WL#7806: Add a temporary workaround until WL#7691.
      WL#7806: Temporarily remove the fil_sys_lookup[] for user tablespaces in order to ensure that we are not masking Bug#18645050.
      WL#7806: Add a flat fil_sys_lookup[] array so that fil_spaces_lookup() can avoid acquiring fil_system->mutex when looking up the system tablespace or the undo tablespaces. This is addressing a [1;31mperf[mormance regression.
      WL#7806: Correct some comments.
      Test that no redo log gets generated unexpectedly.
      Rename some tests to comply with new policy:
      Try to get a test to work on Windows.

[33mcommit 9e64c88ad88d5a9a5801762713dee980c7742e1a[m
Author: Anitha Gopi <anitha.gopi@oracle.com>
Date:   Wed May 13 03:48:52 2015 +0200

    Bug#20762557, Bug#20697533 : Disabled following tests since they fail very often on PB2:
    main.explain_for_connection_rqg_json
    main.explain_for_connection_rqg_trad
    rpl.rpl_[1;31mperf[mschema_applier_status

[33mcommit d33de3bd5c38a25d925927c86e851d0573633999[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Tue May 12 14:44:55 2015 +0100

    WL#8186: Deprecate conversion of pre MySQL 5.1 encoded database names
    
    This is the 5.8 version of the patch.
    
    Remove special handling of #mysql50# prefix.
    Remove UPGRADE DATA DICTIONARY syntax for ALTER DATABASE
    Remove --fix-table-names and --fix-db-names options from mysqlcheck
    
    Note: innodb.alter_crash, i_innodb.innodb_bug15878013 and
    i_main.partition_innodb_crash have been disabled as they relied
    on the #mysql50# prefix to clean up after ALTER TABLE crash recovery.
    The proper fix for this problem will be
    WL#7016: InnoDB: Crash-safe DDL with the global data dictionary
    
    (cherry picked from commit 5e49e083d6eb555716b49947064a9f277030a6aa)
    
    Conflicts:
            client/check/mysqlcheck.cc
            mysql-test/r/mysqlcheck.result
            mysql-test/r/mysqld--help-notwin.result
            mysql-test/r/mysqld--help-win.result
            mysql-test/suite/innodb/r/temporary_table.result
            mysql-test/suite/[1;31mperf[mschema/r/information_schema.result
            mysql-test/suite/[1;31mperf[mschema/r/max_program_zero.result
            mysql-test/suite/[1;31mperf[mschema/r/ortho_iter.result
            mysql-test/suite/[1;31mperf[mschema/r/privilege_table_io.result
            mysql-test/suite/[1;31mperf[mschema/r/sizing_default.result
            mysql-test/suite/[1;31mperf[mschema/r/sizing_high.result
            mysql-test/suite/[1;31mperf[mschema/r/sizing_low.result
            mysql-test/suite/[1;31mperf[mschema/r/sizing_med.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_disable_idle.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_disable_stages.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_disable_statements.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_disable_transactions.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_disable_waits.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_innodb.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_low_index.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_low_table_lock.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_account.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_cond_class.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_cond_inst.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_file_class.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_file_inst.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_host.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_index.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_mdl.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_memory_class.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_mutex_class.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_mutex_inst.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_prepared_stmts_instances.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_rwlock_class.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_rwlock_inst.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_setup_actors.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_setup_objects.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_socket_class.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_socket_inst.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_stage_class.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_stages_history.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_stages_history_long.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_statements_history.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_statements_history_long.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_table_hdl.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_table_inst.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_table_lock.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_thread_class.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_thread_inst.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_transactions_history.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_transactions_history_long.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_user.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_waits_history.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_no_waits_history_long.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_on.result
            mysql-test/suite/[1;31mperf[mschema/r/statement_program_lost_inst.result
            mysql-test/suite/[1;31mperf[mschema/r/table_aggregate_global_2u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_aggregate_global_2u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_aggregate_global_4u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_aggregate_global_4u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_aggregate_hist_2u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_aggregate_hist_2u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_aggregate_hist_4u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_aggregate_hist_4u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_aggregate_off.result
            mysql-test/suite/[1;31mperf[mschema/r/table_aggregate_thread_2u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_aggregate_thread_2u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_aggregate_thread_4u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_aggregate_thread_4u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_io_aggregate_global_2u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_io_aggregate_global_2u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_io_aggregate_global_4u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_io_aggregate_global_4u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_io_aggregate_hist_2u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_io_aggregate_hist_2u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_io_aggregate_hist_4u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_io_aggregate_hist_4u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_io_aggregate_thread_2u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_io_aggregate_thread_2u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_io_aggregate_thread_4u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_io_aggregate_thread_4u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_lock_aggregate_global_2u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_lock_aggregate_global_2u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_lock_aggregate_global_4u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_lock_aggregate_global_4u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_lock_aggregate_hist_2u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_lock_aggregate_hist_2u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_lock_aggregate_hist_4u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_lock_aggregate_hist_4u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_lock_aggregate_thread_2u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_lock_aggregate_thread_2u_3t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_lock_aggregate_thread_4u_2t.result
            mysql-test/suite/[1;31mperf[mschema/r/table_lock_aggregate_thread_4u_3t.result
            mysql-test/t/mysqlcheck.test
            mysql-test/t/upgrade.test
            sql/dd/mtr_readme.txt
            sql/mysqld.cc
            sql/sql_db.cc
            sql/sql_parse.cc
            sql/sql_rename.cc
            sql/sql_table.h
            sql/sql_yacc.yy
            sql/table_trigger_dispatcher.h
            sql/trigger.cc
            sql/trigger_loader.h

[33mcommit 5dc3e0e59a592ef4ff48c7c9b96236574b9c334b[m
Merge: bd324faf2c2 71504da0f99
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue May 5 08:58:36 2015 +0200

    Merge branch 'mysql-5.6' into mysql-5.7
    
    Conflicts:
            mysql-test/r/mysqld--help-notwin.result
            mysql-test/r/mysqld--help-win.result
            mysql-test/suite/[1;31mperf[mschema/r/sizing_default.result
            mysql-test/suite/[1;31mperf[mschema/r/sizing_high.result
            mysql-test/suite/[1;31mperf[mschema/r/sizing_low.result
            mysql-test/suite/[1;31mperf[mschema/r/sizing_med.result
            mysql-test/suite/[1;31mperf[mschema/r/sizing_off.result
            sql/mysqld.cc
            storage/[1;31mperf[mschema/pfs_server.h

[33mcommit 0d6bcef6fda2c529bad62d2c8253a22e47aff55d[m
Merge: ecee5bf88cc 74731704030
Author: Marc Alff <marc.alff@oracle.com>
Date:   Mon Apr 27 14:14:18 2015 +0200

    Merge branch 'mysql-5.7' into mysql-5.7-wl7729
    
    Conflicts:
            mysql-test/suite/[1;31mperf[mschema/r/misc.result
            mysql-test/suite/[1;31mperf[mschema/r/schema.result
            mysql-test/suite/[1;31mperf[mschema/r/start_server_nothing.result
            mysql-test/suite/[1;31mperf[mschema/r/table_schema.result
            scripts/mysql_system_tables.sql
            storage/[1;31mperf[mschema/table_threads.cc

[33mcommit 1b2b3b67ad406444758cba1bb22bae4ec80c681d[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Apr 9 13:56:43 2015 +0200

    Bug#20857979 REMOVE DEPENDENCY ON HANDLER.H FROM PFS_ENGINE_TABLE.H
    
    Reduce dependencies/coupling between PFS and the server:
    
    pfs_engine_table.h includes handler.h in order to get an enum type.
    That enum type isn't needed if we remove an 'extern' declaration,
    and move the function pfs_show_status to the single file where it
    is in use: ha_[1;31mperf[mschema.cc

[33mcommit ca6ecd8229c53b0a139304bf6641cef6e529e61a[m
Merge: b840f9e9e35 2e91bec76f5
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Apr 8 12:35:31 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug #20590548 UNABLE TO LOGIN WITH USER WHOSE PWD CHANGED FROM 5.6.23 MYSQLADMIN IN 5.7.6
      Bug#20726413 : MYSQL_SSL_RSA_SETUP DOES NOT HAVE USER OPTION
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES                    OF INNODB_CHECKSUM_ALGORITHM
      WL#8244 Hints for subquery strategies. Part#2: Add support for SEMIJOIN/_SEMIJOIN and SUBQUERY hints
      WL#8244 Hints for subquery strategies. Part#1: Add optimizer_switch for DuplicateWeedout strategy.
      WL#7696 follow up fix, check return values.
      Fixed bug#20745142: GENERATED COLUMNS: ASSERTION FAILED: THD->CHANGE_LIST.IS_EMPTY()
      Fixed bug#20797941: WL8149:ASSERTION `!TABLE || (!TABLE->READ_SET ||                     BITMAP_IS_SET(TABLE->READ_SET
      BUG#20593808 - CRASH WITH PARTITIONED TABLES + MULTITABLE DELETE
      WL#7696 follow up fix.
      Bug#20788853 MUTEX ISSUE IN SQL/SQL_SHOW.CC RESULTING IN SIG6. SOURCE LIKELY FILL_VARIABLES
      WL#7696 followup - remove unused file
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, rerecord the test
      WL#7696 follow up fix, add INNODB_COMPRESS_DEBUG to the test.
      Bug#20840377 UNITILAISED BYTES REPORTED AT MY_WRITE.C:63
      Fixed failing tests after commit 335a53004313ab5a971cf17dea36f1dc4490db9f MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20755430 COST CONSTANT CACHE MUTEX NOT INSTRUMENTED BY PERFORMANCE SCHEMA
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      WL#7696 follow up fix.
      WL#7696 follow up fix - add INNODB_COMPRESS_DEBUG to the list
      Addendum to bug #20810928: fixed the test to reflect that COM_SHUTDOWN can be a zero-length RPC
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20678411 BROKEN MAKEFILE DEPENDENCY: SQL_YACC.YY AND LEX_TOKEN.H
      Bug #17299181    CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      BUG#20093172 LOG_STATE DECLARED VOLATILE, MISSING MEMORY BARRIERS
      BUG#20042205 RPL_GTID CHECKABLE_RWLOCK DEBUG CODE DOESN'T NEED VOLATILE              LOCK_STATE
      BUG#20042109 MYSQL_BIN_LOG::M_PREP_XIDS DOESN'T NEED TO BE VOLATILE
      BUG#20754369: BACKPORT BUG#20007583 TO 5.1
      Bug #17299181  CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      Bug#20411374:CAN NOT EXECUTE CHANGE MASTER AFTER ERROR OCCURED IN MTS MODE
      Bug#20683741 fixed.
      Bug #20814051 CREATE USER BINLOG EVENTS INCLUDE NEW ACCOUNT KEYWORD
      BUG#20510811 - RQG_ALTER_ONLINE_PART RUN INTO ASSERTION: NODE->ENTRY
      Bug#20279241 - ALTER TABLE XXX CHARACTER SET UTF8, CONVERT TO CHARACTER SET LATIN1 SHOULD FAIL
      Adapt new sql/ha_ndbcluster.cc code to use the new ER_THD() macro
      Remove MCP_GLOBAL_SCHEMA_LOCK patch
      Bug #20810928: CANNOT SHUTDOWN MYSQL USING JDBC DRIVER
      Fixed Bug #20683741.
      Test cleanup
      Bump version to 7.5.0
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20811494 SHOW_COMPATIBILITY_56 = OFF INCOMPATIBLE WITH CONNECTORS
      Bug#20531812: MEMORY CONSUMED QUICKLY WHILE EXECUTING LOOP IN PROCEDURE
      Bug#20683959 LOAD DATA INFILE IGNORES A SPECIFIC ROW SILENTLY UNDER DB CHARSET IS UTF8
      Remove MCP_BUG16021021
      Remove MCP_WIX
      Bug#20313067 CHECK TABLE REPORTS WRONG COUNT FOR SPATIAL INDEX AND OTHER GIS PROBLEMS
      Bug#20124342 MYSQL 5.6 SLAVE OUT OF MEMORY ERROR ? Problem: I/O thread on Slave with master_info_repository=TABLE settings, is leaking memory that leads to Out of memory (OOM) after some time.
      Fix merge error in mysql_system_tables_fix.sql
      Remove MCP tags for BUG16226274
      BUG#20811125 INNODB FTS: FTS_PRINT_DOC_ID PRINTS TOO MANY DEBUG INFORMATION
      Bug#20762059 - innodb_thread_concurrency=1 and queries using intrinsic temp tables, causes hang
      Create an .inc file which does slow shutdown before restarting innodb in read-only mode.
      Bug#19811953 ENVELOPE() FUNCTION RETURNS INVALID POLYGON Bug#20196720 ENVELOPE(P) RETURNS NULL FOR A NON NULL POLYGON P
      Bug #20544581         ASSERTION: REC_PAGE_NO > (ULINT) 4 - (REC_SPACE_ID != 0)
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 - Fix a merge issue.
      WL#7696 - Fix a merge issue
      WL#7696 - Fix the column ordinatlity. Messed up in a previous merge.
      WL#7696 - Fix a compilation error
      move some compression tests elsewhere until using Win32::API module is approved. Improve error detection, if there is no module, the tests will succeed, not fail as before, but the testing power will be somewhat limited.
      Bumped rpm version for oel due to respin
      Bug#20756770 MYSQL SERVER DOESN'T COMPILE AGAINST OPENSSL 1.0.1M
      Patch for Bug#17162055: SSL.CMAKE SILENTLY CHOOSES BUNDLED YASSL INSTEAD OF ERRORING FOR OLD OPENSSL VER
      Bug#20755346 EXAMPLE SCRIPT IN FIREWALL MISSES WHERE CLAUSE
      Bug#20764521 REGRESSION: FIREWALL USE GENERAL_HOST TO RESOLVE HOST
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      Resurrect unintentionally remove disabled.def file
      Resurrect unintentionally remove disabled.def file
      Bug#20651661 NDBEVENTBUFFER LEAKS GCI_OP
      Remove three files which did not properly remain
      WL#7696 - Make LZ4 decompress safe during recovery
      Remove hack to allow large number of failing tests in mtr.pl
      WL#7696 - Reset the contents of the page to NUL.
      WL#7696 - Use the double write buffer pages for compressed pages.
      WL#7696 - Fix syntax error on Windows.
      WL#7696 - Fix debug assertion.
      mysql-test/include/innodb-compress-utils.inc:   add OSD support to get allocated file size for Windows
      add the result file missing in the previous commit
      Test update:   mysql-test/suite/innodb/t/table_compress.test:     fix one failing case for 32k   mysql-test/suite/innodb/r/table_compress_2.result: make use of new     include files   mysql-test/suite/innodb/t/table_compress_3.test: new test to cover     what was not covered yet, shared tablespaces in particular   mysql-test/include/innodb-compress-verify.inc: common sequence     for compression verification   mysql-test/include/innodb-compress-utils.inc: perl compression     related utilities.     Note: OSD Windows file allocated size is not implemented yet.     The test is still expected to pass on Windows because the allocated     size is forced to the expected value.
      Bug #20536590: BACKPORT BUG #12368204 AND BUG #16953758 TO MYSQL-5.6
      WL#7696 - Code clean up. Ignore table COMPRESSION setting if set to NONE.
      WL#7696 - Minor code cleanup
      WL#7696 - Fix the punch hole size calculation.
      Bug#20712432 AUTOTEST: TESTFK FAIL IN CLEARTABLE WITH 256 REFERENCED ROW EXISTS
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#17775772 POTENTIALLY UNINITIALIZED BUFFER IN NDBOUT::PRINT* PRINTOUT   - print nothing or just empty newline instead of uninitialized buffer   - catch error with an assert in debug compile
      Bug#17775607 POTENTIALLY UNINITIALIZED BUFFER IN VNDBOUT_C PRINTOUT  - print empty newline instead of uninitialized buffer  - catch error with an assert in debug compile  - Mark vndbout_c as static and thus local to implementation Conflicts in copyright:        storage/ndb/include/util/NdbOut.hpp     storage/ndb/src/common/util/NdbOut.cpp
      Remove unused parameter ndbcluster_drop_event()
      Bug#20032381 KILLED_STATE SAVE IN NDBCLUSTER_BINLOG RETRY AT SHUTDOWN DOESN'T NEED TO BE VOLA
      Bug#20014045 MONOTONIC SPELT INCORRECTLY IN NDB CODE
      Bug#20092754:  MYSQLD CRASH (FOUND UNCOMITTED AUTOCOMMIT+RBWR TRANSACTION, COMMIT STATUS 3)
      mysql-test/suite/innodb/t/table_compress_2.test:
      Raise version number after cloning 7.4.5
      Correct MTR command for 64k run. Adiing missing "k".
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      Tetss that use innodb_compress_debug should run against debug server
      Added runs with differnt combination and page size setting for Innodb suites
      mysql-test/suite/innodb/t/table_compress.test:   Fix failure when hole punching is not available.   Now the test will be skipped instead
      Revert accidental bump of server version back to 5.6.23
      Fix a compilation warning in non-debug mode
      BUG#18949230: Removed unneeded ndbassert and fixed printout, also recorded number of real periods
      Added some extra output to ndbapi tests utilities as an aid to hunt down the AutoTest failure 'testBasic -n Bug54986 D2'
      Added log printout about invalidation of REDO log and where log head was found
      WL#6815 Adapt MySQL Cluster to 5.7
      Added autotest files for Mikaels environment, added comments about how to get file system as part of results in autotest, added comment about how to handle older git versions with autotest
      BUG#20546157: Fix problems in START_PERMREQ and START_INFOREQ that hangs node restarts when invalidation of nodes is still ongoing at node restart
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20480035 REMOVE MCP_BUG44529
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disable ndb_rpl_circular_2ch* waiting for Bug20592110
      Disable ndb_addnode_witbinlog waiting for Bug17400320
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75720: Fix platform issues with ndb_dd_dump test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      WL#7696 - Don't print a warning on Windows if SPARSE FILE attribute can't be set
      BUG#20631645: Ensure that SYSFILE->latestLCP_ID is properly up-to-date in the pause LCP protocol
      Fix regression caused by wl#7674 in testBasic -n RefreshTuple T6 D1
      Fix regression caused by wl#7674 in testDict -n Bug13416603 I2.
      Fix for Bug#20408733:
      WL#7696 - Punch hole message is Linux specific.
      WL#7696 - Backport code from mysql-trunk to mysql-5.7
      Followup fix for "Bug20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK"
      WL#6815 Adapt MySQL Cluster to 5.7
      Another follow up fix for "BUG11748566 - MYSQL SHOWS WRONG DEFAULT VALUE FOR PK IF  NOT NULL NOT SPECIFIED"
      BUG#20568586: Fix ndb_cpcd to avoid reading a closed file
      BUG#20567730: Ensure that late arriving LCP_FRAG_ORD with lastFragmentFlag set from new master are handled correctly, correct is to ignore them if such a signal arrives in idle LCP state
      Fix for bug#20538179
      BUG#20546899: Faulty ndbrequire fixed
      BUG#20553247: Fix memcpy overlapping copy issue
      BUG#20553247: Use memmove for overlapping memory copy
      Commit this fix on behalf of Pekka N:
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      BUG#19811871 VERSION NUMBR NOT SHOWN IN LOG WHEN [RE]STARTING 5.6.21 SERVICE WITH SLES11 REPO
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      Updated copyright information
      Bug#20228839: MISSING DATABASE '-D' OPTIONS FOR FEW OF THE HUGO TOOLS
      Re-enable clusterj tests disabled during 7.4.4 release.
      Bug#20593065 MULTI UPDATE RETURNS DIFFERENT DATA WITH ENGINE NDB
      This commit is a followup to the fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_time calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop timeout to be configured).
      Add support for SLES12
      Merge 7.3->7.4
      Merge 7.2->7.3
      Overriding release() function from the DynamicObject class in its subclasses.
      This commit is a fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_time calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop timeout to be configured).
      Reverse order of libraries used when linking the ndbapi examples
      Add small MCP for problem with Partition_handler::get_default_num_partitions
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM: fix test regression
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7549: Fix test case for removed EMPTY_LCP protocol
      BUG#20444078: Removed unneeded log printout
      BUG#20444078: Fix master takeover of COPY_GCIREQ protocol
      WL#6815 Adapt MySQL Cluster to 5.7
      Revert accidental version number change
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20528878 : P_S UNIT TEST IS FAILING
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM
      Temporarily hack mtr.pl to allow a large number of failing tests
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disabling ndb.clusterj and ndb.clusterj_jpa tests for 7.4.4 release.
      WL#6815 Adapt MySQL Cluster to 5.7
      bump version to 7.4.5
      Bump version to 7.4.5
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20281479: Entered eternal loop when starting node in MGM server due to buggy bug fix
      Fix unintentional increase in testsize by a factor of 100 of 'testBasic -n Bug54986'
      BUG#20513571: Introduce MaxSendDelay for large clusters
      Fix failing AutoTest 'testIndex -n NFNR3*'
      BUG#20512063: Moved verbose logging to only be used in verbose mode
      Add missing failure detection for 'testBasic -n Bug54986'.
      BUG#20281479: Ensure that START_ORD is properly sent from management server
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20504971: Fixed restart_info table to provide its output
      WL#6815 Adapt MySQL Cluster to 5.7
      Proper error printouts after reaching NDBT_FAILED in test cases
      Backport fix for BUG#20276462
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Updated to newest version of flexAsynch
      Patch related to bug#18401543
      BUG20308276: Don't use same list for master and participant part of takeover processing
      Fix issue in AutoTest where test are being killed by WatchDog during memory allog in startphase 0.
      BUG20276462: Fixed spelling error in error code
      BUG#20276462: Error code ZNODE_FAILURE_ERROR has no treatment in NDB API, use NODE_SHUTDOWN_ERROR instead
      WL#8148 NDB: Add git support to Autotest
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT
      Bug#20234994 JOINS ARE NOT PUSHED AFTER WL6042
      Revert "Adapt pushed joins to WL#6042"
      Fix for Bug#19053226 AUTOTEST FAIL: TESTSRBANK -N MIX -L 300 -R 15 T1
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) PART III
      Bug#20410087 GCOV COVERAGE DATA FOR NDB KERNEL IS MISSING
      WL#8294 NDB: turn on signal checksum as default
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Disabling mtr tests on 7.1 which fail because SSL certificates have expired.
      Re-recording mtr test result after ssl certificate update
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT Generated new certificates with validity upto 2029.
      Fix test client failure for AutoTest 'testNodeRestart -n ClusterSplitLatency'
      Bug#19785977:  CRASH IN NDBINDEXSCANOPERATION::SCANINDEXIMPL
      Bug#20423898 BAD TEST TESTNODERESTART -N LCPTAKEOVER CAN NOT FAIL.
      Improve ndb_rpl_circular_2ch_rep_status reliability.
      Test was random failing due to matching random binlog junk. Make false matches less likely.
      A little brute force to understand the issues with ndb_rpl_circular_2ch_rep_status
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      Experimental experiment with experimental status.
      A more standard variant of !valgrind.
      BUG#19667566 : PARTITION BY WITH COMMENT LEADS TO MYSQL SERVER REBOOT IN MYSQL CLUSTER
      Sacrifice Valgrind run to improve ndb_rpl_slave_binlog_index reliability.
      Backport of fix for bug#16209645
      Bug#17579998 TEST 'TESTNODERESTART -N GCP -L 1 T1' FAILS DUE TO MYSQLD ABORTED
      ndb_rpl_slave_binlog_index.test
      ndb_types.test contained binary raw data from 'bit' and 'binary' columns.
      Bug #20372169         NDB : INCORRECT STATUS VARIABLES NDB_LAST_COMMIT_EPOCH_[SERVER|SESSION]
      Fix of uncorrect merge (7.2 -> 7.3) of regression fix for bug#19524096
      Fix regression introduced by fix for bug#19524096.
      Fix regression introduced by fix for bug#19524096.
      Fix regression introduced by fix for bug#bug#19524096.
      Improve ndb_rpl_slave_binlog_index.test behaviour under Valgrind.
      Bug#20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK INTEGRATION
      Add some improved debugging to help understand non locally reproducable problems with ndb_binlog_last_commit_epoch testcase.
      This commit is a fix for Bug#19880969 (CLUB FOR 7.1, LINUX-RELEASE, 345 WARNINGS IN BUILD). The fix suppresses these warnings, so that the corresponding square in club becomes green rather than red.
      Bug #19306793         CORE IN NDBAPI WHEN EXTENDED EXTENSION TABLE IS CREATED IN MYSQL 7.4
      Quick fix of corrupted special comment characters. No code change.
      Updated the copyright year in README and welcome message
      Improve garbage collection of clusterj artifacts
      Updating copyright year
      Some copyright fixes to files changed in 2014
      Fixing user visible copyright years
      Fix for 7.4.3 build failures
      Fix for copy right year
      Corrected copyright year by sreedhar
      Updated README and banners to 2015
      bump version to 7.1.35
      pgmanpe pe-dump.diff pgman: dump max page entries bug#18484117 bug#19915761 bug#19958804
      pgmanpe pe-config.diff pgman: configure max page entries bug#18484117 bug#19915761 bug#19958804
      BUG#19480197, BUG#73667, BUG#74945: Ensure Local object has transferred back object to real object before calling recursive function
      Cherrypick fix which removes MCP_WL1735 from 7.4
      Cherrypick fix for bug20009152 from 7.4
      Adapt pushed joins to WL#6042
      Follow up fix for bug#20112981
      Fix for bug#20112981
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - rewrite clean_away_stray_files() to use find_files() direct rather than going via make_db_list(). - The only difference between make_db_list() and find_files() is that the information_schema database is not   return in the list of databases. But it's currently not possible  to create a NDB table in information_schema   and thus there can not be any "stray" tables there either.  - testcase added to ndb_reconnect which shows access denied when trying to create table    in information_schema  - This avoids patching the MySQL Server to make the static make_db_list() function available    to use in ha_ndbcluster_binlog and thus the MCP for make_db_list() and LOOKUP_FIELD_VALUES   can be removed. - Also remove the NDB_WITHOUT_MAKE_DB_LIST which was used for compiling ndbcluster in MySQL Server
      Remove unused TNTO_NO_REMOVE_STRAY_FILES Thd_ndb option
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#19898269, BUG#74594: Fixed wrong order of sending bitmap of LCP participants to ensure that starting node can correctly calculate the lcpOngoing flag for each fragment
      Another addendum patch for bug#20112981, adressing comment from Mikael R.
      Incremental addendum patch for bug#20112981
      Fix for bug#20112981
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#75220: Added option to use 10 and 20 LDM threads (same for NoOfLogParts)
      BUG#20215395: Bug in cluster join protocol
      Added jams to place where data nodes freezes in startup
      BUG#19590336: Preparatory patch adding lots of jam:s to DD code, also a few more more comments added
      Additions to wl#7674
      Bug#18715165, BUG#17069285
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug#20193236 SOME COMPILER WARNINGS BECAME ERRORS AFTER MERGE OF MYSQL SERVER 5.5.41
      Cherrypick from 5.6 : Bug#20009154 - FIX REGRESSION AFTER HA_FLUSH_LOGS() HOOK FOR NDB IS REMOVED.
      Bug 19895502 -  BINARY LOG GROUP COMMIT CAUSES REGRESSION FOR NDB REPLICATION.
      This commit is a followup to WL#8145 (NdbInfo : Per-fragment operations info). That WL introduced an error causing 'testScan -n Bug54945 T1' to fail: short-signal scans crashes because the attrinfo section is not available at the point where the code tries to read it to find the size of the interpreted progam. This commit fixes that by not trying to count program size for short-signal scans and lookups. Since these only happen during online upgrade, they are not important for per-fragment statistics.
      Bug #19992856 MYSQL CLUSTER TRIGGER ON DELETE FALSE POSITIVE
      This commit is a followup to the fix for bug#19976428 ("reports failing with 'out of longmessagebuffer' error"). This commit updates a regression test (testIndex/FireTrigOverload) so that it will expect the right error code (293 "Inconsistent trigger state in TC block" instead of 218 "Out of LongMessageBuffer").
      autotest auto1.diff testBasic -n Bug16834333 : fix dict cache crash
      Bug #19858151         MAKING DATA NODE SELF-EXCLUDE MECHANISM MORE ROBUST
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Updated fix for bug#20113145:
      Follow up to fix for bug#bug#20166585:
      Follow up to fix for bug#bug#20166585:
      This commit fixes bug #19976428 ("reports failing with 'out of longmessagebuffer' error"), and a set of other issues related to the pool of "Fired Trigger" records.
      Bug#17069285 : SEGMENTATION FAULT IN NDB_PRINT_FILE
      Update to recent fix where we failed to close scan cursors at the end of their lifetime.
      WL#7514: Fitted into infoEvent max size and decreased some too wordy log printouts
      Update 'v3' fix for bug#20166585:
      WL#7514: Fixed an incorrect assert
      Fix for various AutoTest 'testIndex ...' crashing due to excessive memory usage.
      Bug#18715165, BUG#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for: - Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT - BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      The AutoTest testcase 'testScan -n Bug54945 T1' crashed as it failed to create a transaction object which was later referred without first checking that it was created.
      Fix for crashing AutoTest: 'testNdbApi -n RecordSpecificationBackwardCompatibility'
      WL#6815  Adapt MySQL Cluster to 5.7
      Fix flexAsynch also in 7.3, backport from 7.4
      WL#7508: Parallelize synchronization of starting nodes with live nodes
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - Test fails since the two new default sql_modes  ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES   are displayed by "show create procedure"  - Update .result file to include the two new default sql_modes(as has been done in similar   places)
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      Experimental fix for several AutoTest which crash with an unreadable stack dump very early in their lifecycle, like:
      Fixed crashing AutoTest testBitfield.
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Cherrypick fix for ndb_memcache out of source from 7.4
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20135403 NDB_MEMCACHE TEST DOES NOT WORK IN OUT OF SOURCE BUILD
      Fixed crashing AutoTest: './testLimits -n ExhaustSegmentedSectionPk WIDE_2COL'
      Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT
      BUG#74594: Fixed a hang in PAUSE LCP protocol when LCP was completed between PAUSE and UNPAUSE
      Removed lots of jam noise from QMGR preventing one from seeing the bugs
      WL#6815  Adapt MySQL Cluster to 5.7
      Revert some junk lines from pfs_upfgrade*.result files
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherry-picked from mysql-5.6.22-release
      Cherry-pick from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-pick from mysql-5.5.41-release
      Added tag mysql-5.6.22
      Added tag mysql-5.5.41
      BUG#74594: Fix missing state update that causes PAUSE LCP protocol to hang
      BUG#74594: Added some more DUMP printouts for PAUSE LCP protocol
      WL#7650: Make atrt work on Mac OS X
      Removed assert / require from NDBT_ResultRow c'tor and rewrote it such that it could be constructed even if the the object is not in 'Retrieved' state.
      BUG#75007: Ensure we wait until master takeover is completed before handle LCP_COMPLETE_REP from LQH and DIH participants in the LCP protocol
      Bug#20029843 7.4.2 REGRESSION: UPGRADE_TRAFFIC FAILURES FOR 7.4 -> 7.3: Fixed incorrect conditional expressions
      Cherrypick fix for ndb_dist_priv.sql from 7.4
      WL#6815  Adapt MySQL Cluster to 5.7
      Cherrypick fix for mysql_system_tables_fix.sql from 7.4
      WL#6815 Adapt MySQL Cluster to 5.7
      Encourage MySQL to treat numeric variables as numbers so that ndb_rpl_conflict_epoch2_extra does not return incorrect results from inequality tests.
      BUG#75007: More work on ensuring that we drop the right signals of the LCP_COMPLETE_REP and LCP_FRAG_REP, a bit tricky to decide, wrote up an analysis in a comment and a fairly simple code based on this analysis
      Cherrypick fixes for ndb_alter_table_online from 7.4
      Remove usage of DEFAULT 0 for TIMESTAMP
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fixed for ndb_update_no_read from 7.4
      Turn "info" off after each section in test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fix for ndb_dd_disk2memory from 7.4
      Add missing enable_query_log comman in ndb_dd_disk2memory.test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75007: Fixed interaction with early master takeover initialisation and handling of failed node in LCP, code in new master
      BUG#75007: Handle side effect of bug fix, there are signals generated by node failure handling that must be allowed to pass through the code as they are required for node fail handling to be done properly
      Apply patch for MCP_BUG19704825to 5.7.5
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#74594: Fix of variable length in message to management server to avoid printing garbage
      BUG#75007: Ensure that we drop LCP_FRAG_REP and LCP_COMPLETE_REP that originates from a dead node. The LCP could potentially be done before this arrives due to node failure handling, these signals are sometimes delayed and thus we need to take care that we can still receive them.
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Assumption that all alive nodes have participated in LCP at close down time caused havoc since we can now be alive and still not have participated in the LCP. So had to move the send of the last LCP_COMPLETE_REP backwards a bit to be able to reuse the m_participatingDIH bitmap to send to.
      remove last NDB_WITHOUT_COLUMN_FORMAT ifdef  - since all versions of MySQL Server which ndbcluster   compiles against now supports "field->column_format" and "field->storage_type" - one NDB_WITHOUT_COLUMN_FORMAT left behind(or reappeared)
      BUG#19795152: Missed essential ptrCheckGuard in upgrade/downgrade situations
      WL#7514: More printouts to log for system restart case
      BUG#18610698: New test case
      BUG19795152: Fix Software upgrade issue
      Add missing delete of Ndb instance created by testcase
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Minor tweak of jamming and of a loop
      BUG#19795217: Checked the LCP state a bit too early
      BUG#74594: Added one more cluster log event
      BUG#74594: Wrong check if LCP is idle when sending UnPause message
      bug#20045455 Improve error reporting for clusterj
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Fixed a compiler warning in new tool
      BUG#74594: Wrote an analysis tool for reading DIH Fraglist files to enable easier analysis of system restart bugs
      BUG#74594: Queued LCP_COMPLETE_REP comes from LQH, not from DIH
      BUG#74594: Fixed a typo bug in an important condition
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Added a new ndbrequire to find problem
      WL#7514: Added a bit more logging of the actual start order signal
      flexBench created its worker threads, flexBenchThread, with a stack of insufficent size. This later caused the threads to crash.
      WL#7509: Add undocumented interface to change Disk Write Speed in LCPs, change isn't persistent over restarts, useful to handle SRs where restarts are too slow
      WL#7509: Tweaked the adaptive LCP speed parameters to be a bit slower in changing
      BUG#74594: Add DUMP_STATE_ORD variant to print pause state to cluster log
      BUG#19795108: Proper fix of node restart status using the new Node Recovery Status module
      BUG#19795152: Handle Partial System restarts
      BUG#74594: Used wrong variable in non-master to decide on pauseAction
      Attempt better "htonll" portability in NDB memcache code
      Fix for bug#19390895
      BUG#74594: Ensure that we drop PAUSE_LCP_REQ signals from master if it concerns a node that already has died
      BUG#74594: Node failure in inopportune time caused crash
      BUG#74594: Decrease amount of useless jam:ing to make bugs more visible
      Bug#19642978: NDB_RESTORE CORES ON BUILT-IN PRIMARY KEY + STAGING BLOB CONVERSIONS ON SPARC
      Fix for bug#20031313  AUTOTEST CASE 'TESTDICT -N GETTABINFOREF' NEVER WORKED FOR >= 4 DATA NODES
      BUG#74594: Turned ndbrequire condition the wrong way, caused obvious crash, added a few more ndbrequires while at it
      BUG#19795152: Also NODE_FAILURE_COMPLETED and ALLOCATED_NODE_ID can be states from where a node fails from DISCONNECT_REP although the node hasn't really started its start yet.
      BUG#74594: Removed buggy ndbrequire, not correct though to possibility of delaying arrival of LCP_FRAG_REP when copying table to disk
      BUG#19795152: NdbTick_Elapsed parameters in wrong order
      BUG#19795152: Added one more acceptable state transition, ALLOCATED_NODE_ID -> ALLOCATED_NODE_ID
      BUG#74594: Missed setting lcp id in COPY_TABREQ, added ints of LCP variables on replica and fragment records, removed init of lcpStatus in INCL_NODEREQ which depended on old fact that we included when LCP was idle, now this is no longer necessary, missed init of m_lcp_start_time in including node in LCP, added a number of log prints
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#19676350 NDB_RPL_CONFLICT_EPOCH SHOWS SCHEMA DIST TIME FAST FORWARD DUE TO EINVAL
      BUG#74594: missed init of c_queued_lcp_complete_rep
      BUG#74594: Handle fromTimeQueue issues with LCP_FRAG_REP
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed stopping of pause properly in master and in non-master
      BUG#74594: Wrong assumption in START_LCP_REQ removed, fix of ndbrequire of COPY_TABREQ counter improved
      BUG#74594: Added new parameters to allocStoredReplica
      BUG#74594: Missed init of fragId and tableId in replica record, wrong assumption about m_participatingDIH in START_LCP_REQ
      BUG#74594: Missed clear of own node in NodeReceiverGroup in sending FLUSH_LCP_REP_REQ
      BUG#74594: Fixed typo
      BUG#74594: Missing inserts into signal table
      BUG#74594: Fixes for wrong assert, missing state update and wrong condition
      BUG#74594, fix for sanity check
      BUG#19795152: Fix a placement new that overwrote the node recovery timers in debug mode, added a bit more debug code and arranged the parameters in some common functions a bit more logically
      BUG#74594: Added missing file CopyTab.hpp
      BUG#74594: Remove need for long wait for LCP to copy meta data to make restart times more predictable and faster
      BUG#74639: Preparatory patch to handle overload bugs that is likely to be caused by higher pressure on LCPs and restarts
      BUG#19795152: Added missing file: NodeRecoveryStatusRep.hpp
      BUG#19795152: Wait for LCP start at node restart, add node recovery status table as well
      BUG#19795217: Remove EMPTY_LCP protocol from master takeover
      BUG#74594: Part 2: Fix a potential LCP stoppage
      BUG#74594: Part 1: Remove a faulty ndbrequire
      BUG#19795029: Improve logging of restarts developed in WL#7514
      BUG#19795108: Fix of node restart status for adapting speed of LCP disk write speed
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug#20007248 NDB NOT FUNCTIONAL ON POWER
      Bug#20007216 FLEXASYNC USES 32BIT MATH, LEADING TO INCORRECT SUMMARY ON POWER8
      Fix regression in AutoTest -n DropWithTakeover T1 introduced by fix for bug#19874809:
      Add missing newline before end of file in AsyncNdbContext.cpp
      Fix build failure in MCP patch for BUG19553099
      bug#20017292 Clusterj logging levels too verbose
      Bug#20009152 FIELD NAME NOT INCLUDED IN WARNING WHEN CONVERTING TO FIXED
      WL#7640  Ndb Active Active Delete-Delete handling
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Fix Club test regressions after backport of bug#19524096:
      WL#7640  Ndb Active Active Delete-Delete handling
      Provide easy way to store documents with no mapping and no schema defined   define new method on session factory: db(database_name) returns db object   db object has properties corresponding to table names     if table does not exist, create the table       if user has not mapped the table, create default table mapping and table       if user has mapped the table, use table mapping to create the table   Operations on session using non-existing table name     will now create the table if it does not exist and user has mapped the table
      Fix bad #ifdef
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Bug #19817817 TFBUFFER::VALIDATE() CONST: ASSERTION `(P->M_BYTES & 3) == 0\' FAILED
      Backport of fix for bug#19524096
      Bug#19999242 DELETEING NDB_CLUSTER_CONNECTION WITH NDB INSTANCES
      bug#19913569
      Avoid segv when closing session factory with sessions still active
      Bug #17592990: DATA MISMATCH BETWEEN C NDB API AND MYSQL CLI.
      Backport of fix for Bug#19724313
      Fix for bug#19880747:
      Fix for bug#19875663
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Fix for bug#19881025:
      This commit is an update of WL#7375 (Ndbinfo: Per-fragment memory usage reporting). Column fixed_elem_free_rows in view ndbinfo.memory_per_fragment is renamed to fixed_elem_free_count to get a more consisten naming.
      Fix for bug#19874809 :
      Added sles11 repo packages
      This commit implements WL#8145 (NdbInfo : Per-fragment operations info).
      Follow up fix for bug#18352514 fixing a build failure.
      Addendum fix for bug#18352514:
      bump version to 7.4.3
      Bug #19875710         NDB : COMMIT ACK MARKERS LEAK @ LQH IN 7.4
      BUG#19815044: Part 4, remove usage of global block variable m_pgman_ptr, it is used for parameter passing, but can in some weird situation in DBTUP it can be reassigned to a value that can cause an inconsistent database.
      BUG#19815044: Part 3, fix such that an aborted insert after a committed delete doesn't lead to that triggers for delete isn't executed by ensuring that delete_insert_flag is properly maintained
      BUG#19815044: Part 1: Improve jamming support to make it easier to read what's going on bug situations
      BUG#19815044: Add test case for it used in autotest
      BUG#19815041: Crash on abort of delete after successful delete on a disk data table
      Add global.fail_connect to test utilities
      Fix ProjectionErrorTest
      Improve error reporting for multidb tests
      big lint-fixing patch
      Fix unified_debug issue with per-file levels for C++ files Remove workaround for this in executable programs
      Converter use in DBTableHandler (fixes freeform tests for ndb)
      Big deglobalization patch. Removes many global variables (but not all).
      Move SQL.create and SQL.drop from test harness into adapters. NDB depends on MySQL for this.
      Enhance closeAllOpenSessionFactories() so it takes a callback & returns a promise
      Fix for bug#19712569
      When using node --harmony and strict mode, DBIndexHandler cannot be forward declared   and still use the function DBIndexHandler(parent, dbIndex) syntax.
      jscrund: add support for B tests with varying size varchar. (Only supported by jscrund_mysqljs crund backend).
      lint globals cleanup
      Fixes restart race causing test timeout in AutoTest 'testDict -n schemaTrans'
      Return an error if writing non-Buffer data to binary columns
      Allow flexible mapping for node.js domain classes
      Fix for bug#18352514
      Fix for bug#19661543
      Remove warning introduced with patch for BUG#19236945
      Bug #19236945 ADDRESSSANITIZER BUG SHOW UP IN NDBRECATTR::RECEIVE_DATA CALLED FROM RESTORE.CPP
      bug#19793475 - NO WAIT FOR EPOCHS THAT HAVE NO DB CHANGES MADE BY THIS NDB THD TO BE IN BINLOG
      Removing the extra blank line from daily-basic-autotest-conf
      Fixed compilation error due to changed file name
      Bug#19267720:  NDB REPLICATION : DO NOT SETUP CONFLICT RESOLUTION FOR EXCEPTIONS TABLES
      formatting
      Docs work
      BUG#19795072: Fix problems related to ndbinfo tables for disk write speed
      BUG#19643174: Fix races in relation to sending TC_COMMIT_ACK and handling of complete of a transaction
      Removed compiler warnings
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000): GOT ERROR 4547 PART II
      Cherrypick from 7.4 (revno 4354): Implement status variables exposing last commit epochs for the server   and each session.
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      BUG#19724313: Handle multiple threads crashing at the same time properly
      Added missing include for previous patch Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Restore computeChecksum to computeXorChecksum that was reverted in patch for Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Merge of Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Refactoring of Packer::unpack in preparation of merging Bug#19582925
      Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      wl#7674-5 fixing errors
      wl#7674-5 fixing errors and compiler warnings
      wl#7674 Backward compatibility/new event api methods
      wl#7675 Introduce state machine for event buffering
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) : GOT ERROR 4547 : 'RecordSpecification has overlapping offsets'
      Applying the patch for regression bug#19582807 for 7.1.33 cluster release
      Improve Query documentation
      Cherrypicked
      Cherrypicked
      Bug #19582807 MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Wl#7639 Ndb Active Active Manageability improvements
      Removed compiler warnings
      WL#7642 Ndb Active Active Binlog Read Tracking: Removed uninitialized data to remove valgrind warnings
      Work on new README
      Bug #17257842     EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #19766167         NDB : VALGRIND REACHABLE MEMORY IN NDB_RPL_CONFLICT_EPOCH_TRANS
      Fix new log printouts - Use log functions of component in favour of sql_print_information - Break long lines
      In-Progress Packaging / Documentation improvements
      Iterate array rather than for/in
      Add mynode.closeAllOpenSessionFactories()
      Windows testcase fix attempt
      Follow up patch for WL#7953 Transporter handshake retry
      WL#7642 Ndb Active Active Binlog Read Tracking: Updated result for ndb_rpl_conflict_read_tracking test case to reflect new conflict counters
      WL#7640  Ndb Active Active Delete-Delete handling
      bump version to 7.3.8
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      bump version to 7.2.19
      bump version to 7.1.34
      Bug#19692387 PORT FIX FOR BUG 18770469 TO MYSQL CLUSTER 7.3
      Added ndb_print_file man pages
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug#18487960: SIG 11 on delete with index merge
      Follow up patch for WL#7953 Transporter handshake retry
      Follow up patch for WL#7953 Transporter handshake retry
      Patch 2 for WL#7953 Transporter handshake retry
      Patch 1 for WL#7953 Transporter handshake retry
      Patch 3 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 2 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 1 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      adding checksum to the cnf file
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19600834  late code review comment
      Bug #19600834 DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH)
      Bug #19600834         DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH) ...
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3
      Bug #19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3  - revert the reverted
      Bug#19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Change from mysql-5.6 to build Oracle Linux 7 RPMs
      WL#7640  Ndb Active Active Delete-Delete handling
      WL7640 Add delete-delete conflict count
      Adding ndb_print_file to spec file
      Repush of WL#7544 after 7.4.1 clone tag.
      bump version to 7.4.2
      Set version 7.4.1
      Revert WL#7544, not to be included in DMR 7.4.1
      Reorder member initializer list for thr_data to follow initialization order. This removes compiler warning introduced in fix of Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      WL#7544: Optimisations of the NDB API receiver thread in various manners. 1) Optimising method to unpack field data from TRANSID_AI signal, 2) optimised handling of trp_client locking check, 3) reorganised code in NDB API receiver thread for better [1;31mperf[mormance and more readability, 4) Optimisation signal receive handler
      BUG#19451060: One more step on the way to understanding commit ack markers
      Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Fix for bug#19559313, call getPerformStateString() with a nodeId arg instead of a state argument
      Fix for Bug#19552283 :
      Update documentation to remove useProjection       Update Session.js to remove useProjection
      BUG#19552349: Avoid stack overrun by removing endless recursive call
      BUG#19451060: Further refinements of bug fix, previous ndbrequire revealed a race that could cause multiple REMOVE_MARKER_ORDs to appear for the same transaction, added long comment about this specific race variant. Left a part of the ndbrequire still to ensure that this only happens when receiving REMOVE_MARKER_ORD sent by API through TC_COMMIT_ACK and not through API failure handling
      Bug #18703922  DUMP-CODE ACTIVATED DEBUGGING ON WATCHDOG OVERLOAD ISSUES
      Bug #17730825  NDB API: POSSIBLE LEAK OF CONNECTION OBJECTS
      BUG#19524096: Converted many 4009 errors to temporary error 4035, ensured APIs can use new data nodes sooner, fixed some wrong error categories, removed no longer used errors, fixed some anomaly in communication towards the API, small improvement of restart printouts, should give autotest a much better chance to get rid of redness
      Bug #17893872         ER_DUP_ENTRY WHEN INSERTING TO AUTO-INC COLUMN ON SPARC MULTI-MASTER SETUP
      BUG#19451060: Added more descriptive information at crashes related to commit ack markers, changed name of noFired to numFired for clarity, added possibility to put last in free list to aid crash printouts
      Fix for spelling error in Win32 code
      WL#7509: Introduced more configurability of disk write speeds and added a number of new ndbinfo tables to track this new more adaptive behaviour
      WL7845: More and safer ways to print records in DBTC
      BUG#19451049: Missing call to prepareTUPKEYREQ from handle_lcp_keep, added comment about handle_lcp_keep
      bug#19124970 - PB WITH POLLEVENTS , NDBEVENTS
      Backport from 7.2
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      The Bug was due to m_out object used in NdbOut operator was not initialized/set to the output stream. Added an ndb_init() call to initialize it to output stream. Added an environmental variable $NDB_PRINT_FILE to give path to its binary in  mysql-test/mysql-test-run.pl file. Added a unit test and its result file.
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      bug#19031389 bugfix.diff bug fix
      bug#19031389 bugtest.diff bug test
      BUG#19513967: Fixed missing init of longer bitmask
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      BUG#17703874
      Bug#19202654: NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      Bug #18354165         16723708 CHANGED EVENT CATEGORY VALUES
      Clusterj windows CMakeList error
      Clusterj support for autoincrement columns http://wl.no.oracle.com/worklog/NDB-RawIdeaBin/index.pl?tid=8027
      Added missing logging.properties
      Clusterj improve maven handling for out-of-source builds
      Bug#18875137: NDB_RESTORE STILL MISSING SOME TYPE CONVERSIONS
      Fix for Bug#19414511:
      Bug #19236785  ADDRESSSANITIZER BUG IN ~NDB_MOVE_DATA Bug #73311      AddressSanitizer bug in ~Ndb_move_data
      Bug #19235428  ADDRESSSANITIZER BUG IN DATABUFFER2<SZ,POOL>::IMPORT (DBDICT::ALTERTABLE_PARSE) Bug #73310     AddressSanitizer bug in DataBuffer2<sz,Pool>::import (Dbdict::alterTable_parse)
      Bug #19235170  ADDRESSSANITIZER BUG IN DBUTIL::GET_SYSTAB_TABLEID Bug #73308  AddressSanitizer bug in DbUtil::get_systab_tableid
      Bug#11764704 : Exclude missing tables when restoring a backup  - added an option "--exclude-missing-tables" to ndb_restore tool  - when enabled, the missing tables will be added to the    exclude tables list before starting to restore.  - updated test cases accordingly.
      Revert fix merged in from 5.5.39 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert fix merged in from 5.6.20 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert quick fix for dtrace problems in release tree. New fix in CMake files will be merged in from 5.6.20.
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      This commit is a followup to the one below. It changes the fragment_num colum (in memory_per_fragment), such that it gives the global frgament id rather than a node-local sequence number. That way, it is possible to see where each fragment (or some replica of it) is located. This is consistent with the output from 'ndb_desc -pn -d <database> <table>.
      Bug 19028487 NPE when scanning rows with blob or text columns
      More fixes for bug#19053226
      Fixes for bug#19053226
      More fixes for bug#19053226
      bug#18410939 - MEMORY LEAK AT EVENT BUFFER ALLOCATING A DUMMY EVENT LIST WHEN INCONSISTENCY
      Bug #17184024         ERROR 4 IN LIBNDBCLIENT.SO.6.0.0 (3-7474573041)
      bug#19122346 fix3.diff FK use full name PP/CC/name + debug
      bug#19122346 fix2.diff fix test error from 7.3 r4203 FK_Bug18069680
      bug#19122346 fix1.diff FK use full name PP/CC/name
      ndb - RSS-DynArr256
      A new ndbapi test case: testNodeRestart -n DeleteRestart.
      Bug #18731008    NDB : AVOID MAPPING EMPTY PAGES DUE TO DELETES DURING NR Bug #18683398    MEMORY LEAK DURING ROLLING RESTART
      Bug #19193927         TC TAKEOVER TAKES TOO LONG CAUSING MANY PROBLEMS
      ndb
      Bug#19193756 MTR GENERATES TOO LONG SOCKET PATHS
      Merge from mysql-cluster-7.2.17-release
      ndb
      use primitive types
      Include stdlib.h for malloc() and free()
      Compiler issues on some Windows platforms
      Add debug to trace bug#18411034 - CRASH IN NDB-SHARE
      Updated the list of tables to be deleted after running ndb clusterj tests Added new test and the model to build specification
      Merge latest nodejs-adapter from 7.3 to 7.4
      Unconditionally disable dtrace for rpm, barfs on Oracle dtrace
      Remove su[1;31mperf[mluous -master.opt file for the removed test case ndb_mt_recv.
      Unconditionally disable dtrace for rpm-oel, barfs on Oracle dtrace
      correcting copyright headers
      Fix issues with Read/Modify/Update of NDB VO objects containing blobs.
      All NDB read results (including those containing BLOB and TEXT columns) are now ValueObjects.
      Fix bug of using Persistent<T>(x) rather than Persistent<T>::New(x)
      work on support for NdbRecord-backed ValueObjects which contain TEXT or BLOB columns.
      More TEXT tests for NDB
      less debugging output at end of test run
      Fix composition value checking
      Implement bufferForText and textFromBuffer in C++.
      rawNdbDefaultvalue does not require a full-fledged Node Buffer
      let compiler supply default destructors
      Another attempt to fix crashing bug in BlobHandler
      Expose the string encoder statistics in NdbTypeEncoder.cpp to JavaScript.
      Move v8 calls from worker thread to main JS thread
      Support TEXT columns with character set UTF-8 or ASCII. Other charsets (which require recoding) are not yet supported.
      A test file that does not export a test case now causes a warning rather than an error.  This should make it a little easier to develop new tests.
      Column Metadata API provides charsetName rather than charsetNumber
      Fix apparent bug in calculating size requirement of UTF-8 buffer
      Restore compatibility with node-mysql 2.0.0
      Fix crash on stub commit / stub rollback
      update cmake & gyp build lists
      Finish read & write BLOB implementation for NDB adapter
      Implement connection pooling for mysql adapter
      Fix tests that do not close session after running test
      Improve error reporting for connecting to database
      Add suggestion to user to maximize [1;31mperf[mormance of updates
      Improve spi test error reporting
      Succesful insert into BLOB column
      Add BLOB column to stringtypes test suite & confirm that existing tests pass with a mapped (but unused) BLOB field.
      Test that storing a non-BLOB in a BINARY column gives error SQLState 22000
      Use Error SQLState 0F001 "Bad BLOB" (actually a "Locator Exception") if value intended for a BLOB column is not a Buffer.
      Initial implementation work on BLOB support for NDB adapter.
      Refactor connection handling to prepare for connection pooling
      WL#7626 Implement many-to-many relationships for Document Composition
      Don't try immediate startTransaction() unless using async api.
      Keep a single usedOperationSets array rather than one per DBSession. The array is at file scope in NdbTransactionHandler. It does not grow past 4000 elements (a literal constant). Underlying DBOperationSet native objects are freed when the wrapper is placed in the recycler array.
      Disable mysql tests for now
      Attempt to recycle DBOperationSet wrappers
      wrapPointerInObject and unwrapPointer take a v8::Handle<T> rather than a v8::Local<T>
      Improve error reporting for relationships that are null or undefined
      Test a slightly different approach to V8 wrapping
      Minor refactoring in NdbOperation
      Remove the use of "proto" in DBTableHandler
      Refactor DBTableHandler.getFields() into a simple case getFields() and a separate more complex getFieldsWithListener(). Removed the resolveDefaults option which was always set to false.
      Improve error reporting for ProjectionTest
      Improve error reporting for ProjectionTest
      Improve error reporting for test failures
      Compiler error
      Stub out NdbSession.buildReadProjectionOperation in hopes that test suite will run.
      WL#7626 Composition Implement support for one-one, one-many, and many-many relationships. Replace useProjection with implementation for find (projection, key).
      Rather than having a JavaScript wrapper for Record::setNotNull(), implicitly call setNotNull() when writing a data value in encoderWrite().
      Don't use a startTransaction() hint for unique key operations.
      In JsValueConverter for pointer types, if the JavaScript value is Null, represent it as a null pointer.
      Remove what little was left of NdbTransaction_wrapper.cpp
      move ENABLE_WRAPPER_TYPE_CHECKS define into adapter_global.h
      portability fix
      Update source file lists for gyp & CMake
      Add option free-percent
      New design for scans. This removes the previous wrapper for NdbScanOperation and ScanImpl.cpp file and consolidates all scan functions into ScanOperation. Expected: start 416 tests, pass 413, fail 2, skip 1.
      fix wrappers for boolean types
      In test driver allow --stats=query, e.g. --stats=spi/ndb/DBSession
      Add HandleScope to all toJS() template functions just to be safer from enigmatic V8 memory leaks. Provide toJS() and isWrappedPointer() specializations for type bool.
      Refactor NDB execute. This patch renames PendingOperationSet to DBOperationSet, and makes DBOperationSet the "point of contact" for JavaScript calls to begin and execute transactions. All t_basic tests now pass.
      New SPI test   begin transaction; delete (execute NoCommit) ; read deleted row ; commit.
      Minor bug fixes for passing SPI tests
      Major JavaScript logic changes in NDB adapter. NdbTransactionContext, NdbSession, NdbOperation, and NdbConnectionPool are adapted to use the call flow of DBSessionImpl and DBTransactionContext rather than the native call flow of the NDB API.
      This commit includes various small C++ fixes. The next commit includes major JavaScript logic changes. With these together, spi tests pass.
      Add new connection property ndb_sesion_concurrency Refactor initialization of NdbSession and connecting of the new NdbSession to its impl.
      Adapt DBDictionaryImpl to use DBSessionImpl rather than Ndb.
      Revise protocol for registering a transaction open / closed. Use only two calls, registerIntentToOpen() and registerTxClosed(). Always make these calls from JavaScript main thread.
      NdbTransaction is no longer wrapped for JavaScript
      Template class NativeCFunctionCall_4_
      DBSessionImpl
      Adapt AsyncNdbContext to be aware of DBTransactionContext
      executeAsync() on AsyncNdbContext is no longer wrapped for JavaScript; use executeAsync() on DBTransactionContext instead.
      Refactor DBOperationHelper:  it now takes a DBTransactionContext rather than an NdbTransaction.  it now defines operations, but does not prepare them.
      Rename addOperation() to getNextOperation()
      Add two new classes, DBTransactionContext and DBSessionImpl. These will free the JavaScript code from the start/prepare/execute cycle of Ndb and NdbTransaction, eventually allowing operations to be [1;31mperf[mormed with fewer scheduled async calls and therefore less overhead.
      Adapt DBOperationHelper to the KeyOperation / ScanOperation change.
      Bug fix where the do_close flag must be associated with the transaction rather than its parent Ndb object.
      Refactor Operation and DBScanHelper into two classes called KeyOperation and ScanOperation.
      This change alllows Ndb::startTransaction() to run as a sync call in the main JS thread if we suspect that it will not block.  As a proof of concept, this allows you to measure the [1;31mperf[mormance with this change; but it should not be used as-is, because the guess could be wrong, which would cause the main thread to block waiting for network I/O.
      In the common case where an async method call returns int zero, try to optimize away creating a new JavaScript value.
      Slight change to the compatibility strategy for some libuv changes.
      Combine NdbTransaction execute() and close() into a single scheduled call whenever execType is Commit or Rollback.  This saves the scheduling cost of running the close() call by itself.
      Various fixes for lint.
      Remove old stats API.
      Use new stats API in MySQL code.
      Use new stats API in NDB code.
      Revised statistics API. Now each module owns, at file scope, its own stats object. The module registers the stats object with the global statistics, which keeps a reference to it in the stats tree. This should reduce the cost of keeping statistics to practically zero.
      Delay after (rather than before) the first test iteration. This allows V8 to compile all the JavaScript code before dtrace starts running. High dtrace profiling rates caused the first iteration to run very slowly and skewed the profile towards compile times rather than run times.
      Optional delays both before & after jscrund run
      jscrund: add option to delay start of test run
      Add useProjection to Session   this function specifies a projection to be used for find and query operations
      Minor work on DBDictionaryImpl Contain the code for handling NdbDictionary 3-part/slashed/names in DictionaryNameSplitter class. Reformat patch indent width from 4 spaces to 2 spaces. buildDBForeignKey() takes only the fk* and must use its own private name splitter.
      Error 23000 when attempting to set a non-nullable column to null.
      Restore table which should not have been removed from test suite
      Add support for foreign key metadata
      update literal mapping test for schema
      Fix errors in test case & misc. lint errors.
      Check in test case where one operation in a batch has a data type error. This test fails for both NDB and MySQL.
      Expose NdbRecordObject::prepare() to JavaScript. This is a step towards fixing handling of encoder errors for value objects.
      Write a negative value to an unsigned int field of an NDB Value Object. This test causes the test suite to hang forever.
      Run executeAsynch() in JS main thread rather than a UV worker thread. We had seen higher latency using async ndbapi vs. sync ndbapi, but this change eliminates most of that difference.
      unused table in test suite
      Fix for compiler warning in TimestampWriter validity check
      NDB encoding-related changes.  (1) distinguish between 22003 numeric value out of range and HY000 for "value is not numeric"  (2) provide a (hopefully) faster path to encoderWrite and encoderRead by wrapping them as methods of Record
      Refactor error handling
      Attempt to optimize encodeKeyBuffer() for single-column indexes
      Fix reporting of session factory if no mappings
      Remove JsValueAdapter in loader; it is no longer needed.
      This fixes the failing "timestamp 1969" test case for NDB. Test still fails with MySQL.
      Fixes for lint test failures
      Test & fix NDB handling of encoder errors for numeric types
      Tests for numeric types
      This renames the integraltypes suite to numerictypes and adds stub tests for float, double, and decimal columns
      Test for particular expected errors rather than simply for operation failure
      Add decimal support in NdbTypeEncoders Remove JS wrapper for decimal utilities from ndb_util
      Encoders for NDB integer values: if the fast integer conversion fails, try a slow one, then test whether the result is legal.  This should allow writing valid JS string and float values to int columns.
      Improve handling of errors from NDB data type encoders
      Improve handling of data encoder errors in the ndb adapter
      fix sql_mode for mysql adapter
      Implemented test cases
      Stub out new test cases for data type casting
      If MySQLTime.valid is set to false, NdbTypeEncoder will reject the value.
      Allow user to set sql_mode in mysql adapter with a default of STRICT_ALL_TABLES
      Change console.log to udebug.log in issues/2014-03-18Test
      Add shell script to manage regular runs of jscrund
      Adapt loader to use new Batch.getOperationCount() api
      Batch: use getOperationCount()  rather than getSize()
      Add Batch.getSize() method
      Add test case for issue of bad data type for column
      Fix typo
      Add test case for issue where a TableMapping created from a literal mapping could not be used to [1;31mperf[morm operations (fixed in bzr 686).
      Changes to sample data loader after code review with Craig. This version still has lots of untested features (and combinations of features) but it can load CSV data and random data.
      Bug fix creating TableMapping from object literal
      WL#7578 Replace usage of ndb_schema_share->key with hardcoded text
      WL#7578 Move subscriber bitmaps to NDB binlog component
      WL#7578 Move the g_nodeid_map to Ndb binlog thread
      WL#7578 move clearing of subscribed to binlog thread
      WL#7578 Always expect everyone to ack the schema op
      WL#7578 Refactor schema distribution code
      WL#7578 Refactor schema distribution code
      ndb
      WL#7578 note about nodeid from global cluster connection
      WL#7578 Don't use ndb_schema_share from ack_schema_op
      Initial checkin of JavaScript data loader tool
      Remove windows line endings from ndb_schema_object.cc
      Try to reduce overhead of stats.incr() calls
      Remove the error handling in jscrund_mysqljs backend which duplicates work [1;31mperf[mormed in the jscrund frontend.
      Add conditional guards around udebug log messages.
      Add conditional guards around udebug log statements.
      Improve error reporting while loading mysql node_module
      The node-mysql driver by default constructs an Error object in order to get a stack that includes the user's call to Query. This can be a [1;31mperf[mormance bottleneck.

[33mcommit 4bc6b89fcdefc0189be8aafeb37357db4451819a[m
Merge: 3840940dadb 300f50f6596
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Apr 2 09:28:32 2015 +0200

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            mysql-test/suite/[1;31mperf[mschema/r/show_sanity.result
            storage/[1;31mperf[mschema/pfs_variable.cc
            storage/[1;31mperf[mschema/pfs_variable.h

[33mcommit b73ee71b072c49f7acf2a27f8dc1cbf553ee2e3a[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Mar 31 15:50:40 2015 +0300

    Extend the hash table unit test
    
    Extend the test to also (conditionally, configured at compilation time)
    test the [1;31mperf[mormance of std::map and std::unordered_map.
    
    For this introduce an interface class ut_hash_interface_t which is
    implemented by ut_lock_free_hash_t and also by a simple class inside the
    unit test which uses std::map (or std::unordered_map) + a mutex.
    
    Also make the number of initially pre-allocated elements configurable as
    a parameter to the ut_lock_free_hash_t constructor.
    
    WL#7170 InnoDB buffer estimates for tables and indexes

[33mcommit 89dd986a89840b7d7ffcf3555612c2d4ff01eaf9[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Wed Mar 25 14:56:43 2015 +0100

    Bug#19585938 Crash in get_full_func_mm_tree with null item_field->table_ref
    
    The problem may occur if we have a grouped query with a non-grouped
    subquery that contains a reference to an aggregate function, e.g. in
    the WHERE clause. The aggregate function must not reference any columns.
    
    Example query:
    
    SELECT (SELECT 1
            FROM t1
            WHERE SUM(1) < id
           )
    FROM t1
    GROUP BY col1+col2;
    
    The range optimizer is attempting to optimize the predicate SUM(1) < id.
    SUM(1) is represented by an Item_aggregate_ref object in get_mm_tree().
    Since aggregation is [1;31mperf[mormed in the outer query, this item is an outer
    reference. get_mm_tree() will then call get_full_func_mm_tree() with
    the real_item() of the Item_aggregate_ref object as predicand, which is
    an Item_field. This Item_field represents a field in the temporary table
    allocated for grouping the outer table. But since this table has no
    assigned TABLE_LIST object, trying to calculate the map() for this table
    fails.
    
    However, this seems to be a legacy issue. Before WL#7540 was pushed,
    table map was 1. But this is actually an outer reference, so it was
    wrongly seen as a local table. Actually, being an outer reference, this
    item is const during evaluation of the inner query, so this is not a
    candidate for range optimizer analysis at all.
    
    The fix is just to skip the call to get_full_func_mm_tree() if the
    argument representing the Item_aggregate_ref is an outer reference.
    
    The problem was also identified for other predicate types like BETWEEN.
    Fix has been provided for this too, together with test cases.

[33mcommit 56731d709527a77ac473decda153a192e2049abf[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Mar 26 13:35:09 2015 +0200

    Implement growing of the lock free hash table
    
    With this change when the hash is filled up and needs to be extended, a
    new array is appended and the hash consists of two or more arrays.
    Search and insert operations are [1;31mperf[mormed on each array separately.
    
    When a new array is appended the data in the old one is not transferred
    to the new one. It is to be determined if this is necessary from
    [1;31mperf[mormance point of view (searching in more than one array is
    sub optimal).
    
    WL#7170 InnoDB buffer estimates for tables and indexes

[33mcommit 0b8f6a958b217de63d4ef049ae7990005cfc871c[m
Author: Olav Sandstaa <olav.sandstaa@oracle.com>
Date:   Fri Mar 6 13:58:45 2015 +0100

    Bug#19301539 TABLE IO INSTRUMENTATION LEAK IN DSMRR
    
    The reported problem with leak of [1;31mperf[mormance schema instrumented
    table handles is already fixed. This patch is a small refactoring of
    the interaction between the DsMrr_impl class and the handler class to
    reduce the likelihood of introducing similar resource leaks:
    
    Refactoring:
    
    -The DsMrr_impl class is no longer declared as a friend of the handler class
     to avoid that it can use protected functions of the handler class (which
     was the main reason for the resource leak)
    -Removed all use of non-public functions and variables in the handler class
     from the DsMrr_impl class
    -Ensure that the handler class always completely initializes the DsMrr_impl
     object before it is used

[33mcommit 9f24f1073c9117969fdfa7ae3c1472399d48061e[m
Merge: 067b2c0792f e70d82b42dc
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Mar 4 12:08:20 2015 +0100

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            storage/[1;31mperf[mschema/pfs_variable.h

[33mcommit 75a4dd88c2ee0774556934b7f352af649e145b4c[m
Author: Anitha Gopi <anitha.gopi@oracle.com>
Date:   Thu Feb 19 05:29:47 2015 +0100

    Bug#20083366  : RPL.RPL_PERFSCHEMA_APPLIER_STATUS FAILS IN TEST ASSERTION
    
    Removed rpl.rpl_[1;31mperf[mschema_applier_status from experimental group

[33mcommit 8eda771f49b061da84582ca0db20ac00d2a4a239[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Feb 12 16:16:27 2015 +0100

    Bug#20528224 MOVE KEY_MEMORY_XXX OUT OF MYSQLD.H
    
    Several files do #include mysqld.h
    in order to get one of the [1;31mperf[mormance schema key_memory_xxx identifiers.
    This increases coupling between otherwise independent components.
    
    Suggested Fix:
    Move all key_memory_xxx identifiers to a separate file.

[33mcommit 716906eadca3b4f27a97385aa499e974c7fb094f[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Wed Jun 18 09:47:56 2014 +0300

    WL#7806: Add a flat fil_sys_lookup[] array so that fil_spaces_lookup()
    can avoid acquiring fil_system->mutex when looking up the system tablespace
    or the undo tablespaces. This is addressing a [1;31mperf[mormance regression.
    
    Why not use a variable-size lookup structure such as std::map? Answer:
    Any dynamically sized data structure would require some locking (or
    atomics) around it, to prevent problems when there is concurrent
    modification to other elements while a lookup is in progress.
    
    In this patch, the fil_sys_lookup[] table will also be used for looking up
    the first user tablespaces whose space_id falls within the array boundaries.
For keyword optim:
[33mcommit aff803621af0189df5f337e9b85aeccceb594561[m
Author: Sreeharsha Ramanavarapu <sreeharsha.ramanavarapu@oracle.com>
Date:   Thu May 24 12:46:50 2018 +0530

    Bug #27998526 : FORCE INDEX DOESN'T TAKE EFFECT WHEN A
                    QUERY HAS GROUP_BY, ORDER_BY, AND LIMIT
    
    Issue:
    ------
    FORCE INDEX is ignored when a query has GROUP_BY, ORDER_BY,
    AND LIMIT.
    
    This problem doesn't occur GROUP BY or ORDER BY is removed.
    
    
    DDL and Query:
    --------------
    CREATE TABLE t1 (id INT NOT NULL AUTO_INCREMENT,
                     k INT,
                     PRIMARY KEY(id),
                     KEY idx_k (k));
    
    SELECT * FROM t1 FORCE INDEX (idx_k)
      WHERE k BETWEEN 2 AND 5
      GROUP BY id
      ORDER BY id LIMIT 0,1;
    
    Root cause:
    -----------
    Due to the presence of GROUP BY [1;31moptim[mizer adds clustered
    index to the set of possible keys
    (see add_group_and_distinct_keys()).
    
    test_if_order_by_key() then decides that "idx_k" can't
    provide ordering and that index is excluded from the list of
    potential indexes to be used by range [1;31moptim[mizer for
    ORDER BY. Since the only other option left is the clustered
    index, that is chosen.
    
    Solution:
    ---------
    If FORCE INDEX is set use only those indexes to check if
    they are relevant for ORDER BY. In this query, range
    [1;31moptim[mizer won't be called since there is no relevant index
    (since "idx_k" doesn't include the column "id").
    
    In 5.7, this was fixed as part of WL#6986.

[33mcommit a4ea462626bcc28a20ab84f1ed3f788d6c41965d[m
Author: Sachin Agarwal <sachin.z.agarwal@oracle.com>
Date:   Thu May 17 16:53:30 2018 +0530

    Bug #27326796 - MYSQL CRASH WITH INNODB ASSERTION FAILURE IN
    FILE PARS0PARS.CC
    
    Problem:
    As part of bug #24938374 fix, dict_operation_lock was not taken by
    fts_[1;31moptim[mize_thread while syncing fts cache.
    Due to this change, alter query is able to update SYS_TABLE rows
    simultaneously. Now when fts_[1;31moptim[mizer_thread goes open index table,
    It doesn't open index table if the record corresponding to that table is
    set to REC_INFO_DELETED_FLAG in SYS_TABLES and hits an assert.
    
    Fix:
    If fts sync is already in progress, Alter query would wait for sync to
    complete before renaming table.
    
    RB: #19604
    Reviewed by : Jimmy.Yang@oracle.com

[33mcommit 0df3af6ad29667970f75a6abe9af75a424ddb777[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed May 2 15:20:38 2018 +0200

    Bug#27944624 COMPILE WARNING OF UNINITIALIZED VARIABLE
    
    This patch fixes misc compiler/linker warnings when building with
    gcc 8.0.1 at [1;31moptim[mization level -O3
    
    Change-Id: I5ddd011ac933c6d933204630d28c5ec7c1e7955f

[33mcommit c58c6f8f66ddd0357ecd0c99646aa6bf1dae49c8[m
Author: Aakanksha Verma <aakanksha.verma@oracle.com>
Date:   Fri May 4 15:53:13 2018 +0530

    Bug #27155294   MAX_EXECUTION_TIME NOT INTERUPTED WITH FULLTEXT SEARCH
    USING MECAB
    
    PROBLEM
    
    While running select with [1;31moptim[mizer hint -> max_execution_time to return
    the count of rows using the column that is primary key,the query doesn't
    get interrupted after the max_execution_time is reached.
    Optimizer does some [1;31moptim[mization to fetch count of rows without actually
    searchin of rows if the column in count expression can never be NULL .
    Since there is no trx interruption check inside fts [1;31moptim[mize query the
    query isn't interrupted.
    
    FIX
    
    Add an interruption check in the long running fts_ast_visit function so
    that query gets interrupted as expected.
    
    Reviewed by: Jimmy Yang<Jimmy.Yang@oracle.com>
    RB: 19490

[33mcommit d446af569ad1495ed17a6abbda32ab989500b951[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Apr 19 11:46:24 2018 +0800

    Bug#27755892 - CRASH IN ROW_SEL_FIELD_STORE_IN_MYSQL_FORMAT_FUNC
    
    This is a regression from this commit: ef20b9. The cause is that with
    the changes in aforementioned commit, [1;31moptim[mizer supports 'using index'
    for some LIKE queries on a prefix index, including the virtual index.
    Before this change, this kind of query will go with table scan.
    So the assertion in row_sel_field_store_in_mysql_format_func() is
    somehow bogus now. So the fix is to screen out the case that the field
    is a virtual column. In case of a virtual column, it just ignores the
    field prefix length checking.
    
    RB: 19455
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 2f4b5915607f4b45ffb9d874b6eabba24fe55aa3[m
Author: Pedro Figueiredo <pedro.figueiredo@oracle.com>
Date:   Thu Apr 12 17:44:24 2018 +0100

    Bug#27442477 ASSERT `THD->GET_HA_DATA...HAS_STATE(XID_STATE::XA_ACTIVE))' AT HANDLER.CC:1396
    
    Description
    -----------
    With filter being set on slave, if non-filtered transaction comes post `XA
    ROLLBACK` then it results into ASSERTION failure
    `thd->get_ha_data(ht_arg->slot)->ha_ptr_backup == __null ||
    (thd->get_transaction()->xid_state()-> has_state(XID_STATE::XA_ACTIVE))` at
    handler.cc:1396 in trans_register_ha.
    
    Analysis
    --------
    The replication of empty XA transaction is not currently supported due to the
    "read-only [1;31moptim[mization" covered in the X/Open XA transaction standard.
    Furthermore, the usage of replication filters together with XA transaction is
    also not supported.
    
    The assertion occurs because the data engine plugins that initialize Ha_data
    and are called upon `XA START`, are not properly called back to release
    resources, after `XA PREPARE`, due to the transaction being emptied upon
    applying replication filters. One possible reason for this is that the filtered
    statements are not skipped, instead, they are applied but with no actual impact
    either in the data engine or the binlog.
    
    In addition, the internal state of the data engine transaction is changed when
    using `*-log-info-repository=TABLE`, since the `current_thd` is used to perform
    the system tables update.
    
    All of the above leaves the replication transaction context state inconsistent
    with the data engine native transaction state, leading, either to the above
    assertion being emited or a segmentation fault being hit when the engine plugin
    tries to use the internal transaction.
    
    This problem is present in 5.7 but it got visible in 8.0.5 because of WL#10474
    making `*-log-info-repository=TABLE` the default options.
    
    Fix
    ---
    This patch doesn't solve the overall issue, dealing with XA transactions working
    together with replication filters. Instead, adds an error message warning about
    the unsupported features and adds some validations that will allow the slave to
    continue running without the stated assertion being met, although in an
    undetermined state:
    
    1. Output an error message stating the unsupported feature of using XA
       transactions together with replication filters.
    
    2. Mirror acquisition of `THD` transaction data - `detach_*` functions - when
       reliquishing the same transaction data - `attach_*` functions - and use this
       execution flow when the `Ha_trx_info` has been cleared and is `nullptr`, in
       `xa.cc: attach_native_trx()`.
    
    3. In the engine data plugin function handling attaching and detaching of the
       native transaction, allow for an empty state, meaning, include a state where
       the current `THD` doesn't have any native transaction associated - output of
       using tables to store the metadata.

[33mcommit 96057437026aca80cb563fbb5096e34b5d173441[m
Author: Pedro Figueiredo <pedro.figueiredo@oracle.com>
Date:   Thu Apr 12 17:38:59 2018 +0100

    Bug#27442477 ASSERT `THD->GET_HA_DATA...HAS_STATE(XID_STATE::XA_ACTIVE))' AT HANDLER.CC:1396
    
    Description
    -----------
    With filter being set on slave, if non-filtered transaction comes post `XA
    ROLLBACK` then it results into ASSERTION failure
    `thd->get_ha_data(ht_arg->slot)->ha_ptr_backup == __null ||
    (thd->get_transaction()->xid_state()-> has_state(XID_STATE::XA_ACTIVE))` at
    handler.cc:1396 in trans_register_ha.
    
    Analysis
    --------
    The replication of empty XA transaction is not currently supported due to the
    "read-only [1;31moptim[mization" covered in the X/Open XA transaction standard.
    Furthermore, the usage of replication filters together with XA transaction is
    also not supported.
    
    The assertion occurs because the data engine plugins that initialize Ha_data
    and are called upon `XA START`, are not properly called back to release
    resources, after `XA PREPARE`, due to the transaction being emptied upon
    applying replication filters. One possible reason for this is that the filtered
    statements are not skipped, instead, they are applied but with no actual impact
    either in the data engine or the binlog.
    
    In addition, the internal state of the data engine transaction is changed when
    using `*-log-info-repository=TABLE`, since the `current_thd` is used to perform
    the system tables update.
    
    All of the above leaves the replication transaction context state inconsistent
    with the data engine native transaction state, leading, either to the above
    assertion being emited or a segmentation fault being hit when the engine plugin
    tries to use the internal transaction.
    
    This problem is present in 5.7 but it got visible in 8.0.5 because of WL#10474
    making `*-log-info-repository=TABLE` the default options.
    
    Fix
    ---
    This patch doesn't solve the overall issue, dealing with XA transactions working
    together with replication filters. Instead, adds an error message warning about
    the unsupported features and adds some validations that will allow the slave to
    continue running without the stated assertion being met, although in an
    undetermined state:
    
    1. Output an error message stating the unsupported feature of using XA
       transactions together with replication filters.
    
    2. Mirror acquisition of `THD` transaction data - `detach_*` functions - when
       reliquishing the same transaction data - `attach_*` functions - and use this
       execution flow when the `Ha_trx_info` has been cleared and is `nullptr`, in
       `xa.cc: attach_native_trx()`.
    
    3. In the engine data plugin function handling attaching and detaching of the
       native transaction, allow for an empty state, meaning, include a state where
       the current `THD` doesn't have any native transaction associated - output of
       using tables to store the metadata.

[33mcommit f5017c9a6fd197372dc5c6ffb86d422d26183121[m
Author: Sreeharsha Ramanavarapu <sreeharsha.ramanavarapu@oracle.com>
Date:   Tue Apr 10 06:03:18 2018 +0530

    Bug #27389294: INCORRECT BEHAVIOR WITH DATETIME COLUMN AND
                   QUERY REQUIRING SORTING
    
    Issue:
    ------
    This problem occurs under the following conditions:
    1) A select query is required to do an "open table"
       (i.e. it follows a FLUSH TABLE or it is the first query
        to access that table).
    2) ORDER BY ... LIMIT's presence mandates sorting.
    3) A DATETIME column is used for ref-access.
    
    Root cause:
    -----------
    1) While [1;31moptim[mizing a subquery with ORDER BY:
       a) it is decided that every evaluation of the subquery,
          for every outer row, will use a ref access and a
          filesort.
       b) ref access is set up for WHERE (the referenced value
          is a column of the outer query).
       c) a filesort is set up; this filesort wants to
          implement the ref access too, for this it calls
          get_quick_select_for_ref(); to read the referenced
          value.
    
    2) my_datetime_packed_from_binary() is reached through
       store_key_field::copy_inner() while checking the number
       of rows the ref-access might return.
    
       copy_field.from_field -> (field object of t1_a.c3)
       copy_field.to_field   -> (to object of t1_b.c3)
    
    my_datetime_packed_from_binary() sees a junk value for
    t1_a.c3 is junk as no row of the outer table t1_a has been
    read yet. It is an invalid DATETIME value.
    
    Why does this problem not occur with every other statement?
    For most DML statements empty_record() / restore_record()
    is called at some point and a valid DATETIME value is
    placed in the record buffer.
    
    What about SELECT statements?
    SELECT queries call empty_record() / restore_record() only
    in the execution phase, after the plan is created.
    
    Solution:
    ---------
    Calling cp_buffer_from_ref() during the [1;31moptim[mization phase
    is unsafe because it might access an uninitialized column.
    So remove the call to this function from
    get_quick_select_for_ref(). The actual ref value isn't
    required to create a QUICK_RANGE object anyway.

[33mcommit 4524b5f8da014b2d40932cc3c7095c3ac53dd282[m
Author: Annamalai Gurusami <annamalai.gurusami@oracle.com>
Date:   Wed Apr 4 20:31:40 2018 +0530

    WL#11328 InnoDB: Optimizing Small Changes to BLOBs
    
    This is a follow up worklog for WL#8960.  In WL#8960, the minimum
    change to a BLOB is a single LOB page.  Even if only a few bytes are
    modified, minimum one LOB page will be modified.  So, there is scope
    for improvement for small changes to the BLOBs.
    
    The solution provided by WL#8960 is a general solution suitable for
    all sizes of BLOBs and for all size of changes (from few bytes to even
    1GB of changes).  But it is less efficient for small changes done to
    the BLOBs.  Also, in the case of WL#8960, the old versions of BLOBs
    are stored in the BLOB itself.  Undo log format is not changed.
    
    To [1;31moptim[mize small changes to the BLOBs, we plan to do the regular undo
    logging.  For this the undo log format needs to be changed.  When a
    BLOB is modified/updated, then we need to store the old and new
    portion of the BLOB in the undo log record.  Currently there is a
    restriction that the undo log record must fit within an undo log page.
    We need to perform our operation within that constraint.

[33mcommit 4f60979a2d6aa05338d48dbc4513eb93df6f8e2f[m
Author: Jakub Łopuszański <jakub.lopuszanski@oracle.com>
Date:   Wed Apr 4 12:46:23 2018 +0200

    BUG#27572937 USING VATS WITH SPATIAL INDEX CAN LEAD TO TRANSACTION NEVER BEING WOKEN UP
    
    - lock_use_fcfs now looks at particular lock, not just lock->trx, and checks its type. Only "regular" (non-predicate) row locks can use CATS now
    - creating a new MTR test which reproduces the most important problem
    - removal of unnecessary cleanup from MTR test
    - moving the requirement for DBUG_SYNC utility to the top of MTR file, as it wis required by all tests in that file
    - removal of lock_rec_enqueue_waiting declaration, which had no definition
    - removal of unused lock_table_get_n_locks
    - removal of unused variant of Lock_iter::for_each
    - removal of misleading comments about "next"<->"prev" for table locks which should have been removed in e47f04c145cf778b9ad47ad8957f42a6daaadd5b as part of https://clustra.no.oracle.com/orabugs/bug.php?id=21983865
    - adding ut_ad()s reflecting assumptions stated in comments or required for the code to run correctly (in particular in places which assume that a lock is not a predicate lock)
    - removal of unnecessary checking of conditions which were already checked a few lines above
    - a small [1;31moptim[mization to RecLock::lock_add so that the loop searching for a similar lock is only performed if we can actually use this similar lock (lock_type is not LOCK_WAIT)
    - removal of misleading comments about appending/splicing the grant list which have nothing to do with the actuall code nearby
    - removal of redundant trx argument from lock_rec_unlock_grant (it is always equal to lock->trx)
    - added some explanation for the special case for CATS in assert inside get_first_lock
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>

[33mcommit 3cdd6309d2f787c35102c36e7e48cff4eaf641eb[m
Author: Jakub Łopuszański <jakub.lopuszanski@oracle.com>
Date:   Tue Apr 3 15:12:03 2018 +0200

    BUG#27646322 RECLOCK::ADD_TO_WAITQ CALLS LOCK_UPDATE_AGE ON DB_DEADLOCK INFLATING TRX->AGE
    
    - two new MTR tests (appended to already existing suite/innodb/innodb_cats.test)
    - added DBUG_EXECUTE_IF required to verify that trx->age is now well behaving in above tests
    - change in RecLock::add_to_waitq, such that the lock_update_age is not called in case of DB_DEADLOCK
    - removal of the redundant wait parameter of lock_update_age
    - added C++11 [[ noreturn ]] attribute to ut_error,
    - removed unreachable code after ut_error
    - in particular removed the only use of DB_QUE_THR_SUSPENDED and thus simplified handling of lock_table
    - adjusted @return doxygen comments to reflect that DB_QUE_THR_SUSPENDED is now an impossible value
    - added some ut_ad asserts which verify that return value indeed matches the values advertised by @return documentation
    - [1;31moptim[mized lock_rec_add_to_queue by avoiding a search for similar lock, unless the type_mode permits reuse of a lock object
    - fixed a comment for lock_prdt_lock to reflect that it can return DB_SUCCESS_LOCKED_REC
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Marcin Babij <marcin.babij@oracle.com>

[33mcommit 1ffd7965a5edd7a0742dd1719f4cd4e03e12abce[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Mar 8 18:28:49 2018 +0100

    Bug#27558169 BACKPORT TO 5.7 BUG #26826272: REMOVE GCC 8 WARNINGS [noclose]
    
    MySQL 5.7 should compile warning-free (ie., maintainer mode should work)
    also with GCC 8.
    
    This is a backport of similar patches from current MySQL trunk.
    
    This patch fixes all warnings in [1;31moptim[mized build
    
    Change-Id: Ia157b96c019f056a16ba47f1f5c5ae4d03c1a19d

[33mcommit 4804928a3c9b45ae25d395645754041e0b7b7df8[m
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Thu Mar 15 12:10:35 2018 +0530

    Bug#25669553: MYSQLD_BOOTSTRAP_CMD ENV VARIABLE IS NOT RESET IF TEST HAD
                  BOOTSTRAP OPTIONS
    
    Post push fix:
    
    With the preliminary fix for this bug, the datadir is reinitialized
    each time after a test with bootstrap options in the opt file is run,
    to ensure the variable $MYSQLD_BOOTSTRAP_CMD is reset to its original
    value. However, that fix was not [1;31moptim[mal and now we save the original
    value of $MYSQLD_BOOTSTRAP_CMD and reset it after the test run.
    
    Change-Id: I2633e258d2dcf44e033d21d83654fd1641e72337
    
    Conflicts:
            mysql-test/mysql-test-run.pl

[33mcommit 27e74c6c9c5b8a49d1323f2e134ceb9292ea5a06[m
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Thu Mar 15 12:10:35 2018 +0530

    Bug#25669553: MYSQLD_BOOTSTRAP_CMD ENV VARIABLE IS NOT RESET IF TEST HAD
                  BOOTSTRAP OPTIONS
    
    Post push fix:
    
    With the preliminary fix for this bug, the datadir is reinitialized
    each time after a test with bootstrap options in the opt file is run,
    to ensure the variable $MYSQLD_BOOTSTRAP_CMD is reset to its original
    value. However, that fix was not [1;31moptim[mal and now we save the original
    value of $MYSQLD_BOOTSTRAP_CMD and reset it after the test run.
    
    Change-Id: I2633e258d2dcf44e033d21d83654fd1641e72337

[33mcommit 60a4c082402196cf331cc463bf32d0a7db8cc88e[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Mar 12 14:51:21 2018 +0100

    WL #11590: More flexible filesort [patch 10/10, Item_func_between]
    
    Small [1;31moptim[mization in Item_func_between, which for some reason started
    showing up more in the profiles after the previous patches.
    compare_between_int_result() is only used once per instantiation,
    so there's nothing to win by not inlining it.
    
    Change-Id: I1eb504b69e857063366466234f9968f6096cd77a

[33mcommit 7dc0e3841cbea20dd4d32e3dfd8f6b80eb275d6c[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Mar 12 14:51:20 2018 +0100

    WL #11590: More flexible filesort [patch 9/10, [1;31moptim[mistic sort key generation]
    
    Enable [1;31moptim[mistic sort key generation.
    
    With this change, we no longer end a filesort chunk when it is pessimistically
    out of space (ie., can no longer sustain a worst-case row). Instead, we simply
    start writing the row, and end the chunk only if it actually needed more space
    than the chunk had left (or if it was within a few bytes -- we can't always tell).
    
    This enables us to fit more rows into each chunk (for some cases, quite
    a lot of more rows, although the common case is much more modest), as most rows
    are not worst-case; even more so with the newer Unicode collations. Also,
    it significantly reduces the need for artificially limiting the worst-case
    size of rows through the max_sort_length variable; it is now only used for
    blobs of PAD SPACE collations, where we have to pad the sort lengths to the
    maximum size and the maximum size is by definition large. This means users
    can now ORDER BY things like JSON columns or large VARCHAR fields without
    having to worry that they get wrong results as sort keys are truncated.
    
    Note that this means that you can no longer ORDER BY <json> LIMIT <n>
    (or similarly, on a blob) and get ordering by priority queue, since the
    priority queue still is oriented around worst-case rows. Hopefully, this
    is not a very common use case, and getting actually correct results should
    more than weigh up for it.
    
    In the process, fix so that blobs get variable-length sort keys for
    NO PAD collations. (It would be possible to fix it in a separate commit
    earlier, but not without rewriting tests that would only need to be
    re-rewritten now, so it's easiest to do it in the same commit.)
    
    The unit tests for the filesort buffer have been completely rewritten,
    since the working of the buffer is so different now.
    
    Change-Id: I4c118dd7820549d47fad95e7bea7686cc7df619d

[33mcommit 08db920e283ffe70f4ecbea162e11f3f14dee487[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Mar 12 14:51:13 2018 +0100

    WL #11590: More flexible filesort [patch 4/10, [1;31moptim[mistic merge]
    
    The merge phase of filesort may need room for as much as 15 rows, since
    we need one row for each chunk and there could be as many chunks.
    However, the current code is too pessimistic, refusing to make a sort if
    there exists a possible scenario where this could fail (ie., 15 rows
    of maximum possible size).
    
    This is too pessimistic; most merges have only seven merge chunks or
    fewer, and most rows are not maximum size. Thus, just assume we're fine,
    and give an error if we actually get into the situation where we don't
    have room for a merged row. This means we could potentially be doing
    wasted work before giving out the error, but it is much friendlier for
    the common case where we actually have enough merge buffer.
    
    Change-Id: Idd37075c85f618e6434eb034a5a4a271e170340d

[33mcommit d4b28efd6ecb00ad922592cf4ff7e440837b82c5[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Mar 12 14:51:07 2018 +0100

    WL #11590: More flexible filesort [patch 1/10, MyISAM cleanup]
    
    Pre-cleanup: Remove an [1;31moptim[mization that is only applicable when reading
    sorted data from a MyISAM temporary table.
    
    Change-Id: If42e37b13b04abeea140b4a0514698e918a44a0d

[33mcommit 101204adb602c4f7000894927f787e9b5aecddda[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Mar 14 18:44:25 2018 +0100

    Bug#27692051 IBD2SDI.CC RUNTIME ERROR: DIVISION BY ZERO
    
    The corruption ratio is calculated as the number of corrupted pages
    divided by the number of pages that are not all-zeros. If all the
    pages are all-zeros, it is calculated as 0/0, which usually returns
    NaN or -NaN depending on compiler and [1;31moptim[mization levels.
    
    Clang's UBSAN warns that division by zero is undefined behavior.
    Return NaN directly if all the pages are all-zeros to avoid the
    undefined behavior.
    
    Change-Id: Idd64aea7d94efdef9cc7aa227eaee7d719bde81e

[33mcommit ebcf57c4f2a891a295cc605c24187aaa87f55753[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Wed Mar 14 15:13:08 2018 +0530

    Post-push fix for Bug#26073513
    
    Missed to record window_std_var_[1;31moptim[mized in the previous push

[33mcommit d401baf535a69d6f2a945229acecbfd5863c0a48[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Tue Mar 13 12:09:40 2018 +0530

    Bug#26073513: ALLOW ORDER BY WITH ROLLUP
    Bug#26640100: ALLOW DISTINCT WITH ROLLUP
    Bug#26073525: ALLOW GROUPING FUNCTION IN ORDER BY
    
    Changes done for Bug#26073513: ALLOW ORDER BY WITH ROLLUP
    ---------------------------------------------------------
    Parser:
    Removed error checks when ORDER BY is used WITH ROLLUP.
    
    Resolver:
    In SELECT_LEX::resolve_rollup(), as of now, mysql sets "maybe_null" to true
    for all the fields which refer to group by fields including arguments to
    functions. Along with this, it also sets "has_aggregation" for these functions
    to avoid creation of temp table items. As temp table comes into picture
    when order by is used with rollup, we cannot set "has_aggregation" to
    true (Also, " has_aggregation" is used to indicate if a function has an
    aggregate function as argument). We now set "has_rollup_field" to let the
    executor know if this function might generate a rollup NULL and the result
    should be calculated while writing ROLLUP data.
    
    Optimizer:
    Creation of ref_item_arrays for ROLLUP has been tweaked to work with temp
    tables.
    We have possibly two code flows for writing rollup data into temp table.
    First one being:
    JOIN::rollup_make_fields()
    change_to_use_tmp_fields()
    JOIN::end_write_group()
    JOIN::rollup_write_data()
    
    In ::rollup_make_fields, rollup's ref_item_arrays are created for each
    rollup level. These ref_item_arrays have
     1. Item_null_result objects in place of all the group_by field references
        as these will be replaced with NULL's for that level.
     2. New aggregation functions are added to sum_func_list to calculate
        super aggregates for this level
     3. The remaining objects point to the ref_item_slice that is output of
        join operation.
    The problem with using this ref_item_slice when we have temp tables, is
    that, we cannot evaluate having condition or calculate result of a
    function which needs rollup data. When rollup data is written into temp table,
    the ref_item_slice of join operations has already moved one row ahead in
    ::end_write_group (to check if the next group has started). So, what we
    need is a ref array, which reads fields from temp table to calculate
    the output of rollup. However the current rollup algorithm calculates
    its super aggregates along with the regular aggregations which take join
    results as input. So what is done now is to have a ref_array for each level
    with calculated super aggregates taking in join output, NULL's in place of
    group by fields that need to be NULL for this level and functions, fields
    which need to take input from the first temp table's ref_item_slice.
    
    As a result, what we have now is the following code flow:
    JOIN::rollup_make_fields()
    change_to_use_tmp_fields()
    switch_slice_for_rollup_fields()
    JOIN::end_write_group()
    JOIN::rollup_write_data()
    
    Second code flow for writing rollup data into temp file is as follows:
    change_refs_to_tmp_fields()
    JOIN::rollup_make_fields()
    JOIN::end_write_group()
    JOIN::rollup_write_data()
    
    In the above code path (mostly observed when using windowing functions),
    we create the first temp table where rollup will not be processed
    (Aggregation does not happen). In this case, we do not want to create new
    temp table fields for functions which need rollup data. So we check if a
    function's "has_rollup_field" is set (similar to has_aggregation()). If
    yes, we create a copy or return the same object.
    Note that we do not switch the slice as rollup_make_fields() itself creates
    the ref_item_array's for rollup with the current temp table fields.
    
    However, "having_condition" might get evaluated as part of the windowing
    function step instead of the current temp table's having_condition. This is
    a problem for GROUPING FUNCTION as it is evaluated based on the
    "Item_null_result" object's presence. Since rollup data gets written in the
    previous step, all the "Item_null_result" objects present in ref_arrays
    will be written as "Item_null" objects when saving the result to temp table.
    So what is done now is to call ::split_sum_func on "having_condition" if it
    has a GROUPING FUNCTION. We do this already if there are any aggregation
    functions.
    
    Along with this, changes were made to handle items becoming const_items
    after [1;31moptim[mizer decides that some of the tables can be const tables.
    rollup_process_const_fields() now happens once all the fields (including
    conditions)update their used_table_map() after reading const_tables.
    
    Executor:
    Having condition of QEP_TAB (current temp table) is evaluated in ::rollup_write_data
    instead of JOIN::having_condition.
    JOIN::rollup_write_data() now checks if a field or a function "has_rollup_result"
    to determine if ROLLUP NULL for this level needs to be written to temp table.
    Also, when ROLLUP is not used WITH ORDER BY, creation of copy_fields needed
    to be tweaked.
    
    Changes done for Bug#26640100: ALLOW DISTINCT WITH ROLLUP
    ---------------------------------------------------------
    
    Parser: Remove error checks for syntax where DISTINCT is present WITH ROLLUP
    
    Resolver: None
    
    Optimizer:
    Moving of "having_condition" as temp table condition needed to be changed
    as [1;31moptim[mizer needs to evaluate having condition once rollup data is written.
    
    An extra temp table is needed when DISTINCT is used with ROLLUP in
    certain cases.
    
    Some asserts are no more valid when DISTINCT is used WITH ROLLUP.
    
    Changes done for Bug#26073525: ALLOW GROUPING FUNCTION IN ORDER BY
    ------------------------------------------------------------------
    
    Parser- none
    
    Resolver - Allow grouping function in order by. Do not allow
    "update_used_table_map()" to make GROUPING function constant. If allowed,
    temp table objects will not get created.
    
    Optimizer - none
    
    Executor - none

[33mcommit 91c4d270b6e4d979485657c9fbc85c848402baba[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Mar 8 11:53:09 2018 +0100

    Bug#27589205 CALL TO FUNCTION COMPARE_FIELDS_BY_TABLE_ORDER
    
    Use void* for function arguments, and cast Item_field* in function body.
    
    compare_fields_by_table_order(Item_field*, Item_field*, void*) through
    pointer to incorrect function type 'int (*)(void *, void *, void *)'
    sql/sql_[1;31moptim[mizer.cc:3904: note: compare_fields_by_table_order(Item_field*,
    Item_field*, void*) defined here
        #0 0x34ac57d in base_list::sort(int (*)(void*, void*, void*), void*)
    sql/sql_list.h:278:13
        #1 0x49ad303 in substitute_for_best_equal_field(Item*, COND_EQUAL*,
    
    Change-Id: I4f5417304a24201682f32fc7631034de7aa62589

[33mcommit f395242622f638e09c3fd870bb39b30409cef49d[m
Author: Jakub Łopuszański <jakub.lopuszanski@oracle.com>
Date:   Mon Mar 5 10:44:20 2018 +0100

    Bug#27607235 LOCK_REC_HAS_TO_WAIT_VATS IGNORES LOCKS HELD BY TRANSACTIONS BEING ROLLED BACK
    
    - Renamed VATS (Variance-Aware Transaction Scheduling) to CATS (Contention...)
    - Added MTR include files which make it easier to test CATS
    - Added a MTR test which reproduces the bug
    - Removed an [1;31moptim[mization which ignored transactions being rolled back
    
    Reviewed-by: Sunny Bains<Sunny.Bains@oracle.com>
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    Reviewed-by: Pawel Olchawa <pawel.olchawa@oracle.com>

[33mcommit d35d1ccd65a8a7d45f2012b9cb177709c9e3f85f[m
Author: Jakub Łopuszański <jakub.lopuszanski@oracle.com>
Date:   Mon Mar 5 10:44:20 2018 +0100

    Bug#27607235 LOCK_REC_HAS_TO_WAIT_VATS IGNORES LOCKS HELD BY TRANSACTIONS BEING ROLLED BACK
    
    - Renamed VATS (Variance-Aware Transaction Scheduling) to CATS (Contention...)
    - Added MTR include files which make it easier to test CATS
    - Added a MTR test which reproduces the bug
    - Removed an [1;31moptim[mization which ignored transactions being rolled back
    
    Reviewed-by: Sunny Bains<Sunny.Bains@oracle.com>
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    Reviewed-by: Pawel Olchawa <pawel.olchawa@oracle.com>

[33mcommit b22b505af256851a613d28835254225a804efc5d[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Fri Mar 2 09:40:35 2018 +0100

    Bug#27403367: GENERATED COLUMN EXPRESSIONS IGNORED WITH PREFIX INDEX
    
    Post-push fix for failure in gcol_ndb.gcol_keys_ndb.
    
    NDB doesn't allow prefix indexes on BLOB-based columns, so change the
    type of the column in the test case from TEXT to VARCHAR.
    
    Also harmonize the checks for whether a column is indexed in
    substitute_gc() and substitute_gc_expression() to avoid some extra
    [1;31moptim[mizer trace output in the NDB test because the former thinks a
    column is eligible for substitution and the latter determines it's
    not.

[33mcommit 9d91d93efaa9627f8d6819a3334c9a8cd1968cd8[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Mon Feb 12 17:27:39 2018 +0100

    Bug #26826272: REMOVE GCC 8 WARNINGS [noclose server]
    
    This patch fixes all -Werror warnings of server code built in [1;31moptim[mized mode.
    It also removes _snprintf on windows, snprintf is now C99 standard compliant.
    
    Change-Id: Iafa5aa8d968d97bd2e7a3e39dda64bc308a3de31

[33mcommit 71ed510f5840e72c0a003a9d8b9e53d8dd495bdc[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Fri Jan 19 21:54:03 2018 +0100

    Bug#27403367: GENERATED COLUMN EXPRESSIONS IGNORED WITH PREFIX INDEX
    
    Generated columns with a prefix index are not considered when the
    [1;31moptim[mizer attempts to substitute expressions with an equivalent
    generated column. This prevents use of prefix indexes to speed up
    queries with predicates that use a generated column expression.
    
    This patch makes the [1;31moptim[mizer also consider the generated columns
    that have a prefix index.
    
    Change-Id: Id1b803a8ad39b334b0ef95e50c87f4a21c1d4065

[33mcommit 1e2894b8bae46f02d41269ac90265566993e7db5[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Fri Feb 23 11:02:20 2018 +0100

    Bug#27536421: SET PERSIST CHANGES THE VALUE OF OPTIMIZER_TRACE_OFFSET AFTER
                  RESTART
    
    Problem: Persisting @@[1;31moptim[mizer_trace_offset variable resulted in a wrong value
    after server restart.
    
    Analysis: During server restart the value of this persisted variable is treated
    as an unsigned integer which resulted in a wrong value.
    
    Fix: Fix is to consider this variable value as a signed integer during server
    restart.

[33mcommit 2a4b5619ea482e27eb0c2283681175dc19f35c3d[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Feb 21 17:50:49 2018 +0100

    WL#10310 Redo log [1;31moptim[mization: dedicated threads and concurrent log buffer.
    
    Post-push fix for clang warnings:
    
    storage/innobase/include/sync0sharded_rw.h:61:24: error: lambda capture
          'latch_level' is not used [-Werror,-Wunused-lambda-capture]
        for_each([pfs_key, latch_level](rw_lock_t &lock) {
    
    unittest/gunit/innodb/log0log-t.cc:482:8: error: lambda capture
          'max_dirty_page_age' is not required to be captured for this use [-Werror,-Wunused-lambda-capture]
          [max_dirty_page_age](size_t thread_no) {
    
    Change-Id: I94e89cf47101fd0d2224a1f0b1c41b5b0c0eae3f

[33mcommit 91a3b9b5575d23c168508f9ccda959ff9ea5dd69[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Feb 21 17:50:49 2018 +0100

    WL#10310 Redo log [1;31moptim[mization: dedicated threads and concurrent log buffer.
    
    Post-push fix for clang warnings:
    
    storage/innobase/include/sync0sharded_rw.h:61:24: error: lambda capture
          'latch_level' is not used [-Werror,-Wunused-lambda-capture]
        for_each([pfs_key, latch_level](rw_lock_t &lock) {
    
    unittest/gunit/innodb/log0log-t.cc:482:8: error: lambda capture
          'max_dirty_page_age' is not required to be captured for this use [-Werror,-Wunused-lambda-capture]
          [max_dirty_page_age](size_t thread_no) {
    
    Change-Id: I94e89cf47101fd0d2224a1f0b1c41b5b0c0eae3f

[33mcommit db3b4c462c1fb4e26e7f01141125223ffdbba54f[m
Author: Harin Vadodaria <harin.vadodaria@oracle.com>
Date:   Wed Feb 21 12:08:08 2018 +0100

    Bug#27335346: SYSBENCH CONNECT TEST SHOWS -14% REGRESSION
                  FOR ROOT USER WITOUT PASSWORD
    
    Description: Plugin lock [1;31moptim[mization were missing for
                 caching_sha2_password. This resulted into one
                 lock/unlock per connection.
                 This impacted performance.
    
    Solution: Lock built-in plugins at server startup and keep
              them locked till server shutdown. Also, use these
              plugin handles instead of going through
              lock/unlock at the time of connection.

[33mcommit 80976f88f2cd35f28a8320a40fa17da32723cc92[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Feb 15 17:15:36 2018 +0100

    WL#10310 Redo log [1;31moptim[mization: dedicated threads and concurrent log buffer.
    
    Post-push fixes for clang warnings:
    
    storage/innobase/buf/buf0flu.cc:437:20: error: unused function
          'buf_flush_list_order_validate' [-Werror,-Wunused-function]
    static inline bool buf_flush_list_order_validate(lsn_t earlier_added_lsn,
    
    storage/innobase/os/os0file.cc:314:23:
    error: missing field 'm_file' initializer
          [-Werror,-Wmissing-field-initializers]
      pfs_os_file_t file{0};
    
    storage/innobase/srv/srv0srv.cc:1954:16:
    error: unused function 'timeval_diff_us'
          [-Werror,-Wunused-function]
    
    Change-Id: I2eb1b8347ca7d041ce3c6ac3c0b3a635d5f4805a

[33mcommit 0b1b0b40408d0738ac41f3d1185f5b895730b265[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Feb 15 17:15:36 2018 +0100

    WL#10310 Redo log [1;31moptim[mization: dedicated threads and concurrent log buffer.
    
    Post-push fixes for clang warnings:
    
    storage/innobase/buf/buf0flu.cc:437:20: error: unused function
          'buf_flush_list_order_validate' [-Werror,-Wunused-function]
    static inline bool buf_flush_list_order_validate(lsn_t earlier_added_lsn,
    
    storage/innobase/os/os0file.cc:314:23:
    error: missing field 'm_file' initializer
          [-Werror,-Wmissing-field-initializers]
      pfs_os_file_t file{0};
    
    storage/innobase/srv/srv0srv.cc:1954:16:
    error: unused function 'timeval_diff_us'
          [-Werror,-Wunused-function]
    
    Change-Id: I2eb1b8347ca7d041ce3c6ac3c0b3a635d5f4805a

[33mcommit faa06483b91919790fb4dc489c1e2841ac1d4c18[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Thu Feb 15 16:29:53 2018 +0100

    Bug#24713879 ASSERTION `MAYBE_NULL' FAILED. HANDLE_FATAL_SIGNAL IN TEM_FUNC_CONCAT::VAL_STR
    
    We have an outer query and a subquery.
    Outer query's table is found empty at [1;31moptim[mization: this sets the
    table's column to NULL (table->set_null_row()) even though columns are
    defined as not nullable.
    Then when we [1;31moptim[mize the subquery, which sets up ref lookup using
    outer table's column as reference, and wants to evaluate it
    immediately as it's a constant CONCAT; but CONCAT didn't expect to see
    a NULL argument, as the column was not nullable at fix_fields() time.
    Solution:
    - don't [1;31moptim[mize subquery if outer query JOIN is known to have empty
    result (let EXPLAIN show "Not [1;31moptim[mized, outer query is empty").
    - there remains one case where subquery must be [1;31moptim[mized: it's if the
    outer query has aggregates without GROUP BY: then it has a non-empty
    result and any subquery in SELECT list must be evaluated and thus be
    [1;31moptim[mized, which reopens the issue
    - we detect that in is_null_on_empty_table() and mark the column as
    nullable. As it's done in fix_fields(), it properly propagates to
    CONCAT.

[33mcommit 6be2fa0bdbbadc52cc8478b52b69db02b0eaff40[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Wed Feb 14 09:33:42 2018 +0100

    WL#10310 Redo log [1;31moptim[mization: dedicated threads and concurrent log buffer.
    
    0. Log buffer became a ring buffer, data inside is no longer shifted.
    
    1. User threads are able to write concurrently to log buffer.
    
    2. Relaxed order of dirty pages in flush lists - no need to synchronize
       the order in which dirty pages are added to flush lists.
    
    3. Concurrent MTR commits can interleave on different stages of commits.
    
    4. Introduced dedicated log threads which keep writing log buffer:
        * log_writer: writes log buffer to system buffers,
        * log_flusher: flushes system buffers to disk.
       As soon as they finished writing (flushing) and there is new data to
       write (flush), they start next write (flush).
    
    5. User threads no longer write / flush log buffer to disk, they only
       wait by spinning or on event for notification. They do not have to
       compete for the responsibility of writing / flushing.
    
    6. Introduced a ring buffer of events (one per log-block) which are used
       by user threads to wait for written/flushed redo log to avoid:
        * contention on single event
        * false wake-ups of all waiting threads whenever some write/flush
          has finished (we can wake-up only those waiting in related blocks)
    
    7. Introduced dedicated notifier threads not to delay next writes/fsyncs:
        * log_write_notifier: notifies user threads about written redo,
        * log_flush_notifier: notifies user threads about flushed redo.
    
    8. Master thread no longer has to flush log buffer.
    
    9. Introduced dedicated log thread which is responsible for writing checkpoints.
       No longer concurrent user threads need to compete for this responsibility.
    
    10. Master thread no longer has to take care of periodical checkpoints.
        Log checkpointer thread writes checkpoint at least once per second
        (before it was once per 7 seconds).
    
    11. The following exposed system variables, can be changed in runtime now:
        * innodb_log_buffer_size,
        * innodb_log_write_ahead_size.
    
    12. Master thread measures average global cpu usage in OS.
    
    13. Introduced new exposed system variables:
        * innodb_log_wait_for_flush_spin_hwm,
        * innodb_log_spin_cpu_abs_lwm,
        * innodb_log_spin_cpu_pct_hwm.
        They control when we need to use spinning for the best performance,
        to reduce latency which would otherwise come from communication
        between log threads and user threads. The first one is based on
        average flush time, the two others are based on cpu usage.
    
    14. Introduced new CMake option: ENABLE_EXPERIMENT_SYSVARS=0/1. System variables
        can be marked as hidden unless the experiment mode is turned on.
    
    15. There is a list of hidden new system variables for experiments with redo log.
        We skip listing them here.
    
    16. Created dedicated tester for redo log alone (as gtest).
    
    17. Created doxygen documentation for the new redo log.
    
    18. The dict_persist margin is updated when number of dirty pages is
        changed, instead of calculations on demand.
    
    19. Mechanism used to copy last incomplete block for Clone has been changed,
        because log buffer is concurrent now.
    
    20. Added more useful MONITOR counters for redo, including average lsn rate.
    
    21. Introduced sharded rw-lock to have an option to stop the world in redo,
        because log_mutex is removed.
    
    22. Invented and implemented a concurrent data structure which tracks progress
        of concurrent operations and can answer up to which point they all have been
        finished (when there is some order defined but they are allowed to be executed
        out of the order). This structure is used for concurrent writes to log buffer
        and re-used for concurrent additions to flush lists.
    
    23. Introduced a universal mechanism to wait on event, which starts with
        provided number of spin delays, then fallbacks to waits on event,
        starting at small timeout, but increasing timeout every few waits.
        This mechanism is used in communication between user and log threads,
        and in communication between different log threads.
    
    24. We slow-down redo log writer when there is no space in redo allowing
        checkpoints to progress and rescue the state of redo.
    
    25. Log buffer can be resize in runtime - the size can also be decreased.
    
    26. Simplified shutdown procedure to avoid a possible returns in logic
        to previous phases.
    
    27. Removed concept of multiple log groups.
    
    28. Relaxed conditions required for checkpoint_lsn. It can now point to
        any data byte within redo (does not need to point to a records group
        beginning).
    
    29. Windows: always use buffered IO for redo log.
    
    30. Mysql test runner received a new feature (thanks to Marcin):
        --exec_in_background.
    
    Review: RB#15134
    
    Reviewers:
        - Marcin Babij <marcin.babij@oracle.com>,
        - Debarun Banerjee <debarun.banerjee@oracle.com>.
    
    Performance tests:
        - Dimitri Kravtchuk <dimitri.kravtchuk@oracle.com>,
        - Daniel Blanchard <daniel.blanchard@oracle.com>,
        - Amrendra Kumar <amrendra.x.kumar@oracle.com>.
    
    QA and MTR tests:
        - Vinay Fisrekar <vinay.fisrekar@oracle.com>.

[33mcommit 3621beefb6213a5a7706d1c7a1968b43c4529524[m
Author: Erik Froseth <erik.froseth@oracle.com>
Date:   Tue Feb 6 16:53:28 2018 +0100

    Bug#27499518 CHANGE THE HIDDEN ATTRIBUTE FOR COLUMNS TO AN ENUM
    
    In order to implement functional indexes, we need to mark a column as hidden
    from users. We already have a field named "hidden" for columns, but it hides
    the column completely from the [1;31moptim[mizer. We need have a column that is
    visible to the [1;31moptim[mizer, but invisible to the user.
    
    This bugfix change the field "hidden" from a BOOL to
    ENUM('Visible', 'SE', 'SQL'), so we can have different levels of visibility.
    This will also make it more consistent with the field "hidden" for tables,
    which already is an ENUM.
    
    Change-Id: Id4289ee6b4a88cb94dc4099349d1f09a2002f5a0

[33mcommit 28eac338d3593de8a4d0a74b2d11014ce9cbed35[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Fri Feb 2 15:01:09 2018 +0100

    Bug#27484133    WINDOW FUNCTIONS COULD READ LESS ROWS FROM TEMPORARY TABLE
    
    A refactoring of the logic of how window functions buffer rows and
    re-reads them from the frame buffer.
    This reduces the count of calls to handler::rnd_pos() by 25%.
    During this refactoring, other things have been cleaned up:
    - more comments in code
    - if user didn't specify a frame, create a frame of
    RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW (if there is ORDER BY
    in window), or
    BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING (sql_yacc.yy)
    This allows to eliminate quite few tests like "if frame==nullptr".
    - changed signature of create_tmp_table() to make it less
    window-ish: the last parameter (enum TMP_WIN*) is removed,
    because it's possible to infer its value from other information:
    we now give a non-zero Temp_table_param::m_window only if it's
    the OUT table, not the frame buffer; so testing m_window is equivalent
    to testing TWP_WIN_CONDITIONAL; not_all_columns is also used, as tmp
    tables which don't care for windowing have it false. Thus,
    enum_tmpfile_windowing_action is removed.
    - when we want to calculate FIRST/LAST/NTH_VALUE without
    modifying the current value of other aggregates, instead of evaluating
    other aggregates but with a "dont_aggregate" flag, we don't evaluate
    them (see CFT_WF_USES_ONLY_ONE_ROW)
    - "dynamic frame upper bound" strategy was for
    RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ;  instead, let it flow
    into the normal range-framing code, but still with a couple of if()s
    here and there to keep [1;31moptim[mizations (see range_to_current_row and
    range_from_first_to_current_row)
    - cleaning up of some ref slices was missing (cleanup_item_list)
    - setup_tmp_table_write_func: "phase" can be inferred from
    qep_tab->ref_item_slice
    - saving/restoring special records FBC_FIRST_IN_STATIC_RANGE
    and FBC_LAST_RESULT_OPTIMIZED_RANGE was useless, as WF values
    of previous row are still present in OUT table.
    - sometimes we ask to fetch row N from frame buffer, and do the same
    shortly after; added Window::m_row_has_fields_in_out_table
    which keeps track of the last row fetched, so bring_back_frame_row()
    can consult this variable to know it doesn't really have to fetch
    it a second time.
    - m_input_row_clobbered was there to avoid a fetch in case
    the input row hadn't been clobbered; now that we have
    m_row_has_fields_in_out_table we can ask for a fetch unconditionally:
    if row hasn't been clobbered it won't actually be fetched.
    - introduced Window:m_needs_card to avoid recalculation of this info
    for every row (some_wf_needs_frame_card() is thus removed).
    - make "static aggregate" and "row inversion" and "range inversion"
    mutually exclusive
    - setup_windows(): merged prepared-stmt and non-prep-stmt init
    branches as much as possible
    - short-circuiting of last tmp table: made it apply to more cases
    (e.g. if SQL_BUFFER_RESULT and two windows, short-circuit is
    now possible)
    - mgmt of special records moved out of buffer_record_somewhere() for
    separation of concerns
    - it was common to call bring_back_frame_row() then copy_fields();
    made the former call the latter.
    - in process_buffered_windowing_record: if range frame, set
    upper_limit to INT64_MAX; this is clearer than having
    some_wf_needs_frame_card() return true if range frame (had the same
    effect, but was more hidden).
    - thanks to the caching in bring_back_frame_row(), two_pass_done logic
    is not needed anymore; removed; only one call to
    process_wfs_needing_card() is necessary in code.
    - reestablish_new_partition_row() removed
    - end_write_wf(): moved an if() up so that we have less nested blocks
    - The number of rnd_pos() calls is reduced as announced; but this is
    not tested in MTR, as numbers vary by a few units, depending on if
    test is run alone or not, with prep-stmt or not; so the SHOW STATUS
    are added to window_functions.test but commented out.

[33mcommit 98bd4c636ae68dd2978497e61a88f9f5caf443e3[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Jan 19 11:18:54 2018 +0100

    Bug #26826272: REMOVE GCC 8 WARNINGS [noclose innodb_memcached]
    
    Silence all warnings when building innodb_memcached, by adding -Wno-xxx.
    
    Also fix a few warnings in mysys, so that we can now do a clean build:
    cd plugin/innodb_memcached; make
    In both debug and [1;31moptim[mized mode.
    
    Change-Id: I59232d1af2db3b9ad2efbc79bf1abf2289f9da29

[33mcommit 10c3663cdd1b0d55f259e036b71bf8873faab292[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Wed Jan 17 19:46:25 2018 +0200

    Bug #27270498: DROPPING A UDF FUNCTION DOES NOT REMOVE ENTRY FROM PFS TABLE
    
    Fixed a UDF reference leak in the [1;31moptim[mizer when handling errors.
    
    Added a test case.

[33mcommit dd1231e84dd3a030efa750e3871788182b805efd[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Jan 26 15:52:08 2018 +0100

    Bug #26826272: REMOVE GCC 8 WARNINGS [noclose innodb]
    
    This patch fixes warnings in innodb code in debug and [1;31moptim[mized mode.
    
    $/usr/lib/gcc-snapshot/bin//g++ --version
    g++ (Debian 20180107-1) 8.0.0 20180107 (experimental) [trunk revision 256322]
    
    Error classes fixed are:
    -Werror=array-bounds
    -Werror=cast-function-type
    -Werror=class-memaccess
    -Werror=format-truncation
    -Werror=sizeof-pointer-memaccess
    -Werror=stringop-truncation
    
    Change-Id: Ied9f34309558ddb9fe3e574b40c7b94ce1961205

[33mcommit 60b703951cb62fca79ffec4db15d576efce7ec3f[m
Author: Allen Lai <zheng.lai@oracle.com>
Date:   Thu Jan 18 09:04:27 2018 +0800

    Bug#27353468 OPTIMIZE TRX_RW_IS_ACTIVE() BY TRACKING THE LOWEST ACTIVE TRANSACTION ID
    
    Problem:
    It's a [1;31moptim[mization patch from contributor. It [1;31moptim[mized the checking in
    trx_rw_is_active.
    
    Fix:
    This patch add a new member variable in trx_sys to store the minimal active trx
    id. And in trx_rw_is_active, when the input trx id is smaller than the minimal
    active trx id, just return and skip following step, like acquire trx_sys->mutex,
    etc..
    
    Reviewed-By: Bin Su <bin.x.su@oracle.com>
    RB: 18452

[33mcommit deae1c585fd3596a9e07138deca96332383f41dc[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Jan 5 13:51:59 2018 +0100

    Bug #27348547: MINOR FILESORT CLEANUPS [MyISAM]
    
    Stop adding a special-case [1;31moptim[mization for MyISAM in filesort,
    as MyISAM is largely obsolete.
    
    Change-Id: I7b5d10f8cf903fe9f78757436b2bb4e13bbdd110

[33mcommit 029cdf430d34355c7d104b354b7f2e06180776d0[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Mon Jan 15 18:48:49 2018 +0800

    Fix some compile warnings in [1;31moptim[mized mode build, basically the
    Wmaybe-uninitialized warnings.
    
    Reviewed by Sunny Bains <Sunny.Bains@oracle.com> over IM.

[33mcommit 1bd8998f32c1a62d4e1a6066dedc428f6bb6ee87[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Jan 11 10:52:03 2018 +0100

    Bug#27184567 QUERYING REPLICATION PERFORMANCE SCHEMA TABLES VIA INDEXES
    GIVES WRONG RESULTS
    
    Before this fix,
    queries on performance_schema.replication_* tables
    sometimes returned incorrect results (missing rows),
    in particular when the query execution path used an index.
    
    For example in particular, where clauses involving the
    CHANNEL_NAME columns failed to return rows matching
      WHERE CHANNEL_NAME = ''
    which is the default channel name.
    
    With this fix, the implementation of every index
    on every performance_schema.replication_* table
    has been investigated, and the following bugs
    were identified and corrected.
    
    1) Column CHANNEL_NAME.
    
    Background:
    
    In the performance schema in general,
    a record value is rarely represented by both
    - a null bit
    - a value
    
    Instead, a record value is typically represented by
    a single attribute (for example m_thread_id),
    with the special meaning that m_thread_id == 0
    represents a NULL column, not a 0 column.
    
    Bug:
    
    WHERE CHANNEL_NAME = '' does not return matching rows.
    
    Root cause:
    
    The default channel name is represented by a string,
    with a length of 0.
    
    When using an index, method
      PFS_key_name::match()
    is called to decide if a record matches the index condition.
    
    When processing a CHANNEL_NAME = '' record,
    PFS_key_name::match() considers that the record is a NULL
    column instead, so that the where clause is evaluated as
      WHERE NULL = ''
    which is false, discarding the record.
    
    Fix:
    
    Implement a new method
      PFS_key_name::match_not_null()
    which considers a record of length 0 to be an empty string,
    and use this in every index implementation involving
    a CHANNEL_NAME column.
    
    2) Column THREAD_ID
    
    Bug:
    
    Conditions
      WHERE THREAD_ID IS NULL
      WHERE THREAD_ID IS NOT NULL
    are not implemented properly,
    resulting in
    - missing matching rows
    - extra non matching rows
    
    Root cause:
    
    Some index implementations,
    for example:
      PFS_index_rpl_applier_status_by_coord_by_thread::match()
    evaluate the record THREAD_ID value,
    and discard NULL THREAD_ID as non matching,
    without even looking at the index key condition.
    
    The code causing this is:
    
        if (row.thread_id_is_null)
        {
          return false;
        }
    
    This is incorrect, because when the key search is actually
      WHERE THREAD_ID IS NULL
    records with a NULL should be matching, not discarded.
    
    Fix:
    
    Do not attempt to evaluate conditions in table index ::match() methods,
    and always delegate the index evaluation to the underlying
    key, as in:
    
        if (!m_key.match(row.thread_id))
        {
          return false;
        }
    
    This allows the PFS_key::match() logic to determine matches,
    which turns out to use a complex logic,
    to account for NULL in columns and or keys.
    
    3) Table replication_applier_status_by_worker, primary key.
    
    Bug:
    
    The primary key for this table is
      PRIMARY KEY (CHANNEL_NAME, WORKER_ID)
    aka, it has two parts.
    
    The index on the second part, WORKER_ID, is not working.
    
    Root cause:
    
    PFS_index_rpl_applier_status_by_worker_by_channel::match()
    only implements filtering for the CHANNEL_NAME part,
    as in:
    
      if (m_fields >= 1)
      {
        ... read the channel name value ...
        ... match the channel name key part ...
      }
    
    The second part
    
      if (m_fields >= 2)
      {
        ... read the worker id value ...
        ... match the worker id key part ...
      }
    
    is simply missing in the code.
    
    Fix:
    
    Implemented the second key part (WORKER_ID) in the index.
    
    3) Table replication_applier_status_by_worker, index iteration
    
    Background:
    
    This table logic is more complicated than other replications tables,
    because the table exposes at the same time:
    - data for Single Thread Slave, reporting 1 thread per channel
    - data for Multi Thread Slave, reporting many threads per channel,
      with each worker thread.
    
    Bug:
    
    table_replication_applier_status_by_worker::index_next()
    is not iterating properly for this table.
    
    Root cause:
    
    The ::index_next method implements two separate scans:
    - a scan using m_applier_pos / m_applier_next_pos
    - a scan using m_pos / m_next_pos
    
    This is flawed, as the storage engine interface in general,
    and the interactions with the [1;31moptim[mizer in particular,
    expects only one concept of position per table.
    
    The position used was only m_pos,
    per the table constructor:
    
    table_replication_applier_status_by_worker::
      table_replication_applier_status_by_worker()
      : PFS_engine_table(&m_share, &m_pos), <-- here
        m_pos(),
        m_next_pos(),
        m_applier_pos(0),
        m_applier_next_pos(0)
    {
    }
    
    The m_applier_pos attribute was not part of the table "position".
    
    Beside, the record length ("ref length") was wrong,
    using sizeof(PFS_simple_index) while m_pos is a double index,
    causing even more bugs when iterating.
    
    Fix:
    
    Define a single position concept for this table,
    pos_replication_applier_status_by_worker.
    
    Rewrite ::index_next to only use one position, not two.
    
    Define a pos_t typedef, and use sizeof(pos_t) for "ref length".
    
    4) Table replication_connection_status, THREAD_ID index.
    
    Bug:
    
    The index by THREAD_ID is not working properly.
    For example
      WHERE THREAD_ID = <the THREAD_ID of a record>
    fails to match the record.
    
    Root cause:
    
    On one hand, the logic to build the record,
      table_replication_connection_status::make_row()
    uses:
      mi->info_thd
    to find the THREAD_ID value.
    
    On the other hand, the logic to evaluate the index,
      PFS_index_rpl_connection_status_by_thread::match()
    uses:
      mi->rli->info_thd
    to find the THREAD_ID value.
    
    This points to a different thread, and returns a
    different THREAD_ID, so that an index on THREAD_ID
    does not match its own record.
    
    Fix:
    
    PFS_index_rpl_connection_status_by_thread::match()
    uses the same logic as
    table_replication_connection_status::make_row(),
    pointing to the same thread.
    
    5) Misc code cleanup
    
    a)
    
    Systematically define a pos_t typedef per table,
    and use sizeof(pos_t) for ref length,
    to have more maintainable code and avoid
    incorrect lengths.
    
    b)
    
    Remove incorrect uses of MY_ATTRIBUTE((unused))
    
    6) Test suite
    
    Implemented missing tests,
    to enforce that tables return the same data
    with and without an index:
      performance_schema.idx_compare_replication_*.test
    
    Systematically tested the following conditions:
    - key_part IS NULL
    - key_part IS NOT NULL
    - key_part = '' (for CHANNEL_NAME)
    - key_part != '' (for CHANNEL_NAME)
    - key_part = <expected existing value>, for example for THREAD_ID.

[33mcommit a5c15f5911987b05fa926303d91376f18da5fd88[m
Author: Nuno Carvalho <nuno.carvalho@oracle.com>
Date:   Tue Jan 9 11:32:11 2018 +0100

    BUG#27016053: REGRESSION IN BINLOG_LOG_ROW INTRODUCED BY ADD_PKE
    
    Group Replication plugin is a multi or single primary replication
    solution, on which members do execute transactions [1;31moptim[mistically
    and at commit time they decide, if conflicts happen, which must
    commit or rollback.
    The conflict detection is based on the write-sets of each
    transaction, which is collected along the transaction life when it
    does a update.
    During detailed performance analysis it was discovered that there
    were non-[1;31moptim[mized memory allocations and memory copy operations on
    the write-set extraction.
    
    In order to solve the performance regression, the following actions
    were made:
     1) [1;31moptim[mize memory allocation;
     2) reduce memory copy operations;
     3) only collect foreign key write-sets when the current table has
        foreign keys.

[33mcommit 2987079abfe37e120433e20e6d0ef8a9fb1a198b[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Dec 20 12:13:06 2017 +0100

    Bug#27294450    VALGRIND: BYTES_SENT() DETECT UNINITIALIZE MEMBER SEND_BUFFER::M_SENDING_SIZE
    
    The member variables m_buffered_size and m_sending_size was not initialized in send_buffer_init().
    Could possibly cause incorrect 'send buffer usage levels' to be calculated, which in
    turn could cause un[1;31moptim[mal send scheduling polizies to be used.
    
    Patch init them.

[33mcommit ca40b503918109b91bd5765907282af9f85bc403[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Tue Dec 12 23:17:27 2017 +0100

    Bug#22475473: CRASH AFTER HEAP-BUFFER-OVERFLOW IN MY_UTF32_GET
    
    When the range [1;31moptim[mizer computes the prefix of a long string, it may
    truncate the string in the middle of a character. This could lead to
    assertion failures and the server exiting.
    
    The fix is to make sure the string is truncated at a character
    boundary.
    
    Change-Id: I477966b1ccf0a1d8e44ae06b15775d88b7107124

[33mcommit 7bb3a7131508d25b26753085de6141ef32ba7189[m
Author: Gleb Shchepa <gleb.shchepa@oracle.com>
Date:   Fri Dec 8 14:59:54 2017 +0400

    Bug#27189940: CREATE VIEW FAILS ON JSON_TABLE() IN SCHEMA-LESS CONNECTIONS
    
    Patch author: Roy Lyseng
    
    The problem is that CREATE VIEW performs a privilege check for all
    underlying tables of the view's query expression. However, the JSON
    table function is an [1;31moptim[mizer internal table that has no entry in
    the ACL structures. Note that we already skip privilege checking for
    derived tables and assign SELECT privileges for such tables. We can
    simply extend this test to include all [1;31moptim[mizer internal tables,
    like table functions and recursive references.
    
    We also add a bool is_internal() interface to class TABLE_LIST that is
    used for checking the privilege requirements.
    Note that we might actually use this interface more places, but that is
    beyond the scope of this bug fix.
    
    Change-Id: Ib79f1798af00f4ef1a592be2912046c5ae74b98d

[33mcommit 5d7eb6605a1400d90a0434446ea6e3e08437635b[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:38:57 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    and
    
    Bug#25128512 SET RR WITH >1 NG FAILS DUE TO 'WE(1) HAVE BEEN DECLARED DEAD BY 2 (VIA 4)'
    
    Patch fixes race conditions related to asynchronous disconnect / reconnect
    of the transporter while there could be other threads concurrently
    inserting signal data into the send buffers.
    
    A ::reset_send_buffer() was performed as part of a disconnect, and
    we required the send buffers to still be empty when we later reconnect.
    When this failed, we could either hit the '!has_data_to_send' assert,
    or we received malicous data which had survived the disconnect.
    
    This patch introduce a number of changes to the Transporter implementations
    in order to fix the insufficent concurrency controll:
    
    1)
     The virtual TransporterCallback method reset_send_buffer() is
    replaced with the methods enable_send_buffer() / disable_send_buffer().
    As part of this an 'enabled' state is also introduced in each implementation
    of the TransporterCallback. This enable us to discard any thread local
    send buffers which are 'late' in being appended to a disabled transporter.
    
    1a)
     Enable and disabling of send buffers has been moved into the
    Transporter::connect* methods instead of having them in the
    TransporterRegistry::report_connect/_disconnect. The *receivers*
    are inited here as their connection state is protected by the
    poll right. However, the poll right gives no such protection
    for the send buffers. (Added a large comment about this)
    
    Thus, it feels more correct to handle
    the send buffers where the transporters are connected.
    
    1b)
     The method has_data_to_send() was removed as part of 1). As any
    'data_to_send' could later be discarded by disabling a node, it
    didn't really make sense to check for 'has_data' is it could
    immediately go away before doSend or whatever. Similar logic has
    instead been added to get_bytes_to_send_iovec(), where we with necessary
    locks held can collect (or discard) send buffer to doSend().
    
    2) Added the TransporterSendBufferHandle interface method ::isSendEnabled().
    It replace the usage if Transporter::isConnected() where this method was
    used in a 'send context'. isSendEnabled() provides us with a thread safe
    way of checking if send is enabled for a specific 'send handle'.
    
    2a) Usage of Transporter::isConnected in TransporterRegistry::prepareSend()
    is replaced with ::isSendEnabled().
    
    2b) Defined a 'synchronized' (client threads) or '[1;31moptim[mistic' (data nodes)
    implementation of ::isSendEnabled(). The 'synchronized' implementation
    should be the 'safe' implemetation which Transporter::isConnected() never
    was. This provides us with a thread safe way of checking the connectivity
    to a specific node. (API clients)
    
    2c) Datanodes (both mt- and non-mt) never really cared about a SEND_DISCONNECTED
    error from prepareSend() as it was ignored in the SimulatedBlock::sendSignal()
    methods. (Handled as SEND_OK together with SEND_BLOCKED). So an '[1;31moptim[mistic'
    ::isSendEnabled() is implemented here. (A 'synchronized' implememtation
    with have required taking a mutex, which we probably cant afford)
    Any send buffers allocated data to disabled nodes are discarded by the
    frequent doSend() calling get_bytes_to_send_iovec()

[33mcommit e4942b663f3b81e4c4669a729cd9c114dda0b7df[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:38:57 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    and
    
    Bug#25128512 SET RR WITH >1 NG FAILS DUE TO 'WE(1) HAVE BEEN DECLARED DEAD BY 2 (VIA 4)'
    
    Patch fixes race conditions related to asynchronous disconnect / reconnect
    of the transporter while there could be other threads concurrently
    inserting signal data into the send buffers.
    
    A ::reset_send_buffer() was performed as part of a disconnect, and
    we required the send buffers to still be empty when we later reconnect.
    When this failed, we could either hit the '!has_data_to_send' assert,
    or we received malicous data which had survived the disconnect.
    
    This patch introduce a number of changes to the Transporter implementations
    in order to fix the insufficent concurrency controll:
    
    1)
     The virtual TransporterCallback method reset_send_buffer() is
    replaced with the methods enable_send_buffer() / disable_send_buffer().
    As part of this an 'enabled' state is also introduced in each implementation
    of the TransporterCallback. This enable us to discard any thread local
    send buffers which are 'late' in being appended to a disabled transporter.
    
    1a)
     Enable and disabling of send buffers has been moved into the
    Transporter::connect* methods instead of having them in the
    TransporterRegistry::report_connect/_disconnect. The *receivers*
    are inited here as their connection state is protected by the
    poll right. However, the poll right gives no such protection
    for the send buffers. (Added a large comment about this)
    
    Thus, it feels more correct to handle
    the send buffers where the transporters are connected.
    
    1b)
     The method has_data_to_send() was removed as part of 1). As any
    'data_to_send' could later be discarded by disabling a node, it
    didn't really make sense to check for 'has_data' is it could
    immediately go away before doSend or whatever. Similar logic has
    instead been added to get_bytes_to_send_iovec(), where we with necessary
    locks held can collect (or discard) send buffer to doSend().
    
    2) Added the TransporterSendBufferHandle interface method ::isSendEnabled().
    It replace the usage if Transporter::isConnected() where this method was
    used in a 'send context'. isSendEnabled() provides us with a thread safe
    way of checking if send is enabled for a specific 'send handle'.
    
    2a) Usage of Transporter::isConnected in TransporterRegistry::prepareSend()
    is replaced with ::isSendEnabled().
    
    2b) Defined a 'synchronized' (client threads) or '[1;31moptim[mistic' (data nodes)
    implementation of ::isSendEnabled(). The 'synchronized' implementation
    should be the 'safe' implemetation which Transporter::isConnected() never
    was. This provides us with a thread safe way of checking the connectivity
    to a specific node. (API clients)
    
    2c) Datanodes (both mt- and non-mt) never really cared about a SEND_DISCONNECTED
    error from prepareSend() as it was ignored in the SimulatedBlock::sendSignal()
    methods. (Handled as SEND_OK together with SEND_BLOCKED). So an '[1;31moptim[mistic'
    ::isSendEnabled() is implemented here. (A 'synchronized' implememtation
    with have required taking a mutex, which we probably cant afford)
    Any send buffers allocated data to disabled nodes are discarded by the
    frequent doSend() calling get_bytes_to_send_iovec()

[33mcommit d6bf2b19f240e60c8c86240c61748b75b4019655[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:38:57 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    and
    
    Bug#25128512 SET RR WITH >1 NG FAILS DUE TO 'WE(1) HAVE BEEN DECLARED DEAD BY 2 (VIA 4)'
    
    Patch fixes race conditions related to asynchronous disconnect / reconnect
    of the transporter while there could be other threads concurrently
    inserting signal data into the send buffers.
    
    A ::reset_send_buffer() was performed as part of a disconnect, and
    we required the send buffers to still be empty when we later reconnect.
    When this failed, we could either hit the '!has_data_to_send' assert,
    or we received malicous data which had survived the disconnect.
    
    This patch introduce a number of changes to the Transporter implementations
    in order to fix the insufficent concurrency controll:
    
    1)
     The virtual TransporterCallback method reset_send_buffer() is
    replaced with the methods enable_send_buffer() / disable_send_buffer().
    As part of this an 'enabled' state is also introduced in each implementation
    of the TransporterCallback. This enable us to discard any thread local
    send buffers which are 'late' in being appended to a disabled transporter.
    
    1a)
     Enable and disabling of send buffers has been moved into the
    Transporter::connect* methods instead of having them in the
    TransporterRegistry::report_connect/_disconnect. The *receivers*
    are inited here as their connection state is protected by the
    poll right. However, the poll right gives no such protection
    for the send buffers. (Added a large comment about this)
    
    Thus, it feels more correct to handle
    the send buffers where the transporters are connected.
    
    1b)
     The method has_data_to_send() was removed as part of 1). As any
    'data_to_send' could later be discarded by disabling a node, it
    didn't really make sense to check for 'has_data' is it could
    immediately go away before doSend or whatever. Similar logic has
    instead been added to get_bytes_to_send_iovec(), where we with necessary
    locks held can collect (or discard) send buffer to doSend().
    
    2) Added the TransporterSendBufferHandle interface method ::isSendEnabled().
    It replace the usage if Transporter::isConnected() where this method was
    used in a 'send context'. isSendEnabled() provides us with a thread safe
    way of checking if send is enabled for a specific 'send handle'.
    
    2a) Usage of Transporter::isConnected in TransporterRegistry::prepareSend()
    is replaced with ::isSendEnabled().
    
    2b) Defined a 'synchronized' (client threads) or '[1;31moptim[mistic' (data nodes)
    implementation of ::isSendEnabled(). The 'synchronized' implementation
    should be the 'safe' implemetation which Transporter::isConnected() never
    was. This provides us with a thread safe way of checking the connectivity
    to a specific node. (API clients)
    
    2c) Datanodes (both mt- and non-mt) never really cared about a SEND_DISCONNECTED
    error from prepareSend() as it was ignored in the SimulatedBlock::sendSignal()
    methods. (Handled as SEND_OK together with SEND_BLOCKED). So an '[1;31moptim[mistic'
    ::isSendEnabled() is implemented here. (A 'synchronized' implememtation
    with have required taking a mutex, which we probably cant afford)
    Any send buffers allocated data to disabled nodes are discarded by the
    frequent doSend() calling get_bytes_to_send_iovec()

[33mcommit 1ccf42b77c14b171cc089d922ffede70834e8636[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Fri Dec 1 18:37:26 2017 +0100

    Bug#27205252: VALGRIND: UNINITIALIZED VALUE IN COPY_FIELD::GET_COPY_FUNC
    
    When running the json_conversions test under Valgrind with release
    binaries, a "Conditional jump or move depends on uninitialised
    value(s)" warning is raised by Valgrind for the following statement:
    
    create table t_geo select DISTINCT(_geo) FROM at;
    
    This is a false positive caused by an [1;31moptim[mization in GCC. Valgrind is
    correct that uninitialized memory is read, but it is only done because
    the compiler is reordering statements after it has been able to prove
    that reading possibly uninitialized memory won't affect the result.
    The Valgrind documentation says that such false positives can happen
    with high [1;31moptim[mization levels.
    
    It is an [1;31moptim[mization in Nullable<gis::srid_t>::operator==() that
    triggers the warning. The code checks that both the Nullable objects
    contain a value before it tries to compare their values, but the
    compiler seems to lay out code that compares the values before the
    code that checks if they contain a value.
    
    This patch silences the Valgrind warning by using value-initialization
    instead of default-initialization of Nullable::m_value when no value
    has been provided.
    
    Change-Id: Ibb039cfc45020ece4b295193d9d8c46c4da9103d

[33mcommit de3b3e93b351b060382d8e4f3ff51547d036f0ed[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Thu Nov 23 18:57:21 2017 +0100

    Bug#27041323 INNODB: ASSERTION FAILURE: REM0REC.CC:372:LEN <= COL->LEN || ((COL->MTYPE)==5...
    
    The problem is that the SHOW TABLE STATUS command asserts in
    InnoDB when we set "SET big_tables=1" and "SET
    character_set_connection=ucs2".  This seem to be a sporadic
    problem.
    
    The root cause of the problem is a effect of fix for
    Bug#25793429. The bug was fixed by enabling following UDFs
          GET_DD_CREATE_OPTIONS,
          INTERNAL_GET_COMMENT_OR_ERROR,
          GET_DD_COLUMN_PRIVILEGES
    to use connection collation, avoiding them to be treated as
    binary string by [1;31moptim[mizer. However, we see that MySQL 5.7
    uses system charset for I_S.TABLES columns that show create
    options, comment and privileges.
    
    The fix is to make 8.0 behave the same as 5.7 by using
    system charset for the above mentioned UDFs and few others
    UDFs used by I_S system views.
    
    A test case is added in main.information_schema.
    
    Change-Id: Ib99e20218f94d2724e325060bfb08aa5d4ee1c5f

[33mcommit 476f4f4ea0616db78a110453c900e817cf76dafe[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Mon Nov 27 15:32:56 2017 +0100

    Bug#27041526 assertion `mon > 0 && mon < 13' failed.
    
    The problem is that, when the value of a timestamp field is
    used as argument to IF() condition in SQL, its
    datatype/value changes based on the setting of variable
    collation_connection.  More details of this issue is
    reported in Bug#27143384. This bug will be fixed independent
    of fix for this bug. The root cause of core dump is that the
    value of mysql.table_stats.cached_time is treated as a
    string value, when collation_connection is set to
    utf32_general_ci.  Converting this string version of
    timestamp into a integer value gives us a invalid longlong
    timestamp value. When we use this wrong timestamp value to
    get MYSQL_TIME, we end-up getting invalid date values and
    assert.
    
    The expression which hits the issue in Bug#27143384 is,
    "IF(ISNULL(timestamp_field), 0, timestamp_field)". This
    patch uses COALESCE() which suite better. Part of problem
    was the [1;31moptim[mizer by default converts the timestamp fields
    into strings.  And the IF() resulted in automatic conversion
    to integer only in certain charset (as discussed in
    bug27143384). In order to avoid depending on implicit
    conversions, this patch uses CAST() to explicitly request
    the timestamp value as a unsigned value. This code change
    can be a permanent change, and need not really be reverted
    back after Bug#27143384 is fixed.
    
    The patch also sets null_on_null property for UDF's as
    false. The UDF return's NULL as soon as it sees one of it's
    argument is NULL. This change is not really required for
    the fix in hand. However, this change was expected to be done
    for UDF's implemented in I_S as per [1;31moptim[mizer's suggestions
    in past. The test case contains a SELECT with TABLE_ROWS
    column in WHERE condition, which demonstrates the problem.
    
    The patch also sets the few other internal I_S functions
    with Functype as DD_INTERNAL_FUNC. This was a omission
    when I_S.FILES system view was implemented.
    
    A new test case is added to main.information_schema.
    
    Change-Id: I6904103094c288958af46b6c203a726c31b3093d

[33mcommit a2e09bfd11d0940b6908760437d875c6b91c5bd9[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Mon Nov 27 15:32:45 2017 +0100

    Bug#26770836 SLAVE HANGS - WAITING FOR TABLE METADATA LOCKS
    
    A DDL on table would trigger change in view metadata update.
    We acquire MDL locks on view and the dependent tables during
    this process. We release these acquired locks just after
    finishing the view metadata update, and we do not hold the
    MDL lock until the statement is committed.
    
    An expectation from binary log subsystem is that it assumes
    all MDL acquired by the statement are held till commit
    phase, so two statements acquiring conflicting sets of locks
    can't be committed at the same time. This assumption is
    broken by release-before-commit [1;31moptim[mization done during
    view metadata update.
    
    This patch enables MDL locks acquired during view metadata
    update to be held until commit. A test case is added to make
    sure we acquire lock after view metadata is updated. The test
    case for Bug#25685371 is removed as we no more release locks
    at the end of view metadata update, and the problem reported
    there cannot occur.
    
    Change-Id: I3757428fc01788b9314a961b5fd2f83830811485

[33mcommit 79dd88f1f608387c3ef92ea2acdc95933d695f7f[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Nov 22 10:31:00 2017 +0100

    Bug #27130109: REMOVE OPTIMIZER_TRACE COMPILATION FLAG
    
    We have a CMake flag OPTIMIZER_TRACE=0 to turn off compilation of
    [1;31moptim[mizer trace into the binary. However, this has no visible performance
    impact or any other known advantage (sysbench run showed less than <1%
    difference, which is probably noise), so just remove it.
    
    Change-Id: I242122607e81b7921c1b2ecbc87e3417e3e2e084

[33mcommit 868bf19464f0ab566106ccb8e050ff240481ae77[m
Author: Erik Froseth <erik.froseth@oracle.com>
Date:   Wed Oct 25 08:57:59 2017 +0200

    Bug#27015964 USELESS SPATIAL INDEX CAN BE CREATED WITHOUT WARNING
    
    After the SRID column attribute was introduced (WL#8592), the query
    [1;31moptim[mizer refuses to consider spatial indexes over columns without the SRID
    attribute. Thus, we should raise a warning when a user creates a spatial
    index over a SRID-less column. This patch adds this warning, and adjusts
    a good amount of MTR tests to include the SRID attribute in order to
    avoid having a lot of warnings in the test files.
    
    Change-Id: Idd1b5560328191f66078c6d861921df067fc37fb
    (cherry picked from commit 8c11442ccb3330abb53e97c48bd56b63f5a99e2d)

[33mcommit b382f3935c07e6a64dd1145f4f3219f591090c8b[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Thu Oct 26 01:47:58 2017 +0200

    WL#8069
    More work on ndb_print_backup_file
    More paths coverage tested
    Various debug flags reset
    
    We relied on that the GCI received in START_NODE_LCP_REQ could
    be used as maxGciCompleted. This wasn't true since we could be
    in the final phase of a local LCP as part of the restart at this
    point in time. Given that this was merely an [1;31moptim[misation, the
    code to check this variable was simply removed to ensure that
    even if slightly more GCIs have to be executed during restarts,
    the restarts will be much safer.

[33mcommit c21ddf5c3affdb48a3d15c57a7e7c5cac428eb7a[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Thu Nov 2 10:17:07 2017 +0100

    WL#11345: Increase default value of [1;31moptim[mizer_trace_max_mem_size
    
    The value of this variable is increased from 16kB to 1MB.

[33mcommit 496fc6f544e2714213686a3315b2c682c9b1309e[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Nov 10 15:21:36 2017 +0100

    Bug#22591899: FILE HANDLE LEAK WHEN SETTING SLOW LOG IN MULTIPLE CONNECTIONS.
    
    Post-push fix: unused variable warning in [1;31moptim[mized mode.

[33mcommit 4ddcec6abfe077bdffc599b8974f3f58a8b970f9[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Nov 3 14:38:15 2017 +0100

    Bug#27067538 EXPLAIN OF PUSHED 'MATERIALIZED' JOINS CRASH DUE TO NULL-PTR DEREFERENCING
    
    Explain'ing of join pushdown may encounter unused QEP_TABs. These has a
    'table() == NULL' reference set up (among other unused member variables).
    
    The pattern elsewhere in the [1;31moptim[mizer code is to simply ignore such QEP_TABs,
    which we also does in this patch.
    
    Patch is required by the MysqlCluster patch for bug#27022925,
    SPJ: 'MATERIALIZED' SEMI JOINS ARE NOT CONSIDDERED FOR JOIN PUSHOWN which
    enables join pushdown for more variants of semi joins. As this other patch is
    required for provoking this bug, this patch has no testcase included.
    However, a testcase will be available as part of bug#27022925 patch.
    
    (cherry picked from commit f7b0771b38ae685d192abbe65bf31263e484df94)

[33mcommit 2661366244c319a3cdb7d0cbf92f5d8270122dfb[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Nov 3 14:38:15 2017 +0100

    Bug#27067538 EXPLAIN OF PUSHED 'MATERIALIZED' JOINS CRASH DUE TO NULL-PTR DEREFERENCING
    
    Explain'ing of join pushdown may encounter unused QEP_TABs. These has a
    'table() == NULL' reference set up (among other unused member variables).
    
    The pattern elsewhere in the [1;31moptim[mizer code is to simply ignore such QEP_TABs,
    which we also does in this patch.
    
    Patch is required by the MysqlCluster patch for bug#27022925,
    SPJ: 'MATERIALIZED' SEMI JOINS ARE NOT CONSIDDERED FOR JOIN PUSHOWN which
    enables join pushdown for more variants of semi joins. As this other patch is
    required for provoking this bug, this patch has no testcase included.
    However, a testcase will be available as part of bug#27022925 patch.

[33mcommit 38fa3934264412e83adadb263adca5a7c13b858e[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Nov 8 13:04:25 2017 +0100

    bug#26984919 Addendum patch
    
    Testcases added for this bug didn't enable the required [1;31moptim[mizer switches to allow
    the hinted semijoin strategies to be used. Thus, 'DEPENDENT SUBQUERY' plan was choosen
    instead, which was not what we wanted to test for the MTR test ndb_join_pushdown_none.test.

[33mcommit 84091e8d346f6399d72031e297250cff9e3c877c[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Tue Nov 7 09:28:21 2017 +0800

    Bug #25694140  THE IMPLEMENTATION OF QUERYING P_S.REPLICATION_APPLIER_FILTERS IS SUBOPTIMAL
    
    When querying performance_schema.replication_applier_filters or
    performance_schema.replication_global_applier_filters tables,
    it generates a view on the filters for every row that is
    created. This is sub[1;31moptim[mal.
    
    We implement the best approach to make sure that the P_S view over
    the filters is generated only when the filters are changed. To
    per-channel replication filters, actually increasing counter does
    not change the structure of the P_S view. So we should hold the
    write lock of rpl_channel_filters to generate the P_S view only on
    startup, on CHANGE REPLICATION FILTER, on RESET SLAVE ALL, and on
    CHANGE MASTER to ..., then we just need to hold a read lock of
    rpl_channel_filters to read the P_S view while querying
    P_S.replication_applier_filters. To global replication filter,
    we should hold the write lock of Rpl_global_filter to generate
    its P_S view only on startup and on CHANGE REPLICATION FILTER,
    then we just need to hold a read lock of Rpl_global_filter to read
    its P_S view while querying P_S.replication_applier_global_filters.
    At the same time, we [1;31moptim[mize the code to create a derived class
    of class Rpl_filter for global replication filter and fix a prone
    issue.

[33mcommit 9df4a76c172c45412f6100009c286a2fd2795acf[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Nov 3 09:37:23 2017 +0100

    Bug #27022925 SPJ: 'MATERIALIZED' SEMI JOINS ARE NOT CONSIDDERED FOR JOIN PUSHOWN
    
    The 'Materialized' part of a semi join execution was represented in such a way
    that it was not even 'visible' for the code evaluating the pushability
    if a query plan.
    
    The pitfall turned out to be that there are two slightly different
    'counts' representing the number of tables in a query plan,
    'primary_tables' and 'tables'. It turns out that the 'primary_tables'
    did not include the materialized tables in its count.
    
    This patch change the init of table 'count' in the class Join_plan
    to use 'tables' instead of 'primary_tables'. The materialized
    part of the query plan will then become visible.
    
    As a side effect some 'non-real' (temporary) tables added by the
    [1;31moptim[mizer also becomes visible. Thus the patch also added check
    for 'table() != NULL' a couple of places in order to ignore
    such non-real tables.

[33mcommit 376861a183e1243bf2c8eb4265ca114a4cb84f3f[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Mon Oct 30 16:28:05 2017 +0100

    Bug#27041288: ASSERTION FAILURE:
                  ROW0SEL.CC:3955:PREBUILT->MYSQL_PREFIX_LEN <= RECORD_BUFFER..
    
    If a table contains a column whose length is zero, the [1;31moptim[mizer may
    allocate a record buffer that is too small to hold the columns read by
    the query. This leads to an assert failure in debug builds.
    
    The [1;31moptim[mizer looks for the last column accessed by the query in order
    to find out how much space it needs for each record. To find the last
    column, it compares the pointers to the beginning of each of the
    columns. When one of the columns has zero length, two columns may have
    the same start position. Since the algorithm doesn't have any
    tie-breaker for this case, it may end up returning the second to last
    column instead of the last column.
    
    The fix is to compare the end of the column instead of the beginning
    of the column, since it is the end that is interesting when
    calculating the minimum space needed for a record.
    
    Change-Id: Iadc3a0782dd3bcc553993eeb4ecc4b42b0fc07fa

[33mcommit c2ab508888c1e47788211824300c0e09ecc71bf7[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Tue Oct 17 11:01:50 2017 +0200

    Bug#26436185 Assertion 'buf_is_inside_another(data_in_mysql_buf, ...)
    
    The problem occurs when there is a materialized semi-join operation
    that is evaluated more than once, and one of the tables in the
    materialization is a const table (with join type JT_CONST).
    In second materialization, when the const table is referenced, invalid
    data are accessed, and when these data are shipped to the Temptable
    storage engine, a data validation fails and an assert is raised.
    
    After materialization is done, in debug mode, the contents of the input
    tables are trashed in join_materialize_semijoin(). However, const tables
    (with join type JT_CONST, JT_SYSTEM and JT_EQ_REF - the latter when
    keys are unchanged) are not reread on later materialization, thus
    trashing their contents is incorrect.
    
    The fix is to skip trashing of data for const tables.
    
    The test case for this bug is added to a new test file subquery_bugs,
    which is designated for bugs in subquery operations that need
    a specific set of [1;31moptim[mizer switches to hit.
    
    The test case only checks the JT_CONST join type. The other handled
    join types may be theoretical only.

[33mcommit baae2e2e3f3f40e2ebac0d34a2fe102698a29f05[m
Author: Erik Froseth <erik.froseth@oracle.com>
Date:   Wed Oct 25 08:57:59 2017 +0200

    Bug#27015964 USELESS SPATIAL INDEX CAN BE CREATED WITHOUT WARNING
    
    After the SRID column attribute was introduced (WL#8592), the query
    [1;31moptim[mizer refuses to consider spatial indexes over columns without the SRID
    attribute. Thus, we should raise a warning when a user creates a spatial
    index over a SRID-less column. This patch adds this warning, and adjusts
    a good amount of MTR tests to include the SRID attribute in order to
    avoid having a lot of warnings in the test files.
    
    Change-Id: Idd1b5560328191f66078c6d861921df067fc37fb

[33mcommit 556d45deb2d3c8180c5df483f056b0fe53bf82fb[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Tue Oct 24 22:32:59 2017 +0200

    Bug#26188578 Bug#26164633 Bug#26360114 Bug#26781725 Bug#26848089 Regressions with WL#9236
    
    Bug#26188578 WL#9603: HAVING CONDITION IS OPTIMIZED OUT FOR ALIAS ON AGGREGATE W/O GROUP BY
    Bug#26164633 WL#9603: WRONG RESULT WHEN PARTITION EXPR USING AGGREGATES EVALUATES TO NULL
    Bug#26360114 WRONG RESULT WITH AGGREGATE AND HAVING CLAUSE IN VIEW
    Bug#26781725 INCORRECT RESULTS FOR QUERY(MAX FUNC+HAVING CLAUSE) WHEN USED INSIDE VIEW
    Bug#26848089 LEAD/LAG WINDOW FUNCTIONS ON QUOTED JSON STRINGS RETURNS SAME VALUE FOR ALL ROWS
    
    Regressions introduced by changes to Item_ref done in the patch for
    window functions (WL#9236).
    
    Background of existing design before the WL of window functions:
    
    - Item_ref is very old design which was introduced for SQL clause
    HAVING, when HAVING references an item of the SELECT list through an
    alias. It points to an Item ('ref' pointer). When there is a tmp table
    involved in the execution (e.g. GROUP BY before HAVING), we may
    calculate a SELECT list expression (let's say it's an Item_func) and
    store it in the tmp table in the group's row. The
    tmp table's column where it's stored is known as the Item's result_field.
    If HAVING references that expression through an alias, HAVING contains
    Item_ref with a 'ref' pointing to the Item_func. When evaluating
    HAVING, we want to use the already calculated value of Item_func
    (_not_ evaluating the Item_func again, as it may not be deterministic),
    we do that by looking at the value stored in ref->result_field.
    That is why Item_ref::val_int calls ref->val_int_result(), not
    val_int().
    - So the system is relying on the capacity of Item_ref to
    automatically pick the stored value.
    - While that sounds ok for queries with no or only one tmp table, it
    is not enough for more complex queries
    - hence, a second design: "ref item slices": in different phases of
    execution (simply: depending on which table, tmp or non-tmp,
    we're reading now), a same SELECTed expression is represented by
    different Items: it may be SUM initially (Item_sum), then, once
    calculated (with Item_sum::val_int()) and stored in a tmp table with
    one row per group, it becomes Item_field (a column of the tmp
    table). After all groups have been written, if a filesort is used
    to do a final ORDER BY, that sort must call the Item_field's val_int,
    not the Item_sum::val_int which is just the value of the last group.
    - So, depending on which table we're reading now, the SELECTed
    expression is one object or another; for that, we wrap the expression
    in Item_ref, with 'ref' pointing to a place (a cell in the "ref item
    slice"), and at this place we deposit a pointer either to the original
    Item_sum or to the tmp table's Item_field, depending on the phase
    we're in.
    Phases are identified by numbers (grep for the REF_SLICE enum).
    
    With the advent of window functions, more tmp tables are used, and
    form a chain. The fact that Item_ref::val_int always reads ref->result_field
    (i.e. what was saved in the next tmp table) sometimes leads to reading
    not-yet-calculated data from the next tmp table.
    For example, if we have an Item_func I_F, and a tmp table used for windowing,
    and we have an Item_ref I_R to the I_F (HAVING always creates an
    Item_ref), and before the tmp table is written we use I_R::val_int,
    that gets the value of I_F->result_field, reading random data from the
    tmp table. Such I_R::val_int() (or val_int_result(), equivalently)
    could occur in filesort(), for example.
    HAVING is one problem; but the ORDER BY clauses of windowing also use
    Item_ref; and aggregate functions also do (if involved in a more
    complex expression, see Item::split_sum_func2). Aggregate functions
    may be used as arguments to windows, so, depending on the phase,
    Item_ref should pick the aggregate function's value or its saved
    value, which it can't do. The behaviour of Item_ref of "always reading
    the result_field", combined with the increased number of tmp tables,
    made things harder to manage than they used to be.
    
    So things are refactored in this patch:
    - Item_ref::val_(int,etc)() just calls ref->val_(int,etc)(), doesn't
    read ref->result_field anymore
    - when you are reading QEP_TAB Q and want to evaluate an expression
    which depends on values stored in Q and previous tables in the
    execution order, switch to Q->ref_item_slice slice: it will switch to
    Items which point into Q's table.
    - when you are doing a GROUP BY where grouped rows are not
    materialized in a tmp table (because rows are produced in group order
    by the join), a pseudo-tmp table buffer is used (no change here); if
    you want to evaluate an expression which depends on values
    stored in this buffer, use the REF_SLICE_TMP3 slice.
    - the reads above include: sorting the table, evaluating a condition
    on the table, etc.
    
    Changes:
    
    All val_*result() are removed.
    So Item_ref::val_(int,etc) calls ref->val_(int,etc), not
    val_result. Thus, "ref" needs to be "advanced by one step", as we
    don't look into "its result already stored into the next tmp
    table", anymore. So ref slices are "advanced by one  step" during
    execution.
    Unchanged meaning of "the current ref slice of JOIN":
    it's still the "ref"s (targets) for Item_refs when evaluating Items in
    the current phase of execution.
    Unchanged meaning of QEP_TAB::ref_item_slice: the
    it's still the "ref"s (targets) for Item_refs when evaluating Items
    when reading this QEP_TAB.
    Exception: QEP_TAB::ref_item_slice is not anymore set to
    REF_SLICE_TMP3, as that latter slice is never the one to use to read
    from any QEP_TAB; it's the one to use to read from a pseudo-tmp-table
    of GROUP BY. A consequence is that we cannot use
    QEP_TAB::ref_item_slice to switch to REF_SLICE_TMP3 anymore, so we use
    a new member JOIN::before_ref_item_slice_tmp3 for that.
    Almost all execution functions need to advance to the right slice
    before they read a table.
    
    QEP_TAB::all_fields and QEP_TAB::fields are removed: we can get the
    same information from QEP_TAB::ref_item_slice, using new function
    JOIN::get_current_fields().
    
    class Item:
    all val_x_result() are gone, all calls to them replaced with val_x().
    Item_ref made to behave like Item_direct_ref; thus, Item_direct_ref
    removed and replaced with Item_ref.
    
    Item_field::save_in_field_inner() (item.cc):
        after the changes done to fix_inner_refs() in this patch,
        for the materialization of some IN subquery, we use store_key_item
        to store the left args of the IN subquery,
        while we used to use store_key_field (see comment about fix_inner_refs);
        these left args are indeed outer refs belonging to a grouped query;
        store_key_field() takes its source in Item_field::field;
        store_key_item() rather uses Item_field::save_in_field_inner()
        which takes its source in Item_field::result_field, which assumes
        this field contains the up-to-date value. This logic sounds
        strange and the present patch uses the "field" member as source,
        instead. Perhaps the old logic was necessary when ref slice wasn't
        "advanced one step" as we do now. The modified code is from before
        2000 so we cannot know more about its reason.
    
    item_subselect.cc: ref_by[1] introduced (see explanation there). So we
    now have two "ref_by" pointers; it's then difficult to pass both as
    arguments to split_sum_func2 in sql_resolver.cc so we let
    split_sum_func2 find pointers itself.
    
    sql_join_buffer.cc: assert that we needn't switch slice, because we never
    use join buffer on a tmp table. Removed useless switch.
    
    JOIN::set_ref_item_slice(): as we use it more now, make it do nothing if
    slice number doesn't change ([1;31moptim[mization).
    Switch_ref_item_slice: now it's used in one case where the said slice
    may or not exist, so I make the object a no-op if the slice doesn't
    exist.
    
    JOIN::set_group_rpa: not needed anymore as set_ref_item_slice()
    detects when sliceno doesn't change so we can call it repeatedly;
    removed.
    
    SELECT_LEX::fix_inner_refs(): simplified as Item_direct_ref and
    Item_ref are one now, no need to choose between the two.
    
    sql_select.cc:get_store_key():
    there was an "else if" branch special for DIRECT_REF.
          else if ((*(Item_ref**)(item_ref)->ref)->ref_type()
                   == Item_ref::DIRECT_REF &&
                   item_ref->real_item()->type() == Item::FIELD_ITEM)
                   field_item= static_cast<Item_field*>(item_ref->real_item());
    It was specific of an outer reference belonging to a query with GROUP
    BY. It relied on the two different types of Items created in
    fix_inner_refs(). I remove this because it's not possible anymore to
    distinguish Item_ref from Item_direct_ref (they're one now), and the
    distinction is necessary to make this 'else' work. Likely it makes us
    pick store_key_item() instead of store_key_field(), in this outer-ref
    case, which is acceptable.
    
    sql_select.cc: reset_wf_result_fields(): removed.
      More info about the problem that required this function:
      select from (select WF1 over w1, WF2 over w2) dt;
      where "dt" is materialized. First the "dt" table structure is created with
      create_tmp_table() and that sets WF{1,2}->result_field (pointing into
      columns of "dt"). Then the inner subquery is [1;31moptim[mized, that calls
      create_tmp_table() for the two windows. First for w1: WF1 is to be
      calculated in w1 so a column is added for its result in the tmp table; so
      its result_field gets re-set to point there, all fine. Continuing with the
      creation of wf1, WF2 is skipped. Then change_to_use_tmp_fields() sees that
      WF1 and WF2 have a result_field (see test
      'else if ((field= item->get_tmp_table_field()))'), so concludes that the ref
      slice used to read the tmp table of w1 should contain Item_fields for WF1
      and WF2; that's incorrect for WF2, and leads to WF2 never being calculated.
      My fix: in create_tmp_table(), when the destination table is to materialize
      a derived table / UNION (i.e. is not a group-by/windowing table), there's no
      reason to set result_field (results are not saved by this means anyway, but
      by Query_result_union::send_data() which reads the last table of the query
      and writes that to the materialized table), so don't set it.
    
    sql_select.cc: JOIN::make_tmp_tables_info():
          Complement to comment "Exit the TMP3 slice": failing test was
          main.func_group, consider:
          SELECT (SELECT COUNT(DISTINCT t1.b)) FROM t1 GROUP BY t1.a;
          When evaluating COUNT(DISTINCT t1.b): we copy t1.b to tmp table used by
          COUNT(DISTINCT) (i.e. tmp table of Aggregator_distinct):
          for that we must copy t1.b from JOIN's result, not from TMP3 slice:
          indeed TMP3 was filled when we switched to a new group (see
          end_send_group), so it contains the value of t1.b for the first row of
          the group; while COUNT(DISTINCT) wants the value of the current row (or
          it would think all rows of group have same value of t1.b). So the
          copy_field to the COUNT(DISTINCT) tmp table must take its source in
          JOIN, so ref slice must not be TMP3 in setup_sum_funcs.
          Alternatively, I tried to let COUNT(DISTINCT) read from TMP3, so I had
          to update t1.b in TMP3 for every read row but:
          - it broke the undocumented behaviour that "for a non-functionally dependent
          column in group we choose first row"
          - it broke other tests
    
    sql_executor.cc:
    simplified slice switching: switch, when about to read a table, to the
    Items which point to this table; in practice it means:
    - before reading first row (as it may start with a filesort, which may
    have to evaluate some ORDER BY expression on the table); slice switch
    remains in force for next rows too
    - for tmp tables: before evaluating HAVING; even a bit earlier: before
    copy_fields() (see comment in end_send_group())
    - copy_funcs(): no need to calculate functions in two passes, anymore;
    so tmp_table_param::hidden_func_count is removed (was added by the WF
    WL). Proper order is given by sort_copy_func() now.
    - setup_copy_fields(): no need for special case for Item_aggregate_ref,
    said Evgeny; indeed I don't understand why it still would be needed:
    as Item_ref::val_* just evaluates the referenced Item_field (doesn't
    look at result_field), we can just copy the underlying Item_field.
    - complement to comment "As GROUP expressions have changed" at *end* of
    end_send_group():
            Fixes test: main.group_by, query:
            select a, round(rand(100)*10) r2, sum(1) r1 from t1 where a = 1 group  by a
            having r1>1 and r2<=2;
    - complement to comment "We have created a new Item_field" in
    setup_copy_fields():
                The only new thing is below: let 'item->field' allow access to
                REF_SLICE_TMP3. This won't disturb the Copy_field as it has cached
                field->ptr (in copy_field->set()) before the change to
                'item->field' below.
                Why this change: because when we are in slice TMP3 (end_send_group), to
                evaluate HAVING we use Item_ref::val_int() which doesn't anymore use
                ref->val_int_result() but ref->val_int() instead: and
                Item_field::val_int() uses 'field' not 'result_field' so the
                Item_field here must have valid data (i.e. TMP3) in its 'field'.
    - change in QEP_TAB::remove_duplicates(): the function
    used (this-1)->fields. Now that I get rid rid of this member, I found
    a way to do without it: it was used to count hidden fields in 'this';
    I replaced the counting with the existing hidden_field_count.
    - assertions of type:
      this != join()->before_ref_item_slice_tmp3
    are added to make sure that only well-identified functions read from
    REF_SLICE_TMP3.
    
    sql_tmp_table.cc:
    - don't set result_field when it doesn't make sense;
    removes the need to clear it later (i.e. removed
    reset_wf_result_fields()).
    - as we can now create a tmp table by using as source the fields of slice
    REF_SLICE_TMP3, which don't point in a real table::record[0], fixed the
    "move_field" logic in calculation of the field's default value.
    - added sort_copy_func() to evaluate Copy_func-s in proper order (see
    comment there); uses new function Item_ref::contains_alias_of_expr()
    (item.cc); requires to replace Item* pointer in Func_ptr_array with a
    pair of Item* and alias-of-expr property: class Func_ptr.
    - complement to comment "Let each group expression know"
          it is needed to fix Bug#26475312. Indeed, the scenario was (see
          test in window_functions_bugs.test):
          - for group-by write to a tmp table tmp1
          - there is no group aggregate function (so this GROUP BY is there only
          to make distinct groups) so we use end_write() with a duplicate
          elimination in tmp1
          - the concatenation of group expressions is too long to make it a unique
          key so we use a "unique constraint" (hash_field) instead
          - after tmp1 there is tmp2 for windowing.
          - in end_write() we do check_unique_constraint(); after checking
          hash_field it gets a "candidate duplicate"; to check it more thoroughly
          we use group_rec_cmp() to compare the two rows; this function finds the
          value of group expressions in each row; for that it evaluates the
          expressions; but (after the refactoring) the slice we're at is that of
          tmp1 (not of the table before tmp1, anymore); the expression is
          thus a Item_field with 'field' in tmp1; and 'result_field' in tmp2; when
          group_rec_cmp() used get_tmp_table_item() on this Item_field it returned
          result_field i.e. group_rec_cmp() was reading in tmp2, wrongly.
          The fix is the make group_rec_cmp() find the proper 'field'. We record
          it below. Note that it was recorded in the old code too, but not if using
          hash_field (see branch "if (group && !using_unique_constraint)").
          - I also changed unique_hash_group like group_rec_cmp as they looked
          similar.
    - complement to comment "Get the value from default_values":
            Using move_field_offset(diff) below assumes that orig_field->ptr
            points into record[0], which may not be the case. Example:
            - we are creating a tmp table to materialize the query's result, for a
            PS cursor
            - the last table of the query, i.e. input to the cursor's tmp table,
            is the result of GROUP BY, so here 'fields' is items of
            REF_SLICE_TMP3
            - so orig_field is from REF_SLICE_TMP3, it was created by
            setup_copy_fields() from table->field[x] and its ptr points to a
            temporary memory area.
            Conclusion: so we rather use orig_field->table->field[x] which is
            properly in record[0].  By adding 'diff' to ptr we point that field to
            its default value.
            Fixed mysql_client_test.test (precisely the test for bug 11904 there).
    
    table.h: st_order::field renamed to clearer name field_in_tmp_table.
    
    New MTR test bits for better coverage of modified code.
    Tests for the four fixed bugs.
    
    having.test: UPDATEs to the series table are added to make sure a
    failing section doesn't make other following sections fail.
    
    Change-Id: I9775573b821886932b48b08c5ae9ece12e249e71

[33mcommit 06be797507c1bdf6d5602fe394f3bc38fbab30a3[m
Author: Dag Wanvik <dag.wanvik@oracle.com>
Date:   Mon Oct 16 11:15:53 2017 +0200

    Bug#26389508 INT JOIN_READ_KEY(QEP_TAB*): ASSERTION `!TABLE->HAS_NULL_ROW()' FAILED
    
    Analysis:
    
    When a window with buffering follows a equijoin on a unique index
    (JT_EQ_REF) , we can get into trouble because windowing modifies the
    input record, presuming that once the windowing has been handed the
    record, next time control passes back to the join code a (new) record
    will be read to the input record.
    
    However, this does not hold with JT_EQ_REF, cf. the caching done in
    join_read_key:
    
    From its Doxygen:
    
      "Since the eq_ref access method will always return the same row, it
       is not necessary to read the row more than once, regardless of how
       many times it is needed in execution.  This cache element is used
       when a row is needed after it has been read once, unless a key
       conversion error has occurred, or the cache has been disabled."
    
    Fix:
    
    We solve this problem by reinstating the input record before handing
    control back from end_write_wf. We [1;31moptim[mize: only do this if the
    window in question follows after such a JOIN, i.e. window #1, and it
    has actually clobbered the input record. This can only happen if
    the last qep_tab has type JT_EQ_REF.
    
    Another, perhaps better approach, is to refactor to never touch the
    input record but keep the copying between the out record and the frame
    table record instead. Left for future refactoring.
    
    Added some missing Window method "const"s, and folded a couple of
    one-liners into window.h (from .cc).
    
    Repro added.
    
    Change-Id: I33bc43cd99ff79303b17d181abc3805ce226fb85

[33mcommit 112bb9390f3e493b4f3adef6088eeccc37b57d08[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon Oct 16 12:13:33 2017 +0200

    Bug #26919289 MYSQLD CRASH DURING 'JOIN PUSHDOWN' ANALYSIS
    
    When representing a 'Materialized semijoin' in the query plan,
    the mysql [1;31moptim[mizer inserted extra QEP_TAB + JOIN_TAB objects
    to represent access to the materialized subquery result.
    
    The join pushdown analyzer didn't properly set up its internal
    data structures for these 'artificial tables' and instead left them
    uninitalized. Thus later usage of any item objects REF'ering the materialized
    semijoin ended up using an ininitialized 'tableno' field when
    accessing a 64-bit tableno-bitmask, possibly refering it beyond
    its physical end.
    
    Caused an assert to be hit in DEBUG mode, and possibly (yet unknown)
    unpredictable results else.

[33mcommit e819c4c3e096b3b732f41ea18037412cecd4ed51[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Oct 16 10:32:17 2017 +0200

    Bug #26826272: REMOVE GCC 8 WARNINGS [noclose]
    
    Fix an instance of undefined behavior, where one would allocate some
    memory, cast it to an object, set some fields and then run placement
    new, where the constructor would expect those fields to still be set.
    (The code also calls a virtual member function from its constructor,
    which seldom is a good idea but at least has defined semantics.)
    
    This is undefined behavior because an object's lifetime starts at the
    constructor, so any stores done before that are dead and can be [1;31moptim[mized
    away. GCC 6 and newer does so in some cases, precluding some upcoming
    warning cleanups. Fixing this UB instance allows those cleanups to
    proceed.
    
    Also fixes a leak if the second open_cached_file() should fail.
    
    Change-Id: Iddcbc71dbfe5265c89cc6d39e09746b0029140d1

[33mcommit a646dcfd02b26e03f04ccb33dfa2e7999b7df081[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Oct 12 16:35:45 2017 +0200

    Bug #26927386: REDUCE WEIGHT OF SQL_CLASS.H [noclose]
    
    Post-push fix for broken NDB build in [1;31moptim[mized mode: #include headers in use.
    
    Change-Id: I1dcb40aaf2c45badbd19af56811bb7b3a66af8f4

[33mcommit d0bfaf67997b48ac4e72e90630c0d49c15a66cc5[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Sep 28 12:57:22 2017 +0200

    Bug #26940369: REWRITE THE MEM_ROOT
    
    Streamline and [1;31moptim[mize the MEM_ROOT.
    
    This totally rewrites the MEM_ROOT, though keeping mostly the same conceptual
    idea (arena allocation). Important changes:
    
     - The MEM_ROOT now keeps only one free block, greatly simplifying the logic.
       In particular, we no longer have to traverse a linked list of free blocks
       (with associated cache misses) for allocations that do not fit, and we don't
       need complex heuristics for when to give up a block.
     - Preallocation was hardly ever used and caused a fair amount of complexity,
       so it has been removed.
     - We now have a fast path for Alloc() that can be inlined, so that the common
       case is simply an easily predictable branch and an add.
     - New blocks increase exponentially in size instead of linearly (similar to
       how std::vector and other STL classes operate), so that we can guarantee
       O(1) calls to malloc (assuming constant-sized allocations).
     - A lot of other complexity with questionable use has been removed.
     - The interface is now C++, with C wrappers being kept for compatibility.
     - Since the code is effectively all new, it now follows Google coding style.
    
    Note that this changes the meaning of the “query_prealloc_size” variable somewhat.
    It now sets (up to a constant factor, currently at 5) how much memory is
    allowed to be kept in the MEM_ROOT between queries, instead of actually
    preallocating memory at the start. However, the end-user effect should be
    pretty similar.
    
    sysbench tests show somewhere between 1% and 6% qps increase.
    
    Change-Id: Ia1b5c7b87833dac0d2ef51e0c00399c818f51eb0

[33mcommit 397bc5d53f1bb6b6ddd036b419628701b3169a5e[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Wed Oct 11 14:54:37 2017 +0200

    Bug#26389402: Outer join [1;31moptim[mized away with user-defined functions
    
    When a stored function is used with table column values as arguments
    in a WHERE predicate, its not_null_tables property is falsely set to
    a non-empty value. If this predicate is applied to an outer join
    operation and one of the arguments is from an inner table of the
    outer join, the predicate may be used to convert the outer join to
    an inner join.
    
    According to SQL standard, only functions that have the "RETURNS NULL
    ON NULL INPUT" property should behave like that. (MySQL does not
    currently implement this property.) This function changes semantics
    of stored functions to not implement RETURNS NULL ON NULL INPUT.
    
    Some internal functions (like internal_table_rows) need the same
    possibility as the stored functions. This bug fix will prepare
    not_null_tables functionality for these functions, but will not
    actually change the implementation for these functions.
    
    A "null_on_null" property is implemented on the Item_func class.
    null_on_null is by default true, but is overridden with false in class
    Item_func_sp. Any other function that need the same not_null_tables
    property may also override null_on_null in its constructor.
    
    When null_on_null is false, not_null_tables_cache is always set
    to 0 when updated.
    
    For some Item_func derived classes that effectively did not implement
    RETURNS NULL ON NULL INPUT, the overridden function not_null_tables()
    that used to return 0 is replaced with a simple assignment to
    null_on_null in the constructor, thus eliminating several overridden
    functions.

[33mcommit e26b5971c4d98e66cd6c0e2f0cc9392e2905503a[m
Author: Erik Froseth <erik.froseth@oracle.com>
Date:   Fri Oct 6 14:51:51 2017 +0200

    WL#9223 Using histogram statistics in the [1;31moptim[mizer
    
    Rename one enumerator from READ_ONLY to SERVER_READ_ONLY since
    READ_ONLY conflicts with a #define in sys_vars.h
    
    This conflict is stopping some pending cleanups to be done.
    
    Change-Id: I2d27da2bc094bde9a62f7a5efe7b0728674d5dfa

[33mcommit ff5892b85c5199220c6b7674ac0f67793d4d505f[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Tue Sep 26 17:39:47 2017 +0530

    Bug#21373532: RANGE TESTS FAILS DUE TO DIFFERENCE IN EXPLAIN OUTPUT
    
    One of the test case change has already been pushed. This patch fixes
    index_merge_delete.test
    
    The variation in the plan is expected on different platforms as stated in
    the test file. Added what is done for other tests just below.
    
    Regarding the new change ( from "Delete all rows" to NULL
    in the plan) for some of the deletes is due to changes in 8.0. The
    condition (a subquery) is not a const_item() anymore which makes [1;31moptim[mizer
    choose a different plan in 8.0 (in 5.7, const_item() for the subquery
    returns true).

[33mcommit 7284579aa24bc3634f7a4c42319e60f7c8eedd22[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Wed Sep 20 10:24:56 2017 +0200

    Bug#26516584: Post-push fix. Fix -werror [1;31moptim[mized build failure

[33mcommit 7a8cb67ad4d4e1472097a0519485ce44a803cc95[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Wed Sep 20 10:49:49 2017 +0530

    Bug#26555487: MAIN.DESC_INDEX_INNODB FAILS DUE TO DIFFERENCE
                  IN EXPLAIN RESULT
    
    Changed the data to force [1;31moptim[mizer to pick range access method instead
    of index on some platforms.

[33mcommit faf8497e39518b643d1b2e75c7ccc840153617c5[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Mon Sep 11 13:17:22 2017 +0530

    Bug#26496880: CRASH IN FIELD_BLOB::GET_KEY_IMAGE
    
    Problem:
    read_set for the field is not set because its not part of the query.
    As a result, server exits trying to read the data from the buffer.
    
    Analysis:
    For the query in the bugpage, as field "b" is not part of the query, [1;31moptim[mizer
    does not set the bit for the field in read_set. This results in innodb
    not fetching the data for field "b". But "b" is part of the primary key. So
    [1;31moptim[mizer tries to read the key and fails.
    
    Solution:
    prepare_for_position() called from make_join_read_info() marks the fields
    in read_set, which are part of primary key, if primary key is needed to
    find the row.
    We now call prepare_for_position() if window functions are present.

[33mcommit cfe93c54a6689c4ccd0f69f6ac79b14c47c972cf[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Mon Sep 4 16:30:37 2017 +0200

    Bug#23021693 gcol:assertion '!table->in_use->is_error()' failed
    
    The problem here is that an error leaks from test_quick_select()
    into the executor without being correctly processed.
    When update_generated_read_fields() is called, it expects no current
    error state and asserts.
    
    It is a major problem that subsystems like the range [1;31moptim[mizer has no
    proper way of propagating an error state, however this is a minimum
    fix that checks for error immediately after the call and terminates
    execution when an error state is encountered.

[33mcommit 042199db901644f80cedac1d071b91aa2054bee1[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Mon Sep 4 16:30:37 2017 +0200

    Bug#23021693 gcol:assertion '!table->in_use->is_error()' failed
    
    The problem here is that an error leaks from test_quick_select()
    into the executor without being correctly processed.
    When update_generated_read_fields() is called, it expects no current
    error state and asserts.
    
    It is a major problem that subsystems like the range [1;31moptim[mizer has no
    proper way of propagating an error state, however this is a minimum
    fix that checks for error immediately after the call and terminates
    execution when an error state is encountered.

[33mcommit 4bfcfe5bb01e8d31fd8a3e7fd829eac3b98d3808[m
Author: Sreeharsha Ramanavarapu <sreeharsha.ramanavarapu@oracle.com>
Date:   Fri Sep 1 08:31:23 2017 +0530

    Bug #26483909: INCORRECT BEHAVIOR FOR QUERY WITH DISTINCT
                   and ORDER BY ... LIMIT.
    
    Issue:
    ------
    This problem can occur when :
    1) Query contains DISTINCT and ORDER BY ... LIMIT.
    2) Range access will be used but the conditions are such
    that it will still require a temporary table for ORDER BY.
    
    
    Root cause:
    -----------
    test_if_skip_sort_order() is called from
    JOIN::[1;31moptim[mize_distinct_group_order and this returns true
    meaning that an index can be used and there is no need for
    sorting. But this is called with the flag "no_changes" set
    to true, that is no change to the plan will be affected.
    
    When the same function is called from JOIN::test_skip_sort,
    the "no_changes" is set to false and hence the plan can be
    changed. But since a range access isn't possible for the
    relevant index, it returns a false.
    
    This means that m_ordered_index_usage is left with
    ORDERED_INDEX_VOID and will cause an assert failure.
    
    Solution:
    ---------
    Ideally JOIN::skip_sort_order should be set to false when
    test_if_skip_sort_order() returns a false. This will avoid
    [1;31moptim[mizing the distinct clause while assuming the ORDER BY
    doesn't require a sort.
    
    Other changes:
    --------------
    It is very confusing that the member variable
    'ordered_index_usage' and the values 'ordered_index_*' are
    in the lower case. This has been corrected.

[33mcommit d034d7599c4b1da891fe7ae9510b14adb7ee49df[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Aug 11 12:45:49 2017 +0200

    WL #10343: Switch GCC [1;31moptim[mization from -O3 to -O2
    
    Change from -O3 to -O2 everywhere, for smaller binaries, faster compile
    times and generally better performance. Mark some performance schema
    function as force-inline to avoid performance regressions, since they
    are important to inline despite being big.
    
    Change-Id: Ib7603f141e6974aeed7e4fde2ef7697864231ae3

[33mcommit c453a80684e613dc491b5ff1c6d90d16a81e3501[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Thu Aug 24 21:13:52 2017 +0300

    WL#6049 "Meta-data locking for FOREIGN KEY tables" and WL#11059
    "Implement INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS as a system
    views over dictionary tables."
    
    WL#6049 Meta-data locking for FOREIGN KEY tables.
    
    The primary goal of this task is to ensure that foreign keys checks,
    which are performed by storage engine (e.g. InnoDB), do not access
    tables which are concurrently modified by DDL statements.
    
    Such an isolation of FK checks/actions from DDL statements can be
    achieved by ensuring that FKs are taken into account when we acquire
    metadata "operation-type aware" locks for DML and DDL statements.
    
    This is done by:
    
    1) Extending prelocking algorithm/process to take into account
       foreign keys and acquire metadata locks which are appropriate
       for the operations involving them (checks in parent or child
       tables take SR lock, cascading updates or deletes take SW lock,
       LOCK TABLES takes SRO or SNRW locks correspondingly).
    
    2) Changing DDL statements which add or drop foreign keys to the system
       to X lock on FK parent table before child table definition changes.
    
    3) Changing DDL statements which otherwise affect FK-related metadata
       (like RENAME TABLE on child or parent table) to acquire X lock on
       tables participating in the FK.
    
    4) Changing ALTER TABLE to acquire SU metadata lock on parent tables
       for newly added FKs so it can properly check them.
    
    The secondary goal of this task is to ensure that DDL on parent tables
    correctly updates foreign key metadata. Specifically we now correctly
    update the following metadata:
    
    I)   Name of unique constraint in parent table for the FK.
    
         Old code misused DD.FOREIGN_KEYS.UNIQUE_CONSTRAINT_ID to store
         id of supporting index for the FK in the child table. This WL replaces
         this column with VARCHAR(64) field which stores name of unique
         key in the parent table used for the FK -- UNIQUE_CONSTRAINT_NAME.
         DDL statements code was adjusted to keep this value correct on
         changes to parent table definition.
    
    II)  Referenced schema and table names (DD.FOREIGN_KEYS.REFERENCED_TABLE_SCHEMA
         and DD.FOREIGN_KEYS.REFERENCED_TABLE_NAME) during ALTER TABLE RENAME/
         RENAME TABLES on parent tables.
    
    This WL introduces some new temporary limitations:
    
    - We temporary disallow renaming of parent columns in FKs.
    
    - ALTER TABLE ... ALGORITHM=COPY acquires SRO locks on the parent
      tables for newly added FKs. This is temporary workaround for
      InnoDB SE making information about such FKs to other connections
      before DDL commit.
    
    - We disallow ALTER TABLE ... RENAME under LOCK TABLES on tables
      which have or will have foreign keys. This limitation should
      be weakened soon.
    
    WL#11059 Implement INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS as a system
             views over dictionary tables.
    
    This patch implements I_S.REFERENTIAL_CONSTRAINTS as a system view over data
    dictionary tables, and remove 5.7 code that uses a temporary
    table to represent I_S view.
    
    Following changes are made in the patch:
    
    * Define a system view over data dictionary tables representing
      I_S.REFERENTIAL_CONSTRAINTS.
    
    * Remove 5.7 code from sql_show.cc for I_S.REFERENTIAL_CONSTRAINTS.
    
    * The result file for main.information_schema_inno shows the
      unique_constraint_name as PRIMARY. This is expected change added in
      wl6049. We get 'PRIMARY' as constraint name if a key is promoted as
      primary key. If a unique key is not a primary key, then the constraint name
      does show the unique key name.
    
    * Fixed upgrade code to return just the constraint name and avoid prefixing
      the constraint schema name with it. We also check that the constraint
      name is not more than 64 characters, before continuing further.
    
    * Added ORDER BY clauses in some of I_S query to force order of
      tuple returned. Because, now the [1;31moptim[mizer returns the rows and
      not read from temporary table as in 5.7 I_S design.
    
    * Remove part of test case in main.information_schema. Because,
    
      - The problem reported back then is only applicable for 5.7
        code.
    
      - The output of EXPLAIN ... <select on I_S system view> goes
        through [1;31moptim[mizer and then plan return might vary.
    
    * Fixed InnoDB upgrade code, which ignored setting RESTRICT flag for
      update and delete rule.
    
    * Recorded result files with I_S column names being capitals now,
      this is expected, see wl6599 for more info.

[33mcommit 6626f76d856eb6415d1db37eccd67858cfb71096[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Thu Aug 24 21:13:52 2017 +0300

    WL#6049 "Meta-data locking for FOREIGN KEY tables" and WL#11059
    "Implement INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS as a system
    views over dictionary tables."
    
    WL#6049 Meta-data locking for FOREIGN KEY tables.
    
    The primary goal of this task is to ensure that foreign keys checks,
    which are performed by storage engine (e.g. InnoDB), do not access
    tables which are concurrently modified by DDL statements.
    
    Such an isolation of FK checks/actions from DDL statements can be
    achieved by ensuring that FKs are taken into account when we acquire
    metadata "operation-type aware" locks for DML and DDL statements.
    
    This is done by:
    
    1) Extending prelocking algorithm/process to take into account
       foreign keys and acquire metadata locks which are appropriate
       for the operations involving them (checks in parent or child
       tables take SR lock, cascading updates or deletes take SW lock,
       LOCK TABLES takes SRO or SNRW locks correspondingly).
    
    2) Changing DDL statements which add or drop foreign keys to the system
       to X lock on FK parent table before child table definition changes.
    
    3) Changing DDL statements which otherwise affect FK-related metadata
       (like RENAME TABLE on child or parent table) to acquire X lock on
       tables participating in the FK.
    
    4) Changing ALTER TABLE to acquire SU metadata lock on parent tables
       for newly added FKs so it can properly check them.
    
    The secondary goal of this task is to ensure that DDL on parent tables
    correctly updates foreign key metadata. Specifically we now correctly
    update the following metadata:
    
    I)   Name of unique constraint in parent table for the FK.
    
         Old code misused DD.FOREIGN_KEYS.UNIQUE_CONSTRAINT_ID to store
         id of supporting index for the FK in the child table. This WL replaces
         this column with VARCHAR(64) field which stores name of unique
         key in the parent table used for the FK -- UNIQUE_CONSTRAINT_NAME.
         DDL statements code was adjusted to keep this value correct on
         changes to parent table definition.
    
    II)  Referenced schema and table names (DD.FOREIGN_KEYS.REFERENCED_TABLE_SCHEMA
         and DD.FOREIGN_KEYS.REFERENCED_TABLE_NAME) during ALTER TABLE RENAME/
         RENAME TABLES on parent tables.
    
    This WL introduces some new temporary limitations:
    
    - We temporary disallow renaming of parent columns in FKs.
    
    - ALTER TABLE ... ALGORITHM=COPY acquires SRO locks on the parent
      tables for newly added FKs. This is temporary workaround for
      InnoDB SE making information about such FKs to other connections
      before DDL commit.
    
    - We disallow ALTER TABLE ... RENAME under LOCK TABLES on tables
      which have or will have foreign keys. This limitation should
      be weakened soon.
    
    WL#11059 Implement INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS as a system
             views over dictionary tables.
    
    This patch implements I_S.REFERENTIAL_CONSTRAINTS as a system view over data
    dictionary tables, and remove 5.7 code that uses a temporary
    table to represent I_S view.
    
    Following changes are made in the patch:
    
    * Define a system view over data dictionary tables representing
      I_S.REFERENTIAL_CONSTRAINTS.
    
    * Remove 5.7 code from sql_show.cc for I_S.REFERENTIAL_CONSTRAINTS.
    
    * The result file for main.information_schema_inno shows the
      unique_constraint_name as PRIMARY. This is expected change added in
      wl6049. We get 'PRIMARY' as constraint name if a key is promoted as
      primary key. If a unique key is not a primary key, then the constraint name
      does show the unique key name.
    
    * Fixed upgrade code to return just the constraint name and avoid prefixing
      the constraint schema name with it. We also check that the constraint
      name is not more than 64 characters, before continuing further.
    
    * Added ORDER BY clauses in some of I_S query to force order of
      tuple returned. Because, now the [1;31moptim[mizer returns the rows and
      not read from temporary table as in 5.7 I_S design.
    
    * Remove part of test case in main.information_schema. Because,
    
      - The problem reported back then is only applicable for 5.7
        code.
    
      - The output of EXPLAIN ... <select on I_S system view> goes
        through [1;31moptim[mizer and then plan return might vary.
    
    * Fixed InnoDB upgrade code, which ignored setting RESTRICT flag for
      update and delete rule.
    
    * Recorded result files with I_S column names being capitals now,
      this is expected, see wl6599 for more info.

[33mcommit c39f338765975a1620d0e738a69f30a227c7a8a3[m
Author: Pekka Nousiainen <pekka.nousiainen@oracle.com>
Date:   Wed Aug 23 12:15:44 2017 +0300

    wl#7614 [1;31moptim[m06.diff
    
    batched row transfers for ops

[33mcommit 00d056b2a2e321ab349feb896d96570d40ba3068[m
Author: Pekka Nousiainen <pekka.nousiainen@oracle.com>
Date:   Wed Aug 23 12:15:25 2017 +0300

    wl#7614 [1;31moptim[m05.diff
    
    batched row transfers

[33mcommit 5b8813b5adff088aa28921388fb0343825ee1c9a[m
Author: Pekka Nousiainen <pekka.nousiainen@oracle.com>
Date:   Wed Aug 23 12:12:09 2017 +0300

    wl#7614 [1;31moptim[m04.diff
    
    batched row alloc and free

[33mcommit 842a3e38f2becb9fd63a3c2948d87b2f6e5530b9[m
Author: Pekka Nousiainen <pekka.nousiainen@oracle.com>
Date:   Wed Aug 23 12:11:38 2017 +0300

    wl#7614 [1;31moptim[m03.diff
    
    global stats, lock stats

[33mcommit 81118233af4df5394a84f4d4ed3ed7f295df06de[m
Author: Pekka Nousiainen <pekka.nousiainen@oracle.com>
Date:   Wed Aug 23 12:11:19 2017 +0300

    wl#7614 [1;31moptim[m02.diff
    
    rename some confusing variables

[33mcommit 113a94bbdbbf068625a2a830d89ca692f9ca38ad[m
Author: Pekka Nousiainen <pekka.nousiainen@oracle.com>
Date:   Wed Aug 23 12:10:56 2017 +0300

    wl#7614 [1;31moptim[m01.diff
    
    save performance related options

[33mcommit 817b5c493cfde48861ccaa67d267b34e3601adf6[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Mon Aug 21 16:30:24 2017 +0200

    WL#9223 Using histogram statistics in the [1;31moptim[mizer
    
    Post-push fix for some tests - binlogging is now off by default.
    
    Approved by Erik Froseth <erik.froseth@oracle.com> over IM.

[33mcommit 8104adb3823e45929cf45551cd294bc7255368d8[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Sun Aug 20 07:12:58 2017 +0200

    WL#9223 Using histogram statistics in the [1;31moptim[mizer
    
    Post-push fix: rerecord perfschema.transaction_nested_events

[33mcommit 6aee469375a4eafb39d6bfe55027d0721f4c7c2c[m
Author: Sven Sandberg <sven.sandberg@oracle.com>
Date:   Sat May 6 14:33:42 2017 +0200

    WL#2955: RBR replication of partial JSON updates
    
    This worklog enables the replication of small updates of big JSON
    documents more space-efficiently.  More precisely, when using RBR, we
    will write only the modified parts of JSON documents, instead of the
    whole JSON document.
    
    The patch includes the following major components:
    
    - Implement the new option binlog_row_value_options
    
    - Implement logic to generate JSON diffs only when needed
    
      Before, JSON diffs were generated unconditionally by the [1;31moptim[mizer.
      We changed so that JSON diffs are only generated when the option is
      enabled (unless inhibited by other options).
    
    - Implement new event type and use it when the option is enabled
    
    - Refactor: make max_row_length a private member of Row_data_memory
    
      This function was only used internally in class Row_data_memory, but
      was defined as a global function in table.cc.  Moved it to a private
      member of Row_data_memory.
    
    - Refactor: simplify pack_row and unpack_row
    
      Made several refactorings in these functions, including:
    
      New utility classes for handling null bits: When reading and writing
      a row in a row event, the logic for iterating over fields was
      interleaved with low-level bit operations to maintain a bitmap of
      null fields.  This made the code error-prone and hard to understand
      and edit.  This refactoring encapsulates the bitmap handling in
      utility classes, and simplifies pack_row / unpack_row accordingly.
    
    - Refactor: add const to integer decoder functions in pack.cc
    
      Functions in mysys/pack.cc that read from a buffer did not declare
      the buffer as const.  This patch makes net_field_length_size use a
      const parameter and makes other functions use const internally.
      Since these functions are part of the ABI, we also have to update
      include/mysql.h.pp.  (We do not const-ify pointers-to-pointers in
      function declarations, since that breaks compilation on other places
      that call the functions using non-const arguments.)
    
    - Refactor: change Json_diff_vector from a type alias to a class
    
      This was needed because extend Json_diff_vector with more member
      functions.  It also simplifies some forward declarations.
    
    - Refactor: do not overload global identifier TABLE in rpl_tblmap.h
    
      Class table_mapping in rpl_tblmap.h is used both in mysqlbinlog and
      in the server.  In the server, it maps numbers to TABLE objects.  In
      mysqlbinlog, it maps numbers to Table_map_log_event objects.  This
      was implemented by using the type name TABLE, and in mysqlbinlog use
      a typedef that makes TABLE an alias for Table_map_log_event.
    
      This patch changed rpl_tblmap.h so that it does not use the
      identifier TABLE.  Instead, it uses the new typedef Mapped_table
      that maps to TABLE in the server and to Table_map_log_event in
      mysqlbinlog.
    
    - Refactor: remove unused variable Rows_log_event::m_master_reclength
    
      There was a member variable Rows_log_event::m_master_reclength that
      was set to a (strange) value which was never read.  Removed this.
    
    - Refactor: simplify Rows_log_event::read_write_bitmaps_cmp
    
      This member function was implemented only in the base class, but had
      a switch that made it execute differently depending on the
      instance's subclass.  Changed to use a pure virtual function in the
      base class and implement the different logic in each subclass.
    
    - Implement encoder of new event format
    
      Outline of the pipeline:
    
       1. In binlog.cc:Row_data_memory, take a new argument in the
          constructor having two 'data' pointers (this constructor is used
          for Update_rows_log_event and is invoked in
          binlog.cc:THD::binlog_update_row).  This the value of the new
          server option binlog_row_value_options.  Based on this variable,
          determine if Json diffs may be used, estimate how much memory
          will be used (using the new function
          json_diff.cc:Json_diff_vector::binary_length), decide if full
          format or partial format will be used, and adjust the allocated
          memory accordingly.
    
       2. In binlog.cc:THD::binlog_update_row, pass two new arguments to
          pack_row:
    
          - row_image_type, which specifies if this is a
            Write/Update/Delete, and if it is a before-image or
            after-image.
    
          - value_options, which contains the value of
            binlog_row_value_options for update after-images.
    
       3. In rpl_record.cc:pack_row, accept the two new arguments.  If
          this is an update after-image and the bit in value_options is
          set, then determine if any column will use partial format.  If
          any column will use partial format, write the value_options
          field, followed by the partial_bits, to the output.  Otherwise,
          just write value_options=0 to the output and skip the
          value_options.
    
       4. From rpl_record.cc:pack_row, invoke the new function
          rpl_record.cc:pack_field to write a single field.  If the column
          is JSON and this is the after-image of an Update and the bit in
          value_options is set, invoke the new function
          field.cc:Field_json::pack_diff.  Otherwise, or if
          field.cc:Field_json::pack_diff returned NULL, fall back to the
          usual non-diff writer.
    
       5. In Field_json::pack_diff, determine again if this field will be
          smaller in full format or in partial format.  If full format is
          smaller, just return NULL so that rpl_record.cc:pack_field will
          write the full format.  Otherwise, invoke the new function
          json_diff.cc:Json_diff_vector::write_binary.
    
       6. In json_diff.cc:Json_diff_vector::write_binary, write the length
          using 4 bytes, followed by all the diffs.  Write each diff using
          the new function json_diff.c:Json_diff::write_binary.
    
       7. In json_diff.c:Json_diff::write_binary, write a single diff to
          the output.
    
    - Implement decoder of the new format
    
      The pipeline is now:
    
       1. Add a parameter to
          log_event.cc:Rows_log_event::unpack_current_row, which says if
          this is an after-image or not.  Set the parameter from all the
          callers in log_event.cc.
    
       2. Move Rows_log_event::unpack_current_row from log_event.h to
          log_event.cc and make it pass two new arguments to
          rpl_record.cc:unpack_row: row_image_type, which indicates if
          this is Write/Update/Delete and before-image or after-image, and
          has_value_options, which is true for Update events when
          binlog_row_value_options=PARTIAL_JSON.
    
       3. Make rpl_record.cc:unpack_row accept the two new parameters.
    
          First make a few small refactorings in rpl_record.cc:unpack_row:
    
          - Clarify some variable names and improve the comment for the
            function.
    
          - Remove comments about unpack_row being used by backup, having
            rli==NULL.  This may have been an intention at some point in
            time, perhaps in 5.1, but probably never was true.  And rli is
            unconditionally dereferenced in the main loop, so it cannot be
            NULL.  Instead assert that it is not NULL.  Also assert that
            other parameters are not NULL, as well as other preconditions.
    
          - Improve some debug trace printouts.
    
          - Return bool instead of int since the caller does not need to
            distinguish more than two different return statuses.
    
          Then implement the new logic:
    
          - When partial format is enabled, read partial_bits before the
            after-image (from within the main loop, as well as from the
            loop that consumes unused fields), and also read partial_bits
            after the before-image (after the main loop).  For the
            before-image, leave the read-position before the partial_bits.
            Use the new auxiliary function start_partial_bits_reader to
            read the value_options and initialize the Bit_reader
            accordingly, in the two places (after before-image and before
            after-image).
    
          - In order to read the correct number of bits before the
            after-image, start_partial_bits_reader needs to know the
            number of JSON columns on the master.  This is known from the
            table_map_log_event via the table_def class.  For convenience
            (and reuse in the mysqlbinlog patch), we add a member function
            rpl_utility.cc:table_def::json_column_count.  This function
            also caches the computed column count, to speed up successive
            calls (e.g. for many-row updates).
    
          - For the before-image, set the corresponding bit in the table's
            read_set, for any column having a 1 in the partial_bits.  This
            tells the engine to fetch the blob from storage (later, when
            the engine is invoked).  The blob will be needed since we have
            to apply the diff on it.
    
          - Call an auxiliary function rpl_record.cc:unpack_field to read
            each field move some special case handling for blobs into this
            function too.
    
       4. In rpl_record.cc:unpack_field, call
          field.cc:Field_json::unpack_field for partial Json fields.
    
       5. Add new function field.cc:Field_json::unpack_field, which
          invokes the new function
          json_diff.cc:Json_diff_vector::read_binary to read the
          Json_diff_vector, and the pre-existing (since WL#10570) function
          apply_json_diffs to apply the diff.
    
          The Json_diff_vector uses a new MEM_ROOT rather than the one of
          the current_thd, because that allows memory to be freed for each
          value, which saves resources e.g. in case of many-row updates.
    
          Before apply_json_diff can be invoked, we need to call
          table->mark_column_for_partial_update and
          table->setup_partial_update, in order to enable the *slave*
          server to generate JSON diffs in the *slave's* binary log.
    
       6. Add the new function json_diff.cc:Json_diff_vector:read_binary.
          This function reads the length of the field, then iterates over
          the diffs, reads each diff in turn, constructs Json_path and
          Json_wrapper/Json_dom objects, and appends them to the
          Json_diff_vector.
    
          We implement the auxiliary function net_field_length_checked,
          which reads an integer in packed format (see mysys/pack.cc),
          checking for out-of-bounds conditions.
    
    - Implement decoding and pretty-formatting of JSON diffs in mysqlbinlog
    
      mysqlbinlog outputs row events in two forms:
    
      - BINLOG statements that a server can apply.  There is nothing to
        change to make this work for the new event type.
      - "Pseudo-SQL" that humans can read, in case mysqlbinlog is invoked
        with the -v flag.  This is what the present patch implements.
    
      The pipeline in mysqlbinlog is:
    
       1. log_event.cc:Rows_log_event::print_verbose invokes
          log_event.cc:Rows_log_event::print_verbose_one_row with the new
          argument row_image_type, which indicates if this is a
          Write/Update/Delete and whether it is a before-image or
          after-image.
    
       2. In log_event.cc:log_event.cc:Rows_log_event::print_verbose_one_row
          we do two things:
    
          - Refactorings:
    
            - Use a Bit_reader to read the null bits, instead of using bit
              arithmetic.
    
            - Use safer boundary checks.  The code has a pointer to row
              data and a pointer to the end of the row data.  In C/C++, a
              pointer may point to the next byte after an allocated block
              of memory, but incrementing it further has an undefined
              result.  After reading the length of a field, the correct
              way to check that this length is not corrupt is to compare
              it with the end pointer minus the pointer to the read
              position.  (Before, it added the length to the read position
              and compared with the end pointer, but the read position
              plus the length is undefined.)
    
          - Implement the feature:
    
            - Read the value_options, if this is the after-image of a
              PARTIAL_UPDATE_ROWS_EVENT.
    
            - If value_options has the PARTIAL_JSON bit set, read the
              partial_bits.
    
            - Pass the partialness of the column as a parameter to
              log_event.cc:log_event_print_value.
    
       3. In the new function log_event_print_value, accept the new
          parameter, and in case the value is partial, call the new
          function log_event.cc:print_json_diff to parse and print the
          Json diffs.
    
       4. In the new function log_event.cc:print_json_diff, read, parse,
          and print all the diffs.
    
          The output has the form:
            JSON_<func>(
            JSON_<func>(
            ...
            JSON_<func>(@column, path[, value][,
                        path [,value][,
                        ...]]),
            ...
                        path[, value][,
                        path [,value][,
                        ...]]),
                        path[, value][,
                        path [,value][,
                        ...]])
    
          In this output format, the JSON_<func> functions appear in
          *reversed* order, whereas all the (path, value) pairs appear in
          order of appearance.  Therefore, we make two passes over the
          sequence of diffs:
    
           1. Read just the operations and store them in a vector.  Then
              print the operations in reverse order. Operations are
              printed using the new function
              log_event.cc:json_wrapper_to_string.
    
           2. Read the full diffs and output in the order of appearance.
    
       5. Add a new function log_event.cc:json_wrapper_to_string to print
          a Json_wrapper.  This ensures that the Json values are printed
          in the correct type.  JSON_<func> functions will convert SQL
          types to their JSON equivalents: for instance, the JSON function
          JSON_SET('[1, 2]', '$[0]', '[]') will set the 0th element of the
          JSON array to a string containing an open and closing square
          bracket, and not to an empty JSON array.  To account for this,
          different data types need different quoting, and to insert a
          JSON object or JSON array we need to cast the string to JSON
          first.
    
       6. To output JSON values with correct quoting for SQL strings, we use
          the existing my_b_write_quoted, but change it so that:
    
          - it uses a lookup table (computed only once) for simplicity and
            performance;
    
          - it prints common escapes such as \n, \\ in a more
            human-readable way.
    
    - BUG#26018522: MYSQLBINLOG -V PRINTS JSON IN ROW EVENTS WRONG
      mysqlbinlog -v had two problems:
    
      P1. It only read the length of JSON objects from two bytes. But the
          length of JSON data in row events is encoded (in little endian)
          using four bytes.  Therefore, it printed the wrong data for JSON
          objects bigger than 64K.  This also caused subsequent errors.
    
      P2. It only dumped the raw bytes of the buffer (quoted).  But row
          events contain a binary format for JSON, so the output was not
          useful.
    
      We fix these two problems as follows:
    
      F1. Read the length from four bytes.
    
      F2. Link mysqlbinlog with the parts of the server that can parse
          binary JSON and format it in human-readable form.  This includes
          three files:
          - json_binary.cc can parse the binary JSON format.
          - json_dom.cc can format human-readable JSON.
          - sql_time.cc is used by json_dom.cc to format time and date.
          All these files contain code that mysqlbinlog does not need and
          which needs to link with more parts of the server (e.g. THD).  To
          avoid link problems we put such code inside #ifdef MYSQL_SERVER.
    
    - Created a new test suite for tests that should not be
      parallelized by MTR because they require many mysqlds.
    
      The new suite contains test cases requiring many (6 or more) mysqlds
      in a replication topology. Running those test cases with
      "--parallel" > 1 may exhaust the test host I/O resources. So, this
      new suite should run only with "--parallel=1".

[33mcommit ee5bb64ccafa4629d2de0ea93d7b46727703abfc[m
Author: Erik Froseth <erik.froseth@oracle.com>
Date:   Fri Jun 30 08:35:40 2017 +0200

    WL#9223 Using histogram statistics in the [1;31moptim[mizer
    
    This worklog makes use of histogram statistics in the [1;31moptim[mizer
    during query planning. It is used for estimating the selectivity
    given one or more predicates.
    
    Change-Id: I337a90e71698f0d36d24b8e5ac648a4b7847ec08

[33mcommit 93f6badda86b030dbc8b770a5ee1886acd71d123[m
Author: Deepthi ES <deepthi.e.s@oracle.com>
Date:   Sat Aug 19 19:21:23 2017 +0530

    WL#10475 : Defaults: Enable Parallel Replication Applier
    
    This worklog enbles parallel replication applier by enabling the 3 options by default :
    
    Server Changes:
    slave-parallel-type = LOGICAL_CLOCK : Enables the [1;31moptim[mal generic parallelism
    method.
    slave-parallel-workers = 4 : Offers a good base level of parallelism.
    slave-preserve-commit-order = ON : Ensures no user/application visible changes
    in behavior.
    
    User Override
    slave-parallel-workers = 0 : disables parallel slave applier execution and
    causes the other two options to be ignored

[33mcommit 1afff519aa3e919331b45376d799052e6433e0ca[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Fri Aug 18 09:15:46 2017 +0200

    WL#9814 Implement INFORMATION_SCHEMA system views for FILES/PARTITIONS
    
    This patch implements I_S.FILES as a system view over data
    dictionary tables, and remove 5.7 code that uses a temporary
    table to represent I_S view.
    
    Following changes are made in the patch:
    
    * Define a system view over data dictionary tables representing
      I_S.FILES.
    
    * Remove 5.7 code from sql_show.cc for I_S.PARTITIONS.
    
    * Add new handler API handlerton::get_tablespace_statistics_t with
      following signature.
    
      typedef bool handlerton::(*get_tablespace_statistics_t)(
                      const char *tablespace_name,
                      const dd::Properties &ts_se_private_data,
                      ha_tablespace_statistics *stats);
    
      This handler provides following data to I_S.FILES,
        ID,
        TYPE,
        LOGFILE_GROUP_NAME,    // To be used by NDB
        LOGFILE_GROUP_NUMBER,  // To be used by NDB
        FREE_EXTENTS,
        TOTAL_EXTENTS,
        EXTENT_SIZE,
        INITIAL_SIZE,
        MAXIMUM_SIZE,
        AUTOEXTEND_SIZE,
        VERSION,     // To be used by NDB
        ROW_FORMAT,  // To be used by NDB
        DATA_FREE,
        STATUS
    
    * Add new internal native functions to fetch above statistics for
      I_S.FILES.
        INTERNAL_TABLESPACE_ID()
        INTERNAL_TABLESPACE_TYPE()
        INTERNAL_TABLESPACE_FREE_EXTENTS()
        INTERNAL_TABLESPACE_TOTAL_EXTENTS()
        INTERNAL_TABLESPACE_EXTENT_SIZE()
        INTERNAL_TABLESPACE_INITIAL_SIZE()
        INTERNAL_TABLESPACE_MAXIMUM_SIZE()
        INTERNAL_TABLESPACE_AUTOEXTEND_SIZE()
        INTERNAL_TABLESPACE_DATA_FREE()
        INTERNAL_TABLESPACE_STATUS()
    
    * Added new per statistics cache class dd::info_schema::Tablespace_statistics
      to store statistics retrived by SE to be used when processing
      single row of a I_S query. This avoids internal native functions to
      invoke SE API only once per row.
    
    * Renamed dd::info_schema::Statistics_cache to
      dd::info_schema::Table_statistics because we now have not only table
      statistics by tablespace statistics to be cached.
    
    * Added ORDER BY clauses in some of I_S query to force order of
      tuple returned. Because, now the [1;31moptim[mizer returns the rows and
      not read from temporary table as in 5.7 I_S design.
    
    * Add new error message that can be reported when by I_S.FILES when
      tablespace is missing when fetching tablespaces statistics.
    
    * Remove part of test case in main.information_schema. Because,
    
      - The problem reported back then is only applicable for 5.7
        code.
    
      - The output of EXPLAIN ... <select on I_S system view> goes
        through [1;31moptim[mizer and then plan return might vary.
    
    * Suppress additional warnings generated which report missing tablespaces.
      This happens now, because of one of following,
    
      case1) If .ibd is copy by user manually on file-system, then DD is not
             updated and hence I_S do not see it. The 5.7 behavior is that it looks
             at .ibd file in file-system and not in DD.
    
      case2) Once I_S query execution starts we see the content of DD as of the
             time I_S query started. If there is a new tablespace added or removed,
             then I_S would not see it.
    
    * MySQL 5.7 does prefix './' with all .ibd files which are to be stored in
      data directory. MySQL 8.0 had skipped it. I_S.FILES system view prefixes
      './' if filename does not have explicit patch already specified by user.
    
      Perhaps this should need a fix in server or innodb. Probably the concern
      raised in Bug#26518545 is the same. We might need to change
      I_S.FILES.FILE_NAME definition after the bug fix.
    
    * Test case for Bug#23477214 is removed now. Because the race condition
      does not apply now after I_S.FILES becomes a system view.
    
    * Record result files with capital I_S column names, this is expected. See
      WL6599 for more info.
    
    * We now show 1024 character of partition comment string, unlike just 80
      characters shown in 5.7 by I_S.

[33mcommit f4442838be86ec00123fb17752e6be8a97b7181b[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Fri Aug 18 09:15:39 2017 +0200

    WL#9814 Implement INFORMATION_SCHEMA system views for FILES/PARTITIONS
    
    This patch implements I_S.PARTITIONS as a system view over data
    dictionary tables, and remove 5.7 code that uses a temporary
    table to represent I_S view.
    
    Following changes are made in the patch:
    
    * Define a system view over data dictionary tables representing
      I_S.PARTITIONS.
    
    * Add following new dictionary columns to store utf8 string version.
    
      mysql.table_partitions.description_utf8 representing
      I_S.PARTITIONS.DESCRIPTION
    
      mysql.tables.subpartition_expression_utf8 representing
      I_S.PARTITIONS.SUBPARTITION_EXPRESSION
    
      mysql.tables.partition_expression_utf8 representing
      I_S.PARTITIONS.PARTITION_EXPRESSION
    
    * Make dd::info_schema::Statistics_cache implementation to
      consider not just schema_name and table_name for cache key, but
      also include partition name. This is required now because we
      now cache per partition dynamic statistics with this WL.
    
    * Make dd::info_schema::Statistics_cache implementation to cache
      the table checksum value. This value is computed only for
      partitions.
    
    * Make implementation of Statistics_cache::read_stat_by_open_table()
      to fetch per partition dynamic table statistics.
    
    * If a partition is not found when fetching dynamic table
      statistics, then we will report a warning and continue
      processing new rows.  This might happen when I_S system view
      execution starts and later the partition table is ALTERed. A
      test case parts.partition_debug_sync_innodb is updated to cover
      this scenario.
    
    * Change definition of internal sql functions to accept partition
      name.This is used to calculate the per partition statistics.
    
      We currently read the statistics for partitioned table by
      opening the table. We can probably improve the performance for
      InnoDB partitioned tables, by calling SE api's that read just
      the statistics. This is not done as of now.
    
    * Introduce internal sql function
      INTERNAL_GET_PARTITION_NODEGROUP() to fetch
      I_S.PARTITIONS.NODEGROUP value from
      mysql.table_partitions.options.
    
    * There is no consumer of function expr_to_string() requesting
      the string in hex form. So, the patch modifies it to return
      only string.
    
    * Remove 5.7 code from sql_show.cc for I_S.PARTITIONS.
    
    * Added ORDER BY clauses in some of I_S query to force order of
      tuple returned. Because, now the [1;31moptim[mizer returns the rows and
      not read from temporary table as in 5.7 I_S design.
    
    * Remove part of test case in main.information_schema. Because,
    
      - The problem reported back then is only applicable for 5.7
        code.
    
      - The output of EXPLAIN ... <select on I_S system view> goes
        through [1;31moptim[mizer and then plan return might vary.
    
    * We now show 1024 character of partition comment string, unlike just 80
      characters shown in 5.7 by I_S.

[33mcommit 68512547c244d57bc94408f00a708844d0541855[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Fri Aug 18 10:21:17 2017 +0530

    Bug#26497247:WINDOW FUNCTIONS: CRASH IN DO_COPY_MAYBE_NULL
    
    Problem:
    Writing NULL to a non-nullable column results in server exit as null_ptr is not
    allocated.
    
    Analysis:
    ROLLUP writes NULL's to columns which are part of group by clause. So we set
    "maybe_null" to true in ::resolve_rollup() if any item in the item
    list is part of group_by clause. We also set "maybe_null" to true for all the
    arguments to a function, which are part of group_by clause. This happens in
    ::change_group_ref() and similarly we generate Item_null_result objects
    in ::rollup_make_fields() for items which are part of group by clause.
    
    However, [1;31moptim[mizer does not set "maybe_null" to true for arguments to a
    window function as ::change_group_ref() is called only if an item is of
    Item_func type which is not the case for windowing functions.
    But we do add all the arguments of a window function to the item list when
    ::split_sum_func() gets called. So checking if this argument is equal to any
    item in group by clause, would ensure that "maybe_null" is set to true.
    By setting it to true, fields would be created in temp tables using
    create_tmp_field_from_item() instead of create_tmp_field_from_field() which
    further ensures that null_ptr's are allocated correctly.
    
    Solution:
    Check if an item is part of group by clause by calling ::eq() instead
    of just pointer comparison. This is in line with what we do in ::change_group_ref()
    and in ::rollup_make_fields().

[33mcommit 7674c07d2db9f40a29c36b560011d43a3e898b5f[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Wed Aug 16 11:48:40 2017 +0530

    Bug #26496645: WINDOW FUNCTIONS: CRASH IN WINDOW::RESTORE_SPECIAL_RECORD
    
    Problem
    When we have a value which is less than argument value for a range frame in
    a windowing function, mysql server exits
    
    Analysis:
    Currently, for a range [1;31moptim[mizable window function, the result of the
    window function is stored into a in-memory table in the form of a
    special record, which can be restored later.
    This saves us time from calculating the results again for the next row if
    the value for window function is expected to be the same. But for a case
    when all the values in the frame are less than the specified range value,
    we skip saving this special record. This results in restoring a non-existent
    record and the server exits because of this.
    
    Solution:
    Added saving of the special record to the code flow in
     process_buffered_windowing_record.

[33mcommit cee10edc538af3e6f3dc7ace45026fe244660ffc[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Wed Aug 16 11:21:59 2017 +0530

    Bug#26497353: ASSERTION FAILED: M_OPENED_TABLE != NULLPTR
    
    Problem:
    Temp table is not created to handle grouping for the query as its grouping
    on constants. When a temp table is created for handling windowing function,
    it does not get instantiated because window_short_circuit is enabled and we
    choose end_write_group to write to it. But end_write_group fails while trying
    to write to the uninstantiated temp table.
    
    Analysis:
    For the given query, a temp table is needed to materialize group rows for rollup
    before windowing functions can be handled. But need_tmp_before_win does not
    get set. If rollup is not present, "group by" gets [1;31moptim[mized away in
    [1;31moptim[mize_distinct_group_order() and we do not see the issue. However, when
    rollup is present, as group by is not [1;31moptim[mized away for this case, we need a
    temp table. (see [1;31moptim[mize_distinct_group_order())
    
    Solution:
    Set need_tmp_table_before_win, when rollup is present with windowing functions
    (similar to rollup with distinct).

[33mcommit 10a3fe05784854b9b9c8c6f88d7841257945b23c[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Aug 8 15:29:47 2017 +0200

    Bug#26037206 WL8117: VALGRIND WARNINGS IN DERIVED.TEST
    
    Running 'mtr --valgrind --debug main.derived' gives misc warnings, mostly
    in the handler interface when printing human-readable versions of records.
    
    Fix: don't print records when running with --valgrind, unless the server
    is actually *built* with -DWITH_VALGRIND=1
    
    Also: initialize buffer for dbug-printing range [1;31moptim[mizer trees.
    Initialize Protocol_classic::input_packet_length in the default CTOR.
    
    Change-Id: I365cde0fe5158d7004228c3c0c873812cb78e437

[33mcommit 199eb8047690350b39cd60b3381d3c0b2c3cc8b1[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Aug 8 15:30:14 2017 +0200

    Bug #26562464: ONE DEFINITION RULE VIOLATIONS [noclose]
    
    The C++ One Definition Rule states, among others, that all structs must be
    defined equivalently in all translation units in a program, or undefined
    behavior occurs. This patch doesn't fix all the ODR violations found by GCC
    when using link-time [1;31moptim[mization, but it fixes some of them, and makes it
    possible to build MySQL with LTO at all.
    
    Change-Id: I436d612c73a301c66e83e122f48cf230d621a6f1

[33mcommit 1319f6619658b18e6c18392782a1c9aa3f58ea5e[m
Author: Martin Hansson <martin.hansson@oracle.com>
Date:   Thu Jun 22 09:09:49 2017 +0200

    WL#10891: [1;31moptim[mizer_switch to see invisible indexes
    Bug#25837038: FEATURE REQUEST : USE INVISIBLE INDEXES SPECIFIC QUERY
    
    This patch adds the [1;31moptim[mizer_switch use_invisible_indexes,
    which lets the session's queries leverage invisible
    indexes. The variable is read by
    TABLE_SHARE::usable_indexes().

[33mcommit 07fdc81331459a3d217668fc336298a0e0f13ed8[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Thu Jul 20 10:46:41 2017 +0200

    Bug#26495028: REMOVE UNNECESSARY JSON CODE FROM BINARY
    
    Use function objects instead of function pointers as arguments to
    std::find_if_not and std::any_of in json_path.cc. Even though GCC
    seems to be able to inline the function calls in release builds with
    [1;31moptim[mization level 3, it leaves the function definitions in the
    binary, presumably because pointers to them have been taken. Using
    function objects makes it eliminate the function definitions from the
    binary. An additional benefit is that function objects are more likely
    to be inlined at lower [1;31moptim[mization levels.
    
    Also change the calculation of the typelit_max_length constant in
    item_json_func.cc to use constexpr functions so that it gets
    calculated during compilation.
    
    Change-Id: Id90f64a9a68f894c688905a75df5adb74f7e3971

[33mcommit d771a19f51021fce07579fecc2016fd6fc3e6b1d[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Wed Jul 26 08:32:41 2017 +0800

    Bug #25982097  WRITESET DEPENDENCY TRACKING SUB-OPTIMAL AFTER ROTATION OR ON EMPTY TRANSACTIONS
    
    Writeset replication generates sub-[1;31moptim[mal commit parents on some
    circumstances:
    1. after rotation the minimum commit parent is 0 and not 1, which
    makes the slave applier serialize transactions and not execute
    them in parallel;
    2. empty transactions clear the history, while they could just be
    ignored.
    The use of smaller history sizes makes the system behave better
    as the minimal commit parent will be reset earlier.
    
    To fix the problem, set the minimum commit_parent to 1 after
    rotation and an empty transaction does not clear the writeset
    history any more.
    
    mysql-test/suite/rpl/t/rpl_binlog_transaction_dependency_tracking_with_filters.test
    The above test is updated, since empty transactions which are
    filtered out by REPLICATE_IGNORE_DB=(nodb) do not clear the
    writeset history any more.
    
    mysql-test/suite/rpl/t/rpl_binlog_transaction_dependency_history_size.test
    mysql-test/suite/rpl/t/rpl_binlog_transaction_dependency_tracking_with_fk.test
    mysql-test/suite/rpl/t/rpl_binlog_transaction_dependency_tracking.test
    mysql-test/suite/rpl/t/rpl_binlog_transaction_dependency_tracking_with_indexes.test
    The above tests are updated, since the minimum commit_parent is set
    to 1 after rotation.

[33mcommit cec51276d37904635d991f423c08ed2c90a60ec2[m
Author: Sreeharsha Ramanavarapu <sreeharsha.ramanavarapu@oracle.com>
Date:   Tue Jul 25 10:49:48 2017 +0530

    Bug #25899921: INCORRECT BEHAVIOR WITH DESC INDEX AND
                   DELETE STATEMENT
    
    Issue:
    ------
    In case of an UPDATE/DELETE statement with an
    ORDER BY ... LIMIT, table scan is used. When the [1;31moptim[mizer
    tries to check if there is a cheaper ordering compared to
    filesort, some checks are missing.
    
    Solution:
    ---------
    Use the table object instead of the JOIN_TAB object.

[33mcommit 62d9d8e0f47ddac82c456e7cc8bd89c12063aede[m
Author: Havard Dybvik <havard.dybvik@oracle.com>
Date:   Wed Jul 12 11:24:25 2017 +0200

    Bug#26352119: WHERE JSON_EXTRACT() ON GEN KEY
    
    Updated to incorporate suggestions from Knut Anders.
    
    The index on a generated column, whose value was generated from
    JSON_EXTRACT, was in some cases not used because the [1;31moptim[mizer failed to
    substitute expressions with matching generated columns due to different
    collations being used for the string literals in the generated column
    expression and the corresponding string literals in the expression in
    the WHERE clause. The fix for bug#22991924 forces a character set
    introducer for string literals in generated columns, rewriting e.g. '$.id'
    to _utf8mb4'$.id'.  Because the character set is specified while collation
    is omitted, the collation type for the generated column is set to the
    default collation of utf8mb4; any specific collation set for the
    connection is ignored.  The collation of expressions in subsequent
    queries, also from the same connection, may therefore not match the
    collation of the corresponding generated column, thus preventing
    substitution and consequently use of any index on that column.
    
    To be compatible with this change, Item_func_json_extract::eq() now
    ignores collation when comparing strings with the same character set,
    enabling the [1;31moptim[mizer to successfully substitute JSON_EXTRACT
    expressions with matching generated columns. Doing this is safe as:
    
     1) JSON_EXTRACT does not depend on the collation of its string arguments
        because it converts them to utf8mb4 before passing them  on to the parser.
     2) JSON_EXTRACT (and most other JSON functions) are hard-coded to
        return utf8mb4_bin, hence the collation of its string arguments does
        not affect the collation of its returned value.

[33mcommit 751e6730c94e754da79100ebd2609e545ec60921[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Mon Jul 3 19:18:37 2017 +0200

    Bug#26388690: SUBOPTIMAL STRING::APPEND() USAGE IN JSON PROCESSING
    
    This improvement is based on a contribution by
    Alexey Kopytov <akopytov@gmail.com>.
    
    When creating an external representation of a JSON string, we should
    [1;31moptim[mize for the common case, which is that there are no special
    characters that need to be escaped.
    
    This patch makes the code scan for the first special character in the
    string, and copy sequences of non-special characters in one go with
    memcpy().
    
    While at it, also fix a bug where the special character 1F (Unit
    Separator) was not escaped, although both RFC 7159 and the code
    comments say it should be escaped. This is Bug#25977595 -
    JSON OUTPUT DOES NOT QUOTE ASCII 31.
    
    Microbenchmarks (64-bit, Intel Core i7-4770 3.4 GHz, GCC 6.3):
    
    BM_JsonStringToString_Plain          104 ns/iter [+214%]
    BM_JsonStringToString_SpecialChars   233 ns/iter [ +39%]
    BM_JsonObjectToString               1277 ns/iter [  +1%]
    
    Change-Id: Ica04fe96a0babee20ffbe7fecb59f1008f4929a2

[33mcommit df6d5800adbc2937eb815cc5006ff157b1c1d778[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Jul 3 13:09:29 2017 +0200

    Bug #26384166: SPEED UP DECIMAL/BINARY CONVERSIONS
    
    decimal2bin / bin2decimal is used fairly extensively in code that works on
    decimal columns. Pick some low-hanging micro[1;31moptim[mization fruit.
    
    Microbenchmarks (Skylake 3.4 GHz):
    
      BM_Decimal2Bin_10_2   24478 -> 21457 µs/iter  [+14.1%]
      BM_Bin2Decimal_10_2   19161 -> 16782 µs/iter  [+14.2%]
    
    Change-Id: I805d0af353472688f0b3cec239dba8fa6cef1458

[33mcommit 30613d6ac81ede01ad2c45ea8d74fd5d43163f48[m
Author: Havard Dybvik <havard.dybvik@oracle.com>
Date:   Fri Jun 23 14:33:29 2017 +0200

    Bug#25738624: ASSERTION `FALSE' FAILED IN SQL/SQL_EXECUTOR.CC
    
    An assertion protecting an unused branch failed if an indexed column in
    a system table was referenced in a MIN/MAX and in a join, and the
    [1;31moptim[mizer was unable to [1;31moptim[mize away the join in opt_sum_query(). If an
    index was used to extract the MIN/MAX value of the column, the row
    buffer of that table would get status 'started' with the content stored
    in the record[0] buffer. If the [1;31moptim[mizer later tried to access the
    table using read_system(), this status would cause an attempt to restore
    the content from the record[1] buffer instead of reading it directly
    from the table. Because only record[0] contains valid data and
    the branch restoring the data from record[1] is declared as unused, the
    assertion fails as it should.
    
    To account for cases where opt_sum_query() is able to determine MIN/MAX
    value from an indexed column in a system table but is not able to
    [1;31moptim[mize away subsequent reads to the same table, the row buffer status
    is now reset to 'not started' after reading the index. Any subsequent
    read will then fetch data from the table instead of attempting to
    restore it from record[1].

[33mcommit 425588ef52491b160059713cc06657b001070a40[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Mon Jun 26 10:15:20 2017 +0200

    Bug#26336244: REMOVE USAGE OF BOOST IN MYSQLPUMP SOURCE CODE
    
    The mysqlpump code has some usage of boost that is easily avoided:
    
    boost::trim is used to remove the trailing newline character from the
    string returned by std::ctime. However, all users of the returned
    string add a trailing newline for formatting purposes. This use of
    boost::trim can simply be dropped, and the formatting can stop adding
    the newline back.
    
    boost::split is used to read lines from a string, or sometimes values
    from a comma-separated list. The use of boost::split causes
    maybe-uninitialized warnings inside of boost in gcc 7 under certain
    [1;31moptim[mization levels (at least with -Og). It can be replaced with the
    use of std::istringstream and std::getline to read individual tokens
    from the stream. In one case std::string::substr is sufficient.

[33mcommit d9737c9114ceed97eff7f2e3edd974d43feb1f8e[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Mon Jun 26 08:45:15 2017 +0200

    Remove a couple of [1;31moptim[mizer tests from valgrind runs.
    
    main.greedy_[1;31moptim[mizer and main.window_functions_big time out.
    
    Approved by Anitha Gopi <anitha.gopi@oracle.com> over e-mail.

[33mcommit 7141f6db3364630f9e065f6b285b050adf97009d[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Fri Jun 16 11:37:15 2017 +0200

    WL#9185 MySQL Cluster support for new DD
    
     - remove now unnecessary friend declaration for
       ndbcluster_drop_database_impl() in ha_ndbcluster
     - remove outdated part of comment
     - mark ndb_[1;31moptim[mize_table() as const

[33mcommit ff690de83b493f0bc2a6556ee29a3b3ed48fb089[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Thu May 25 00:37:58 2017 +0200

    Bug#26138592 MANY DELETES (OR MANY INSERTS) THEN DROP TABLE MAY CAUSE UNDEFINED BEHAVIOUR
    
    When a fragment is about to be released (releaseFragResources), make sure
    that there are no pending expand or shrink on fragment.
    
    As [1;31moptim[mization change fragment state so that expand or shrink will do
    nothing.
    
    In addition to the above bug fix, in execEXPANDCHECK2 and execSHRINKCHECK2
    check of fragment level is moved before potentially pages allocation.

[33mcommit 9cf8a0b68adbb4f418bfc74b928f574a31fc87cb[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jun 9 08:56:07 2017 +0200

    Bug#26239591 ALLOW JOIN-PUSHDOWN OF JOIN IN COMBINATION WITH 'GROUP BY'
    
    Due to previous unclear seperation between the [1;31moptim[mize
    and execute phases when the query involved a 'GROUP BY',
    the 'join-pushable evaluator' couldn't previously be sure
    whether the [1;31moptim[mized QEP (Query Execution Plan) was pushable
    or not. Thus it choosed to not push 'grouped joins'.
    
    This has been cleaned up by WL5558 long ago, so we can
    now remove this limitation.

[33mcommit 9de621c5472779b36aa1d259d810da8aee3df1ea[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Jun 7 13:38:07 2017 +0200

    Bug #25997748: MIGRATE FROM HASH TO STD::UNORDERED_MAP [patch 4, noclose]
    
    Post-push fix: Fix a memory leak that only manifested itself in the test
    with GCC 4.x (which doesn't have the short-string [1;31moptim[mization for
    std::string).

[33mcommit 517efb8ae2d276b94c618bae2837fe9e5fe61802[m
Author: Dhruthi K V <dhruthi.k.v@oracle.com>
Date:   Thu May 18 17:50:07 2017 +0530

    WL#10477 Defaults: Enable Transaction Write Sets - Code Review
    
    Rationale
    
    By using Transaction Write Sets, the master has to do slightly more work to
    generate the write sets which is helpfull in conflict detection. This allows
    users to easily move into GR since transaction-write-set is a requirement for GR.
    Also, the new default will make users to easily enable binary log writeset
    parallelization on master to speed up replication.
    https://dev.mysql.com/doc/refman/8.0/en/replication-options-binary-
    log.html#sysvar_binlog_transaction_dependency_tracking
    
    Server Changes
    
    transaction-write-set-extraction = XXHASH64 : Enables the [1;31moptim[mal method for
    generating the write set hashes.

[33mcommit 26f0ba33b7bc64439146566fb299d003934576b0[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Mon May 15 16:59:31 2017 +0200

    WL#9344: Logging services: error messages
    
    Post-push fix: broken ndbcluster build in [1;31moptim[mized mode.
    include/mysql/components/services/log_builtins.h:1043:
    error: undefined reference to 'log_bi'
    
    Change-Id: I08356f0107db6e29c0fc9566d522c720c3603ec5
    Fix: #include log.h before log_builtins.h in ndb source files.

[33mcommit 3503477a67f0fb469d5189502120664807741486[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon Apr 24 15:24:22 2017 +0200

    WL#8500 Adapt MySQL Cluster to 8.0
    
     - some information_schema tables and columns are now cached, tests
       which want to read the absolute latest value need to turn the
       caching off or repopulate using ANALYZE TABLE
     - fix problem with ndb_[1;31moptim[mize_table which read
       information_schema.tables.data_length before and after OPTIMIZE TABLE
       to determine if [1;31moptim[mize was succesful by turning caching off
     - remove unnecessary DROP TABLE IF EXISTS, FLUSH TABLES, use of
       sever variables and restore of session variables.
     - improve comments

[33mcommit 749d0c169ec7fa57004d2354ddb2e2721311d71d[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Apr 20 10:53:47 2017 +0200

    WL#8500 Adapt MySQL Cluster to 8.0
    
     - fix result of ndb_index to accept new explain output
       from group by query, [1;31moptim[mizer have changed
     - fix result of ndb_index_unique to accept new explain
       output, the "Using where" clause is gone.
     - fix result of ndb_index_unique to mixed case when querying
       performance_schema.session_status

[33mcommit 0be0718f6b773916f7cc6dacfa7d9b64dd2377fb[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Apr 20 10:13:11 2017 +0200

    WL#8500 Adapt MySQL Cluster to 8.0
    
     - fix ndbinfo.test
     - to show the columns of a hidden ndbinfo table you now need to
       turn ndbinfo_show_hidden on, since before accesing DD the
       ndbinfo_find_files is asked wheter to allow it or not.
     - change to uppercase column names in information_schema.views query
     - slightly different counter values, seems reasonable and most
       likely changed because of [1;31moptim[mizer
     - remove unused argument varnings and fix spelling error in
       ndbinfo_find_files()

[33mcommit eecdf6a61b3af51f2f048059ffab3195fc83b352[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon Apr 10 13:52:48 2017 +0200

    WL#8500 Adapt MySQL Cluster to 8.0
    
     - fix ndb_join_pushdown_*.result
     - different explain outputs caused by WL#s implementing
       descending indexes, causing "Using filesort" to be removed for
       some queries and "asc" to be appended to explain output
     - different explain outputs caused by WL#s implementing
       [1;31moptim[mizer cost model adjustments causing cost estimates to change
     - variable names from performance_schema are no longer in upper case

[33mcommit 269139b2bd2842f47e8cab0296c6d110b73ea730[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon Apr 3 12:45:11 2017 +0200

    WL#8500 Adapt MySQL Cluster to 8.0
    
     - update .result files for gcol_ndb tests which sources upstream
       include files.
     - fixing diffs caused by "WL#1074: Add descending indexes support"
       which turn off filesort.
     - fixing diffs caused by "WL#8737 IO aware defaults for [1;31moptim[mizer
       cost constants" which changes the [1;31moptim[mizer const constant
     - siumilar fixes has been done to upstream .result files
     - this patch requires fixes to gcol_keys.inc and gcol_select.inc
       done by bug25820923

[33mcommit af348acb1fbb89b3e39356d3b69393bb6d967321[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Sat Apr 22 03:50:01 2017 +0200

    WL#9495 Update schema tables of dynamic plugins into data dictionary.
    
    This WL focuses to present INFORMATION_SCHEMA (I_S) tables
    metadata to be visible through I_S.TABLES. Following are the
    three areas where we can find I_S tables in MySQL server.
    
       1. Server I_S table.
       2. Builtin plugin's I_S table.
       3. Dynamic plugin's I_S table.
    
    Writes metadata of above I_S tables to data dictionary (DD)
    tables, so that the system view I_S.TABLES picks it. Major
    changes involve,
    
    * Update DD tables when a plugin is loaded or unloaded.
      This can happen when server is started by command line
      options or by INSTALL/UNINSTALL commands.
    
    * Store plugin I_S table metadata in DD on server restart.
      Discard old plugin I_S table metadata based on plugin
      version number.
    
    * Upgrade system views by introducing 'IS_version' number.
    
    * Update server I_S table metadata into DD upon server
      initial start. And also update the same based a
      'IS_version' upon server restart.
    
    * Move creation of system views from mysql_system_tables.sql
      script to server initial start similar to the way the
      DD tables are created.
    
    * Hide I_S.*_DYNAMIC and I_S.SHOW_* internal system view
      from user to be visible from INFORMATION_SCHEMA.TABLES.
    
    * Restrict use of I_S.SHOW_* and I_S.*_DYNAMIC I_S table
      names in a SQL statement by user, similar to the way we
      restrict use of DD table names.
    
    The patch also does following,
    
    - Keep all the related I_S metadata related code in
      sql/dd/info_schema namespace.
    
    - Rename table mysql.version to mysql.dd_properties. Due to
      the new definition and name of the version table the new
      binaries cannot run on old data directories.
    
    - Store 'IS_version' property in mysql.dd_properties. Update
      IS metadata in DD upon server restart if this version
      changes.
    
    - Force [1;31moptim[mizer to use InnoDB engine (during bootstrap) to
      instantiate temporary table while processing UNION clause
      when creating I_S system system.
    
    - Add SELECT_LEX flag call OPTION_SELECT_FOR_SHOW which
      enables server to block any use of server internal system
      views by the users in user SQL statements.
    
    - I_S column property is_nullable and is_unsigned are also
      stored in DD now, this was ignored earlier.
    
    - The st_field_info has no option to specify a default value,
      numeric precision and scale, and hence these values would
      differ when compared to new values. This is something we
      can work on to match the behavior, but it seems like these
      values are of less important to users.
    
    - Added test to thread_pool.thread_pool_i_s_restart with
      scenarios specific to loading I_S plugin using --plugin_load
      option.
    
    - Added test case in main.information_schema and other
      scenarios are being tested by existing test cases.

[33mcommit 14ed25dc7da5efad7a31892bf229c7205c9e696c[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Mon Mar 27 09:35:09 2017 +0200

    WL#8963: Support for partial update of JSON in the [1;31moptim[mizer
    
    Post-push fix: Filter out unstable part of EXPLAIN FORMAT=JSON output
    in testing of multi-table updates. The set of "used_columns" is
    different when the test runs with --mysqld=--log_bin (bug#22472365).

[33mcommit c5f663e74f914505efa1c8c676149ad5e0a8ad8c[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Tue Mar 21 12:38:05 2017 +0100

    WL#8963: Support for partial update of JSON in the [1;31moptim[mizer
    WL#9192: Add JSON_STORAGE_SIZE / JSON_STORAGE_FREE functions
    
    This commit introduces infrastructure in the [1;31moptim[mizer to help the
    storage engines perform partial update of JSON values more
    efficiently. Partial update can be performed for UPDATE statements
    such as
    
      UPDATE t SET json_col = JSON_SET(json_col, '$.path', 'abc')
    
    or
    
      UPDATE t SET json_col = JSON_REPLACE(json_col, '$.path', 'xyz')
    
    if the new value can be added to the JSON document by overwriting the
    old value at the modified path. This is possible if the new value does
    not require more storage space than the value that is replaced, or if
    there is sufficiently unused spaced around the replaced value to add
    the new value without increasing the size of the JSON document.
    
    When partial update is possible, a list of differences between the
    original document and the updated document is made available to the
    storage engine, so that it can write only the few bytes that actually
    changed, instead of rewriting the entire document, thereby reducing
    the amount of I/O.
    
    No storage engine takes advantage of this information for now.

[33mcommit 9fdf2e21a9d85a0adaf214e8bd49df72237835f6[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Mar 16 15:20:01 2017 +0100

    Bug #25733784: NUM_TMP_FILES IN FILESORT OPTIMIZER TRACE IS NONSENSICAL
    
    num_tmp_files in [1;31moptim[mizer trace for filesort is a pretty meaningless number;
    it holds the number of chunks left after the final disk merge pass, so it's
    always between 1 and 15 (MERGEBUFF2). This isn't a very good indication of
    how much disk activity it is (and they're all really in one file, so “files”
    is wrong).
    
    Rename the parameter to “num_initial_chunks_spilled_to_disk”, and make it
    contain the actual number of chunks _before_ any merging has happened.
    
    Change-Id: I07cb2cb39a41a15356e6e771eb50da25471d5b41

[33mcommit 282d15d8bb03095ebb6ef286b8466bd0c8278bb5[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Fri Mar 10 12:55:20 2017 +0100

    WL#10344: Remove disabling of strict aliasing [1;31moptim[mization (GCC)
    
    This patch re-enables the strict aliasing [1;31moptim[mization when building
    the server with GCC or Clang. Sysbench tests have shown a 0-4%
    performance increase - especially for single-threaded tests.
    
    -fno-strict-aliasing is still used when building NDB or
    InnoDB memcached.
    
    The patch also fixes a few recently introduced strict-aliasing
    build warnings in mysqlpump.

[33mcommit d5c5e1dbcec85e754ebbff0e0bd133b56cbf523c[m
Author: Havard Dybvik <havard.dybvik@oracle.com>
Date:   Wed Mar 15 10:47:29 2017 +0100

    Bug#23209903: ASSERTION: SELECT_LEX->LEAF_TABLE_COUNT == 0 || THD->LEX->IS_QUERY_TABLES_LOCKED
    
    Problem: The explain function for single-table modifications by UPDATE and
    DELETE statements would attempt to [1;31moptim[mize all subqueries in a query. But if a
    query is empty (the outermost query block is determined to return no rows), none
    of its referenced tables will be locked between the preparation and [1;31moptim[mization
    phases as the subqueries are not to be executed. Optimizing subqueries in an
    empty query will therefore cause an assertion in JOIN::[1;31moptim[mize() to fail.
    
    Fix: Explain for single-table modifications will only [1;31moptim[mize and explain
    subqueries in non-empty queries.

[33mcommit d683d253698dc0096c230ff8f6c048a77d9637b4[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Mar 8 11:03:52 2017 +0100

    Bug #25688673: REMOVE SPECIAL-CASING OF NON-STRNXFRM-BASED COLLATIONS
    
    Some character sets are designated as MY_CS_STRNXFRM, meaning that sorting
    needs to go through my_strnxfrm() (implemented by the charset), and some are
    not, meaning that a client can do the strnxfrm itself based on
    cs->sort_order. However, most of the logic related to the latter has been
    removed already (e.g. filesort always uses my_strnxfrm() since 2003), and now
    it's mostly in the way. The three main uses left are:
    
     1. A micro[1;31moptim[mization for constructing sort keys in filesort.
     2. A home-grown implementation of Boyer-Moore for accelerating certain
        LIKE patterns that should probably be handled through FTS.
     3. Some [1;31moptim[mizations to MyISAM prefix keys.
    
    Given that our default collation (utf8mb4_0900_ai_ci) now is a strnxfrm-based
    collation, the benefits of keeping these around for a narrow range of
    single-byte locales (like latin1_swedish_ci, cp850 and a bunch of more
    obscure locales) seems dubious. We seemingly can't remove the flag entirely
    due to #3 seemingly affecting the on-disk MyISAM structure, but we can remove
    the code for #1 and #2.
    
    Change-Id: If974e490d451b7278355e33ab1fca993f446b792

[33mcommit cf3c40097241dd597449e5d323e4e7d07310a971[m
Author: Bjorn Munch <bjorn.munch@oracle.com>
Date:   Tue Nov 15 14:39:50 2016 +0100

    Bug #25083555 SOME TESTS FAIL WITH DEBUG SERVER ON SOLARIS WHEN BUILT WITH DEVELOPER STUDIO
    
    When we do a release type build of the server (with both [1;31moptim[mized and
    debug enabled server/plugins) with Developer Studio, some MTR tests
    when run with --debug-server will fail in one of two ways:
    
    1. Tests which try to load a plugin into the mysql client fail with
       missing symbols. This is caused by the plugin having references to
       functions which do not exist in the non-debug client.
    
    2. Some tests on sparc fail with Thread stack overrun.
    
    Fix for issue #1: mtr will have appended /debug to the plugin dir part
    when running with --debug-server and if there actually is such a
    directory. The fix is to remove any trailing /debug from the
    env. variable within the test. This will affect the client only, not
    the server. Developer builds will not have put the plugins in a
    subdirectory /debug so it makes no different to those.
    
    Fix for issue #2: apparently this thread stack overrun is not feasible
    to avoid, so just skip the test if running with debug server on sparc;
    there is already an include file to do that.
    
    Also added not_sparc_debug.inc to the "white list" so the tests are
    skipped even when running mtr --no-skip.
    
    (cherry picked from commit 9c79e477261ab252e38def436bca3336ef597603)

[33mcommit fa9e1f6dff27673f992e8f64c79b29177726169d[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Fri Mar 10 22:41:18 2017 +0100

    Bug#25709647: FIX MAYBE-UNINITIALIZED WARNINGS
    
    Debug builds with gcc fail because of maybe-uninitialized warnings
    when -Og is given as extra [1;31moptim[mization flag.
    
    Change-Id: I7e4781bfa4d03d67f5b28c3e768460a37a607904

[33mcommit 7d8f29750b4508ae6179d0a3a179d01e695a0ff3[m
Author: Bernt M. Johnsen <bernt.johnsen@oracle.com>
Date:   Sat Mar 4 17:49:20 2017 +0100

    Bug#25669553 MTR DOES NOT CLEAN DATADIR WHEN PREVIOUS TEST HAD BOOT OPTIONS.
    
    Post-push fix for WL#7554. This is non-[1;31moptim[mal, but get the value of
    MYSQL_BOOSTRAP_CMD right. A finaly fix would be to set
    MYSQL_BOOSTRAP_CMD elsewhere so you den't get the not needed
    cla-datadir() call.

[33mcommit d63308401ac0718113d70a9ff353d5fa193abb75[m
Author: Bernt M. Johnsen <bernt.johnsen@oracle.com>
Date:   Sat Mar 4 17:49:20 2017 +0100

    Bug#25669553 MTR DOES NOT CLEAN DATADIR WHEN PREVIOUS TEST HAD BOOT OPTIONS.
    
    Post-push fix for WL#7554. This is non-[1;31moptim[mal, but get the value of
    MYSQL_BOOSTRAP_CMD right. A finaly fix would be to set
    MYSQL_BOOSTRAP_CMD elsewhere so you den't get the not needed
    cla-datadir() call.

[33mcommit 7d17582eb0cfd25bcb0c37b067c7839fa7d32d31[m
Author: Oystein Grovlen <oystein.grovlen@oracle.com>
Date:   Sat Mar 4 07:14:01 2017 +0100

    WL#10128: Add defaults column to [1;31moptim[mizer cost tables
    
    This worklog adds generated columns that will show the default values for
    the constants defined in the two system tables, server_cost and engine_cost.
    
    Details:
    
    scripts/mysql_system_tables.sql
       Add column definition to cost constant tables.
    
    scripts/mysql_system_tables_fix.sql
       Add SQL code to upgrade cost constant tables to include column.
    
    sql/opt_costconstants.cc
       Added comment to remind developers that above scripts need to be
       updated to if cost constants are changed.
    
    sql/opt_costconstantcache.cc
       In order for resolving of generated column to work correctly when
       opening cost tables, lex_start() must be called.
    
    mysql-test/t/opt_costmodel_tables.test
    mysql-test/r/opt_costmodel_tables.result
       Added test that default_value is defined for all cost constants.
       Added test that verifies that default_value columns may not be updated
       Update test and result files to handle new column.
    
    mysql-test/t/opt_costmodel_upgrade.test
    mysql-test/r/opt_costmodel_upgrade.result
       New test file to test upgrade of cost tables.
       mysql_upgrade currently fails with 4k pages.
       Only run test when page size is minimum 8k
       Defined as big test since it may time out with high load.
    
    mysql-test/t/opt_costmodel_restart.test
    mysql-test/r/opt_costmodel_restart.result
    mysql-test/t/opt_costmodel_warnings.test
    mysql-test/r/opt_costmodel_warnings.result
       Update test and result files to handle new column.
    
    mysql-test/suite/funcs_1/r/is_columns_mysql.result
    mysql-test/suite/innodb/r/innodb-system-table-view_ci.result
    mysql-test/suite/innodb/r/innodb-system-table-view_cs.result
    mysql-test/suite/innodb/r/virtual_basic.result
       Update result files for tests that are affected by system tables definitions
    
    mysql-test/suite/i_innodb/t/discard_tablespace.test
       This test assumed that table created by the test was the only one
       with virtual columns.  This is no longer the case.  Fix assumes
       that system tables have lower table ids than the relevant table,
       and compares the maximum table id before and after ALTER TABLE.

[33mcommit 6d5ebe83126f6309458ae9fe9a52555044f92e41[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Feb 28 15:21:46 2017 +0100

    Bug#25474239 MISC MTR TESTS FAIL WHEN CHANGING DEFAULT CHARACTER SET FOR DATABASE
    
    Patch #9
    
    Also: Some tests failed in debug mode due to some DBUG_PRINT in the
    range [1;31moptim[mizer.
    Fix: check _db_enabled_() before doing any tree traversal
    
    To repeat:
    ./mtr --charset-for-testdb=utf8mb4 --defaults-file=include/utf8mb4_my.cnf
    
    locking_part
    
    innodb_icp
    innodb_icp_all
    innodb_icp_none
    myisam_icp
    myisam_icp_all
    myisam_icp_none
    
    [1;31moptim[mizer_bug12837084
    
    subselect_innodb.test
    
    select_all
    select_all_bka
    select_all_bka_nixbnl
    select_icp_mrr
    select_icp_mrr_bka
    select_icp_mrr_bka_nixbnl
    select_none
    select_none_bka
    select_none_bka_nixbnl
    
    Change-Id: I480fac2801e4135aa6d06c9ee8eb86d3f1f935d8

[33mcommit b16e96e6a5b8e338e65ff663d520381ab847439e[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Tue Feb 21 13:40:58 2017 +0100

    Bug#25576205 WRONG COLUMN CARDINALITY PASSED TO GET STATS
    
    The problem is that the UDF
    INTERNAL_INDEX_COLUMN_CARDINALITY() is invoked even for
    hidden index elements. The system view I_S.STATISTICS_BASE
    used CAN_ACCESS_TABLE() to ignore hidden indexes, but the
    [1;31moptim[mizer seem to invoke outer query conditions first and
    then the conditions of inner query. As per [1;31moptim[mizer team
    the view [1;31moptim[mization is correct and cannot be changed.
    
    In order to fix the problem, the UDF
    INTERNAL_INDEX_COLUMN_CARDINALITY() is passed as new
    argument conveying that index element is hidden. And if
    it is hidden the UDF will return NULL and avoid invoking
    SE API's for hidden elements.
    
    Because the hidden index elements are added in
    mysql-trunk-meta-sync tree the problem is not seen in
    mysql-trunk yet.
    
    A test case is added.

[33mcommit ebcb981807e3d91a64782e89d48e1a25622eafea[m
Author: Sergey Glukhov <sergey.glukhov@oracle.com>
Date:   Fri Feb 17 11:31:52 2017 +0300

    WL#9167 Index merge hints.
    
        INDEX_MERGE, NO_INDEX_MERGE hints are added to allow the user to
        control index merge behavior for the particular query without changing
        the [1;31moptim[mizer switch.
    
        INDEX_MERGE hint:
    
           The hint forces the [1;31moptim[mizer to use index merge for the specified
           table using the specified set of indexes. If no index is specified,
           all possible index combinations are considered by the [1;31moptim[mizer and
           cheapest one is selected.
    
        NO_INDEX_MERGE hint:
    
           The hint disables index merge combinations that involve any of the
           specified indexes. If no index is specified, index merge is not
           allowed for the table.

[33mcommit 9d1e341d1799f5ce9f456796595690540b994769[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Wed Feb 1 15:50:02 2017 +0100

    Bug#25253540 LOOP OPTIMIZATION COMPILE BUG ON SPARC WITH GCC 5.3.0
    
    Detect GNU C/C++ 5.3.0 Bug 78807 - Loop [1;31moptim[mization trigger bus error
    
    See https://gcc.gnu.org/bugzilla/show_bug.cgi?id=78807
    
    If compiler bug detected using test program, some tree loop [1;31moptim[mizations
    are turned off.
    
    Two CMake functions CHECK_C_COMPILER_BUG and CHECK_CXX_COMPILER_BUG are
    added that first check if bug is detected, and if so checks if given
    workaround works if not build is aborted otherwise the workaround flags
    are appended to compile flags.

[33mcommit ee8b04fe168173f93faef8f0f47ba1a846a996d3[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Wed Feb 1 15:50:02 2017 +0100

    Bug#25253540 LOOP OPTIMIZATION COMPILE BUG ON SPARC WITH GCC 5.3.0
    
    Detect GNU C/C++ 5.3.0 Bug 78807 - Loop [1;31moptim[mization trigger bus error
    
    See https://gcc.gnu.org/bugzilla/show_bug.cgi?id=78807
    
    If compiler bug detected using test program, some tree loop [1;31moptim[mizations
    are turned off.
    
    Two CMake functions CHECK_C_COMPILER_BUG and CHECK_CXX_COMPILER_BUG are
    added that first check if bug is detected, and if so checks if given
    workaround works if not build is aborted otherwise the workaround flags
    are appended to compile flags.

[33mcommit 389ea43bea4b0e230a35e65c648d53ff4591d95e[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Mon Feb 6 11:35:01 2017 +0000

    Bug #25306089 NDBAPI : FINALISE 'OLD' SCANS OUTSIDE OF TRANSPORTER RELATED LOCKS
    
     - The NdbRecord scan Api is [1;31moptim[mised w.r.t the NdbRecAttr based scan Api
     - At the time of introduction, the NdbRecAttr based scan Api was
       modified to use the NdbRecord scan Api internally
     - This required that the NdbRecAttr scan Api build up a set of scan
       parameters, which are used to define an actual NdbRecord scan in a
       'finalisation' step
     - This step was put into NdbScanOperation::executeCursor() which is
       executed as part of sending a scan to the data nodes.
     - Sending is done holding various transporter-layer locks
     - NdbRecAttr scan finalisation is really a 'definition' time operation
       potentially including memory allocation, object id allocation etc
     - Moving finalisation out of sending into the preparation phase allows
       it to be done without holding locks which :
       - Reduces hold time on contended locks
       - Avoids risks of deadlocks when adding locking to finalise()
    
     - This fix moves the finalise() step into executeAsynchPrepare(), which
       is called without holding any transporter locks
     - Additionally :
       - The fix for bug#42545 is modified to cover other scenarios where
         user code error checking is insufficient - any prepared scan
         (NdbRecAttr or NdbRecord) is covered for an unguarded nextResult()
         call
       - NdbScanOperation::close() is modified to avoid waiting for signals
         from the data node regarding a scan, when none were sent.
         This improves API error handling for cases other than data node
         failure where a prepared scan is not sent.
       - A new NdbApi error code 4342 is added to catch cases where a scan
         is defined but not prepared.
       - A new testcase testNdbApi -n OldApiScanFinalise is added to show
         the mechanisms working.

[33mcommit a9e792f7175d0aff0de3c5b0c06a80ae6856f46e[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Sun Jan 29 07:15:11 2017 +0100

    WL#6599 - New Data Dictionary and I_S integration.
    
    Post-push fix: Sporadic failure of main.show_check test.
    
    The test case for Bug#28808 is written to test behavior of
    'log_queries_not_using_indexes' variable based on test that uses
    INFORMATION_SCHEMA.TABLES. The expectation is that it should not
    use index. But, after WL#6599, INFORMATION_SCHEMA.TABLES is a
    system view which a JOIN over several DD tables and there is
    possibility of [1;31moptim[mizer opting to use a index. This leads
    [1;31moptim[mizer to set or unset SERVER_QUERY_NO_INDEX_USED as
    thd->server_status sporadically. And this causes
    log_slow_applicable() function to ignore logging the the query
    when SERVER_QUERY_NO_INDEX_USED is not set to thd->server_status.
    
    In order to fix the issue, the test case is modified to use a
    user table 'tab1' (as described in bug#28808) instead of
    INFORMATION_SCHEMA.TABLES. This avoid the sporadic failure.

[33mcommit 0768c0c425f244d8c800f77d1789f42d5827df88[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Wed Jan 18 12:07:59 2017 +0530

    WL#1074: Desc index support in mysql
    
    Post-push fix
    Test is not stable because [1;31moptim[mizer has three choices for index defined on
    the same field. Remove the choice of indexes defined on field "pk" so that
    [1;31moptim[mizer always chooses PRIMARY index.
    The corresponding code for this bugfix makes sure that the ranges are
    ordered correctly when desc index is chosen. Among the choice of indexes, only
    PRIMARY index is desc. So the original intention of the bugfix was to choose
    PRIMARY index itself.

[33mcommit 7be5eee9a8bc1b07db1fbe5acf5bf5ee2a9d6718[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Nov 29 15:52:09 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Various benchmarking tweaks as we prepare to wrap up the changes:
    
     - Make microbenchmarks show number of processed bytes, in order to
       easier compare throughput between the benchmarks, even if they have
       different input lengths.
     - Add benchmarks for two important cases that were missing (latin1,
       and Hungarian, a locale with frequent contractions). We don't intend
       to [1;31moptim[mize these at the current point, but having microbenchmarks
       is an important reminder of what is still left to work on.
     - Fix collation loading; just using the my_charset_foo pointer without
       initializing it first is illegal, and will break anything with
       e.g. contractions.
     - Add a unit test to verify that contractions are working at all.
    
    Change-Id: I85b4a8817fb630d2df36d9b8a4e7437a89a4745f

[33mcommit 629f8c5329b940fc070f805a242d2bbc5b0f1ce9[m
Author: Arnab Ray <arnab.r.ray@oracle.com>
Date:   Thu Dec 15 12:51:58 2016 +0530

    Post Merge Fix
    
    Update the result file of the ndb_statistics1 test.
    
    The changes are due to:
    
    - Fix for Bug #23259872: OPTIMIZER CHOOSES TO USE NON
      PRIMARY INDEX, EVEN THOUGH COST IS HIGHER. The [1;31moptim[mizer now
      chooses a range access rather than a ref access in this
      particular case
    - The addition of a new warning in WL#9457: Deprecate support
      for non-native partitioning

[33mcommit c7617fdc19bfe739d9fa6edd7f0c4ee7b87517bd[m
Author: Arnab Ray <arnab.r.ray@oracle.com>
Date:   Thu Dec 15 12:06:23 2016 +0530

    Post Merge Fix
    
    Update the result file of the ndb_statistics1 test. The change
    is due to fix for Bug #23259872: OPTIMIZER CHOOSES TO USE NON
    PRIMARY INDEX, EVEN THOUGH COST IS HIGHER. The [1;31moptim[mizer now
    chooses a range access rather than a ref access in this
    particular case

[33mcommit ce1a10576cc20ec6e43da1c6a119059f5a2db179[m
Author: Allen Lai <zheng.lai@oracle.com>
Date:   Thu Dec 8 18:54:56 2016 +0800

    Ported Bjorn's patch:
    
    commit 9c79e477261ab252e38def436bca3336ef597603
    Author: Bjorn Munch <bjorn.munch@oracle.com>
    Date:   Tue Nov 15 14:39:50 2016 +0100
    
        Bug #25083555 SOME TESTS FAIL WITH DEBUG SERVER ON SOLARIS WHEN BUILT WITH DEVELOPER STUDIO
    
        When we do a release type build of the server (with both [1;31moptim[mized and
        debug enabled server/plugins) with Developer Studio, some MTR tests
        when run with --debug-server will fail in one of two ways:
    
        1. Tests which try to load a plugin into the mysql client fail with
           missing symbols. This is caused by the plugin having references to
           functions which do not exist in the non-debug client.
    
        2. Some tests on sparc fail with Thread stack overrun.
    
        Fix for issue #1: mtr will have appended /debug to the plugin dir part
        when running with --debug-server and if there actually is such a
        directory. The fix is to remove any trailing /debug from the
        env. variable within the test. This will affect the client only, not
        the server. Developer builds will not have put the plugins in a
        subdirectory /debug so it makes no different to those.
    
        Fix for issue #2: apparently this thread stack overrun is not feasible
        to avoid, so just skip the test if running with debug server on sparc;
        there is already an include file to do that.
    
        Also added not_sparc_debug.inc to the "white list" so the tests are
        skipped even when running mtr --no-skip.
    
    for fixing test failures on Solaris.

[33mcommit b28a90b8f23e3abdbd8f1b2b9a3765e577255673[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Wed Dec 7 14:08:12 2016 +0100

    Bug#25183521: Rename a few fields in Query_result class
    
    Some functions are given more comprehensive names:
    
    - initialize_tables() is renamed to [1;31moptim[mize()
      This function is called during the [1;31moptim[mization stage to create
      specific objects that are needed for execution.
    
    - prepare2() is renamed to start_execution()
      Despite the name, this function is actually called at start of
      execution, after [1;31moptim[mization.
      So, we can eliminate a few "prepare() && prepare2()" constructs
      because they target different phases.
    
    Fields used in prepared DELETE and UPDATE statements change semantics
    slightly:
    
    - do_delete replaced with delete_completed.
    - do_update replaced with update_completed.
    
    These booleans will start out in false state and get set to true when
    the operation is actually completed.
    For repeated executions, they will likely be set to false in appropriate
    start_execution() function.
    
    In addition, some arguments and return values are cleaned up.
    Return values are changed from int to bool.

[33mcommit 8809747e7543598ff73cd61a02a22d921e20157f[m
Author: Oystein Grovlen <oystein.grovlen@oracle.com>
Date:   Wed Dec 7 09:26:46 2016 +0100

    WL#8737 IO aware defaults for [1;31moptim[mizer cost constants
    Addendum: Reset cost constant at end of greedy_search.test
              to avoid affecting other tests

[33mcommit c106e7a529a568e6ff1e62afa183ad0cd8208e6c[m
Author: Jimmy Yang <jimmy.yang@oracle.com>
Date:   Wed Dec 7 09:04:38 2016 +0800

    Remove UNIV_PFS_THREAD for create_thd() for purge and work thread. Create
    THD for FTS [1;31moptim[mizer thread. Replace more dict_table_open_*

[33mcommit cfdcc29d0ac1bace465c5d4138e7950fea53acf9[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Sun Dec 4 22:22:08 2016 +0100

    Bug#25201815: USE STD::IS_TRIVIALLY_DESTRUCTIBLE IN MEM_ROOT_ARRAY
    
    Remove the has_trivial_destructor template parameter from
    Mem_root_array, and instead let it determine automatically if the
    elements are trivially destructible using
    std::is_trivially_destructible.
    
    There were three cases where the has_trivial_destructor value did not
    match std::is_trivially_destructible:
    
    1) in_string::base_objects is a Mem_root_array of String objects,
    where has_trivial_destructor was true even though the String class has
    a non-trivial destructor. in_string's destructor manually destroyed
    all elements of the array to compensate for this. Now the memory is
    managed by Mem_root_array, and the manual destruction is removed.
    
    2) in_row::base_object is a Mem_root_array of cmp_item_row objects,
    where has_trivial_destructor was true even though the cmp_item_row
    class has a non-trivial destructor. Now the objects are destroyed
    automatically by Mem_root_array instead of manually by in_row's
    destructor.
    
    3) in_decimal::base is a Mem_root_array of my_decimal objects.
    my_decimal has a non-trivial destructor, but has_trivial_destructor
    was set to true. The destructor only contained sanity checks and did
    no resource management. Now we only define the destructor in debug
    builds, so that destruction is trivial (and still skipped) in
    [1;31moptim[mized builds.
    
    Change-Id: I935c68a196545ed78fff10d17386f07da964f936

[33mcommit 7187b6dc451433ee6274a4738576f7a65ae40d84[m
Author: Oystein Grovlen <oystein.grovlen@oracle.com>
Date:   Tue Dec 6 08:46:09 2016 +0100

    WL#8737 IO aware defaults for [1;31moptim[mizer cost constants
    Addendum: Stabilize some long-running tests
    
    Tests that runs long with much data got unstable cost estimates after
    WL#8737 since InnoDB would not necessarily have all of tables/indexes
    in buffer pool for the entire test.
    
    mysql-test/include/index_merge_ror.inc
    mysql-test/r/index_merge_innodb.result
    mysql-test/r/index_merge_myisam.result
      Mask entire cost estimates, not just decimals.
    
    mysql-test/r/greedy_search.result
    mysql-test/t/greedy_search.test
      Set memory_block_read_cost equal to io_block_read_cost to make plan
      search independent on how much data is cached in buffer pool.

[33mcommit 0ebb1902359788a50765ee3c112cc8498efaac9d[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Fri May 6 23:13:52 2016 +0200

    WL#9609: Remove alias [1;31moptim[mization part of LocalXXXList
    
    XXXList<Pool,Head>(Pool&) - internal head, empty on ctor, should be empty on dtor
    XXXList<Pool,Head&>(Pool&, Head&) - external head
    XXXList<Pool,const Head&>(Pool&, Const Head&) - read only
    XXXList<Pool,Head&>(Pool&, Head&) - move external head local, and back on destruction

[33mcommit 8e257e76a8b5798729fb111bb78cd4cf26980e2b[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Nov 29 12:48:57 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Micro[1;31moptim[mize and simplify utf8mb4 parsing:
    
     - Use regular AND masks and comparisons instead of xor-ing away
       the continuation bits. GCC rewrites the xor-and-comparison tests
       to wrapping adds, which are not as easy to mix with shifts as
       ANDs are. (See also below.)
     - Use adds instead of ors, since these are equivalent and can
       sometimes be rewritten as LEAs. (The compiler doesn't actually
       seem to do so in this case, though.)
     - When testing for multiple continuation bytes, read a larger
       chunk using memcpy and do all the comparisons at the same time.
       This would not be possible to do using the XOR trick.
     - When testing if we are outside the allowed range for a given number
       of UTF-8 bytes, simply test the resulting code point (after piecing
       it together) instead of doing complicated testing on each byte
       of the encoded form.
    
    In particular, this matters for three- and four-byte code points;
    one- and two-byte are generally unchanged, and ASCII is of course
    taken by the UCA scanner fast path anyway. Add a new microbenchmark
    consisting exclusively of Japanese (which is represented mainly
    using three-byte code points) to highlight the differences.
    
    Also unify the many different UTF-8 parsing routines that we have.
    
    Microbenchmarks (Skylake 3.4 GHz, 64-bit, GCC 6.2):
    
      BM_SimpleUTF8                328 -> 334 ns/iter [ -1.8%]
      BM_UTF8MB4StringLength        47 ->  47 ns/iter [  0.0%]
      BM_SimpleUTF8MB4             142 -> 142 ns/iter [  0.0%]
      BM_MixedUTF8MB4              197 -> 188 ns/iter [ +4.8%]
      BM_MixedUTF8MB4_AS_CS        643 -> 576 ns/iter [+11.6%]
      BM_JapaneseUTF8MB4           663 -> 542 ns/iter [+22.3%]
      BM_NewlineFilledUTF8MB4      171 -> 172 ns/iter [ -0.6%]
      BM_HashSimpleUTF8MB4         306 -> 306 ns/iter [  0.0%]
    
    sysbench results are neutral, since they don't test anything
    but ASCII.
    
    Change-Id: I57a72abf69d1b636d2224a1f6e0ebb1aa196296e

[33mcommit f8c2b4efd7866301e7245a15cd73287513e47466[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Nov 28 14:45:49 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Some small cleanups in the UCA scanners; in particular, we don't check against
    uca->maxchar in the 9.0.0 scanner, since we already know that we cover the
    entire BMP in our 9.0.0 tables, and the scanner checks if we're outside that.
    Apart from that, we remove the odd instruction here and there (mostly sign
    extensions, and also a few indirections through the stack), but those don't
    show up as clearly in the benchmarks.
    
    Microbenchmarks (Skylake 3.4 GHz, [1;31moptim[mized mode, GCC 6.2):
    
      BM_SimpleUTF8MB4          147 -> 141 ns/iter  [ +4.3%]
      BM_MixedUTF8MB4           223 -> 195 ns/iter  [+14.4%]
      BM_MixedUTF8MB4_AS_CS     668 -> 631 ns/iter  [ +5.8%]
      BM_NewlineFilledUTF8MB4   206 -> 191 ns/iter  [ +7.9%]
      BM_HashSimpleUTF8MB4      306 -> 307 ns/iter  [ -0.3%]
    
    I haven't compared in sysbench, since these changes are small enough that they
    probably would not be easy to measure.
    
    Change-Id: I103a483a106b0b7f581d64e876204554154a13bc

[33mcommit 5fa1980a784b42247a8d0ca377b6eb9f6d6ab8db[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Nov 29 08:28:22 2016 +0100

    Bug#25148549 REVISIT COMPILER FLAGS FOR ORACLE DEVELOPER STUDIO
    
    Post-push fix: Check for CMAKE_BUILD_TYPE = Release or RelWithDebInfo
    when compiling item_geofunc_buffer.cc in [1;31moptim[mized mode.

[33mcommit 864da1b27945e3e9cb01c6fb50d19eacbb8524a1[m
Author: Oystein Grovlen <oystein.grovlen@oracle.com>
Date:   Mon Nov 28 13:48:03 2016 +0100

    WL#8737 IO aware defaults for [1;31moptim[mizer cost constants
    
    Addendum: Stabilize tests in PushBuild
    
    mysql-test/include/index_merge_ror.inc
    mysql-test/r/index_merge_innodb.result
    mysql-test/r/index_merge_myisam.result
      Mask decimals in cost numbers due to differences between platforms
    mysql-test/t/explain_for_connection_crash.test
    mysql-test/t/internal_tmp_disk_storage_engine.test
    mysql-test/r/internal_tmp_disk_storage_engine.result
    mysql-test/suite/opt_trace/include/bugs.inc
    mysql-test/suite/opt_trace/r/bugs_no_prot_all.result
    mysql-test/suite/opt_trace/r/bugs_no_prot_none.result
    mysql-test/suite/opt_trace/r/bugs_ps_prot_all.result
    mysql-test/suite/opt_trace/r/bugs_ps_prot_none.result
      Run ANALYZE TABLE to stabilize statistics

[33mcommit 4bf48e8bf0d572fafc0349a3d7e9376b781a1302[m
Author: Oystein Grovlen <oystein.grovlen@oracle.com>
Date:   Fri Nov 25 13:32:20 2016 +0100

    WL#8737 IO aware defaults for [1;31moptim[mizer cost constants
    
    Update default values for [1;31moptim[mizer cost constants. New values are:
    
      row_evaluate_cost             0.1
      key_compare_cost              0.05
      memory_temptable_create_cost  1.0
      memory_temptable_row_cost     0.1
      disk_temptable_create_cost    20.0
      disk_temptable_row_cost       0.5
      memory_block_read_cost        0.25
      io_block_read_cost            1.0
    
    Changes to source files:
    
    sql/opt_costconstants.cc
      Changed default values for cost constants.
    sql/sql_select.h
      Change type of JOIN_TAB::read_time from ha_rows to double since cost may now
      be lower than 1.
    sql/sql_[1;31moptim[mizer.cc
    sql/sql_select.cc
      Removed casts when assigning to/from JOIN_TAB::read_time
    unittest/gunit/opt_costconstants-t.cc
      Updated unit tests to use new values for cost constants
    
    Changes in tests:
    
    mysql-test/include/join_cache.inc
      Added more data in one table to preserve original query plan.
    mysql-test/include/mix1.inc
      Added more data in in two tables to preserve original query plan.
    mysql-test/r/count_distinct.result
      User variable changed because plans go from BNL to ref access
    mysql-test/t/dd_is_compatibility.test
    mysql-test/r/dd_is_compatibility.result
    mysql-test/r/dd_is_compatibility_ci.result
      Lowered setting of max_join_size to make sure test still get ER_TOO_BIG_SELECT
    mysql-test/r/delete.result
      Changed join order gives more warnings
    mysql-test/r/endspace.result
      Query returned result in different order, re-recorded.
    mysql-test/r/explain.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_rqg_json.result
      Change in two query plans, updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_rqg_trad.result
      Change in one query plan, updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_small_json.result
    mysql-test/r/explain_for_connection_small_trad.result
      One query changes from table scan to ref access, due to magic constants
      added when calculating cost for tables scan. Two queries changes from
      index scan to ref access due to lower cost of doing ref access. Updated cost
      numbers in EXPLAIN JSON.
    mysql-test/r/explain_json_all.result
      Re-recorded new query plan for one query since it no longer tested
      what the original test was for. Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_json_none.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/explain_other.test
    mysql-test/r/explain_other.result
      Added more data to one table in order to preserver original query plan.
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/func_concat.result
      Changed from table scan with BNL to eq_ref access.
      The new plan is identical to the plan when the test case was added.
    mysql-test/r/greedy_[1;31moptim[mizer.result
      Several queries got new query plan. All new query plans resulted in a
      lower number of Handler_reads. Updated Last_query_cost numbers.
    mysql-test/r/greedy_search.result
      No changes in query plans but the number of partial plans evaluated
      was changed for several queries.
    mysql-test/r/group_by.result
      Changed from table scan with BNL to ref access
    mysql-test/r/group_min_max.result
      Four queries changes from doing index scan to use range scan due to
      range scan becoming cheaper with all data in memory buffer.
    mysql-test/r/heap_hash.result
      One query changes from using join buffer to use ref access for join.
      This is what the original test used, accepted new plan.
    mysql-test/r/index_merge_innodb.result
      One query changes from ref to range. This is caused by using DS-MRR for the
      range scan. Updated cost numbers in EXPLAIN JSON.
    mysql-test/include/index_merge_intersect_dml.inc
    mysql-test/r/index_merge_intersect_dml.result
      One query changed from doing range scan on primary key to range scan on
      secondary key. Changed query to switch back to use primary key.
    mysql-test/r/index_merge_myisam.result
    mysql-test/r/innodb_explain_json_non_select_all.result
    mysql-test/r/innodb_explain_json_non_select_none.result
    mysql-test/r/internal_tmp_disk_storage_engine.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/join.test
    mysql-test/r/join.result
      Query plan changes for two queries. First fixed by increasing the range
      interval in the query. The second query changes from table scan to
      eq_ref for one table, re-recorded new query plan. Updated Last_query_cost
      numbers.
    mysql-test/r/join_cache_bka.result
      Four queries changes from using BNL to use BKA/ref access.
    mysql-test/r/join_cache_bka_nixbnl.result
      One query changes from table scan to BKA/ref access.
      One query changes join order
    mysql-test/r/join_cache_bkaunique.result
      Four queries changes from using BNL to use BKA-unique/ref access.
    mysql-test/r/join_cache_bnl.result
      Four queries changes from using BNL to use ref access due to ref access
      becoming cheaper with all data in a memory buffer.
    mysql-test/r/join_cache_nojb.result
      Changed join order for one query due to ref access becomming relatively
      less costly compared to table scan when all data is in a memory buffer.
    mysql-test/r/join_outer.result
      Changes in order of results from a few queries, re-recorded. Updated cost
      numbers in EXPLAIN JSON.
    mysql-test/r/join_outer_bka.result
    mysql-test/r/join_outer_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/key.result
      Updated Last_query_cost numbers.
    mysql-test/r/key_diff.result
      One query changes from using join buffering to ref access. The new plan
      has also been accepted as plan for this query before, so just use it.
    mysql-test/r/myisam.result
      One query changes from table scan to range scan, likely due to use of
      magic constants when calculating cost of table scan.
    mysql-test/r/myisam_explain_json_non_select_all.result
    mysql-test/r/myisam_explain_json_non_select_none.result
      Updated cost numbers in EXPLAIN JSON plus two rows estimates in explain.
    mysql-test/r/myisam_icp.result
    mysql-test/r/myisam_icp_all.result
    mysql-test/r/myisam_icp_none.result
      Changes to query plans for two bugs that was reported for InnoDB.
      Accepted changes since the plan is still the same when run with
      InnoDB.
    mysql-test/t/opt_costmodel.test
    mysql-test/r/opt_costmodel.result
    mysql-test/t/opt_costmodel_flush.test
    mysql-test/r/opt_costmodel_flush.result
      Updated to use new cost numbers, updated result files.
    mysql-test/r/opt_costmodel_restart.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/opt_hints.result
      Changes from ref access to range access. Does not affect purpose of test
    mysql-test/t/opt_hints_subquery.test
    mysql-test/r/opt_hints_subquery.result
      A lot of changes to explain output:
      -Most of the changes are from using join buffer to ref access (ok)
      -Some changes are in join order (ok)
      -Some changes are in semijoin strategy; adjusted test cases so hints
       are used according to original purpose of tests.
    mysql-test/r/order_by_all.result
    mysql-test/r/order_by_icp_mrr.result
    mysql-test/r/order_by_none.result
      Two queries joining three tables changes join order. The new query plans are
      equal to earlier query plans, so no attempt on reproducing current query
      plans.
    mysql-test/r/partition.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/partition_locking.test
    mysql-test/r/partition_locking.result
      Many queries changed from doing index scan to range scan. Adjusted
      the queries to use index scan. For the last query, the plan change
      is accepted since it is the same as the initial query plan.
    mysql-test/t/partition_pruning.test
    mysql-test/r/partition_pruning.result
      Two queries changed from table scan to range scan. Adjusted queries
      to produce same plan.
    mysql-test/r/range_all.result
    mysql-test/r/range_icp.result
    mysql-test/r/range_icp_mrr.result
    mysql-test/r/range_mrr.result
    mysql-test/r/range_mrr_cost.result
    mysql-test/r/range_none.result
    mysql-test/r/range_with_memory_limit.result
      Change in three query plans. The first is due to range scan becoming cheaper
      than table scan, and join buffering is no longer considered. The two last is
      Change in join order due to differences in cost estimate for ref access
      versus join buffering. The new plan is more similar to initial plan for
      these two queries.
    mysql-test/include/select.inc
    mysql-test/r/select_all.result
    mysql-test/r/select_all_bka.result
    mysql-test/r/select_icp_mrr.result
    mysql-test/r/select_icp_mrr_bka.result
      Two identical queries switches from using join buffering to use ref access.
      Change accepted since ref access was the original join method for these
      queries.
    mysql-test/r/select_none.result
    mysql-test/r/select_none_bka.result
    mysql-test/r/select_none_bka_nixbnl.result
      In addition to the two queries above, a third query changes from table
      scan to range scan due to range access is cheaper with all data in memory.
      Accepted new plan since range scan was the origianal plan when the bug
      was first fixed.
    mysql-test/r/select_all_bka_nixbnl.result
    mysql-test/r/select_icp_mrr_nixbnl.result
      Updated result file after adding sorted_result for two queries in select.inc
    mysql-test/t/select_safe.test
    mysql-test/r/select_safe.result
      Adjusted value for max_join_size to make query fail.
    mysql-test/t/single_delete_update.test
    mysql-test/r/single_delete_update.result
      Two limit queries changed from doing file sort to using index. The
      test assumed that is should use filesort, so increased the limit to
      produce original query plan. Needed to adjust some other parts of
      the test due to this.
    mysql-test/r/status.result
      Updated Last_query_cost numbers.
    mysql-test/r/subquery_all.result
    mysql-test/r/subquery_all_bka.result
      Five queries have changes in query plans:
      -Change from using join buffer to ref access due to ref access is less costly
       with all data in memory buffer.
      -Join order changes due to minor changes in cost estimates, the new
       plan is identical to a former plan for this query.
      -Last three queries change from using join buffering to use ref access
       due to ref access is less costly with data in memory. The query plan for
       these queries has changed several times so no effort on reproducing
       original plan.
    mysql-test/r/subquery_all_bka_nixbnl.result
      Join order changes for one query due to minor changes in cost estimates,
      the new plan is identical to a former plan for this query.
    mysql-test/r/subquery_mat_all.result
      Several queries changes from using DuplicateWeedout to FirstMatch due
      to the cost of FirstMatch reading data is now lower compared to using
      the temporary table. The query plan for these queries have changed
      several times so no attempt on reproducing original query plan.
    mysql-test/r/subquery_nomat_nosj.result
    mysql-test/r/subquery_nomat_nosj_bka.result
    mysql-test/r/subquery_none.result
    mysql-test/r/subquery_none_bka.result
      Join order changes for two queries due to minor changes in cost estimates.
    mysql-test/r/subquery_nomat_nosj_bka_nixbnl.result
    mysql-test/r/subquery_none_bka_nixbnl.result
      Join order change for one query due to minor changes in cost estimates.
    mysql-test/r/subquery_sj_all.result
    mysql-test/r/subquery_sj_all_bka.result
    mysql-test/r/subquery_sj_all_bka_nixbnl.result
    mysql-test/r/subquery_sj_all_bkaunique.result
      About 25 queries has changes in query plans:
      -Materialization to FirstMatch: FirstMatch becomes cheaper due to the
       cost of reading the data when it is in memory is now lower
      -Materialization to DupsWeedOut: Some of the changes are due to
       materialization and dupsweedout having the exact same cost and the change
       is caused by rounding errors. In a few cases, the cost of DupsWeedOut
       is now lower than Materialization.
      -DupsWeedout to FirstMatch: FirstMatch benefits more from having all
       data in a memory buffer
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer
    mysql-test/r/subquery_sj_dupsweed.result
    mysql-test/r/subquery_sj_dupsweed_bka.result
    mysql-test/r/subquery_sj_dupsweed_bka_nixbnl.result
    mysql-test/r/subquery_sj_dupsweed_bkaunique.result
      A few queries have changes in query plan, no changes in semi-join strategy:
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
    mysql-test/r/subquery_sj_firstmatch.result
    mysql-test/r/subquery_sj_firstmatch_bka.result
    mysql-test/r/subquery_sj_firstmatch_bkaunique.result
      A few queries have changes in query plan, no change in semi-join strategy:
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
    mysql-test/r/subquery_sj_firstmatch_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/subquery_sj_loosescan.result
    mysql-test/r/subquery_sj_loosescan_bka.result
    mysql-test/r/subquery_sj_loosescan_bka_nixbnl.result
    mysql-test/r/subquery_sj_loosescan_bkaunique.result
      A few queries have changes in query plan, no change in semi-join strategy:
      -Join order: due to changes in cost estimates, verified that current
       plan is not the same as origianal plan, so just re-recorded.
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
    mysql-test/r/subquery_sj_mat.result
    mysql-test/r/subquery_sj_mat_bka.result
    mysql-test/r/subquery_sj_mat_bka_nixbnl.result
    mysql-test/r/subquery_sj_mat_bkaunique.result
      A few queries have changes in query plan:
      -Join order: due to changes in cost estimates, verified that current
       plan is not the same as origianal plan, so just re-recorded.
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
      -One query changes from MaterializeLookup to MaterializeScan.
    mysql-test/r/subquery_sj_mat_nosj.result
      A few queries change from using join buffer to use eq_ref or ref:
      eq_ref and ref get a lower cost when all data is in a memory buffer. This
      causes changes to join order.
    mysql-test/r/subquery_sj_none.result
    mysql-test/r/subquery_sj_none_bka.result
    mysql-test/r/subquery_sj_none_bkaunique.result
      One query changes from using join buffer to use eq_ref or ref:
      eq_ref and ref get a lower cost when all data is in a memory buffer. This
      causes changes to join order.
    mysql-test/r/subquery_sj_none_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/type_blob.result
      Change from ALL to ref_or_null.  Back to plan before switch to InnoDB
    mysql-test/r/type_ranges.result
      Order of warnings changed for an INSERT INTO SELECT statement likely due
      to plan change. Re-recorded result file.
    mysql-test/r/user_var.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/engines/iuds/r/insert_calendar.result
    mysql-test/suite/engines/iuds/t/insert_calendar.test
      Different plans for MyISAM and InnoDB caused different number of warnings.
      Changed start date for range for query to avoid warnings for zero date.
    mysql-test/suite/gcol/inc/gcol_ins_upd.inc
    mysql-test/suite/gcol/r/gcol_ins_upd_innodb.result
    mysql-test/suite/gcol/r/gcol_ins_upd_myisam.result
      Added sorted_result to some queries to handle that the order of the
      result changes. This happened for the MyISAM test, the InnoDB test
      had the same order.
    mysql-test/suite/gcol/r/gcol_keys_innodb.result
    mysql-test/suite/gcol/r/gcol_keys_myisam.result
      Changed plans from table scan to index usage
    mysql-test/suite/gcol/r/gcol_select_myisam.result
      One query changes join order and switches from join buffering to ref
      access.
    mysql-test/suite/gcol/r/gcol_select_innodb.result
      One query changes from using join buffering to do ref access. This is
      caused by table scan becoming relatively more costly compared to ref
      access.
    mysql-test/suite/innodb/t/innodb_mysql.test
    mysql-test/suite/innodb/r/innodb_mysql.result
      Added extra rows to a few tables to preserve original query plan.
    mysql-test/suite/innodb/include/query_workload_itt.inc
    mysql-test/suite/innodb/r/[1;31moptim[mizer_temporary_table.result
      Cost estimates of EXPLAIN JSON was unstable since one table was not used
      for a while and sometimes its pages was flushed from buffer pool.
      Added a query that does a table scan to ensure that pages are in buffer pool.
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/innodb_gis/r/create_spatial_index.result
    mysql-test/suite/innodb_gis/r/rtree.result
    mysql-test/suite/innodb_gis/r/rtree_multi_pk.result
      Changes in query plans from full table/index scan to range scan
      Queries will now actually use a spatial index
    mysql-test/suite/innodb/r/temporary_table.result
    mysql-test/suite/innodb/r/temporary_table_[1;31moptim[mization.result
    mysql-test/suite/innodb_zip/r/wl6469.result
    mysql-test/suite/innodb_zip/r/wl6560.result
      A few queries changes from table scan to range scan due to use of magic
      constants in the cost model for table scan.
    mysql-test/suite/innodb_fts/r/opt.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/json/r/json_agg.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/opt_trace/r/bugs_no_prot_all.result
    mysql-test/suite/opt_trace/r/bugs_ps_prot_all.result
      Updated cost estimate numbers in [1;31moptim[mizer trace output.
      There are a few minor changes in the [1;31moptim[mizer trace output
      and a few plan changes.
    mysql-test/suite/opt_trace/r/bugs_no_prot_none.result
    mysql-test/suite/opt_trace/r/bugs_ps_prot_none.result
    mysql-test/suite/opt_trace/r/fulltext.result
    mysql-test/suite/opt_trace/r/general2_no_prot.result
    mysql-test/suite/opt_trace/r/general2_ps_prot.result
    mysql-test/suite/opt_trace/r/general_no_prot_none.result
    mysql-test/suite/opt_trace/r/general_ps_prot_none.result
    mysql-test/suite/opt_trace/r/range_no_prot.result
    mysql-test/suite/opt_trace/r/range_ps_prot.result
      Updated cost estimate numbers in [1;31moptim[mizer trace output.
      There are a few tiny minor change in the [1;31moptim[mizer trace output.
    mysql-test/suite/opt_trace/r/charset.result
    mysql-test/suite/opt_trace/r/eq_range_statistics.result
    mysql-test/suite/opt_trace/r/filesort_pack.result
    mysql-test/suite/opt_trace/r/filesort_pq.result
    mysql-test/suite/opt_trace/r/general_no_prot_all.result
    mysql-test/suite/opt_trace/r/general_ps_prot_all.result
    mysql-test/suite/opt_trace/r/subquery_no_prot.result
    mysql-test/suite/opt_trace/r/subquery_ps_prot.result
    mysql-test/suite/opt_trace/r/temp_table.result
      Updated cost estimate numbers in [1;31moptim[mizer trace output.
    mysql-test/suite/opt_trace/r/security_no_prot.result
    mysql-test/suite/opt_trace/r/security_ps_prot.result
      Updated length numbers for [1;31moptim[mizer trace output.
    mysql-test/suite/parts/r/partition_icp.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/sysschema/r/pr_statement_performance_analyzer.result
      Changed query plans give different number for rows_examined
    mysql-test/suite/sys_vars/r/max_join_size_func.result
    mysql-test/suite/sys_vars/r/sql_big_selects_func.result
    mysql-test/suite/sys_vars/t/max_join_size_func.test
    mysql-test/suite/sys_vars/t/sql_big_selects_func.test
      Reduced value for max_join_size to make queries fail with new cost constants.
    mysql-test/suite/test_service_sql_api/r/test_sql_stmt.result
      Changed result order due to different access method
    mysql-test/suite/i_main/r/bug18932813.result
    mysql-test/suite/i_main/r/derived.result
    mysql-test/suite/i_main/r/explain_json.result
    mysql-test/suite/i_main/r/group_by.result
    mysql-test/suite/i_main/r/partition_icp.result
    mysql-test/suite/i_main/r/subquery_mat_cost_based.result
    mysql-test/suite/i_main/r/view.result
      Updated cost numbers in EXPLAIN JSON.
    .../mysql-test/suite/i_main/r/bug22671573.result
      Plan changed from table scan to range scan.
      Verified that test case still reproduce the original bug.
    .../mysql-test/suite/i_main/r/costmodel_planchange.result
      Adjust queries to still identify plan changes
    .../mysql-test/suite/i_main/t/insert.test
    .../mysql-test/suite/i_main/r/insert.result
      Added data to keep same query plan
    .../mysql-test/suite/i_main/t/subquery-bug22262843.test
    .../mysql-test/suite/i_main/r/subquery-bug22262843.result
      Added a row so that subquery materialization is still used.
    .../mysql-test/suite/i_main/t/subquery.test
    .../mysql-test/suite/i_main/r/subquery.result
      Added data to keep on query plan
      Some changes from table scan (with BNL) to ref access
      Some semijoin strategy changes that seems reasonable
    .../mysql-test/suite/i_opt_trace/include/bugs.inc
      Added analyze table to make test stable
    .../mysql-test/suite/i_opt_trace/r/bugs_no_prot.result
    .../mysql-test/suite/i_opt_trace/r/bugs_ps_prot.result
    .../mysql-test/suite/i_opt_trace/r/query_cache_trace.result
      Updated cost numbers in EXPLAIN JSON.
    .../mysql-test/suite/i_opt_trace/r/refaccess_trace.result
      One query plan goes from table scan to eq_ref
      Updated cost numbers in EXPLAIN JSON.
    
    Implemented by Olav Sandstå

[33mcommit b2d7d9d6dc9835d895ed06c4069743592533f226[m
Author: Viswanatham Gudipati <viswanatham.gudipati@oracle.com>
Date:   Fri Nov 25 12:38:22 2016 +0530

    Bug#25127417 : main.group_by.test fails sporadically on PB2
    
    Problem :
    main.group_by.test fails sporadically on PB2 after wl#9489
    
    Solution :
    But after detail investigation and discussion among the [1;31moptim[mizer team, it was decided that, this particular test has to be retained as Myisam
    specific. the following steps are adapted.
    
    A Engine=Myisam has been added in the DDL statement , to retained as Myisam
    A column masking at 10 & 11 , has been added for the sporadic explain failures
    
    Reviewed-by: Chaithra <chaithra.gopalareddy@oracle.com>
    
    RB : 14668

[33mcommit c5768818b32fdc65aec9118b1fe7e63205eefd45[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Nov 22 10:43:41 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Drop char_index for UCA 9.0.0 scanners, now that strnxfrm is no longer expected
    to truncate (and we don't need it for padding). Speeds up the slow path
    significantly.
    
    Microbenchmarks (Skylake 3.4 GHz, [1;31moptim[mized mode, GCC 6.2):
    
      BM_SimpleUTF8MB4                147 -> 142 ns/iter  [ +3.5%]
      BM_MixedUTF8MB4                 277 -> 212 ns/iter  [+30.7%]
      BM_MixedUTF8MB4_AS_CS           786 -> 657 ns/iter  [+19.6%]
      BM_NewlineFilledUTF8MB4         231 -> 200 ns/iter  [+15.5%]
      BM_HashSimpleUTF8MB4            306 -> 306 ns/iter  [  0.0%]
    
    Change-Id: Id9883ac4d73618e05b4663d7cb15310aa300cbcc

[33mcommit 616f1be47b5b43877079d80449f8f658e1643e21[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Nov 17 13:48:33 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Optimize the hash function; the old one was horrible both in speed and quality.
    The new one is significantly faster and slightly less horrible (verified with
    SMHasher). Note that we can do this only because the UCA 9.0.0 collations are
    not part of a GA release; we cannot go back and do this to other collations
    without breaking partitioning.
    
    Microbenchmarks (Skylake 3.4 GHz, [1;31moptim[mized, GCC 6.2):
    
      BM_HashSimpleUTF8MB4   1140 -> 289 ns/iter  [+294.5%]
    
    sysbench goes from 11519 -> 12022 tps (+3.2%).
    
    Change-Id: I6c554110387d927ad1d139c19627c6c51a6aa10c

[33mcommit 2bd59f6e54cb152d539c46aa52a3b6507fb10bca[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Nov 17 13:48:33 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Optimize the hash function; the old one was horrible both in speed and quality.
    The new one is significantly faster and slightly less horrible (verified with
    SMHasher). Note that we can do this only because the UCA 9.0.0 collations are
    not part of a GA release; we cannot go back and do this to other collations
    without breaking partitioning.
    
    Microbenchmarks (Skylake 3.4 GHz, [1;31moptim[mized, GCC 6.2):
    
      BM_HashSimpleUTF8MB4   1140 -> 289 ns/iter  [+294.5%]
    
    sysbench goes from 11519 -> 12022 tps (+3.2%).
    
    Change-Id: I6c554110387d927ad1d139c19627c6c51a6aa10c

[33mcommit e11d8a155d97d03f2160ab3b3c67c3e16f135d2d[m
Author: Bjorn Munch <bjorn.munch@oracle.com>
Date:   Tue Nov 15 14:39:50 2016 +0100

    Bug #25083555 SOME TESTS FAIL WITH DEBUG SERVER ON SOLARIS WHEN BUILT WITH DEVELOPER STUDIO
    
    When we do a release type build of the server (with both [1;31moptim[mized and
    debug enabled server/plugins) with Developer Studio, some MTR tests
    when run with --debug-server will fail in one of two ways:
    
    1. Tests which try to load a plugin into the mysql client fail with
       missing symbols. This is caused by the plugin having references to
       functions which do not exist in the non-debug client.
    
    2. Some tests on sparc fail with Thread stack overrun.
    
    Fix for issue #1: mtr will have appended /debug to the plugin dir part
    when running with --debug-server and if there actually is such a
    directory. The fix is to remove any trailing /debug from the
    env. variable within the test. This will affect the client only, not
    the server. Developer builds will not have put the plugins in a
    subdirectory /debug so it makes no different to those.
    
    Fix for issue #2: apparently this thread stack overrun is not feasible
    to avoid, so just skip the test if running with debug server on sparc;
    there is already an include file to do that.
    
    Also added not_sparc_debug.inc to the "white list" so the tests are
    skipped even when running mtr --no-skip.

[33mcommit e161b51a9ff3293b662adf31c63d5954ae40e3c7[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Wed Oct 12 16:00:59 2016 +0300

    Bug#25047032 DECLARE OVERRIDDEN ITEM MEMBER FUNCTIONS AND FINAL ITEM SUBCLASSES
    
    When virtual member functions are being renamed or replaced, it would
    be extremely useful if the compiler were able to warn about member
    functions that were intended to be overriding a member function in a
    base class, but are not actually overriding anything.
    
    The C++11 override keyword would allow this.
    
    Furthermore, the C++11 final keyword would enable some additional
    [1;31moptim[mizations, and it would make the code more readable by documenting
    that there cannot be any classes derived from a final class.
    
    This is a logical follow-up of
    Bug#24787984 DECLARE DERIVED METHODS IN THE OPTIMIZER WITH THE C++11
    OVERRIDE KEYWORD
    applied to all Item classes.
    
    Reviewed-by: Knut Hatlen <knut.hatlen@oracle.com>

[33mcommit 8571fd1b569bb6d04be92914084b747d3a45b4b1[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Oct 11 15:42:31 2016 +0200

    Bug#24826541 TABLE PERFORMANCE_SCHEMA.DATA_LOCKS IS MISSING RECORDS
    
    Tests involving performance_schema.lock_data have been found
    to be unstable.
    After analysis, several issues, both in the server code and the test
    scripts, have been identified, fixed by this patch.
    
    ISSUE #1
    ========
    
    When SELECT * from performance_schema.data_locks
    is executed, the code in table_data_locks::rnd_next()
    extracts rows from innodb, using a restartable scan,
    using an iterator:
      PSI_engine_data_lock_iterator *it= ...
    
    Assume that for example the first call to
      it->scan();
    returns 10 rows, and a subsequent call returns 5 more rows.
    
    Before this fix,
    - the data container after first call contains rows [0] .. [9]
    - the ::rnd_next loop with m_index_2 at positions [0] .. [9]
    - all the rows for the first scan are returned properly
    - the data container after second call contains rows [0] .. [5]
    - the ::rnd_next loop with m_index_2 at positions [10] .. [14]
    - rows for the second scan are missed
    
    The root cause is the discrepancy in "index":
    - the data container uses relative positions in each scan
    - the m_index_2 loop in rnd_next uses absolute positions
    
    With this fix, restartable scans keep rows numbered in absolute,
    with PFS_data_lock_container::m_logical_row_index.
    The container is not cleared, but only truncated with ::shrink(),
    during the scan, to preserve row numbering.
    
    ISSUE #2
    ========
    
    Because of restartable scans, locks are not returned always in the same
    order from a select, as two transactions can be returned
    in the same or in different scans.
    
    As a result, tests scripts need to use an ORDER BY clause
    on SELECT, to have a stable output.
    
    This fix corrected the test scripts.
    
    ISSUE #3
    ========
    
    Using SELECT ... ORDER BY cause the [1;31moptim[mizer to use
    table_data_locks::rnd_pos(), after a filesort.
    
    This code path is longer from a plain table scan,
    and exposed further bugs:
    
    ISSUE #3-1
    ----------
    
    Lock rows exported by a scan can not be fetched back,
    because of incorrect filtering on the lock heap_no.
    
    A given LOCK_REC structure is not associated with a
    single heap_no, but with a -- set of -- heap_no.
    
    When performing a table scan,
    Innodb_data_lock_iterator::scan_trx()
    is called with filter = false,
    and iterate properly on heap_no,
    using:
      heap_no = lock_rec_find_set_bit(lock);
      heap_no = lock_rec_find_next_set_bit(lock, heap_no);
    
    When called for a fetch however, with filter = true,
    the code failed to look for the entire set of heap_no,
    and only considered the first in the set.
    
    This fix now iterate properly on all heap_no
    when using a filter with filter_heap_id.
    
    ISSUE #3-2
    ----------
    
    Transactions exported by a scan can not be fetched back,
    because of incorrect iteration on the trx list in innodb.
    
    The "transaction list" in innodb is a complex structure,
    made of two lists (trx_list, mysql_trx_list).
    
    To iterate properly, the code must use the get_next_trx()
    helper, instead of using UT_LIST_GET_NEXT().
    
    The code in fetch_trx_in_trx_list() has been fixed to iterate
    on the proper transaction list.
    
    ISSUE #3-3
    ----------
    
    Transactions exported by a scan can not be fetched back,
    because of incorrect values for the transaction id.
    
    The problem is that trx->id may, or may not,
    be a valid transaction id.
    
    In particular, some transactions in read only mode
    can have a trx->id of 0.
    
    See comments in trx_get_id_for_print() for details.
    
    The code exported a lock with a value for engine_lock_id,
    that contained a (fabricated) transaction id value.
    
    On a subsequent fetch, after parsing the value of engine_transaction_id
    to find a trx id, fetch_trx_in_trx_list() failed to locate the transaction,
    because the code was comparing the fabricated value with a zero trx->id
    
    The fix is to always use trx_get_id_for_print(trx), and never use trx->id
    directly, when exporting data in a scan, or fetching a particular row from
    rnd_pos().
    
    ISSUE #4
    --------
    
    In the test scripts, replying on column LOCK_DATA
    in table performance_schema.data_locks may cause spurious failures.
    This column can be NULL, in case the innodb storage engine
    purged data from the server memory to disk: this is a documented limitation.
    
    Relaxed the use of LOCK_DATA in test cases.

[33mcommit 2b9258c05ca521b34d78cfa547de4154296a93c7[m
Author: Xing Zhang <xing.z.zhang@oracle.com>
Date:   Thu Oct 27 16:29:38 2016 +0800

    Bug #24930682: NEED A PROGRAM TO AUTO-GENERATE WEIGHT TABLES FOR UCA9.0.0
    
    Add uca9-dump.cc which is used to auto-generate weight tables we
    use in utf8mb4 collations. This file will be used for further
    [1;31moptim[mization by customizing these tables.

[33mcommit bb9b7c67838832f895b889f8c10006dd736a0249[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Tue Oct 25 12:43:26 2016 +0200

    Bug#24947597 SHIFT-OR COMPILER BUG WITH GCC -FEXPENSIVE-OPTIMIZATIONS
    
    GNU C/C++ 5.2.0/5.3.0 compiler has a bug for big-endian systems
    [1;31moptim[mizing a some shift-or to a faulty load if -fexpensive-[1;31moptim[mizations
    is used.
    
    Expensive [1;31moptim[mizations is turned off if that compiler bug is detected.
    
    Reference bug for GNU C/C++ is:
    Bug 67781 - [5 Regression] wrong code generated on big-endian with -O1
    -fexpensive-[1;31moptim[mizations
    
    (cherry picked from commit 9072e9014dde0cdbdce0bd631df36461474eb7e1)

[33mcommit eb646a10c80b6215efbdf4ae3a8ba89e6b7ea9ca[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Thu Oct 20 15:11:22 2016 +0200

    Bug #24571672 DO NOT USE -FNO-EXPENSIVE-OPTIMIZATIONS JUST TO AVOID
    FUSED MADD INSTRUCTIONS
    
    Post push fix to use -fno-expensive-[1;31moptim[mizations if the compiler
    doesn't support -ffp-contract=off.
    
    (cherry picked from commit d90ffbb4e2309993e2f94c10992c37f3ce5fe5dd)

[33mcommit 6d0882d91e9c383361c23047d447ef1053a38c06[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Mon Oct 10 12:54:05 2016 +0200

    Bug #24571672 DO NOT USE -FNO-EXPENSIVE-OPTIMIZATIONS JUST TO AVOID
    FUSED MADD INSTRUCTIONS
    
    The fix for bug #23046775 introduced the -fno-expensive-[1;31moptim[mizations
    compiler flag on some platforms. This patch lifts that restriction and
    instead explicitly turns off fused multiply-add instructions by
    setting -ffp-contract=off.
    
    This patch is a contribution from Alexey Kopytov.
    
    (cherry picked from commit a3ebd157e71347d5f654510d752aa699d6808fc7)

[33mcommit 8c68159292604fec1be33b9d98cf7c120d9c66c6[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Thu Jan 7 10:07:35 2016 +0100

    Bug#13915291 NOT IN (SUBQUERY) GIVES WRONG RESULT WHEN PREFIX INDEX OF INNER TABLE IS USED
    
    When we switch to index_subquery strategy, remove_additional_cond()
    removes equalities injected by in-to-exists, saying that they are
    already implemented by the index ref access. Without realizing that
    this is wrong reasoning when the index is only on a prefix of the
    column.
    In the bug's testcase remove_additional_cond() should leave the
    conditions in place, instead of removing them and giving a wrong
    result (the prefix index gives false positives, causing NOT IN to give
    false negatives).
    
    index_subquery (and unique_subquery) is for two types of subqueries:
    - subqueries which have to deal with inner NULLs
    - subqueries which don't.
    The former have more complex injected conditions, use ref_or_null, and
    are submitted to remove_additional_cond(). The latter are simpler, use
    [eq_]ref, and are submitted to remove_subq_pushed_predicates().
    remove_subq_pushed_predicates() properly detects the index prefix
    problem, using test_if_ref().
    Adding the same logic to remove_additional_cond() proved to be
    difficult:
    - one has to scan the WHERE, analyze AND-ed parts, a part can be a
    triggered condition, itself wrapping two OR-ed conditions
    ("outer=inner OR inner IS NULL")
    - after locating the "outer=inner" equality, we need to see if this
    equality is handled by the index; but test_if_ref() will say no for
    two reasons: ref_or_null is used and the key has guarded conditions
    (see part_of_refkey()). So a modification of test_if_ref() would be
    needed; but this function is sensitive (see its comments), and a
    modification of part_of_refkey() would be needed too.
    - And we cannot just skip test_if_ref() because it handles: prefix
    index detection, and truncation detection (example: lookup "aa" in a
    CHAR(1) indexed column: "a" will be a match; test_if_ref() notices
    that). Those two detections are needed to decide if we can skip the
    condition.
    
    For simplification, in this patch remove_additional_cond() is simply
    deleted. The drawback is that we have more "using WHERE" for
    complete-index (non-prefix) index_subquery using ref_or_null. I think
    that it isn't a real problem; indeed, in this equivalent join query:
    explain format=json select * from t1 force index (xx) where a1='b' or a1 is null;
    shows:
    |  1 | SIMPLE      | t1    | NULL       | ref_or_null | xx            | xx   | 9       | const |    2 |   100.00 | Using index condition |
    the conditions are still tested, they are not removed.
    The HAVING clause isn't affected by this patch.
    
    in_additional_cond is thus unnecessary.
    Removed a useless comment from sql_[1;31moptim[mizer and a wrong one from
    item_subselect.
    
    After removing in_additional_cond, we also remove in_having_cond.
    The logic is: in_having_cond is only tested in sql_[1;31moptim[mizer.cc,
    to see if HAVING is equal to the one created by IN->EXISTS (which may
    be false, HAVING can be <other cond> AND <the one created by IN->EXISTS>).
    Instead of testing that, we can test if HAVING was created by
    IN->EXISTS. That can be done with created_by_in2exists().
    A few calls to set_created_by_in2exists() were missing, they're added.
    Because this function belongs to Item_bool_func, and objects
    like having_item are Item*, their type is change to Item_bool_func*;
    it's not a problem as in fact they are Item_bool_func* by the way
    they are constructed (AND chains of equalities, triggered conditions and
    IS NULL tests). They are constructed by and_items(), so an overload
    of and_items() is added, taking Item_bool_func and returning
    Item_bool_func.

[33mcommit 741acc33b80bd4747f55bb71d23c6d20df91fffa[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Oct 12 14:02:00 2016 +0200

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Refactor the scanners so that we can inline mb_wc in the UCA collation,
    like we do in the UTF-8 binary collations.
    
    First and foremost, the split between “scanner” and “scanner handler”
    is now gone; the data belongs squarely in the scanner, which is a full class
    with its own private member functions and most of the state kept private.
    This allows us to more easily templatize them on mb_wc.
    
    Second, the scanner classes are now templatized on mb_wc, so that we can
    specialize them for the important case of utf8mb4, instead of calling it
    through a function pointer.
    
    Note that since the private member functions are no longer “static”,
    we need to convince GCC a bit harder (ie., using the “always_inline”
    attribute) for the bigger ones to actually be inlined, which matters
    for overall performance.
    
    Microbenchmarks (Skylake 3.4 GHz, 64-bit, [1;31moptim[mized) are significantly
    improved in terms of throughput:
    
      Microbenchmarks.BM_SimpleUTF8MB4   1737 -> 1404 ns/iter  (+23.7%)
      Microbenchmarks.BM_MixedUTF8MB4     722 ->  609 ns/iter  (+18.6%)
    
    sysbench variability is rather high, but longer runs indicate we've gone
    from 5527 -> 6117 tps (+10.7%).
    
    Change-Id: Id9125af181db1b6976c288e38009b73e2bce6980

[33mcommit bba37c917e3ed48384857693999032c4c9213624[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Wed Oct 12 13:49:54 2016 +0200

    Bug#24489037 ASSERTION `!\"SHOULD NOT HIT HERE\"\' IN DD_GET_OLD_FIELD_TYPE
    
    The issue here is that, some of UDF's introduced by WL#6599
    crashes because the UDF is invoked with wrong argument i.e.,
    NULL. These UDF's are invoked with data dictionary table
    columns as arguments. And the UDF's mostly expected valid
    arguments and did not check for NULL. The crash is due to a
    assert when we got a invalid column type. This can happen if
    a user has a query which does a LEFT JOIN and I_S table.
    Then there is possiblity that these UDF's getting called
    with NULL as their arguments.
    
    Note that these UDF's are used by INFORMATION_SCHEMA system
    views and are not exposed to users.
    
    The patch also does following changes:-
    
    - Makes sure all the UDF's do proper evaluation of
      arguments.
    
    - Removed Item_*::fix_length_and_dec() methods which are no
      more used by [1;31moptim[mizer. Replaced it with adding
      resolve_type() method as requested by Optimizer team.
    
    - Pass only table 'options' to UDF INTERNAL_KEYS_DISABLED,
      as schema and table name are not really used.
    
    - Few UDF's are marked as nullable, and others are retained
      as non-nullable to match the old behavior expected.
    
    - A test case invoking all UDF's with NULL arguments is
      added to main.dd_is_gcov.

[33mcommit 2d6573151bae665e4878b3843bd2ab81a9034d03[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Oct 11 12:47:14 2016 +0200

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    In heap engine: do not scan for character position unless we have
    a partial key (the [1;31moptim[mizer uses full key to eliminate duplicates)
    
    Change-Id: If6e2b8ed63db8949a9171adefdf4ff2d09a0fb79

[33mcommit 0a417e8464096d3c10755b33018847a7ca44ed6e[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Mon Oct 10 12:54:05 2016 +0200

    Bug #24571672 DO NOT USE -FNO-EXPENSIVE-OPTIMIZATIONS JUST TO AVOID
    FUSED MADD INSTRUCTIONS
    
    The fix for bug #23046775 introduced the -fno-expensive-[1;31moptim[mizations
    compiler flag on some platforms. This patch lifts that restriction and
    instead explicitly turns off fused multiply-add instructions by
    setting -ffp-contract=off.
    
    This patch is a contribution from Alexey Kopytov.

[33mcommit ba5ca306e3ab5b9e16b69450478378d9fca06c52[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Aug 16 09:56:29 2016 +0200

    WL#8741 Varlen keys for sorting JSON values
    
    WL#8539 allowed to sort JSON values. However, in order to limit scope and reduce
    various risks it was done in sub[1;31moptim[mal way. This WL aims to provide better
    performance for sorting/grouping JSON values by using variable length sort keys
    for them.

[33mcommit c863738034e7bc7f539e48d0aa60711c9276ba60[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Oct 4 14:43:01 2016 +0200

    Bug #24788778: SEVERE REGRESSION IN MY_STRNXFRM() FROM MYSQL-5.5 -> 5.6
    
    MySQL 5.6 changed utf8 binary collation strxfrm() from just comparing the UTF-8
    string to converting it to UCS-2 (big-endian) and padding before compare.
    (Similarly for utf8mb4, just with UCS-3 instead, which isn't correct for
    all Unicode code points.)
    
    Both are correct (although changing it also changed the hash function, which
    might on-disk binary compatibility wrt. partitioning), but the latter makes for
    fixed-length keys, which was seemingly important for the (now discontinued)
    Falcon storage engine at the time. However, it also introduces a bottleneck
    when hashing. We add a very simple benchmark (based on the benchmark in the
    bug) and then [1;31moptim[mize the string transformation:
    
     - Add an SSE2 version of the padding as long as we're sufficiently far away
       from the end of the string; this will be used automatically for all 64-bit
       Intel compiles (as well as 32-bit Intel compiles with -march=native or
       similar).
     - Inline the mbwc() function for the special case of my_utf8_uni.
     - Some general micro[1;31moptim[mization.
    
    All in all, we're at about 7x the speed of before. Old version
    (trunk, 64-bit, [1;31moptim[mized mode, GCC 6.1.1, Skylake 3.4 GHz):
    
      Done, used 1.696 seconds (1.696 us/iteration)
    
    This version:
    
      Done, used 0.242 seconds (0.242 us/iteration)
    
    The code is written to be C++98 compatible (even though a lambda would be
    much more elegant than a functor class), as it will probably want a 5.6 and 5.7
    backport. The benchmark isn't, though, as it uses std::chrono.
    
    Change-Id: I9da8c8af448bdacd6028a65c10ce232f841cdc94

[33mcommit 67c32d572d495352574b08373acff5d13f1de843[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Oct 4 14:44:51 2016 +0200

    Bug#24795241 INTERNAL ERROR IN DEVELOPERSTUDIO IN RELEASE MODE
    
    When compiling rapid/plugin/x/ngs/src/client.cc, we get:
    assertion failed in function assert_with_dumps() @ ssa.c:621 when using -xO3
    
    Change-Id: Ie655df41a33ba036dd12b9685cb00f2f4c1be538
    Fix: use -xO2 for this source file.
    
    One unit test segfaulted with -xO3, lower [1;31moptim[mization level fixed it.
    
    Also: remove remaining usage of BOOST_LIB_SOURCES, BOOST_SOURCES_DIR
    and BOOST_THREAD_SOURCES

[33mcommit 8ac4784fcf72690c08f8ebbc2d810ca14e1587d9[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Mon Oct 3 14:32:08 2016 +0300

    Bug#24787984 DECLARE DERIVED METHODS IN THE OPTIMIZER WITH THE C++11 OVERRIDE KEYWORD
    
    In many derived classes in the [1;31moptim[mizer, introduce the keywords
    override and final, and remove redundant use of the keyword virtual.
    
    Add and revise some Doxygen comments.
    
    Query_result_union_direct::begin_dataset(): Introduce the method
    only for EMBEDDED_LIBRARY, because that is the only case when
    Query_result::begin_dataset() is declared as virtual.
    
    JOIN_CACHE_BKA_UNIQUE::check_all_match_flags_for_key(): Remove the
    keyword virtual, because JOIN_CACHE_BKA_UNIQUE is a final class.
    
    Reviewed-by: Knut Hatlen <knut.hatlen@oracle.com>
    Reviewed-by: Tor Didriksen <tor.didriksen@oracle.com>

[33mcommit c371d9ca434beb74a53cadc1785faef6569b07d9[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Wed Sep 21 12:20:52 2016 +0300

    Bug#24287772 SUBQUERY RETURNS EMPTY LIST WHILE IDENTICAL QUERY WITH JOIN RETURNS RESULT
    
    This bug affects subqueries converted to semijoins, and programmatically
    generated INFORMATION_SCHEMA tables. The affected subqueries would
    incorrectly pretend that the INFORMATION_SCHEMA table is empty.
    
    Workaround: SET [1;31moptim[mizer_switch='semijoin=off';
    
    convert_subquery_to_semijoin(): Copy the OPTION_SCHEMA_TABLE flag from the
    options of the subquery, so that JOIN::prepare_result() will invoke
    get_schema_tables_result() to materialize the I_S table data.
    
    Reviewed-by: Roy Lyseng <roy.lyseng@oracle.com>

[33mcommit 1e49b533d37457e10003713bd97647096e941dbe[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Fri Sep 23 15:37:08 2016 +0200

    Post push fix for bug#23555834.
    
    Make select_node use [1;31moptim[mized_node_selection setting.

[33mcommit 64415cd707795fbfae95c5bd28bcb9151e44b0a2[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Thu Sep 15 13:28:24 2016 +0300

    Bug#24484060 INCORRECT EVALUATION OF MIN/MAX REFERRING TO AN OUTER QUERY BLOCK
    
    Bug#24657798 HANDLER::HA_INDEX_INIT() TRIES TO USE AN
    UNLOCKED CONST TABLE IN OPT_SUM_QUERY()
    
    Bug#24484060 was unreachable before WL#6369 EXPLAIN for other thread,
    which was introduced in MySQL 5.7.2.
    
    In WL#6369, some table access during query [1;31moptim[mization was deferred.
    Before WL#6369, opt_sum_query() would be able to check table->file->inited
    to determine if the table belongs to an outer query block. After WL#6369,
    we must refer to the correct predicate instead.
    
    This bug results in wrong query results (too few rows) if MIN() or MAX()
    in a subquery refers to an indexed column. Curiously, the bug was not
    repeatable with ENGINE=MEMORY tables, but only with MyISAM and InnoDB.
    
    Bug#24657798 is older; it is affecting MyISAM tables in MySQL 5.6 already.
    The engines InnoDB, MEMORY, CSV, ARCHIVE are not affected.
    
    opt_sum_query(): Do not attempt to access a table handle that belongs to
    an outer query block.

[33mcommit 67f529591057c5e4233f6bb753de6257b37f5632[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Sat Jun 18 18:06:47 2016 +0200

    Bug#22671573: SIG11 IN SEL_ARG::RB_INSERT |SQL/OPT_RANGE.CC
    
    Split out the concept of "a node in the SEL_ARG tree" from the concept
    of the tree itself (the latter is now called SEL_ROOT). This untangles
    the two concepts (although the split isn't complete; parts of the split
    are complicated enough to be future patch); in particular, SEL_ARG
    no longer needs to carry around fields which only makes sense at
    the root (such as use_count or type), and copy them around when the root moves.
    
    The motivating change, however, is that SEL_ARGs can now point to SEL_ROOTs
    instead of another SEL_ARG. Previously, the pointer was implicitly to the
    root node of the tree; however, a node that used to be the root can later be
    made non-root due to R-B tree rotations, which would then cause issues when
    it was attempted traversed. Now, SEL_ROOT is the sole place holding the
    SEL_ARG root, which is then easy to keep up to date during rotations.
    SEL_ROOT also now holds the "type" field, which uncovered several minor issues
    where our refcounting was either too conservative or aggressive.
    
    If we want to, this also opens up for more opportunities to reduce the size
    of SEL_ARG down the road; in particular, the "part" and "field" fields
    (and possibly "maybe_flag") can be probably moved into SEL_ROOT with a bit of
    effort, and the "parent" pointer is now only needed during insertions and
    deletions, so can also probably be held implicitly. Optionally, we can
    store all SEL_ARGs in a contiguous array in the SEL_ROOT, enabling use of
    smaller indexes instead of pointers, and possibly also other traversal
    [1;31moptim[mizations. Or, if we just want cleanup, we can get rid of the R-B tree
    entirely and replace it with a std::map.
    
    Change-Id: Ia152b411d4d4dde98c9a3adb70aad958bccfba81

[33mcommit 20d32c5e7a26f79cbd5d6d8b714ecff4269c3f23[m
Author: Martin Hansson <martin.hansson@oracle.com>
Date:   Wed Sep 7 08:47:41 2016 +0200

    Bug#23541244: INVISIBLE INDEXES NOT WORKING ON MYISAM
    
    Invisible indexes did not work on MyISAM because it
    overwrites the keys_in_use bitmap.
    
    Fixed by introducing a new bitmap visible_indexes, and a new
    interface TABLE_LIST::usable_indexes for the [1;31moptim[mizer to
    use.
    
    We also update the version token from 5.8 to 8.0.

[33mcommit 447c4cc3c4f74003ff42304ce21f7b75bc5756a8[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Mon Sep 5 14:00:36 2016 +0200

    WL#5094 Create SQL command classes for DML statements
    
    Refined the class Sql_cmd_dml as a subclass of Sql_cmd for processing
    of SQL DML statements. Subclasses of Sql_cmd_dml are created for these
    classes of SQL statements:
    
    - SELECT
    - INSERT ... VALUES, INSERT ... SELECT
    - UPDATE (both single-table and multi-table variation)
    - DELETE (both single-table and multi-table variation)
    - DO
    - CALL
    
    Refactored processing of INSERT, UPDATE and DELETE statements for clear
    separation of preparation and execution code, as well as simplifying
    the execution logic.
    
    After this refactoring, most DML statements go through a fixed set of
    processes, each implemented using member functions, most of them virtual.
    SET statements and CREATE TABLE ... SELECT statements are still processed
    by handle_query() after this worklog, however.
    
    Preparing a statement goes through these processes:
    
    - precheck()
    - open_tables_for_query()
    - resolve_var_assignments()
    - prepare_inner() (the actual preparation code)
    - cleanup()
    
    Executing a statement goes through these processes:
    
    - set_statement_timer()
    - preparation (if not already done, otherwise precheck() and open_tables())
    - run_before_dml_hook() (if data change statement)
    - push_internal_handler() (if data change statement)
    - lock_tables()
    - query_cache.store_query()
    - execute_inner() (the actual [1;31moptim[mization and execution code)
    - pop_internal_handler()
    - cleanup()
    - reset_statement_timer()
    
    Query_result objects are changed so that they are created for
    the duration of the statement object.

[33mcommit d2d91c3286b9ac3b95ef0e5036c5319aa4ffeda2[m
Author: Sergey Glukhov <sergey.glukhov@oracle.com>
Date:   Thu Aug 4 16:09:48 2016 +0300

    WL#9158 Join Order Hints.
    
    The following query hints are implemented:
    
    JOIN_FIXED_ORDER similar to existing STRAIGHT_JOIN hint, will be used as replacement of the old hint later.
    JOIN_ORDER instructs the [1;31moptim[mizer to use the specified table order.
    JOIN_PREFIX instructs the [1;31moptim[mizer to use the specified table order for the first tables of the join execution plan.
    JOIN_SUFFIX instructs the [1;31moptim[mizer to use the specified table order for the last tables of the join execution plan.

[33mcommit a61e316e525c0b0aca4dcf695ec89535ec05eed7[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Aug 25 16:36:19 2016 +0200

    Bug #23623110: Range [1;31moptim[mizer: Rework use_count handling.
    
    Post-push fix: Temporarily disable DBUG_ASSERTs that check that inserts
    and deletes happen at the root. This was an issue already before this
    patch (it just makes them more visible by asserting instead of silently
    corrupting the tree), and there's a patch in the pipeline to fix the root
    issue, but for now, we disable them to avoid tripping up too many RQG runs.
    
    Change-Id: I5ac90450cd2d5dffa62b135e5e28e9dbcd975aaa

[33mcommit a2dbe619322d4b9f2b3d488a39604ab9b6bb4c45[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Aug 23 12:39:27 2016 +0200

    Bug #23623110: Range [1;31moptim[mizer: Rework use_count handling.
    
    Post-push commit to fix some Doxygen warnings.
    
    The “clone_flag” parameter was archaic and easy to remove, so I did so
    instead of trying to write up an apology in a @param directive.
    
    Change-Id: I1dca86ea2f123486f50606b954940ce98f509cc5

[33mcommit 94b4ff92fce9ad9a77590dc09d8ea15badcb6042[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Sat Jun 18 18:06:47 2016 +0200

    Bug #23623110: Range [1;31moptim[mizer: Rework use_count handling.
    
    This entirely rewrites the range [1;31moptim[mizer's treatment of use_count,
    replacing multiple layers of subtle and complicated handling with
    one simple rule: SEL_ARG::use_count counts the number of references
    from next_key_part or keys[]. (Well, there's one exception in
    and_all_keys(), but it's well-documented and localized.)
    
    In particular, this means that the logic with recursive use_counts,
    where increment_use_count() modifies the use count of every SEL_ARG
    that the current SEL_ARG tree points to recursively, goes away.
    The entire concept of adding more than one use_count at a time
    also goes away. Instead, there are two simple functions to modify
    next_key_part (release_next_key_part() and set_next_key_part())
    that automatically maintain use_count, and these are used the majority
    of the time. (Unfortunately, we still don't have compiler-assisted
    handling of correct _use_ of the use_count; it would be nice to make
    it impossible to modify a SEL_ARG with use_count > 1 without cloning
    it first, but it would probably require significant investments to
    const use in this file.) Almost all remaining tricky or unintuitive use_count
    handling has been commented, as well as general invariants preserved by
    functions.
    
    In line with the new rules, key_and() and key_or() no longer modify the
    use_count of their arguments since they don't modify anything pointing
    to them; they are now much closer to purely functional. In the same vein,
    they also don't send back the return value with use_count incremented,
    which simplifies the overall flow. There are also somewhat tighter asserts in
    place, including on the root node of the R-B tree (where we know there are bugs
    that this patch doesn't do much with).
    
    Finally, the global SEL_ARG null_element was an object of class type
    in static scope, which is a style guide violation; this has been remedied
    by replacing it with a pointer that's explicitly allocated and destroyed
    as part of normal server startup/shutdown. This fixes issues where the
    SEL_ARG destructor assert would spuriously fire when something else caused
    the server to exit.
    
    I found a preexisting issue I don't fully understand, and annotated
    it with FIXME comments, so it is not forgotten. (It goes back more than 15
    years.) Several similar ones were fixed.
    
    Change-Id: Id4941372393aef2f720cdd2ef7aa7b101d4afac6

[33mcommit 2e8bc4fbf2b9d418b39ea6f1fb9d9231fffc5efb[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Wed Aug 17 12:11:04 2016 +0200

    WL#7069: Followup. Avoid running perf unit test in debug builds, and reduce
    number of iterations in [1;31moptim[mized builds.
    
    There is not much point in running a perf test in debug mode, and there is no
    point in wasting cpu on many iterations unless benchmarking.
    
    Patch reviewed by Tor Didriksen.

[33mcommit b36429a61b18aece770fc29851b41601a0f08ce7[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Wed Aug 17 11:29:19 2016 +0200

    Bug#23106330: MISSING CHECK_STACK_OVERRUN IN JSON_BINARY::SERIALIZE_JSON_VALUE
    
    The JSON tests ran out of stack space on some platforms when running
    against a debug enabled server. Because of lacking checks for stack
    usage, the server would not detect this situation in time, and it led
    to the server exiting.
    
    The fix is twofold:
    
    1) It add calls to check_stack_overrun() before attempting to
    serialize a nested array or object in order to detect stack overruns
    up front and fail gracefully when processing deeply nested JSON
    documents. This prevents the server from exiting if it runs out of
    stack space.
    
    2) It reorganizes the code that serializes JSON document so that it is
    less stack-hungry when compiled without [1;31moptim[mization. Specifically:
    
      a) The function json_binary::append_value() is manually inlined the
      two places it is called. This function is called recursively when
      serializing nested JSON documents, so inlining it removes one stack
      frame for each level of nesting in the document.
    
      b) The code in json_binary::serialize_json_object() that writes the
      key entries section of the object, is moved out to a separate
      function called append_key_entries(). This reduces the size of the
      stack frames for serialize_json_object(), which is called
      recursively when serializing nested objects.
    
      c) The cases for serializing opaque, datetime and decimal values in
      json_binary::serialize_json_value() are moved out to separate
      functions. This reduces the stack frame size of the recursive
      serialize_json_value() function.
    
    This makes the JSON tests pass with the default stack size on more
    platforms.

[33mcommit a9304dfd24d56cd08f42084c4426fb0e985ba6be[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Wed Jul 27 10:59:32 2016 +0200

    WL#9468: Step 2. Followup. Tests using DBUG_SET must be excluded in [1;31moptim[mized mode.
    
    Test for out of memory condition which rely on DBUG_SET will fail in [1;31moptim[mized mode and
    must be removed.

[33mcommit 032a422636937c8a7f1dbad8dd87ec124f802b06[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Mon Jul 25 13:11:53 2016 +0200

    WL#988: Roles
    
    Post-push fix: Disable yet more compile warnings for files
    using Boost. This fixes build breakage on Fedora ([1;31moptim[mized build).
    
    boost_1_60_0/boost/graph/detail/adj_list_edge_iterator.hpp:70:9:
    error: '*((void*)(& eit)+48).std::_Rb_tree_const_iterator
    <boost::detail::stored_edge_property<long unsigned int,
    boost::property<boost::edge_capacity_t, int> > >::_M_node'
    may be used uninitialized in this function [-Werror=maybe-uninitialized]

[33mcommit 539dee9871d292293b5e1806098e356d830dec85[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Jul 14 15:42:28 2016 +0200

    WL#8579 Spatial Reference Systems
    
    Followup patch.
    
    Problem: out-of-memory when compiling wkt_parser.cc in [1;31moptim[mized
    mode on intel/solaris.
    Fixed by upgrading to GNU make 4.1, so the "-O1" workaround can be removed.
    
    Change-Id: I3657d9030eb7a1ead54b3d2c2287e0b4f69dc9fb

[33mcommit f7f9292f75a4b007b60185bdfacd36ec2c4fe824[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Tue May 31 11:01:51 2016 +0200

    Bug#22328100 MISSING HINTS FOR DERIVED TABLES
    WL#9307 Enabling merging a derived table or view through a [1;31moptim[mizer hint
    
    Implements a table-level hint:
     select /*+ merge(dt) */ * from (select * from t1) as dt;
     select /*+ no_merge(dt) */ * from (select * from t1) as dt;
     create view v1 as (select * from t1);
     select /*+ merge(v1) */ * from v1;
     select /*+ no_merge(v1) */ * from v1;
    Hint is of the form
    select /*+ [no_]merge([dt[@qb]]) */ ...
    and means "in query block 'qb', [don't] merge the derived table 'dt'".
    If 'qb' isn't specified it means the query block where the hint is.
    If '()' is empty it applies to all derived tables of the query block.
    For example:
    select /*+ no_merge() */ ...
    means "don't merge any derived table referenced by this query block".
    'dt@qb' can also be written as '@qb dt', and
    multiple tables can be listed in the hint, as explained in
    http://dev.mysql.com/doc/refman/5.7/en/[1;31moptim[mizer-hints.html
    
    The hint:
    - overrides any heuristic which isn't a real technical constraint
    - overrides [1;31moptim[mizer_switch flag 'derived_merge'
    - is overriden by "algorithm=merge/temptable" clause of CREATE VIEW.
    
    Specifying the hint in the query which references the derived table
    makes sense for views, as the view's definer doesn't always know
    all queries which will use his view.
    
    Changes:
    - hint functions which used a TABLE* argument now use a TABLE_LIST*
    (derived table has no TABLE at this point); for most cases it is
    more natural (less ->pos_in_table_list hops).
    - is_mergeable() is split in two (technical constraints and heuristics)
    - sql_resolver.cc: need to process hints before "if(table==NULL)continue;"
    as derived tables have table==NULL.
    
    derived.result shows the hint overriding the heuristic of
    Bug#22223202, so the user can have total control.

[33mcommit b90bd7d394a59a51909f244dd2cac70419d72520[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Jun 22 11:16:15 2016 +0200

    Bug #23623110: Range [1;31moptim[mizer: Small comment cleanup.
    
    Add an explanatory comment in SEL_ARG (on maybe_flag), and make a few existing
    ones clearer. Also add a comment on null_element.
    
    Change-Id: I57b9dac1b22e0a1b10139dda87cad6e4d08dffbd

[33mcommit cbc524750c486e9fde8266439979476964917bbb[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Wed Jun 8 10:29:10 2016 +0800

    BUG#23067038 ASSERTION FAILURE: BUF0BUF.CC:2861:BUF_PAGE_IN_FILE(BPAGE)
                 LEADS TO CORRUPT DATA
    
    It's a regression of wl#8423 InnoDB: Split the buffer pool mutex.
    
    There is a race: Thread 1, we set buf_fix_count to 0 in buf_page_init().
    Thread 2, we decrease buf_fix_count to 0xffffffff in buf_page_[1;31moptim[mistic_get().
    Thread 2, we increase buf_fix_count to 0 in buf_page_get_gen(). Thread 3,
    we evict the page from LRU list. Thread 2, assert fails: buf_page_in_file().
    
    The root cause is missing block mutex protection for buf_page_init().
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 12456

[33mcommit 82c2227a88794bfc1bea52bb925237327ae49a1c[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Fri May 27 15:19:56 2016 +0200

    Bug#23046775 DIFFERENT FLOATING POINT RESULTS ON ARM64 AND POWERPC
    
    Problem: The -fexpensive-[1;31moptim[mizations option to gcc causes ARM64 and
    PowerPC build to compute floating point operations slightly
    differently from other platforms. This flag is enabled by -O2 and
    higher [1;31moptim[mization levels.
    
    Fix: Check for the unwanted floating point behavior in CMake and
    disable expensive-[1;31moptim[mizations in GCC builds on platforms that
    experience this behavior.

[33mcommit f13858af99d3f5cff5ea0dfc1eaeebc110770f1f[m
Author: Arnab Ray <arnab.r.ray@oracle.com>
Date:   Fri May 13 01:12:54 2016 +0530

    Bug #23225849: NDB_JOIN_PUSHDOWN* TESTS FAILING ON 32-BIT MACHINES
    
    Problem:
    
    The ndb_join_pushdown* tests began failing on 32-bit machines after
    the recent server merge. The range [1;31moptim[mization step is skipped
    in these tests. In commit 87152b59b563e2749f6ea21a772d9e1d4c6dc258,
    the 'range_[1;31moptim[mizer_max_mem_size' was lowered to ensure that the
    limit was exceeded and the [1;31moptim[mization step was skipped on 32-bit
    machines as well. However, this change was effectively undone in
    commit 4cdb516fe1261b601d48d8d30916299c1e68e37a in which the memory
    usage for range [1;31moptim[mization was reduced.
    
    Fix:
    
    Further lower the limit such that it is triggered on 32-bit machines
    even in the light of the reduction of memory usage for range
    [1;31moptim[mization.

[33mcommit ea4d2c444ff091c1cc3499b8074c825998bbc001[m
Author: Sreeharsha Ramanavarapu <sreeharsha.ramanavarapu@oracle.com>
Date:   Thu May 12 15:59:19 2016 +0530

    Bug #22276843: INCORRECT BEHAVIOR OF SET VARIABLE WITH
                   SUBQUERY AND ROW CONSTRUCT
    
    ISSUE:
    ------
    The root cause here is that SET statement locks the tables
    at the beginning. This allows the [1;31moptim[mizer to read tables
    and evaluate subqueries during the PREPARE phase.
    
    The current query is of the form:
    SET @x:= (SQ1 ORDER BY (SQ2 IN (SQ3)));
    
    - The IN-to-exists (or subquery materialization, depending
    on the hint) transform is applied to the inner subquery.
    
    - Since this is a SET statement, SQ1 is also considered as
    a subquery. ORDER BY inside a subquery is redundant and is
    removed by remove_redundant_subquery_clauses(). This does
    clean_up_after_removal() on SQ3, which unplugs SQ2 and its
    children (SQ3) from the chain of units and calls
    invalidate() on them.
    
    - The crash is because, unlike cleanup() of item_subselect
    and item_singlerow_subselect, item_in_subselect::cleanup()
    tries to access first_select(). It does that because
    exec_strategy is EXEC_MATERIALIZATION or EXEC_EXISTS. In
    this case, SQ3 is evaluated and then it is invalidated for
    the reasons mentioned above. Normally, for an invalidated
    unit ("unplugged" unit) the containing Item_in_subselect
    hasn't been evaluated yet so exec_strategy is
    EXEC_EXISTS_OR_MAT and things are fine.
    
    SOLUTION:
    ---------
    Currently [1;31moptim[mizer the steps for a SET statement are:
    1) check_table_access
    2) open_and_lock_tables
    3) sql_set_var
       a) check
          i) fix_fields
          ii) ......
    
    
    Notice here that the locking of the tables precedes the
    fix_fields. As mentioned above this causes the [1;31moptim[mizer
    to assume that, with locked tables, the output of the
    subquery will be constant.
    
    To remedy this issue, we should make sure that the SET
    statements don't lock the tables before fix_fields. In this
    fix, the locking of tables is delayed until after
    fix_fields, hence avoiding the above mentioned problems.
    The new steps will be:
    
    1) check_table_access
    2) open_tables_for_query
    3) sql_set_var
       a) resolve
          i) fix_fields
          ii) ......
       b) lock_tables
       c) check
       .......
    
    Also, I'm moving the DBUG_EXECUTE_IF
    "open_tables_for_query__out_of_memory" to
    Sql_cmd_insert::mysql_test_insert and renaming it. Since
    open_tables_for_query will be used for SET statements,
    this test can be moved to an earlier insert-related function.

[33mcommit 22c8be30d2e5eb0cf887bba05cd3ec70045cd789[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Sun May 8 11:18:31 2016 +0200

    WL#9141 InnoDB: Refactor uncompressed BLOB code to facilitate partial
            fetch/update
    
    Post-push fix: Fix new compile warnings with Clang and/or
    [1;31moptim[mized build.

[33mcommit d9af8472553f3bc1ebbdb38f5b3d5a9ea9794e9c[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Fri May 6 17:29:02 2016 +0530

    Bug #22661012 : "USING INDEX FOR GROUP-BY" QUERIES CAN RETURN NO
                    DATA WITH LE/LEQ AND ROUNDING
    
    Problem:
    If rounding happens while storing a predicate value,
    range [1;31moptim[mizer might not return correct results for < and <= operators.
    
    Analysis:
    For the data presented in the bugpage, we have a value for second column
    in a multi-part index which is equal to the value that range [1;31moptim[mizer
    stores after rounding up the predicate value. This makes loose index scan
    think it has a qualifying row. But during execution, the row is rejected
    because it is larger than the value specified in the where condition.
    As a result no rows are selected.
    
    For example:
    In the data presented, we have (1,1000), (1,1001), (1,2000) (1,3000)
    with 'a' being the first column and 'b' second.
    
    For the query
    
    SELECT a, max(b) FROM t1 WHERE a = 1 and b < 1999.5 GROUP BY a;
    
    we should get row (1,1001).
    
    However since "b" is an int column, range [1;31moptim[mizer rounds off 1999.5
    to 2000. Loose index scan later finds a row with the matching record
    and thinks that this is indeed the max value for the group and
    returns (1,2000) as the row which gets rejected later.
    
    The above behavior of loose index scan picking row (1,2000) is
    because of the max_flag not being set to NEAR_MAX when range
    [1;31moptim[mizer detects that the stored value is greater than the
    predicate value. In this case, loose index scan needs to start
    reading from a value less than the stored value.
    
    However currently, loose index scan starts reading from a value equal
    to or less than the value stored.
    
    Solution:
    Set NEAR_MAX for max_flag if the stored value is >= than the specified value
    for operator < or if the stored value is > than the specified value for the
    <= operator.
    This patch is contributed by Andrew Bloomgarden.

[33mcommit eda9201048d495932261d4ae93631ee9704a6c3d[m
Author: Annamalai Gurusami <annamalai.gurusami@oracle.com>
Date:   Thu Apr 28 12:29:00 2016 +0530

    WL#9141 InnoDB: Refactor uncompressed BLOB code to facilitate partial
    fetch/update
    
    Introduction:
    =============
    
    This is a sub worklog of "WL#8960 InnoDB: Partial Fetch and Update of BLOB".
    This worklog is the second sub worklog followed by "WL#8985 InnoDB: Refactor
    compressed BLOB code to facilitate partial fetch/update". The purpose of this
    worklog is to refactor current code so that new BLOB features can be added
    conveniently.  This worklog does to uncompressed BLOB similar to what wl#8985
    did to compressed BLOB code.
    
    Logical Changes:
    ================
    
    .  The functionality of uncompressed BLOB is provided by C-style functions.
       This will be converted to C++ classes, structs and member functions.
    .  The BLOB code will be isolated and kept in lob0lob.h and lob0lob.cc files.
       This will help in modular development of BLOB features.
    .  All references will now be LOB (large objects).
    
    Detailed Changes:
    =================
    
    . Introduced new module named lob.  It contains lob/lob0lob.cc and
      include/lob0lob.h files.
    . Added new namespace lob.
    . lob::Inserter - a new class to insert a complete uncompressed BLOB.
    . lob::zInserter - a new class to insert a complete compressed BLOB.
    . lob::InsertContext - a new class to contain contextual information for the
       insert operation.
    . lob::BaseInserter - a class that holds common state and functions useful
       for both compressed and uncompressed BLOB.  This is the base class for
       lob::Inserter and lob::zInserter.
    . lob::Deleter - a new class to destory/delete a BLOB
      (both compressed/uncompressed)
    . lob::DeleteContext - a new class to contain contextual information for the
      delete operation
    . lob::Reader - a new class to fetch a uncompressed BLOB.
    . lob::zReader - a new class to fetch a compressed BLOB.
    . lob::ReaderContext - a new class to contain contextual information for the
       fetch operation
    
    Design Rationale:
    =================
    
    There are 2 approaches that I explored - one is to have a single LOB class with
    each major operations as an member function.  For example,
    
    class LOB {
    public:
       int insert();
       int update();
       int read();
       // ..
    private:
       // ...
       Context* m_ctx;
    };
    
    But doing it this way, will make the class LOB like a kitchen sink.  It will
    end up that some member variables are used only when we are doing insert
    operation, and some other member variables are used when doing read operation
    and so on.  There won't be any cohesion b/w the member variables and member
    functions.  For one instance of the LOB class, we will most likely use only one
    operation, eg insert.  This is the reason I didn't prefer this approach.  The
    other approach is to design LOB classes around the major operations that will
    be performed, which truely reflects the way these classes will be used.
    
    The current design of LOB classes revolves around the way the major operations
    that will be performed on LOB data.  The currently supported major operations
    are insert, delete and read.  As of now all of them operate on complete LOB
    data.  For each of the major operation one new class is introduced.
    
    Inserter - for inserting LOB data.
    Reader   - for reading LOB data.
    Deleter  - for deleting LOB data.
    
    Now there are two variants to LOB data - compressed and uncompressed.  An
    insert operation or a read operation is completely depended on whether the data
    is compressed or not. But a delete operation is not that much dependant on
    this. Hence I introduced separate classes for compressed LOB.
    
    Inserter - for inserting uncompressed LOB data.
    zInserter - for inserting compressed LOB data.
    Reader   - for reading uncompressed LOB data.
    zReader   - for reading compressed LOB data.
    Deleter  - for deleting both compressed and uncompressed LOB data.
    
    At this point I noticed that there was some common code between Inserter and
    zInserter which I can factor out into a base class.  So I introduced
    BaseInserter which will contain common state and function useful for both
    Inserter and zInserter.  So the final list of main LOB classes are:
    
    Inserter - for inserting uncompressed LOB data.
    zInserter - for inserting compressed LOB data.
    BaseInserter - a base class containing common state and functions useful for
                       both Inserter and zInserter.  Inserter and zInserter derives
                       from this base class.
    Reader   - for reading uncompressed LOB data.
    zReader   - for reading compressed LOB data.
    Deleter  - for deleting both compressed and uncompressed LOB data.
    
    One point to be noted is that these classes are formed by refactoring existing
    code.  So to reduce the amount of code changes, I allowed some differences in
    the way they operate.  The Inserter and zInserter class is designed to insert
    all the LOB data of a single clustered index record.  It operates on the big
    record vector.  But the other classes (Reader, Deleter, zReader) all operate
    on a single LOB data only.  By doing it this way, I avoid significant amount
    of code changes.
    
    The main classes of the LOB module has been identified above.  To support them
    there was a need to provide context classes that will contain information needed
    for LOB operation.  Previously, the C style functions had a list of 6 or 7
    arguments.  These arguments are the context information that is necessary to provide
    the various main operations on LOB data.  For each main operation, the context
    information is identified separately.  They are as follows:
    
    InsertContext - context information for doing insert of LOB. `
    DeleteContext - context information for doing delete of LOB. `
    ReadContext   - context information for doing fetch of LOB. `
    
    The insert operation also has one special [1;31moptim[mization - the bulk insert.
    These context classes evolved separately as I refactored one operation at a
    time.  And when I look back, I don't see any need to club them all together.
    There are some specific checks that are done only for the insert operation,
    like the redo log space check, which are captured in the InsertContext.  If
    we have a single context class, then it will contain unnecessary information
    not usable for the current operation.  Also, all these context classes are
    arrived at based on how and where it will be used.
    
    Finally, while evaluating this design, please do keep in mind that these
    classes come out of refactoring existing code.  If you look at the patch, the
    amount of code changed where LOB module is _used_ is very minimal.  I think my
    main focus was to isolate the LOB code and design a set of C++ classes which
    will make the extension of functionality easier.
    
    And the main purpose of refactoring was to enable to add partial fetch and
    partial modify/update operations.  For these purposes, I believe that this
    design is suitable.  Surely one can do more and more refactoring to achieve
    better results.  But since we are doing refactoring for a particular purpose, I
    think we should stop when our purpose will be solved.
    
    Functions Removed:
    ==================
    
    The following functions has been removed.
    
    . btr_copy_blob_prefix()
    . btr_copy_externally_stored_field_prefix_low_func()
    
    Functions Moved to lob module:
    ==============================
    
    The following functions are moved to the lob module.
    
    . btr_copy_externally_stored_field_prefix_func() and the associated
      macros.
    . btr_rec_free_updated_extern_fields()
    . btr_blob_get_part_len()
    . btr_blob_get_next_page_no()
    . btr_check_blob_fil_page_type()
    . btr_rec_free_externally_stored_fields()
    . btr_copy_externally_stored_field_prefix_func()
    . btr_copy_externally_stored_field_func()
    
    rb#11861 approved by Deb.

[33mcommit 56f7761cd1362de9249029e5309d14aaf49d12fe[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Mar 4 13:38:12 2016 +0100

    Bug#22839888 UNINITIALIZED VALUE WHEN CONVERTING MULTIBYTE STRINGS TO NUMBERS
    
    Problem: valgrind warnings with clang in [1;31moptim[mized mode.
    Fix: do not read past the end of the input buffer in my_strtod_int()

[33mcommit 4b9fe117eccea4b09b10ad11b053d2b87ee597dc[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Mon Feb 29 16:27:53 2016 +0800

    BUG#21378944 FTS ASSERT ENC.SRC_ILIST_PTR != NULL, FTS_OPTIMIZE_WORD(),
                 OPTIMIZE TABLE
    
    Problem:
    when we [1;31moptim[mize a deleted word with only one entry in fts aux table,
    a new empty entry is written, then server cores when the empty entry
    gets [1;31moptim[mized again.
    
    Solution:
    Don't write empty entry.
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    RB: 11926

[33mcommit cc72f65f4c13d47026230005e4fcc751c54c0f48[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Mon Feb 29 16:09:45 2016 +0800

    BUG#21378944 FTS ASSERT ENC.SRC_ILIST_PTR != NULL, FTS_OPTIMIZE_WORD(),
                 OPTIMIZE TABLE
    
    Problem:
    when we [1;31moptim[mize a deleted word with only one entry in fts aux table,
    a new empty entry is written, then server cores when the empty entry
    gets [1;31moptim[mized again.
    
    Solution:
    Don't write empty entry.
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    RB: 11926

[33mcommit 21c9d3ba31bdde54ef219d64c81a3975bb39bd01[m
Author: Sreeharsha Ramanavarapu <sreeharsha.ramanavarapu@oracle.com>
Date:   Thu Feb 4 08:15:33 2016 +0530

    Bug #20933307: VIEWS CAN EVALUATE USER FUNCTIONS BEFORE
                   VIEW RESTRICTIONS
    
    ISSUE:
    ------
    VIEWs are a common means to implement row-level filtering.
    Such VIEWs have filter-conditions on which rows are
    accessible to end users.  However, in certain conditions,
    the [1;31moptim[mizer may choose to defer evaluating the
    restrictions contained in the VIEW definition if they are
    determined to be more expensive than other, user-supplied
    conditions.
    
    This is problematic when user-supplied conditions include
    UDFs or SQL functions which can record row data before VIEW
    filters have been applied.
    
    SOLUTION:
    ---------
    While merging the view's underlying table with the query,
    we swap the evaluation order to bring the predicates from
    the view definition ahead of the outer-query's predicate.
    
    This change happens only when there is a stored procedure
    in the outer-query's predicate.

[33mcommit c20b85db7b1bd83ad26512a9cf6c925db21eb421[m
Author: Martin Hansson <martin.hansson@oracle.com>
Date:   Mon Feb 1 11:13:08 2016 +0100

    Removal of Doxygen 'undocumented parameter' warnings in the [1;31moptim[mizer.

[33mcommit 16758e6a0ab45fbc559bcbdc94ec1bd924661fe4[m
Merge: de40bfb2b7d b5e72d2e130
Author: Evgeny Potemkin <evgeny.potemkin@oracle.com>
Date:   Fri Jan 29 21:55:16 2016 +0400

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            sql/sql_[1;31moptim[mizer.cc

[33mcommit e00a774b954014a4640de9d173503d1b438144e3[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Mon Jan 25 15:43:14 2016 +0100

    Bug#22565155 DATA ROWS LOST AFTER ADDING DISTINCT WITH SUBSTR() IN SELECT LIST
    
    Problem: Item_func_substr::fix_length_and_dec tries to [1;31moptim[mize 'max_length'
    in case input arguments 2/3 are constant values. The result of val_int()
    was cast to int32, thus losing precision. For the 'distinct' case we end up
    with a temporary table with column size 3 rather than 33, and rows are
    incorrectly discarded as duplicates.
    
    Fix: check that constant input values are between INT_MIN and INT_MAX,
    before doing the 'max_length' [1;31moptim[mization.
    
    Implement a new Integer_value class, with appropriate comparison operators,
    to simplify the code.
    
    Also: use the new Integer_value and compare operators to simplify the patch for:
    Bug#22523685 FUNCTION GREATEST AND LEAST WORKS INCORRECTLY WITH BIGINT UNSIGNED VALUE

[33mcommit 4d1f996d7fca85178b759df79fcb84459427c34c[m
Author: Debarun Banerjee <debarun.banerjee@oracle.com>
Date:   Mon Jan 18 16:33:02 2016 +0530

    BUG#22452597 CHECK ALGORITHM=INNODB ON CRC32 CHECKSUM MISMATCH
    
    Problem :
    ---------
    When a page checksum validation fails for default crc32, we always
    try computing legacy big endian crc32 checksum first and then the
    innodb checksum. While upgrading from 5.6 (default checksum innodb)
    to 5.7 (default checksum crc32), this would cause repeated evaluation
    of the legacy checksum.
    
    This issue is there for both compressed and uncompressed pages.
    
    Solution :
    ----------
    Since it is likely that all the pages would have same checksum
    algorithm, we [1;31moptim[mize the order dynamically.
    
    1. By default attempt innodb checksum after crc32
    2. Once we find a page with legacy big endian crc32 checksum we
    switch the order and attempt big endian checksum first.
    
    Reviewed-by: Jimmy Yang <Jimmy.Yang@oracle.com>
    
    RB: 11403

[33mcommit 714f04a881edfd15b6c62a9b3d12ec51d9af6af7[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Fri Jan 15 08:34:43 2016 +0100

    Bug#22522073: Assertion failed: !thd->is_error() in [1;31moptim[mize_cond()
    
    Another issue of missing error propagation:
    
    - Added return on error after calling val_json() in resolve_const_item().
    
    - Missing error check in Item_singlerow_subselect::val_json() caused
      wrong function result.

[33mcommit 0c98a6d9d126095fbddebea8abf1901d4fa00cb6[m
Author: Olav Sandstaa <olav.sandstaa@oracle.com>
Date:   Tue Dec 8 09:53:19 2015 +0100

    Bug#22304236 RESULT CONTENT MISMATCH IN MAIN.GREEDY_SEARCH
    
    The greedy_search test could fail due to differences in query plans on
    servers where the table_open_cache was adjusted to a low value. The
    cause for the different query plans was due to the TABLE objects were
    deleted after inserting data into the tables and re-created when
    starting on the next query. This caused statistics about the number of
    records for some of the tables to be missing when [1;31moptim[mizing the first
    few queries. This only affected queries until the persistent
    statistics was updated for all tables by a background thread in
    InnoDB.
    
    To ensure that information about the number of records and index
    statistics are updated before running queries, run ANALYZE TABLE for
    each of the tables used by the test.
    
    Two queries get new query plans with the updated statistics. The new
    query plans for these queries are now identical to the query plans in
    mysql-5.7 where this test is run using MyISAM instead of InnoDB.

[33mcommit ca0bf2727f27d51d09f1437f80fa7ef7799f9d04[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Fri Dec 25 12:47:18 2015 +0100

    BUG#21889312: Introduce new config variable SchedulerResponsiveness that makes it possible to be more or less latency/throughput [1;31moptim[mised, higher value means more responsive

[33mcommit eef9ce1bc81b7b1cfe3fbe38f79c13c9fc495a67[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Wed Dec 23 12:45:51 2015 +0100

    Bug#22098258: Refactor the multi-dimensional ref_pointer_array into 5 individual arrays
    
    This is a prerequisite for WL#6570: Refactor DML statement preparation
    
    The ref_pointer_array is an array of references to item objects that is
    shared between the resolver struct and the [1;31moptim[mizer struct. It is
    created during resolving in five slices. The first of these slices is
    populated during resolving, whereas the remaining four slices are
    populated during [1;31moptim[mization. The array is used during execution using
    a technique that involves copying slices of the array on top of slice zero.
    
    The ref_pointer_array is used together with Item_ref objects to
    reference a varying set of other Item objects during execution.
    Each Item_ref object contains a ref field which is a pointer to a pointer
    to an Item. It is set to point to one cell in slice zero of the
    ref_pointer_array. By copying another slice over slice zero, the
    Item_ref will actually point to a different Item.
    
    There are several problems with this structure:
    
    1. The sharing between resolver and [1;31moptim[mizer means it is impossible to
    have multiple query execution plans for a single query.
    
    2. By allocating the array as a multi-dimensional array, the size of the
    array must be determined before allocation. This forces us to make some
    conservative estimates about the size of the array.
    
    3. By letting Item_ref::ref point to a cell of the array, the array must
    be fixed during preparation, [1;31moptim[mization and execution. It has to be
    allocated up front and all five slices must be allocated, even though
    simple queries only need slice zero.
    
    4. The copying of slices means that the plan is modified during
    execution. This prevents us from sharing plans
    between concurrently executing sessions. It is probably possible to use
    it when creating a multi-thread plan, but it forces us to perform the
    copying in lock-step. Query plans for individual threads are not
    independent.
    
    This subtask will address item 1 and partially item 2 above. It lays the
    groundwork for addressing the remaining items.
    
    Splitting the array
    -------------------
    
    The main task is to split the array from being a multi-dimensional array
    to an array with five elements that each may reference an array of item
    pointers. This array is kept in class JOIN and is named ref_items.
    
    Slice zero of the existing array is allocated during resolving and is
    kept in class SELECT_LEX with the name base_ref_items. During
    [1;31moptim[mization, slice zero of JOIN::ref_items is set to point to this array.
    
    Modifications to class SELECT_LEX
    ---------------------------------
    
    - The class used for ref_pointer_array is renamed from Ref_ptr_array to
      Ref_item_array, since it is an array of references to Item objects.
    
    - The array references ref_pointer_array and ref_ptrs are replaced with
      base_ref_items, which only contains slice zero of the previous ref array.
    
    - The function ref_ptr_array_slice() is no longer necessary, since we
      now have individual arrays of item references instead of a
      multi-dimensional array.
    
    - setup_base_ref_items() is a new function that creates slice zero of
      the ref array.
    
    Modifications to class JOIN
    ---------------------------
    
    Instead of structures with hard-coded names such as tmp_all_fields1,
    tmp_all_fields2, where 1 resp. 2 is a step number, these structures are
    now placed in an array that is indexed with slice numbers. We have also
    given symbolic names to slice numbers: There are five slices, slice
    number zero is the base slice, slice 1, 2 and 3 are associated with
    handling of the first, second and third temporary table, respectively,
    and slice 4 is used to save the original contents of slice zero.
    By using symbolic names, it has become easy to rearrange the slices.
    We have taken advantage of that to make the "save" slice number four
    instead of one, so that the temporary tables are related to
    corresponding fixed slice numbers 1, 2 and 3.
    
    - ref_items contains what used to be ref_pointer_array. The difference
      is that it is an array with pointers to one-dimensional arrays instead
      of being a multi-dimensional array.
    
    - tmp_all_fields is an array of field list pointers which replace the
      previous lists tmp_all_fields1, tmp_all_fields2 and tmp_all_fields3.
    
    - tmp_fields_list is an array of field list pointers which replace the
      existing lists tmp_fields_list1, tmp_fields_list2 and tmp_fields_list3.
    
    - current_ref_item_slice denotes the number of the slice of ref items
      that currently reside in slice zero of ref_items.
    
    - copy_ref_item_slice() has been modified to take slice numbers as
      arguments instead of arrays. (The exception is ROLLUP processing,
      which still needs to operate on pointers to ref item arrays).
    
    - alloc_ref_item_slice() allocates a slice of the ref item array, by
      supplying a slice number between 1 and 4.
    
    - set_ref_item_slice() copies one of the slices to slice zero and sets
      current_ref_item_slice accordingly.
    
    Modifications to class QEP_TAB (executor.h)
    -------------------------------------------
    
    - ref_array_pointer is replaced with ref_item_slice.

[33mcommit 9fce6b0f909b09645d308912001c4234e06eaf3a[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Nov 19 14:49:30 2015 +0100

    Bug#22239943 GET RID OF THD::NO_ERRORS
    
    THD has a bool member called no_errors.
    It is used only by the range [1;31moptim[mizer, to ignore certain
    conversion errors during [1;31moptim[mization.
    
    The value is checked in various val_xxx functions
    and warnings are suppressed.
    
    Comment in opt_range.cc says 'Don't warn about NULL'
    The code is obsolete, there are no warnings about NULL.
    
    Only one test in the entire test suite needs re-recording.
    
    Most new warnings are duplicates, the only new and interesting one is
    +Warning        1292    Truncated incorrect DOUBLE value: 't'
    
    The range [1;31moptim[mizer is evaluating 'alias2.pk >= alias1.col_varchar_nokey'
    
    We are doing Item_field::val_real on "col_varchar_nokey"
    because res_type == REAL_RESULT in stored_field_cmp_to_item

[33mcommit ebc4a60a46a3077a20ce346dee07bdea2c936bfc[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Dec 10 12:47:51 2015 +0100

    Bug#22194071 ENABLING UNDEFINED BEHAVIOR SANITIZER RESULTS IN BROKEN SERVER
    
    -DWITH_UBSAN=ON results in server that is not able to --bootstrap for MTR.
    
    This patch gives a clean bootstrap, and a mostly-clean run of main.1st
    Lots of warnings about undefined behaviour are gone, so that
    -DWITH_UBSAN=1 now actually can give useful results.
    Below is a detailed list of changes done.
    
    Remove the virtual DTOR for class ilink, it is obsolete.
    With that gone, we can static_assert that base_ilist is only used for
    PODs, which should be safe. These classes were not safe for linking
    THDs, as evidenced by Bug#13645095
    
    Suppress UBSAN warnings for three member functions sql_list.h
    We know that the sentinel is not a T (the template argument),
    but given the assert that it's a POD, this should be safe.
    
    Remove [1;31moptim[mization for UBSAN, function inlining made traces really
    hard to read.
    
    Field::Field used the member function normalize_dec in the CTOR init
    list. Make normalize_dec static, so that behaviour is defined.
    
    Same thing in Item_func_interval, non-static member function alloc_row
    cannot be called in CTOR init list.
    
    Similar things in Write_rows_log_event / Delete_rows_log_event /
    Update_rows_log_event CTORs.
    They initialized the base class Rows_event with a member field in Rows_event.
    Initializing a field with itself makes little sense, and it is
    undefined behaviour to access that field in a CTOR init list of a
    derived class.
    
    sp_head::operator new() and sp_head::operator delete() have undefined
    behaviour, they access the sp_head object before it is constructed.
    Suppress this one for now: TODO fix it properly.
    
    Fix wrong C-style cast in substitute_for_best_equal_field()
    Fix wrong C-style cast in update_const_equal_items()
    Remove wrong C-style cast in new_Cached_item()
    Remove wrong C-style cast in get_mm_leaf()
    
    Remove the return value from Abstract_option::add_callback,
    it is unused in the code, and the C-style cast was wrong.
    
    Add test for "len > 0" a few places for memcpy, memcmp, memset etc.
    to avoid warnings for pointer arguments being NULL.
    
    Disable the alignment attribute for Stage_manager::Mutex_queue.
    It gave *lots* of warnings of missing 64-byte alignment.
    
    There were several warnings from copy CTORs generated by the compiler,
    when the source object was only partly initialized.
    Fixed by adding a few more field initializers in existing CTORs.
    
    Remove casting of -1 to the enum Item_result,
    add a new enum with value -1 instead.
    
    Add CTOR to struct HA_CREATE_INFO, and remove memset(create_info) a
    few places.
    
    Suppress warnings from copying YASSL WindowSlider objects.

[33mcommit 6b9553855de124cd720cb6da015f9f97eede75b1[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Nov 12 07:58:53 2015 +0100

    Bug#22148586 IF(BOOL, DATE STR, DATE STR) THROWS ERROR IN UPDATE
    
    The [1;31moptim[mizer is trying [1;31moptim[mize away the constant expression
      IF(true, '2015-01-01', '2015-01-01') IS NOT NULL
    In order to do so, it calls update_null_value(), which invokes val_int()
    which fails.
    
    Solution: use Item::evaluate() instead, it will invoke the correct val_xx()
    Remove all the specializations of update_null_value, they are not needed.

[33mcommit 410c63b8d1df8489e0cfdd73ce667b445d4a08d8[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Fri Nov 13 11:49:37 2015 +0530

    WL#7771 Make sure errors are properly handled in DD API.
    
    * Handle error from Weak_object_impl::check_parent_consistency().
    
    * Handle error from Tables::max_se_private_id().
    
    * Removing fprintf() in DD code and use sql_print_error/warning.
    
    * Update code to handle [1;31moptim[mized build, where we currently assert
      only in debug build using DBUG_ASSERT(!"...");
    
    * Validate DD objects after restoring them from the database. This would
      help catch scenario when DD table is possibly corrupt.

[33mcommit f0314c1702d21de7055ab667c1733784b48a6421[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Wed Nov 4 10:33:59 2015 +0100

    Bug#21522980: Resolver: Simplify some often executed condition and expr code
    
    This is a cleanup patch for better performance and code simplification.
    
    Refactored processing of join conditions: Previously, join conditions
    were resolved by running through the leaf table list and traversing
    upwards using the embedding member until the root was reached. This
    meant that several join nodes might be visited multiple times.
    The new implementation is a recursive function that goes top-down,
    visiting each table/join nest only once. Even though the function
    is recursive, it will be invoked only once for simple queries.
    
    Shortcut of function calls: The following functions are no longer
    called when there is no work to do:
    - setup_ftfuncs()
    - check_view_privileges()
    - setup_natural_join_row_types()
    - flatten_subqueries()
    
    Resolving of variable assignments: This used to be done for every time
    the expressions of a query block were resolved, but it is necessary
    only once per query. Separated into a new function
    resolve_var_assignments() which is called once from handle_query().
    
    Error handling: Added a few asserts for !thd->is_error(), to improve
    checking for unnoticed errors, that otherwise may cause erroneous
    execution.
    Due to adding these new checks, it was necessary to add explicit
    check for thd->is_error() in Item_sum_num::fix_fields() and
    mysql_test_select().
    
    Test change in i_main.subquery: Since join conditions now may be resolved
    in a different order, [1;31moptim[mization may be shortcut due to
    "Impossible WHERE" for a different join nest.
    
    sysbench point select shows performance enhancement 0-1 per cent.

[33mcommit c698b024880694f69f490c09edbf67d0a8b22de3[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Tue Nov 3 16:31:46 2015 +0800

    To fix the valgrind issue in fts [1;31moptim[mizer.
    
    Remove the useless and bogus judgement, so that we can now consume all
    the messages passed in to fts [1;31moptim[mizer thread.
    
    Approved by Marko via IM.

[33mcommit 2989607f28cef0c7fd1c897d4d77b2db0654ee3b[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Mon Oct 19 11:22:32 2015 +0200

    WL#6815 Adapt MySQL Cluster to 5.7
    
     - another fix for new warning about "'range_[1;31moptim[mizer_max_mem_size'
       exceeded" where the limit was not exceeded on 32bit.
     - fix by lowering the limit so it's triggered also on 32bit.
     - considered raising the limit or setting to unlimited but since
       it requires a really large amount of memory to range [1;31moptim[mize
       this query and it's not really what's being tested, it feels better
       to skip the range opimitzation step.

[33mcommit 640b994560e0111f7111bde0cb5db968533f3a8f[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Fri Oct 9 11:42:46 2015 +0200

    WL#6815 Adapt MySQL Cluster to 5.7
    
     - fix slightly different output from EXPLAIN, the order of
       tables and columns have changed
     - fix new warning about "'range_[1;31moptim[mizer_max_mem_size' exceeded" for
       a few queries with large IN() clasuses. This does not matter since
       those large IN was tested only to see that they were discarded
       also by ndbcluster.

[33mcommit 2a45e55ad875a385f6c3ddc5436e43d0fe2cc93b[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Fri Oct 9 10:02:12 2015 +0200

    Make NDBT_Test programs use --ndb-[1;31moptim[mized-node-selection option.
    
    Option was accepted but never used.

[33mcommit 5434508117166e38c0d06edb02ea13b2ff4d034b[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Thu Oct 8 23:28:51 2015 +0200

    Turn off [1;31moptim[mized node selection for testScan -n Bug54945.
    
    Error is injected in a dbtc node, and depends on that eventually
    that nodes dbtc are used for a transaction, which [1;31moptim[mized node
    selection can hinder.
    
    Also one need to wait for ndb client to connect to cluster
    (waitUntilReady) before start transaction after cluster system
    restart.

[33mcommit a196f2316a0f72edb7f50c8b796cc613368f3212[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Thu Oct 8 23:06:29 2015 +0200

    Turn of [1;31moptim[mized node selection for testIndex -n DeferredMixedLoadError.
    
    Test depends on that dbtc there error are inserted eventually is
    used for some transaction.

[33mcommit 6e290b49e06ae3bec2a63d49d7bdf6cf8932a637[m
Author: Sergey Glukhov <sergey.glukhov@oracle.com>
Date:   Fri Sep 4 08:19:04 2015 +0300

    Bug#21621313: ASSERTION FAILED: JOIN == 0 IN SELECT_LEX::OPTIMIZE() WITH MAX_EXECUTION_TIME
    
    Subquery fails during [1;31moptim[mization in make_join_plan() function.
    We exit from JOIN::[1;31moptim[mize with return value TRUE but no error code
    is set in this case. Subquery [1;31moptim[mization and execution is called from
    [1;31moptim[mize_cond() function. This function ignores the fact that thread is killed.
    After [1;31moptim[mize_cond() we check if error happens and since no error code is set
    we continue [1;31moptim[mization. In this case SELECT_LEX_UNIT::is_[1;31moptim[mized is not
    TRUE and we attempt to [1;31moptim[mize already processed SELECT_LEX in
    SELECT_LEX::[1;31moptim[mize which leads to assert failure.

[33mcommit c8e8997b9df5102ce2992e20e4cbb03ed50bd7d6[m
Merge: 93dddaaa68b c44f992c575
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Wed Sep 2 15:57:43 2015 +0200

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            sql/sql_delete.cc
            sql/sql_[1;31moptim[mizer.cc

[33mcommit 91d368cdfe8514627a8227e31dab67b93ae18eb8[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Aug 26 14:02:48 2015 +0300

    Fix a race between delete and copy-to-next
    
    There is a bug in the lock free hash table used in WL#7170:
    
    During copy to the next array tuples with val = DELETED are skipped and
    not copied as an [1;31moptim[mization because such tuples are treated as they do
    not exist, so their existence is not necessary and they only take up
    space.
    
    But there is the following race between copy and concurrent delete:
    
    copy: copy to the next array because val != DELETED (e.g val == 12345)
    (now the next array contains the tuple with val == 12345)
    
    del: change val from 12345 to DELETED
    
    copy: try to CAS val from 12345 to GOTO_NEXT_ARRAY, but it fails because
          val is now DELETED. CAS will return the most recent val and it
          will be DELETED
    
    copy: since CAS failed and we have the most recent value (DELETED), copy
          again to the next array, but val == DELETED and we skip this
          operation as the buggy [1;31moptim[mization, nothing is done
    
    copy: try to CAS val from DELETED to GOTO_NEXT_ARRAY, success.
    
    Now the old array contains a tuple with val == DELETED, the next array
    contains a tuple with val == 12345 and the effect of the delete
    operation is lost.
    
    WL#7170 InnoDB buffer estimates for tables and indexes

[33mcommit 821b4edc70bfbaa2e46280fae4e9a1f75b67199a[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Jun 22 13:57:10 2015 +0300

    Go to the next array if the val is flagged as such
    
    This patch handles GOTO_NEXT_ARRAY in the read scenarios (get(), del()).
    
    This will be used when copying all the tuples to the next array.
    
    Also, designate a deleted tuple with val == DELETED, instead of
    key == DELETED. There are two reasons for this:
    1. This way it is possible to atomically change a tuple from deleted to
       'go to the next array', by CASing val from DELETED to GOTO_NEXT_ARRAY.
    2. This is more [1;31moptim[mal in a scenario where a tuple with a given key is
       being constantly deleted and readded. Now a single cell in the array will
       be reused for this, instead of grabbing a new cell on each readd.
    
    WL#7170 InnoDB buffer estimates for tables and indexes

[33mcommit e3cb6e35db815d2afa881e00d33a14fbef588b1e[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Thu Jun 11 14:51:33 2015 +0200

    Bug#21038929 SINGLE-TABLE SCALAR SUBQUERY WITH LIMIT AND ORDER BY GIVES WRONG RESULTS
    
    In the 5.7 fix for this bug, a slightly wrong [1;31moptim[mization is removed.
    Here, only for trunk, we put the removed [1;31moptim[mization back, but
    in a correct form, into remove_redundant_subquery_clauses().
    Compared to the original [1;31moptim[mization, it's not limited to single-table
    queries with unique fields in GROUP BY.
    Test results: in subquery* and opt_trace* we observe the removed ORDER BY;
    to preserve the intention of group_by.test I add LIMIT (so that
    ORDER BY is not removed).

[33mcommit 46e4c02e8398337e931dada1f170db79d5b42692[m
Merge: 54a57b25ede 38e3aa74d8d
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Mon Jun 1 15:42:50 2015 -0500

    Merge branch 'mysql-5.7-wl#7943' into mysql-trunk
    
    Conflicts:
            mysql-test/r/partition_innodb_tablespace.result
            mysql-test/suite/innodb/r/temporary_table_[1;31moptim[mization.result
            mysql-test/suite/innodb/t/create_tablespace.test
            mysql-test/suite/innodb/t/temporary_table_[1;31moptim[mization.test
            mysql-test/t/partition_innodb_tablespace.test
            storage/innobase/handler/ha_innodb.cc

[33mcommit 75d1452d2e8f0161f63e4c985acc7ccd72d34f8c[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Thu May 28 14:59:55 2015 +0200

    Bug#20949117: Remove obsolete code from UNION processing
    
    After the last refactoring work in preparation and [1;31moptim[mization,
    there are some unused code blocks in sql_union.cc.
    This bug fix eliminates those code blocks completely and performs
    some simple additional refactoring.
    
    - Added an interface st_select_lex_unit::is_simple() that wraps
      testing for !(is_union() || fake_select_lex)
    
    - Cleaned up global_parameters() a bit: Only ORDER BY/LIMIT/OFFSET
      should be accessed through it, otherwise use fake_select_lex.
    
    - Initialization of JOIN::do_send_rows was moved from [1;31moptim[mization to
      execution, since it is used only in the latter.
    
    - st_select_lex_unit::prepare() has mostly cosmetic changes and improved
      comments. Call to set_current_select() eliminated for error case.
    
    - Deleted unused function Query_result::reset_offset_limit_cnt
    
    - st_select_lex_unit::[1;31moptim[mize() had an unused code block started with
      if (sl == global_parameters() && is_union()).
      It was unused because global_parameters() always return the "fake" object
      for a UNION query. Besides, with the introduction of
      Query_result_union_direct, LIMIT/OFFSET handling is correct without
      adjusting offset_limit_cnt and select_limit_cnt.
    
    - An equivalent code block is removed from st_select_lex_unit::execute().
      Variable rows_at_start was found to be redundant.
      Calls to set_current_select() were removed in error case.
      offset_limit_cnt did not need to be assigned here, since it is done
      in set_limit().
      Call info(HA_STATUS_VARIABLE) was moved to a more logical place
      (used to get row count from temporary table used by UNION).
      add_rows was never assigned so it could be removed:
      sl->join->calc_found_rows is never true for a query block that is
      part of a UNION (either braces=true or m_select_limit=HA_POS_ERROR,
      see JOIN::[1;31moptim[mize()), search for comment "Calculate found rows if".
      join->examined_rows is reset in JOIN::exec() so assignment is deleted.
    
    - Added more extensive tests for LIMIT and OFFSET to limit.test

[33mcommit ca6ecd8229c53b0a139304bf6641cef6e529e61a[m
Merge: b840f9e9e35 2e91bec76f5
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Apr 8 12:35:31 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug #20590548 UNABLE TO LOGIN WITH USER WHOSE PWD CHANGED FROM 5.6.23 MYSQLADMIN IN 5.7.6
      Bug#20726413 : MYSQL_SSL_RSA_SETUP DOES NOT HAVE USER OPTION
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES                    OF INNODB_CHECKSUM_ALGORITHM
      WL#8244 Hints for subquery strategies. Part#2: Add support for SEMIJOIN/_SEMIJOIN and SUBQUERY hints
      WL#8244 Hints for subquery strategies. Part#1: Add [1;31moptim[mizer_switch for DuplicateWeedout strategy.
      WL#7696 follow up fix, check return values.
      Fixed bug#20745142: GENERATED COLUMNS: ASSERTION FAILED: THD->CHANGE_LIST.IS_EMPTY()
      Fixed bug#20797941: WL8149:ASSERTION `!TABLE || (!TABLE->READ_SET ||                     BITMAP_IS_SET(TABLE->READ_SET
      BUG#20593808 - CRASH WITH PARTITIONED TABLES + MULTITABLE DELETE
      WL#7696 follow up fix.
      Bug#20788853 MUTEX ISSUE IN SQL/SQL_SHOW.CC RESULTING IN SIG6. SOURCE LIKELY FILL_VARIABLES
      WL#7696 followup - remove unused file
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, rerecord the test
      WL#7696 follow up fix, add INNODB_COMPRESS_DEBUG to the test.
      Bug#20840377 UNITILAISED BYTES REPORTED AT MY_WRITE.C:63
      Fixed failing tests after commit 335a53004313ab5a971cf17dea36f1dc4490db9f MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20755430 COST CONSTANT CACHE MUTEX NOT INSTRUMENTED BY PERFORMANCE SCHEMA
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      WL#7696 follow up fix.
      WL#7696 follow up fix - add INNODB_COMPRESS_DEBUG to the list
      Addendum to bug #20810928: fixed the test to reflect that COM_SHUTDOWN can be a zero-length RPC
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20678411 BROKEN MAKEFILE DEPENDENCY: SQL_YACC.YY AND LEX_TOKEN.H
      Bug #17299181    CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      BUG#20093172 LOG_STATE DECLARED VOLATILE, MISSING MEMORY BARRIERS
      BUG#20042205 RPL_GTID CHECKABLE_RWLOCK DEBUG CODE DOESN'T NEED VOLATILE              LOCK_STATE
      BUG#20042109 MYSQL_BIN_LOG::M_PREP_XIDS DOESN'T NEED TO BE VOLATILE
      BUG#20754369: BACKPORT BUG#20007583 TO 5.1
      Bug #17299181  CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      Bug#20411374:CAN NOT EXECUTE CHANGE MASTER AFTER ERROR OCCURED IN MTS MODE
      Bug#20683741 fixed.
      Bug #20814051 CREATE USER BINLOG EVENTS INCLUDE NEW ACCOUNT KEYWORD
      BUG#20510811 - RQG_ALTER_ONLINE_PART RUN INTO ASSERTION: NODE->ENTRY
      Bug#20279241 - ALTER TABLE XXX CHARACTER SET UTF8, CONVERT TO CHARACTER SET LATIN1 SHOULD FAIL
      Adapt new sql/ha_ndbcluster.cc code to use the new ER_THD() macro
      Remove MCP_GLOBAL_SCHEMA_LOCK patch
      Bug #20810928: CANNOT SHUTDOWN MYSQL USING JDBC DRIVER
      Fixed Bug #20683741.
      Test cleanup
      Bump version to 7.5.0
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20811494 SHOW_COMPATIBILITY_56 = OFF INCOMPATIBLE WITH CONNECTORS
      Bug#20531812: MEMORY CONSUMED QUICKLY WHILE EXECUTING LOOP IN PROCEDURE
      Bug#20683959 LOAD DATA INFILE IGNORES A SPECIFIC ROW SILENTLY UNDER DB CHARSET IS UTF8
      Remove MCP_BUG16021021
      Remove MCP_WIX
      Bug#20313067 CHECK TABLE REPORTS WRONG COUNT FOR SPATIAL INDEX AND OTHER GIS PROBLEMS
      Bug#20124342 MYSQL 5.6 SLAVE OUT OF MEMORY ERROR ? Problem: I/O thread on Slave with master_info_repository=TABLE settings, is leaking memory that leads to Out of memory (OOM) after some time.
      Fix merge error in mysql_system_tables_fix.sql
      Remove MCP tags for BUG16226274
      BUG#20811125 INNODB FTS: FTS_PRINT_DOC_ID PRINTS TOO MANY DEBUG INFORMATION
      Bug#20762059 - innodb_thread_concurrency=1 and queries using intrinsic temp tables, causes hang
      Create an .inc file which does slow shutdown before restarting innodb in read-only mode.
      Bug#19811953 ENVELOPE() FUNCTION RETURNS INVALID POLYGON Bug#20196720 ENVELOPE(P) RETURNS NULL FOR A NON NULL POLYGON P
      Bug #20544581         ASSERTION: REC_PAGE_NO > (ULINT) 4 - (REC_SPACE_ID != 0)
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 - Fix a merge issue.
      WL#7696 - Fix a merge issue
      WL#7696 - Fix the column ordinatlity. Messed up in a previous merge.
      WL#7696 - Fix a compilation error
      move some compression tests elsewhere until using Win32::API module is approved. Improve error detection, if there is no module, the tests will succeed, not fail as before, but the testing power will be somewhat limited.
      Bumped rpm version for oel due to respin
      Bug#20756770 MYSQL SERVER DOESN'T COMPILE AGAINST OPENSSL 1.0.1M
      Patch for Bug#17162055: SSL.CMAKE SILENTLY CHOOSES BUNDLED YASSL INSTEAD OF ERRORING FOR OLD OPENSSL VER
      Bug#20755346 EXAMPLE SCRIPT IN FIREWALL MISSES WHERE CLAUSE
      Bug#20764521 REGRESSION: FIREWALL USE GENERAL_HOST TO RESOLVE HOST
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      Resurrect unintentionally remove disabled.def file
      Resurrect unintentionally remove disabled.def file
      Bug#20651661 NDBEVENTBUFFER LEAKS GCI_OP
      Remove three files which did not properly remain
      WL#7696 - Make LZ4 decompress safe during recovery
      Remove hack to allow large number of failing tests in mtr.pl
      WL#7696 - Reset the contents of the page to NUL.
      WL#7696 - Use the double write buffer pages for compressed pages.
      WL#7696 - Fix syntax error on Windows.
      WL#7696 - Fix debug assertion.
      mysql-test/include/innodb-compress-utils.inc:   add OSD support to get allocated file size for Windows
      add the result file missing in the previous commit
      Test update:   mysql-test/suite/innodb/t/table_compress.test:     fix one failing case for 32k   mysql-test/suite/innodb/r/table_compress_2.result: make use of new     include files   mysql-test/suite/innodb/t/table_compress_3.test: new test to cover     what was not covered yet, shared tablespaces in particular   mysql-test/include/innodb-compress-verify.inc: common sequence     for compression verification   mysql-test/include/innodb-compress-utils.inc: perl compression     related utilities.     Note: OSD Windows file allocated size is not implemented yet.     The test is still expected to pass on Windows because the allocated     size is forced to the expected value.
      Bug #20536590: BACKPORT BUG #12368204 AND BUG #16953758 TO MYSQL-5.6
      WL#7696 - Code clean up. Ignore table COMPRESSION setting if set to NONE.
      WL#7696 - Minor code cleanup
      WL#7696 - Fix the punch hole size calculation.
      Bug#20712432 AUTOTEST: TESTFK FAIL IN CLEARTABLE WITH 256 REFERENCED ROW EXISTS
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#17775772 POTENTIALLY UNINITIALIZED BUFFER IN NDBOUT::PRINT* PRINTOUT   - print nothing or just empty newline instead of uninitialized buffer   - catch error with an assert in debug compile
      Bug#17775607 POTENTIALLY UNINITIALIZED BUFFER IN VNDBOUT_C PRINTOUT  - print empty newline instead of uninitialized buffer  - catch error with an assert in debug compile  - Mark vndbout_c as static and thus local to implementation Conflicts in copyright:        storage/ndb/include/util/NdbOut.hpp     storage/ndb/src/common/util/NdbOut.cpp
      Remove unused parameter ndbcluster_drop_event()
      Bug#20032381 KILLED_STATE SAVE IN NDBCLUSTER_BINLOG RETRY AT SHUTDOWN DOESN'T NEED TO BE VOLA
      Bug#20014045 MONOTONIC SPELT INCORRECTLY IN NDB CODE
      Bug#20092754:  MYSQLD CRASH (FOUND UNCOMITTED AUTOCOMMIT+RBWR TRANSACTION, COMMIT STATUS 3)
      mysql-test/suite/innodb/t/table_compress_2.test:
      Raise version number after cloning 7.4.5
      Correct MTR command for 64k run. Adiing missing "k".
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      Tetss that use innodb_compress_debug should run against debug server
      Added runs with differnt combination and page size setting for Innodb suites
      mysql-test/suite/innodb/t/table_compress.test:   Fix failure when hole punching is not available.   Now the test will be skipped instead
      Revert accidental bump of server version back to 5.6.23
      Fix a compilation warning in non-debug mode
      BUG#18949230: Removed unneeded ndbassert and fixed printout, also recorded number of real periods
      Added some extra output to ndbapi tests utilities as an aid to hunt down the AutoTest failure 'testBasic -n Bug54986 D2'
      Added log printout about invalidation of REDO log and where log head was found
      WL#6815 Adapt MySQL Cluster to 5.7
      Added autotest files for Mikaels environment, added comments about how to get file system as part of results in autotest, added comment about how to handle older git versions with autotest
      BUG#20546157: Fix problems in START_PERMREQ and START_INFOREQ that hangs node restarts when invalidation of nodes is still ongoing at node restart
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20480035 REMOVE MCP_BUG44529
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disable ndb_rpl_circular_2ch* waiting for Bug20592110
      Disable ndb_addnode_witbinlog waiting for Bug17400320
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75720: Fix platform issues with ndb_dd_dump test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      WL#7696 - Don't print a warning on Windows if SPARSE FILE attribute can't be set
      BUG#20631645: Ensure that SYSFILE->latestLCP_ID is properly up-to-date in the pause LCP protocol
      Fix regression caused by wl#7674 in testBasic -n RefreshTuple T6 D1
      Fix regression caused by wl#7674 in testDict -n Bug13416603 I2.
      Fix for Bug#20408733:
      WL#7696 - Punch hole message is Linux specific.
      WL#7696 - Backport code from mysql-trunk to mysql-5.7
      Followup fix for "Bug20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK"
      WL#6815 Adapt MySQL Cluster to 5.7
      Another follow up fix for "BUG11748566 - MYSQL SHOWS WRONG DEFAULT VALUE FOR PK IF  NOT NULL NOT SPECIFIED"
      BUG#20568586: Fix ndb_cpcd to avoid reading a closed file
      BUG#20567730: Ensure that late arriving LCP_FRAG_ORD with lastFragmentFlag set from new master are handled correctly, correct is to ignore them if such a signal arrives in idle LCP state
      Fix for bug#20538179
      BUG#20546899: Faulty ndbrequire fixed
      BUG#20553247: Fix memcpy overlapping copy issue
      BUG#20553247: Use memmove for overlapping memory copy
      Commit this fix on behalf of Pekka N:
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      BUG#19811871 VERSION NUMBR NOT SHOWN IN LOG WHEN [RE]STARTING 5.6.21 SERVICE WITH SLES11 REPO
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      Updated copyright information
      Bug#20228839: MISSING DATABASE '-D' OPTIONS FOR FEW OF THE HUGO TOOLS
      Re-enable clusterj tests disabled during 7.4.4 release.
      Bug#20593065 MULTI UPDATE RETURNS DIFFERENT DATA WITH ENGINE NDB
      This commit is a followup to the fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_time calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop timeout to be configured).
      Add support for SLES12
      Merge 7.3->7.4
      Merge 7.2->7.3
      Overriding release() function from the DynamicObject class in its subclasses.
      This commit is a fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_time calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop timeout to be configured).
      Reverse order of libraries used when linking the ndbapi examples
      Add small MCP for problem with Partition_handler::get_default_num_partitions
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM: fix test regression
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7549: Fix test case for removed EMPTY_LCP protocol
      BUG#20444078: Removed unneeded log printout
      BUG#20444078: Fix master takeover of COPY_GCIREQ protocol
      WL#6815 Adapt MySQL Cluster to 5.7
      Revert accidental version number change
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20528878 : P_S UNIT TEST IS FAILING
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM
      Temporarily hack mtr.pl to allow a large number of failing tests
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disabling ndb.clusterj and ndb.clusterj_jpa tests for 7.4.4 release.
      WL#6815 Adapt MySQL Cluster to 5.7
      bump version to 7.4.5
      Bump version to 7.4.5
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20281479: Entered eternal loop when starting node in MGM server due to buggy bug fix
      Fix unintentional increase in testsize by a factor of 100 of 'testBasic -n Bug54986'
      BUG#20513571: Introduce MaxSendDelay for large clusters
      Fix failing AutoTest 'testIndex -n NFNR3*'
      BUG#20512063: Moved verbose logging to only be used in verbose mode
      Add missing failure detection for 'testBasic -n Bug54986'.
      BUG#20281479: Ensure that START_ORD is properly sent from management server
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20504971: Fixed restart_info table to provide its output
      WL#6815 Adapt MySQL Cluster to 5.7
      Proper error printouts after reaching NDBT_FAILED in test cases
      Backport fix for BUG#20276462
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Updated to newest version of flexAsynch
      Patch related to bug#18401543
      BUG20308276: Don't use same list for master and participant part of takeover processing
      Fix issue in AutoTest where test are being killed by WatchDog during memory allog in startphase 0.
      BUG20276462: Fixed spelling error in error code
      BUG#20276462: Error code ZNODE_FAILURE_ERROR has no treatment in NDB API, use NODE_SHUTDOWN_ERROR instead
      WL#8148 NDB: Add git support to Autotest
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT
      Bug#20234994 JOINS ARE NOT PUSHED AFTER WL6042
      Revert "Adapt pushed joins to WL#6042"
      Fix for Bug#19053226 AUTOTEST FAIL: TESTSRBANK -N MIX -L 300 -R 15 T1
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) PART III
      Bug#20410087 GCOV COVERAGE DATA FOR NDB KERNEL IS MISSING
      WL#8294 NDB: turn on signal checksum as default
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Disabling mtr tests on 7.1 which fail because SSL certificates have expired.
      Re-recording mtr test result after ssl certificate update
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT Generated new certificates with validity upto 2029.
      Fix test client failure for AutoTest 'testNodeRestart -n ClusterSplitLatency'
      Bug#19785977:  CRASH IN NDBINDEXSCANOPERATION::SCANINDEXIMPL
      Bug#20423898 BAD TEST TESTNODERESTART -N LCPTAKEOVER CAN NOT FAIL.
      Improve ndb_rpl_circular_2ch_rep_status reliability.
      Test was random failing due to matching random binlog junk. Make false matches less likely.
      A little brute force to understand the issues with ndb_rpl_circular_2ch_rep_status
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      Experimental experiment with experimental status.
      A more standard variant of !valgrind.
      BUG#19667566 : PARTITION BY WITH COMMENT LEADS TO MYSQL SERVER REBOOT IN MYSQL CLUSTER
      Sacrifice Valgrind run to improve ndb_rpl_slave_binlog_index reliability.
      Backport of fix for bug#16209645
      Bug#17579998 TEST 'TESTNODERESTART -N GCP -L 1 T1' FAILS DUE TO MYSQLD ABORTED
      ndb_rpl_slave_binlog_index.test
      ndb_types.test contained binary raw data from 'bit' and 'binary' columns.
      Bug #20372169         NDB : INCORRECT STATUS VARIABLES NDB_LAST_COMMIT_EPOCH_[SERVER|SESSION]
      Fix of uncorrect merge (7.2 -> 7.3) of regression fix for bug#19524096
      Fix regression introduced by fix for bug#19524096.
      Fix regression introduced by fix for bug#19524096.
      Fix regression introduced by fix for bug#bug#19524096.
      Improve ndb_rpl_slave_binlog_index.test behaviour under Valgrind.
      Bug#20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK INTEGRATION
      Add some improved debugging to help understand non locally reproducable problems with ndb_binlog_last_commit_epoch testcase.
      This commit is a fix for Bug#19880969 (CLUB FOR 7.1, LINUX-RELEASE, 345 WARNINGS IN BUILD). The fix suppresses these warnings, so that the corresponding square in club becomes green rather than red.
      Bug #19306793         CORE IN NDBAPI WHEN EXTENDED EXTENSION TABLE IS CREATED IN MYSQL 7.4
      Quick fix of corrupted special comment characters. No code change.
      Updated the copyright year in README and welcome message
      Improve garbage collection of clusterj artifacts
      Updating copyright year
      Some copyright fixes to files changed in 2014
      Fixing user visible copyright years
      Fix for 7.4.3 build failures
      Fix for copy right year
      Corrected copyright year by sreedhar
      Updated README and banners to 2015
      bump version to 7.1.35
      pgmanpe pe-dump.diff pgman: dump max page entries bug#18484117 bug#19915761 bug#19958804
      pgmanpe pe-config.diff pgman: configure max page entries bug#18484117 bug#19915761 bug#19958804
      BUG#19480197, BUG#73667, BUG#74945: Ensure Local object has transferred back object to real object before calling recursive function
      Cherrypick fix which removes MCP_WL1735 from 7.4
      Cherrypick fix for bug20009152 from 7.4
      Adapt pushed joins to WL#6042
      Follow up fix for bug#20112981
      Fix for bug#20112981
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - rewrite clean_away_stray_files() to use find_files() direct rather than going via make_db_list(). - The only difference between make_db_list() and find_files() is that the information_schema database is not   return in the list of databases. But it's currently not possible  to create a NDB table in information_schema   and thus there can not be any "stray" tables there either.  - testcase added to ndb_reconnect which shows access denied when trying to create table    in information_schema  - This avoids patching the MySQL Server to make the static make_db_list() function available    to use in ha_ndbcluster_binlog and thus the MCP for make_db_list() and LOOKUP_FIELD_VALUES   can be removed. - Also remove the NDB_WITHOUT_MAKE_DB_LIST which was used for compiling ndbcluster in MySQL Server
      Remove unused TNTO_NO_REMOVE_STRAY_FILES Thd_ndb option
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#19898269, BUG#74594: Fixed wrong order of sending bitmap of LCP participants to ensure that starting node can correctly calculate the lcpOngoing flag for each fragment
      Another addendum patch for bug#20112981, adressing comment from Mikael R.
      Incremental addendum patch for bug#20112981
      Fix for bug#20112981
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#75220: Added option to use 10 and 20 LDM threads (same for NoOfLogParts)
      BUG#20215395: Bug in cluster join protocol
      Added jams to place where data nodes freezes in startup
      BUG#19590336: Preparatory patch adding lots of jam:s to DD code, also a few more more comments added
      Additions to wl#7674
      Bug#18715165, BUG#17069285
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug#20193236 SOME COMPILER WARNINGS BECAME ERRORS AFTER MERGE OF MYSQL SERVER 5.5.41
      Cherrypick from 5.6 : Bug#20009154 - FIX REGRESSION AFTER HA_FLUSH_LOGS() HOOK FOR NDB IS REMOVED.
      Bug 19895502 -  BINARY LOG GROUP COMMIT CAUSES REGRESSION FOR NDB REPLICATION.
      This commit is a followup to WL#8145 (NdbInfo : Per-fragment operations info). That WL introduced an error causing 'testScan -n Bug54945 T1' to fail: short-signal scans crashes because the attrinfo section is not available at the point where the code tries to read it to find the size of the interpreted progam. This commit fixes that by not trying to count program size for short-signal scans and lookups. Since these only happen during online upgrade, they are not important for per-fragment statistics.
      Bug #19992856 MYSQL CLUSTER TRIGGER ON DELETE FALSE POSITIVE
      This commit is a followup to the fix for bug#19976428 ("reports failing with 'out of longmessagebuffer' error"). This commit updates a regression test (testIndex/FireTrigOverload) so that it will expect the right error code (293 "Inconsistent trigger state in TC block" instead of 218 "Out of LongMessageBuffer").
      autotest auto1.diff testBasic -n Bug16834333 : fix dict cache crash
      Bug #19858151         MAKING DATA NODE SELF-EXCLUDE MECHANISM MORE ROBUST
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Updated fix for bug#20113145:
      Follow up to fix for bug#bug#20166585:
      Follow up to fix for bug#bug#20166585:
      This commit fixes bug #19976428 ("reports failing with 'out of longmessagebuffer' error"), and a set of other issues related to the pool of "Fired Trigger" records.
      Bug#17069285 : SEGMENTATION FAULT IN NDB_PRINT_FILE
      Update to recent fix where we failed to close scan cursors at the end of their lifetime.
      WL#7514: Fitted into infoEvent max size and decreased some too wordy log printouts
      Update 'v3' fix for bug#20166585:
      WL#7514: Fixed an incorrect assert
      Fix for various AutoTest 'testIndex ...' crashing due to excessive memory usage.
      Bug#18715165, BUG#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for: - Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT - BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      The AutoTest testcase 'testScan -n Bug54945 T1' crashed as it failed to create a transaction object which was later referred without first checking that it was created.
      Fix for crashing AutoTest: 'testNdbApi -n RecordSpecificationBackwardCompatibility'
      WL#6815  Adapt MySQL Cluster to 5.7
      Fix flexAsynch also in 7.3, backport from 7.4
      WL#7508: Parallelize synchronization of starting nodes with live nodes
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - Test fails since the two new default sql_modes  ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES   are displayed by "show create procedure"  - Update .result file to include the two new default sql_modes(as has been done in similar   places)
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      Experimental fix for several AutoTest which crash with an unreadable stack dump very early in their lifecycle, like:
      Fixed crashing AutoTest testBitfield.
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Cherrypick fix for ndb_memcache out of source from 7.4
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20135403 NDB_MEMCACHE TEST DOES NOT WORK IN OUT OF SOURCE BUILD
      Fixed crashing AutoTest: './testLimits -n ExhaustSegmentedSectionPk WIDE_2COL'
      Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT
      BUG#74594: Fixed a hang in PAUSE LCP protocol when LCP was completed between PAUSE and UNPAUSE
      Removed lots of jam noise from QMGR preventing one from seeing the bugs
      WL#6815  Adapt MySQL Cluster to 5.7
      Revert some junk lines from pfs_upfgrade*.result files
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherry-picked from mysql-5.6.22-release
      Cherry-pick from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-pick from mysql-5.5.41-release
      Added tag mysql-5.6.22
      Added tag mysql-5.5.41
      BUG#74594: Fix missing state update that causes PAUSE LCP protocol to hang
      BUG#74594: Added some more DUMP printouts for PAUSE LCP protocol
      WL#7650: Make atrt work on Mac OS X
      Removed assert / require from NDBT_ResultRow c'tor and rewrote it such that it could be constructed even if the the object is not in 'Retrieved' state.
      BUG#75007: Ensure we wait until master takeover is completed before handle LCP_COMPLETE_REP from LQH and DIH participants in the LCP protocol
      Bug#20029843 7.4.2 REGRESSION: UPGRADE_TRAFFIC FAILURES FOR 7.4 -> 7.3: Fixed incorrect conditional expressions
      Cherrypick fix for ndb_dist_priv.sql from 7.4
      WL#6815  Adapt MySQL Cluster to 5.7
      Cherrypick fix for mysql_system_tables_fix.sql from 7.4
      WL#6815 Adapt MySQL Cluster to 5.7
      Encourage MySQL to treat numeric variables as numbers so that ndb_rpl_conflict_epoch2_extra does not return incorrect results from inequality tests.
      BUG#75007: More work on ensuring that we drop the right signals of the LCP_COMPLETE_REP and LCP_FRAG_REP, a bit tricky to decide, wrote up an analysis in a comment and a fairly simple code based on this analysis
      Cherrypick fixes for ndb_alter_table_online from 7.4
      Remove usage of DEFAULT 0 for TIMESTAMP
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fixed for ndb_update_no_read from 7.4
      Turn "info" off after each section in test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fix for ndb_dd_disk2memory from 7.4
      Add missing enable_query_log comman in ndb_dd_disk2memory.test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75007: Fixed interaction with early master takeover initialisation and handling of failed node in LCP, code in new master
      BUG#75007: Handle side effect of bug fix, there are signals generated by node failure handling that must be allowed to pass through the code as they are required for node fail handling to be done properly
      Apply patch for MCP_BUG19704825to 5.7.5
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#74594: Fix of variable length in message to management server to avoid printing garbage
      BUG#75007: Ensure that we drop LCP_FRAG_REP and LCP_COMPLETE_REP that originates from a dead node. The LCP could potentially be done before this arrives due to node failure handling, these signals are sometimes delayed and thus we need to take care that we can still receive them.
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Assumption that all alive nodes have participated in LCP at close down time caused havoc since we can now be alive and still not have participated in the LCP. So had to move the send of the last LCP_COMPLETE_REP backwards a bit to be able to reuse the m_participatingDIH bitmap to send to.
      remove last NDB_WITHOUT_COLUMN_FORMAT ifdef  - since all versions of MySQL Server which ndbcluster   compiles against now supports "field->column_format" and "field->storage_type" - one NDB_WITHOUT_COLUMN_FORMAT left behind(or reappeared)
      BUG#19795152: Missed essential ptrCheckGuard in upgrade/downgrade situations
      WL#7514: More printouts to log for system restart case
      BUG#18610698: New test case
      BUG19795152: Fix Software upgrade issue
      Add missing delete of Ndb instance created by testcase
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Minor tweak of jamming and of a loop
      BUG#19795217: Checked the LCP state a bit too early
      BUG#74594: Added one more cluster log event
      BUG#74594: Wrong check if LCP is idle when sending UnPause message
      bug#20045455 Improve error reporting for clusterj
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Fixed a compiler warning in new tool
      BUG#74594: Wrote an analysis tool for reading DIH Fraglist files to enable easier analysis of system restart bugs
      BUG#74594: Queued LCP_COMPLETE_REP comes from LQH, not from DIH
      BUG#74594: Fixed a typo bug in an important condition
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Added a new ndbrequire to find problem
      WL#7514: Added a bit more logging of the actual start order signal
      flexBench created its worker threads, flexBenchThread, with a stack of insufficent size. This later caused the threads to crash.
      WL#7509: Add undocumented interface to change Disk Write Speed in LCPs, change isn't persistent over restarts, useful to handle SRs where restarts are too slow
      WL#7509: Tweaked the adaptive LCP speed parameters to be a bit slower in changing
      BUG#74594: Add DUMP_STATE_ORD variant to print pause state to cluster log
      BUG#19795108: Proper fix of node restart status using the new Node Recovery Status module
      BUG#19795152: Handle Partial System restarts
      BUG#74594: Used wrong variable in non-master to decide on pauseAction
      Attempt better "htonll" portability in NDB memcache code
      Fix for bug#19390895
      BUG#74594: Ensure that we drop PAUSE_LCP_REQ signals from master if it concerns a node that already has died
      BUG#74594: Node failure in inopportune time caused crash
      BUG#74594: Decrease amount of useless jam:ing to make bugs more visible
      Bug#19642978: NDB_RESTORE CORES ON BUILT-IN PRIMARY KEY + STAGING BLOB CONVERSIONS ON SPARC
      Fix for bug#20031313  AUTOTEST CASE 'TESTDICT -N GETTABINFOREF' NEVER WORKED FOR >= 4 DATA NODES
      BUG#74594: Turned ndbrequire condition the wrong way, caused obvious crash, added a few more ndbrequires while at it
      BUG#19795152: Also NODE_FAILURE_COMPLETED and ALLOCATED_NODE_ID can be states from where a node fails from DISCONNECT_REP although the node hasn't really started its start yet.
      BUG#74594: Removed buggy ndbrequire, not correct though to possibility of delaying arrival of LCP_FRAG_REP when copying table to disk
      BUG#19795152: NdbTick_Elapsed parameters in wrong order
      BUG#19795152: Added one more acceptable state transition, ALLOCATED_NODE_ID -> ALLOCATED_NODE_ID
      BUG#74594: Missed setting lcp id in COPY_TABREQ, added ints of LCP variables on replica and fragment records, removed init of lcpStatus in INCL_NODEREQ which depended on old fact that we included when LCP was idle, now this is no longer necessary, missed init of m_lcp_start_time in including node in LCP, added a number of log prints
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#19676350 NDB_RPL_CONFLICT_EPOCH SHOWS SCHEMA DIST TIME FAST FORWARD DUE TO EINVAL
      BUG#74594: missed init of c_queued_lcp_complete_rep
      BUG#74594: Handle fromTimeQueue issues with LCP_FRAG_REP
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed stopping of pause properly in master and in non-master
      BUG#74594: Wrong assumption in START_LCP_REQ removed, fix of ndbrequire of COPY_TABREQ counter improved
      BUG#74594: Added new parameters to allocStoredReplica
      BUG#74594: Missed init of fragId and tableId in replica record, wrong assumption about m_participatingDIH in START_LCP_REQ
      BUG#74594: Missed clear of own node in NodeReceiverGroup in sending FLUSH_LCP_REP_REQ
      BUG#74594: Fixed typo
      BUG#74594: Missing inserts into signal table
      BUG#74594: Fixes for wrong assert, missing state update and wrong condition
      BUG#74594, fix for sanity check
      BUG#19795152: Fix a placement new that overwrote the node recovery timers in debug mode, added a bit more debug code and arranged the parameters in some common functions a bit more logically
      BUG#74594: Added missing file CopyTab.hpp
      BUG#74594: Remove need for long wait for LCP to copy meta data to make restart times more predictable and faster
      BUG#74639: Preparatory patch to handle overload bugs that is likely to be caused by higher pressure on LCPs and restarts
      BUG#19795152: Added missing file: NodeRecoveryStatusRep.hpp
      BUG#19795152: Wait for LCP start at node restart, add node recovery status table as well
      BUG#19795217: Remove EMPTY_LCP protocol from master takeover
      BUG#74594: Part 2: Fix a potential LCP stoppage
      BUG#74594: Part 1: Remove a faulty ndbrequire
      BUG#19795029: Improve logging of restarts developed in WL#7514
      BUG#19795108: Fix of node restart status for adapting speed of LCP disk write speed
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug#20007248 NDB NOT FUNCTIONAL ON POWER
      Bug#20007216 FLEXASYNC USES 32BIT MATH, LEADING TO INCORRECT SUMMARY ON POWER8
      Fix regression in AutoTest -n DropWithTakeover T1 introduced by fix for bug#19874809:
      Add missing newline before end of file in AsyncNdbContext.cpp
      Fix build failure in MCP patch for BUG19553099
      bug#20017292 Clusterj logging levels too verbose
      Bug#20009152 FIELD NAME NOT INCLUDED IN WARNING WHEN CONVERTING TO FIXED
      WL#7640  Ndb Active Active Delete-Delete handling
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Fix Club test regressions after backport of bug#19524096:
      WL#7640  Ndb Active Active Delete-Delete handling
      Provide easy way to store documents with no mapping and no schema defined   define new method on session factory: db(database_name) returns db object   db object has properties corresponding to table names     if table does not exist, create the table       if user has not mapped the table, create default table mapping and table       if user has mapped the table, use table mapping to create the table   Operations on session using non-existing table name     will now create the table if it does not exist and user has mapped the table
      Fix bad #ifdef
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Bug #19817817 TFBUFFER::VALIDATE() CONST: ASSERTION `(P->M_BYTES & 3) == 0\' FAILED
      Backport of fix for bug#19524096
      Bug#19999242 DELETEING NDB_CLUSTER_CONNECTION WITH NDB INSTANCES
      bug#19913569
      Avoid segv when closing session factory with sessions still active
      Bug #17592990: DATA MISMATCH BETWEEN C NDB API AND MYSQL CLI.
      Backport of fix for Bug#19724313
      Fix for bug#19880747:
      Fix for bug#19875663
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Fix for bug#19881025:
      This commit is an update of WL#7375 (Ndbinfo: Per-fragment memory usage reporting). Column fixed_elem_free_rows in view ndbinfo.memory_per_fragment is renamed to fixed_elem_free_count to get a more consisten naming.
      Fix for bug#19874809 :
      Added sles11 repo packages
      This commit implements WL#8145 (NdbInfo : Per-fragment operations info).
      Follow up fix for bug#18352514 fixing a build failure.
      Addendum fix for bug#18352514:
      bump version to 7.4.3
      Bug #19875710         NDB : COMMIT ACK MARKERS LEAK @ LQH IN 7.4
      BUG#19815044: Part 4, remove usage of global block variable m_pgman_ptr, it is used for parameter passing, but can in some weird situation in DBTUP it can be reassigned to a value that can cause an inconsistent database.
      BUG#19815044: Part 3, fix such that an aborted insert after a committed delete doesn't lead to that triggers for delete isn't executed by ensuring that delete_insert_flag is properly maintained
      BUG#19815044: Part 1: Improve jamming support to make it easier to read what's going on bug situations
      BUG#19815044: Add test case for it used in autotest
      BUG#19815041: Crash on abort of delete after successful delete on a disk data table
      Add global.fail_connect to test utilities
      Fix ProjectionErrorTest
      Improve error reporting for multidb tests
      big lint-fixing patch
      Fix unified_debug issue with per-file levels for C++ files Remove workaround for this in executable programs
      Converter use in DBTableHandler (fixes freeform tests for ndb)
      Big deglobalization patch. Removes many global variables (but not all).
      Move SQL.create and SQL.drop from test harness into adapters. NDB depends on MySQL for this.
      Enhance closeAllOpenSessionFactories() so it takes a callback & returns a promise
      Fix for bug#19712569
      When using node --harmony and strict mode, DBIndexHandler cannot be forward declared   and still use the function DBIndexHandler(parent, dbIndex) syntax.
      jscrund: add support for B tests with varying size varchar. (Only supported by jscrund_mysqljs crund backend).
      lint globals cleanup
      Fixes restart race causing test timeout in AutoTest 'testDict -n schemaTrans'
      Return an error if writing non-Buffer data to binary columns
      Allow flexible mapping for node.js domain classes
      Fix for bug#18352514
      Fix for bug#19661543
      Remove warning introduced with patch for BUG#19236945
      Bug #19236945 ADDRESSSANITIZER BUG SHOW UP IN NDBRECATTR::RECEIVE_DATA CALLED FROM RESTORE.CPP
      bug#19793475 - NO WAIT FOR EPOCHS THAT HAVE NO DB CHANGES MADE BY THIS NDB THD TO BE IN BINLOG
      Removing the extra blank line from daily-basic-autotest-conf
      Fixed compilation error due to changed file name
      Bug#19267720:  NDB REPLICATION : DO NOT SETUP CONFLICT RESOLUTION FOR EXCEPTIONS TABLES
      formatting
      Docs work
      BUG#19795072: Fix problems related to ndbinfo tables for disk write speed
      BUG#19643174: Fix races in relation to sending TC_COMMIT_ACK and handling of complete of a transaction
      Removed compiler warnings
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000): GOT ERROR 4547 PART II
      Cherrypick from 7.4 (revno 4354): Implement status variables exposing last commit epochs for the server   and each session.
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      BUG#19724313: Handle multiple threads crashing at the same time properly
      Added missing include for previous patch Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Restore computeChecksum to computeXorChecksum that was reverted in patch for Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Merge of Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Refactoring of Packer::unpack in preparation of merging Bug#19582925
      Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      wl#7674-5 fixing errors
      wl#7674-5 fixing errors and compiler warnings
      wl#7674 Backward compatibility/new event api methods
      wl#7675 Introduce state machine for event buffering
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) : GOT ERROR 4547 : 'RecordSpecification has overlapping offsets'
      Applying the patch for regression bug#19582807 for 7.1.33 cluster release
      Improve Query documentation
      Cherrypicked
      Cherrypicked
      Bug #19582807 MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Wl#7639 Ndb Active Active Manageability improvements
      Removed compiler warnings
      WL#7642 Ndb Active Active Binlog Read Tracking: Removed uninitialized data to remove valgrind warnings
      Work on new README
      Bug #17257842     EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #19766167         NDB : VALGRIND REACHABLE MEMORY IN NDB_RPL_CONFLICT_EPOCH_TRANS
      Fix new log printouts - Use log functions of component in favour of sql_print_information - Break long lines
      In-Progress Packaging / Documentation improvements
      Iterate array rather than for/in
      Add mynode.closeAllOpenSessionFactories()
      Windows testcase fix attempt
      Follow up patch for WL#7953 Transporter handshake retry
      WL#7642 Ndb Active Active Binlog Read Tracking: Updated result for ndb_rpl_conflict_read_tracking test case to reflect new conflict counters
      WL#7640  Ndb Active Active Delete-Delete handling
      bump version to 7.3.8
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      bump version to 7.2.19
      bump version to 7.1.34
      Bug#19692387 PORT FIX FOR BUG 18770469 TO MYSQL CLUSTER 7.3
      Added ndb_print_file man pages
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug#18487960: SIG 11 on delete with index merge
      Follow up patch for WL#7953 Transporter handshake retry
      Follow up patch for WL#7953 Transporter handshake retry
      Patch 2 for WL#7953 Transporter handshake retry
      Patch 1 for WL#7953 Transporter handshake retry
      Patch 3 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 2 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 1 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      adding checksum to the cnf file
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19600834  late code review comment
      Bug #19600834 DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH)
      Bug #19600834         DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH) ...
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3
      Bug #19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3  - revert the reverted
      Bug#19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Change from mysql-5.6 to build Oracle Linux 7 RPMs
      WL#7640  Ndb Active Active Delete-Delete handling
      WL7640 Add delete-delete conflict count
      Adding ndb_print_file to spec file
      Repush of WL#7544 after 7.4.1 clone tag.
      bump version to 7.4.2
      Set version 7.4.1
      Revert WL#7544, not to be included in DMR 7.4.1
      Reorder member initializer list for thr_data to follow initialization order. This removes compiler warning introduced in fix of Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      WL#7544: Optimisations of the NDB API receiver thread in various manners. 1) Optimising method to unpack field data from TRANSID_AI signal, 2) [1;31moptim[mised handling of trp_client locking check, 3) reorganised code in NDB API receiver thread for better performance and more readability, 4) Optimisation signal receive handler
      BUG#19451060: One more step on the way to understanding commit ack markers
      Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Fix for bug#19559313, call getPerformStateString() with a nodeId arg instead of a state argument
      Fix for Bug#19552283 :
      Update documentation to remove useProjection       Update Session.js to remove useProjection
      BUG#19552349: Avoid stack overrun by removing endless recursive call
      BUG#19451060: Further refinements of bug fix, previous ndbrequire revealed a race that could cause multiple REMOVE_MARKER_ORDs to appear for the same transaction, added long comment about this specific race variant. Left a part of the ndbrequire still to ensure that this only happens when receiving REMOVE_MARKER_ORD sent by API through TC_COMMIT_ACK and not through API failure handling
      Bug #18703922  DUMP-CODE ACTIVATED DEBUGGING ON WATCHDOG OVERLOAD ISSUES
      Bug #17730825  NDB API: POSSIBLE LEAK OF CONNECTION OBJECTS
      BUG#19524096: Converted many 4009 errors to temporary error 4035, ensured APIs can use new data nodes sooner, fixed some wrong error categories, removed no longer used errors, fixed some anomaly in communication towards the API, small improvement of restart printouts, should give autotest a much better chance to get rid of redness
      Bug #17893872         ER_DUP_ENTRY WHEN INSERTING TO AUTO-INC COLUMN ON SPARC MULTI-MASTER SETUP
      BUG#19451060: Added more descriptive information at crashes related to commit ack markers, changed name of noFired to numFired for clarity, added possibility to put last in free list to aid crash printouts
      Fix for spelling error in Win32 code
      WL#7509: Introduced more configurability of disk write speeds and added a number of new ndbinfo tables to track this new more adaptive behaviour
      WL7845: More and safer ways to print records in DBTC
      BUG#19451049: Missing call to prepareTUPKEYREQ from handle_lcp_keep, added comment about handle_lcp_keep
      bug#19124970 - PB WITH POLLEVENTS , NDBEVENTS
      Backport from 7.2
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      The Bug was due to m_out object used in NdbOut operator was not initialized/set to the output stream. Added an ndb_init() call to initialize it to output stream. Added an environmental variable $NDB_PRINT_FILE to give path to its binary in  mysql-test/mysql-test-run.pl file. Added a unit test and its result file.
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      bug#19031389 bugfix.diff bug fix
      bug#19031389 bugtest.diff bug test
      BUG#19513967: Fixed missing init of longer bitmask
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      BUG#17703874
      Bug#19202654: NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      Bug #18354165         16723708 CHANGED EVENT CATEGORY VALUES
      Clusterj windows CMakeList error
      Clusterj support for autoincrement columns http://wl.no.oracle.com/worklog/NDB-RawIdeaBin/index.pl?tid=8027
      Added missing logging.properties
      Clusterj improve maven handling for out-of-source builds
      Bug#18875137: NDB_RESTORE STILL MISSING SOME TYPE CONVERSIONS
      Fix for Bug#19414511:
      Bug #19236785  ADDRESSSANITIZER BUG IN ~NDB_MOVE_DATA Bug #73311      AddressSanitizer bug in ~Ndb_move_data
      Bug #19235428  ADDRESSSANITIZER BUG IN DATABUFFER2<SZ,POOL>::IMPORT (DBDICT::ALTERTABLE_PARSE) Bug #73310     AddressSanitizer bug in DataBuffer2<sz,Pool>::import (Dbdict::alterTable_parse)
      Bug #19235170  ADDRESSSANITIZER BUG IN DBUTIL::GET_SYSTAB_TABLEID Bug #73308  AddressSanitizer bug in DbUtil::get_systab_tableid
      Bug#11764704 : Exclude missing tables when restoring a backup  - added an option "--exclude-missing-tables" to ndb_restore tool  - when enabled, the missing tables will be added to the    exclude tables list before starting to restore.  - updated test cases accordingly.
      Revert fix merged in from 5.5.39 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert fix merged in from 5.6.20 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert quick fix for dtrace problems in release tree. New fix in CMake files will be merged in from 5.6.20.
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      This commit is a followup to the one below. It changes the fragment_num colum (in memory_per_fragment), such that it gives the global frgament id rather than a node-local sequence number. That way, it is possible to see where each fragment (or some replica of it) is located. This is consistent with the output from 'ndb_desc -pn -d <database> <table>.
      Bug 19028487 NPE when scanning rows with blob or text columns
      More fixes for bug#19053226
      Fixes for bug#19053226
      More fixes for bug#19053226
      bug#18410939 - MEMORY LEAK AT EVENT BUFFER ALLOCATING A DUMMY EVENT LIST WHEN INCONSISTENCY
      Bug #17184024         ERROR 4 IN LIBNDBCLIENT.SO.6.0.0 (3-7474573041)
      bug#19122346 fix3.diff FK use full name PP/CC/name + debug
      bug#19122346 fix2.diff fix test error from 7.3 r4203 FK_Bug18069680
      bug#19122346 fix1.diff FK use full name PP/CC/name
      ndb - RSS-DynArr256
      A new ndbapi test case: testNodeRestart -n DeleteRestart.
      Bug #18731008    NDB : AVOID MAPPING EMPTY PAGES DUE TO DELETES DURING NR Bug #18683398    MEMORY LEAK DURING ROLLING RESTART
      Bug #19193927         TC TAKEOVER TAKES TOO LONG CAUSING MANY PROBLEMS
      ndb
      Bug#19193756 MTR GENERATES TOO LONG SOCKET PATHS
      Merge from mysql-cluster-7.2.17-release
      ndb
      use primitive types
      Include stdlib.h for malloc() and free()
      Compiler issues on some Windows platforms
      Add debug to trace bug#18411034 - CRASH IN NDB-SHARE
      Updated the list of tables to be deleted after running ndb clusterj tests Added new test and the model to build specification
      Merge latest nodejs-adapter from 7.3 to 7.4
      Unconditionally disable dtrace for rpm, barfs on Oracle dtrace
      Remove superfluous -master.opt file for the removed test case ndb_mt_recv.
      Unconditionally disable dtrace for rpm-oel, barfs on Oracle dtrace
      correcting copyright headers
      Fix issues with Read/Modify/Update of NDB VO objects containing blobs.
      All NDB read results (including those containing BLOB and TEXT columns) are now ValueObjects.
      Fix bug of using Persistent<T>(x) rather than Persistent<T>::New(x)
      work on support for NdbRecord-backed ValueObjects which contain TEXT or BLOB columns.
      More TEXT tests for NDB
      less debugging output at end of test run
      Fix composition value checking
      Implement bufferForText and textFromBuffer in C++.
      rawNdbDefaultvalue does not require a full-fledged Node Buffer
      let compiler supply default destructors
      Another attempt to fix crashing bug in BlobHandler
      Expose the string encoder statistics in NdbTypeEncoder.cpp to JavaScript.
      Move v8 calls from worker thread to main JS thread
      Support TEXT columns with character set UTF-8 or ASCII. Other charsets (which require recoding) are not yet supported.
      A test file that does not export a test case now causes a warning rather than an error.  This should make it a little easier to develop new tests.
      Column Metadata API provides charsetName rather than charsetNumber
      Fix apparent bug in calculating size requirement of UTF-8 buffer
      Restore compatibility with node-mysql 2.0.0
      Fix crash on stub commit / stub rollback
      update cmake & gyp build lists
      Finish read & write BLOB implementation for NDB adapter
      Implement connection pooling for mysql adapter
      Fix tests that do not close session after running test
      Improve error reporting for connecting to database
      Add suggestion to user to maximize performance of updates
      Improve spi test error reporting
      Succesful insert into BLOB column
      Add BLOB column to stringtypes test suite & confirm that existing tests pass with a mapped (but unused) BLOB field.
      Test that storing a non-BLOB in a BINARY column gives error SQLState 22000
      Use Error SQLState 0F001 "Bad BLOB" (actually a "Locator Exception") if value intended for a BLOB column is not a Buffer.
      Initial implementation work on BLOB support for NDB adapter.
      Refactor connection handling to prepare for connection pooling
      WL#7626 Implement many-to-many relationships for Document Composition
      Don't try immediate startTransaction() unless using async api.
      Keep a single usedOperationSets array rather than one per DBSession. The array is at file scope in NdbTransactionHandler. It does not grow past 4000 elements (a literal constant). Underlying DBOperationSet native objects are freed when the wrapper is placed in the recycler array.
      Disable mysql tests for now
      Attempt to recycle DBOperationSet wrappers
      wrapPointerInObject and unwrapPointer take a v8::Handle<T> rather than a v8::Local<T>
      Improve error reporting for relationships that are null or undefined
      Test a slightly different approach to V8 wrapping
      Minor refactoring in NdbOperation
      Remove the use of "proto" in DBTableHandler
      Refactor DBTableHandler.getFields() into a simple case getFields() and a separate more complex getFieldsWithListener(). Removed the resolveDefaults option which was always set to false.
      Improve error reporting for ProjectionTest
      Improve error reporting for ProjectionTest
      Improve error reporting for test failures
      Compiler error
      Stub out NdbSession.buildReadProjectionOperation in hopes that test suite will run.
      WL#7626 Composition Implement support for one-one, one-many, and many-many relationships. Replace useProjection with implementation for find (projection, key).
      Rather than having a JavaScript wrapper for Record::setNotNull(), implicitly call setNotNull() when writing a data value in encoderWrite().
      Don't use a startTransaction() hint for unique key operations.
      In JsValueConverter for pointer types, if the JavaScript value is Null, represent it as a null pointer.
      Remove what little was left of NdbTransaction_wrapper.cpp
      move ENABLE_WRAPPER_TYPE_CHECKS define into adapter_global.h
      portability fix
      Update source file lists for gyp & CMake
      Add option free-percent
      New design for scans. This removes the previous wrapper for NdbScanOperation and ScanImpl.cpp file and consolidates all scan functions into ScanOperation. Expected: start 416 tests, pass 413, fail 2, skip 1.
      fix wrappers for boolean types
      In test driver allow --stats=query, e.g. --stats=spi/ndb/DBSession
      Add HandleScope to all toJS() template functions just to be safer from enigmatic V8 memory leaks. Provide toJS() and isWrappedPointer() specializations for type bool.
      Refactor NDB execute. This patch renames PendingOperationSet to DBOperationSet, and makes DBOperationSet the "point of contact" for JavaScript calls to begin and execute transactions. All t_basic tests now pass.
      New SPI test   begin transaction; delete (execute NoCommit) ; read deleted row ; commit.
      Minor bug fixes for passing SPI tests
      Major JavaScript logic changes in NDB adapter. NdbTransactionContext, NdbSession, NdbOperation, and NdbConnectionPool are adapted to use the call flow of DBSessionImpl and DBTransactionContext rather than the native call flow of the NDB API.
      This commit includes various small C++ fixes. The next commit includes major JavaScript logic changes. With these together, spi tests pass.
      Add new connection property ndb_sesion_concurrency Refactor initialization of NdbSession and connecting of the new NdbSession to its impl.
      Adapt DBDictionaryImpl to use DBSessionImpl rather than Ndb.
      Revise protocol for registering a transaction open / closed. Use only two calls, registerIntentToOpen() and registerTxClosed(). Always make these calls from JavaScript main thread.
      NdbTransaction is no longer wrapped for JavaScript
      Template class NativeCFunctionCall_4_
      DBSessionImpl
      Adapt AsyncNdbContext to be aware of DBTransactionContext
      executeAsync() on AsyncNdbContext is no longer wrapped for JavaScript; use executeAsync() on DBTransactionContext instead.
      Refactor DBOperationHelper:  it now takes a DBTransactionContext rather than an NdbTransaction.  it now defines operations, but does not prepare them.
      Rename addOperation() to getNextOperation()
      Add two new classes, DBTransactionContext and DBSessionImpl. These will free the JavaScript code from the start/prepare/execute cycle of Ndb and NdbTransaction, eventually allowing operations to be performed with fewer scheduled async calls and therefore less overhead.
      Adapt DBOperationHelper to the KeyOperation / ScanOperation change.
      Bug fix where the do_close flag must be associated with the transaction rather than its parent Ndb object.
      Refactor Operation and DBScanHelper into two classes called KeyOperation and ScanOperation.
      This change alllows Ndb::startTransaction() to run as a sync call in the main JS thread if we suspect that it will not block.  As a proof of concept, this allows you to measure the performance with this change; but it should not be used as-is, because the guess could be wrong, which would cause the main thread to block waiting for network I/O.
      In the common case where an async method call returns int zero, try to [1;31moptim[mize away creating a new JavaScript value.
      Slight change to the compatibility strategy for some libuv changes.
      Combine NdbTransaction execute() and close() into a single scheduled call whenever execType is Commit or Rollback.  This saves the scheduling cost of running the close() call by itself.
      Various fixes for lint.
      Remove old stats API.
      Use new stats API in MySQL code.
      Use new stats API in NDB code.
      Revised statistics API. Now each module owns, at file scope, its own stats object. The module registers the stats object with the global statistics, which keeps a reference to it in the stats tree. This should reduce the cost of keeping statistics to practically zero.
      Delay after (rather than before) the first test iteration. This allows V8 to compile all the JavaScript code before dtrace starts running. High dtrace profiling rates caused the first iteration to run very slowly and skewed the profile towards compile times rather than run times.
      Optional delays both before & after jscrund run
      jscrund: add option to delay start of test run
      Add useProjection to Session   this function specifies a projection to be used for find and query operations
      Minor work on DBDictionaryImpl Contain the code for handling NdbDictionary 3-part/slashed/names in DictionaryNameSplitter class. Reformat patch indent width from 4 spaces to 2 spaces. buildDBForeignKey() takes only the fk* and must use its own private name splitter.
      Error 23000 when attempting to set a non-nullable column to null.
      Restore table which should not have been removed from test suite
      Add support for foreign key metadata
      update literal mapping test for schema
      Fix errors in test case & misc. lint errors.
      Check in test case where one operation in a batch has a data type error. This test fails for both NDB and MySQL.
      Expose NdbRecordObject::prepare() to JavaScript. This is a step towards fixing handling of encoder errors for value objects.
      Write a negative value to an unsigned int field of an NDB Value Object. This test causes the test suite to hang forever.
      Run executeAsynch() in JS main thread rather than a UV worker thread. We had seen higher latency using async ndbapi vs. sync ndbapi, but this change eliminates most of that difference.
      unused table in test suite
      Fix for compiler warning in TimestampWriter validity check
      NDB encoding-related changes.  (1) distinguish between 22003 numeric value out of range and HY000 for "value is not numeric"  (2) provide a (hopefully) faster path to encoderWrite and encoderRead by wrapping them as methods of Record
      Refactor error handling
      Attempt to [1;31moptim[mize encodeKeyBuffer() for single-column indexes
      Fix reporting of session factory if no mappings
      Remove JsValueAdapter in loader; it is no longer needed.
      This fixes the failing "timestamp 1969" test case for NDB. Test still fails with MySQL.
      Fixes for lint test failures
      Test & fix NDB handling of encoder errors for numeric types
      Tests for numeric types
      This renames the integraltypes suite to numerictypes and adds stub tests for float, double, and decimal columns
      Test for particular expected errors rather than simply for operation failure
      Add decimal support in NdbTypeEncoders Remove JS wrapper for decimal utilities from ndb_util
      Encoders for NDB integer values: if the fast integer conversion fails, try a slow one, then test whether the result is legal.  This should allow writing valid JS string and float values to int columns.
      Improve handling of errors from NDB data type encoders
      Improve handling of data encoder errors in the ndb adapter
      fix sql_mode for mysql adapter
      Implemented test cases
      Stub out new test cases for data type casting
      If MySQLTime.valid is set to false, NdbTypeEncoder will reject the value.
      Allow user to set sql_mode in mysql adapter with a default of STRICT_ALL_TABLES
      Change console.log to udebug.log in issues/2014-03-18Test
      Add shell script to manage regular runs of jscrund
      Adapt loader to use new Batch.getOperationCount() api
      Batch: use getOperationCount()  rather than getSize()
      Add Batch.getSize() method
      Add test case for issue of bad data type for column
      Fix typo
      Add test case for issue where a TableMapping created from a literal mapping could not be used to perform operations (fixed in bzr 686).
      Changes to sample data loader after code review with Craig. This version still has lots of untested features (and combinations of features) but it can load CSV data and random data.
      Bug fix creating TableMapping from object literal
      WL#7578 Replace usage of ndb_schema_share->key with hardcoded text
      WL#7578 Move subscriber bitmaps to NDB binlog component
      WL#7578 Move the g_nodeid_map to Ndb binlog thread
      WL#7578 move clearing of subscribed to binlog thread
      WL#7578 Always expect everyone to ack the schema op
      WL#7578 Refactor schema distribution code
      WL#7578 Refactor schema distribution code
      ndb
      WL#7578 note about nodeid from global cluster connection
      WL#7578 Don't use ndb_schema_share from ack_schema_op
      Initial checkin of JavaScript data loader tool
      Remove windows line endings from ndb_schema_object.cc
      Try to reduce overhead of stats.incr() calls
      Remove the error handling in jscrund_mysqljs backend which duplicates work performed in the jscrund frontend.
      Add conditional guards around udebug log messages.
      Add conditional guards around udebug log statements.
      Improve error reporting while loading mysql node_module
      The node-mysql driver by default constructs an Error object in order to get a stack that includes the user's call to Query. This can be a performance bottleneck.

[33mcommit 1f266fb4edd077fe121202a661d2511e8d6672cd[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Fri Mar 27 16:19:29 2015 +0100

    Bug#20748660 THD->MDL_CONTEXT.OWNS_EQUAL_OR_STRONGER_LOCK | CREATE_INFO->TABLESPACE
    
    Post push fix due to a variable being used only in a DBUG_ASSERT(),
    making [1;31moptim[mized werror builds fail.

[33mcommit 89dd986a89840b7d7ffcf3555612c2d4ff01eaf9[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Wed Mar 25 14:56:43 2015 +0100

    Bug#19585938 Crash in get_full_func_mm_tree with null item_field->table_ref
    
    The problem may occur if we have a grouped query with a non-grouped
    subquery that contains a reference to an aggregate function, e.g. in
    the WHERE clause. The aggregate function must not reference any columns.
    
    Example query:
    
    SELECT (SELECT 1
            FROM t1
            WHERE SUM(1) < id
           )
    FROM t1
    GROUP BY col1+col2;
    
    The range [1;31moptim[mizer is attempting to [1;31moptim[mize the predicate SUM(1) < id.
    SUM(1) is represented by an Item_aggregate_ref object in get_mm_tree().
    Since aggregation is performed in the outer query, this item is an outer
    reference. get_mm_tree() will then call get_full_func_mm_tree() with
    the real_item() of the Item_aggregate_ref object as predicand, which is
    an Item_field. This Item_field represents a field in the temporary table
    allocated for grouping the outer table. But since this table has no
    assigned TABLE_LIST object, trying to calculate the map() for this table
    fails.
    
    However, this seems to be a legacy issue. Before WL#7540 was pushed,
    table map was 1. But this is actually an outer reference, so it was
    wrongly seen as a local table. Actually, being an outer reference, this
    item is const during evaluation of the inner query, so this is not a
    candidate for range [1;31moptim[mizer analysis at all.
    
    The fix is just to skip the call to get_full_func_mm_tree() if the
    argument representing the Item_aggregate_ref is an outer reference.
    
    The problem was also identified for other predicate types like BETWEEN.
    Fix has been provided for this too, together with test cases.

[33mcommit 56731d709527a77ac473decda153a192e2049abf[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Mar 26 13:35:09 2015 +0200

    Implement growing of the lock free hash table
    
    With this change when the hash is filled up and needs to be extended, a
    new array is appended and the hash consists of two or more arrays.
    Search and insert operations are performed on each array separately.
    
    When a new array is appended the data in the old one is not transferred
    to the new one. It is to be determined if this is necessary from
    performance point of view (searching in more than one array is
    sub [1;31moptim[mal).
    
    WL#7170 InnoDB buffer estimates for tables and indexes

[33mcommit 64173ab8553d7b5ebd6c2cb188309c21ddb54436[m
Author: Benny Wang <benny.wang@oracle.com>
Date:   Thu Mar 5 01:43:32 2015 +0100

     Fixed bug#20590162: incorrect assumption about innodb
                            record length in [1;31moptim[mizer temporary tables
    
    For ha_innobase::max_supported_key_part_length(), the returned value relies on
    innodb_large_prefix. However, in innodb itself, the limitation on key_part
    length is up to the ROW_FORMAT. In current trunk, internal temp table's
    ROW_FORMAT is COMPACT. In order to keep the consistence between server and
    innodb, here we hard-coded 767 as the maximum of key_part length supported by
    innodb until bug#20629014 is fixed.

[33mcommit fa6f397f73ce0f95b3d4558fc5a40aabad89c269[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Wed Mar 4 14:44:27 2015 +0100

    Bug#17766653 CRASH IN ADD_KEY_FIELD Bug#20558891 HANDLE_FATAL_SIGNAL (SIG=11) IN QEP_SHARED_OWNER::KEYS
    
    Problem:
    SELECT a.a FROM `t1` `a`, t1 b
    HAVING 1 NOT IN (SELECT a.a FROM `t1`);
    - We resolve the clauses of the subquery: an Item_field is created
    for 'a.a', with depended_from=select#1.
    - the subquery is inside HAVING, and as usual all columns used by
    HAVING must be Item_ref, so an Item_ref is created, with
    depended_from=select#1; this Item_ref then goes through fix_fields()
    which finds 'a.a' is also present in the SELECT list of select#1 and
    thus makes Item_ref wrap the Item_field of the SELECT list of
    select#1, which has depended_from=NULL. Note that the first Item_field
    is thus dropped.
    - So far so good.
    - in-to-exists transformation then wants to build an equality of the
    form: left_expr==right_expr; when it does so, it uses
    right_expr->real_item() for the right side of the equality; right_expr
    is the Item_ref but its real_item() is the SELECT list element of
    select#1, which has depended_from=0.
    - thus, with this real_item(), we end up with 'a.a' on the right side,
    in the WHERE clause of the subquery, with depended_from=0
    i.e. considered as a non-outer, local column, which is wrong.
    - top query is completely [1;31moptim[mized
    - In [1;31moptim[mization of the subquery, we then look for Keyuse-s for this
    column, which is absurd; add_key_field() reaches to reginfo.join_tab
    which is NULL (because the outer query has already been [1;31moptim[mized, and
    WL#6042 zeroes the join_tab pointers at the end of [1;31moptim[mization), and
    we get a problem.
    The root cause is: we use real_item().
    
    Fix:
    - I first tried to use the solution of Bug 18014565
    (substitutional_item() at line 1996 of item_subselect.cc);
    but it does not solve the problem in ps-protocol mode; indeed in that
    mode, the Item_ref being a rollbackable one (runtime-created),
    substitutional_item() is equal to real_item()
    - removing real_item() isn't a solution either, for reasons explained
    in new comments in item_subselect.cc
    - So, until wl#6570 is implemented, two if()s are added, which are
    sufficient to fix all testcases of the two bug reports.

[33mcommit 0626283fa5937de2a6cf99012f57bb4d6561fb60[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Tue Mar 3 09:53:56 2015 +0100

    Bug#20454833 PREFIX INDEX FIELD, ON AN INAPPROPRIATE DATA TYPE Bug#20506527 FAILING ASSERTION: !MBMAXLEN || !(PREFIX_LEN % MBMAXLEN)
    
    Both bugs have the same cause; I'll describe the scenario of the first
    one. Query is:
    select `t2`.`b`,`t1`.`b`,`t1`.`a`
    from `t2` inner join `t1` on 1 cross join `t2` `a`  on 1
    group by `t1`.`b`;
    
    In trunk as in 5.6, [1;31moptim[mizer decides to create a tmp table
    for the grouping. It will have 3 columns: t2.b (blob), t1.b (int),
    t1.a (blob). Notice the same name (but different source table) for
    the two first.
    An index is wanted, on t1.b (for grouping on it).
    In 5.6, it works.
    In trunk (if internal_tmp_disk_storage_engine=innodb), we go into
    ha_innodb.cc's create_index(), which has this loop to find which Field
    is related to the key_part (key_part describes the index which the
    [1;31moptim[mizer asks to create):
    
         for (ulint i = 0; i < key->user_defined_key_parts; i++) {
             KEY_PART_INFO*    key_part = key->key_part + i;
    ...
             Field*    field = NULL;
             for (ulint j = 0; j < form->s->fields; j++) {
    
                 field = form->field[j];
    
                 if (0 == innobase_strcasecmp(
                         field->field_name,
                         key_part->field->field_name)) {
                     /* Found the corresponding column */
    
                     goto found;
    
    See how it compares field names. key_part->field->field_name is "b" (t1.b);
    in our case, t2.b is the first column of form->s->fields, its field_name
    is "b", so we have a (wrong) match; then things go wrong as expected
    (field t2.b is a blob, though the index was supposed to be on an int (t1.b)),
    and we have:
    [ERROR] MySQL is trying to create a column prefix index field, on an
    inappropriate data type. Table name tmp/#sql_4d6e_0, column name b.
    
    The loop above was surely relying on the fact that in a user-created
    table, field names are unique. But this is not (yet) true for internal
    tmp tables.
    Fix: replace the loop with:
    field=form->field[key_part->field->field_index];
    I verified with dbug_assert + running mtr, that the loop above effectively
    finds "field" equal to the proposed form->field[etc], except in the bugs'
    testcases.

[33mcommit 5ce27f3e80636bded4b855930646f9af5b062d6a[m
Author: Debarun Banerjee <debarun.banerjee@oracle.com>
Date:   Thu Feb 19 10:46:01 2015 +0530

    BUG#20468234 - REMOVE __ATTRIBUTE__((NONNULL)) FROM INNODB
    
    Problem :
    ---------
    __attribute__((nonnull)) is forbidden by InnoDB coding guidelines, but
    there are leftovers from past times. Some bits of code in InnoDB wrongly
    use that attribute and later use the parameter in a conditionals,
    checking if it is NULL, but the compiler could [1;31moptim[mize those conditionals
    altogether, causing very hard to diagnose bugs.
    
    Solution :
    ----------
    Remove __attribute__((nonnull)) from all innodb files.
    
    Reviewed-by: Vasil Dimov <vasil.dimov@oracle.com>
    
    RB: 7998

[33mcommit 3b3751230790525dae83aed0896b5997fd7ef5d7[m
Merge: 1af9d73526c 78158e80dbc
Author: haixli <haixiang.li@oracle.com>
Date:   Thu Feb 12 01:16:12 2015 +0100

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Description:
    ------------
     - LooseScan algorithm requires 'sorted' retrieval of keys, so it can't
       use EQ_REF access type(calling DBUG_ASSERT(qep_tab->use_order()) in
       evaluate_join_record() function).
     - For a first inner table of semi join(IN-Subquery), MySQL believes
       LooseScan is the best by calculating its cost
       with semijoin_firstmatch_loosescan_access_paths().
     - If this first inner table only use a primary key, its access type is
       EQ_REF, which violates the constraint of LooseScan algorithm, so
       it triggers a ASSERT in execute phase.
    
     - 5.6.x believes Materialize algorithm is the best for this case.
     - Why does this test case use Loosescan algorithm in 5.7.x?
       It is because WL#6635 fixed semijoin_firstmatch_loosescan_access_paths(),
       it reduced the cost of LooseScan algorithm, so MySQL believes LooseScan
       is a best way.
    
    Fix:
    ----
    Allow a table to use EQ_REF and be [1;31moptim[mized by LooseScan, because EQ_REF can keep a unique order.
    
    Test case added.

[33mcommit 3cb15fe58df4c8c4ea294ede5198fb448a7ec01f[m
Author: haixli <haixiang.li@oracle.com>
Date:   Wed Feb 11 01:35:16 2015 +0100

    Bug#20119743 ASSERTIONQEP_TAB->USE_ORDER() IN ENUM_NESTED_LOOP_STATE
                 EVALUATE_JOIN_RECORD
    
    Description:
    ------------
     - LooseScan algorithm requires 'sorted' retrieval of keys, so it can't
       use EQ_REF access type(calling DBUG_ASSERT(qep_tab->use_order()) in
       evaluate_join_record() function).
     - For a first inner table of semi join(IN-Subquery), MySQL believes
       LooseScan is the best by calculating its cost
       with semijoin_firstmatch_loosescan_access_paths().
     - If this first inner table only use a primary key, its access type is
       EQ_REF, which violates the constraint of LooseScan algorithm, so
       it triggers a ASSERT in execute phase.
    
     - 5.6.x believes Materialize algorithm is the best for this case.
     - Why does this test case use Loosescan algorithm in 5.7.x?
       It is because WL#6635 fixed semijoin_firstmatch_loosescan_access_paths(),
       it reduced the cost of LooseScan algorithm, so MySQL believes LooseScan
       is a best way.
    
    Fix:
    ----
    Allow a table to use EQ_REF and be [1;31moptim[mized by LooseScan, because EQ_REF can keep a unique order.
    
    Test case added.
For keyword regression:
[33mcommit c73f0e3eb113ddcb8b553d255a99a860f01d0144[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Tue May 22 17:58:36 2018 +0200

    Bug #27786807: CLIENT --TLS-VERSION HELP TEXT INCORRECT FOR WOLFSSL
    
    Fixed two issues:
    1. the originally reported issue with the --tls-version's help
    text with wolfSSL. Fixed by removing the #ifdef
    2. Fixed a [1;31mregression[m in compiling mysql with wolfSSL: a missing
    function X509_check_ip_asc. Fixed by adding a new dummy function
    to wolfSSL's mysql diff that always returns success.
    Had to amend the cert_verify test to cover that.

[33mcommit c84ed7095ddbc4040e5967c0e4c53b171520fd34[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Mon Apr 30 06:30:08 2018 +0200

    Bug #26643180: MYSQLDUMP IS EXCLUDING GTID_EXECUTED TABLE FROM THE DUMP
    
    Problem: This bug is a [1;31mregression[m of bug#24590891.
    
    Fix: Fix is to retain gtid_executed table and skip the data from that
    table during dump process.

[33mcommit d446af569ad1495ed17a6abbda32ab989500b951[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Apr 19 11:46:24 2018 +0800

    Bug#27755892 - CRASH IN ROW_SEL_FIELD_STORE_IN_MYSQL_FORMAT_FUNC
    
    This is a [1;31mregression[m from this commit: ef20b9. The cause is that with
    the changes in aforementioned commit, optimizer supports 'using index'
    for some LIKE queries on a prefix index, including the virtual index.
    Before this change, this kind of query will go with table scan.
    So the assertion in row_sel_field_store_in_mysql_format_func() is
    somehow bogus now. So the fix is to screen out the case that the field
    is a virtual column. In case of a virtual column, it just ignores the
    field prefix length checking.
    
    RB: 19455
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 5c9dda425c0bfc88c33ac20badccbad7d789d568[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Apr 12 09:27:13 2018 +0800

    WL#11250 - Support Instant Add Column - Regression
    
    The [1;31mregression[m was found in SELECT - OR scenario, which was about 7%-8%
    according to QA.
    
    After testing and verification, two changes would help improve the
    performance, and current [1;31mregression[m is only about 1.7% in the SELECT - OR
    scenario, which should be acceptable, because overhead for checking
    instant columns are inevitable.
    
    The two changes are mainly about:
    1. Two different rec_get_nth_field for record with
    (rec_get_nth_field_instant) or without(rec_get_nth_field as is)
    instant columns. Thus for the record without instant columns, there won't
    be extra checking.
    2. Introduce a bit flag in dict_index_t to say if this is clustered index
    with some instant columns, rather than consulting with the table.
    
    From the testing, 1 saved the [1;31mregression[m a lot, but without 2, it's not
    good enough. So it would be nice to pick both. Furthermore, with these
    two changes, there are also some small improvement in other testing
    scenarios.
    
    RB: 19392
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 64fb797ab49af6598ce55f54c864a4330d520cd7[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Fri Apr 6 10:10:28 2018 +0200

    Bug #27627136 DOXYERROR.LOG DOESN'T CONTAIN ERRORS FROM PLANTUML AND DIA
    
    Problem: Doxygen runs with QUIET=NO and
    WARN_LOGFILE=@CMAKE_CURRENT_BINARY_DIR@/doxyerror.log. This writes all
    Doxygen errors and warnings to doxyerror.log instead of to
    stderr. However, errors from external tools called by Doxygen, such as
    PlantUML and dia, are not included. These are only writen to stderr, and
    lost in a long list of Doxygen stdout messages.
    
    Solution: Use the output to stderr instead of WARN_LOGFILE in order to
    pick up errors from third party tools. Build all error filtering that
    used to be done with sed and grep into the CMake script, so that
    everything is done by one call to make doxygen.
    
    The result is the following files:
    
    doxyoutput.log:
      stdout from Doxygen.
    
    doxyerror.log:
      stderr from Doxygen.
    
    tofix-all.log:
      Same as doxyerror.log, but without dia status messages, and with paths
      relative to the source directory.
    
    tofix-[1;31mregression[ms.log:
      Same as tofix-all.log, but without known warnings and errors (filters
      defined in Doxyfile-ignored).
    
    The tofix-[1;31mregression[ms.log messages are also printed to stdout during
    make doxygen, and the target will finish by reporting if any [1;31mregression[ms
    were found.
    
    Change-Id: I0e45745976bedbcb83f8ed952e52f927de99eb21

[33mcommit 71464a1edb94d93c0f0c986752b95bcc4d0eb28a[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Mar 12 14:51:11 2018 +0100

    WL #11590: More flexible filesort [patch 3/10, incremental buffer]
    
    Instead of allocating one big filesort buffer up-front, start with
    a small buffer, only increasing it (exponentially) once we actually get more
    data. If we actually need all of the buffer, we do somewhat more mallocs
    than in the allocate-once case, but on Linux, the mallocs disappear
    entirely in the rest of the work. (On Windows, we do see a [1;31mregression[m
    in heavily concurrent sort benchmarks, but that will be fixed in a future
    worklog.)
    
    For the case where we have a large buffer but don't use it (e.g. 256 kB
    of data with 32 MB large buffer), we do save a fair amount of CPU time (on the
    order of 7–8%, although of course this will vary with the exact circumstances).
    Also, of course, we save the RAM we don't use.
    
    Note that we never move data between the sort buffers -- once rows are written
    into a buffer, they never move. This means we need separate storage for the
    record pointers, which means we also need some care to make sure we don't
    overrun the sort buffer budget too much with the hidden cost of storing the
    pointers.
    
    Change-Id: I0599bc10947aec95ae80a3dbbf04e81d2017cfb0

[33mcommit 6f3d60d7a06d851f5ffce8c163e3f5f7d887a082[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Tue Mar 6 10:15:24 2018 +0800

    Bug#27577704 - INNODB: ASSERTION FAILURE: HA_INNOPART.CC:3331:IB_TABLE->STAT_INITIALIZED
    Bug#27586419 - ASSERT: TABLE->STAT_INITIALIZED::DICT_STATS_ASSERT_INITIALIZED
    
    These two bugs should be due to the same cause, which is a [1;31mregression[m from
    bug#26848711. In that bug, the dict_sys mutex was removed for
    dict_table_close(). So it requires a per-table lock to prevent the race
    between table->n_rec_count and table->stats_initialized. The problems are
    in that patch, it only forced the table lock around table->acquire() in
    ha_innobase::open(). This is far not enough. In fact, all acquiring tables
    when the table is already in memory should acquire the table lock, because
    in all those code pathes, the table->stats_initialized would be checked,
    and the race should be prevented too.
    
    The patch fixes all these two bugs, by introducing a new dict_table_t API
    called acquire_with_lock(), which will lock() and unlock() when acquiring
    the table. This API should will replace normal acquire() calls when the
    table to be opened is in memory and there would be stats initialization
    afterwards. Comments related are also modified a bit to clearly demonstrate
    this point.
    
    RB: 19020
    Reviewed by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit aa82204ffea191a121d6f90d122b7bb2ff39c8a8[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Tue Mar 6 10:15:24 2018 +0800

    Bug#27577704 - INNODB: ASSERTION FAILURE: HA_INNOPART.CC:3331:IB_TABLE->STAT_INITIALIZED
    Bug#27586419 - ASSERT: TABLE->STAT_INITIALIZED::DICT_STATS_ASSERT_INITIALIZED
    
    These two bugs should be due to the same cause, which is a [1;31mregression[m from
    bug#26848711. In that bug, the dict_sys mutex was removed for
    dict_table_close(). So it requires a per-table lock to prevent the race
    between table->n_rec_count and table->stats_initialized. The problems are
    in that patch, it only forced the table lock around table->acquire() in
    ha_innobase::open(). This is far not enough. In fact, all acquiring tables
    when the table is already in memory should acquire the table lock, because
    in all those code pathes, the table->stats_initialized would be checked,
    and the race should be prevented too.
    
    The patch fixes all these two bugs, by introducing a new dict_table_t API
    called acquire_with_lock(), which will lock() and unlock() when acquiring
    the table. This API should will replace normal acquire() calls when the
    table to be opened is in memory and there would be stats initialization
    afterwards. Comments related are also modified a bit to clearly demonstrate
    this point.
    
    RB: 19020
    Reviewed by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 9daba613b440f1009b3419f9e5bbec0e3a2e48f4[m
Author: Malika Agarwal <malika.agarwal@oracle.com>
Date:   Thu Feb 8 16:36:48 2018 +0530

    BUG#26940372: INCREASE TEST COVERAGE FOR MYSQLADMIN AND MYSQLD_SAFE
    
    Description:
    ------------
    Currently only the basic funcionality of mysqld_safe and mysqladmin
    is being tested in MTR. Many recent [1;31mregression[ms have been observed
    which could be solved by increasing the test coverage of the
    mysqld_safe and mysqladmin tests. These functionalities have a lot
    of options and scenarios involving these options should be tested.
    
    Fix:
    ---
    Some positive and negative scenarios related to mysqld_safe and
    mysqladmin options have been added to the existing tests.

[33mcommit 80013ff933f7c9aad1a5da5b29bfd2df0eefc85b[m
Author: Debarun Banerjee <debarun.banerjee@oracle.com>
Date:   Wed Jan 31 10:55:45 2018 +0530

    BUG#27135742 CLONE CREATED IBDATA1 IS OF A DIFFERENT SIZE
    BUG#27245214 LATCHDEBUG::CHECK_ORDER
    
    Problem :
    ---------
    1. When file is extended in page copy stage we are always extending
    the first node/file for the tablespace. For multi-node system tablespace
    this results in extending the first file more than configured length.
    
    2. For persisting dynamic metadata, checkpoint needs to insert data into
    tables. A recent patch caused this [1;31mregression[m, where checkpoint is
    called before releasing archiver mutex. This triggers the debug mode
    assert checking mutex order.
    
    3. Issue when clone lsn with block boundary
        - when Trailer chunk is first block in next redo file
        - when trailer chunk ends at file and block boundary
    
    4. Non-linux platforms are not using clone_buffer_size
    
    Solution :
    ----------
    1. Evaluate the right size and extend the last file after PAGE COPY
    2. Call checkpoint after releasing archiver mutex
    3. Avoid overwriting trailer if archived log ends at block boundary
    4. Add check if zero-copy is supported and use clone_buffer_size
    
    5. Tests for scenarios 1-4
    5A.Test shutdown while clone is in progress
    5B.Test coverage for clone with read/write when not using O_DIRECT
    
    Reviewed-by: Satya Bodapati <satya.bodapati@oracle.com>
    
    RB: 18427

[33mcommit e3e2ccc2cf00436a8be026ff421ec5e6facaaa1f[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Jan 25 10:50:14 2018 +0100

    Bug#27418207 MAIN.COMMENT_COLUMN2 FAILS WITH COMPRESSION
    
    Before this fix,
    the following assert fails in sql-common/net_serv.cc,
    in function net_read_packet()
    
        /*
          The right-hand expression
          must match the size of the buffer allocated in net_realloc().
        */
        DBUG_ASSERT(net->where_b + NET_HEADER_SIZE + sizeof(uint32) <=
                    net->max_packet + NET_HEADER_SIZE + COMP_HEADER_SIZE);
    
    This is a [1;31mregression[m introduced by:
    
    commit 304578be76ba4c4f012c0a591c751ce9fcbb169b
    Author: Tor Didriksen <tor.didriksen@oracle.com>
    Date:   Wed Jan 8 15:12:04 2014 +0100
    
        Bug#17922198 REMOVE OBSOLETE IFDEF HAVE_PURIFY CODE.
    
        Patch #6
        Do not allocate extra byte for uint3korr.
    
    Before this change:
    - uint3korr could read 4 bytes instead of 3
    - an extra byte was allocated as safety
    so that the assert was of the form
    
      DBUG_ASSERT( ... + sizeof(uint32) <= ... + COMP_HEADER_SIZE + 1);
    
    This represents that memory used by the code, in the left hand side,
    is actually within the memory allocated for the data, in the right hand
    side.
    
    The expression "sizeof(uint32)" represented the 4 bytes used by uint3korr.
    
    When the code for uint3korr() was fixed to use really only 3 bytes
    instead of 4, the allocation was shortened by 1 byte (right hand side),
    but the left hand side was forgotten (only 3 bytes are used, not 4),
    causing the [1;31mregression[m.
    
    The fix is to implement the correct assert, as in:
    
        DBUG_ASSERT(... + 3 <=
                    ... + COMP_HEADER_SIZE);

[33mcommit 8321df87fd3d2be53576d9de4cf6074550571157[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Mon Jan 22 11:40:13 2018 +0800

    BUG#27419487 - INNODB: ASSERTION FAILURE: DICT0DICT.CC.*(&DICT_SYS->MUTEX)->IS_OWNED()
    
    This is a [1;31mregression[m from bug#26848711. The dict_sys mutex should be
    acquired before handling error to remove the index from cache.
    
    The fix is simply requiring the mutex and release later.
    
    Reviewed by: Allen Lai <zheng.lai@oracle.com> over IM.

[33mcommit 329bdc384bbf8d4561d1eed92b6009264bd4249c[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Mon Jan 22 11:16:20 2018 +0800

    BUG#27419487 - INNODB: ASSERTION FAILURE: DICT0DICT.CC.*(&DICT_SYS->MUTEX)->IS_OWNED()
    
    This is a [1;31mregression[m from bug#26848711. The dict_sys mutex should be
    acquired before handling error to remove the index from cache.
    
    The fix is simply requiring the mutex and release later.
    
    Reviewed by: Allen Lai <zheng.lai@oracle.com> over IM.

[33mcommit 43d9c74574d30d0a2be499521cde711185309db3[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Jan 18 09:54:42 2018 +0800

    Bug#27389274 - DICT0DICT.CC:1380:TABLE2 == NULL ASSERTION HIT DURING CONCURRENT DDL
    
    This is a [1;31mregression[m from push of bug#26848711.
    In dict_sdi_create_idx_in_mem(), there was a short period when the
    dict_sys mutex would be released and re-acquired, during this period,
    one dict_table_t object with the same name may be created by another
    thread, like background threads, etc. So when adding current dict_table_t,
    it will assert there is one same table exists.
    
    Solution is to double check the dict_table_t object after re-acquiring
    the dict sys mutex, if there is already one, then the current one would
    be abondanded and just return the existing one, otherwise, return the
    current one. In this way, it's possible to release the dict_sys mutex
    earlier so not to block other threads too much.
    
    RB: 18458
    Reviewed by: Allen Lai <zheng.lai@oracle.com>

[33mcommit 71b0c585173257ff7a27f0cebe562f69ada2720a[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Fri Jan 12 11:14:55 2018 +0800

    Bug#26848711 - PERFORMANCE REGRESSION IN "CREATE TABLE" SPEED AND SCALABILITY IN 8.0.3
    
    The performance [1;31mregression[m is mainly due to that DDL logs are logged and
    flushed after every transaction commit under dict mutex and lock protection.
    So it showed that dict_operation_lock is very hot.
    
    Since it has to flush redo logs after every transaction commits, so that
    it's true crash-safe DDL, this penalty can't be avoided. However,
    after new DD, dict_operation_lock along with dict_sys mutex are not
    necessary to be held for such a long time during DDL, so we should
    try to deprecate dict_operation_lock and ask for dict_sys mutex
    as less as possible.
    
    Current patch mainly fix this issue in above way for CREATE TABLE and
    the modified code will of course affect ALTER TABLE a bit too.
    Basically, dict_operation_lock is not necessary for CREATE TABLE any more.
    And dict_sys mutex would be acquired only when dict_sys information
    is modified, such as adding new dict_table_t to cache, increase
    dict_sys->size etc. The dict_sys mutex should not be held during
    creating physical data files, etc. Once it's proper time to get rid of
    these dict lock and mutex for all DDLs, it could be possible to clean up
    dict_sys mutex further.
    
    At the meantime, since dict_sys mutex is not held during the whole
    process of CREATE TABLE, once the dict_table_t is added to global cache,
    it has to be kept in cache without eviction before writing metadata of it
    to dd::Table. So this requires some changes for
    innobase_basic_ddl::create_impl().
    
    Furthermore, in this patch, dict_table_close() doesn't have to acquire
    dict_sys mutex any more, instead it has to acquire a per-table mutex
    called dict_table_t::mutex, to prevent the race from ha_innobase::open().
    
    RB: 17608
    Reviewed by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit a5c15f5911987b05fa926303d91376f18da5fd88[m
Author: Nuno Carvalho <nuno.carvalho@oracle.com>
Date:   Tue Jan 9 11:32:11 2018 +0100

    BUG#27016053: REGRESSION IN BINLOG_LOG_ROW INTRODUCED BY ADD_PKE
    
    Group Replication plugin is a multi or single primary replication
    solution, on which members do execute transactions optimistically
    and at commit time they decide, if conflicts happen, which must
    commit or rollback.
    The conflict detection is based on the write-sets of each
    transaction, which is collected along the transaction life when it
    does a update.
    During detailed performance analysis it was discovered that there
    were non-optimized memory allocations and memory copy operations on
    the write-set extraction.
    
    In order to solve the performance [1;31mregression[m, the following actions
    were made:
     1) optimize memory allocation;
     2) reduce memory copy operations;
     3) only collect foreign key write-sets when the current table has
        foreign keys.

[33mcommit 838871ffe5b464364bd6489b389b0c438a0b69ac[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Tue Jan 9 18:13:36 2018 +1100

    Bug#26399073 - MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS
    
    Fix a performance [1;31mregression[m; InnoDB has a system where the performance
    schema key is decided by FILE, and the patch that extended the basename
    function to work with both / and \ made these allocations slower (as it
    uses std::string, which can allocate on the heap).
    
    However, there is no reason whatsoever that this lookup needs to be done
    runtime in a map. Change it to use a constexpr function; it goes through
    the array linearly, but it's small and it's compile-time. The end result
    is that the compiled code stores a PSI key directly, instead of taking
    FILE, removing its path runtime and looking it up in an std::map.
    
    Improves a data loading benchmark with ~3%, in addition to the ~7%
    [1;31mregression[m it fixes
    
    rb#18379 Approved by Bin. Fixed by Steinar.

[33mcommit 1b0a0645a2803b4a5f3bd5ada356a3edf9d1624a[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Tue Jan 9 18:13:36 2018 +1100

    Bug#26399073 - MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS
    
    Fix a performance [1;31mregression[m; InnoDB has a system where the performance
    schema key is decided by FILE, and the patch that extended the basename
    function to work with both / and \ made these allocations slower (as it
    uses std::string, which can allocate on the heap).
    
    However, there is no reason whatsoever that this lookup needs to be done
    runtime in a map. Change it to use a constexpr function; it goes through
    the array linearly, but it's small and it's compile-time. The end result
    is that the compiled code stores a PSI key directly, instead of taking
    FILE, removing its path runtime and looking it up in an std::map.
    
    Improves a data loading benchmark with ~3%, in addition to the ~7%
    [1;31mregression[m it fixes
    
    rb#18379 Approved by Bin. Fixed by Steinar.

[33mcommit 4cf07627f374793c03f6867e048a6bc611e96475[m
Author: Srikanth B R <srikanth.b.r@oracle.com>
Date:   Fri Jan 5 11:52:22 2018 +0530

    Bug#27343113 MTR: --SKIP-RPL WONT SKIP FEW TESTS IN RPL_GTID SUITE
    
    Issue:
    ------
    Using the MTR option --skip-rpl skips tests which are in rpl suite
    even though it does not include master-slave.inc/rpl_init.inc. But,
    --skip-rpl fails to skip tests which are in rpl_gtid suite and does
    not include master-slave.inc/rpl_init.inc.
    
    This is a [1;31mregression[m caused by the patch for Bug#25166686 due to
    which only tests in the rpl suite were being tagged as rpl_test's
    but not those in rpl_gtid or rpl_nogtid suites.
    
    Fix:
    ----
    Identify all suites whose names match 'rpl' as replication tests
    and skip them when the option --skip-rpl is specified.
    
    Change-Id: I505cef82a7dfc0d5528dc588068f4347d2fc3e61

[33mcommit 94f5b892bf9c0a8c2a09c5e108004afa0f73e4c7[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Dec 14 15:14:04 2017 +0100

    Bug#24444908  CLUSTER CRASHED DURING RESTART WITH AN ASSERTION `!CALLBACKOBJ->HAS_DATA_TO_SEND
    
    Follow up patch fixing [1;31mregression[ms caused by original patch.
    
    There basically were two issues identified:
    
    1) TransporterFacade::enable_send_buffer() and ::disable_send_buffer() could cause
       a deadlock as they took the TransporterFacade::m_open_close_mutex and
       trp_client::m_mutex in the wrong order. Intention here was to ensure
       that TransporterFacade::m_enabled_nodes_mask and each clients m_enabled
       flag was updated atomically.
    
    2) There were no concurrency protection against different threads starting
       a enable_send_buffer() immediately after a disable_send_buffer() (Immediately
       trying to reconnect) where the later 'enable could overtake the 'disable',
       resulting in undefined states transitions in the send buffers.
    
    Patch revert (most of) a previous addendum patch attempted to fix these [1;31mregression[ms.
    
    Fix for 1) is to reduce the scope of the 'm_open_close_mutex' in the TF enable/disable
    methods, such that it is not held together with the trp_client::m_mutex.
    These overlapping mutexes didn't really serve any purposes anyway as ::open_clnt(),
    which use m_enabled_nodes_mask, has to handle the trp_client enable/disable
    initially not being entirely 'in synch' - Extended comments to cover this.
    
    Fix for 2) is move calls to enable_send_buffer() and disable_send_buffer()
    into report_connect() and report_disconnect() which is called as poll-owner.
    Thus, enable/disable could only be called from a single thread, providing the
    required serialization of these calls. In addition it also guards against
    a :close() removing the client under the feet of enable/disable as close
    is also guarded by the poll-right.
    
    Note that prior to original patch for this bug, ::reset_send_buffers() used
    to be called from the same report_* methods, before this patch replaced 'reset'
    with enable/disable and placed the calls at the incorrect place.

[33mcommit f043f0205d50cfdc720271772e29c52b6299ccd6[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Dec 7 14:33:00 2017 +0100

    bug#24444908  CLUSTER CRASHED DURING RESTART WITH AN ASSERTION `!CALLBACKOBJ->HAS_DATA_TO_SEND.
    
    Addendum patch to fix a [1;31mregression[m introduce by previous patch set:
    
    Patch for this bug introduced enable/disable semantics for send_buffers. Initially
    all send buffers are disabled, and got enabled as Transporters 'connect', or
    when we 'open' a ned trp_client.
    
    However, if the 'open' of a new client required the m_threads[] array to
    be expanded, it have to send a request signal to its own clusterMgr.
    This happened *before* we had set up which nodes send_bufffers were enabled
    for this client. Thus the send (silently) failed, and 'open' waited
    forever for the m_threads[] array to be expanded.
    
    This patch reordered the 'open' logic, such that the TransporterFacade set
    of already enabled send_buffers are assigned to the to-be-opened-client
    before we possible send the expand request.

[33mcommit 9c9bdf17e2159af46ef036910a1e33fa14a5261e[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Dec 1 11:18:12 2017 +0100

    Bug #26399073: MYSQL DOES NOT COMPILE WITH CLANG ON WINDOWS [noclose]
    
    Fix a performance [1;31mregression[m; InnoDB has a system where the performance
    schema key is decided by __FILE__, and the patch that extended the
    basename function to work with both / and \ made these allocations
    slower (as it uses std::string, which can allocate on the heap).
    
    However, there is no reason whatsoever that this lookup needs to be done
    runtime in a map. Change it to use a constexpr function; it goes through
    the array linearly, but it's small and it's compile-time. The end result
    is that the compiled code stores a PSI key directly, instead of taking
    __FILE__, removing its path runtime and looking it up in an std::map.
    
    Improves a data loading benchmark with ~3%, in addition to the ~7% [1;31mregression[m
    it fixes.
    
    Change-Id: Ia536f6342278fcd6cc990053c3d2b0978e781b29

[33mcommit 20e971e87fb197411c2910430b9b1ddb0c3c604c[m
Author: Dag Wanvik <dag.wanvik@oracle.com>
Date:   Tue Nov 7 16:36:45 2017 +0100

    Bug#27082154 MTR NO LONGER FINDS EXECUTABLES FOR XCODE BUILT PROJECT
    
    This was a [1;31mregression[m after the fix for Bug#26985269: code which
    previously was execute for Mac OS, no longer was: now it was only
    executed for Windows, leading to the issue.
    
    Extend the condition for WINDOWS to also include Mac OS.

[33mcommit 1c368c1b32514ae3f21eac7dcb8cc2cdada92542[m
Author: Christopher Powers <chris.powers@oracle.com>
Date:   Thu Oct 19 23:32:41 2017 +0200

    Bug#26980399 STACK BUFFER OVERFLOW OF LOWER_CASE_NAME WHEN SETTING VARIABLES
    
    This bug is a [1;31mregression[m from Bug#25680866 "CHARACTER SET SPECS HAVE LOUSY PERFORMANCE..."
    which introduced functions that map character set and collation names to a number.
    These functions copy a null-terminated name string into a fixed-size buffer for
    for conversion to lower case. The problem is that incoming strings longer than
    the buffer are not re-terminated with null, allowing subsequent reads beyond
    the end of the buffer.
    
    The fix ensures that character set names are null-terminated before converting
    to lowercase.

[33mcommit 2f5be15558ae4a93f08ed9f13308ed192b19f2cf[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon Oct 16 09:44:32 2017 +0200

    Bug#25868387 WRONG DATA RETURNED WITH NDB JOIN PUSHDOWN
    
    Fix a [1;31mregression[m caused by patch for:
      bug#23130819  (REFACTOR STATE CHANGES FOR THE ROW BUFFER ASSOCIATED WITH THE TABLE CLASS)
    
    The 'Refactor state change' seems to have removed some 'clear all row buffers' logic
    and instead only relied on that all handler calls returned 'HA_ERR_END_OF_FILE' if
    no rows were found.
    
    The ndbcluster handler interface for  ha_ndbcluster::index_read_pushed()
    instead returned 'ok' (0) of no rows were found, which was now interpreted
    as 'another row found'.
    
    Patch fix this by returning 'HA_ERR_END_OF_FILE' as expected by
    the enhanced handler semantics.

[33mcommit fe30399d788089efed4eaf3f84d9b404111afc45[m
Author: Jens Even Berg Blomsoy <jens.even.blomsoy@oracle.com>
Date:   Wed Sep 13 13:33:30 2017 +0200

    BUG#26766501 - PATCH FOR #26271244 CAUSES PERFORMANCE REGRESSION FOR READ WRITE WORK LOADS
    
    POST FIX
    ==========
    Removed the check for HT_HIDDEN_SE from lock_table_names() which is called
    frequently, and added it to mysql_rename_tables() which is the only place
    not covered by other checks. This fixed the [1;31mregression[m problem.
    
    BUG#26271244 - ASSERT FAILS WHEN SHOW CREATE TABLE CALLED ON A FILE
    CREATED FOR FULLTEXT INDEX
    
    Analysis of Initial Problem
    ========
    a) FTS indexes are represented as hidden tables which do not show
    up when doing SHOW TABLES. Yet their .ibd files are in the schema
    directory and issuing SHOW CREATE TABLE on the corresponding table name
    would trigger an assert.
    
    b) Other issues revealed themselves while digging into the bug.
    OPTIMIZE, REPAIR, TRUNCATE and LOCK TABLES all asserted, while
    RENAME and DROP TABLE was allowed.
    
    FIX
    ======
    OPTIMIZE, REPAIR, TRUNCATE, LOCK, RENAME, ALTER and DROP TABLE
    now issues an error of ER_NO_SUCH_TABLE when called with and FTS
    index.

[33mcommit f101afb46e6ff3d8b4ee5679e52555272d3b26ac[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Fri Sep 1 17:54:18 2017 +0300

    Bug#26719289 "8.0.3-RC SHOWS UP TO 25% PERFORMANCE REGRESSION WITH WL6049 PUSH".
    
    The problem was that WL6049 introduced heavy performance [1;31mregression[m
    for write related tests. The source of this [1;31mregression[m was new
    process_table_fks() function. This function is called for each table
    modified by typical DML statement to determine on which tables related
    through foreign keys to table modified we need to additionally acquire
    metadata locks. This function used dd::Dictionary_client::acquire()
    method to get information about table's foreign keys and this method
    is known to be scalability bottleneck since it acquires global
    (actually per object type) lock. Additionally when validating elements
    of prelocked set for foreign keys with cascading updates or deletes we
    acquired global LOCK_open lock and locks on all table cache partitions,
    which devasted scalability for statements causing such actions.
    
    This patch solves the problem by not using dd::Dictionary_client::acquire()
    in process_table_fks() and instead relying of information about foreign
    keys caches in TABLE_SHARE object. In the most common scenario it is already
    available when we call process_tables_fks(). In another case it can be
    easily accessed through table cache which is protected by partitioned
    lock. This patch also introduces caching of necessary information about
    foreign keys in the table share. We also use this TABLE_SHARE for
    prelocking set validation when necessary and thus avoid unnecessary
    locking for statements with cascading deletes or updates.

[33mcommit 8676d8ce7b74b465a93ec175cd0caa59f2e83150[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Fri Sep 1 17:54:18 2017 +0300

    Bug#26719289 "8.0.3-RC SHOWS UP TO 25% PERFORMANCE REGRESSION WITH WL6049 PUSH".
    
    The problem was that WL6049 introduced heavy performance [1;31mregression[m
    for write related tests. The source of this [1;31mregression[m was new
    process_table_fks() function. This function is called for each table
    modified by typical DML statement to determine on which tables related
    through foreign keys to table modified we need to additionally acquire
    metadata locks. This function used dd::Dictionary_client::acquire()
    method to get information about table's foreign keys and this method
    is known to be scalability bottleneck since it acquires global
    (actually per object type) lock. Additionally when validating elements
    of prelocked set for foreign keys with cascading updates or deletes we
    acquired global LOCK_open lock and locks on all table cache partitions,
    which devasted scalability for statements causing such actions.
    
    This patch solves the problem by not using dd::Dictionary_client::acquire()
    in process_table_fks() and instead relying of information about foreign
    keys caches in TABLE_SHARE object. In the most common scenario it is already
    available when we call process_tables_fks(). In another case it can be
    easily accessed through table cache which is protected by partitioned
    lock. This patch also introduces caching of necessary information about
    foreign keys in the table share. We also use this TABLE_SHARE for
    prelocking set validation when necessary and thus avoid unnecessary
    locking for statements with cascading deletes or updates.

[33mcommit d034d7599c4b1da891fe7ae9510b14adb7ee49df[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Aug 11 12:45:49 2017 +0200

    WL #10343: Switch GCC optimization from -O3 to -O2
    
    Change from -O3 to -O2 everywhere, for smaller binaries, faster compile
    times and generally better performance. Mark some performance schema
    function as force-inline to avoid performance [1;31mregression[ms, since they
    are important to inline despite being big.
    
    Change-Id: Ib7603f141e6974aeed7e4fde2ef7697864231ae3

[33mcommit c10127a41e4f65062bf932a70e6f336d7411a778[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Thu Aug 17 14:51:19 2017 +0300

    Bug #26173244: THE UDF INSTALL SERVICE CAN'T BE USED AT
     PLUGIN INSTALLS
    
    Split the UDF initialization/deinitialization into two:
    1. Initialization/deinitialization of the global structures
    2. Loading of the UDF definitions from the table and removing them from the global
    
    Then kept the #2 at the place of the current initialization/deinitalization
    routines and added #2 initialization very early (before component/plugin
    initialization) and #2 deinitialization very late (after the plugin/compononent
    deinitialization.
    
    Added a test plugin and a [1;31mregression[m test.

[33mcommit 34a9bad08cb29410db399f098f828ed6ce907908[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Thu Aug 3 10:28:25 2017 +0200

    Bug#25526439: Assertion failed: is_fixed_or_outer_ref(this)
    Bug#25071305: Assertion failed: first_execution || !tl->is_view_or_derived() ...
    Bug#24716127: Incorrect behavior by insert statement with "on duplicate ..."
    
    This is a combined fix for three [1;31mregression[m bugs in INSERT resolving
    that came after WL#5094 refactoring.
    
    The main problem here is about bad sequence of resolver actions, as
    WL#5094 introduced one sequence for all INSERT syntax that proved to
    be insufficient. The problem was that apply_local_transforms() was
    sometimes not performed for subqueries in the INSERT ... ON DUPLICATE KEY
    UPDATE clause.
    
    It is necessary to know one implementation detail in order to grasp the
    full problem: Subqueries on INSERT ... VALUES clauses and subqueries in
    ON DUPLICATE KEY UPDATE clauses are attached to the last query block of
    the query expression of the INSERT statement, even though they are not
    actually referenced from this query block. And apply_local_transforms()
    will only be applied to subquery objects when called from an outermost
    query block.
    
    The solution is to identify three distinct cases for ON DUPLICATE KEY
    UPDATE resolving, with their required resolver sequences:
    
    1. INSERT INTO t ... VALUES ... ON DUPLICATE KEY UPDATE ...
       - Resolve VALUES expressions.
       - Resolve ON DUPLICATE KEY UPDATE expressions.
       - Call apply_local_transforms() on outer-most query block, which
         will include any subqueries in VALUES expressions.
    
    2. INSERT INTO t ... SELECT <non-union> ON DUPLICATE KEY UPDATE ...
       - Resolve SELECT query block, but do not call apply_local_transforms().
       - Combine context for SELECT query block and INSERT table
         (if the query block is non-grouped).
       - Resolve ON DUPLICATE KEY UPDATE expressions.
       - Call apply_local_transforms() on outer-most query block.
    
    3. INSERT INTO t ... SELECT ... UNION ... ON DUPLICATE KEY UPDATE ...
       - Resolve ON DUPLICATE KEY UPDATE expressions.
         (the outer query block may stay unresolved because there are no
          references into it).
       - Resolve the query expression, include calling apply_local_transforms()
         which will also include any subqueries in ON DUPLICATE KEY UPDATE
         clauses.
    
    In addition, we have extended with two new subquery context types:
    CTX_INSERT_VALUES and CTX_INSERT_UPDATE. They are used to generally
    provide more information about the parsing process, and in particular
    make it possible to build AST without outer references from subqueries
    in INSERT ... VALUES statements and in INSERT ... ON DUPLICATE KEY UPDATE
    statements.

[33mcommit 58c0815f71151c91990f2e685d099e1caccd27c3[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Mon Jul 24 16:48:10 2017 +0800

    WL#9536: Fix a [1;31mregression[m on trx and thr, reformat DDL log a bit.

[33mcommit fb056f442a96114c74d291302e8c4406c8c8e1af[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Fri Jul 14 09:15:44 2017 +1000

    WL#10793 - InnoDB: Use VATS for scheduling lock release under high load
    
    Variance-Aware Transaction Scheduling (VATS) is described in
    https://arxiv.org/pdf/1602.01871.pdf. The patch was contributed by
    Jiamin Huang <jiamin@umich.edu> and Barzan Mozafari <mozafari@umich.edu>
    from the University of Michigan.
    
    When granting locks the grant strategy used depends on the number of waiting
    locks. If it is >= 32 then VATS will be used otherwise the original first come
    first served (FCFS) strategy will be used. The threshold of 32 was chosen
    after empirical verification on a supra class machine. Ideally we would
    like to default to VATS for all loads but a small [1;31mregression[m was seen on
    the lower loads.
    
    Reviewed-by: Jimmy <jimmy.yang@oracle.com>
    Reviewed-by: Deb <debarun.banerjee@oracle.com>
    RB:16290

[33mcommit 5ed6fc6bb56af560e5ab3b3d7e5c5da9fc452942[m
Author: Dag Wanvik <dag.wanvik@oracle.com>
Date:   Tue Jun 20 20:49:31 2017 +0200

    Bug#26359109 REFACTOR ITEM_FUNC::FIX_NUM_TYPE_SHARED_FOR_CASE FOR REUSE BY LEAD/LAG
    
    [ was: Settled a TODO FIXME item: reuse fix_num_type_shared_for_case for LEAD/LAG ]
    
    [ Revision 2: after Roy's 2. review
    
      - Renamed fix_*from_args -> aggregate_*  (after first rename in revision 1)
      - Fixed bug in set_data_type_datetime: used wrong MAX_*_WIDTH constant
      - Removed Docygen reference to max_chars for methods that don't see
        that level of detail.
      - Unfolded logic into separate switch branches for readability in
        Item::aggregate_temporal_properties
    ]
    
    [ Revision 1: after Roy's review
    
      - All review items except:
    
      "I also wonder if we should skip max_length calculation here and
      thus ignore decimals in that calculation. Calculation of decimals
      might still be needed to avoid [1;31mregression[ms in results, but
      max_length should be strictly derived from the float type, IMHO."
    
      and one changed that caused a crash:
    
      "I do not think we should set decimals here, we should accept the
      constructor default."
    
      which, if done, breaks func_time.test
    ]
    
    Settled a windowing TODO FIXME item: reuse fix_num_type_shared_for_case
    for LEAD/LAG
    
    - Added the method header file and made it non-static, so we can use
      it in Item_lead_lag.
    
    - Changed its signature to accept Item instead of Item_func, since
      Item_sum (parent class of Item_lead_lag) is not an Item_func.
    
    - In the process lifted auxiliary type resolving functions up from
      Item_result_field/Item_func up to Item (at Roy's request: we felt
      they belong more naturally there than in Item_result_field even
      though that is the closes common ancestor of Item_func and
      Item_sum).

[33mcommit e7a917c41017f4eefbdceb4cab509a6fc138d8d5[m
Author: Parveez Baig <parveez.baig@oracle.com>
Date:   Mon Jun 19 16:29:21 2017 +0530

    WL9776 : Add/Extend mtr tests for replication with generated columns or X plugin
    
    The aim of this wl is to just add mtr tests for replication [1;31mregression[m suite for
    the below two sections.
    
    1) Generated columns
    2) X-Plugin

[33mcommit b0594720a0c8bb268fe47bda61b7f469b57f40fa[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Apr 6 19:27:41 2017 +0800

    Disable innodb.innodb_wl6560_debug which is [1;31mregression[m of WL#9499.
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit b5e97e6273d745b0e1e0c9cb10eadf43ad891e3d[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Mar 22 09:19:31 2017 +0100

    Bug#25654833 MYSQL CLUSTER 7.5.5 REPLICATION SLAVE SQL THREAD HANGS WITH CREATE TABLE
    
    This is 'best effort' patch for the above problem, which seems to be a [1;31mregression[m introduced in 7.5.5. Based on bug description, we *assume* this to be caused bu the 'part 3 of 4' push of patch for Bug#25042101 'SPLIT BINLOG INJECTOR_MUTEX IN TWO, DO REQUIRED CLEANUP':
    
    .........
      Remove thread_yield() in binlog injector code previously put there
      as a temp stopgap in the commit below. This used to be required
      as the injector thread held the injector_mutex > 99% of the time when
      waiting for pollEvents(). That blocked client threads either wanting to
      access the data shared from the injector thread, or needing the injector_mutex
      while waiting for injector_cond to be signaled
    
      This should not be required anymore, as:
    
      1) injector_mutex has been splitt in two separate mutexes.
      2) We changed init of the injector_event_mutex from a 'FAST' to a 'SLOW'
         mutex which has better 'farness' properties in the scheduler
    .........
    
    The theory is that using the more 'fair' SLOW-mutex variant is not as 'fair' as assumed to be on all OS/VM variants. Thus the 'yields' may be unsafe to remove.
    
    Bug has been hard to reproduce:
    
     - It has been 'randomly' reproduced using Oracle Linux 7 on top
       of 'Virtualbox'
     - It has than gone away for a couple of days.
     - It has *not* been reporoduced with this patch.
    
    So it should be reasonable to expect that reintroducing the 'thread_yields' should solve the problem.
    
    We cant say for sure though....
    
    (cherry picked from commit f0e06cc2bc975ca5be084be9c307803e1da53cd4)

[33mcommit 0d6bd740997f6d5daa56b961378708dff5196b35[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Mar 23 15:18:07 2017 +0100

    Bug#25741170 SPJ: DON'T ADD FLUSH_AI-PSEUDO_READS WHEN NOT NEEDED
    
    Follow up patch to fix a [1;31mregression[m detected by ATR test
    ./testSpj -n NF_Join T6
    
    In case the SPJ results has to be sent by the routed TRANSID_AI_R
    signal the block ref for the 'route' destination refered the
    SPJ block instead of the TC block.
    
    It turns out that for scan type SPJ request LQHKEYCONF/REF
    is expected by the SPJ for the lookup-leaf treeNode. The
    LqhKeyReq::tcBlockref is set up to contain the SPJ block
    which such CONF/REF should be sent to.
    
    Unfortunately the same ::tcBlockref field is used in cases where
    a TRANSID_AI_R signal has to be used, which in these cases will
    refer a SPJ block.
    
    Thus we have to use the FLUSH_AI which contain its own 'routeRef'
    block in a SPJ scan-request.
    
    This patch fix the above issue and revert the part of the previous
    patch which set up scan requests for eliminating unneeded FLUSH_AI's
    
    This causes us to loose some important oportunities for sending
    packed 'short' TRANSID_AI signals. However, this is assumed to be
    regained by the upcomming patch for:
    
    bug 25750355 SEND SPJ RESULTS AS 'PACKED' TRANSID_AI WHERE APPLICABLE

[33mcommit f9a5c2caa466689a4d5d73565940ef4c5e4b1760[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Mar 22 09:19:31 2017 +0100

    Bug#25654833 MYSQL CLUSTER 7.5.5 REPLICATION SLAVE SQL THREAD HANGS WITH CREATE TABLE
    
    This is 'best effort' patch for the above problem, which seems to be a [1;31mregression[m introduced in 7.5.5. Based on bug description, we *assume* this to be caused bu the 'part 3 of 4' push of patch for Bug#25042101 'SPLIT BINLOG INJECTOR_MUTEX IN TWO, DO REQUIRED CLEANUP':
    
    .........
      Remove thread_yield() in binlog injector code previously put there
      as a temp stopgap in the commit below. This used to be required
      as the injector thread held the injector_mutex > 99% of the time when
      waiting for pollEvents(). That blocked client threads either wanting to
      access the data shared from the injector thread, or needing the injector_mutex
      while waiting for injector_cond to be signaled
    
      This should not be required anymore, as:
    
      1) injector_mutex has been splitt in two separate mutexes.
      2) We changed init of the injector_event_mutex from a 'FAST' to a 'SLOW'
         mutex which has better 'farness' properties in the scheduler
    .........
    
    The theory is that using the more 'fair' SLOW-mutex variant is not as 'fair' as assumed to be on all OS/VM variants. Thus the 'yields' may be unsafe to remove.
    
    Bug has been hard to reproduce:
    
     - It has been 'randomly' reproduced using Oracle Linux 7 on top
       of 'Virtualbox'
     - It has than gone away for a couple of days.
     - It has *not* been reporoduced with this patch.
    
    So it should be reasonable to expect that reintroducing the 'thread_yields' should solve the problem.
    
    We cant say for sure though....

[33mcommit 77d0abb4c4d76c335d37b30a374a16dd76253428[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Fri Mar 10 13:02:13 2017 +0100

    Bug#25688504: [1;31mregression[m: scale >= 0 && precision >= 0 && scale <= precision
    
    Fix for bug#25669580 was insufficient for some cases where the first
    argument was of type DECIMAL. New fix is to assign all type-related
    properties instead of just the type code.

[33mcommit 977ea2985ba5737df5b706f50b583c649d74f2db[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Tue Mar 7 17:17:51 2017 +0100

    Bug#25669580: [1;31mregression[m: assertion failed: 0 in Item_num_func1::str_op
    Bug#25669590: [1;31mregression[m: assertion failed: collation.collation == ...
    Bug#25669606: [1;31mregression[m: assertion failed: !is_temporal()
    
    Follow-up fix: Fix Clang build warning about unused
    is_numeric_type() in log_event.cc when MYSQL_SERVER is set.

[33mcommit fefc49211947bbc4155f8629281c45344bedf218[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Mon Mar 6 09:12:30 2017 +0100

    Bug#25669580: [1;31mregression[m: assertion failed: 0 in Item_num_func1::str_op
    Bug#25669590: [1;31mregression[m: assertion failed: collation.collation == ...
    Bug#25669606: [1;31mregression[m: assertion failed: !is_temporal()
    
    Bug#25669580:
    Problem here is that for ROUND function when second argument is constant NULL,
    data type is uncritically copied from first argument. If first argument
    is not numeric, assign DOUBLE as type.
    
    Bug#25669590:
    Problem was caused by a too aggressive assert (although I see no harm in it)
    
    Bug#25669606:
    Problem is that Item_func_nullif inherits from Item_bool_func2,
    and thus Item_int_func, in order to utilize the comparison mechanism
    for equality operations. However, by doing this, in 5.7 the derived
    type of this Item is MYSQL_TYPE_VAR_STRING, even though the first argument
    is a temporal type. After bug#25221172, derived type is correctly
    MYSQL_TYPE_TIME, but then we reach Item::get_time_from_int(), which
    crashes because it is not implemented for temporal types.
    
    Quick fix: Adjust data type of item to MYSQL_TYPE_VAR_STRING in
    Item_func_nullif::resolve_type().
    
    Best fix would be to let Item_func_nullif inherit from Item_func_case
    and remove implementations for resolving and evaluation.

[33mcommit 02336705f41385ca05666211fa83cb35a7df8491[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Wed Mar 1 12:08:21 2017 +0100

    Bug#24666169: I_S.TABLE_CONSTRAINTS.CONSTRAINT_NAME IS NOT UPDATED
                  AFTER RENAME TABLE
    
    Bug#25339192: NEWDD: SERVER SHOULD DISALLOW FOREIGN KEYS ON BASE
                  COLUMN OF STORED COLUMN
    
    This patch consists of three parts:
    
    1) When tables are renamed, any foreign keys with generated
    names are renamed as well. This is necessary since the table
    name is part of the generated name. We assume that the name
    was generated if it starts with table_name + '_ibfk_', similar
    to how InnoDB does it in earlier versions.
    This part fixes Bug#24666169.
    
    2) During ALTER TABLE, both the new and the old table definition
    exists in the data dictionary at the same time (uncommitted).
    In order to satisfy the unique constraint on schema_name+fk_name,
    pre-existing FKs were before not transferred to the new table
    definition until ALTER TABLE was almost completed. This meant
    that FK metadata was not available to InnoDB during ALTER TABLE
    processing. In order to make it available to InnoDB, foreign keys
    are now transferred to the new table definintion immediately,
    but with a temporary name to satisfy the unique constraint.
    The original name is restored at the end of ALTER TABLE.
    This part is required to fix Bug#25339192.
    
    3) As a consequence of 2), more validity checking of pre-existing
    foreign keys had been added to the SQL layer to avoid [1;31mregression[ms
    in error reporting. This consists of checking and reporting
    ER_FK_DUP_NAME, ER_DROP_INDEX_FK and ER_FK_COLUMN_CANNOT_DROP.

[33mcommit 6aa6ad4fa9e301b0475e1e3fe1f3c1b6c027e1d1[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Thu Feb 23 14:15:51 2017 +0100

    Bug#25422034 CRASH IN TABLE_LIST::QUERY_BLOCK_ID_FOR_EXPLAIN DURING EXPLAIN FOR CONNECTION
    
    Problem under concurrency:
    SELECTing from materialized view and doing EXPLAIN from another connection.
    The SELECT goes into TABLE_LIST::resolve_derived() which creates a tmp
    table and stores it into the 'derived_table' member of the SELECT_LEX_UNIT
    of the query expression underlying the derived table.
    But before 'derived_table' gets set, EXPLAIN runs and looks at the unit;
    (in Explain::explain_subqueries()) it sees this unit is for a derived
    table (context==CTX_DERIVED) and wants to access the tmp table; however
    'derived_table' is still nullptr so this fails.
    The 'derived_table' member was introduced by WL#883 (CTEs) so it's
    a [1;31mregression[m.
    The reason EXPLAIN accesses 'derived_table' is to
    reach the CTE, and from there, the first materialized reference to the CTE,
    and from there, the unit underlying that reference and finally
    the ID of the first query block of that unit, because EXPLAIN wants
    to mention only one plan for the CTE for all references to the CTE.
    Fix: in EXPLAIN FOR CONNECTION, if the stmt is not yet fully prepared,
    don't explain it. This way, if the explainer reaches the point to test
    the 'derived_table' pointer it is sure it is set.
    Testcase with DEBUG_SYNC, as the problem requires concurrency.

[33mcommit c4bc5300862f416ac3853e10b16ffadb6930a227[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Feb 15 22:26:27 2017 +0100

    Fixed a [1;31mregression[m introduced by:
    
      commit f0c99144ef59390487fa2c7608bbeff1582ca4dc
      Author: Christopher Powers <chris.powers@oracle.com>
      Date:   Thu Aug 11 20:52:36 2016 +0200
    
          WL#6616 PERFORMANCE SCHEMA, INDEXES
    
          Implement indexes for Performance Schema tables.
    
          Marc Alff, Chris Powers, Mayank Prasad, Tarique Saleem
    
    Now that the instrument prefix does not contain a trailing '/'
    character which is added in build_prefix,
    the length check needs to account for the extra character added.

[33mcommit 4a14fb77732a8e9cb2bed1ac70bfa6004644bdab[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Feb 8 16:53:37 2017 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Post-push fix: Add a missing inline declaration that would cause performance
    [1;31mregression[ms on the string length microbenchmark with -O2 (instead of -O3).
    
    Change-Id: I6a576557606ff1aafed1f51340b578028c80227e

[33mcommit 8617d643bcaaab36155aef35b39afd60c3bf3f30[m
Author: Lukasz Kotula <lukasz.kotula@oracle.com>
Date:   Thu Jan 26 11:29:16 2017 +0100

    Fix for toggling x.[1;31mregression[m
    
    Description
    ===========
    
    Creation of 'mysqlxsys' account in thread That calls plugin entry
    Point is not possible, because it could be executed at the start mysqld.
    When mysqld starts the SQL service is not accessable. The creation
    of account was moved to a separate thread which races with 'mysql-test'
    pre / post-check.
    
    Fix
    ===
    
    Plugin is going to be loaded by mysqltest script instead from MTRs
    opt file. In this case we aren't in race with MTR.
    
    RB: 15320
    Reviewed-by: Andrzej Religa <andrzej.religa@oracle.com>

[33mcommit d194220d77cf7c71f13f3b132fee97c4db6a58d6[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Thu Jan 26 11:04:54 2017 +0100

    Bug#23130819: Refactor state changes for the row buffer in class TABLE
    
    Followup to fix [1;31mregression[m introduced by original bugfix.
    The [1;31mregression[m was in the test information_schema-big.
    
    For join operations that produced aggregated, empty results, some
    tables might be left in the "null_row" state after the output row
    had been produced. For the test that failed, this coincided with a later
    ICP evaluation on the table with the erroneous state, which caused a
    wrong false result.
    
    The immediate fix to this problem was to add reset_null_row() calls
    for all tables involved in such operations. This fixed the problem,
    but re-introduced another problem about overwriting of NULL value flags
    for const tables. Const tables actually need the same save and restore
    logic for NULL values as for eq_ref tables. It seemed like a good idea
    to consolidate all NULL value setting and restoring.
    
    Thus, saving and restoring of NULL values is moved from the TABLE_REF
    class to the TABLE class. A null_flags_saved buffer is allocated for
    all TABLE objects together with record[0] and record[1]. (It is a very
    small buffer, so the overhead is marginal).
    
    The function JOIN::clear() is renamed to JOIN::clear_fields(), it is
    extended with functionality to save NULL values for const tables,
    and it is paired with a new function JOIN::restore_fields() that will
    restore NULL values saved in JOIN::clear_fields().
    
    This also fixed a [1;31mregression[m that was introduced when bug#13430588
    was fixed: The offending aggregated query would report a non-NULL value
    when a NULL was expected, see test main.group_by.

[33mcommit ae7079af5e85f57bc1a99c696471ea0036ab9d82[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Mon Jan 23 11:14:35 2017 +0530

    BUG#24806257 : MTR DOESN'T DO CHECK-TESTCASE IF THERE IS --SKIP IN TEST
    
    Description :
    =============
    Skip statements should be placed in the beginning of a test before it
    creates tables and other objects. If a test is skipped after altering
    the database state then it might affect the subsequent test runs on
    the same thread. `check-testcase` is run only if a test run is
    completed successfully and not run when a test gets skipped. This is a
    badly written test and will be better if it fails and gets noticed in PB2.
    
    E.g :
    -----
    CREATE TABLE t1(a INT);
    skip "Intentional skip doesn't complain about existing table t1";
    DROP TABLE t1;
    
    Here, MTR should have complained about existing table t1.
    
    Fix :
    =====
    MTR is modified to run check-testcase after a test gets skipped.
    Tests modifying the system state before the skip will now fail with
    check-testcase failure and get noticed in [1;31mregression[m runs.
    
    Reviewed-by: Anitha Gopi <anitha.gopi@oracle.com>
    Reviewed-by: Deepa Dixit <deepa.dixit@oracle.com>
    RB: 14835

[33mcommit 93f4a9b6fbae1578ed1225af1655c69ca0fee69f[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Jan 19 16:11:23 2017 +0100

    Bug#22705935 NDBAPI : SENDSIGNAL FLUSH OPTIMISATION ISSUES
    
    Follow up patch to fix [1;31mregression[m observed in the ATR
    tests:
    
    - testNdbApi -n ApiFailReqBehaviour T1
    - testNdbApi -n CheckDisconnectCommit T1
    - testNdbApi -n CheckDisconnectComplete T1
    - testNdbApi -n FragmentedApiFailure T1
    - ... and possibly more
    
    The original patch removed the ::flush_send_signal()
    from TransporterFacade::reportConnected / ::reportDisconnected()
    after it had returned from ClusterMgr::reportConnected
    or ::reportDisconnected().
    
    This was done as flushing is now done by by the poll owner
    when it 'finished poll'. However, that is probably too late
    for the ::reportDisconnected() as we want the receiver to
    take immediate actions on this - Possibly we even reset
    the send buffers as part of disconnecting, such that the
    unflushed signals are lost before they are sent, (Didn't
    really investigate that though)
    
    This patch reintroduce flushing for ClusterMgr::reportConnected()
    and ::reportDisconnected() by changing their signal sending
    to use the flushing ::safe_sendSignal() instead of
    ::safe_noflush_sendSignal(). This reintroduce the
    immediate flushing of signals sent as part of a
    connect/disconnect.

[33mcommit 44bb2e6dd187dc5917cf8cdac362ee0146c77698[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Jan 2 13:16:33 2017 +0100

    Bug #25336715: ADD AN OPTION TO RANDOMIZE LINK ORDER
    
    We keep seeing spurious performance changes that we believe are caused by lucky
    or unlucky alignment of code, and that tend to go away by themselves at a later
    stage. This commit adds a CMake flag (-DLINK_RANDOMIZE=ON) that randomizes the
    order of almost all symbols in the mysqld binary; the idea is that if a
    [1;31mregression[m between binaries A and B (presumably at different versions) are
    detected, one can randomize both sides to test randomize(A) vs. randomize(B)
    and see if the [1;31mregression[m still holds. If the randomized versions are the
    same, it's much more likely to be random.
    
    The randomization is reproducable, as it works by hashing the function name
    together with a seed (which can be set by -DLINK_RANDOMIZE_SEED=).
    
    It's not recommended to use this flag for regular builds, especially as it
    causes somewhere around 5% performance [1;31mregression[m in sysbench; the default
    order (ie., just keep the order from each source code file, and link object
    files in the order they are given on the command-line) is quite good for
    reducing TLB misses, as it puts related functions together.
    
    I haven't tested actually reproducing historical spurious [1;31mregression[ms
    with this (it would probably mean running quite large benchmarks), so it's
    somewhat experimental, but should be used next time we debug such a [1;31mregression[m.
    Different seeds make for differences in some microbenchmarks, which is a good
    indication that it would have a real measurement effect.
    
    Change-Id: Ide109371bd99390bd79b1809d771c444ac70b837

[33mcommit deefa5c57e2bb11ffca5904130b5b841f2e81648[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Fri Dec 9 10:47:50 2016 +0100

    Bug#25228584 ST_ASBINARY DOESN'T ACCEPT SECOND PARAMETER
    
    This is a [1;31mregression[m introduced by the fix for bug #25027963.
    
    Problem: ST_ASBINARY doesn't accept it's second parameter.
    
    During the refactoring done in bug #25027963, ST_ASBINARY was defined as
    a function that only accepts one parameter instead of a function that
    takes one or two parameters. This made ST_ASBINARY and ST_ASWKB, that
    are aliases to the same function implementation, behave
    differently. However, since only ST_ASWKB was tested with two
    parameters, this was not discovered during refactoring.
    
    Fix: Define ST_ASBINARY as a function that takes one or two parameters
    and add more tests of ST_ASBINARY.
    
    Change-Id: I0b0ed078a92060a8bb81c6eab3eda5839e38b462

[33mcommit 7aae987b29448c47ed97fad23769a99308b742ca[m
Author: Aakanksha Verma <aakanksha.verma@oracle.com>
Date:   Wed Dec 7 15:41:50 2016 +0530

    Bug #14025581 FILE IO INSTRUMENTATION DISABLED IN PERFORMANCE SCHEMA FOR INNODB
    
    Post Push fix for performance [1;31mregression[m on windows trunk.
    
    Reviewed by : Jimmy Yang <Jimmy.Yang@oracle.com>

[33mcommit 213c0a07cadb422b4b99bbea399e105d5f8c492a[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Mon Nov 28 11:05:03 2016 +0100

    Bug#24733658: If and friends give wrong type for signed and unsigned integer
    
    The problem here is that the CASE, COALESCE, IF and IFNULL functions merge
    signed and unsigned integer data types incorrectly. The value range of
    the merged type is not large enough to accomodate all values from the
    source expressions. Interestingly, this is only a problem with SELECT,
    when the SELECT is used with a CREATE TABLE statement, a correct
    data type is generated. This is because the merged field_type is used
    to determine the data type in the SELECT case, whereas result_type is used
    to determine the data type in the CREATE TABLE case.
    
    The solution is to refactor how the data type of such functions are
    generated, and derive the result type from the data type. A new function
    Item::aggregate_type() is implemented that loops over all source items
    to the function. NULL types are skipped, and if only NULLs are input,
    a NULL value is generated. Otherwise, the function Field::field_type_merge
    is used to generate the proper data type. However, when the generated
    data type is an integer type, and we have both unsigned and signed arguments,
    the data type may be adjusted to one with a bigger range. Let's say we have
    a signed short int and an unsigned short int as arguments. The value
    range for those are -32768..32767 and 0..65535, respectively. The resulting
    values are not accomodated in a short int, so we make the resulting type
    a signed long int. The range need to be "bumped" only if the largest
    unsigned type is the same as the type resulting from field_type_merge().
    If the longlong integer type must be bumped, no integer type is wide
    enough to hold the resulting values, and a DECIMAL(20,0) is generated.
    
    When implementing Item::aggregate_type(), a few functions were made
    redundant and have been deleted. These are item_store_type() (we
    no longer aggregate result type, the result type is derived from field
    type), agg_result_type() (replaced by field_type_merge()) and
    Item_func_if::cache_type_info(). In addition, the resolve_type() functions
    of class Item_func_ifnull,  Item_func_if, Item_func_case and
    Item_func_coalesce have been made as equal as possible.
    
    This change caused one [1;31mregression[m because fields of type BIT and integer
    were merged to a string type instead of an integer type. In trunk,
    agg_field_type() generated VARCHAR for this combination, but
    agg_result_type() generated DECIMAL_RESULT, and this was the chosen
    data type. Since a BIT is classified as an integer data type in the
    manual, the conversions for BIT and integer types in the array
    field_types_merge_rules were changed to numeric types. This caused the
    [1;31mregression[m to disappear, and no other test failures were introduced.
    
    This will also fix bug#25139420. A test case for this bug is added.

[33mcommit 191494cfabd08f8afb4b19ae3fe18a8531f19b3a[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Nov 7 11:08:06 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Prefactoring: In the collations test suite, output the actual weight string
    we are sorting on, in order to more easily detect and debug [1;31mregression[ms.
    
    Change-Id: I27620708d5869c4371aa0c2ecc9f6812239fbe55

[33mcommit a6f313d36fa3fda2b393ca0f9dde14ab56aa3fdd[m
Author: Ole John <ole.john.aske@oracle.com>
Date:   Fri Nov 11 13:44:27 2016 +0100

     Bug #25042101 SPLIT BINLOG INJECTOR_MUTEX IN TWO, DO REQUIRED CLEANUP
    
        Remove thread_yield() in binlog injector code previously put there
        as a temp stopgap in the commit below. This used to be required
        as the injector thread held the injector_mutex > 99% of the time when
        waiting for pollEvents(). That blocked client threads either wanting to
        access the data shared from the injector thread, or needing the injector_mutex
        while waiting for injector_cond to be signaled
    
        This should not be required anymore, as:
    
        1) injector_mutex has been splitt in two separate mutexes.
        2) We changed init of the injector_event_mutex from a 'FAST' to a 'SLOW'
           mutex which has better 'farness' properties in the scheduler
    
        This also reverts the patch:
    
        commit 000394fbe3a8d7a2945fb6b483024b77e16ab20a
        Author: Ole John Aske <ole.john.aske@oracle.com>
        Date:   Fri Jan 15 09:55:05 2016 +0100
    
            Follow up patch for performance [1;31mregression[m introduced by patch for bug#20957068
    
            Introduce some sched_yield() in the binlog-thread loops where
            the injector_mutex is held >99% if the elapsed time. The yields
            let other threads waiting to be scheduled a chance to run,
            and grab the injector_mutex when not held by the binlog-thread.

[33mcommit 75180fbb0116b5df9fa06dbbf16fe56dbe68adf2[m
Author: Christopher Powers <chris.powers@oracle.com>
Date:   Wed Oct 12 13:06:38 2016 -0500

    Bug#24519021 FEW XA TESTS FAIL IN WAIT_COND'N.INC AS VIEW ON P_S.THREADS DOESNT RETURN RESULT
    
    This is a [1;31mregression[m from WL#6616 Performance Schema, Indexes. Under high
    stress conditions, performance_schema.threads may attempt to materialize a
    row representing a thread that is being disconnected, resulting in an error
    similar to "At line 41: Query 'SELECT count(*) = 0 FROM v_processlist WHERE
    PROCESSLIST_ID = 17' didn't return a result set
    
    The fix is for table_threads::make_row() to return a row only if the state of
    the thread has not changed.

[33mcommit 751c37e454ccbf4b1edcd70a98bde80bef31ed82[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Oct 5 14:58:07 2016 +0300

    Fix Bug#24666839 INNODB'S ESTIMATE FOR ROWS-IN-TABLE CAN RETURN ROWS=1 DUE TO A RACE CONDITION
    
    Previously, when copying stats around, we did:
    
    1. reset all stats of table T
    2. copy the stats from a dummy table object into T
    
    We only did 1. because during 2. we may skip some indexes which could
    then remain uninitialized in T. The problem is that between 1. and 2. the
    stats could be read without taking any locks (if ha_innobase::info() is
    called with HA_STATUS_NO_LOCK) which could lead to reading the zeroed
    stats which almost certainly do not describe the table well (too wrong).
    
    The solution is to avoid 1. and directly overwrite the existing stats in
    2. and in addition, if the index is to be skipped, then reset its stats,
    as what would have been done by 1.
    
    Still, this could cause an inconsistent stats read by
    ha_innobase::info(HA_STATUS_NO_LOCK) - it could read partially the old
    stats and partially the new stats. This is acceptable because:
    * The stats are an approximation and not exact/precise numbers,
      occasionally reading outdated stats should not cause problems
    * Doing any locking in ha_innobase::info(HA_STATUS_NO_LOCK) was
      tested and causes performance [1;31mregression[ms.
    
    RB: 14204
    Reviewed by: Satya Bodapati <satya.bodapati@oracle.com>

[33mcommit a600868f12cc6607654756ba30f6908b7f083160[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Wed Sep 14 13:37:47 2016 +0200

    Bug#24661626: -DWITH_ASAN=ON SEEMS TO BE BROKEN ON MAC OS X XCODE TOOLCHAIN
    
    The bug was that ASAN support was broken on OS X. The problem is
    that the same CMake symbol used to store the result of ASAN/UBSAN/TSAN
    checks, was also used by the check for the gold linker. Since OS X
    supports ASAN but does not support the gold linker, the symbol
    reuse gave build break.
    
    This bug was a [1;31mregression[m introduced by the patch for:
    Bug #23759968: ENABLE THE GNU GOLD LINKER
    
    This patch fixes the problem by renaming the CMake symbol
    used to store the result of the gold linker check.

[33mcommit 7484a8b0360b6556fe1a6149322a24f9c626db57[m
Author: Annamalai Gurusami <annamalai.gurusami@oracle.com>
Date:   Tue Aug 23 11:22:19 2016 +0530

    Bug #24480254 LOB DELETER NOT DELETING THE LOB PAGES
    
    Problem:
    
    While doing code reading I identified the following problem:
    Code in lob::Deleter::destroy() function is as follows:
    
    1708
    1709                 while (m_ctx.m_blobref.page_no() == FIL_NULL) {
    1710                         err = free_first_page();
    1711                         if (err != DB_SUCCESS) {
    1712                                 break;
    1713                         }
    1714                 }
    1715
    
    The while condition should contain != instead of ==.  This means that
    the LOB deleter is not really deleting the LOB pages.  This is a
    [1;31mregression[m introduced by me in WL#9141 InnoDB: Refactor uncompressed
    BLOB code to facilitate partial fetch/update.
    
    Solution:
    
    The while condition should check that the page_no in the LOB
    reference is not equal to FIL_NULL.
    
    WIP.

[33mcommit e359ebc26ea3c193f52dbb06475137f94bd3c07c[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Wed Aug 17 09:43:37 2016 +0200

    WL#6599 - New Data Dictionary and I_S integration.
    
    Post-push patch fixing POINT_SELECT performance [1;31mregression[m fix.
    
    The patch does following improvement in open_tables() call flow,
    
    1 We were invoking dd::Dictionary::is_system_view_name() several
      times for a table. E.g., SELECT_LEX::add_table_to_list() would
      already know that if a TABLE_LIST is a system view. We were not
      setting TABLE_LIST->is_system_view here.  This patch sets this in
      SELECT_LEX::add_table_to_list() and avoids calls to
      dd::Dictionary::is_system_view_name() function call which goes
      throw all the system view names within the open_tables() call flow.
    
    2 We also avoid call to dd::Dictionary::is_dd_table_name().
      Basically there are two possibilities of open_tables() call seeing
      a DD tables.
    
      a) DD table being opened as part of DD operations invoking
         dd::Open_dictionary_tables_ctx::open_tables().
    
      b) DD table being opened as part of I_S system view execution.
    
      During open_table(), we need to know if a TABLE_LIST belongs to a
      DD table for several checks. Currently we do that by invoking
      dd::Dictionary::is_dd_table_name() which is a looking in a list.
      We can avoid that as described below.
    
      When open_table() is opening a DD table in case of a), the
      table_list used there is nothing but dd::Raw_table::m_table_list.
      And we are sure that this belongs to only DD tables. So, this
      patch adds a member TABLE_LIST->is_dd_table, which is set only by
      dd::Raw_table.  So the open_table() call now uses it.
    
      For b), we know that TABLE_LIST->is_system_view is marked for all
      the I_S system views. And
      TABLE_LIST->referencing_view->is_system_view would tell us that
      the TABLE_LIST is refering to a DD table. So, this avoids calls
      to dd::Dictionary::is_system_view_name().
    
    3 The function TABLE_SHARE::get_table_ref_version() is invoking
      both dd::Dictionary::is_dd_table_name() and
      dd::Dictionary::is_system_view_name().  This is a overhead.  This
      patch adds a TABLE_SHARE->table_category called
      TABLE_CATEGORY_DICTIONARY. This helps us avoid call to
      is_dd_table_name(). And use TABLE_SHARE->view_object->type() ==
      dd::enum_table_type::SYSTEM_VIEW to check if that is a system view.
    
    4 The patch does following change, that is not necessarily to
      improve the permformance. Basically the revno 56eaef86 sets
      MYSQL_OPEN_IGNORE_FLUSH flag while opening DD tables in
      Open_dictionary_tables_ctx::open_tables().  And later the revno
      11eeb00a removes this flag, expecting open_table() to set it for
      DD tables. Conceptually it looks correct to set this flag for all
      DD table at Open_dictionary_tables_ctx::open_tables() so this
      patch retain setting of this flag as done by revno 56eaef86.
      These revno are from mysql-trunk-wl6599-1 branch.

[33mcommit b435c4893f32e0c8ad197e95bd3c051dcf201f62[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Wed Aug 17 09:43:37 2016 +0200

    WL#6599 - New Data Dictionary and I_S integration.
    
    Post-push patch fixing POINT_SELECT performance [1;31mregression[m fix.
    
    The patch does following improvement in open_tables() call flow,
    
    1 We were invoking dd::Dictionary::is_system_view_name() several
      times for a table. E.g., SELECT_LEX::add_table_to_list() would
      already know that if a TABLE_LIST is a system view. We were not
      setting TABLE_LIST->is_system_view here.  This patch sets this in
      SELECT_LEX::add_table_to_list() and avoids calls to
      dd::Dictionary::is_system_view_name() function call which goes
      throw all the system view names within the open_tables() call flow.
    
    2 We also avoid call to dd::Dictionary::is_dd_table_name().
      Basically there are two possibilities of open_tables() call seeing
      a DD tables.
    
      a) DD table being opened as part of DD operations invoking
         dd::Open_dictionary_tables_ctx::open_tables().
    
      b) DD table being opened as part of I_S system view execution.
    
      During open_table(), we need to know if a TABLE_LIST belongs to a
      DD table for several checks. Currently we do that by invoking
      dd::Dictionary::is_dd_table_name() which is a looking in a list.
      We can avoid that as described below.
    
      When open_table() is opening a DD table in case of a), the
      table_list used there is nothing but dd::Raw_table::m_table_list.
      And we are sure that this belongs to only DD tables. So, this
      patch adds a member TABLE_LIST->is_dd_table, which is set only by
      dd::Raw_table.  So the open_table() call now uses it.
    
      For b), we know that TABLE_LIST->is_system_view is marked for all
      the I_S system views. And
      TABLE_LIST->referencing_view->is_system_view would tell us that
      the TABLE_LIST is refering to a DD table. So, this avoids calls
      to dd::Dictionary::is_system_view_name().
    
    3 The function TABLE_SHARE::get_table_ref_version() is invoking
      both dd::Dictionary::is_dd_table_name() and
      dd::Dictionary::is_system_view_name().  This is a overhead.  This
      patch adds a TABLE_SHARE->table_category called
      TABLE_CATEGORY_DICTIONARY. This helps us avoid call to
      is_dd_table_name(). And use TABLE_SHARE->view_object->type() ==
      dd::enum_table_type::SYSTEM_VIEW to check if that is a system view.
    
    4 The patch does following change, that is not necessarily to
      improve the permformance. Basically the revno 56eaef86 sets
      MYSQL_OPEN_IGNORE_FLUSH flag while opening DD tables in
      Open_dictionary_tables_ctx::open_tables().  And later the revno
      11eeb00a removes this flag, expecting open_table() to set it for
      DD tables. Conceptually it looks correct to set this flag for all
      DD table at Open_dictionary_tables_ctx::open_tables() so this
      patch retain setting of this flag as done by revno 56eaef86.
      These revno are from mysql-trunk-wl6599-1 branch.

[33mcommit 3b1718b8150ea92166111798c5dc6a11a0e4bfeb[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Thu Aug 11 11:16:28 2016 +0800

    BUG#24287290 BUF POOL MUTEX ORDER VIOLATION IN BUF_POOL_RESIZE
                 WITH MULTIPLE INSTANCES
    
    It's a [1;31mregression[m of wl#8423: InnoDB: Split the buffer pool mutex.
    
    In buf_pool_resize(), we enter all buffer pool mutexes for each
    buffer pool instance. we should enter a mutex a time for all
    intances to avoid mutex violation.
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 13614

[33mcommit 8d5089b714b8f768c4a62389e638ab5e1f95814f[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Tue Aug 2 15:20:08 2016 -0700

    Bug #23020280: INNODB_BUG56143.TEST FAILURE
    - COUNT_ALLOC IN MEMORY_SUMMARY_GLOBAL_BY_EVENT_NAME IS NOT 0
    
    This patch is more complete than the last one since it adds 13 modules that contain
    some form of the case insensitive grep for "ut_malloc", "ut_alloc" and "ut_new".
    The previous patch that was reverted missed 5 modules and it caused a [1;31mregression[m
    on PB2 because a performance schema array size was no longer large enough.
    Here, PFS_MAX_MEMORY_CLASS is increased to 350 from 320 so that there is
    more room for new modules.

[33mcommit 2729678b95c9d5866fb5ff1fe13bbefc397e9295[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Thu Jul 28 15:34:35 2016 +0200

    Bug#24365738: MYSQLTEST MAY FAIL TO COMPILE BECAUSE
                  MYSQLCLIENT_ERNAME.H NOT YET GENERATED
    
    The problem was that building of mysqltest could fail
    since it depended on GenClientError (and GenError) and these
    targets might not have finished.
    
    This patch fixes the problem by adding the missing
    depedencies to mysqltest.
    
    This was a [1;31mregression[m caused by the patch for
    Bug#21048973 SUPPORT "--ERROR CR_..." FOR COMMUNICATION RELATED ERRORS

[33mcommit e376b3ce44bcc94937e831dbedc78d84bddfa3fe[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Thu Jul 7 22:10:09 2016 +0800

    BUG#23739332 INNODB: VARIABLE UNDECLARED ERROR WITH -DDISABLE_PSI_THREAD=1
    
    It's [1;31mregression[m of WL#9359 - Change to std::thread
    
    Redefine os_thread_create() using __VA_ARGS__.
    
    Reviewed-by: Sunny Bains <sunny.bains@oracle.com>
    RB: 13240

[33mcommit a0d0cab0304389f5a1135ba4157c01236e0d80e9[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Thu Jun 30 16:00:31 2016 +0200

    WL#8971: Deprecate and remove partitioning storage engine
    
    This worklog implements the following main changes:
    
    1. Modify cmake files, do not build partitioning engine.
    2. Remove files implementing the partitioning engine.
    3. Remove some mtr tests using non-native partitioning.
    4. Rewrite some mtr tests to use native partitioning.
       Various adjustments necessary, e.g. regarding EXPLAIN
       output.
    5. Introduce error handling at the SQL layer to fail
       if using partitioning related DDL statements for
       engines not supporting it natively.
    6. Remove reference to the DB_TYPE_PARTITIONING_DB
       internally, but keep the enum entry to avoid
       disturbing other values.
    7. Add an mtr test testing the error handling.
    8. Add an mtr test to check for [1;31mregression[ms in support
       for partitioning in ndb.
    9. Copy comments from storage/partition/ha_partition.*
       to sql/handler.*, include/my_base.h etc.

[33mcommit c4f655a9aebff04ab4b0859a7ea4e5173a636727[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Wed Jun 22 12:14:02 2016 +0530

    Bug #23225800: NDB_DD_DUMP TEST FAILING ON ALL PLATFORMS
    
    (Server Bug #23259328: NDB_DD_DUMP TEST FAILING DUE TO CHANGE IN
     MYSQLDUMP)
    
    Problem: Fix for Bug#21382184 caused a [1;31mregression[m making ndb dump
    test to fail. Reverted minor part of the code as part of the fix.
    
    (cherry picked from commit cc696659a035448af3a8f42371fd9a5b5def83cd)

[33mcommit 9ac74502201a24a2aba9f7e22e50afdae8be7e66[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Tue Jun 21 10:27:01 2016 +0800

    BUG#22885524 RW_LOCK_OWN(HASH_LOCK, RW_LOCK_X)
                 || RW_LOCK_OWN(HASH_LOCK, RW_LOCK_S)
    
    It's a [1;31mregression[m of rb#9797(wl#8423 InnoDB: Split the buffer pool mutex).
    
    If we don't hold buf_pool->LRU_list_mutex, etc, page hash can be changed
    by buf_pool_resize(), so we need to use buf_page_hash_lock_s_confirm or
    buf_page_hash_lock_x_confirm to confirm hash lock, otherwise assert fails.
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 13009

[33mcommit cbc524750c486e9fde8266439979476964917bbb[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Wed Jun 8 10:29:10 2016 +0800

    BUG#23067038 ASSERTION FAILURE: BUF0BUF.CC:2861:BUF_PAGE_IN_FILE(BPAGE)
                 LEADS TO CORRUPT DATA
    
    It's a [1;31mregression[m of wl#8423 InnoDB: Split the buffer pool mutex.
    
    There is a race: Thread 1, we set buf_fix_count to 0 in buf_page_init().
    Thread 2, we decrease buf_fix_count to 0xffffffff in buf_page_optimistic_get().
    Thread 2, we increase buf_fix_count to 0 in buf_page_get_gen(). Thread 3,
    we evict the page from LRU list. Thread 2, assert fails: buf_page_in_file().
    
    The root cause is missing block mutex protection for buf_page_init().
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 12456

[33mcommit 4725662f61ddf768995bc4c352c521f127924624[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Fri May 27 16:55:24 2016 +0530

    BUG#23474669 : MTR: PRESENCE OF CHECK-WARNINGS.LOG IN VARDIR/TMP CAUSES CHTEST FAILURE
    
    Description :
    =============
    Presence of check-warnings.log in VARDIR/tmp causes chtest to
    fail due to a result content mismatch in the check for the
    directory's contents. This seems to be a [1;31mregression[m introduced
    by the fix for Bug#18274766.
    
    The CHECK TESTCASES module of chtest checks for the contents of
    $MYSQLTEST_VARDIR/tmp directory and finds an extra file present
    leading to a mismatch of files.
    
    Fix :
    =====
    Since check-warnings.test doesn't produce any output, delete the
    check-warnings.log file generated after the check-warnings test
    run is completed.
    
    Reviewed-by: Srikanth B R <srikanth.b.r@oracle.com>
    RB: 12822

[33mcommit 7bb89905d02cd7f78bf73c268c431e4677818ae2[m
Author: Annamalai Gurusami <annamalai.gurusami@oracle.com>
Date:   Wed May 25 15:13:56 2016 +0530

    Bug #23259754 SYS_VARS.INNODB_NUMA_INTERLEAVE_BASIC.TEST NEVER RUNS
    
    Problem:
    
    Binaries are not built with NUMA feature even if it is available and
    requested by the user.  This is a [1;31mregression[m caused by (rb#11231):
    
    commit bf050ecc5c80f72ad068b0228324bebed9064def
    Author: Annamalai Gurusami <annamalai.gurusami@oracle.com>
    Date:   Mon Dec 7 12:40:49 2015 +0530
    
    This patch attempted to use WITH_NUMA for conditional compilation,
    which is wrong.
    
    Solution:
    
    The WITH_NUMA is a cmake variable and is not available as a macro
    to the compiler.  So we should not be using it in #if or #ifdef.
    Instead use WITH_NUMA to control the value of HAVE_LIBNUMA, which
    can be used for conditional compilation.
    
    rb#12650 approved by Shaohua and Tor.

[33mcommit d887a49e84a618e150dfa90d3b977614dc0cb020[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Thu May 19 20:33:06 2016 +0800

    BUG#23136397 ASSERTION FAILURE: BUF0BUF.CC:5410:RW_LOCK_IS_LOCKED
                 (&BLOCK->LOCK, RW_LOCK_X)
    
    It's [1;31mregression[m of wl#8423 InnoDB: Split the buffer pool mutex.
    
    We should protect buf_page_set_io_fix(&block->page, BUF_IO_READ)
    and rw_lock_x_lock(&block->lock) by buf_pool->LRU_list_mutex.
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 12707

[33mcommit 968ef0ed0300c8eed08f268cb54ff684ea230db8[m
Author: Annamalai Gurusami <annamalai.gurusami@oracle.com>
Date:   Tue May 17 16:36:39 2016 +0530

    Bug #23259754 SYS_VARS.INNODB_NUMA_INTERLEAVE_BASIC.TEST NEVER RUNS
    
    Problem:
    
    Binaries are not built with NUMA feature even if it is available and
    requested by the user.  This is a [1;31mregression[m caused by
    
    commit 73b6f6dfc7056358414cd3dc72cbda6fa523635f
    Author: Vasil Dimov <vasil.dimov@oracle.com>
    Date:   Tue Jul 21 11:03:25 2015 +0300
    
    Solution:
    
    The WITH_NUMA is a cmake variable and is not available as a macro
    to the compiler.  So we should not be using it in #if or #ifdef.
    Instead use WITH_NUMA to control the value of HAVE_LIBNUMA, which
    can be used for conditional compilation.
    
    Also, an unwanted error log message is removed.
    
    rb#12650 approved by Shaohua.

[33mcommit bd914aebb3ec510784f364e5e71cd35bb8a0cad5[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Thu Apr 28 16:28:07 2016 +0800

    BUG#23102834 INNODB: ZERO FLUSH FROM LRU
    
    It's a [1;31mregression[m of wl#8423 InnoDB: Split the buffer pool mutex.
    we wrongly removed the count for lru flushing in buf_flush_batch().
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 12509

[33mcommit 65649a16ce9412f7d9286e7e6ad6c2de5769be25[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Thu Apr 21 13:34:00 2016 +0800

    BUG#23067038 ASSERTION FAILURE: BUF0BUF.CC:2861:BUF_PAGE_IN_FILE(BPAGE)
                 LEADS TO CORRUPT DATA
    
    It's a [1;31mregression[m of wl#8423 InnoDB: Split the buffer pool mutex,
    in which we removed block mutex protection for buf_fix_count.
    
    The assertion happens when one thread fixed a dirty block but the
    other thread flushed the block and moved the page from LRU list to
    free list, because it saw buf_fix_count is 0, other than 1.
    
    The solution is holding block mutex when buf fix and unfix.
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 12456

[33mcommit 3dfc79ee38f19c30a597ec2a24de1198bd646c74[m
Author: Srikanth B R <srikanth.b.r@oracle.com>
Date:   Tue Apr 5 06:46:11 2016 +0530

    WL#8982 - QUALIFY MAIN SUITE WITH DIFFERENT BINLOG MODES
              AND ADD TO WEEKLY PUSHBUILD RUN
    
    All tests in the main suite which are run when 'perl mysql-
    test-run.pl --suite=main' is executed have been qualified
    to run with binary logging enabled in row and mixed modes.
    Also, regular pushbuild [1;31mregression[m runs have been introduced
    in weekly-trunk to test the main suite with binary logging
    in row and mixed binlog formats.
    
    Reviewed by :
    Lalit Choudhary <lalit.choudhary@oracle.com>
    Vinay Fisrekar  <vinay.fisrekar@oracle.com>
    RB: 12057

[33mcommit f7361ce37a2628c5d66b567fb189733554b751eb[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Thu Mar 31 11:11:32 2016 +0300

    Bug#23028144 CORE STACK NOT SHOWING ASSERTION
    
    This is a [1;31mregression[m from
    Bug#22996442 INNODB: MAKE UNIV_DEBUG DEPEND ON DBUG_OFF, AND REPLACE
    REFERENCES TO DBUG_OFF.
    
    When ut_ad() was made an alias of DBUG_ASSERT(), which in turn is an
    alias of assert(), the assertion expression would not necessarily
    any longer be in the call stack, depending on the implementation of
    assert().
    
    The fix is to make ut_ad() an alias of ut_a() like it used to be,
    but also improve ut_dbg_assertion_failed() so that it displays
    the file name, line number and assertion expression in a single line,
    for easier viewing of the error logs.
    
    ut_dbg_assertion_failed(): Use sql_print_error() to display the
    file name, line number and message in a single line, and the thread ID
    in a subsequent line.
    
    Adjust some tests to suppress warnings about the sql_print_error()
    messages for assertion failures, including ib::fatal().
    
    RB:12295
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 59f0e98e8f295c30296c52050e001dba7b549f2f[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Thu Mar 17 11:08:10 2016 +0200

    Bug#22885524 RW_LOCK_OWN(HASH_LOCK, RW_LOCK_X) || RW_LOCK_OWN(HASH_LOCK, RW_LOCK_S) Bug#22898711 SERVER HANG WITH SRV_THREAD_CONCURRENCY 8
    
    The bugs are [1;31mregression[ms of
    Bug#22663240 NEVER READ A PAGE IN BUF_PAGE_CREATE().
    
    The fix is to revert that patch for now.
    
    This reverts commit 9109a04240ee19c11636b8f3f7a81a038b373660
    Bug#22742918 ASSERT BUF_PAGE_GET_IO_FIX(BPAGE)==BUF_IO_NONE, BUF_RELOCATE()
    and commit a7d6c402f5adb26e04935f25e38c560ba122122e
    Bug#22663240 NEVER READ A PAGE IN BUF_PAGE_CREATE().

[33mcommit 67e3c26e6e3ba3af8dbb88d9bac61571bf732307[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Tue Mar 1 15:55:55 2016 +0100

    Bug#22376177: MAIN.VIEW_GTID_MODE_ON_DEBUG.TEST THROWS
                  CORE DUMP WHEN RUN WITH SC_56=OFF
    
    Move a DBUG_EXECUTE_IF added as part of the [1;31mregression[m test for
    Bug#21463167 so that the [1;31mregression[m test becomes compatible with
    running with SHOW_COMPATIBILITY_56=OFF and does not trigger an
    assert in debug mode.

[33mcommit 93d1cbfa0e8b0a38cd4b820ba70aa901bb2609bf[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Mon Feb 1 09:51:14 2016 +0100

    WL#8150: Dictionary cache
    
    Post-push fix of a doxygen [1;31mregression[m.

[33mcommit ca239bab3220afcf1fc79cc240d55b8801595847[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Tue Jan 26 14:21:45 2016 +0100

    Bug #22477433: TABLE WITH UNKNOWN COLLATION CRASHES MYSQL
    
    The global DD has caused [1;31mregression[ms in the handling of
    invalid collations. This patch will report an error
    instead of asserting when opening a table definition
    where a column refers an invalid collation.

[33mcommit 87b570ca652d97b36a4f8311d9a6fd2814fac783[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jan 15 12:36:03 2016 +0100

    Another follow up patch for performance [1;31mregression[m introduced by patch for bug#20957068
    
    Previous patch introduce the usage of the non-portable sched_yield().
    This patch change that to use pthread_yield() which is defined in
    include/my_pthread().
    
    (cherry picked from commit c7a844a8e373633c4a3e91be7af3f789d19d4fbb)

[33mcommit f1fd8b7e7f6382f4ef1c83b4b7702b5773a47f9c[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jan 15 09:55:05 2016 +0100

    Follow up patch for performance [1;31mregression[m introduced by patch for bug#20957068
    
    Introduce some sched_yield() in the binlog-thread loops where
    the injector_mutex is held >99% if the elapsed time. The yields
    let other threads waiting to be scheduled a chance to run,
    and grab the injector_mutex when not held by the binlog-thread.
    
    (cherry picked from commit 000394fbe3a8d7a2945fb6b483024b77e16ab20a)

[33mcommit edb538c4b1ba2db8599d06c0f45e7ae858fb6360[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jan 15 12:36:03 2016 +0100

    Another follow up patch for performance [1;31mregression[m introduced by patch for bug#20957068
    
    Previous patch introduce the usage of the non-portable sched_yield().
    This patch change that to use pthread_yield() which is defined in
    include/my_pthread().

[33mcommit ab386d5c0faf316f451a81a811dc53580a62f7f4[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jan 15 09:55:05 2016 +0100

    Follow up patch for performance [1;31mregression[m introduced by patch for bug#20957068
    
    Introduce some sched_yield() in the binlog-thread loops where
    the injector_mutex is held >99% if the elapsed time. The yields
    let other threads waiting to be scheduled a chance to run,
    and grab the injector_mutex when not held by the binlog-thread.

[33mcommit 30ed9d3a3cdd19bd7162e56e42fdce54de1fa068[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Fri Nov 13 17:16:59 2015 +0100

    Bug#22110284: RBR CONVERSION FROM SMALLER MASTER TYPE TO BIGGER SLAVE TYPE IS BROKEN
    
    Problem: Replication from MEDUMTEXT to LONGTEXT would truncate columns
    to 2^16-1 bytes, when running with the new data dictionary.
    
    The [1;31mregression[m was caused by a tightening of the requirement on the
    type argument passed to make_field (via
    Create_field::init_for_tmp_table()) which had been done as part of the
    new dictionary work. With this tightening the exact blob subtype was
    no longer being deuced from pack_length inside make_field().
    
    Since only the pack_length and not the blob subtype is recorded in the
    binlog, this resulted in the conversion table on the slave being
    created with column type MYSQL_TYPE_BLOB rather than MYSQL_TYPE_MEDIUM_BLOB,
    as the pack_length was no longer taken into consideration.
    
    Solution: Use the replicated pack_length to detect the actual BLOB
    type when creating the conversion table at the slave.

[33mcommit 0e47d8b7c5f97870980b6fd876ebbd3a17a19f78[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Dec 2 15:15:33 2015 +0100

    Followup patch for bug#22135584. Fix [1;31mregression[m.
    
    When the binlog thread was not binloging, it should
    only handle 'non-data events' arriving at the 'i_ndb'.
    
    The loop doing this was rewritten by the patch for
    bug#22135584. Unfortunately there were no initial nextEvent()
    after the pollEvents() call, such that i_pOp was always NULL.
    Thus, the non-data events were never handled, which resulted
    in node failures never being acted upon, and then got stuck in
    read only mode forever.
    
    This patch fixes this by doing a small refactorication:
    The special pollEvents() case for 'not binlogging' has been
    removed and instead integrated as part of the normal
    'i_ndb->pollEvents()'.
    
    Furthermore, the calculation of 'current_epoch' has been
    moved into the function find_epoch_to_handle().

[33mcommit 76c30f54816989da99a0eb9d05593dbb9edf2654[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon Nov 30 14:07:47 2015 +0100

    Follow up patch for bug#22135584
    
    Fix a [1;31mregression[m introduced by prev. batch for above bug:
    
    When calculating the current_epoch to handle events from,
    we didn't take the 'no-binlogging' case into considderation.
    
    When there are no binlogging, the 'i_epoch'
    (and ndb_latest_received_binlog_epoc) is '0'. This caused
    'current_epoch' to always be calculated as '0' as well, effectively
    causing no (schema-)events to ever be handled by the BI-thread.

[33mcommit 7efcb619c4c2c72a6d55a5036c805c7052997242[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Nov 12 09:12:18 2015 +0100

    Bug#22188058 CRASH IN MY_DECIMAL::SANITY_CHECK AND MY_DECIMAL2BINARY
    
    Problem: select .... order by (unsigned decimal op) crashes, since
    filesort() does not handle NULL pointer return.
    
    This is a [1;31mregression[m from the patch for
    Bug#22083757 FLAGS INFO IN RESULT META DATA IS INCORRECT ( NEGATIVE NUM W/ "UNSIGNED")
    
    Solution: same as elsewhere: return decimal zero rather than NULL pointer.

[33mcommit 6113174cb16c3615b9e7fcac80fd0c37a97a9505[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Fri Nov 13 14:49:35 2015 +0800

    Bug#22186558 - ALTER TABLE...TRUNCATE PARTITION FORGETS KEY_BLOCK_SIZE
    
    This could be a [1;31mregression[m of WL#6795. During TRUNCATE of one partition
    of partition table, we should remember the key_block_size like what we do
    in non-partition InnoDB table.
    
    RB: 11035
    Reviewed-by: Marko Makela <marko.makela@oracle.com>

[33mcommit dbfa680e568a59f10df6c664e86f9e06719dad2d[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Thu Oct 29 16:52:19 2015 +0100

    Bug#17234686: Refactor Item: Complete constructor and reorder fields
    
    This is spun out of the work for bug 68825/16598320:
    Performance [1;31mregression[ms for single-threaded workloads
    
    This patch simplifies the structure of class Item by collecting fields
    by size (widest first) to avoid gaps, and creates a proper constructor.
    
    The basic Item object is reduced in size from 152 to 144 bytes.
    
    Without counting padding, object size is now 137 bytes.
    
    It was chosen not to inline the constructor, as objects of this class
    are used in numerous other classes, and we are unsure if the inevitable
    code bloat is good for high-concurrency workloads.
    
    However, a few constructors for derived classes have been inlined.
    
    Some invalid todo comments were removed from definition of enum enum_walk.
    
    Some fields have changed type from my_bool to bool.
    
    The "rsize" field was unused and has been removed.
    
    A couple of virtual functions were removed from class SELECT_LEX,
    since there is no need for this class to be virtual.

[33mcommit 3dd56bef99ad4292f5f4b2122b98135ef9bc5d15[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Sep 30 11:03:00 2015 +0200

    Revert of patch for bug#21886157
    
    Caused severe [1;31mregression[ms in MTR and ATR tests

[33mcommit 52042b2759926a41f4c0d84383f08ba6648ca7f7[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Mon Aug 17 19:39:03 2015 +0200

    Bug#21616263 NDB : DROPEVENTOPERATION INTERNAL RETRIES CORRUPT M_ACTIVE_OP_COUNT
    
    Count of active subscriptions for NdbEventBuffer could be
    decremented more one once if stopping subscription failed due to
    for example busy server.  Count could also fail to decrement if
    communication with data node fore example timed out.
    
    This was a [1;31mregression[m introduced with:
    commit 50a55ef9520ff0c8cb1c9e4a825f8bfec191afbd
    Author: Mauritz Sundell <mauritz.sundell@oracle.com>
    Date:   Thu Mar 19 13:50:08 2015 +0100
    
        Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS
        Bug#20561446 NDB : NDBEVENTBUFFER NEEDS MORE THREADING PROTECTION

[33mcommit c1d398449b9927d1e25ee85bc932bff761047444[m
Author: Annamalai Gurusami <annamalai.gurusami@oracle.com>
Date:   Fri Jul 31 12:18:51 2015 +0530

    Bug #21520379 ASSERT AT BTR_FREE_EXTERNALLY_STORED_FIELD IN BTR0CUR.CC
    
    Problem:
    
    This is a [1;31mregression[m from the fix for Bug# 18195972 CODE CLEANUP
    RELATED TO BLOB OWNERSHIP AND INHERITANCE (rb#9508).  In the
    function btr_store_big_rec_extern_fields(), the local variables
    blobref and field_ref must be kept in sync with each other.  In one
    place, when field_ref was modified, blobref was not updated.
    
    Solution:
    
    Keep blobref and field_ref in sync with each other in function
    btr_store_big_rec_extern_fields().
    
    rb#9795 approved by Krunal.

[33mcommit 3d6293a288cd1750f4ca10d8715ee4d8efbdc8e5[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Mon Jul 13 20:08:53 2015 +0200

    Bug#21337139 ATRT SILENTLY STOPS TESTING AT FIRST SYNTAX ERROR IN TEST CASE FILE
    
    Post push fix of test [1;31mregression[m.
    
    ATRT no longer fail after last test case executed.
    
    Also now detects bad element lines which miss colon (:) or equality
    sign (=) that earlier faulty terminated a test case description.

[33mcommit 206b7bdbc114e7505fb52d8349a4433be22caf48[m
Merge: 8358d59e0ed 7d8937daf6f
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Jul 13 19:17:19 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      BUG#21389101 ST_GEOMFROMGEOJSON: STACK OVERFLOW IN RAPIDJSON::GENERICREADER
      Bug#21383284: ASSERTION IN SELECT_LEX::SETUP_CONDS
      BUG#21303289  Removed sqlbench leftover in deb platform pkg src
      BUG#21434004   UBUNTU 15.04 REPO PACKAGES DO NOT CONTAIN ESSENTIAL SCRIPT LIKE MYSQLD_SAFE list of files being re-installed in server pkg: +usr/bin/mysqlbinlog +usr/bin/mysqld_multi +usr/bin/mysqld_safe
      Remove MCP_GLOBAL_SCHEMA_LOCK patch
      Fix syntax error in ndbinfo_sql.cpp
      Fixed mysql_ssl_rsa_setup test failing on Windows after pushing bug fix for bug#21025377
      BUG#21280816 CONNECTION PERFORMANCE REGRESSION TEST HANGS SYSBENCH
      Keep ndbinfo_sql.ccp in sync with mysql_system_tables.sql
      Remove unintentional change in variables-big.test
      Bug #20168526 YASSL: CORRUPT SSL-KEY CRASHES CLIENT
      Version change in d/changelog for DEB pkg src 5.7.9+ are non-rc releases
      - Bug#21407023: DISABLING AHI SHOULD AVOID TAKING AHI LATCH   Currently if AHI is disabled check for it was protected by AHI latch which   caused latch overhead even though the feature is not adding any value.
      Bug#21429471 - COMMUNITY/COMMERCIAL EL7 UPDATE FAILING WHEN MARIADB-BENCH.X86_64 INSTALLED
      Bug #20728894: MEMORY LEAK IN ADD_DERIVED_KEY()
      Bug #21056907: CONTENTS OF NOT REQUESTED CHAR/VARCHAR                COLUMN ARE REVEALED
      Bug #20777016: DELETE CHECKS PRIVILEGES ON THE WRONG                DATABASE WHEN USING TABLE ALIASES
      Bug #18636874 PASSWORD VALIDATE PLUGIN: DICTIONARY CHECK MISBEHAVES WITH GOOD HEX INPUT
      WL#7254 Audit API extensions
      Bug#21374104 SETUP_TIMERS INITIALIZATION ASSUMES CYCLE TIMER IS ALWAYS AVAILABLE
      Bug #20087571: 5.7 EASILY HITS ERROR 1436 (HY000): THREAD STACK OVERRUN ERRORS ON MANY EXPR'S
      Bug#21383896 DECIMAL FIELD TAKES IN VALUES FROM OTHER FIELDS
      Bug#21153489 VALGRIND ERRORS IN ITEM_BOOL_FUNC2::IS_NULL LEAD TO CRASH LATER
      Fix syntax errors in 16node-tests.txt and upgrade-tests.txt
      Bug#21337139 ATRT SILENTLY STOPS TESTING AT FIRST SYNTAX ERROR IN TEST CASE FILE
      Fix a compilation error after bc098885
      Bug#21338012 MTR MANUAL-GDB OPTION DOES NOT WORK
      Bug #21280801: VERSION TOKEN LOCKING DOES NOT WORK
      BUG#21421471 LICENSE HEADERS MISSING IN FILES
      Bug#21300774 ASSERT `!INIT_FTFUNCS(THD, SELECT_LEX)` IN JOIN::RESET AT SQL/SQL_SELECT.CC:874
      Bug#21300774 ASSERT `!INIT_FTFUNCS(THD, SELECT_LEX)` IN JOIN::RESET AT SQL/SQL_SELECT.CC:874
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      BUG#20074353 HANDLE_FATAL_SIGNAL (SIG=11) IN MY_B_WRITE | MYSYS/MF_IOCACHE.C:1597
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      Addendum 2 to bug #21034322: removed the max test due to it being different for different OSes
      Follow up fix for WL#8149 change, fix create_thd() issue and test mismatches
      Merge WL#8149 related worklogs to mysql-trunk
      Bug#21271736 UNITTEST UT0CRC32-T HANGS ON SOLARIS 10 SPARC
      Bug#21381060 A "CASE WHEN" EXPRESSION WITH NULL AND AN UNSIGNED TYPE GIVES A SIGNED RESULT
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Remove non experimental test.
      Bug#18949282 I_MAIN.MYSQL_CLIENT_TEST FAILED AT LINE 43, COMMAND $I_M_C_T
      Configure smaller redo log for test ndb.ndb_backup_rate.
      Updating the test case ndb_addnode_restart* :  The autotest testSystemRestart had an additional restart loop  in runAddNodesAndRestart function, which is not needed as there  is no change in the configuration of the cluster.  Removed that and updated the name of the funcction and added few  comments to explain the proper setup of the testcase
      Fix for WL#7763
      WL#7763, remove use of inet_ntoa from ndb parts
      Post-push test fix for Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      Bug#17493646 NDB: CALL TO MY_ERROR() LACKS ERROR CODE AND ERROR STRING ARGUMENTS
      Bug#21352763 FLEXASYNC SEGFAULTS IF FAILED TO CREATE TABLES
      BUG#21297407: Fix to ensure sending CONTINUEB with proper variables in dropTable_wait_usage
      Pushing BUG#21297407 revealed an uninited variable in Fragrecord in DBLQH (lcp_frag_ord_state, was set to LCP_QUEUED == 0 in most cases which led to crash if drop table happened before LCP had time to execute
      BUG#20981491: Fix resource issues for NR, LCP andb Backup with regard to scan numbers, BUG#21362758: Crash with holding LocalDLFifoList context over call EXECUTE_DIRECT(NEXT_SCANCONF), BUG#21370839: Ensure also ACC scans are queued in a proper manner, previous push only added test case to autotest
      BUG#20981491: Fix resource issues for NR, LCP andb Backup with regard to scan numbers, BUG#21362758: Crash with holding LocalDLFifoList context over call EXECUTE_DIRECT(NEXT_SCANCONF), BUG#21370839: Ensure also ACC scans are queued in a proper manner
      BUG#20993380: (Also BUG#69994 in community bugs), ensured that node recovery and LCP scans can continue even if user has used up all resources for user level transactions, reserved operation records and segments for necessary things during LCP and NR scans
      Fix test case testRedo -n RedoFull
      Fix testRedo -n RedoFull test case
      BUG#21297407: Speed up drop table
      Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Raise version number after cloning 7.1.36
      Raise version number after cloning 7.3.10
      Raise version number after cloning 7.4.7
      Raise version number after cloning 7.2.21
      Fixed syntax errors in daily-basic-tests.txt
      Implement required methods in clusterj-openjpa
      Bug#20504741 Improve clusterj release of byte buffers by adding a user method session.release
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7570 Remove ifdefs which are not necessary since trunk has it all
      Bug #20592110         CLUSTER CIRCULAR REPLICATION WITH IGNORE_SERVER_IDS() BROKEN BY ANONYMOUS_GTIDS
      revert change to mysql-test-run
      Bug #21326540         NDB_JOIN_PUSHDOWN TESTS UNSTABLE EXECUTE_COUNT
      Remove obsolete ifdef
      Add comment re. valgrind
      WL#6815 Adapt MySQL Cluster to 5.7
      Revert "WL#6815 Adapt MySQL Cluster to 5.7"
      Removed extra blank line in ATRT test scripts preventing tests to start (Due to ATRT bug)
      Bug #17878183       NDB CONTINUOUSLY REBOOTING DUE TO FILE NOT FOUND (DBLQH:
      Bug#17493646 NDB: CALL TO MY_ERROR() LACKS ERROR CODE AND ERROR STRING ARGUMENTS
      Increase timeout for ATRT test
      Increase timeout for ATRT test
      BUG#20904721, WL#8525: Fix of part9, used internal TUP pointer instead of LQH pointer when calling LQH function directly, leads to both wrong handling and sometimes even a crash when index is not a used scan pointer
      Apply pollEvent_v4.patch from Ole John
      restore new scheduler & multiwait fix to bug branch
      If memcached crashes, mysql-test-run should not restart it.
      On misc. errors, print workitem to debug log
      always compile ndb memcache with DEBUG_OUTPUT
      More unified error handling
      New record_ndb_error() function where error logger keeps statistics but caller is resposnsible for writing to log file. Direct error messages to the debug log if enabled.
      The table scan code where NDB Memcache reads it configuration tables was written poorly, and could cause memcached to crash during configuration.
      revise debug messages in new scheduler
      switch default scheduler to Trondheim
      always compile ndb memcache with DEBUG_OUTPUT
      More unified error handling
      New record_ndb_error() function where error logger keeps statistics but caller is resposnsible for writing to log file. Direct error messages to the debug log if enabled.
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#11759461 NDB_CONFIG --XML --CONFIGINFO: VARIOUS UPDATES TO PARAMETERS LISTED
      Bug#11760628 DEPRECATE EXECUTEONCOMPUTER
      Bug #21270509         FAULTY COMMENT DESCRIBING NDB_MGM_NODE_STATE.CONNECT_ADDRESS IN MGMAPI.H
      Bug #21270425         MGMAPI.H SPELLING ERROR
      Bug#20617891: NDB : SUSPICIOUS HANDLING OF SIGNAL-WAIT TIMEOUT IN NDBAPI
      read configuration in a single consistent transaction
      The table scan code where NDB Memcache reads it configuration tables was written poorly, and could cause memcached to crash during configuration.
      Revert "Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000"
      Revert "Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000"
      Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      BUG#20904721: Fix for a number of asserts that assumed interpreted mode for all scans
      BUG#20727343: Fix failing ndb_dd_initial_lg test case, minor initialisation issue
      reapply bugfix in this branch. do not push this change to 7.4
      move another message from debug to detail level
      move another message from debug to detail level
      WL#8525: Part 11, don't use interpreted execution for LCPs and Backups since it is a waste of CPU resources
      BUG#20904721: Part 9: Implementing the adaptive LCP speed using bounded delay concepts and A-level signals
      more safety when Ndb::startTransaction() fails
      more safety when Ndb::startTransaction() fails
      add a more detailed debug output level to ndb memcache
      Anticipate SERVER_ERROR responses in My::Memcache.pm
      Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      Test case for Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      induce memcached to flush its log file at end of mtr testing
      BUG#20727343: Fix problems in UNDO log applier when changing log files
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Revert of prev push for bug#20957068
      Fix for Bug#20957068:
      Post merge fixes (mysql-5.6.25 via mysql-5.6-cluster-7.3 into mysql-5.6-cluster-7.4)
      Port commit to MySQL Cluster 7.3
      Port of commit to MySQL Cluster 7.3
      Port of commit to MySQL Cluster 7.3
      Port commit to MySQL Cluster 7.3
      some additional debug output re. online reconfiguration
      Test: temporarily revert recent changes
      Bug#20730053: BACKPORT BUG#19770858 TO 5.1
      Test: temporarily revert recent changes
      Bug#20734434 - SPELLING ERROR \"EMDEDDED\" IN RPM SPEC FILES
      Bug#20788853 MUTEX ISSUE IN SQL/SQL_SHOW.CC RESULTING IN SIG6. SOURCE LIKELY
      Bug#18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Bug#21270190 REMOVE UNUSED AND DANGEROUS NDBHOST_GETHOSTNAME()
      Fix compiler warnings due to hidden inherited virtual and release-unused variables.
      Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Backport of Part 2 (of 2) of fix for Bug#18390321 to 7.2 & 7.3
      bug#17638548 Try to address test failures from previous push
      Reenable usage of send threads in MTR tests.
      Part2 (of 2) fix for Bug#18390321
      Temporarily change default MTR test config to use worker thread sending (No send threads) in order to get some [1;31mregression[m test coverage of part1 patch for bug 18390321
      Bug #17878183         NDB CONTINUOUSLY REBOOTING DUE TO FILE NOT FOUND (DBLQH: CAUSED BY ERROR 2341)
      Part1 (of 2): Fix for Bug#18390321
      bug#17638548 In NDB Memcache 7.4 use 7.3 Scheduler by default
      bug#17638548 : reset "woken" state after wakeups
      Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Fix failing ATRT testcases:
      Increase timeout value for several failing 'testNodeRestart ... DD' tests.
      Fix failing testcase 'testNodeRestart -n GcpStop T1 --loops=1' :
      Added more printout to testcase 'testBasic -n Bug54986 D2' in order to aid in understanding why / where this test fails.
      Increase timeout for  'testNodeRestart -n Bug27003 T1' from 1800 -> 3600sec.
      Moved unstable 'basic' tests to 'devel'.
      Fix compiler warnings in patch for bug#21185585:
      fix bug in cmakelists from previous push
      Convert test_workqueue into a TAP test
      Fix for bug#21185585
      ndb memcache: recently in CLUB testing of ndb memcache suite, 7.4 consistently passes but 7.3 has many failures.  This commit swaps the default schedulers in 7.3 and 7.4 to see if that leads to any change in the pattern of test results.
      ndb memcache: change default scheduler in 7.3
      bug#21067283 Fix inconsistent space calculations in NdbRecord
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      BUG#18234170 Foreign Constraints are lost from NDB Tables during truncate
      Bug#21184102 PATCH FOR BUG#16890703 MYSQLD STUCK IN OPN TABLES ..., LOST IN 7.3 AND UPWARD Added error check for missing database directory, added testcase
      BUG#18234170 Foreign Constraints are lost from NDB Tables during truncate
      WL#8648 NDB_SHARE lifecycle improvements
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7578 Refactor schema distribution code
      WL#8648 NDB_SHARE lifecycle improvements
      Bug#21141495 NDB_MGMD USES 90% CPU
      Remove global forward declaration of Ndb_fk_data
      BUG#20095208: Fix to make portlib not dependent of ndbgeneral
      Removed compiler warning
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Only use C++ ABI functionality if libstdc++ is being linked. Otherwise resort to protect the allocation/deallocation of the static objects using the existing connection mutex.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      Patch for bug#21109605
      Removed compiler warning
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Only use C++ ABI functionality if libstdc++ is being linked. Otherwise resort to protect the allocation/deallocation of the static objects using the existing connection mutex.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      WL#8525: BUG#20904721: Part6: Improve performance of checksum calculations, remove unnecessary ones and simplify bit toggling ones. Also solves BUG#20980229 that ensures that also header bits are included in checksum calculation.
      BUG#20904721: Fix LCP processing with heavy insert activity, part 2
      Improve multi-thread use of charsetDecoder and charsetEncoder in clusterj Utility   charsetDecoder is used only in Decimal decoding   charsetEncoder is used only in Decimal encoding   charsetDecoder and charsetEncoder are not thread-safe   use charset.decode for decoding   use charset.newEncoder().encode for encoding   avoid synchronization
      bug#20095208 - UNABLE TO STORE FRAGMENT DURING LCP. NDBFS ERROR: 2812 - DBLQH (LINE: 14305)
      bug#20095208 - UNABLE TO STORE FRAGMENT DURING LCP. NDBFS ERROR: 2812 - DBLQH (LINE: 14305)
      Bug#18753887 MYSQLD STOPPED WRITING TO BINARY LOG Modifies pollEvents to return latest_GCI as NDB_FAILURE_GCI (~(Uint64)0) in case a cluster failure has been detected. An internal flag is set in NdbEventBuffer::report_node_failure_completed and the flag is reset when the next SUB_GCP_COMPLETE_REP signal is received. Test case StallingSubscriber is extended to verify that NDB_FAILURE_GCI is returned and that polling of events is resumed after the cluster is connected again and new epochs are received.
      Bug#18753887 MYSQLD STOPPED WRITING TO BINARY LOG     Modifies pollEvents to return latest_GCI as NDB_FAILURE_GCI (~(Uint64)0)     in case a cluster failure has been detected. An internal flag is set     in NdbEventBuffer::report_node_failure_completed and the flag is     reset when the next SUB_GCP_COMPLETE_REP signal is received.     Function Ndb::isExpectingHigherQueuedEpochs is added to be used together     with pollEvents2 that checks if cluster has disconnected due to failure     causing no more events to be received.     Test case StallingSubscriber is extended to verify that NDB_FAILURE_GCI     is returned and that polling of events is resumed after the cluster     is connected again and new epochs are received.
      BUG#20904721: Part 8: Fixing the NDB scheduler to work with Bounded delay signals
      Revert last merge
      Fix multi-thread use of charsetDecoder in clusterj Utility   charsetDecoder is used only in Decimal decoding   charsetDecoder is not thread-safe
      Follow up testcase fix for MCP_BUG20701918
      MCP_BUG20701918  create-old-temporals MySQLD option
      BUG#20904721: Fix of previous push
      Fix [1;31mregression[m in debug build caused by fix for bug#20408733.
      WL#8525: BUG#20904721: Part 4, write up description of local LCP protocol and how to handle overload situations, increase to prio level A in some cases. Also standardise naming on END_LCPREQ and END_LCPCONF and remove all usages of END_LCP_REQ and END_LCP_CONF.
      BUG#20904721: WL#8525: Part 3, use prefetch to speed up scan processing for LCP scans and also other full table scans, such as node recovery scans and user level full table scans
      WL#8525: BUG#20904721: Part 7: Ensure it's not so easy to misconfigure LCPs and Backups
      BUG#21049554: Fix OM_SYNC flag to work on all platforms, not only those that support the O_SYNC flag
      WL#8525, BUG#20904721: Part1: Avoid LCP watchdog crash when scanning many pages with LCP_SKIP records
      Fix annoying compiler warnings on Mac OS X
      Fix white space warning in clusterj
      Bug #20504741 Bug #20695155 Improve Clusterj handling of ByteBuffers to reduce direct memory footprint Fix Clusterj incompatibility with Java 7
      Backport My::Memcache.pm improvements from 7.3 This will be null-merged up
      Eliminate some compiler warnings in 3rd party memcached code for NDB Memcache This fix includes both reducing the gcc warning config in CMakeLists.txt and changing two memcached source files. No Oracle copyright is added to the changed 3rd party files.
      Clusterj Trivial bug fix for error displays
      Bug#21055643 REDUCE DEBUG PRINTOUT DURING A GAP AND IMPROVE
      Properly include m_string.h when using my_stpcpy
      Improve comments
      Cache the key_length in NDB_SHARE_KEY
      Provide type safety by using the opaque NDB_SHARE_KEY* type
      Use NDB_SHARE::key_string() instead of direct access to key member
      Move NDB_SHARE::key_length into NDB_SHARE_KEY
      Rewrite the lgive share leak name  to also use NDB_SHARE::create_key
      Move all NDB_SHARE key initialization into NDB_SHARE::creat_key()
      Fix some compiler warnings from memcached sources
      My::Memcache.pm: handle case where the last read before a timeout completed the read buffer. Open a new memcache connection when trying to fetch server error stats.
      Save the prepared key in Ndb_schema_dist_data
      Rename ndbcluster_prepare_rename_share to NDB_SHARE::create_key
      Remove NDB_SHARE::mem_root and instead use my_malloc for dynamic strings
      Change ndcluster_prepare_rename_share to return newly allocated key
      Remove NDB_SHARE::old_names
      Pass the new_key as argument to ndbcluster_rename_share
      Skip ndb_ddl tests with embeddes server
      Change to allocate Ndb_CONFLICT_FN_SHARE bith my_malloc
      Make the NDB_CONFLICT_FN_SHARE an opaque type for users of ndb_share.h
      Remove useless typedefs
      Remove backwards jump into a hoop on fire
      bug#18411034: Remove an unnecessary if-statement
      Print stats for the MEM_ROOT in Ndb_event_data
      Increased the undolog file size from 256MB to 512MB and FragmentLogFileSize from 64MB to 128MB.
      bug#18411034: Assertion gci_ops && (gci == gci_ops->m_gci) failed
      bug#18411034: Assertion gci_ops && (gci == gci_ops->m_gci) failed
      bug#20553313, bug#20707694 - fix index stats query delays
      Bug#20479917 REMOVE MCP_BUG16021021
      Bug#21026199  RANDOM WARNING ORDER NDB_ONE_FRAGMENT
      Addendum to the fix for bug #20681412:
      post push minor test fix for bug:19887143
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug#20234681 HA_NDBCLUSTER USAGE OF FIND_FILES LEAK MEMORY INTO (UNRELEASED) MEM_ROOT
      Move new drop_table test to suite ndbcluster
      Bug#20728189 DROP TABLE SEGFAULTS IF FIRST STATEMENT ON A NEW CONNECTION
      Adding force_restart option to ndb_addnode_restart_setup.inc To force restart servers during retries.
      Bug#20782580: NDB REDO OVERLOAD: ABORT QUEUING REQUESTS IF OUT OF LOG SPACE
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      Added 5 autotest testcases to test node restart with following scenarios. 1. Restarting one node at a time. 2. killing two node of different groups and starting them with and without initial option. 3. Restarting a node which doesn't belongs to node group 0, and checking that it is not associated with node group 0 after restart. 4. killing four node of different groups and starting them with and without initial option. 5. Killing only the master nodes one by one and starting them without initial option.
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      Bug#11762750 TABLE NDBINFO.CONFIG_PARAMS SHOULD BE READ-ONLY (FOR NOW)
      Bug#16731538 MYSQLD CRITICAL FAILURE DURING ORDERED SELECT FROM NDBINFO.CLUSTER_OPERATIONS
      BUG#20075747 RND_INIT() ON AN OPEN SCAN IS USED TO REPOSITION THE CURSOR
      WL#7575 Remove ndbinfo's usage of other engine
      My::Memcache -- longer write timeot
      My::Memcache client, fix bug in read() where desired length is 0
      Remove include/ndb_default_cluster.inc
      WL#8165 Use new records per key interface in NDB
      Fix for Bug#20954804
      Fix for Bug#20954804
      Bug#20782580: NDB REDO OVERLOAD: ABORT QUEUING REQUESTS IF OUT OF LOG SPACE
      Fix a possible crash in AutoTest when an ordered scan encounter error 4008, scan timeout. One such testcase is 'testScan -n ScanRead4880'
      Bug#11760802 SEVERAL MGMAPI FUNCTIONS RETURN 0(SUCCESS) WHEN NO HANDLE OR NOT CONNECTED
      Refactoring of create partitioned table
      Revert unintentional change
      My::Memcache - do not close connection before attempting to fetch server error statistics
      MTR ndb_memcache more tweaks to timeout handling
      Bug#20814396 PB2 IS SECRET ABOUT WHAT UNIT TESTS IT RUN
      Revert "Remove MCP_GLOBAL_SCHEMA_LOCK patch"
      Revert "Remove MCP_GLOBAL_SCHEMA_LOCK patch"
      Fixing the following test failures by synch'ing the error injection and the test checking the error:
      increase timeouts
      Better failure handling in My::Memcache.pm
      Provide more information when an ndb_memcache test fails
      BUG#20887445: Fix so that cpuset is working in ThreadConfig, previously node log proclaimed it was working where it wasn't really working
      Fix ndbapi example programs to work on Mac OS X Yosemite
      BUG#20887445: Fix so that cpuset is working in ThreadConfig, previously node log proclaimed it was working where it wasn't really working
      Fix ndbapi example programs to work on Mac OS X Yosemite
      Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED
      Bug#20729091 - ASSERTION TYPE < NDBDICTIONARY::EVENT::TE_EMPTY FAILED
      Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS
      Bug#20762291 - POLLEVENTS2() WILL RETURN ERROR (-1) IF GIVEN WAITTIME AMILLISECONDS IS NEGATIVE
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Fix testIndex seg fault where index not exists when calling indexReadRecords, added check for NULL return
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      MTR ndb_memcache : still better timeout handling & more verbose reporting during test runs
      Revert to older scheduler as default in 7.4 for testing
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Remove MCP_WIX
      Handle server timouts and disconnects in MTR's My::Memcache client
      Work on My::Memcache to handle server disconnects and timeouts
      Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS Bug#20561446 NDB : NDBEVENTBUFFER NEEDS MORE THREADING PROTECTION
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      fix
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      NDB Memcache external_values fixes: The external_values test had a Perl bug using "==" instead of "eq", causing tests to pass even when the server produced errant responses. This patch fixes the test case and also fixes the revealed errant behavior in memcached.
      Remove MCP_WIX
      Remove MCP_WIX
      Remove MCP_WIX
      Do not change default scheduler in 7.2
      NDB Memcache: use pollEvents2() in reconfiguration waiter thread
      bug#17638548: NDB Memcached uses excessive CPU. This patch works around the underlying issue by defaulting to a new scheduler which does not make use of the NDB MultiWait APIs.
      NDB Memcached: enable "Trondheim" scheduler in 7.2
      one more solaris fix
      Fix for compiler error on Solaris
      Adapt 73 Scheduler to new online configuration manager
      one more solaris fix
      Fix for compiler error on Solaris
      Fixup from previous merge
      NDB Memcache: backport improvements into 7.2
      Backport misc. NDB memcache changes from 7.3 to 7.2
      Raise version number after cloning 7.2.20
      Raise version number after cloning 7.3.9
      Raise version number after cloning 7.4.6
      Raise version number after cloning 7.1.35
      Attempt better "htonll" portability in NDB memcache code
      BUG#20665205, fixed a part where we skipped reading of page 0 which was required to do in last file, also due to file 0, page 0 writes we can trust this page to be correct
      Add ndb specific changes for Bug#20094067: BACKPORT BUG#19683834 TO 5.5 AND 5.6
      Added ndb testcase for bug#19856162.
      Post-push fix for bug#19856162.
      Merge into cluster: WL#8354 BACKPORT DIGEST IMPROVEMENTS TO MYSQL 5.6
      Revert "Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS"
      Revert "Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS"
      Revert "Bug#20729091 - ASSERTION `TYPE < NDBDICTIONARY::EVENT::TE_EMPTY' FAILED."
      Revert "Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED"
      BUG#20665205: Fix REDO log issue
      Added autotest testcases to test addnode and restart.
      Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED
      Bug#20729091 - ASSERTION `TYPE < NDBDICTIONARY::EVENT::TE_EMPTY' FAILED.
      Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS
      Bug 20762291 - POLLEVENTS2() WILL RETURN ERROR (-1) IF GIVEN WAITTIME AMILLISECONDS IS NEGATIVE
      Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS Bug#20561446 NDB : NDBEVENTBUFFER NEEDS MORE THREADING PROTECTION
      Remove MCP_WIX
      Resurrect unintentionally remove disabled.def file

[33mcommit d8da6023b6100bd348160187a9eeedd35f1c3898[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Tue Jun 16 10:45:11 2015 +0300

    Bug#21184265 ASSERT AT ALL || TRX_SYS_GET_N_RW_TRX() > 0
    
    This is a [1;31mregression[m from the startup refactoring in WL#7488.
    We aim to create the thread for rolling back incomplete transactions
    only if there are any such transactions to roll back.
    
    The assertion sometimes failed in the recovery steps of the test
    binlog.binlog_group_commit_flush_crash.
    
    The problem appears to be that the XA PREPARE transaction (internally
    created by the binlog) is accounted for in the trx_sys_get_n_rw_trx(),
    which we were checking. We should only consider those incomplete
    transactions that can be rolled back without involving other layers
    (transactions that are not in XA PREPARE state).
    
    In one observed failure, the error log output suggests that the binlog
    subsystem will have issued XA ROLLBACK for the transaction before the
    InnoDB rollback thread starts executing. The count was 1 before the XA
    ROLLBACK, and 0 after it.
    
    trx_sys_need_rollback(): Renamed from trx_sys_get_n_rw_trx(). Do not
    count transactions that are in XA PREPARE state.
    
    trx_sys_t::n_prepared_recovered_trx: Remove. This field was made redundant
    by the fix of
    Bug#20461632 QUERY CACHE IS DISABLED WHEN RECOVERED XA PREPARE
    TRANSACTIONS EXIST
    
    RB: 9306
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 3446269a9e723ace5204b3674bfc81625374cffa[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Wed Jun 10 14:25:15 2015 +0300

    Bug#21130285 MISSING MLOG_FILE_NAME RECORD FOR UNDO OR USER TABLESPACE
    
    mtr_t::Command::prepare_write(): Invoke fil_names_write_if_was_clean()
    on all tablespaces, even if a MLOG_FILE_NAME record was emitted for
    the system or undo tablespace.
    
    This is a [1;31mregression[m from WL#7806, which is a follow-up to WL#7142.
    In WL#7142, a mini-transaction commit could generate MLOG_FILE_NAME
    for only one tablespace (the *.ibd file), while WL#7806 does it for
    the system and undo tablespaces as well.
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 87dbde022c53d393f24d181ff00e52eb5e30922c[m
Merge: 112025a48f8 5eef003ae44
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri May 15 10:46:34 2015 +0300

    Merge remote-tracking branch 'local/mysql-trunk' into mysql-trunk-wl7170
    
    * local/mysql-trunk:
      Fix Bug#20783098 INNODB_CHECKSUM_ALGORITHM=CRC32 IS NOT BYTE ORDER AGNOSTIC
      Bug#20819189: ASSERT IF .FRM EXISTS BUT NO PARTITIONED INNODB TABLE.
      Bug#20561087 : REPLACE_USER_TABLE() DOES NOT CHECK ERROR WHEN READING FROM MYSQL.USER
      Bug#20819189: ASSERT IF .FRM EXISTS BUT NO PARTITIONED INNODB TABLE.
      BUG#19706455: RESET MASTER SHOULD RESET GTID STATE AND NOT ERROR OUT WHEN BINLOG IS OFF
      Test suite cleanup
      Some cosmetic changes which had been suggested in the review of wl#2489 but had to wait for wl#5275 and wl#7870 to be pushed.
      Test cleanup
      Bug#21074643: SERVER SETS OPEN_FILES_LIMIT UNCONDITIONALLY
      Fix for build failure after pushing a767e483e9496e8427d50f59dfa4842d4895e08a
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Bug#20896539 - A QUERY DIGEST SOMETIMES CONTAIN BACKTICKS AND SOMETIMES NOT DEPENDING ON CS
      Post push cleanup
      WL#8216: Deprecate and remove the sync_frm sysvar
      PB2 failures (valgrind and result mismatch) fixes.
      Follow up patch of bug20734998 for fixing Werror failure.
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20762557, Bug#20697533 : Disabled following tests since they fail very often on PB2: main.explain_for_connection_rqg_json main.explain_for_connection_rqg_trad rpl.rpl_perfschema_applier_status
      Test commit
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      WL#8186: Deprecate conversion of pre MySQL 5.1 encoded database names
      Bug#20980885: ENSURE THAT START/STOP GROUP REPLICATION ALWAYS REQUIRE SUPER PRIVILEGE
      Partial backport from mysql-trunk to mysql.5.7 of Bug#21041451: ENABLE AND FIX ADDITONAL WARNINGS REPORTED BY CLANG in order to fix Clang 3.4 warnings in release build. No new warning options are added in the backport.
      Bug#21074358: SOME NEW 5.7 SOURCE FILES ARE D0S FORMATTED
      Bug #17818062       PERFORMANCE SCHEMA, ISSUE WITH UPPERCASE ROUTINES NAMES, PERFSCHEMA.MISC FAILS
      Bug #17818062         PERFORMANCE SCHEMA, ISSUE WITH UPPERCASE ROUTINES NAMES, PERFSCHEMA.MISC FAILS
      Bug#17832047: Crash in calculate_materialization_costs
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      Added openssl multithreading to client.
      Added openssl multithreading to client.
      Bug#20721087 UPGRADE TO BOOST 1.58.0
      Bug#20734998 FAILING ASSERTION: !CURSOR->INDEX->IS_COMMITTED()
      Bug #21047137 REMOVE -GCC FROM NAME OF SOLARIS PACKAGES/TARBALLS
      Bug#19316063: MAKE MTS WORK WITH RELAY_LOG_RECOVERY=1 WHEN GTID IS ENABLED
      Bug#21062842 : Made i_main.costmodel_plan change experimental.
      Bug# 19823076 : READ OF FREED MEMORY IN MY_MB_WC_SJIS WITH                 SOUNDS LIKE OPERATOR IN SUBQUERY
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      BUG#20743468: ASSERTION `OLD_VALUE >= 1' FAILED. | ABORT (SIG=6) IN GTID_STATE::END_ANONYMOUS_ BUG#20748502: ASSERTION `THD->VARIABLES.GTID_NEXT.TYPE== ANONYMOUS_GROUP' FAILED.
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      WL#7589: Updated the README file.
      Bug#21041451: ENABLE AND FIX ADDITONAL WARNINGS REPORTED BY CLANG
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20753620: DBUG: DICT_LOAD_FOREIGN, HA_INNOPART::CHECK, HA_INNOPART::CREATE_NEW_PARTITION
      Silence rpl.rpl_xa_survive_crash_debug in Valgrind
      Bug#21021894 : UNHELPFUL ERROR FOR MYSQL_SSL_RSA_SETUP WHEN DATADIR DOESN'T EXIST
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      Bug#21021754 - OPTION FOR MAX_STATEMENT_TIME IS MISSING
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      BUG #21063087 - MTR SHOULD PASS --INNODB_UNDO_TABLESPACES VARIABLE AT BOOTSTRAP
      BUG#20921940 DEBUG ONLY-CODE MAY HAVE SIDE EFFECTS IN HA_INNOBASE::
      - Bug#21046781: WHILE TRUNCATE UNDO-TABLESPACE FILE COULD BE CLOSED IN BACKGROUND
      BUG#21041449 ASSERT IN I_INNODB.INNODB_BUG16244691
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug #20445525 ADD A CONSISTENCY CHECK AGAINST DB_TRX_ID BEING IN THE FUTURE
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20835095 CRASH AT CREATE_REF_FOR_KEY IN SQL/SQL_SELECT.CC
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20980217 - TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE DOES NOT SHOW CORRECT INDEX NAMES
      Bug#20923066: SSL AND RSA KEY MATERIAL EXPIRATION SHOULD BE EXTENDED
      Corrected validate_password_strength and export_set functions
      Post push fix for BUG#18731252
      Bug#21046582 GEOMETRYCOLLECTION COLUMNS CAN'T STORE SUBTYPES
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      Fix for PB2 test failure.
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      - Bug#21053486: TRUNCATE_RECOVER FAILING IN MYSQL-TRUNK
      Bug#21021894 : UNHELPFUL ERROR FOR MYSQL_SSL_RSA_SETUP WHEN DATADIR DOESN'T EXIST
      Bug#20705648 - max_statement_time leaks memory on windows Bug#20705642 - max_statement_time: assertion failed: pending || thd_timer->thread_id
      Bug#20996273 ALTER USER REWRITE CAUSES DIFFERENCES ON SLAVE
      Fix to remove data dir reference
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Bug#20987568 - INCREASE STOP TIMEOUT OF COMMUNITY RPM SHUTDOWN SCRIPT /ETC/INIT.D/MYSQLD
      - Bug#21046968 : POSSIBLE RACE IN THE TRUNCATE CODE
      WL#7899: Add the tests that were accidentally omitted.
      WL#7899: InnoDB: Map compressed temporary tables to uncompressed
      Bug#20918881 CRASH WITH CENTROID - INVALID FREE
      Bug#20854952 SHOW GLOBAL VARIABLES RETURN WARNING ABOUT SQL_LOG_BIN BEING DEPRECATED
      Bug#21021670 - MISLEADING WARNING WHEN PER-QUERY STATEMENT TIME IS EXCEEDED
      Bug#20854952 SHOW GLOBAL VARIABLES RETURN WARNING ABOUT SQL_LOG_BIN BEING DEPRECATED
      Bug #20692556 : PREPARED STATEMENTS DO NOT TRACK STATUS LIKE STATISTICS
      - Bug#20023425: EMBEDDED SERVER FAILS TO BOOTSTRAP/START UP WITH   INNODB_UNDO_TABLESPACES=2
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Bug #20376498: MAX_ALLOWED_PACKET ERROR DESTROYS ORIGINAL               DATA
      BUG#20753463 HANDLE_FATAL_SIGNAL (SIG=11) IN __STRLEN_SSE2_PMINUB ON              CHANGE MASTER
      Bug#20507804 FAILING ASSERTION: TRX->READ_ONLY && TRX->AUTO_COMMIT && TRX->ISOLATION_LEVEL==1.
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      BUG#18731252 SLAVES WITH SAME SERVER_ID / SERVER_UUID COMPETE FOR              MASTER CONNECTION
      BUG#20768847 ASSERTION 0 IN HA_INNOBASE::COMMIT_INPLACE_ALTER_TABLE
      Post-push fix for BUG#20470724: SET GTID_PURGED SHOULD NOT ROTATE BINLOG
      Fixed Bug#20145024: WRONG RESULT FOR COUNT DISTINCT QUERY IN DERIVED TABLE
      Bug #20592961  'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381 - post fix
      BUG#20977779 CANNOT IMPORT TABLES CONTAINING PREFIX INDEXES
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Fix to avoid build break
      Bug#20814280 SEVERAL PERFORMANCE SCHEMA UNIT TESTS FAIL
      Bug#20814280 SEVERAL PERFORMANCE SCHEMA UNIT TESTS FAIL
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Test cleanup
      Test cleanup
      BUG#20470724: SET GTID_PURGED SHOULD NOT ROTATE BINLOG
      Bug#20748537 INNODB: FAILING ASSERTION: NODE->PCUR->REL_POS == BTR_PCUR_ON
      BUG#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bugi#20593257 FIREWALL PLUGIN LEAK PINS UNDER SPECIAL CIRCUMSTANCES
      BUG#20949314 PARTITION_HELPER::PH_RND_INIT(BOOL): ASSERTION `0' FAILED
      Fix firewall_qc broken test case when the FIREWALL_PLUGIN variable isn't set. This affected 32bit debian
      Fix firewall_qc broken test case when the FIREWALL_PLUGIN variable isn't set. This affected 32bit debian
      Bug#20963147 DECOUPLE DIGEST SIZE FROM SERVER AND PFS
      Bug #20926253 VALGRIND FAILURE IN INNODB.ALTER_MISSING_TABLESPACE
      - Bug#20023425: EMBEDDED SERVER FAILS TO BOOTSTRAP/START UP WITH   INNODB_UNDO_TABLESPACES=2
      Bug#20963147 DECOUPLE DIGEST SIZE FROM SERVER AND PFS
      Raise version number after cloning 5.6.25
      Raise version number after cloning 5.5.44
      BUG#21023683 FAILURE IN EMBEDDED I_INNODB.INNODB-ALTER
      Follow-up to BUG#20913616 - FIREWALL INTEGRATES BADLY WITH QUERY CACHE
      Bug #20914786 : MYSQL_UPGRADE FAILS WITH SHOW_COMPATIBILITY_56 = OFF
      Bug #20753378 ASSERTION `GTID_NEXT->TYPE != AUTOMATIC_GROUP || THD->OWNED_GTID.IS_EMPTY()'
      Bug #20592961  'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381
      Bug #20592961 'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381
      Bug #20753378 ASSERTION `GTID_NEXT->TYPE != AUTOMATIC_GROUP || THD->OWNED_GTID.IS_EMPTY()'
      Fix for missing test recording and test output differences on Windows.
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Bug#20913616 FIREWALL INTEGRATES BADLY WITH QUERY CACHE
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      BUG#19897405: CRASH WHILE ACCESSING VIEWS IN STORED ROUTINE               AND TABLES ARE FLUSHED
      Bug#20515155 Views: Assertion failed: is_view_or_derived() && is_merged()
      Bug #20987420 PB2 FAILURE OF TEST CASE INNODB_ZIP.INNODB_16K
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      BUG#20007583: THE EVENT_SCHEDULER USERNAME IS NOT RESERVERD.               ALLOWS PROCESSLIST VIEW.
      Windows installer in need of fixing to accommodate for WL#7307
      Bug#20768717: DEBUG BUILD FAILS WHEN USING GCC 5 DUE TO COMPILER WARNING
      post push minor test fix for bug:19887143
      BUG#20768847 ASSERTION 0 IN HA_INNOBASE::COMMIT_INPLACE_ALTER_TABLE
      - bug#20938115: innodb_undo_logs max limit should be downgraded from 126 to 94^
      Bug #20563332 : OPEN_FILES_LIMIT BINARY PUT INTO ./BIN DIRECTORY OF A BUILD?
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      Addendum to the fix for bug #20681412:
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug#20979020 - THE TRX IN DDL SHOULD ALWAYS NOT BE ROLLED BACK
      Bug#20709462: GENERATED COLUMNS NOT PRINTED CORRECTLY IN SHOW CREATE TABLE
      Bug#20583321: CRASH ON PS_THREAD_INFO / SYS USAGE
      Bug #18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Fixed failing test
      Bug#20583321: CRASH ON PS_THREAD_INFO / SYS USAGE
      Bug #19077239 mtr tests fixed.
      Bug#19077239 re-enabling disable tests mysql_secure_installation amd mysql_secure_installation_ssl
      Revert "WL#8462: test_services are plugins serving as examples for how plugin services can be tested with mtr."
      Bug #19887143 : THREAD/SQL/MAIN DOESN'T CHANGE STATE/INFO AFTER STARTUP
      WL#7895 - Add systemd support to server.
      Fixed Bug #20683741 UNZIP REQUIRED TO RUN MYSQL-TEST-RUN.PL BUT NOT CHECKED FOR BY CMAKE
      Bug#20865674-VALGRIND FAILURE IN INNODB.CREATE_TABLESPACE
      BUG#19821087 UPDATES TO INDEXED COLUMN MUCH SLOWER IN 5.7.5
      Fixed Bug #20949226: CAN ASSIGN NON-DEFAULT() VALUE TO GENERATED COLUMN
      rb8590 Fixes to sporadically failing on PB2 rpl_xa_survive_crash_debug
      WL#8462: test_services are plugins serving as examples for how plugin services can be tested with mtr.
      Bug #20681412 MYSQLD --INITIALIZE REFERS TO MYSQL_INSTALL_DB AND BOOTSTRAP
      Bug#20937654 CANNOT BUILD WITH "-DDISABLE_SHARED=ON" FOR CMAKE BECAUSE OF REWRITER PLUGIN
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      Fixed failing tests
      WL#6940 Server version token and check
      Bug #20181776 :- ACCESS CONTROL DOESN'T MATCH MOST SPECIFIC                  HOST WHEN IT CONTAINS WILDCARD
      Bug#20961660 RPL TESTS ARE FAILING WITH INNODB: UNDO TABLESPACES MUST BE READABLE!
      WL#4601: Remove fastmutex from the server sources
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      BUG#20955104: ADD UNIT TEST BINARIES AS OPTIONAL TARGETS WHEN MERGE_UNITTESTS=1
      Bug#19865673 DDL LIKE ADD INDEX IS VERY SLOW IN 5.7.5
      Bug #20294225 - INVALID MEMORY ACCESS
      Bug#20275612  MEMCACHED INNODB PLUGIN BREAKS MYSQL ENTERPRISE BACKUP
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug #18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Bug#19822257: WRONG VALUE PASSED TO --INIT-FILE OPTION CAUSES SERVER HANG
      BUG#20748570  BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      Bug#20515155 Views: Assertion failed: is_view_or_derived() && is_merged()
      Improved the way --print-defaults works.
      Bug#20615597 Assertion !thd->is_error() at st_select_lex::prepare()
      BUG#20960406  NO_PROTOCOL.INC SHOULD BE IN MYSQL-TEST/INCLUDE DIRECTORY
      WL#8165 Use new records per key interface in NDB
      Bug #20683237 BACKPORT 19817663 TO 5.1 and 5.5
      Bug #20275612 MEMCACHED INNODB PLUGIN BREAKS MYSQL ENTERPRISE BACKUP
      Bug#20895852 UNDERSIZED TMP_TABLE_SIZE - ASSERTION OR ERROR 2027 (HY000): MALFORMED PACKET
      Bug#20895852 UNDERSIZED TMP_TABLE_SIZE - ASSERTION OR ERROR 2027 (HY000): MALFORMED PACKET
      Revert "Bug#20683741 fixed."
      Revert "Updated file have_util_uz.inc under Bug Bug#20683741"
      Revert "Fixed Bug#20683741"
      WL#6940 Server version token and check
      Bug #20052580 MISSING MUTEX/LOCK IN ACL_AUTHENTICATION()
      Bug#20318154 : NEGATIVE ARRAY INDEX WRITE V2
      Bug#20952953 RPL.RPL_SLAVE_SKIP FAILS IN VALGRIND
      Bug#20952953 RPL.RPL_SLAVE_SKIP FAILS IN VALGRIND
      Fixed Bug#20683741
      Bug#20937173 CLEANUP GIS_DEBUG USELESS CODE
      WL#6940 Server version token and check
      Bug#20922238: REDUCE HEADER FILE DEPENDENCIES IN MY_SYS.H AND M_STRING.H
      BUG#20889900: UNITTESTS SHOULD START THE SERVER WITH APPROPRIATE OPTIONS
      Bug#20810627 ASSERTION: REC_PAGE_NO > 2 IN IBUF_GET_MERGE_PAGE_NOS_FUNC
      Bug#20748570 BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      WL#8017 Infrastructure for Optimizer Hints
      Fixing the query tipping points
      Modified the test to run only on 64 bit machine
      Revert accidental changes to collections/default.push
      Bug#20927239: MY_TIMER-T UNIT TEST DOES NOT WORK WITH MERGE_UNITTESTS=0
      Bug#20922238: REDUCE HEADER FILE DEPENDENCIES IN MY_SYS.H AND M_STRING.H
      Post push fix for BUG#20431860
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Bug#20748570 BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      Bug#20902791 MYSQLDUMP DUMPS SYS_SCHEMA
      Bug#20782142 PAM tests Fixed
      Updated file have_util_uz.inc under Bug Bug#20683741
      BUG#17259750 - STACK CORRUPTION IN VIO_IO_WAIT ON MAC OS X
      BUG# 20798617 - MYSQL CALLS  EXIT(MYSQLD_ABORT_EXIT) WITHOUT                 SHUTTING DOWN INNODB.
      BUG#20597821 INVALID READ OF BLOB MEMORY FREED IN ::CLEAR_BLOB_HEAP_PART
      Bug#20911624 THE SERVER CRASH WHEN TEST ST_INTERSECTS WITH ST_BUFFER
      Bug #20904893         INNODB: FIX RECENT WINDOWS 32 AND 63 BIT COMPILER WARNINGS
      Bug#20921370: NEW CLANG 3.6 WARNINGS - MUST ENABLE -WNO-UNUSED-LOCAL-TYPEDEF
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Clean up mysql-test/collections
      Enable run of default suites on daily valgrind
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Bug#20903701 FIX VALGRIND WARNINGS IN UNIT TESTS
      WL#8161: Locking service for read/write named locks
      Bug#20789078 innodb: assertion: index->id == btr_page_get_index_id(page)
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug#18486509 ASSERTION FAILED: TABLE->KEY_READ == 0 IN CLOSE_THREAD_TABLE
      WL#8161: Locking service for read/write named locks
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Fix Bug#20618309 ASSERT SLOT1->PAGE_LEVEL == SLOT2->PAGE_LEVEL, BTR_ESTIMATE_N_ROWS_IN_RANGE()
      Bug #20476395 DICT_LOAD_FOREIGNS() FAILED IN COMMIT_INPLACE_ALTER_TABLE
      Bug#20573701 DROP DATABASE ASSERT ON DEBUG WHEN OTHER FILES PRESENT IN DB FOLDER.
      Bug#20573701 DROP DATABASE ASSERT ON DEBUG WHEN OTHER FILES PRESENT IN DB FOLDER.
      Bug#20902600: REDUCE HEADER FILE DEPENDENCIES IN SP* AND EVENT* FILES
      Bug #20883256         INNODB: WARNINGS: NONNULL PARAMETER WILL EVALUATE TO 'TRUE' ON FIRST ENCOUNTER
      Bug#20888417: REMOVE FUNCTION DECLARATIONS WITHOUT DEFINITIONS
      Bug#20814396 PB2 IS SECRET ABOUT WHAT UNIT TESTS IT RUN
      WL#8161: Locking service for read/write named locks
      BUG #20414588 - REMOVE HARD-CODED AIO DISABLE FROM MTR
      Bug#20882432 INCORRECT MERGE_THRESHOLD LENGTH IN SYS_INDEXES AFTER UPGRADE, TRUNCATE, RESTART
      Clarify comment in my_global.h about where and why this header should be included.
      Dummy commit to keep the push hook happy.
      Bug#20856729: QUERY REWRITE: WRONG IFDEF SYMBOL IN SERVICE_PARSER.H
      Bug#20364862 : MYSQLADMIN PASSWORD AFFECTS EXTERNAL AUTH ACCOUNTS
      Bug#20364862 : MYSQLADMIN PASSWORD AFFECTS EXTERNAL AUTH ACCOUNTS
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Bug #19953365 MY_PRINT_DEFAULTS DOES NOT MASK PASSWORDS
      Bug#20752436: INNODB: FAILING ASSERTION: 0 IN FILE HANDLER0ALTER.CC LINE 6647
      BUG#17650326 MYSQLBINLOG PRINTS INVALID SQL FROM RELAY LOGS WHEN GTID IS ENABLED
      Bug#20350989: MYSQLBINLOG CAN'T DECODE EVENTS > ~1.6GB
      Bug#20609063 - STDOUT AND STDERR REDIRECTION ISSUES
      Bug#20752436: INNODB: FAILING ASSERTION: 0 IN FILE HANDLER0ALTER.CC LINE 6647
      Bug#20886222 MOVE THE DECLARATION OF FIL_NODE_T TO A HEADER FILE,              AND CLEAN UP COMMENTS Move the definition of the data structure fil_node_t from fil0fil.cc to fil0fil.h so that diagnostics code outside that module can access information about the files belonging to a tablespace. Also do other cleanup and formatting changes.
      Bug#20888417: REMOVE FUNCTION DECLARATIONS WITHOUT DEFINITIONS
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Test cleanup
      Convert a func comments to new the InnoDB style.
      Non-functional style fixups
      Bug#20872436 MAKE DIST BY MISTAKE COPIES FILES WITH VARIABLE EXPANSION
      Bug#20882345: MOVE CODE OUT OF HANDLER.H
      Post-merge fix for WL#7806: Remove bogus files.
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug#20615023 SIGNAL 11 IN ITEM_FIELD::RESULT_TYPE DURING 1ST EXECUTION OF PREPARED STMT
      Bug#20872436 MAKE DIST BY MISTAKE COPIES FILES WITH VARIABLE EXPANSION
      BUG 20459905 - DEADLOCK OF THREADS DETECTED! 5.7.5, 1 THREAD SQL TESTCASE, SPORADIC, IN IB_LOGF
      Bug#20863042 Stop filling mtr logs with InnoDB page dumps
      Remove a test from the experimental collection.
      Bug#20865407: DBUG_ASSERT(1) MAKES NO SENSE
      BUG#20857756: BUILD NT_SERVC.CC ONCE FOR ALL UNITTESTS ON WIN32
      Clean up the post-commit fix for Bug#20872655 debug instrumentation.
      Bug#20874411 INNODB SHUTDOWN HANGS IF INNODB_FORCE_RECOVERY>=3 SKIPPED ANY ROLLBACK
      Followup fix for BUG#20518099
      Post-commit fix or work-around for Bug#20872655 debug instrumentation.
      Post-merge fix for Bug#20872655 XA ROLLBACK IS NOT CRASH-SAFE
      Bug#20518099 - CLEANUP UNIV_INNOCHECKSUM in innodb code base
      Bug#19363615 : innodb.log_file fails very frequently on windows and solaris. Moved test from experimental to disabled state
      Raised version after tagging 5.1.74 (some commits skipped)
      Bug#20872655 XA ROLLBACK IS NOT CRASH-SAFE
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Bug#20788811 MAX_STATEMENT_TIME: ASSERTION `EXPLAIN_OTHER || UNIT->IS_OPTIMIZED()' FAILED.
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Test cleanup
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES            OF INNODB_CHECKSUM_ALGORITHM
      Bug#20104307 GTID_EXECUTED TABLE COMPRESSION THREAD MAY NOT WAKE UP
      sys_vars.innodb_compress_debug_basic requires P_S to run
      Bug#20859285: REDUCE HEADER FILE DEPENDENCIES OF SQL_CLASS.H AND TABLE.H
      Add daily and weekly collections of tests that shun --parallel.
      Bug#20578834 - INNODB READ ONLY MODE AND NON EXISTENT TMP DIR CRASHES SERVER
      Bug #20809045    BUFFER OVERFLOW IN MYSQL
      Silence rpl_xa_survive_crash_debug in Valgrind.
      Bug# 19573096: LOADING CORRUPTED GEOMETRY DATA INTO A                MYISAM TABLE CAUSES THE SERVER TO CRASH
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES                    OF INNODB_CHECKSUM_ALGORITHM
      Bug#20857979 REMOVE DEPENDENCY ON HANDLER.H FROM PFS_ENGINE_TABLE.H
      Bug#20768820 MAIN.BIGINT TEST FAILS WHEN BUILT WITH GCC 5 IN RELEASE BUILD
      Bug#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bug#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bug#20855853 MDL SUBSYSTEM ENCAPSULATION BROKEN
      Bug#20816223 test fix.
      Remove MCP_WIX
      Remove MCP_WIX
      WL#7806: Add a test case from Viswanatham Gudipati with some cleanup by me.
      Test cleanup
      WL#7806: Relax a test that started to fail due to WL#6205.
      WL#7795 PERFORMANCE SCHEMA, HISTORY PER THREAD
      WL#7795 PERFORMANCE SCHEMA, HISTORY PER THREAD
      Clean up a test case. Use slow shutdown in order to avoid generating redo log after restart, for processing old undo logs or change buffer records.
      WL#7806: Re-enable a test and work around a problem in WL#6965.
      WL#7806: Add a temporary workaround until WL#7691.
      WL#7806: Temporarily remove the fil_sys_lookup[] for user tablespaces in order to ensure that we are not masking Bug#18645050.
      WL#7806: Add a flat fil_sys_lookup[] array so that fil_spaces_lookup() can avoid acquiring fil_system->mutex when looking up the system tablespace or the undo tablespaces. This is addressing a performance [1;31mregression[m.
      WL#7806: Correct some comments.
      Test that no redo log gets generated unexpectedly.
      Rename some tests to comply with new policy:
      Try to get a test to work on Windows.

[33mcommit 7c70f4704a8aff4d22ccd9eb7e0343346d6bcfe2[m
Merge: 938349594c5 a7b252e1a71
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Apr 9 14:29:16 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Fixed bug#20566243: ERROR WHILE DOING CREATE TABLE T1 SELECT
      Bug #20686665 MISSING SYMBOL IN LIBMYSQLCLIENT.SO: MYSQL_GET_PARAMETERS() - DBD:MYSQL BREAKS
      Bug#20443863 USE OF WORST_SEEKS IN FIND_BEST_REF() CAN LEAD TO WRONG QUERY PLAN
      Bug#20778898: FIX #INCLUDE DEPENDENCIES IN SQL* HEADERS
      Bug#20753642 INNODB: FAILING ASSERTION: !DICT_INDEX_IS_SPATIAL(INDEX)
      Problem: RPL.RPL_INIT_SLAVE_ERRORS is randomly failing in Pb2
      Bug#20816223 InnoDB crash on shutdown if XA PREPARE transactions hold explicit locks.
      WL#7696 followup, ignoring the value this value is OK.
      WL#7696 follow up - rerecord test.
      WL#7696 followup, ignoring the return value is legitmate for certain use cases
      Bug #20759613         ALTER TABLE CAN CRASH THE SERVER Post-fix: delete an ill-advised test added to create_tablespace.test. It had different results when innodb-page-size=32k and 64k, and it is not really needed to make the point it was showing.
      Bug #20840368 INNODB ASSERTS FOR DROP TABLESPACE `IB_LOGFILE0`;
      WL#7150:  Remove use of DATADIR in mysqld_safe for setting MYSQL_HOME in 5.7
      Bug#20768820 MAIN.BIGINT TEST FAILS WHEN BUILT WITH GCC 5 IN RELEASE BUILD
      BUG#20376106: MTS: CHANGE '..EXECUTE_STATUS_BY_WORKER' TO '..APPLIER_STATUS_BY_WORKER' IN CODE
      BUG#19729278: 5.7.5: NOISYNESS AND NO LOG THROTTLING (SQL COORDINATOR MESSAGES)
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES            OF INNODB_CHECKSUM_ALGORITHM
      Fix after removal of default database: Add DataLocation to Registry
      Bug#20785598 USE ATOMICS TO AVOID MUTEX CONTENTION ON LOCK_PLUGIN DUE TO QUERY REWRITE FRAMEW
      Bug#20756770 MYSQL SERVER DOESN'T COMPILE AGAINST OPENSSL 1.0.1M
      Patch for Bug#17162055: SSL.CMAKE SILENTLY CHOOSES BUNDLED YASSL INSTEAD OF ERRORING FOR OLD OPENSSL VER
      Revert "WL#8322 Improve default MySQL CLI prompt in 5.7"
      Followup fix after deprecating m_i_db: Solaris postinstall referred to sbin/mysqld instead of bin/mysqld
      BUG#20728488 MYSQL_INSTALL_DB DOES NOT WAIT FOR FORKED MYSQLD TO FINISH BOOTSTRAP
      Post-push fix for Bug#20691930 (innodb_zip.wl5522_debug_zip failure):
      Bug#20691930 5.7.6 CRASH WHEN RUNNING MYSQL_UPGRADE AFTER BINARY UPGRADE This is a [1;31mregression[m from Bug#17345513 CHECKING FIL_PAGE_TYPE BREAKS COMPATIBILITY WITH OLD INNODB DATA FILES
      Remove old style spec references
      Removed support-files directory from CMakeLists.txt
      Removed old style rpm spec file mysql.spec.sh
      Bug#20685859 ENABLE STAGES WITH PROGRESS BY DEFAULT FOR EASE OF USE
      Bug#20575529 PERFORMANCE_SCHEMA.GLOBAL_VARIABLES MYSTERY DEPRECATION WARNING
      Bug#20559828 SHOW GLOBAL VARIABLES WHERE NOT DEPRECATED IN EMBEDDED
      Adding additional check to check the existence of mysqltest.1 manpage.

[33mcommit ca6ecd8229c53b0a139304bf6641cef6e529e61a[m
Merge: b840f9e9e35 2e91bec76f5
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Apr 8 12:35:31 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug #20590548 UNABLE TO LOGIN WITH USER WHOSE PWD CHANGED FROM 5.6.23 MYSQLADMIN IN 5.7.6
      Bug#20726413 : MYSQL_SSL_RSA_SETUP DOES NOT HAVE USER OPTION
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES                    OF INNODB_CHECKSUM_ALGORITHM
      WL#8244 Hints for subquery strategies. Part#2: Add support for SEMIJOIN/_SEMIJOIN and SUBQUERY hints
      WL#8244 Hints for subquery strategies. Part#1: Add optimizer_switch for DuplicateWeedout strategy.
      WL#7696 follow up fix, check return values.
      Fixed bug#20745142: GENERATED COLUMNS: ASSERTION FAILED: THD->CHANGE_LIST.IS_EMPTY()
      Fixed bug#20797941: WL8149:ASSERTION `!TABLE || (!TABLE->READ_SET ||                     BITMAP_IS_SET(TABLE->READ_SET
      BUG#20593808 - CRASH WITH PARTITIONED TABLES + MULTITABLE DELETE
      WL#7696 follow up fix.
      Bug#20788853 MUTEX ISSUE IN SQL/SQL_SHOW.CC RESULTING IN SIG6. SOURCE LIKELY FILL_VARIABLES
      WL#7696 followup - remove unused file
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, rerecord the test
      WL#7696 follow up fix, add INNODB_COMPRESS_DEBUG to the test.
      Bug#20840377 UNITILAISED BYTES REPORTED AT MY_WRITE.C:63
      Fixed failing tests after commit 335a53004313ab5a971cf17dea36f1dc4490db9f MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20755430 COST CONSTANT CACHE MUTEX NOT INSTRUMENTED BY PERFORMANCE SCHEMA
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      WL#7696 follow up fix.
      WL#7696 follow up fix - add INNODB_COMPRESS_DEBUG to the list
      Addendum to bug #20810928: fixed the test to reflect that COM_SHUTDOWN can be a zero-length RPC
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20678411 BROKEN MAKEFILE DEPENDENCY: SQL_YACC.YY AND LEX_TOKEN.H
      Bug #17299181    CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      BUG#20093172 LOG_STATE DECLARED VOLATILE, MISSING MEMORY BARRIERS
      BUG#20042205 RPL_GTID CHECKABLE_RWLOCK DEBUG CODE DOESN'T NEED VOLATILE              LOCK_STATE
      BUG#20042109 MYSQL_BIN_LOG::M_PREP_XIDS DOESN'T NEED TO BE VOLATILE
      BUG#20754369: BACKPORT BUG#20007583 TO 5.1
      Bug #17299181  CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      Bug#20411374:CAN NOT EXECUTE CHANGE MASTER AFTER ERROR OCCURED IN MTS MODE
      Bug#20683741 fixed.
      Bug #20814051 CREATE USER BINLOG EVENTS INCLUDE NEW ACCOUNT KEYWORD
      BUG#20510811 - RQG_ALTER_ONLINE_PART RUN INTO ASSERTION: NODE->ENTRY
      Bug#20279241 - ALTER TABLE XXX CHARACTER SET UTF8, CONVERT TO CHARACTER SET LATIN1 SHOULD FAIL
      Adapt new sql/ha_ndbcluster.cc code to use the new ER_THD() macro
      Remove MCP_GLOBAL_SCHEMA_LOCK patch
      Bug #20810928: CANNOT SHUTDOWN MYSQL USING JDBC DRIVER
      Fixed Bug #20683741.
      Test cleanup
      Bump version to 7.5.0
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20811494 SHOW_COMPATIBILITY_56 = OFF INCOMPATIBLE WITH CONNECTORS
      Bug#20531812: MEMORY CONSUMED QUICKLY WHILE EXECUTING LOOP IN PROCEDURE
      Bug#20683959 LOAD DATA INFILE IGNORES A SPECIFIC ROW SILENTLY UNDER DB CHARSET IS UTF8
      Remove MCP_BUG16021021
      Remove MCP_WIX
      Bug#20313067 CHECK TABLE REPORTS WRONG COUNT FOR SPATIAL INDEX AND OTHER GIS PROBLEMS
      Bug#20124342 MYSQL 5.6 SLAVE OUT OF MEMORY ERROR ? Problem: I/O thread on Slave with master_info_repository=TABLE settings, is leaking memory that leads to Out of memory (OOM) after some time.
      Fix merge error in mysql_system_tables_fix.sql
      Remove MCP tags for BUG16226274
      BUG#20811125 INNODB FTS: FTS_PRINT_DOC_ID PRINTS TOO MANY DEBUG INFORMATION
      Bug#20762059 - innodb_thread_concurrency=1 and queries using intrinsic temp tables, causes hang
      Create an .inc file which does slow shutdown before restarting innodb in read-only mode.
      Bug#19811953 ENVELOPE() FUNCTION RETURNS INVALID POLYGON Bug#20196720 ENVELOPE(P) RETURNS NULL FOR A NON NULL POLYGON P
      Bug #20544581         ASSERTION: REC_PAGE_NO > (ULINT) 4 - (REC_SPACE_ID != 0)
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 - Fix a merge issue.
      WL#7696 - Fix a merge issue
      WL#7696 - Fix the column ordinatlity. Messed up in a previous merge.
      WL#7696 - Fix a compilation error
      move some compression tests elsewhere until using Win32::API module is approved. Improve error detection, if there is no module, the tests will succeed, not fail as before, but the testing power will be somewhat limited.
      Bumped rpm version for oel due to respin
      Bug#20756770 MYSQL SERVER DOESN'T COMPILE AGAINST OPENSSL 1.0.1M
      Patch for Bug#17162055: SSL.CMAKE SILENTLY CHOOSES BUNDLED YASSL INSTEAD OF ERRORING FOR OLD OPENSSL VER
      Bug#20755346 EXAMPLE SCRIPT IN FIREWALL MISSES WHERE CLAUSE
      Bug#20764521 REGRESSION: FIREWALL USE GENERAL_HOST TO RESOLVE HOST
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      Resurrect unintentionally remove disabled.def file
      Resurrect unintentionally remove disabled.def file
      Bug#20651661 NDBEVENTBUFFER LEAKS GCI_OP
      Remove three files which did not properly remain
      WL#7696 - Make LZ4 decompress safe during recovery
      Remove hack to allow large number of failing tests in mtr.pl
      WL#7696 - Reset the contents of the page to NUL.
      WL#7696 - Use the double write buffer pages for compressed pages.
      WL#7696 - Fix syntax error on Windows.
      WL#7696 - Fix debug assertion.
      mysql-test/include/innodb-compress-utils.inc:   add OSD support to get allocated file size for Windows
      add the result file missing in the previous commit
      Test update:   mysql-test/suite/innodb/t/table_compress.test:     fix one failing case for 32k   mysql-test/suite/innodb/r/table_compress_2.result: make use of new     include files   mysql-test/suite/innodb/t/table_compress_3.test: new test to cover     what was not covered yet, shared tablespaces in particular   mysql-test/include/innodb-compress-verify.inc: common sequence     for compression verification   mysql-test/include/innodb-compress-utils.inc: perl compression     related utilities.     Note: OSD Windows file allocated size is not implemented yet.     The test is still expected to pass on Windows because the allocated     size is forced to the expected value.
      Bug #20536590: BACKPORT BUG #12368204 AND BUG #16953758 TO MYSQL-5.6
      WL#7696 - Code clean up. Ignore table COMPRESSION setting if set to NONE.
      WL#7696 - Minor code cleanup
      WL#7696 - Fix the punch hole size calculation.
      Bug#20712432 AUTOTEST: TESTFK FAIL IN CLEARTABLE WITH 256 REFERENCED ROW EXISTS
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#17775772 POTENTIALLY UNINITIALIZED BUFFER IN NDBOUT::PRINT* PRINTOUT   - print nothing or just empty newline instead of uninitialized buffer   - catch error with an assert in debug compile
      Bug#17775607 POTENTIALLY UNINITIALIZED BUFFER IN VNDBOUT_C PRINTOUT  - print empty newline instead of uninitialized buffer  - catch error with an assert in debug compile  - Mark vndbout_c as static and thus local to implementation Conflicts in copyright:        storage/ndb/include/util/NdbOut.hpp     storage/ndb/src/common/util/NdbOut.cpp
      Remove unused parameter ndbcluster_drop_event()
      Bug#20032381 KILLED_STATE SAVE IN NDBCLUSTER_BINLOG RETRY AT SHUTDOWN DOESN'T NEED TO BE VOLA
      Bug#20014045 MONOTONIC SPELT INCORRECTLY IN NDB CODE
      Bug#20092754:  MYSQLD CRASH (FOUND UNCOMITTED AUTOCOMMIT+RBWR TRANSACTION, COMMIT STATUS 3)
      mysql-test/suite/innodb/t/table_compress_2.test:
      Raise version number after cloning 7.4.5
      Correct MTR command for 64k run. Adiing missing "k".
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      Tetss that use innodb_compress_debug should run against debug server
      Added runs with differnt combination and page size setting for Innodb suites
      mysql-test/suite/innodb/t/table_compress.test:   Fix failure when hole punching is not available.   Now the test will be skipped instead
      Revert accidental bump of server version back to 5.6.23
      Fix a compilation warning in non-debug mode
      BUG#18949230: Removed unneeded ndbassert and fixed printout, also recorded number of real periods
      Added some extra output to ndbapi tests utilities as an aid to hunt down the AutoTest failure 'testBasic -n Bug54986 D2'
      Added log printout about invalidation of REDO log and where log head was found
      WL#6815 Adapt MySQL Cluster to 5.7
      Added autotest files for Mikaels environment, added comments about how to get file system as part of results in autotest, added comment about how to handle older git versions with autotest
      BUG#20546157: Fix problems in START_PERMREQ and START_INFOREQ that hangs node restarts when invalidation of nodes is still ongoing at node restart
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20480035 REMOVE MCP_BUG44529
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disable ndb_rpl_circular_2ch* waiting for Bug20592110
      Disable ndb_addnode_witbinlog waiting for Bug17400320
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75720: Fix platform issues with ndb_dd_dump test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      WL#7696 - Don't print a warning on Windows if SPARSE FILE attribute can't be set
      BUG#20631645: Ensure that SYSFILE->latestLCP_ID is properly up-to-date in the pause LCP protocol
      Fix [1;31mregression[m caused by wl#7674 in testBasic -n RefreshTuple T6 D1
      Fix [1;31mregression[m caused by wl#7674 in testDict -n Bug13416603 I2.
      Fix for Bug#20408733:
      WL#7696 - Punch hole message is Linux specific.
      WL#7696 - Backport code from mysql-trunk to mysql-5.7
      Followup fix for "Bug20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK"
      WL#6815 Adapt MySQL Cluster to 5.7
      Another follow up fix for "BUG11748566 - MYSQL SHOWS WRONG DEFAULT VALUE FOR PK IF  NOT NULL NOT SPECIFIED"
      BUG#20568586: Fix ndb_cpcd to avoid reading a closed file
      BUG#20567730: Ensure that late arriving LCP_FRAG_ORD with lastFragmentFlag set from new master are handled correctly, correct is to ignore them if such a signal arrives in idle LCP state
      Fix for bug#20538179
      BUG#20546899: Faulty ndbrequire fixed
      BUG#20553247: Fix memcpy overlapping copy issue
      BUG#20553247: Use memmove for overlapping memory copy
      Commit this fix on behalf of Pekka N:
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      BUG#19811871 VERSION NUMBR NOT SHOWN IN LOG WHEN [RE]STARTING 5.6.21 SERVICE WITH SLES11 REPO
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      Updated copyright information
      Bug#20228839: MISSING DATABASE '-D' OPTIONS FOR FEW OF THE HUGO TOOLS
      Re-enable clusterj tests disabled during 7.4.4 release.
      Bug#20593065 MULTI UPDATE RETURNS DIFFERENT DATA WITH ENGINE NDB
      This commit is a followup to the fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_time calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop timeout to be configured).
      Add support for SLES12
      Merge 7.3->7.4
      Merge 7.2->7.3
      Overriding release() function from the DynamicObject class in its subclasses.
      This commit is a fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_time calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop timeout to be configured).
      Reverse order of libraries used when linking the ndbapi examples
      Add small MCP for problem with Partition_handler::get_default_num_partitions
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM: fix test [1;31mregression[m
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7549: Fix test case for removed EMPTY_LCP protocol
      BUG#20444078: Removed unneeded log printout
      BUG#20444078: Fix master takeover of COPY_GCIREQ protocol
      WL#6815 Adapt MySQL Cluster to 5.7
      Revert accidental version number change
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20528878 : P_S UNIT TEST IS FAILING
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM
      Temporarily hack mtr.pl to allow a large number of failing tests
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disabling ndb.clusterj and ndb.clusterj_jpa tests for 7.4.4 release.
      WL#6815 Adapt MySQL Cluster to 5.7
      bump version to 7.4.5
      Bump version to 7.4.5
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20281479: Entered eternal loop when starting node in MGM server due to buggy bug fix
      Fix unintentional increase in testsize by a factor of 100 of 'testBasic -n Bug54986'
      BUG#20513571: Introduce MaxSendDelay for large clusters
      Fix failing AutoTest 'testIndex -n NFNR3*'
      BUG#20512063: Moved verbose logging to only be used in verbose mode
      Add missing failure detection for 'testBasic -n Bug54986'.
      BUG#20281479: Ensure that START_ORD is properly sent from management server
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20504971: Fixed restart_info table to provide its output
      WL#6815 Adapt MySQL Cluster to 5.7
      Proper error printouts after reaching NDBT_FAILED in test cases
      Backport fix for BUG#20276462
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Updated to newest version of flexAsynch
      Patch related to bug#18401543
      BUG20308276: Don't use same list for master and participant part of takeover processing
      Fix issue in AutoTest where test are being killed by WatchDog during memory allog in startphase 0.
      BUG20276462: Fixed spelling error in error code
      BUG#20276462: Error code ZNODE_FAILURE_ERROR has no treatment in NDB API, use NODE_SHUTDOWN_ERROR instead
      WL#8148 NDB: Add git support to Autotest
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT
      Bug#20234994 JOINS ARE NOT PUSHED AFTER WL6042
      Revert "Adapt pushed joins to WL#6042"
      Fix for Bug#19053226 AUTOTEST FAIL: TESTSRBANK -N MIX -L 300 -R 15 T1
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) PART III
      Bug#20410087 GCOV COVERAGE DATA FOR NDB KERNEL IS MISSING
      WL#8294 NDB: turn on signal checksum as default
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Disabling mtr tests on 7.1 which fail because SSL certificates have expired.
      Re-recording mtr test result after ssl certificate update
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT Generated new certificates with validity upto 2029.
      Fix test client failure for AutoTest 'testNodeRestart -n ClusterSplitLatency'
      Bug#19785977:  CRASH IN NDBINDEXSCANOPERATION::SCANINDEXIMPL
      Bug#20423898 BAD TEST TESTNODERESTART -N LCPTAKEOVER CAN NOT FAIL.
      Improve ndb_rpl_circular_2ch_rep_status reliability.
      Test was random failing due to matching random binlog junk. Make false matches less likely.
      A little brute force to understand the issues with ndb_rpl_circular_2ch_rep_status
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      Experimental experiment with experimental status.
      A more standard variant of !valgrind.
      BUG#19667566 : PARTITION BY WITH COMMENT LEADS TO MYSQL SERVER REBOOT IN MYSQL CLUSTER
      Sacrifice Valgrind run to improve ndb_rpl_slave_binlog_index reliability.
      Backport of fix for bug#16209645
      Bug#17579998 TEST 'TESTNODERESTART -N GCP -L 1 T1' FAILS DUE TO MYSQLD ABORTED
      ndb_rpl_slave_binlog_index.test
      ndb_types.test contained binary raw data from 'bit' and 'binary' columns.
      Bug #20372169         NDB : INCORRECT STATUS VARIABLES NDB_LAST_COMMIT_EPOCH_[SERVER|SESSION]
      Fix of uncorrect merge (7.2 -> 7.3) of [1;31mregression[m fix for bug#19524096
      Fix [1;31mregression[m introduced by fix for bug#19524096.
      Fix [1;31mregression[m introduced by fix for bug#19524096.
      Fix [1;31mregression[m introduced by fix for bug#bug#19524096.
      Improve ndb_rpl_slave_binlog_index.test behaviour under Valgrind.
      Bug#20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK INTEGRATION
      Add some improved debugging to help understand non locally reproducable problems with ndb_binlog_last_commit_epoch testcase.
      This commit is a fix for Bug#19880969 (CLUB FOR 7.1, LINUX-RELEASE, 345 WARNINGS IN BUILD). The fix suppresses these warnings, so that the corresponding square in club becomes green rather than red.
      Bug #19306793         CORE IN NDBAPI WHEN EXTENDED EXTENSION TABLE IS CREATED IN MYSQL 7.4
      Quick fix of corrupted special comment characters. No code change.
      Updated the copyright year in README and welcome message
      Improve garbage collection of clusterj artifacts
      Updating copyright year
      Some copyright fixes to files changed in 2014
      Fixing user visible copyright years
      Fix for 7.4.3 build failures
      Fix for copy right year
      Corrected copyright year by sreedhar
      Updated README and banners to 2015
      bump version to 7.1.35
      pgmanpe pe-dump.diff pgman: dump max page entries bug#18484117 bug#19915761 bug#19958804
      pgmanpe pe-config.diff pgman: configure max page entries bug#18484117 bug#19915761 bug#19958804
      BUG#19480197, BUG#73667, BUG#74945: Ensure Local object has transferred back object to real object before calling recursive function
      Cherrypick fix which removes MCP_WL1735 from 7.4
      Cherrypick fix for bug20009152 from 7.4
      Adapt pushed joins to WL#6042
      Follow up fix for bug#20112981
      Fix for bug#20112981
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - rewrite clean_away_stray_files() to use find_files() direct rather than going via make_db_list(). - The only difference between make_db_list() and find_files() is that the information_schema database is not   return in the list of databases. But it's currently not possible  to create a NDB table in information_schema   and thus there can not be any "stray" tables there either.  - testcase added to ndb_reconnect which shows access denied when trying to create table    in information_schema  - This avoids patching the MySQL Server to make the static make_db_list() function available    to use in ha_ndbcluster_binlog and thus the MCP for make_db_list() and LOOKUP_FIELD_VALUES   can be removed. - Also remove the NDB_WITHOUT_MAKE_DB_LIST which was used for compiling ndbcluster in MySQL Server
      Remove unused TNTO_NO_REMOVE_STRAY_FILES Thd_ndb option
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#19898269, BUG#74594: Fixed wrong order of sending bitmap of LCP participants to ensure that starting node can correctly calculate the lcpOngoing flag for each fragment
      Another addendum patch for bug#20112981, adressing comment from Mikael R.
      Incremental addendum patch for bug#20112981
      Fix for bug#20112981
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#75220: Added option to use 10 and 20 LDM threads (same for NoOfLogParts)
      BUG#20215395: Bug in cluster join protocol
      Added jams to place where data nodes freezes in startup
      BUG#19590336: Preparatory patch adding lots of jam:s to DD code, also a few more more comments added
      Additions to wl#7674
      Bug#18715165, BUG#17069285
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug#20193236 SOME COMPILER WARNINGS BECAME ERRORS AFTER MERGE OF MYSQL SERVER 5.5.41
      Cherrypick from 5.6 : Bug#20009154 - FIX REGRESSION AFTER HA_FLUSH_LOGS() HOOK FOR NDB IS REMOVED.
      Bug 19895502 -  BINARY LOG GROUP COMMIT CAUSES REGRESSION FOR NDB REPLICATION.
      This commit is a followup to WL#8145 (NdbInfo : Per-fragment operations info). That WL introduced an error causing 'testScan -n Bug54945 T1' to fail: short-signal scans crashes because the attrinfo section is not available at the point where the code tries to read it to find the size of the interpreted progam. This commit fixes that by not trying to count program size for short-signal scans and lookups. Since these only happen during online upgrade, they are not important for per-fragment statistics.
      Bug #19992856 MYSQL CLUSTER TRIGGER ON DELETE FALSE POSITIVE
      This commit is a followup to the fix for bug#19976428 ("reports failing with 'out of longmessagebuffer' error"). This commit updates a [1;31mregression[m test (testIndex/FireTrigOverload) so that it will expect the right error code (293 "Inconsistent trigger state in TC block" instead of 218 "Out of LongMessageBuffer").
      autotest auto1.diff testBasic -n Bug16834333 : fix dict cache crash
      Bug #19858151         MAKING DATA NODE SELF-EXCLUDE MECHANISM MORE ROBUST
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Updated fix for bug#20113145:
      Follow up to fix for bug#bug#20166585:
      Follow up to fix for bug#bug#20166585:
      This commit fixes bug #19976428 ("reports failing with 'out of longmessagebuffer' error"), and a set of other issues related to the pool of "Fired Trigger" records.
      Bug#17069285 : SEGMENTATION FAULT IN NDB_PRINT_FILE
      Update to recent fix where we failed to close scan cursors at the end of their lifetime.
      WL#7514: Fitted into infoEvent max size and decreased some too wordy log printouts
      Update 'v3' fix for bug#20166585:
      WL#7514: Fixed an incorrect assert
      Fix for various AutoTest 'testIndex ...' crashing due to excessive memory usage.
      Bug#18715165, BUG#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for: - Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT - BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      The AutoTest testcase 'testScan -n Bug54945 T1' crashed as it failed to create a transaction object which was later referred without first checking that it was created.
      Fix for crashing AutoTest: 'testNdbApi -n RecordSpecificationBackwardCompatibility'
      WL#6815  Adapt MySQL Cluster to 5.7
      Fix flexAsynch also in 7.3, backport from 7.4
      WL#7508: Parallelize synchronization of starting nodes with live nodes
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - Test fails since the two new default sql_modes  ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES   are displayed by "show create procedure"  - Update .result file to include the two new default sql_modes(as has been done in similar   places)
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      Experimental fix for several AutoTest which crash with an unreadable stack dump very early in their lifecycle, like:
      Fixed crashing AutoTest testBitfield.
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Cherrypick fix for ndb_memcache out of source from 7.4
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20135403 NDB_MEMCACHE TEST DOES NOT WORK IN OUT OF SOURCE BUILD
      Fixed crashing AutoTest: './testLimits -n ExhaustSegmentedSectionPk WIDE_2COL'
      Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT
      BUG#74594: Fixed a hang in PAUSE LCP protocol when LCP was completed between PAUSE and UNPAUSE
      Removed lots of jam noise from QMGR preventing one from seeing the bugs
      WL#6815  Adapt MySQL Cluster to 5.7
      Revert some junk lines from pfs_upfgrade*.result files
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherry-picked from mysql-5.6.22-release
      Cherry-pick from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-pick from mysql-5.5.41-release
      Added tag mysql-5.6.22
      Added tag mysql-5.5.41
      BUG#74594: Fix missing state update that causes PAUSE LCP protocol to hang
      BUG#74594: Added some more DUMP printouts for PAUSE LCP protocol
      WL#7650: Make atrt work on Mac OS X
      Removed assert / require from NDBT_ResultRow c'tor and rewrote it such that it could be constructed even if the the object is not in 'Retrieved' state.
      BUG#75007: Ensure we wait until master takeover is completed before handle LCP_COMPLETE_REP from LQH and DIH participants in the LCP protocol
      Bug#20029843 7.4.2 REGRESSION: UPGRADE_TRAFFIC FAILURES FOR 7.4 -> 7.3: Fixed incorrect conditional expressions
      Cherrypick fix for ndb_dist_priv.sql from 7.4
      WL#6815  Adapt MySQL Cluster to 5.7
      Cherrypick fix for mysql_system_tables_fix.sql from 7.4
      WL#6815 Adapt MySQL Cluster to 5.7
      Encourage MySQL to treat numeric variables as numbers so that ndb_rpl_conflict_epoch2_extra does not return incorrect results from inequality tests.
      BUG#75007: More work on ensuring that we drop the right signals of the LCP_COMPLETE_REP and LCP_FRAG_REP, a bit tricky to decide, wrote up an analysis in a comment and a fairly simple code based on this analysis
      Cherrypick fixes for ndb_alter_table_online from 7.4
      Remove usage of DEFAULT 0 for TIMESTAMP
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fixed for ndb_update_no_read from 7.4
      Turn "info" off after each section in test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fix for ndb_dd_disk2memory from 7.4
      Add missing enable_query_log comman in ndb_dd_disk2memory.test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75007: Fixed interaction with early master takeover initialisation and handling of failed node in LCP, code in new master
      BUG#75007: Handle side effect of bug fix, there are signals generated by node failure handling that must be allowed to pass through the code as they are required for node fail handling to be done properly
      Apply patch for MCP_BUG19704825to 5.7.5
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#74594: Fix of variable length in message to management server to avoid printing garbage
      BUG#75007: Ensure that we drop LCP_FRAG_REP and LCP_COMPLETE_REP that originates from a dead node. The LCP could potentially be done before this arrives due to node failure handling, these signals are sometimes delayed and thus we need to take care that we can still receive them.
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Assumption that all alive nodes have participated in LCP at close down time caused havoc since we can now be alive and still not have participated in the LCP. So had to move the send of the last LCP_COMPLETE_REP backwards a bit to be able to reuse the m_participatingDIH bitmap to send to.
      remove last NDB_WITHOUT_COLUMN_FORMAT ifdef  - since all versions of MySQL Server which ndbcluster   compiles against now supports "field->column_format" and "field->storage_type" - one NDB_WITHOUT_COLUMN_FORMAT left behind(or reappeared)
      BUG#19795152: Missed essential ptrCheckGuard in upgrade/downgrade situations
      WL#7514: More printouts to log for system restart case
      BUG#18610698: New test case
      BUG19795152: Fix Software upgrade issue
      Add missing delete of Ndb instance created by testcase
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Minor tweak of jamming and of a loop
      BUG#19795217: Checked the LCP state a bit too early
      BUG#74594: Added one more cluster log event
      BUG#74594: Wrong check if LCP is idle when sending UnPause message
      bug#20045455 Improve error reporting for clusterj
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Fixed a compiler warning in new tool
      BUG#74594: Wrote an analysis tool for reading DIH Fraglist files to enable easier analysis of system restart bugs
      BUG#74594: Queued LCP_COMPLETE_REP comes from LQH, not from DIH
      BUG#74594: Fixed a typo bug in an important condition
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Added a new ndbrequire to find problem
      WL#7514: Added a bit more logging of the actual start order signal
      flexBench created its worker threads, flexBenchThread, with a stack of insufficent size. This later caused the threads to crash.
      WL#7509: Add undocumented interface to change Disk Write Speed in LCPs, change isn't persistent over restarts, useful to handle SRs where restarts are too slow
      WL#7509: Tweaked the adaptive LCP speed parameters to be a bit slower in changing
      BUG#74594: Add DUMP_STATE_ORD variant to print pause state to cluster log
      BUG#19795108: Proper fix of node restart status using the new Node Recovery Status module
      BUG#19795152: Handle Partial System restarts
      BUG#74594: Used wrong variable in non-master to decide on pauseAction
      Attempt better "htonll" portability in NDB memcache code
      Fix for bug#19390895
      BUG#74594: Ensure that we drop PAUSE_LCP_REQ signals from master if it concerns a node that already has died
      BUG#74594: Node failure in inopportune time caused crash
      BUG#74594: Decrease amount of useless jam:ing to make bugs more visible
      Bug#19642978: NDB_RESTORE CORES ON BUILT-IN PRIMARY KEY + STAGING BLOB CONVERSIONS ON SPARC
      Fix for bug#20031313  AUTOTEST CASE 'TESTDICT -N GETTABINFOREF' NEVER WORKED FOR >= 4 DATA NODES
      BUG#74594: Turned ndbrequire condition the wrong way, caused obvious crash, added a few more ndbrequires while at it
      BUG#19795152: Also NODE_FAILURE_COMPLETED and ALLOCATED_NODE_ID can be states from where a node fails from DISCONNECT_REP although the node hasn't really started its start yet.
      BUG#74594: Removed buggy ndbrequire, not correct though to possibility of delaying arrival of LCP_FRAG_REP when copying table to disk
      BUG#19795152: NdbTick_Elapsed parameters in wrong order
      BUG#19795152: Added one more acceptable state transition, ALLOCATED_NODE_ID -> ALLOCATED_NODE_ID
      BUG#74594: Missed setting lcp id in COPY_TABREQ, added ints of LCP variables on replica and fragment records, removed init of lcpStatus in INCL_NODEREQ which depended on old fact that we included when LCP was idle, now this is no longer necessary, missed init of m_lcp_start_time in including node in LCP, added a number of log prints
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#19676350 NDB_RPL_CONFLICT_EPOCH SHOWS SCHEMA DIST TIME FAST FORWARD DUE TO EINVAL
      BUG#74594: missed init of c_queued_lcp_complete_rep
      BUG#74594: Handle fromTimeQueue issues with LCP_FRAG_REP
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed stopping of pause properly in master and in non-master
      BUG#74594: Wrong assumption in START_LCP_REQ removed, fix of ndbrequire of COPY_TABREQ counter improved
      BUG#74594: Added new parameters to allocStoredReplica
      BUG#74594: Missed init of fragId and tableId in replica record, wrong assumption about m_participatingDIH in START_LCP_REQ
      BUG#74594: Missed clear of own node in NodeReceiverGroup in sending FLUSH_LCP_REP_REQ
      BUG#74594: Fixed typo
      BUG#74594: Missing inserts into signal table
      BUG#74594: Fixes for wrong assert, missing state update and wrong condition
      BUG#74594, fix for sanity check
      BUG#19795152: Fix a placement new that overwrote the node recovery timers in debug mode, added a bit more debug code and arranged the parameters in some common functions a bit more logically
      BUG#74594: Added missing file CopyTab.hpp
      BUG#74594: Remove need for long wait for LCP to copy meta data to make restart times more predictable and faster
      BUG#74639: Preparatory patch to handle overload bugs that is likely to be caused by higher pressure on LCPs and restarts
      BUG#19795152: Added missing file: NodeRecoveryStatusRep.hpp
      BUG#19795152: Wait for LCP start at node restart, add node recovery status table as well
      BUG#19795217: Remove EMPTY_LCP protocol from master takeover
      BUG#74594: Part 2: Fix a potential LCP stoppage
      BUG#74594: Part 1: Remove a faulty ndbrequire
      BUG#19795029: Improve logging of restarts developed in WL#7514
      BUG#19795108: Fix of node restart status for adapting speed of LCP disk write speed
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug#20007248 NDB NOT FUNCTIONAL ON POWER
      Bug#20007216 FLEXASYNC USES 32BIT MATH, LEADING TO INCORRECT SUMMARY ON POWER8
      Fix [1;31mregression[m in AutoTest -n DropWithTakeover T1 introduced by fix for bug#19874809:
      Add missing newline before end of file in AsyncNdbContext.cpp
      Fix build failure in MCP patch for BUG19553099
      bug#20017292 Clusterj logging levels too verbose
      Bug#20009152 FIELD NAME NOT INCLUDED IN WARNING WHEN CONVERTING TO FIXED
      WL#7640  Ndb Active Active Delete-Delete handling
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Fix Club test [1;31mregression[ms after backport of bug#19524096:
      WL#7640  Ndb Active Active Delete-Delete handling
      Provide easy way to store documents with no mapping and no schema defined   define new method on session factory: db(database_name) returns db object   db object has properties corresponding to table names     if table does not exist, create the table       if user has not mapped the table, create default table mapping and table       if user has mapped the table, use table mapping to create the table   Operations on session using non-existing table name     will now create the table if it does not exist and user has mapped the table
      Fix bad #ifdef
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Bug #19817817 TFBUFFER::VALIDATE() CONST: ASSERTION `(P->M_BYTES & 3) == 0\' FAILED
      Backport of fix for bug#19524096
      Bug#19999242 DELETEING NDB_CLUSTER_CONNECTION WITH NDB INSTANCES
      bug#19913569
      Avoid segv when closing session factory with sessions still active
      Bug #17592990: DATA MISMATCH BETWEEN C NDB API AND MYSQL CLI.
      Backport of fix for Bug#19724313
      Fix for bug#19880747:
      Fix for bug#19875663
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Fix for bug#19881025:
      This commit is an update of WL#7375 (Ndbinfo: Per-fragment memory usage reporting). Column fixed_elem_free_rows in view ndbinfo.memory_per_fragment is renamed to fixed_elem_free_count to get a more consisten naming.
      Fix for bug#19874809 :
      Added sles11 repo packages
      This commit implements WL#8145 (NdbInfo : Per-fragment operations info).
      Follow up fix for bug#18352514 fixing a build failure.
      Addendum fix for bug#18352514:
      bump version to 7.4.3
      Bug #19875710         NDB : COMMIT ACK MARKERS LEAK @ LQH IN 7.4
      BUG#19815044: Part 4, remove usage of global block variable m_pgman_ptr, it is used for parameter passing, but can in some weird situation in DBTUP it can be reassigned to a value that can cause an inconsistent database.
      BUG#19815044: Part 3, fix such that an aborted insert after a committed delete doesn't lead to that triggers for delete isn't executed by ensuring that delete_insert_flag is properly maintained
      BUG#19815044: Part 1: Improve jamming support to make it easier to read what's going on bug situations
      BUG#19815044: Add test case for it used in autotest
      BUG#19815041: Crash on abort of delete after successful delete on a disk data table
      Add global.fail_connect to test utilities
      Fix ProjectionErrorTest
      Improve error reporting for multidb tests
      big lint-fixing patch
      Fix unified_debug issue with per-file levels for C++ files Remove workaround for this in executable programs
      Converter use in DBTableHandler (fixes freeform tests for ndb)
      Big deglobalization patch. Removes many global variables (but not all).
      Move SQL.create and SQL.drop from test harness into adapters. NDB depends on MySQL for this.
      Enhance closeAllOpenSessionFactories() so it takes a callback & returns a promise
      Fix for bug#19712569
      When using node --harmony and strict mode, DBIndexHandler cannot be forward declared   and still use the function DBIndexHandler(parent, dbIndex) syntax.
      jscrund: add support for B tests with varying size varchar. (Only supported by jscrund_mysqljs crund backend).
      lint globals cleanup
      Fixes restart race causing test timeout in AutoTest 'testDict -n schemaTrans'
      Return an error if writing non-Buffer data to binary columns
      Allow flexible mapping for node.js domain classes
      Fix for bug#18352514
      Fix for bug#19661543
      Remove warning introduced with patch for BUG#19236945
      Bug #19236945 ADDRESSSANITIZER BUG SHOW UP IN NDBRECATTR::RECEIVE_DATA CALLED FROM RESTORE.CPP
      bug#19793475 - NO WAIT FOR EPOCHS THAT HAVE NO DB CHANGES MADE BY THIS NDB THD TO BE IN BINLOG
      Removing the extra blank line from daily-basic-autotest-conf
      Fixed compilation error due to changed file name
      Bug#19267720:  NDB REPLICATION : DO NOT SETUP CONFLICT RESOLUTION FOR EXCEPTIONS TABLES
      formatting
      Docs work
      BUG#19795072: Fix problems related to ndbinfo tables for disk write speed
      BUG#19643174: Fix races in relation to sending TC_COMMIT_ACK and handling of complete of a transaction
      Removed compiler warnings
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000): GOT ERROR 4547 PART II
      Cherrypick from 7.4 (revno 4354): Implement status variables exposing last commit epochs for the server   and each session.
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      BUG#19724313: Handle multiple threads crashing at the same time properly
      Added missing include for previous patch Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Restore computeChecksum to computeXorChecksum that was reverted in patch for Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Merge of Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Refactoring of Packer::unpack in preparation of merging Bug#19582925
      Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      wl#7674-5 fixing errors
      wl#7674-5 fixing errors and compiler warnings
      wl#7674 Backward compatibility/new event api methods
      wl#7675 Introduce state machine for event buffering
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) : GOT ERROR 4547 : 'RecordSpecification has overlapping offsets'
      Applying the patch for [1;31mregression[m bug#19582807 for 7.1.33 cluster release
      Improve Query documentation
      Cherrypicked
      Cherrypicked
      Bug #19582807 MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Wl#7639 Ndb Active Active Manageability improvements
      Removed compiler warnings
      WL#7642 Ndb Active Active Binlog Read Tracking: Removed uninitialized data to remove valgrind warnings
      Work on new README
      Bug #17257842     EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #19766167         NDB : VALGRIND REACHABLE MEMORY IN NDB_RPL_CONFLICT_EPOCH_TRANS
      Fix new log printouts - Use log functions of component in favour of sql_print_information - Break long lines
      In-Progress Packaging / Documentation improvements
      Iterate array rather than for/in
      Add mynode.closeAllOpenSessionFactories()
      Windows testcase fix attempt
      Follow up patch for WL#7953 Transporter handshake retry
      WL#7642 Ndb Active Active Binlog Read Tracking: Updated result for ndb_rpl_conflict_read_tracking test case to reflect new conflict counters
      WL#7640  Ndb Active Active Delete-Delete handling
      bump version to 7.3.8
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      bump version to 7.2.19
      bump version to 7.1.34
      Bug#19692387 PORT FIX FOR BUG 18770469 TO MYSQL CLUSTER 7.3
      Added ndb_print_file man pages
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug#18487960: SIG 11 on delete with index merge
      Follow up patch for WL#7953 Transporter handshake retry
      Follow up patch for WL#7953 Transporter handshake retry
      Patch 2 for WL#7953 Transporter handshake retry
      Patch 1 for WL#7953 Transporter handshake retry
      Patch 3 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 2 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 1 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      adding checksum to the cnf file
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19600834  late code review comment
      Bug #19600834 DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH)
      Bug #19600834         DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH) ...
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3
      Bug #19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3  - revert the reverted
      Bug#19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Change from mysql-5.6 to build Oracle Linux 7 RPMs
      WL#7640  Ndb Active Active Delete-Delete handling
      WL7640 Add delete-delete conflict count
      Adding ndb_print_file to spec file
      Repush of WL#7544 after 7.4.1 clone tag.
      bump version to 7.4.2
      Set version 7.4.1
      Revert WL#7544, not to be included in DMR 7.4.1
      Reorder member initializer list for thr_data to follow initialization order. This removes compiler warning introduced in fix of Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      WL#7544: Optimisations of the NDB API receiver thread in various manners. 1) Optimising method to unpack field data from TRANSID_AI signal, 2) optimised handling of trp_client locking check, 3) reorganised code in NDB API receiver thread for better performance and more readability, 4) Optimisation signal receive handler
      BUG#19451060: One more step on the way to understanding commit ack markers
      Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Fix for bug#19559313, call getPerformStateString() with a nodeId arg instead of a state argument
      Fix for Bug#19552283 :
      Update documentation to remove useProjection       Update Session.js to remove useProjection
      BUG#19552349: Avoid stack overrun by removing endless recursive call
      BUG#19451060: Further refinements of bug fix, previous ndbrequire revealed a race that could cause multiple REMOVE_MARKER_ORDs to appear for the same transaction, added long comment about this specific race variant. Left a part of the ndbrequire still to ensure that this only happens when receiving REMOVE_MARKER_ORD sent by API through TC_COMMIT_ACK and not through API failure handling
      Bug #18703922  DUMP-CODE ACTIVATED DEBUGGING ON WATCHDOG OVERLOAD ISSUES
      Bug #17730825  NDB API: POSSIBLE LEAK OF CONNECTION OBJECTS
      BUG#19524096: Converted many 4009 errors to temporary error 4035, ensured APIs can use new data nodes sooner, fixed some wrong error categories, removed no longer used errors, fixed some anomaly in communication towards the API, small improvement of restart printouts, should give autotest a much better chance to get rid of redness
      Bug #17893872         ER_DUP_ENTRY WHEN INSERTING TO AUTO-INC COLUMN ON SPARC MULTI-MASTER SETUP
      BUG#19451060: Added more descriptive information at crashes related to commit ack markers, changed name of noFired to numFired for clarity, added possibility to put last in free list to aid crash printouts
      Fix for spelling error in Win32 code
      WL#7509: Introduced more configurability of disk write speeds and added a number of new ndbinfo tables to track this new more adaptive behaviour
      WL7845: More and safer ways to print records in DBTC
      BUG#19451049: Missing call to prepareTUPKEYREQ from handle_lcp_keep, added comment about handle_lcp_keep
      bug#19124970 - PB WITH POLLEVENTS , NDBEVENTS
      Backport from 7.2
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      The Bug was due to m_out object used in NdbOut operator was not initialized/set to the output stream. Added an ndb_init() call to initialize it to output stream. Added an environmental variable $NDB_PRINT_FILE to give path to its binary in  mysql-test/mysql-test-run.pl file. Added a unit test and its result file.
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      bug#19031389 bugfix.diff bug fix
      bug#19031389 bugtest.diff bug test
      BUG#19513967: Fixed missing init of longer bitmask
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      BUG#17703874
      Bug#19202654: NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      Bug #18354165         16723708 CHANGED EVENT CATEGORY VALUES
      Clusterj windows CMakeList error
      Clusterj support for autoincrement columns http://wl.no.oracle.com/worklog/NDB-RawIdeaBin/index.pl?tid=8027
      Added missing logging.properties
      Clusterj improve maven handling for out-of-source builds
      Bug#18875137: NDB_RESTORE STILL MISSING SOME TYPE CONVERSIONS
      Fix for Bug#19414511:
      Bug #19236785  ADDRESSSANITIZER BUG IN ~NDB_MOVE_DATA Bug #73311      AddressSanitizer bug in ~Ndb_move_data
      Bug #19235428  ADDRESSSANITIZER BUG IN DATABUFFER2<SZ,POOL>::IMPORT (DBDICT::ALTERTABLE_PARSE) Bug #73310     AddressSanitizer bug in DataBuffer2<sz,Pool>::import (Dbdict::alterTable_parse)
      Bug #19235170  ADDRESSSANITIZER BUG IN DBUTIL::GET_SYSTAB_TABLEID Bug #73308  AddressSanitizer bug in DbUtil::get_systab_tableid
      Bug#11764704 : Exclude missing tables when restoring a backup  - added an option "--exclude-missing-tables" to ndb_restore tool  - when enabled, the missing tables will be added to the    exclude tables list before starting to restore.  - updated test cases accordingly.
      Revert fix merged in from 5.5.39 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert fix merged in from 5.6.20 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert quick fix for dtrace problems in release tree. New fix in CMake files will be merged in from 5.6.20.
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      This commit is a followup to the one below. It changes the fragment_num colum (in memory_per_fragment), such that it gives the global frgament id rather than a node-local sequence number. That way, it is possible to see where each fragment (or some replica of it) is located. This is consistent with the output from 'ndb_desc -pn -d <database> <table>.
      Bug 19028487 NPE when scanning rows with blob or text columns
      More fixes for bug#19053226
      Fixes for bug#19053226
      More fixes for bug#19053226
      bug#18410939 - MEMORY LEAK AT EVENT BUFFER ALLOCATING A DUMMY EVENT LIST WHEN INCONSISTENCY
      Bug #17184024         ERROR 4 IN LIBNDBCLIENT.SO.6.0.0 (3-7474573041)
      bug#19122346 fix3.diff FK use full name PP/CC/name + debug
      bug#19122346 fix2.diff fix test error from 7.3 r4203 FK_Bug18069680
      bug#19122346 fix1.diff FK use full name PP/CC/name
      ndb - RSS-DynArr256
      A new ndbapi test case: testNodeRestart -n DeleteRestart.
      Bug #18731008    NDB : AVOID MAPPING EMPTY PAGES DUE TO DELETES DURING NR Bug #18683398    MEMORY LEAK DURING ROLLING RESTART
      Bug #19193927         TC TAKEOVER TAKES TOO LONG CAUSING MANY PROBLEMS
      ndb
      Bug#19193756 MTR GENERATES TOO LONG SOCKET PATHS
      Merge from mysql-cluster-7.2.17-release
      ndb
      use primitive types
      Include stdlib.h for malloc() and free()
      Compiler issues on some Windows platforms
      Add debug to trace bug#18411034 - CRASH IN NDB-SHARE
      Updated the list of tables to be deleted after running ndb clusterj tests Added new test and the model to build specification
      Merge latest nodejs-adapter from 7.3 to 7.4
      Unconditionally disable dtrace for rpm, barfs on Oracle dtrace
      Remove superfluous -master.opt file for the removed test case ndb_mt_recv.
      Unconditionally disable dtrace for rpm-oel, barfs on Oracle dtrace
      correcting copyright headers
      Fix issues with Read/Modify/Update of NDB VO objects containing blobs.
      All NDB read results (including those containing BLOB and TEXT columns) are now ValueObjects.
      Fix bug of using Persistent<T>(x) rather than Persistent<T>::New(x)
      work on support for NdbRecord-backed ValueObjects which contain TEXT or BLOB columns.
      More TEXT tests for NDB
      less debugging output at end of test run
      Fix composition value checking
      Implement bufferForText and textFromBuffer in C++.
      rawNdbDefaultvalue does not require a full-fledged Node Buffer
      let compiler supply default destructors
      Another attempt to fix crashing bug in BlobHandler
      Expose the string encoder statistics in NdbTypeEncoder.cpp to JavaScript.
      Move v8 calls from worker thread to main JS thread
      Support TEXT columns with character set UTF-8 or ASCII. Other charsets (which require recoding) are not yet supported.
      A test file that does not export a test case now causes a warning rather than an error.  This should make it a little easier to develop new tests.
      Column Metadata API provides charsetName rather than charsetNumber
      Fix apparent bug in calculating size requirement of UTF-8 buffer
      Restore compatibility with node-mysql 2.0.0
      Fix crash on stub commit / stub rollback
      update cmake & gyp build lists
      Finish read & write BLOB implementation for NDB adapter
      Implement connection pooling for mysql adapter
      Fix tests that do not close session after running test
      Improve error reporting for connecting to database
      Add suggestion to user to maximize performance of updates
      Improve spi test error reporting
      Succesful insert into BLOB column
      Add BLOB column to stringtypes test suite & confirm that existing tests pass with a mapped (but unused) BLOB field.
      Test that storing a non-BLOB in a BINARY column gives error SQLState 22000
      Use Error SQLState 0F001 "Bad BLOB" (actually a "Locator Exception") if value intended for a BLOB column is not a Buffer.
      Initial implementation work on BLOB support for NDB adapter.
      Refactor connection handling to prepare for connection pooling
      WL#7626 Implement many-to-many relationships for Document Composition
      Don't try immediate startTransaction() unless using async api.
      Keep a single usedOperationSets array rather than one per DBSession. The array is at file scope in NdbTransactionHandler. It does not grow past 4000 elements (a literal constant). Underlying DBOperationSet native objects are freed when the wrapper is placed in the recycler array.
      Disable mysql tests for now
      Attempt to recycle DBOperationSet wrappers
      wrapPointerInObject and unwrapPointer take a v8::Handle<T> rather than a v8::Local<T>
      Improve error reporting for relationships that are null or undefined
      Test a slightly different approach to V8 wrapping
      Minor refactoring in NdbOperation
      Remove the use of "proto" in DBTableHandler
      Refactor DBTableHandler.getFields() into a simple case getFields() and a separate more complex getFieldsWithListener(). Removed the resolveDefaults option which was always set to false.
      Improve error reporting for ProjectionTest
      Improve error reporting for ProjectionTest
      Improve error reporting for test failures
      Compiler error
      Stub out NdbSession.buildReadProjectionOperation in hopes that test suite will run.
      WL#7626 Composition Implement support for one-one, one-many, and many-many relationships. Replace useProjection with implementation for find (projection, key).
      Rather than having a JavaScript wrapper for Record::setNotNull(), implicitly call setNotNull() when writing a data value in encoderWrite().
      Don't use a startTransaction() hint for unique key operations.
      In JsValueConverter for pointer types, if the JavaScript value is Null, represent it as a null pointer.
      Remove what little was left of NdbTransaction_wrapper.cpp
      move ENABLE_WRAPPER_TYPE_CHECKS define into adapter_global.h
      portability fix
      Update source file lists for gyp & CMake
      Add option free-percent
      New design for scans. This removes the previous wrapper for NdbScanOperation and ScanImpl.cpp file and consolidates all scan functions into ScanOperation. Expected: start 416 tests, pass 413, fail 2, skip 1.
      fix wrappers for boolean types
      In test driver allow --stats=query, e.g. --stats=spi/ndb/DBSession
      Add HandleScope to all toJS() template functions just to be safer from enigmatic V8 memory leaks. Provide toJS() and isWrappedPointer() specializations for type bool.
      Refactor NDB execute. This patch renames PendingOperationSet to DBOperationSet, and makes DBOperationSet the "point of contact" for JavaScript calls to begin and execute transactions. All t_basic tests now pass.
      New SPI test   begin transaction; delete (execute NoCommit) ; read deleted row ; commit.
      Minor bug fixes for passing SPI tests
      Major JavaScript logic changes in NDB adapter. NdbTransactionContext, NdbSession, NdbOperation, and NdbConnectionPool are adapted to use the call flow of DBSessionImpl and DBTransactionContext rather than the native call flow of the NDB API.
      This commit includes various small C++ fixes. The next commit includes major JavaScript logic changes. With these together, spi tests pass.
      Add new connection property ndb_sesion_concurrency Refactor initialization of NdbSession and connecting of the new NdbSession to its impl.
      Adapt DBDictionaryImpl to use DBSessionImpl rather than Ndb.
      Revise protocol for registering a transaction open / closed. Use only two calls, registerIntentToOpen() and registerTxClosed(). Always make these calls from JavaScript main thread.
      NdbTransaction is no longer wrapped for JavaScript
      Template class NativeCFunctionCall_4_
      DBSessionImpl
      Adapt AsyncNdbContext to be aware of DBTransactionContext
      executeAsync() on AsyncNdbContext is no longer wrapped for JavaScript; use executeAsync() on DBTransactionContext instead.
      Refactor DBOperationHelper:  it now takes a DBTransactionContext rather than an NdbTransaction.  it now defines operations, but does not prepare them.
      Rename addOperation() to getNextOperation()
      Add two new classes, DBTransactionContext and DBSessionImpl. These will free the JavaScript code from the start/prepare/execute cycle of Ndb and NdbTransaction, eventually allowing operations to be performed with fewer scheduled async calls and therefore less overhead.
      Adapt DBOperationHelper to the KeyOperation / ScanOperation change.
      Bug fix where the do_close flag must be associated with the transaction rather than its parent Ndb object.
      Refactor Operation and DBScanHelper into two classes called KeyOperation and ScanOperation.
      This change alllows Ndb::startTransaction() to run as a sync call in the main JS thread if we suspect that it will not block.  As a proof of concept, this allows you to measure the performance with this change; but it should not be used as-is, because the guess could be wrong, which would cause the main thread to block waiting for network I/O.
      In the common case where an async method call returns int zero, try to optimize away creating a new JavaScript value.
      Slight change to the compatibility strategy for some libuv changes.
      Combine NdbTransaction execute() and close() into a single scheduled call whenever execType is Commit or Rollback.  This saves the scheduling cost of running the close() call by itself.
      Various fixes for lint.
      Remove old stats API.
      Use new stats API in MySQL code.
      Use new stats API in NDB code.
      Revised statistics API. Now each module owns, at file scope, its own stats object. The module registers the stats object with the global statistics, which keeps a reference to it in the stats tree. This should reduce the cost of keeping statistics to practically zero.
      Delay after (rather than before) the first test iteration. This allows V8 to compile all the JavaScript code before dtrace starts running. High dtrace profiling rates caused the first iteration to run very slowly and skewed the profile towards compile times rather than run times.
      Optional delays both before & after jscrund run
      jscrund: add option to delay start of test run
      Add useProjection to Session   this function specifies a projection to be used for find and query operations
      Minor work on DBDictionaryImpl Contain the code for handling NdbDictionary 3-part/slashed/names in DictionaryNameSplitter class. Reformat patch indent width from 4 spaces to 2 spaces. buildDBForeignKey() takes only the fk* and must use its own private name splitter.
      Error 23000 when attempting to set a non-nullable column to null.
      Restore table which should not have been removed from test suite
      Add support for foreign key metadata
      update literal mapping test for schema
      Fix errors in test case & misc. lint errors.
      Check in test case where one operation in a batch has a data type error. This test fails for both NDB and MySQL.
      Expose NdbRecordObject::prepare() to JavaScript. This is a step towards fixing handling of encoder errors for value objects.
      Write a negative value to an unsigned int field of an NDB Value Object. This test causes the test suite to hang forever.
      Run executeAsynch() in JS main thread rather than a UV worker thread. We had seen higher latency using async ndbapi vs. sync ndbapi, but this change eliminates most of that difference.
      unused table in test suite
      Fix for compiler warning in TimestampWriter validity check
      NDB encoding-related changes.  (1) distinguish between 22003 numeric value out of range and HY000 for "value is not numeric"  (2) provide a (hopefully) faster path to encoderWrite and encoderRead by wrapping them as methods of Record
      Refactor error handling
      Attempt to optimize encodeKeyBuffer() for single-column indexes
      Fix reporting of session factory if no mappings
      Remove JsValueAdapter in loader; it is no longer needed.
      This fixes the failing "timestamp 1969" test case for NDB. Test still fails with MySQL.
      Fixes for lint test failures
      Test & fix NDB handling of encoder errors for numeric types
      Tests for numeric types
      This renames the integraltypes suite to numerictypes and adds stub tests for float, double, and decimal columns
      Test for particular expected errors rather than simply for operation failure
      Add decimal support in NdbTypeEncoders Remove JS wrapper for decimal utilities from ndb_util
      Encoders for NDB integer values: if the fast integer conversion fails, try a slow one, then test whether the result is legal.  This should allow writing valid JS string and float values to int columns.
      Improve handling of errors from NDB data type encoders
      Improve handling of data encoder errors in the ndb adapter
      fix sql_mode for mysql adapter
      Implemented test cases
      Stub out new test cases for data type casting
      If MySQLTime.valid is set to false, NdbTypeEncoder will reject the value.
      Allow user to set sql_mode in mysql adapter with a default of STRICT_ALL_TABLES
      Change console.log to udebug.log in issues/2014-03-18Test
      Add shell script to manage regular runs of jscrund
      Adapt loader to use new Batch.getOperationCount() api
      Batch: use getOperationCount()  rather than getSize()
      Add Batch.getSize() method
      Add test case for issue of bad data type for column
      Fix typo
      Add test case for issue where a TableMapping created from a literal mapping could not be used to perform operations (fixed in bzr 686).
      Changes to sample data loader after code review with Craig. This version still has lots of untested features (and combinations of features) but it can load CSV data and random data.
      Bug fix creating TableMapping from object literal
      WL#7578 Replace usage of ndb_schema_share->key with hardcoded text
      WL#7578 Move subscriber bitmaps to NDB binlog component
      WL#7578 Move the g_nodeid_map to Ndb binlog thread
      WL#7578 move clearing of subscribed to binlog thread
      WL#7578 Always expect everyone to ack the schema op
      WL#7578 Refactor schema distribution code
      WL#7578 Refactor schema distribution code
      ndb
      WL#7578 note about nodeid from global cluster connection
      WL#7578 Don't use ndb_schema_share from ack_schema_op
      Initial checkin of JavaScript data loader tool
      Remove windows line endings from ndb_schema_object.cc
      Try to reduce overhead of stats.incr() calls
      Remove the error handling in jscrund_mysqljs backend which duplicates work performed in the jscrund frontend.
      Add conditional guards around udebug log messages.
      Add conditional guards around udebug log statements.
      Improve error reporting while loading mysql node_module
      The node-mysql driver by default constructs an Error object in order to get a stack that includes the user's call to Query. This can be a performance bottleneck.

[33mcommit b1c132ea01724d755453a334cedaf47dbe635caa[m
Merge: 4129e497b95 94ae74578a5
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Mar 17 15:46:28 2015 +0200

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug#20691930 5.7.6 CRASH WHEN RUNNING MYSQL_UPGRADE AFTER BINARY UPGRADE This is a [1;31mregression[m from Bug#17345513 CHECKING FIL_PAGE_TYPE BREAKS COMPATIBILITY WITH OLD INNODB DATA FILES
      BUG#20562022: ED_CONNECTION::EXECUTE_DIRECT() USES UNINITIALIZED VALUES
      Bug #20536590: BACKPORT BUG #12368204 AND BUG #16953758 TO MYSQL-5.6
      Fix comments about recommended way to build.
      Fix comments about recommended way to build.
      Fix comments about recommended way to build.
      Fix comments about recommended way to build.
      Fix comments about recommended way to build.
      Followup: bug#20651493 INNODB FTS WITH MECAB PARSER PRINTS EMPTY ERROR MESSAGE
      Remove redundancy in release test suite. funcs_1 is a default suite and run with ps-protocol is covered by "--comment=ps" run
      Bug#19822257 WRONG VALUE PASSED TO --INIT-FILE OPTION CAUSES SERVER HANG
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#8326: Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      Bug#20661940 REDUCE DEPENDENCIES ON MYSQLD.H
      Bug # 20645725 GRAVE ACCENT CHARACTER (`) IS NOT FOLLOWED WITH BACKSLASH WHEN ESCAPING IT

[33mcommit 8a479d84b76ce806a164935b91b2a8aa94e55ff9[m
Author: Praveenkumar.Hulakund <praveenkumar.hulakund@oracle.com>
Date:   Mon Feb 16 14:07:22 2015 +0530

    Bug#20030284 - HANDLE_FATAL_SIGNAL (SIG=11) IN NAME_HASH_SEARCH
    
    Followup patch to fix [1;31mregression[m caused in trunk.
    
    Some tests were failing in trunk because of resetting
    db name to "NULL" for derived tables which aren't created
    for views.
    
    Changed code to reset db name only for views in function
    TABLE_LIST::reset_name_temporary.

[33mcommit 716906eadca3b4f27a97385aa499e974c7fb094f[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Wed Jun 18 09:47:56 2014 +0300

    WL#7806: Add a flat fil_sys_lookup[] array so that fil_spaces_lookup()
    can avoid acquiring fil_system->mutex when looking up the system tablespace
    or the undo tablespaces. This is addressing a performance [1;31mregression[m.
    
    Why not use a variable-size lookup structure such as std::map? Answer:
    Any dynamically sized data structure would require some locking (or
    atomics) around it, to prevent problems when there is concurrent
    modification to other elements while a lookup is in progress.
    
    In this patch, the fil_sys_lookup[] table will also be used for looking up
    the first user tablespaces whose space_id falls within the array boundaries.
For keyword speed:
[33mcommit 71ed510f5840e72c0a003a9d8b9e53d8dd495bdc[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Fri Jan 19 21:54:03 2018 +0100

    Bug#27403367: GENERATED COLUMN EXPRESSIONS IGNORED WITH PREFIX INDEX
    
    Generated columns with a prefix index are not considered when the
    optimizer attempts to substitute expressions with an equivalent
    generated column. This prevents use of prefix indexes to [1;31mspeed[m up
    queries with predicates that use a generated column expression.
    
    This patch makes the optimizer also consider the generated columns
    that have a prefix index.
    
    Change-Id: Id1b803a8ad39b334b0ef95e50c87f4a21c1d4065

[33mcommit 5c072b1481bc996185d30fe7484bd750cf5b78fc[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Fri Feb 16 16:27:26 2018 +0100

    BUG#27493720: INPLACE ALTER TABLE FAILS ON PARTICIPANT AFTER FIX FOR
    BUG#25915132
    
    Problem: Cloning a dd::Table object only worked correctly if
    sub-objects had been assigned a valid dd::Object_id. As this is done
    when the object is stored, it meant that unstored object could not be
    cloned. Root cause was that the Object_id was used to establish
    cross-references inside the dd::Table object-tree when cloning.
    
    Solution: Use ordinal position, rather than dd::Object_id when
    establishing cross-references during clone. Using the ordinal position
    provides a [1;31mspeed[mup compared to the linear search through a Collection
    and comparing names. Comparing names would work even for objects which
    have not been stored and thus do not have valid Object_ids.
    
    For cloning we assume that all sub-objects in the source have correct
    ordinal positions matching their current place in the Collection. It
    is also assumed that the Column collection has been correctly cloned
    before cloning the Index_elements, and the Index collection has been
    correctly cloned before cloning the Partion_indexes. This was always
    the case as the get_column() and get_index() apis used previously also
    depended on the collections being cloned in the right order.
    
    Change-Id: I56a0c19f2e5e54fbfdc899ef75072abdb4e5b1e9
    (cherry picked from commit d61472af985382eac89c98cb85ff8e0ba341aaa9)

[33mcommit e59dc28e4984aab4ba59e331c619473714a2e760[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Fri Feb 16 16:27:26 2018 +0100

    BUG#27493720: INPLACE ALTER TABLE FAILS ON PARTICIPANT AFTER FIX FOR
    BUG#25915132
    
    Problem: Cloning a dd::Table object only worked correctly if
    sub-objects had been assigned a valid dd::Object_id. As this is done
    when the object is stored, it meant that unstored object could not be
    cloned. Root cause was that the Object_id was used to establish
    cross-references inside the dd::Table object-tree when cloning.
    
    Solution: Use ordinal position, rather than dd::Object_id when
    establishing cross-references during clone. Using the ordinal position
    provides a [1;31mspeed[mup compared to the linear search through a Collection
    and comparing names. Comparing names would work even for objects which
    have not been stored and thus do not have valid Object_ids.
    
    For cloning we assume that all sub-objects in the source have correct
    ordinal positions matching their current place in the Collection. It
    is also assumed that the Column collection has been correctly cloned
    before cloning the Index_elements, and the Index collection has been
    correctly cloned before cloning the Partion_indexes. This was always
    the case as the get_column() and get_index() apis used previously also
    depended on the collections being cloned in the right order.
    
    Change-Id: I56a0c19f2e5e54fbfdc899ef75072abdb4e5b1e9

[33mcommit 60d8e4614ce5d92d4318912c0c62342d3f511687[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Tue Nov 28 11:51:38 2017 +0530

    WL #8478: UNDO log [1;31mspeed[mup- parallel LGMAN applying
    
    Code refactoring for better readability.

[33mcommit a97493014c98627ef0d0971e81e582377fae9294[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Thu Nov 2 15:54:14 2017 +0530

    WL #8478: UNDO log [1;31mspeed[mup- parallel LGMAN applying
    
    Add disk tables to autotest test cases related to undo logs.

[33mcommit ec22907d9b429d866379e26ff8765f737e2f1c77[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Thu Nov 2 15:44:39 2017 +0530

    WL #8478: UNDO log [1;31mspeed[mup- parallel LGMAN applying
    
    MTR Test case
    -------------
    
    Steps followed:
    
    1) Create disk tables and do some basic operations on them.
    2) Start LCP so that disk table pages flushed to disk.
    3) Restart one data node in "no-start" mode.
    4) Insert error 7248 to that node for the latest LCP to be
       invalidated, so that the undo log records till the previous LCP
       are applied.
    5) Start node and wait for it to start.
    6) Make sure tables are intact.

[33mcommit 200bf464776319dd2619cd7dc398d53c5e2e958b[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Thu Nov 2 14:46:26 2017 +0530

    WL #8478: UNDO log [1;31mspeed[mup- parallel LGMAN applying
    
    Enforce ordering of application of undo records for a given page
    in the LDM threads.
    
    With parallel undo log application, many undo records can be sent to the
    LDM threads without waiting for the LDM threads to finish applying them.
    Before applying a log record, we must fetch the page (get_page) and
    sometimes, if the page is not available immediately, we have to wait for it
    before the log record can be applied. Waiting is done by periodically
    checking if the page is available (do_busy_loop()).
    However, between the checks, a subsequent log record belonging to the same
    page might get processed. This is because multiple log records are sent from
    LGMAN to the LDM threads continuously without waiting for the LDM threads to
    finish applying them. (WL8478)
    This subsequent log record will try to get the page as well and might succeed.
    This will result in unordered application of the undo records.
    The solution for this is to order the undo records belonging to a page.
    This is done by maintaining a queue of undo records received in LDM per
    page and applying them in order when the page becomes available in the
    page cache

[33mcommit 68aff6a71347cbe18985f119aaec8d09dd7fd4bb[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Mon Jul 10 17:05:19 2017 +0530

    WL #8478: UNDO log [1;31mspeed[mup- parallel LGMAN applying
    
    For record types that require serialization, do not continue fetching
    log records in LGMAN until all the pending records have been applied.
    
    Record types that require serialization are UNDO_LCP, UNDO_LCP_FIRST,
    UNDO_END, UNDO_TUP_CREATE, UNDO_TUP_DROP.

[33mcommit cb9f7758e7ea10681e8c469306827009690cfd53[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Mon Nov 13 16:47:16 2017 +0530

    WL #8478: UNDO log [1;31mspeed[mup- parallel LGMAN applying
    
    Allow negative counts for pending records since it is not guaranteed
    that the CONTINUEB from DBTUP(0) will be processed before the CONTINUEB
    from LDM threads.

[33mcommit 3b2cf5e0321b08722b29991035801487ce7f46d5[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Mon Jul 10 17:05:18 2017 +0530

    WL #8478: UNDO log [1;31mspeed[mup- parallel LGMAN applying
    
    Keep track of the total number of pending records and the number
    of pending records for each LDM thread.
    Enforce limit on the number of pending records per LDM thread.
    When this limit is reached for any LDM thread, LGMAN doesn't fetch
    the next undo record until that LDM thread has completed applying
    at least one undo log record.
    
    This does not include the pending records for records that require
    serialization.
    The numbers are applicable only to records of type UNDO_TUP_ALLOC,
    UNDO_TUP_UPDATE, UNDO_TUP_UPDATE_PART, UNDO_TUP_UPDATE_PART,
    UNDO_TUP_FREE and UNDO_TUP_FREE_PART.

[33mcommit e10c9e90afbc334faafb0d353883da58796e57a9[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Mon Jul 10 17:05:17 2017 +0530

    WL #8478: UNDO log [1;31mspeed[mup- parallel LGMAN applying
    
    Eliminate the wait in LGMAN for LDM to complete the record execution,
    proceed to process the next record after a record has been sent to
    LDM thread for applying.

[33mcommit ef2b59418fe5f7aa7a2044b379991edaf8a8fac3[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Wed Oct 25 19:00:24 2017 +0200

    WL#8069
    1) Ensured that ndb_print_backup_file checks for entries already existing
       and prints a bit more in verbose level
    2) Ensure that LQHKEYCONF and LQHKEYREF to RESTORE block executes as
       EXECUTE_DIRECT to ensure that we can check error codes immediately
       and to [1;31mspeed[m up restore process.
    3) Fix a few spelling errors
    4) Fixed a bug in handle_lcp_drop_change_page where I had an ndbrequire
       on header size that compared with 20, this was thought to be in bytes,
       but in reality header size is in words, so changed to 5, also added
       room for not using a checksum word, so changed to 4.
    5) Added a bit more debug statements in RESTORE block
    6) Introduced a new method in restore execution called
       handle_return_execute_operation
       This method checks if INSERT or WRITE hit error code 630.
       This could happen due to that restore not only insert rows, it
       also insert keys in hash index. So when inserting a row one could
       have the key already inserted. This key is going to be removed
       later, but since we are executing in rowid order we can hit a
       temporary state where we have a key defined that is to be deleted
       later. The same happens in node recovery and is handled by
       nr_copy_delete_row.

[33mcommit f1e4a00eb2edc5c411588a1699c0fe8bc1181d28[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Sun Oct 22 07:10:14 2017 +0200

    Bug#26199233 create like ignores innodb_file_per_table
    
    This patch fixes following three issues,
    
    Consider following table,
      SET @@global.innodb_file_per_table=OFF;
      CREATE TABLE t1 (c1 INT) ENGINE=InnoDB;
    
    Problem 1)
      The statements
      SET @@global.innodb_file_per_table=ON;
      CREATE TABLE t2 LIKE t1;
    
      Ignores innodb_file_per_table setting and picks the
      tablespace name used by table t1, even if user did not
      explicitly specify the tablespace name for t1. MySQL 5.7
      assigns tablespace name based on innodb_file_per_table
      setting.
    
    Problem 2)
      SHOW CREATE on table t1, shows TABLESPACE `innodb_system`
      clause, even when user did not explicitly specify
      tablespace.  MySQL 5.7 do not show TABLESPACE clause.
    
    Problem 3)
      SHOW CREATE on table names that match DD table names
      created in any database, endup showing tablespace name as
      'mysql'.
      E.g.,
        ...
        CREATE DATABASE db1;
        CREATE TABLESPACE ts0 ADD DATAFILE 'df0.ibd';
        CREATE TABLE db1.tables (c1 INT)
          ENGINE=InnoDB tablespace=ts0;
        SHOW CREATE TABLE db1.tables;
        Table Create Table
        tables  CREATE TABLE `tables` (
           `c1` int(11) DEFAULT NULL
        ) /*!50100 TABLESPACE `mysql` */
        ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        ...
    
    The patch fixes above issues by,
    
    - Maintain a boolean property 'explicit_tablespace=true' in
      mysql.tables.options, if user provides TABLESPACE clause
      when creating tables.
    
    - Make CREATE LIKE copy tablespace name, only
      if 'explicit_tablespace' property is true for the source
      table.  Otherwise InnoDB would decide the tablespace name
      based on 'innodb_file_per_table', this fixes 1)
    
    - SHOW CREATE implementation now reads the table property
      'explicit_tablespace' to decide if we need to print the
      TABLESPACE clause in the output. This fixes 2)
    
    - Use 'mysql' tablespace id to [1;31mspeed[m-up
      get_tablespace_name() on DD tables. This fixes 3).
    
    - The recorded result files now match 5.7 results.
    
    - Added new test case in innodb.create_tablespace.
    
    Change-Id: I7f890569f41a048e5e264d50434c30b8d4773311

[33mcommit 18dc75bdecb1b0598d8dbc8ba9bfd4b418032209[m
Author: Gopal Shankar <gopal.shankar@oracle.com>
Date:   Sun Oct 22 07:10:14 2017 +0200

    Bug#26199233 create like ignores innodb_file_per_table
    
    This patch fixes following three issues,
    
    Consider following table,
      SET @@global.innodb_file_per_table=OFF;
      CREATE TABLE t1 (c1 INT) ENGINE=InnoDB;
    
    Problem 1)
      The statements
      SET @@global.innodb_file_per_table=ON;
      CREATE TABLE t2 LIKE t1;
    
      Ignores innodb_file_per_table setting and picks the
      tablespace name used by table t1, even if user did not
      explicitly specify the tablespace name for t1. MySQL 5.7
      assigns tablespace name based on innodb_file_per_table
      setting.
    
    Problem 2)
      SHOW CREATE on table t1, shows TABLESPACE `innodb_system`
      clause, even when user did not explicitly specify
      tablespace.  MySQL 5.7 do not show TABLESPACE clause.
    
    Problem 3)
      SHOW CREATE on table names that match DD table names
      created in any database, endup showing tablespace name as
      'mysql'.
      E.g.,
        ...
        CREATE DATABASE db1;
        CREATE TABLESPACE ts0 ADD DATAFILE 'df0.ibd';
        CREATE TABLE db1.tables (c1 INT)
          ENGINE=InnoDB tablespace=ts0;
        SHOW CREATE TABLE db1.tables;
        Table Create Table
        tables  CREATE TABLE `tables` (
           `c1` int(11) DEFAULT NULL
        ) /*!50100 TABLESPACE `mysql` */
        ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        ...
    
    The patch fixes above issues by,
    
    - Maintain a boolean property 'explicit_tablespace=true' in
      mysql.tables.options, if user provides TABLESPACE clause
      when creating tables.
    
    - Make CREATE LIKE copy tablespace name, only
      if 'explicit_tablespace' property is true for the source
      table.  Otherwise InnoDB would decide the tablespace name
      based on 'innodb_file_per_table', this fixes 1)
    
    - SHOW CREATE implementation now reads the table property
      'explicit_tablespace' to decide if we need to print the
      TABLESPACE clause in the output. This fixes 2)
    
    - Use 'mysql' tablespace id to [1;31mspeed[m-up
      get_tablespace_name() on DD tables. This fixes 3).
    
    - The recorded result files now match 5.7 results.
    
    - Added new test case in innodb.create_tablespace.
    
    Change-Id: I7f890569f41a048e5e264d50434c30b8d4773311

[33mcommit 79f49360dca75e6495cd104fc651a7db4212e6be[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Thu Aug 10 18:55:39 2017 +0200

    Bug#26614455: MAKE CACHED JSON_PATH OBJECTS IMMUTABLE
    
    The cached Json_path object returned by Json_path_cache::get_path() is
    mutable. If a caller modifies the returned object and doesn't restore
    the original state of the object when it is done, the cache is
    corrupted and could cause wrong results the next time it is used.
    
    JSON_SEARCH is the only caller that does any modification on the
    cached Json_path object. This patch changes it so that it doesn't
    modify the Json_path object. Instead it makes the modifications on a
    String object that represents the path. Since the path needs to be
    converted to a string in the end anyway, this saves some round-trips
    between Json_path representation and String, and gives a small [1;31mspeed[mup
    as an extra bonus.
    
    Json_path_cache::get_path() is changed to return a pointer to a const
    Json_path object.
    
    Additional changes in the JSON_SEARCH function, while at it:
    
    Remove the String members m_one_or_all_value and m_escape. Since the
    valid values of the one-or-all argument and escape character argument
    of JSON_SEARCH are quite small (3 characters and 1 character), there
    isn't any point in caching these strings in the Item object. Creating
    a small buffer on the stack would be enough to avoid heap allocation
    in all the common cases.
    
    Microbenchmarks (64-bit, Intel Core i7-4770 3.4 GHz, GCC 6.3):
    
    BM_JsonSearch              1389 -> 1163 ns/iter [+19.4%]
    BM_JsonSearch_Wildcard     3203 -> 3216 ns/iter [ -0.4%]
    
    Change-Id: I31c5adaafc41403efcbc1edb84ec76b2b7949b57

[33mcommit 6aee469375a4eafb39d6bfe55027d0721f4c7c2c[m
Author: Sven Sandberg <sven.sandberg@oracle.com>
Date:   Sat May 6 14:33:42 2017 +0200

    WL#2955: RBR replication of partial JSON updates
    
    This worklog enables the replication of small updates of big JSON
    documents more space-efficiently.  More precisely, when using RBR, we
    will write only the modified parts of JSON documents, instead of the
    whole JSON document.
    
    The patch includes the following major components:
    
    - Implement the new option binlog_row_value_options
    
    - Implement logic to generate JSON diffs only when needed
    
      Before, JSON diffs were generated unconditionally by the optimizer.
      We changed so that JSON diffs are only generated when the option is
      enabled (unless inhibited by other options).
    
    - Implement new event type and use it when the option is enabled
    
    - Refactor: make max_row_length a private member of Row_data_memory
    
      This function was only used internally in class Row_data_memory, but
      was defined as a global function in table.cc.  Moved it to a private
      member of Row_data_memory.
    
    - Refactor: simplify pack_row and unpack_row
    
      Made several refactorings in these functions, including:
    
      New utility classes for handling null bits: When reading and writing
      a row in a row event, the logic for iterating over fields was
      interleaved with low-level bit operations to maintain a bitmap of
      null fields.  This made the code error-prone and hard to understand
      and edit.  This refactoring encapsulates the bitmap handling in
      utility classes, and simplifies pack_row / unpack_row accordingly.
    
    - Refactor: add const to integer decoder functions in pack.cc
    
      Functions in mysys/pack.cc that read from a buffer did not declare
      the buffer as const.  This patch makes net_field_length_size use a
      const parameter and makes other functions use const internally.
      Since these functions are part of the ABI, we also have to update
      include/mysql.h.pp.  (We do not const-ify pointers-to-pointers in
      function declarations, since that breaks compilation on other places
      that call the functions using non-const arguments.)
    
    - Refactor: change Json_diff_vector from a type alias to a class
    
      This was needed because extend Json_diff_vector with more member
      functions.  It also simplifies some forward declarations.
    
    - Refactor: do not overload global identifier TABLE in rpl_tblmap.h
    
      Class table_mapping in rpl_tblmap.h is used both in mysqlbinlog and
      in the server.  In the server, it maps numbers to TABLE objects.  In
      mysqlbinlog, it maps numbers to Table_map_log_event objects.  This
      was implemented by using the type name TABLE, and in mysqlbinlog use
      a typedef that makes TABLE an alias for Table_map_log_event.
    
      This patch changed rpl_tblmap.h so that it does not use the
      identifier TABLE.  Instead, it uses the new typedef Mapped_table
      that maps to TABLE in the server and to Table_map_log_event in
      mysqlbinlog.
    
    - Refactor: remove unused variable Rows_log_event::m_master_reclength
    
      There was a member variable Rows_log_event::m_master_reclength that
      was set to a (strange) value which was never read.  Removed this.
    
    - Refactor: simplify Rows_log_event::read_write_bitmaps_cmp
    
      This member function was implemented only in the base class, but had
      a switch that made it execute differently depending on the
      instance's subclass.  Changed to use a pure virtual function in the
      base class and implement the different logic in each subclass.
    
    - Implement encoder of new event format
    
      Outline of the pipeline:
    
       1. In binlog.cc:Row_data_memory, take a new argument in the
          constructor having two 'data' pointers (this constructor is used
          for Update_rows_log_event and is invoked in
          binlog.cc:THD::binlog_update_row).  This the value of the new
          server option binlog_row_value_options.  Based on this variable,
          determine if Json diffs may be used, estimate how much memory
          will be used (using the new function
          json_diff.cc:Json_diff_vector::binary_length), decide if full
          format or partial format will be used, and adjust the allocated
          memory accordingly.
    
       2. In binlog.cc:THD::binlog_update_row, pass two new arguments to
          pack_row:
    
          - row_image_type, which specifies if this is a
            Write/Update/Delete, and if it is a before-image or
            after-image.
    
          - value_options, which contains the value of
            binlog_row_value_options for update after-images.
    
       3. In rpl_record.cc:pack_row, accept the two new arguments.  If
          this is an update after-image and the bit in value_options is
          set, then determine if any column will use partial format.  If
          any column will use partial format, write the value_options
          field, followed by the partial_bits, to the output.  Otherwise,
          just write value_options=0 to the output and skip the
          value_options.
    
       4. From rpl_record.cc:pack_row, invoke the new function
          rpl_record.cc:pack_field to write a single field.  If the column
          is JSON and this is the after-image of an Update and the bit in
          value_options is set, invoke the new function
          field.cc:Field_json::pack_diff.  Otherwise, or if
          field.cc:Field_json::pack_diff returned NULL, fall back to the
          usual non-diff writer.
    
       5. In Field_json::pack_diff, determine again if this field will be
          smaller in full format or in partial format.  If full format is
          smaller, just return NULL so that rpl_record.cc:pack_field will
          write the full format.  Otherwise, invoke the new function
          json_diff.cc:Json_diff_vector::write_binary.
    
       6. In json_diff.cc:Json_diff_vector::write_binary, write the length
          using 4 bytes, followed by all the diffs.  Write each diff using
          the new function json_diff.c:Json_diff::write_binary.
    
       7. In json_diff.c:Json_diff::write_binary, write a single diff to
          the output.
    
    - Implement decoder of the new format
    
      The pipeline is now:
    
       1. Add a parameter to
          log_event.cc:Rows_log_event::unpack_current_row, which says if
          this is an after-image or not.  Set the parameter from all the
          callers in log_event.cc.
    
       2. Move Rows_log_event::unpack_current_row from log_event.h to
          log_event.cc and make it pass two new arguments to
          rpl_record.cc:unpack_row: row_image_type, which indicates if
          this is Write/Update/Delete and before-image or after-image, and
          has_value_options, which is true for Update events when
          binlog_row_value_options=PARTIAL_JSON.
    
       3. Make rpl_record.cc:unpack_row accept the two new parameters.
    
          First make a few small refactorings in rpl_record.cc:unpack_row:
    
          - Clarify some variable names and improve the comment for the
            function.
    
          - Remove comments about unpack_row being used by backup, having
            rli==NULL.  This may have been an intention at some point in
            time, perhaps in 5.1, but probably never was true.  And rli is
            unconditionally dereferenced in the main loop, so it cannot be
            NULL.  Instead assert that it is not NULL.  Also assert that
            other parameters are not NULL, as well as other preconditions.
    
          - Improve some debug trace printouts.
    
          - Return bool instead of int since the caller does not need to
            distinguish more than two different return statuses.
    
          Then implement the new logic:
    
          - When partial format is enabled, read partial_bits before the
            after-image (from within the main loop, as well as from the
            loop that consumes unused fields), and also read partial_bits
            after the before-image (after the main loop).  For the
            before-image, leave the read-position before the partial_bits.
            Use the new auxiliary function start_partial_bits_reader to
            read the value_options and initialize the Bit_reader
            accordingly, in the two places (after before-image and before
            after-image).
    
          - In order to read the correct number of bits before the
            after-image, start_partial_bits_reader needs to know the
            number of JSON columns on the master.  This is known from the
            table_map_log_event via the table_def class.  For convenience
            (and reuse in the mysqlbinlog patch), we add a member function
            rpl_utility.cc:table_def::json_column_count.  This function
            also caches the computed column count, to [1;31mspeed[m up successive
            calls (e.g. for many-row updates).
    
          - For the before-image, set the corresponding bit in the table's
            read_set, for any column having a 1 in the partial_bits.  This
            tells the engine to fetch the blob from storage (later, when
            the engine is invoked).  The blob will be needed since we have
            to apply the diff on it.
    
          - Call an auxiliary function rpl_record.cc:unpack_field to read
            each field move some special case handling for blobs into this
            function too.
    
       4. In rpl_record.cc:unpack_field, call
          field.cc:Field_json::unpack_field for partial Json fields.
    
       5. Add new function field.cc:Field_json::unpack_field, which
          invokes the new function
          json_diff.cc:Json_diff_vector::read_binary to read the
          Json_diff_vector, and the pre-existing (since WL#10570) function
          apply_json_diffs to apply the diff.
    
          The Json_diff_vector uses a new MEM_ROOT rather than the one of
          the current_thd, because that allows memory to be freed for each
          value, which saves resources e.g. in case of many-row updates.
    
          Before apply_json_diff can be invoked, we need to call
          table->mark_column_for_partial_update and
          table->setup_partial_update, in order to enable the *slave*
          server to generate JSON diffs in the *slave's* binary log.
    
       6. Add the new function json_diff.cc:Json_diff_vector:read_binary.
          This function reads the length of the field, then iterates over
          the diffs, reads each diff in turn, constructs Json_path and
          Json_wrapper/Json_dom objects, and appends them to the
          Json_diff_vector.
    
          We implement the auxiliary function net_field_length_checked,
          which reads an integer in packed format (see mysys/pack.cc),
          checking for out-of-bounds conditions.
    
    - Implement decoding and pretty-formatting of JSON diffs in mysqlbinlog
    
      mysqlbinlog outputs row events in two forms:
    
      - BINLOG statements that a server can apply.  There is nothing to
        change to make this work for the new event type.
      - "Pseudo-SQL" that humans can read, in case mysqlbinlog is invoked
        with the -v flag.  This is what the present patch implements.
    
      The pipeline in mysqlbinlog is:
    
       1. log_event.cc:Rows_log_event::print_verbose invokes
          log_event.cc:Rows_log_event::print_verbose_one_row with the new
          argument row_image_type, which indicates if this is a
          Write/Update/Delete and whether it is a before-image or
          after-image.
    
       2. In log_event.cc:log_event.cc:Rows_log_event::print_verbose_one_row
          we do two things:
    
          - Refactorings:
    
            - Use a Bit_reader to read the null bits, instead of using bit
              arithmetic.
    
            - Use safer boundary checks.  The code has a pointer to row
              data and a pointer to the end of the row data.  In C/C++, a
              pointer may point to the next byte after an allocated block
              of memory, but incrementing it further has an undefined
              result.  After reading the length of a field, the correct
              way to check that this length is not corrupt is to compare
              it with the end pointer minus the pointer to the read
              position.  (Before, it added the length to the read position
              and compared with the end pointer, but the read position
              plus the length is undefined.)
    
          - Implement the feature:
    
            - Read the value_options, if this is the after-image of a
              PARTIAL_UPDATE_ROWS_EVENT.
    
            - If value_options has the PARTIAL_JSON bit set, read the
              partial_bits.
    
            - Pass the partialness of the column as a parameter to
              log_event.cc:log_event_print_value.
    
       3. In the new function log_event_print_value, accept the new
          parameter, and in case the value is partial, call the new
          function log_event.cc:print_json_diff to parse and print the
          Json diffs.
    
       4. In the new function log_event.cc:print_json_diff, read, parse,
          and print all the diffs.
    
          The output has the form:
            JSON_<func>(
            JSON_<func>(
            ...
            JSON_<func>(@column, path[, value][,
                        path [,value][,
                        ...]]),
            ...
                        path[, value][,
                        path [,value][,
                        ...]]),
                        path[, value][,
                        path [,value][,
                        ...]])
    
          In this output format, the JSON_<func> functions appear in
          *reversed* order, whereas all the (path, value) pairs appear in
          order of appearance.  Therefore, we make two passes over the
          sequence of diffs:
    
           1. Read just the operations and store them in a vector.  Then
              print the operations in reverse order. Operations are
              printed using the new function
              log_event.cc:json_wrapper_to_string.
    
           2. Read the full diffs and output in the order of appearance.
    
       5. Add a new function log_event.cc:json_wrapper_to_string to print
          a Json_wrapper.  This ensures that the Json values are printed
          in the correct type.  JSON_<func> functions will convert SQL
          types to their JSON equivalents: for instance, the JSON function
          JSON_SET('[1, 2]', '$[0]', '[]') will set the 0th element of the
          JSON array to a string containing an open and closing square
          bracket, and not to an empty JSON array.  To account for this,
          different data types need different quoting, and to insert a
          JSON object or JSON array we need to cast the string to JSON
          first.
    
       6. To output JSON values with correct quoting for SQL strings, we use
          the existing my_b_write_quoted, but change it so that:
    
          - it uses a lookup table (computed only once) for simplicity and
            performance;
    
          - it prints common escapes such as \n, \\ in a more
            human-readable way.
    
    - BUG#26018522: MYSQLBINLOG -V PRINTS JSON IN ROW EVENTS WRONG
      mysqlbinlog -v had two problems:
    
      P1. It only read the length of JSON objects from two bytes. But the
          length of JSON data in row events is encoded (in little endian)
          using four bytes.  Therefore, it printed the wrong data for JSON
          objects bigger than 64K.  This also caused subsequent errors.
    
      P2. It only dumped the raw bytes of the buffer (quoted).  But row
          events contain a binary format for JSON, so the output was not
          useful.
    
      We fix these two problems as follows:
    
      F1. Read the length from four bytes.
    
      F2. Link mysqlbinlog with the parts of the server that can parse
          binary JSON and format it in human-readable form.  This includes
          three files:
          - json_binary.cc can parse the binary JSON format.
          - json_dom.cc can format human-readable JSON.
          - sql_time.cc is used by json_dom.cc to format time and date.
          All these files contain code that mysqlbinlog does not need and
          which needs to link with more parts of the server (e.g. THD).  To
          avoid link problems we put such code inside #ifdef MYSQL_SERVER.
    
    - Created a new test suite for tests that should not be
      parallelized by MTR because they require many mysqlds.
    
      The new suite contains test cases requiring many (6 or more) mysqlds
      in a replication topology. Running those test cases with
      "--parallel" > 1 may exhaust the test host I/O resources. So, this
      new suite should run only with "--parallel=1".

[33mcommit 60f3f81238a8a4fb230dbde87c708b10a2cf8122[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Wed May 10 23:16:52 2017 +0200

    WL#8069: Some adaptions of reporting restorable GCIs to [1;31mspeed[m it up, ensured that we don't report LCP watchdog issues when the real issue is a GCP stop issue

[33mcommit 517efb8ae2d276b94c618bae2837fe9e5fe61802[m
Author: Dhruthi K V <dhruthi.k.v@oracle.com>
Date:   Thu May 18 17:50:07 2017 +0530

    WL#10477 Defaults: Enable Transaction Write Sets - Code Review
    
    Rationale
    
    By using Transaction Write Sets, the master has to do slightly more work to
    generate the write sets which is helpfull in conflict detection. This allows
    users to easily move into GR since transaction-write-set is a requirement for GR.
    Also, the new default will make users to easily enable binary log writeset
    parallelization on master to [1;31mspeed[m up replication.
    https://dev.mysql.com/doc/refman/8.0/en/replication-options-binary-
    log.html#sysvar_binlog_transaction_dependency_tracking
    
    Server Changes
    
    transaction-write-set-extraction = XXHASH64 : Enables the optimal method for
    generating the write set hashes.

[33mcommit 4880f977236b5a33acc531bf420d503f9832781b[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Tue Nov 29 15:46:27 2016 +0100

    WL#883 non-recursive CTE
    WL#3634 recursive CTE
    
    As single patch. Adds support for:
    
     WITH query_name AS (subquery)
     SELECT * FROM query_name;
    and
     WITH RECURSIVE query_name AS (recursive subquery)
     SELECT * FROM query_name;
    
    The objects introduced after WITH are called "common table
    expressions" (CTEs). There can be several, separated with ','.
    A CTE can reference CTEs defined before it in the WITH list.
    A CTE is materialized or merged, which can be influenced with the
    Merge/No_merge hint.
    A CTE can be referenced multiple times in the query; if it's
    materialized it's materialized only once in the query.
    
    Specific of WITH RECURSIVE:
    'recursive subquery' must be
    of the form
    SELECT ... UNION [ALL] ... SELECT ... etc
    where the union is formed of a head of SELECTs which don't reference
    query_name (are non-recursive) followed by a tail of SELECTs which
    reference it. UNION DISTINCT and UNION ALL can be used. This allows
    traversing trees, hierarchies, finding transitive closures, computing
    numbers recursively, applying algorithms...
    
    CTEs can be defined in SELECT, UPDATE, DELETE, INSERT SELECT, REPLACE
    SELECT, CREATE SELECT, CREATE VIEW.
    
    After 'query_name' one can specify column names in parentheses:
    WITH query_name(a,b) AS...
    Such feature is also added to derived tables i.e.
    FROM (SELECT ...) AS dt(a,b)
    Such feature already existed for views but is rewritten (it had a bug,
    see at the end); to support this rewrite, a column VIEW_COLUMN_NAMES
    is added to the TABLES table of the Data Dictionary; this will prevent
    on-the-fly upgrades from 8.0.0 to 8.0.1, which mgmt has approved.
    
    Like derived tables:
    - a CTE may not reference an outer table
    - functional dependencies in (non-recursive) CTEs are recognized.
    - relevant indexes are automatically added to the materialized CTE if the
    Optimizer thinks that they will [1;31mspeed[m up the top query's access to the CTE.
    
    Also fixes:
    Bug#23265335 SPECIFYING A NAME FOR VIEW'S COLUMN IN CREATE VIEW MAKES SELECT
    FAIL
    Bug#23024178 WRITES TO INNODB INTERNAL TEMPORARY TABLE DOESN'T INCREASE
    "HANDLER_WRITE"
    
    Partially fixes:
    BUG#23022426 UNION ALL STILL USES TEMPORARY TABLE WITH INSERT SELECT
    i.e. with this WL, UNION ALL doesn't create a temporary table with
    INSERT SELECT iff the UNION ALL is not the top query expression after
    INSERT (i.e. is a subquery).

[33mcommit 616f1be47b5b43877079d80449f8f658e1643e21[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Nov 17 13:48:33 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Optimize the hash function; the old one was horrible both in [1;31mspeed[m and quality.
    The new one is significantly faster and slightly less horrible (verified with
    SMHasher). Note that we can do this only because the UCA 9.0.0 collations are
    not part of a GA release; we cannot go back and do this to other collations
    without breaking partitioning.
    
    Microbenchmarks (Skylake 3.4 GHz, optimized, GCC 6.2):
    
      BM_HashSimpleUTF8MB4   1140 -> 289 ns/iter  [+294.5%]
    
    sysbench goes from 11519 -> 12022 tps (+3.2%).
    
    Change-Id: I6c554110387d927ad1d139c19627c6c51a6aa10c

[33mcommit 2bd59f6e54cb152d539c46aa52a3b6507fb10bca[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Nov 17 13:48:33 2016 +0100

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Optimize the hash function; the old one was horrible both in [1;31mspeed[m and quality.
    The new one is significantly faster and slightly less horrible (verified with
    SMHasher). Note that we can do this only because the UCA 9.0.0 collations are
    not part of a GA release; we cannot go back and do this to other collations
    without breaking partitioning.
    
    Microbenchmarks (Skylake 3.4 GHz, optimized, GCC 6.2):
    
      BM_HashSimpleUTF8MB4   1140 -> 289 ns/iter  [+294.5%]
    
    sysbench goes from 11519 -> 12022 tps (+3.2%).
    
    Change-Id: I6c554110387d927ad1d139c19627c6c51a6aa10c

[33mcommit 0bf59db1c7230f2f62047cf1fbae32c3bd603ddc[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Thu Nov 3 17:44:01 2016 +0100

    Add missing view ndbinfo.disk_write_[1;31mspeed[m_aggregate_node in ndbinfo_sql.
    
    View was added to mysql_system_tables.sql with
    WL#7509: Introduced more configurability of disk write [1;31mspeed[ms and added a number of new ndbinfo tables to track this new more adaptive behaviour

[33mcommit f578cb7198c0b0739f2440f970d911f1ae8f985f[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Thu Nov 3 17:13:29 2016 +0100

    Add missing changes to ndbinfo.ndb$disk_write_[1;31mspeed[m_*.
    
    Changes were pushed to mysql_system_tables.sql with
    BUG#19795072: Fix problems related to ndbinfo tables for disk write [1;31mspeed[m

[33mcommit 5eacde0ff70999eed6762c166a464de9f1237dc3[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Oct 13 14:31:38 2016 +0200

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Specialize the UCA scanners on number of levels to compare.
    In particular, this allows us to make the scanner significantly
    simpler for the special case of only one level (ie., accent-
    and case-insensitive collations), making for a significant
    [1;31mspeed[m boost.
    
    Also add a new accent- and case-_sensitive_ benchmark, so that
    we can track the difference in [1;31mspeed[mup between the two.
    
    Microbenchmarks (Skylake, 3.4 GHz, 64-bit, GCC 6.1.1):
    
      BM_SimpleUTF8MB4       1374 -> 1138 ns/iter  (+20.7%)
      BM_MixedUTF8MB4         597 ->  527 ns/iter  (+13.3%)
      BM_MixedUTF8MB4_AS_CS  1839 -> 1760 ns/iter  ( +4.5%)
    
    sysbench results are pretty much in the noise (+3–4% for a
    single-threaded test).
    
    Change-Id: I942d178962b053e2f65dbb7de1f4ffc61a98ea81

[33mcommit c863738034e7bc7f539e48d0aa60711c9276ba60[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Oct 4 14:43:01 2016 +0200

    Bug #24788778: SEVERE REGRESSION IN MY_STRNXFRM() FROM MYSQL-5.5 -> 5.6
    
    MySQL 5.6 changed utf8 binary collation strxfrm() from just comparing the UTF-8
    string to converting it to UCS-2 (big-endian) and padding before compare.
    (Similarly for utf8mb4, just with UCS-3 instead, which isn't correct for
    all Unicode code points.)
    
    Both are correct (although changing it also changed the hash function, which
    might on-disk binary compatibility wrt. partitioning), but the latter makes for
    fixed-length keys, which was seemingly important for the (now discontinued)
    Falcon storage engine at the time. However, it also introduces a bottleneck
    when hashing. We add a very simple benchmark (based on the benchmark in the
    bug) and then optimize the string transformation:
    
     - Add an SSE2 version of the padding as long as we're sufficiently far away
       from the end of the string; this will be used automatically for all 64-bit
       Intel compiles (as well as 32-bit Intel compiles with -march=native or
       similar).
     - Inline the mbwc() function for the special case of my_utf8_uni.
     - Some general microoptimization.
    
    All in all, we're at about 7x the [1;31mspeed[m of before. Old version
    (trunk, 64-bit, optimized mode, GCC 6.1.1, Skylake 3.4 GHz):
    
      Done, used 1.696 seconds (1.696 us/iteration)
    
    This version:
    
      Done, used 0.242 seconds (0.242 us/iteration)
    
    The code is written to be C++98 compatible (even though a lambda would be
    much more elegant than a functor class), as it will probably want a 5.6 and 5.7
    backport. The benchmark isn't, though, as it uses std::chrono.
    
    Change-Id: I9da8c8af448bdacd6028a65c10ce232f841cdc94

[33mcommit 9c5412867c3bef6d78f55992eed26509081aed71[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Jun 14 16:54:13 2016 +0200

    Fix several failures in 'testSystemRestart -n SR_DD_n*' tests
    
    Tests where inserting into tables or updating rows at the
    max [1;31mspeed[m of the test client machines for the duration of
    each test loop.
    
    As the new vigdis servers are fastart than the machines they
    replaced, we are now able to fill the TableSpace and/or
    redo logs to their max sizes, and thus the test failes.
    
    This patch introduce a load limiting machanism which limit
    the client load to 10.000 insert/update/deletes pr sec.
    
    This should also avoid that these tests fails the next time
    the ATR test are moved to faster hardware.

[33mcommit 2b3e1dded4588054fe81cfcc0e20e866221f2099[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Thu Mar 10 10:52:20 2016 +0100

    Bug#22900585: Switch to 64 bit toolchain on 64 bit Windows
    
    Set PreferredToolArchitecture to x64 when building
    in Windows. This [1;31mspeed[ms up linking and avoids issues
    related to limited address space with the 32 bit linker.

[33mcommit fb01e5ee05861e9aea5a76c1a15a78a09362706c[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Mon Jan 25 12:16:59 2016 +0000

    Bug #22582233 NDB : MAXDISKWRITESPEEDOWNRESTART NOT USED
    
    The fix for
      Bug 20204854 BACKUP FAILING UNDER HEAVY LOAD EXCEPT WHEN
      SNAPSHOTSTART USED
    
    contained a bug which resulted in the wrong disk write
    [1;31mspeed[m configuration parameter being used during System
    and Node restarts.
    
    MaxDiskWriteSpeedOtherNodeRestart was used instead of
    MaxDiskWriteSpeedOwnRestart.
    
    MaxDiskWriteSpeedOwnRestart       (Min=Max,
                                       Default 200MB/s)
    MaxDiskWriteSpeedOtherNodeRestart (Default Min=10MB/s,
                                               Max=50MB/s)
    
    This generally results in local checkpoint (LCP) taking
    longer than designed during node and system restarts, which
    increased the duration of node and system restarts.
    
    This is fixed so that MaxDiskWriteSpeedOwnRestart is
    used while a node is restarting.

[33mcommit 1120d8b550da0e5e7f4e096caf3811aa3d02d1a8[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Mon Jan 25 11:38:40 2016 +0000

    Bug #22582233 NDB : MAXDISKWRITESPEEDOWNRESTART NOT USED
    
    The fix for
      Bug 20204854 BACKUP FAILING UNDER HEAVY LOAD EXCEPT WHEN
      SNAPSHOTSTART USED
    
    contained a bug which resulted in the wrong disk write
    [1;31mspeed[m configuration parameter being used during System
    and Node restarts.
    
    MaxDiskWriteSpeedOtherNodeRestart was used instead of
    MaxDiskWriteSpeedOwnRestart.
    
    MaxDiskWriteSpeedOwnRestart       (Min=Max,
                                       Default 200MB/s)
    MaxDiskWriteSpeedOtherNodeRestart (Default Min=10MB/s,
                                               Max=50MB/s)
    
    This generally results in local checkpoint (LCP) taking
    longer than designed during node and system restarts, which
    increased the duration of node and system restarts.
    
    This is fixed so that MaxDiskWriteSpeedOwnRestart is
    used while a node is restarting.

[33mcommit cbb3f6c0c28ac7716e9c3824ae654b9f97fa1884[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Tue Jul 28 12:19:58 2015 +0100

    Bug#20204854       BACKUP FAILING UNDER HEAVY LOAD EXCEPT WHEN SNAPSHOTSTAR
    Bug#21362380       NDB : LOG MAXDISKWRITESPEEDCHANGES FROM ONE LDM INSTANCE
    
    Background
    
    During normal operation, data nodes attempt to maximise
    the disk write [1;31mspeed[m used for LCP and Backup while remaining
    within the bounds of the configured MinDiskWriteSpeed and
    MaxDiskWriteSpeed.
    
    In 7.4, the implementation of disk write throttling was
    changed to give each LDM thread an equal share of the total
    budget.  This allows parallel LCP to occur without exceeding
    the configured disk IO budget.
    
    However, Backup is executed by only one LDM thread, and so
    it effectively suffered a budget cut.  This results in
    slower time to backup completion, and, if the change
    rate is high enough, can result in failure to backup
    as the Backup log buffer fill rate is higher than the
    achievable write rate.
    
    Solution
    
    This patch adds a new cluster configuration parameter :
    
    BackupDiskWriteSpeedPct
    
    This parameter defaults to 50(%) and can be set between
    0(%) and 90(%).
    
    When a Backup starts, the configured percentage of the
    node's maximum write rate budget will be reserved prior
    to sharing out the remainder of the budget amongst LDM
    threads for LCP.
    
    The LDM thread running the backup will receive the whole
    write rate budget for the Backup, plus its (reduced) share
    of the write rate budget for LCP.
    
    This increased budget makes the disk write rate budget
    behave in a similar way to releases < 7.4.
    
    Additionally, a new node log message has been added which
    appears at the end of a Backup and indicates the high-water-mark
    usage of the Backup log buffer.  This can be an aid to efficiently
    configuring this parameter.
    
    Notes :
    The LDM thread with increased 'budget' is still free to
    assign the budget to LCP/Backup scan/Backup log on a
    first-come-first-served (FCFS) basis, so the bandwidth
    is not guaranteed.
    
    Reducing the budget available to LCP on the other LDM
    threads will slow the LCP for the duration of the backup.
    This can affect the amount of Redo and Undo log space
    needed.
    
    A separate bug where each LDM thread reported max [1;31mspeed[m
    changes separately has also been fixed.
    
    Example :
    
    Max write rate = 20MB/s
    Num LDMs = 4
    
    Normal case (no backup):
    
    Each LDM has a Max write rate of 20/4 = 5MB/s
    
    Backup case
    
    Node backup budget = 50% of 20MB = 10MB/s
    Node LCP budget = 20 - 10 = 10MB/s
    Per-LDM LCP budget share = 10/4 = 2.5MB/s
    
    Backup LDM thread budget : 10 + 2.5 = 12.5MB/s
    Other LDM threads budget : 2.5MB/s
    
    Total budget = 12.5 + 2.5 + 2.5 + 2.5 = 20MB/s
    
    Notes :
    
    - 50% default gives similar behavior to previous releases
    - 0% gives current behaviour
    - Increased budget is not guaranteed for Backup log - similar
    to previous releases.

[33mcommit 206b7bdbc114e7505fb52d8349a4433be22caf48[m
Merge: 8358d59e0ed 7d8937daf6f
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Jul 13 19:17:19 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      BUG#21389101 ST_GEOMFROMGEOJSON: STACK OVERFLOW IN RAPIDJSON::GENERICREADER
      Bug#21383284: ASSERTION IN SELECT_LEX::SETUP_CONDS
      BUG#21303289  Removed sqlbench leftover in deb platform pkg src
      BUG#21434004   UBUNTU 15.04 REPO PACKAGES DO NOT CONTAIN ESSENTIAL SCRIPT LIKE MYSQLD_SAFE list of files being re-installed in server pkg: +usr/bin/mysqlbinlog +usr/bin/mysqld_multi +usr/bin/mysqld_safe
      Remove MCP_GLOBAL_SCHEMA_LOCK patch
      Fix syntax error in ndbinfo_sql.cpp
      Fixed mysql_ssl_rsa_setup test failing on Windows after pushing bug fix for bug#21025377
      BUG#21280816 CONNECTION PERFORMANCE REGRESSION TEST HANGS SYSBENCH
      Keep ndbinfo_sql.ccp in sync with mysql_system_tables.sql
      Remove unintentional change in variables-big.test
      Bug #20168526 YASSL: CORRUPT SSL-KEY CRASHES CLIENT
      Version change in d/changelog for DEB pkg src 5.7.9+ are non-rc releases
      - Bug#21407023: DISABLING AHI SHOULD AVOID TAKING AHI LATCH   Currently if AHI is disabled check for it was protected by AHI latch which   caused latch overhead even though the feature is not adding any value.
      Bug#21429471 - COMMUNITY/COMMERCIAL EL7 UPDATE FAILING WHEN MARIADB-BENCH.X86_64 INSTALLED
      Bug #20728894: MEMORY LEAK IN ADD_DERIVED_KEY()
      Bug #21056907: CONTENTS OF NOT REQUESTED CHAR/VARCHAR                COLUMN ARE REVEALED
      Bug #20777016: DELETE CHECKS PRIVILEGES ON THE WRONG                DATABASE WHEN USING TABLE ALIASES
      Bug #18636874 PASSWORD VALIDATE PLUGIN: DICTIONARY CHECK MISBEHAVES WITH GOOD HEX INPUT
      WL#7254 Audit API extensions
      Bug#21374104 SETUP_TIMERS INITIALIZATION ASSUMES CYCLE TIMER IS ALWAYS AVAILABLE
      Bug #20087571: 5.7 EASILY HITS ERROR 1436 (HY000): THREAD STACK OVERRUN ERRORS ON MANY EXPR'S
      Bug#21383896 DECIMAL FIELD TAKES IN VALUES FROM OTHER FIELDS
      Bug#21153489 VALGRIND ERRORS IN ITEM_BOOL_FUNC2::IS_NULL LEAD TO CRASH LATER
      Fix syntax errors in 16node-tests.txt and upgrade-tests.txt
      Bug#21337139 ATRT SILENTLY STOPS TESTING AT FIRST SYNTAX ERROR IN TEST CASE FILE
      Fix a compilation error after bc098885
      Bug#21338012 MTR MANUAL-GDB OPTION DOES NOT WORK
      Bug #21280801: VERSION TOKEN LOCKING DOES NOT WORK
      BUG#21421471 LICENSE HEADERS MISSING IN FILES
      Bug#21300774 ASSERT `!INIT_FTFUNCS(THD, SELECT_LEX)` IN JOIN::RESET AT SQL/SQL_SELECT.CC:874
      Bug#21300774 ASSERT `!INIT_FTFUNCS(THD, SELECT_LEX)` IN JOIN::RESET AT SQL/SQL_SELECT.CC:874
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      BUG#20074353 HANDLE_FATAL_SIGNAL (SIG=11) IN MY_B_WRITE | MYSYS/MF_IOCACHE.C:1597
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      Addendum 2 to bug #21034322: removed the max test due to it being different for different OSes
      Follow up fix for WL#8149 change, fix create_thd() issue and test mismatches
      Merge WL#8149 related worklogs to mysql-trunk
      Bug#21271736 UNITTEST UT0CRC32-T HANGS ON SOLARIS 10 SPARC
      Bug#21381060 A "CASE WHEN" EXPRESSION WITH NULL AND AN UNSIGNED TYPE GIVES A SIGNED RESULT
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Remove non experimental test.
      Bug#18949282 I_MAIN.MYSQL_CLIENT_TEST FAILED AT LINE 43, COMMAND $I_M_C_T
      Configure smaller redo log for test ndb.ndb_backup_rate.
      Updating the test case ndb_addnode_restart* :  The autotest testSystemRestart had an additional restart loop  in runAddNodesAndRestart function, which is not needed as there  is no change in the configuration of the cluster.  Removed that and updated the name of the funcction and added few  comments to explain the proper setup of the testcase
      Fix for WL#7763
      WL#7763, remove use of inet_ntoa from ndb parts
      Post-push test fix for Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      Bug#17493646 NDB: CALL TO MY_ERROR() LACKS ERROR CODE AND ERROR STRING ARGUMENTS
      Bug#21352763 FLEXASYNC SEGFAULTS IF FAILED TO CREATE TABLES
      BUG#21297407: Fix to ensure sending CONTINUEB with proper variables in dropTable_wait_usage
      Pushing BUG#21297407 revealed an uninited variable in Fragrecord in DBLQH (lcp_frag_ord_state, was set to LCP_QUEUED == 0 in most cases which led to crash if drop table happened before LCP had time to execute
      BUG#20981491: Fix resource issues for NR, LCP andb Backup with regard to scan numbers, BUG#21362758: Crash with holding LocalDLFifoList context over call EXECUTE_DIRECT(NEXT_SCANCONF), BUG#21370839: Ensure also ACC scans are queued in a proper manner, previous push only added test case to autotest
      BUG#20981491: Fix resource issues for NR, LCP andb Backup with regard to scan numbers, BUG#21362758: Crash with holding LocalDLFifoList context over call EXECUTE_DIRECT(NEXT_SCANCONF), BUG#21370839: Ensure also ACC scans are queued in a proper manner
      BUG#20993380: (Also BUG#69994 in community bugs), ensured that node recovery and LCP scans can continue even if user has used up all resources for user level transactions, reserved operation records and segments for necessary things during LCP and NR scans
      Fix test case testRedo -n RedoFull
      Fix testRedo -n RedoFull test case
      BUG#21297407: Speed up drop table
      Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Raise version number after cloning 7.1.36
      Raise version number after cloning 7.3.10
      Raise version number after cloning 7.4.7
      Raise version number after cloning 7.2.21
      Fixed syntax errors in daily-basic-tests.txt
      Implement required methods in clusterj-openjpa
      Bug#20504741 Improve clusterj release of byte buffers by adding a user method session.release
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7570 Remove ifdefs which are not necessary since trunk has it all
      Bug #20592110         CLUSTER CIRCULAR REPLICATION WITH IGNORE_SERVER_IDS() BROKEN BY ANONYMOUS_GTIDS
      revert change to mysql-test-run
      Bug #21326540         NDB_JOIN_PUSHDOWN TESTS UNSTABLE EXECUTE_COUNT
      Remove obsolete ifdef
      Add comment re. valgrind
      WL#6815 Adapt MySQL Cluster to 5.7
      Revert "WL#6815 Adapt MySQL Cluster to 5.7"
      Removed extra blank line in ATRT test scripts preventing tests to start (Due to ATRT bug)
      Bug #17878183       NDB CONTINUOUSLY REBOOTING DUE TO FILE NOT FOUND (DBLQH:
      Bug#17493646 NDB: CALL TO MY_ERROR() LACKS ERROR CODE AND ERROR STRING ARGUMENTS
      Increase timeout for ATRT test
      Increase timeout for ATRT test
      BUG#20904721, WL#8525: Fix of part9, used internal TUP pointer instead of LQH pointer when calling LQH function directly, leads to both wrong handling and sometimes even a crash when index is not a used scan pointer
      Apply pollEvent_v4.patch from Ole John
      restore new scheduler & multiwait fix to bug branch
      If memcached crashes, mysql-test-run should not restart it.
      On misc. errors, print workitem to debug log
      always compile ndb memcache with DEBUG_OUTPUT
      More unified error handling
      New record_ndb_error() function where error logger keeps statistics but caller is resposnsible for writing to log file. Direct error messages to the debug log if enabled.
      The table scan code where NDB Memcache reads it configuration tables was written poorly, and could cause memcached to crash during configuration.
      revise debug messages in new scheduler
      switch default scheduler to Trondheim
      always compile ndb memcache with DEBUG_OUTPUT
      More unified error handling
      New record_ndb_error() function where error logger keeps statistics but caller is resposnsible for writing to log file. Direct error messages to the debug log if enabled.
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#11759461 NDB_CONFIG --XML --CONFIGINFO: VARIOUS UPDATES TO PARAMETERS LISTED
      Bug#11760628 DEPRECATE EXECUTEONCOMPUTER
      Bug #21270509         FAULTY COMMENT DESCRIBING NDB_MGM_NODE_STATE.CONNECT_ADDRESS IN MGMAPI.H
      Bug #21270425         MGMAPI.H SPELLING ERROR
      Bug#20617891: NDB : SUSPICIOUS HANDLING OF SIGNAL-WAIT TIMEOUT IN NDBAPI
      read configuration in a single consistent transaction
      The table scan code where NDB Memcache reads it configuration tables was written poorly, and could cause memcached to crash during configuration.
      Revert "Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000"
      Revert "Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000"
      Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      BUG#20904721: Fix for a number of asserts that assumed interpreted mode for all scans
      BUG#20727343: Fix failing ndb_dd_initial_lg test case, minor initialisation issue
      reapply bugfix in this branch. do not push this change to 7.4
      move another message from debug to detail level
      move another message from debug to detail level
      WL#8525: Part 11, don't use interpreted execution for LCPs and Backups since it is a waste of CPU resources
      BUG#20904721: Part 9: Implementing the adaptive LCP [1;31mspeed[m using bounded delay concepts and A-level signals
      more safety when Ndb::startTransaction() fails
      more safety when Ndb::startTransaction() fails
      add a more detailed debug output level to ndb memcache
      Anticipate SERVER_ERROR responses in My::Memcache.pm
      Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      Test case for Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      induce memcached to flush its log file at end of mtr testing
      BUG#20727343: Fix problems in UNDO log applier when changing log files
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Revert of prev push for bug#20957068
      Fix for Bug#20957068:
      Post merge fixes (mysql-5.6.25 via mysql-5.6-cluster-7.3 into mysql-5.6-cluster-7.4)
      Port commit to MySQL Cluster 7.3
      Port of commit to MySQL Cluster 7.3
      Port of commit to MySQL Cluster 7.3
      Port commit to MySQL Cluster 7.3
      some additional debug output re. online reconfiguration
      Test: temporarily revert recent changes
      Bug#20730053: BACKPORT BUG#19770858 TO 5.1
      Test: temporarily revert recent changes
      Bug#20734434 - SPELLING ERROR \"EMDEDDED\" IN RPM SPEC FILES
      Bug#20788853 MUTEX ISSUE IN SQL/SQL_SHOW.CC RESULTING IN SIG6. SOURCE LIKELY
      Bug#18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Bug#21270190 REMOVE UNUSED AND DANGEROUS NDBHOST_GETHOSTNAME()
      Fix compiler warnings due to hidden inherited virtual and release-unused variables.
      Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Backport of Part 2 (of 2) of fix for Bug#18390321 to 7.2 & 7.3
      bug#17638548 Try to address test failures from previous push
      Reenable usage of send threads in MTR tests.
      Part2 (of 2) fix for Bug#18390321
      Temporarily change default MTR test config to use worker thread sending (No send threads) in order to get some regression test coverage of part1 patch for bug 18390321
      Bug #17878183         NDB CONTINUOUSLY REBOOTING DUE TO FILE NOT FOUND (DBLQH: CAUSED BY ERROR 2341)
      Part1 (of 2): Fix for Bug#18390321
      bug#17638548 In NDB Memcache 7.4 use 7.3 Scheduler by default
      bug#17638548 : reset "woken" state after wakeups
      Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Fix failing ATRT testcases:
      Increase timeout value for several failing 'testNodeRestart ... DD' tests.
      Fix failing testcase 'testNodeRestart -n GcpStop T1 --loops=1' :
      Added more printout to testcase 'testBasic -n Bug54986 D2' in order to aid in understanding why / where this test fails.
      Increase timeout for  'testNodeRestart -n Bug27003 T1' from 1800 -> 3600sec.
      Moved unstable 'basic' tests to 'devel'.
      Fix compiler warnings in patch for bug#21185585:
      fix bug in cmakelists from previous push
      Convert test_workqueue into a TAP test
      Fix for bug#21185585
      ndb memcache: recently in CLUB testing of ndb memcache suite, 7.4 consistently passes but 7.3 has many failures.  This commit swaps the default schedulers in 7.3 and 7.4 to see if that leads to any change in the pattern of test results.
      ndb memcache: change default scheduler in 7.3
      bug#21067283 Fix inconsistent space calculations in NdbRecord
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      BUG#18234170 Foreign Constraints are lost from NDB Tables during truncate
      Bug#21184102 PATCH FOR BUG#16890703 MYSQLD STUCK IN OPN TABLES ..., LOST IN 7.3 AND UPWARD Added error check for missing database directory, added testcase
      BUG#18234170 Foreign Constraints are lost from NDB Tables during truncate
      WL#8648 NDB_SHARE lifecycle improvements
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7578 Refactor schema distribution code
      WL#8648 NDB_SHARE lifecycle improvements
      Bug#21141495 NDB_MGMD USES 90% CPU
      Remove global forward declaration of Ndb_fk_data
      BUG#20095208: Fix to make portlib not dependent of ndbgeneral
      Removed compiler warning
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Only use C++ ABI functionality if libstdc++ is being linked. Otherwise resort to protect the allocation/deallocation of the static objects using the existing connection mutex.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      Patch for bug#21109605
      Removed compiler warning
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Only use C++ ABI functionality if libstdc++ is being linked. Otherwise resort to protect the allocation/deallocation of the static objects using the existing connection mutex.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      WL#8525: BUG#20904721: Part6: Improve performance of checksum calculations, remove unnecessary ones and simplify bit toggling ones. Also solves BUG#20980229 that ensures that also header bits are included in checksum calculation.
      BUG#20904721: Fix LCP processing with heavy insert activity, part 2
      Improve multi-thread use of charsetDecoder and charsetEncoder in clusterj Utility   charsetDecoder is used only in Decimal decoding   charsetEncoder is used only in Decimal encoding   charsetDecoder and charsetEncoder are not thread-safe   use charset.decode for decoding   use charset.newEncoder().encode for encoding   avoid synchronization
      bug#20095208 - UNABLE TO STORE FRAGMENT DURING LCP. NDBFS ERROR: 2812 - DBLQH (LINE: 14305)
      bug#20095208 - UNABLE TO STORE FRAGMENT DURING LCP. NDBFS ERROR: 2812 - DBLQH (LINE: 14305)
      Bug#18753887 MYSQLD STOPPED WRITING TO BINARY LOG Modifies pollEvents to return latest_GCI as NDB_FAILURE_GCI (~(Uint64)0) in case a cluster failure has been detected. An internal flag is set in NdbEventBuffer::report_node_failure_completed and the flag is reset when the next SUB_GCP_COMPLETE_REP signal is received. Test case StallingSubscriber is extended to verify that NDB_FAILURE_GCI is returned and that polling of events is resumed after the cluster is connected again and new epochs are received.
      Bug#18753887 MYSQLD STOPPED WRITING TO BINARY LOG     Modifies pollEvents to return latest_GCI as NDB_FAILURE_GCI (~(Uint64)0)     in case a cluster failure has been detected. An internal flag is set     in NdbEventBuffer::report_node_failure_completed and the flag is     reset when the next SUB_GCP_COMPLETE_REP signal is received.     Function Ndb::isExpectingHigherQueuedEpochs is added to be used together     with pollEvents2 that checks if cluster has disconnected due to failure     causing no more events to be received.     Test case StallingSubscriber is extended to verify that NDB_FAILURE_GCI     is returned and that polling of events is resumed after the cluster     is connected again and new epochs are received.
      BUG#20904721: Part 8: Fixing the NDB scheduler to work with Bounded delay signals
      Revert last merge
      Fix multi-thread use of charsetDecoder in clusterj Utility   charsetDecoder is used only in Decimal decoding   charsetDecoder is not thread-safe
      Follow up testcase fix for MCP_BUG20701918
      MCP_BUG20701918  create-old-temporals MySQLD option
      BUG#20904721: Fix of previous push
      Fix regression in debug build caused by fix for bug#20408733.
      WL#8525: BUG#20904721: Part 4, write up description of local LCP protocol and how to handle overload situations, increase to prio level A in some cases. Also standardise naming on END_LCPREQ and END_LCPCONF and remove all usages of END_LCP_REQ and END_LCP_CONF.
      BUG#20904721: WL#8525: Part 3, use prefetch to [1;31mspeed[m up scan processing for LCP scans and also other full table scans, such as node recovery scans and user level full table scans
      WL#8525: BUG#20904721: Part 7: Ensure it's not so easy to misconfigure LCPs and Backups
      BUG#21049554: Fix OM_SYNC flag to work on all platforms, not only those that support the O_SYNC flag
      WL#8525, BUG#20904721: Part1: Avoid LCP watchdog crash when scanning many pages with LCP_SKIP records
      Fix annoying compiler warnings on Mac OS X
      Fix white space warning in clusterj
      Bug #20504741 Bug #20695155 Improve Clusterj handling of ByteBuffers to reduce direct memory footprint Fix Clusterj incompatibility with Java 7
      Backport My::Memcache.pm improvements from 7.3 This will be null-merged up
      Eliminate some compiler warnings in 3rd party memcached code for NDB Memcache This fix includes both reducing the gcc warning config in CMakeLists.txt and changing two memcached source files. No Oracle copyright is added to the changed 3rd party files.
      Clusterj Trivial bug fix for error displays
      Bug#21055643 REDUCE DEBUG PRINTOUT DURING A GAP AND IMPROVE
      Properly include m_string.h when using my_stpcpy
      Improve comments
      Cache the key_length in NDB_SHARE_KEY
      Provide type safety by using the opaque NDB_SHARE_KEY* type
      Use NDB_SHARE::key_string() instead of direct access to key member
      Move NDB_SHARE::key_length into NDB_SHARE_KEY
      Rewrite the lgive share leak name  to also use NDB_SHARE::create_key
      Move all NDB_SHARE key initialization into NDB_SHARE::creat_key()
      Fix some compiler warnings from memcached sources
      My::Memcache.pm: handle case where the last read before a timeout completed the read buffer. Open a new memcache connection when trying to fetch server error stats.
      Save the prepared key in Ndb_schema_dist_data
      Rename ndbcluster_prepare_rename_share to NDB_SHARE::create_key
      Remove NDB_SHARE::mem_root and instead use my_malloc for dynamic strings
      Change ndcluster_prepare_rename_share to return newly allocated key
      Remove NDB_SHARE::old_names
      Pass the new_key as argument to ndbcluster_rename_share
      Skip ndb_ddl tests with embeddes server
      Change to allocate Ndb_CONFLICT_FN_SHARE bith my_malloc
      Make the NDB_CONFLICT_FN_SHARE an opaque type for users of ndb_share.h
      Remove useless typedefs
      Remove backwards jump into a hoop on fire
      bug#18411034: Remove an unnecessary if-statement
      Print stats for the MEM_ROOT in Ndb_event_data
      Increased the undolog file size from 256MB to 512MB and FragmentLogFileSize from 64MB to 128MB.
      bug#18411034: Assertion gci_ops && (gci == gci_ops->m_gci) failed
      bug#18411034: Assertion gci_ops && (gci == gci_ops->m_gci) failed
      bug#20553313, bug#20707694 - fix index stats query delays
      Bug#20479917 REMOVE MCP_BUG16021021
      Bug#21026199  RANDOM WARNING ORDER NDB_ONE_FRAGMENT
      Addendum to the fix for bug #20681412:
      post push minor test fix for bug:19887143
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug#20234681 HA_NDBCLUSTER USAGE OF FIND_FILES LEAK MEMORY INTO (UNRELEASED) MEM_ROOT
      Move new drop_table test to suite ndbcluster
      Bug#20728189 DROP TABLE SEGFAULTS IF FIRST STATEMENT ON A NEW CONNECTION
      Adding force_restart option to ndb_addnode_restart_setup.inc To force restart servers during retries.
      Bug#20782580: NDB REDO OVERLOAD: ABORT QUEUING REQUESTS IF OUT OF LOG SPACE
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      Added 5 autotest testcases to test node restart with following scenarios. 1. Restarting one node at a time. 2. killing two node of different groups and starting them with and without initial option. 3. Restarting a node which doesn't belongs to node group 0, and checking that it is not associated with node group 0 after restart. 4. killing four node of different groups and starting them with and without initial option. 5. Killing only the master nodes one by one and starting them without initial option.
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      Bug#11762750 TABLE NDBINFO.CONFIG_PARAMS SHOULD BE READ-ONLY (FOR NOW)
      Bug#16731538 MYSQLD CRITICAL FAILURE DURING ORDERED SELECT FROM NDBINFO.CLUSTER_OPERATIONS
      BUG#20075747 RND_INIT() ON AN OPEN SCAN IS USED TO REPOSITION THE CURSOR
      WL#7575 Remove ndbinfo's usage of other engine
      My::Memcache -- longer write timeot
      My::Memcache client, fix bug in read() where desired length is 0
      Remove include/ndb_default_cluster.inc
      WL#8165 Use new records per key interface in NDB
      Fix for Bug#20954804
      Fix for Bug#20954804
      Bug#20782580: NDB REDO OVERLOAD: ABORT QUEUING REQUESTS IF OUT OF LOG SPACE
      Fix a possible crash in AutoTest when an ordered scan encounter error 4008, scan timeout. One such testcase is 'testScan -n ScanRead4880'
      Bug#11760802 SEVERAL MGMAPI FUNCTIONS RETURN 0(SUCCESS) WHEN NO HANDLE OR NOT CONNECTED
      Refactoring of create partitioned table
      Revert unintentional change
      My::Memcache - do not close connection before attempting to fetch server error statistics
      MTR ndb_memcache more tweaks to timeout handling
      Bug#20814396 PB2 IS SECRET ABOUT WHAT UNIT TESTS IT RUN
      Revert "Remove MCP_GLOBAL_SCHEMA_LOCK patch"
      Revert "Remove MCP_GLOBAL_SCHEMA_LOCK patch"
      Fixing the following test failures by synch'ing the error injection and the test checking the error:
      increase timeouts
      Better failure handling in My::Memcache.pm
      Provide more information when an ndb_memcache test fails
      BUG#20887445: Fix so that cpuset is working in ThreadConfig, previously node log proclaimed it was working where it wasn't really working
      Fix ndbapi example programs to work on Mac OS X Yosemite
      BUG#20887445: Fix so that cpuset is working in ThreadConfig, previously node log proclaimed it was working where it wasn't really working
      Fix ndbapi example programs to work on Mac OS X Yosemite
      Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED
      Bug#20729091 - ASSERTION TYPE < NDBDICTIONARY::EVENT::TE_EMPTY FAILED
      Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS
      Bug#20762291 - POLLEVENTS2() WILL RETURN ERROR (-1) IF GIVEN WAITTIME AMILLISECONDS IS NEGATIVE
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Fix testIndex seg fault where index not exists when calling indexReadRecords, added check for NULL return
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      MTR ndb_memcache : still better timeout handling & more verbose reporting during test runs
      Revert to older scheduler as default in 7.4 for testing
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Remove MCP_WIX
      Handle server timouts and disconnects in MTR's My::Memcache client
      Work on My::Memcache to handle server disconnects and timeouts
      Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS Bug#20561446 NDB : NDBEVENTBUFFER NEEDS MORE THREADING PROTECTION
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      fix
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      NDB Memcache external_values fixes: The external_values test had a Perl bug using "==" instead of "eq", causing tests to pass even when the server produced errant responses. This patch fixes the test case and also fixes the revealed errant behavior in memcached.
      Remove MCP_WIX
      Remove MCP_WIX
      Remove MCP_WIX
      Do not change default scheduler in 7.2
      NDB Memcache: use pollEvents2() in reconfiguration waiter thread
      bug#17638548: NDB Memcached uses excessive CPU. This patch works around the underlying issue by defaulting to a new scheduler which does not make use of the NDB MultiWait APIs.
      NDB Memcached: enable "Trondheim" scheduler in 7.2
      one more solaris fix
      Fix for compiler error on Solaris
      Adapt 73 Scheduler to new online configuration manager
      one more solaris fix
      Fix for compiler error on Solaris
      Fixup from previous merge
      NDB Memcache: backport improvements into 7.2
      Backport misc. NDB memcache changes from 7.3 to 7.2
      Raise version number after cloning 7.2.20
      Raise version number after cloning 7.3.9
      Raise version number after cloning 7.4.6
      Raise version number after cloning 7.1.35
      Attempt better "htonll" portability in NDB memcache code
      BUG#20665205, fixed a part where we skipped reading of page 0 which was required to do in last file, also due to file 0, page 0 writes we can trust this page to be correct
      Add ndb specific changes for Bug#20094067: BACKPORT BUG#19683834 TO 5.5 AND 5.6
      Added ndb testcase for bug#19856162.
      Post-push fix for bug#19856162.
      Merge into cluster: WL#8354 BACKPORT DIGEST IMPROVEMENTS TO MYSQL 5.6
      Revert "Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS"
      Revert "Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS"
      Revert "Bug#20729091 - ASSERTION `TYPE < NDBDICTIONARY::EVENT::TE_EMPTY' FAILED."
      Revert "Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED"
      BUG#20665205: Fix REDO log issue
      Added autotest testcases to test addnode and restart.
      Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED
      Bug#20729091 - ASSERTION `TYPE < NDBDICTIONARY::EVENT::TE_EMPTY' FAILED.
      Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS
      Bug 20762291 - POLLEVENTS2() WILL RETURN ERROR (-1) IF GIVEN WAITTIME AMILLISECONDS IS NEGATIVE
      Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS Bug#20561446 NDB : NDBEVENTBUFFER NEEDS MORE THREADING PROTECTION
      Remove MCP_WIX
      Resurrect unintentionally remove disabled.def file

[33mcommit 9098b95e8b50533f359b1e263713a1d9423ec9f4[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Sat Apr 18 10:57:00 2015 +0100

    Bug#20902600: REDUCE HEADER FILE DEPENDENCIES IN SP* AND EVENT* FILES
    
    Remove unneccesary #includes from sql/sp* and sql/event* files
    (implementing stored program support). Reduce dependencies and
    [1;31mspeed[m up compilation.

[33mcommit ca6ecd8229c53b0a139304bf6641cef6e529e61a[m
Merge: b840f9e9e35 2e91bec76f5
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Apr 8 12:35:31 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug #20590548 UNABLE TO LOGIN WITH USER WHOSE PWD CHANGED FROM 5.6.23 MYSQLADMIN IN 5.7.6
      Bug#20726413 : MYSQL_SSL_RSA_SETUP DOES NOT HAVE USER OPTION
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES                    OF INNODB_CHECKSUM_ALGORITHM
      WL#8244 Hints for subquery strategies. Part#2: Add support for SEMIJOIN/_SEMIJOIN and SUBQUERY hints
      WL#8244 Hints for subquery strategies. Part#1: Add optimizer_switch for DuplicateWeedout strategy.
      WL#7696 follow up fix, check return values.
      Fixed bug#20745142: GENERATED COLUMNS: ASSERTION FAILED: THD->CHANGE_LIST.IS_EMPTY()
      Fixed bug#20797941: WL8149:ASSERTION `!TABLE || (!TABLE->READ_SET ||                     BITMAP_IS_SET(TABLE->READ_SET
      BUG#20593808 - CRASH WITH PARTITIONED TABLES + MULTITABLE DELETE
      WL#7696 follow up fix.
      Bug#20788853 MUTEX ISSUE IN SQL/SQL_SHOW.CC RESULTING IN SIG6. SOURCE LIKELY FILL_VARIABLES
      WL#7696 followup - remove unused file
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, rerecord the test
      WL#7696 follow up fix, add INNODB_COMPRESS_DEBUG to the test.
      Bug#20840377 UNITILAISED BYTES REPORTED AT MY_WRITE.C:63
      Fixed failing tests after commit 335a53004313ab5a971cf17dea36f1dc4490db9f MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20755430 COST CONSTANT CACHE MUTEX NOT INSTRUMENTED BY PERFORMANCE SCHEMA
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      WL#7696 follow up fix.
      WL#7696 follow up fix - add INNODB_COMPRESS_DEBUG to the list
      Addendum to bug #20810928: fixed the test to reflect that COM_SHUTDOWN can be a zero-length RPC
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20678411 BROKEN MAKEFILE DEPENDENCY: SQL_YACC.YY AND LEX_TOKEN.H
      Bug #17299181    CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      BUG#20093172 LOG_STATE DECLARED VOLATILE, MISSING MEMORY BARRIERS
      BUG#20042205 RPL_GTID CHECKABLE_RWLOCK DEBUG CODE DOESN'T NEED VOLATILE              LOCK_STATE
      BUG#20042109 MYSQL_BIN_LOG::M_PREP_XIDS DOESN'T NEED TO BE VOLATILE
      BUG#20754369: BACKPORT BUG#20007583 TO 5.1
      Bug #17299181  CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      Bug#20411374:CAN NOT EXECUTE CHANGE MASTER AFTER ERROR OCCURED IN MTS MODE
      Bug#20683741 fixed.
      Bug #20814051 CREATE USER BINLOG EVENTS INCLUDE NEW ACCOUNT KEYWORD
      BUG#20510811 - RQG_ALTER_ONLINE_PART RUN INTO ASSERTION: NODE->ENTRY
      Bug#20279241 - ALTER TABLE XXX CHARACTER SET UTF8, CONVERT TO CHARACTER SET LATIN1 SHOULD FAIL
      Adapt new sql/ha_ndbcluster.cc code to use the new ER_THD() macro
      Remove MCP_GLOBAL_SCHEMA_LOCK patch
      Bug #20810928: CANNOT SHUTDOWN MYSQL USING JDBC DRIVER
      Fixed Bug #20683741.
      Test cleanup
      Bump version to 7.5.0
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20811494 SHOW_COMPATIBILITY_56 = OFF INCOMPATIBLE WITH CONNECTORS
      Bug#20531812: MEMORY CONSUMED QUICKLY WHILE EXECUTING LOOP IN PROCEDURE
      Bug#20683959 LOAD DATA INFILE IGNORES A SPECIFIC ROW SILENTLY UNDER DB CHARSET IS UTF8
      Remove MCP_BUG16021021
      Remove MCP_WIX
      Bug#20313067 CHECK TABLE REPORTS WRONG COUNT FOR SPATIAL INDEX AND OTHER GIS PROBLEMS
      Bug#20124342 MYSQL 5.6 SLAVE OUT OF MEMORY ERROR ? Problem: I/O thread on Slave with master_info_repository=TABLE settings, is leaking memory that leads to Out of memory (OOM) after some time.
      Fix merge error in mysql_system_tables_fix.sql
      Remove MCP tags for BUG16226274
      BUG#20811125 INNODB FTS: FTS_PRINT_DOC_ID PRINTS TOO MANY DEBUG INFORMATION
      Bug#20762059 - innodb_thread_concurrency=1 and queries using intrinsic temp tables, causes hang
      Create an .inc file which does slow shutdown before restarting innodb in read-only mode.
      Bug#19811953 ENVELOPE() FUNCTION RETURNS INVALID POLYGON Bug#20196720 ENVELOPE(P) RETURNS NULL FOR A NON NULL POLYGON P
      Bug #20544581         ASSERTION: REC_PAGE_NO > (ULINT) 4 - (REC_SPACE_ID != 0)
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 - Fix a merge issue.
      WL#7696 - Fix a merge issue
      WL#7696 - Fix the column ordinatlity. Messed up in a previous merge.
      WL#7696 - Fix a compilation error
      move some compression tests elsewhere until using Win32::API module is approved. Improve error detection, if there is no module, the tests will succeed, not fail as before, but the testing power will be somewhat limited.
      Bumped rpm version for oel due to respin
      Bug#20756770 MYSQL SERVER DOESN'T COMPILE AGAINST OPENSSL 1.0.1M
      Patch for Bug#17162055: SSL.CMAKE SILENTLY CHOOSES BUNDLED YASSL INSTEAD OF ERRORING FOR OLD OPENSSL VER
      Bug#20755346 EXAMPLE SCRIPT IN FIREWALL MISSES WHERE CLAUSE
      Bug#20764521 REGRESSION: FIREWALL USE GENERAL_HOST TO RESOLVE HOST
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      Resurrect unintentionally remove disabled.def file
      Resurrect unintentionally remove disabled.def file
      Bug#20651661 NDBEVENTBUFFER LEAKS GCI_OP
      Remove three files which did not properly remain
      WL#7696 - Make LZ4 decompress safe during recovery
      Remove hack to allow large number of failing tests in mtr.pl
      WL#7696 - Reset the contents of the page to NUL.
      WL#7696 - Use the double write buffer pages for compressed pages.
      WL#7696 - Fix syntax error on Windows.
      WL#7696 - Fix debug assertion.
      mysql-test/include/innodb-compress-utils.inc:   add OSD support to get allocated file size for Windows
      add the result file missing in the previous commit
      Test update:   mysql-test/suite/innodb/t/table_compress.test:     fix one failing case for 32k   mysql-test/suite/innodb/r/table_compress_2.result: make use of new     include files   mysql-test/suite/innodb/t/table_compress_3.test: new test to cover     what was not covered yet, shared tablespaces in particular   mysql-test/include/innodb-compress-verify.inc: common sequence     for compression verification   mysql-test/include/innodb-compress-utils.inc: perl compression     related utilities.     Note: OSD Windows file allocated size is not implemented yet.     The test is still expected to pass on Windows because the allocated     size is forced to the expected value.
      Bug #20536590: BACKPORT BUG #12368204 AND BUG #16953758 TO MYSQL-5.6
      WL#7696 - Code clean up. Ignore table COMPRESSION setting if set to NONE.
      WL#7696 - Minor code cleanup
      WL#7696 - Fix the punch hole size calculation.
      Bug#20712432 AUTOTEST: TESTFK FAIL IN CLEARTABLE WITH 256 REFERENCED ROW EXISTS
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#17775772 POTENTIALLY UNINITIALIZED BUFFER IN NDBOUT::PRINT* PRINTOUT   - print nothing or just empty newline instead of uninitialized buffer   - catch error with an assert in debug compile
      Bug#17775607 POTENTIALLY UNINITIALIZED BUFFER IN VNDBOUT_C PRINTOUT  - print empty newline instead of uninitialized buffer  - catch error with an assert in debug compile  - Mark vndbout_c as static and thus local to implementation Conflicts in copyright:        storage/ndb/include/util/NdbOut.hpp     storage/ndb/src/common/util/NdbOut.cpp
      Remove unused parameter ndbcluster_drop_event()
      Bug#20032381 KILLED_STATE SAVE IN NDBCLUSTER_BINLOG RETRY AT SHUTDOWN DOESN'T NEED TO BE VOLA
      Bug#20014045 MONOTONIC SPELT INCORRECTLY IN NDB CODE
      Bug#20092754:  MYSQLD CRASH (FOUND UNCOMITTED AUTOCOMMIT+RBWR TRANSACTION, COMMIT STATUS 3)
      mysql-test/suite/innodb/t/table_compress_2.test:
      Raise version number after cloning 7.4.5
      Correct MTR command for 64k run. Adiing missing "k".
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      Tetss that use innodb_compress_debug should run against debug server
      Added runs with differnt combination and page size setting for Innodb suites
      mysql-test/suite/innodb/t/table_compress.test:   Fix failure when hole punching is not available.   Now the test will be skipped instead
      Revert accidental bump of server version back to 5.6.23
      Fix a compilation warning in non-debug mode
      BUG#18949230: Removed unneeded ndbassert and fixed printout, also recorded number of real periods
      Added some extra output to ndbapi tests utilities as an aid to hunt down the AutoTest failure 'testBasic -n Bug54986 D2'
      Added log printout about invalidation of REDO log and where log head was found
      WL#6815 Adapt MySQL Cluster to 5.7
      Added autotest files for Mikaels environment, added comments about how to get file system as part of results in autotest, added comment about how to handle older git versions with autotest
      BUG#20546157: Fix problems in START_PERMREQ and START_INFOREQ that hangs node restarts when invalidation of nodes is still ongoing at node restart
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20480035 REMOVE MCP_BUG44529
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disable ndb_rpl_circular_2ch* waiting for Bug20592110
      Disable ndb_addnode_witbinlog waiting for Bug17400320
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75720: Fix platform issues with ndb_dd_dump test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      WL#7696 - Don't print a warning on Windows if SPARSE FILE attribute can't be set
      BUG#20631645: Ensure that SYSFILE->latestLCP_ID is properly up-to-date in the pause LCP protocol
      Fix regression caused by wl#7674 in testBasic -n RefreshTuple T6 D1
      Fix regression caused by wl#7674 in testDict -n Bug13416603 I2.
      Fix for Bug#20408733:
      WL#7696 - Punch hole message is Linux specific.
      WL#7696 - Backport code from mysql-trunk to mysql-5.7
      Followup fix for "Bug20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK"
      WL#6815 Adapt MySQL Cluster to 5.7
      Another follow up fix for "BUG11748566 - MYSQL SHOWS WRONG DEFAULT VALUE FOR PK IF  NOT NULL NOT SPECIFIED"
      BUG#20568586: Fix ndb_cpcd to avoid reading a closed file
      BUG#20567730: Ensure that late arriving LCP_FRAG_ORD with lastFragmentFlag set from new master are handled correctly, correct is to ignore them if such a signal arrives in idle LCP state
      Fix for bug#20538179
      BUG#20546899: Faulty ndbrequire fixed
      BUG#20553247: Fix memcpy overlapping copy issue
      BUG#20553247: Use memmove for overlapping memory copy
      Commit this fix on behalf of Pekka N:
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      BUG#19811871 VERSION NUMBR NOT SHOWN IN LOG WHEN [RE]STARTING 5.6.21 SERVICE WITH SLES11 REPO
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      Updated copyright information
      Bug#20228839: MISSING DATABASE '-D' OPTIONS FOR FEW OF THE HUGO TOOLS
      Re-enable clusterj tests disabled during 7.4.4 release.
      Bug#20593065 MULTI UPDATE RETURNS DIFFERENT DATA WITH ENGINE NDB
      This commit is a followup to the fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_time calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop timeout to be configured).
      Add support for SLES12
      Merge 7.3->7.4
      Merge 7.2->7.3
      Overriding release() function from the DynamicObject class in its subclasses.
      This commit is a fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_time calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop timeout to be configured).
      Reverse order of libraries used when linking the ndbapi examples
      Add small MCP for problem with Partition_handler::get_default_num_partitions
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM: fix test regression
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7549: Fix test case for removed EMPTY_LCP protocol
      BUG#20444078: Removed unneeded log printout
      BUG#20444078: Fix master takeover of COPY_GCIREQ protocol
      WL#6815 Adapt MySQL Cluster to 5.7
      Revert accidental version number change
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20528878 : P_S UNIT TEST IS FAILING
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM
      Temporarily hack mtr.pl to allow a large number of failing tests
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disabling ndb.clusterj and ndb.clusterj_jpa tests for 7.4.4 release.
      WL#6815 Adapt MySQL Cluster to 5.7
      bump version to 7.4.5
      Bump version to 7.4.5
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20281479: Entered eternal loop when starting node in MGM server due to buggy bug fix
      Fix unintentional increase in testsize by a factor of 100 of 'testBasic -n Bug54986'
      BUG#20513571: Introduce MaxSendDelay for large clusters
      Fix failing AutoTest 'testIndex -n NFNR3*'
      BUG#20512063: Moved verbose logging to only be used in verbose mode
      Add missing failure detection for 'testBasic -n Bug54986'.
      BUG#20281479: Ensure that START_ORD is properly sent from management server
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20504971: Fixed restart_info table to provide its output
      WL#6815 Adapt MySQL Cluster to 5.7
      Proper error printouts after reaching NDBT_FAILED in test cases
      Backport fix for BUG#20276462
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Updated to newest version of flexAsynch
      Patch related to bug#18401543
      BUG20308276: Don't use same list for master and participant part of takeover processing
      Fix issue in AutoTest where test are being killed by WatchDog during memory allog in startphase 0.
      BUG20276462: Fixed spelling error in error code
      BUG#20276462: Error code ZNODE_FAILURE_ERROR has no treatment in NDB API, use NODE_SHUTDOWN_ERROR instead
      WL#8148 NDB: Add git support to Autotest
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT
      Bug#20234994 JOINS ARE NOT PUSHED AFTER WL6042
      Revert "Adapt pushed joins to WL#6042"
      Fix for Bug#19053226 AUTOTEST FAIL: TESTSRBANK -N MIX -L 300 -R 15 T1
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) PART III
      Bug#20410087 GCOV COVERAGE DATA FOR NDB KERNEL IS MISSING
      WL#8294 NDB: turn on signal checksum as default
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Disabling mtr tests on 7.1 which fail because SSL certificates have expired.
      Re-recording mtr test result after ssl certificate update
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT Generated new certificates with validity upto 2029.
      Fix test client failure for AutoTest 'testNodeRestart -n ClusterSplitLatency'
      Bug#19785977:  CRASH IN NDBINDEXSCANOPERATION::SCANINDEXIMPL
      Bug#20423898 BAD TEST TESTNODERESTART -N LCPTAKEOVER CAN NOT FAIL.
      Improve ndb_rpl_circular_2ch_rep_status reliability.
      Test was random failing due to matching random binlog junk. Make false matches less likely.
      A little brute force to understand the issues with ndb_rpl_circular_2ch_rep_status
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      Experimental experiment with experimental status.
      A more standard variant of !valgrind.
      BUG#19667566 : PARTITION BY WITH COMMENT LEADS TO MYSQL SERVER REBOOT IN MYSQL CLUSTER
      Sacrifice Valgrind run to improve ndb_rpl_slave_binlog_index reliability.
      Backport of fix for bug#16209645
      Bug#17579998 TEST 'TESTNODERESTART -N GCP -L 1 T1' FAILS DUE TO MYSQLD ABORTED
      ndb_rpl_slave_binlog_index.test
      ndb_types.test contained binary raw data from 'bit' and 'binary' columns.
      Bug #20372169         NDB : INCORRECT STATUS VARIABLES NDB_LAST_COMMIT_EPOCH_[SERVER|SESSION]
      Fix of uncorrect merge (7.2 -> 7.3) of regression fix for bug#19524096
      Fix regression introduced by fix for bug#19524096.
      Fix regression introduced by fix for bug#19524096.
      Fix regression introduced by fix for bug#bug#19524096.
      Improve ndb_rpl_slave_binlog_index.test behaviour under Valgrind.
      Bug#20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK INTEGRATION
      Add some improved debugging to help understand non locally reproducable problems with ndb_binlog_last_commit_epoch testcase.
      This commit is a fix for Bug#19880969 (CLUB FOR 7.1, LINUX-RELEASE, 345 WARNINGS IN BUILD). The fix suppresses these warnings, so that the corresponding square in club becomes green rather than red.
      Bug #19306793         CORE IN NDBAPI WHEN EXTENDED EXTENSION TABLE IS CREATED IN MYSQL 7.4
      Quick fix of corrupted special comment characters. No code change.
      Updated the copyright year in README and welcome message
      Improve garbage collection of clusterj artifacts
      Updating copyright year
      Some copyright fixes to files changed in 2014
      Fixing user visible copyright years
      Fix for 7.4.3 build failures
      Fix for copy right year
      Corrected copyright year by sreedhar
      Updated README and banners to 2015
      bump version to 7.1.35
      pgmanpe pe-dump.diff pgman: dump max page entries bug#18484117 bug#19915761 bug#19958804
      pgmanpe pe-config.diff pgman: configure max page entries bug#18484117 bug#19915761 bug#19958804
      BUG#19480197, BUG#73667, BUG#74945: Ensure Local object has transferred back object to real object before calling recursive function
      Cherrypick fix which removes MCP_WL1735 from 7.4
      Cherrypick fix for bug20009152 from 7.4
      Adapt pushed joins to WL#6042
      Follow up fix for bug#20112981
      Fix for bug#20112981
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - rewrite clean_away_stray_files() to use find_files() direct rather than going via make_db_list(). - The only difference between make_db_list() and find_files() is that the information_schema database is not   return in the list of databases. But it's currently not possible  to create a NDB table in information_schema   and thus there can not be any "stray" tables there either.  - testcase added to ndb_reconnect which shows access denied when trying to create table    in information_schema  - This avoids patching the MySQL Server to make the static make_db_list() function available    to use in ha_ndbcluster_binlog and thus the MCP for make_db_list() and LOOKUP_FIELD_VALUES   can be removed. - Also remove the NDB_WITHOUT_MAKE_DB_LIST which was used for compiling ndbcluster in MySQL Server
      Remove unused TNTO_NO_REMOVE_STRAY_FILES Thd_ndb option
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#19898269, BUG#74594: Fixed wrong order of sending bitmap of LCP participants to ensure that starting node can correctly calculate the lcpOngoing flag for each fragment
      Another addendum patch for bug#20112981, adressing comment from Mikael R.
      Incremental addendum patch for bug#20112981
      Fix for bug#20112981
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#75220: Added option to use 10 and 20 LDM threads (same for NoOfLogParts)
      BUG#20215395: Bug in cluster join protocol
      Added jams to place where data nodes freezes in startup
      BUG#19590336: Preparatory patch adding lots of jam:s to DD code, also a few more more comments added
      Additions to wl#7674
      Bug#18715165, BUG#17069285
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug#20193236 SOME COMPILER WARNINGS BECAME ERRORS AFTER MERGE OF MYSQL SERVER 5.5.41
      Cherrypick from 5.6 : Bug#20009154 - FIX REGRESSION AFTER HA_FLUSH_LOGS() HOOK FOR NDB IS REMOVED.
      Bug 19895502 -  BINARY LOG GROUP COMMIT CAUSES REGRESSION FOR NDB REPLICATION.
      This commit is a followup to WL#8145 (NdbInfo : Per-fragment operations info). That WL introduced an error causing 'testScan -n Bug54945 T1' to fail: short-signal scans crashes because the attrinfo section is not available at the point where the code tries to read it to find the size of the interpreted progam. This commit fixes that by not trying to count program size for short-signal scans and lookups. Since these only happen during online upgrade, they are not important for per-fragment statistics.
      Bug #19992856 MYSQL CLUSTER TRIGGER ON DELETE FALSE POSITIVE
      This commit is a followup to the fix for bug#19976428 ("reports failing with 'out of longmessagebuffer' error"). This commit updates a regression test (testIndex/FireTrigOverload) so that it will expect the right error code (293 "Inconsistent trigger state in TC block" instead of 218 "Out of LongMessageBuffer").
      autotest auto1.diff testBasic -n Bug16834333 : fix dict cache crash
      Bug #19858151         MAKING DATA NODE SELF-EXCLUDE MECHANISM MORE ROBUST
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Updated fix for bug#20113145:
      Follow up to fix for bug#bug#20166585:
      Follow up to fix for bug#bug#20166585:
      This commit fixes bug #19976428 ("reports failing with 'out of longmessagebuffer' error"), and a set of other issues related to the pool of "Fired Trigger" records.
      Bug#17069285 : SEGMENTATION FAULT IN NDB_PRINT_FILE
      Update to recent fix where we failed to close scan cursors at the end of their lifetime.
      WL#7514: Fitted into infoEvent max size and decreased some too wordy log printouts
      Update 'v3' fix for bug#20166585:
      WL#7514: Fixed an incorrect assert
      Fix for various AutoTest 'testIndex ...' crashing due to excessive memory usage.
      Bug#18715165, BUG#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for: - Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT - BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      The AutoTest testcase 'testScan -n Bug54945 T1' crashed as it failed to create a transaction object which was later referred without first checking that it was created.
      Fix for crashing AutoTest: 'testNdbApi -n RecordSpecificationBackwardCompatibility'
      WL#6815  Adapt MySQL Cluster to 5.7
      Fix flexAsynch also in 7.3, backport from 7.4
      WL#7508: Parallelize synchronization of starting nodes with live nodes
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - Test fails since the two new default sql_modes  ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES   are displayed by "show create procedure"  - Update .result file to include the two new default sql_modes(as has been done in similar   places)
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      Experimental fix for several AutoTest which crash with an unreadable stack dump very early in their lifecycle, like:
      Fixed crashing AutoTest testBitfield.
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Cherrypick fix for ndb_memcache out of source from 7.4
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20135403 NDB_MEMCACHE TEST DOES NOT WORK IN OUT OF SOURCE BUILD
      Fixed crashing AutoTest: './testLimits -n ExhaustSegmentedSectionPk WIDE_2COL'
      Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT
      BUG#74594: Fixed a hang in PAUSE LCP protocol when LCP was completed between PAUSE and UNPAUSE
      Removed lots of jam noise from QMGR preventing one from seeing the bugs
      WL#6815  Adapt MySQL Cluster to 5.7
      Revert some junk lines from pfs_upfgrade*.result files
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherry-picked from mysql-5.6.22-release
      Cherry-pick from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-pick from mysql-5.5.41-release
      Added tag mysql-5.6.22
      Added tag mysql-5.5.41
      BUG#74594: Fix missing state update that causes PAUSE LCP protocol to hang
      BUG#74594: Added some more DUMP printouts for PAUSE LCP protocol
      WL#7650: Make atrt work on Mac OS X
      Removed assert / require from NDBT_ResultRow c'tor and rewrote it such that it could be constructed even if the the object is not in 'Retrieved' state.
      BUG#75007: Ensure we wait until master takeover is completed before handle LCP_COMPLETE_REP from LQH and DIH participants in the LCP protocol
      Bug#20029843 7.4.2 REGRESSION: UPGRADE_TRAFFIC FAILURES FOR 7.4 -> 7.3: Fixed incorrect conditional expressions
      Cherrypick fix for ndb_dist_priv.sql from 7.4
      WL#6815  Adapt MySQL Cluster to 5.7
      Cherrypick fix for mysql_system_tables_fix.sql from 7.4
      WL#6815 Adapt MySQL Cluster to 5.7
      Encourage MySQL to treat numeric variables as numbers so that ndb_rpl_conflict_epoch2_extra does not return incorrect results from inequality tests.
      BUG#75007: More work on ensuring that we drop the right signals of the LCP_COMPLETE_REP and LCP_FRAG_REP, a bit tricky to decide, wrote up an analysis in a comment and a fairly simple code based on this analysis
      Cherrypick fixes for ndb_alter_table_online from 7.4
      Remove usage of DEFAULT 0 for TIMESTAMP
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fixed for ndb_update_no_read from 7.4
      Turn "info" off after each section in test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fix for ndb_dd_disk2memory from 7.4
      Add missing enable_query_log comman in ndb_dd_disk2memory.test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75007: Fixed interaction with early master takeover initialisation and handling of failed node in LCP, code in new master
      BUG#75007: Handle side effect of bug fix, there are signals generated by node failure handling that must be allowed to pass through the code as they are required for node fail handling to be done properly
      Apply patch for MCP_BUG19704825to 5.7.5
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#74594: Fix of variable length in message to management server to avoid printing garbage
      BUG#75007: Ensure that we drop LCP_FRAG_REP and LCP_COMPLETE_REP that originates from a dead node. The LCP could potentially be done before this arrives due to node failure handling, these signals are sometimes delayed and thus we need to take care that we can still receive them.
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Assumption that all alive nodes have participated in LCP at close down time caused havoc since we can now be alive and still not have participated in the LCP. So had to move the send of the last LCP_COMPLETE_REP backwards a bit to be able to reuse the m_participatingDIH bitmap to send to.
      remove last NDB_WITHOUT_COLUMN_FORMAT ifdef  - since all versions of MySQL Server which ndbcluster   compiles against now supports "field->column_format" and "field->storage_type" - one NDB_WITHOUT_COLUMN_FORMAT left behind(or reappeared)
      BUG#19795152: Missed essential ptrCheckGuard in upgrade/downgrade situations
      WL#7514: More printouts to log for system restart case
      BUG#18610698: New test case
      BUG19795152: Fix Software upgrade issue
      Add missing delete of Ndb instance created by testcase
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Minor tweak of jamming and of a loop
      BUG#19795217: Checked the LCP state a bit too early
      BUG#74594: Added one more cluster log event
      BUG#74594: Wrong check if LCP is idle when sending UnPause message
      bug#20045455 Improve error reporting for clusterj
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Fixed a compiler warning in new tool
      BUG#74594: Wrote an analysis tool for reading DIH Fraglist files to enable easier analysis of system restart bugs
      BUG#74594: Queued LCP_COMPLETE_REP comes from LQH, not from DIH
      BUG#74594: Fixed a typo bug in an important condition
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Added a new ndbrequire to find problem
      WL#7514: Added a bit more logging of the actual start order signal
      flexBench created its worker threads, flexBenchThread, with a stack of insufficent size. This later caused the threads to crash.
      WL#7509: Add undocumented interface to change Disk Write Speed in LCPs, change isn't persistent over restarts, useful to handle SRs where restarts are too slow
      WL#7509: Tweaked the adaptive LCP [1;31mspeed[m parameters to be a bit slower in changing
      BUG#74594: Add DUMP_STATE_ORD variant to print pause state to cluster log
      BUG#19795108: Proper fix of node restart status using the new Node Recovery Status module
      BUG#19795152: Handle Partial System restarts
      BUG#74594: Used wrong variable in non-master to decide on pauseAction
      Attempt better "htonll" portability in NDB memcache code
      Fix for bug#19390895
      BUG#74594: Ensure that we drop PAUSE_LCP_REQ signals from master if it concerns a node that already has died
      BUG#74594: Node failure in inopportune time caused crash
      BUG#74594: Decrease amount of useless jam:ing to make bugs more visible
      Bug#19642978: NDB_RESTORE CORES ON BUILT-IN PRIMARY KEY + STAGING BLOB CONVERSIONS ON SPARC
      Fix for bug#20031313  AUTOTEST CASE 'TESTDICT -N GETTABINFOREF' NEVER WORKED FOR >= 4 DATA NODES
      BUG#74594: Turned ndbrequire condition the wrong way, caused obvious crash, added a few more ndbrequires while at it
      BUG#19795152: Also NODE_FAILURE_COMPLETED and ALLOCATED_NODE_ID can be states from where a node fails from DISCONNECT_REP although the node hasn't really started its start yet.
      BUG#74594: Removed buggy ndbrequire, not correct though to possibility of delaying arrival of LCP_FRAG_REP when copying table to disk
      BUG#19795152: NdbTick_Elapsed parameters in wrong order
      BUG#19795152: Added one more acceptable state transition, ALLOCATED_NODE_ID -> ALLOCATED_NODE_ID
      BUG#74594: Missed setting lcp id in COPY_TABREQ, added ints of LCP variables on replica and fragment records, removed init of lcpStatus in INCL_NODEREQ which depended on old fact that we included when LCP was idle, now this is no longer necessary, missed init of m_lcp_start_time in including node in LCP, added a number of log prints
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#19676350 NDB_RPL_CONFLICT_EPOCH SHOWS SCHEMA DIST TIME FAST FORWARD DUE TO EINVAL
      BUG#74594: missed init of c_queued_lcp_complete_rep
      BUG#74594: Handle fromTimeQueue issues with LCP_FRAG_REP
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed stopping of pause properly in master and in non-master
      BUG#74594: Wrong assumption in START_LCP_REQ removed, fix of ndbrequire of COPY_TABREQ counter improved
      BUG#74594: Added new parameters to allocStoredReplica
      BUG#74594: Missed init of fragId and tableId in replica record, wrong assumption about m_participatingDIH in START_LCP_REQ
      BUG#74594: Missed clear of own node in NodeReceiverGroup in sending FLUSH_LCP_REP_REQ
      BUG#74594: Fixed typo
      BUG#74594: Missing inserts into signal table
      BUG#74594: Fixes for wrong assert, missing state update and wrong condition
      BUG#74594, fix for sanity check
      BUG#19795152: Fix a placement new that overwrote the node recovery timers in debug mode, added a bit more debug code and arranged the parameters in some common functions a bit more logically
      BUG#74594: Added missing file CopyTab.hpp
      BUG#74594: Remove need for long wait for LCP to copy meta data to make restart times more predictable and faster
      BUG#74639: Preparatory patch to handle overload bugs that is likely to be caused by higher pressure on LCPs and restarts
      BUG#19795152: Added missing file: NodeRecoveryStatusRep.hpp
      BUG#19795152: Wait for LCP start at node restart, add node recovery status table as well
      BUG#19795217: Remove EMPTY_LCP protocol from master takeover
      BUG#74594: Part 2: Fix a potential LCP stoppage
      BUG#74594: Part 1: Remove a faulty ndbrequire
      BUG#19795029: Improve logging of restarts developed in WL#7514
      BUG#19795108: Fix of node restart status for adapting [1;31mspeed[m of LCP disk write [1;31mspeed[m
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug#20007248 NDB NOT FUNCTIONAL ON POWER
      Bug#20007216 FLEXASYNC USES 32BIT MATH, LEADING TO INCORRECT SUMMARY ON POWER8
      Fix regression in AutoTest -n DropWithTakeover T1 introduced by fix for bug#19874809:
      Add missing newline before end of file in AsyncNdbContext.cpp
      Fix build failure in MCP patch for BUG19553099
      bug#20017292 Clusterj logging levels too verbose
      Bug#20009152 FIELD NAME NOT INCLUDED IN WARNING WHEN CONVERTING TO FIXED
      WL#7640  Ndb Active Active Delete-Delete handling
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Fix Club test regressions after backport of bug#19524096:
      WL#7640  Ndb Active Active Delete-Delete handling
      Provide easy way to store documents with no mapping and no schema defined   define new method on session factory: db(database_name) returns db object   db object has properties corresponding to table names     if table does not exist, create the table       if user has not mapped the table, create default table mapping and table       if user has mapped the table, use table mapping to create the table   Operations on session using non-existing table name     will now create the table if it does not exist and user has mapped the table
      Fix bad #ifdef
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Bug #19817817 TFBUFFER::VALIDATE() CONST: ASSERTION `(P->M_BYTES & 3) == 0\' FAILED
      Backport of fix for bug#19524096
      Bug#19999242 DELETEING NDB_CLUSTER_CONNECTION WITH NDB INSTANCES
      bug#19913569
      Avoid segv when closing session factory with sessions still active
      Bug #17592990: DATA MISMATCH BETWEEN C NDB API AND MYSQL CLI.
      Backport of fix for Bug#19724313
      Fix for bug#19880747:
      Fix for bug#19875663
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Fix for bug#19881025:
      This commit is an update of WL#7375 (Ndbinfo: Per-fragment memory usage reporting). Column fixed_elem_free_rows in view ndbinfo.memory_per_fragment is renamed to fixed_elem_free_count to get a more consisten naming.
      Fix for bug#19874809 :
      Added sles11 repo packages
      This commit implements WL#8145 (NdbInfo : Per-fragment operations info).
      Follow up fix for bug#18352514 fixing a build failure.
      Addendum fix for bug#18352514:
      bump version to 7.4.3
      Bug #19875710         NDB : COMMIT ACK MARKERS LEAK @ LQH IN 7.4
      BUG#19815044: Part 4, remove usage of global block variable m_pgman_ptr, it is used for parameter passing, but can in some weird situation in DBTUP it can be reassigned to a value that can cause an inconsistent database.
      BUG#19815044: Part 3, fix such that an aborted insert after a committed delete doesn't lead to that triggers for delete isn't executed by ensuring that delete_insert_flag is properly maintained
      BUG#19815044: Part 1: Improve jamming support to make it easier to read what's going on bug situations
      BUG#19815044: Add test case for it used in autotest
      BUG#19815041: Crash on abort of delete after successful delete on a disk data table
      Add global.fail_connect to test utilities
      Fix ProjectionErrorTest
      Improve error reporting for multidb tests
      big lint-fixing patch
      Fix unified_debug issue with per-file levels for C++ files Remove workaround for this in executable programs
      Converter use in DBTableHandler (fixes freeform tests for ndb)
      Big deglobalization patch. Removes many global variables (but not all).
      Move SQL.create and SQL.drop from test harness into adapters. NDB depends on MySQL for this.
      Enhance closeAllOpenSessionFactories() so it takes a callback & returns a promise
      Fix for bug#19712569
      When using node --harmony and strict mode, DBIndexHandler cannot be forward declared   and still use the function DBIndexHandler(parent, dbIndex) syntax.
      jscrund: add support for B tests with varying size varchar. (Only supported by jscrund_mysqljs crund backend).
      lint globals cleanup
      Fixes restart race causing test timeout in AutoTest 'testDict -n schemaTrans'
      Return an error if writing non-Buffer data to binary columns
      Allow flexible mapping for node.js domain classes
      Fix for bug#18352514
      Fix for bug#19661543
      Remove warning introduced with patch for BUG#19236945
      Bug #19236945 ADDRESSSANITIZER BUG SHOW UP IN NDBRECATTR::RECEIVE_DATA CALLED FROM RESTORE.CPP
      bug#19793475 - NO WAIT FOR EPOCHS THAT HAVE NO DB CHANGES MADE BY THIS NDB THD TO BE IN BINLOG
      Removing the extra blank line from daily-basic-autotest-conf
      Fixed compilation error due to changed file name
      Bug#19267720:  NDB REPLICATION : DO NOT SETUP CONFLICT RESOLUTION FOR EXCEPTIONS TABLES
      formatting
      Docs work
      BUG#19795072: Fix problems related to ndbinfo tables for disk write [1;31mspeed[m
      BUG#19643174: Fix races in relation to sending TC_COMMIT_ACK and handling of complete of a transaction
      Removed compiler warnings
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000): GOT ERROR 4547 PART II
      Cherrypick from 7.4 (revno 4354): Implement status variables exposing last commit epochs for the server   and each session.
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      BUG#19724313: Handle multiple threads crashing at the same time properly
      Added missing include for previous patch Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Restore computeChecksum to computeXorChecksum that was reverted in patch for Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Merge of Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Refactoring of Packer::unpack in preparation of merging Bug#19582925
      Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      wl#7674-5 fixing errors
      wl#7674-5 fixing errors and compiler warnings
      wl#7674 Backward compatibility/new event api methods
      wl#7675 Introduce state machine for event buffering
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) : GOT ERROR 4547 : 'RecordSpecification has overlapping offsets'
      Applying the patch for regression bug#19582807 for 7.1.33 cluster release
      Improve Query documentation
      Cherrypicked
      Cherrypicked
      Bug #19582807 MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Wl#7639 Ndb Active Active Manageability improvements
      Removed compiler warnings
      WL#7642 Ndb Active Active Binlog Read Tracking: Removed uninitialized data to remove valgrind warnings
      Work on new README
      Bug #17257842     EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #19766167         NDB : VALGRIND REACHABLE MEMORY IN NDB_RPL_CONFLICT_EPOCH_TRANS
      Fix new log printouts - Use log functions of component in favour of sql_print_information - Break long lines
      In-Progress Packaging / Documentation improvements
      Iterate array rather than for/in
      Add mynode.closeAllOpenSessionFactories()
      Windows testcase fix attempt
      Follow up patch for WL#7953 Transporter handshake retry
      WL#7642 Ndb Active Active Binlog Read Tracking: Updated result for ndb_rpl_conflict_read_tracking test case to reflect new conflict counters
      WL#7640  Ndb Active Active Delete-Delete handling
      bump version to 7.3.8
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      bump version to 7.2.19
      bump version to 7.1.34
      Bug#19692387 PORT FIX FOR BUG 18770469 TO MYSQL CLUSTER 7.3
      Added ndb_print_file man pages
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug#18487960: SIG 11 on delete with index merge
      Follow up patch for WL#7953 Transporter handshake retry
      Follow up patch for WL#7953 Transporter handshake retry
      Patch 2 for WL#7953 Transporter handshake retry
      Patch 1 for WL#7953 Transporter handshake retry
      Patch 3 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 2 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 1 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      adding checksum to the cnf file
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19600834  late code review comment
      Bug #19600834 DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH)
      Bug #19600834         DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH) ...
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3
      Bug #19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3  - revert the reverted
      Bug#19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Change from mysql-5.6 to build Oracle Linux 7 RPMs
      WL#7640  Ndb Active Active Delete-Delete handling
      WL7640 Add delete-delete conflict count
      Adding ndb_print_file to spec file
      Repush of WL#7544 after 7.4.1 clone tag.
      bump version to 7.4.2
      Set version 7.4.1
      Revert WL#7544, not to be included in DMR 7.4.1
      Reorder member initializer list for thr_data to follow initialization order. This removes compiler warning introduced in fix of Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      WL#7544: Optimisations of the NDB API receiver thread in various manners. 1) Optimising method to unpack field data from TRANSID_AI signal, 2) optimised handling of trp_client locking check, 3) reorganised code in NDB API receiver thread for better performance and more readability, 4) Optimisation signal receive handler
      BUG#19451060: One more step on the way to understanding commit ack markers
      Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Fix for bug#19559313, call getPerformStateString() with a nodeId arg instead of a state argument
      Fix for Bug#19552283 :
      Update documentation to remove useProjection       Update Session.js to remove useProjection
      BUG#19552349: Avoid stack overrun by removing endless recursive call
      BUG#19451060: Further refinements of bug fix, previous ndbrequire revealed a race that could cause multiple REMOVE_MARKER_ORDs to appear for the same transaction, added long comment about this specific race variant. Left a part of the ndbrequire still to ensure that this only happens when receiving REMOVE_MARKER_ORD sent by API through TC_COMMIT_ACK and not through API failure handling
      Bug #18703922  DUMP-CODE ACTIVATED DEBUGGING ON WATCHDOG OVERLOAD ISSUES
      Bug #17730825  NDB API: POSSIBLE LEAK OF CONNECTION OBJECTS
      BUG#19524096: Converted many 4009 errors to temporary error 4035, ensured APIs can use new data nodes sooner, fixed some wrong error categories, removed no longer used errors, fixed some anomaly in communication towards the API, small improvement of restart printouts, should give autotest a much better chance to get rid of redness
      Bug #17893872         ER_DUP_ENTRY WHEN INSERTING TO AUTO-INC COLUMN ON SPARC MULTI-MASTER SETUP
      BUG#19451060: Added more descriptive information at crashes related to commit ack markers, changed name of noFired to numFired for clarity, added possibility to put last in free list to aid crash printouts
      Fix for spelling error in Win32 code
      WL#7509: Introduced more configurability of disk write [1;31mspeed[ms and added a number of new ndbinfo tables to track this new more adaptive behaviour
      WL7845: More and safer ways to print records in DBTC
      BUG#19451049: Missing call to prepareTUPKEYREQ from handle_lcp_keep, added comment about handle_lcp_keep
      bug#19124970 - PB WITH POLLEVENTS , NDBEVENTS
      Backport from 7.2
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      The Bug was due to m_out object used in NdbOut operator was not initialized/set to the output stream. Added an ndb_init() call to initialize it to output stream. Added an environmental variable $NDB_PRINT_FILE to give path to its binary in  mysql-test/mysql-test-run.pl file. Added a unit test and its result file.
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      bug#19031389 bugfix.diff bug fix
      bug#19031389 bugtest.diff bug test
      BUG#19513967: Fixed missing init of longer bitmask
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      BUG#17703874
      Bug#19202654: NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      Bug #18354165         16723708 CHANGED EVENT CATEGORY VALUES
      Clusterj windows CMakeList error
      Clusterj support for autoincrement columns http://wl.no.oracle.com/worklog/NDB-RawIdeaBin/index.pl?tid=8027
      Added missing logging.properties
      Clusterj improve maven handling for out-of-source builds
      Bug#18875137: NDB_RESTORE STILL MISSING SOME TYPE CONVERSIONS
      Fix for Bug#19414511:
      Bug #19236785  ADDRESSSANITIZER BUG IN ~NDB_MOVE_DATA Bug #73311      AddressSanitizer bug in ~Ndb_move_data
      Bug #19235428  ADDRESSSANITIZER BUG IN DATABUFFER2<SZ,POOL>::IMPORT (DBDICT::ALTERTABLE_PARSE) Bug #73310     AddressSanitizer bug in DataBuffer2<sz,Pool>::import (Dbdict::alterTable_parse)
      Bug #19235170  ADDRESSSANITIZER BUG IN DBUTIL::GET_SYSTAB_TABLEID Bug #73308  AddressSanitizer bug in DbUtil::get_systab_tableid
      Bug#11764704 : Exclude missing tables when restoring a backup  - added an option "--exclude-missing-tables" to ndb_restore tool  - when enabled, the missing tables will be added to the    exclude tables list before starting to restore.  - updated test cases accordingly.
      Revert fix merged in from 5.5.39 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert fix merged in from 5.6.20 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert quick fix for dtrace problems in release tree. New fix in CMake files will be merged in from 5.6.20.
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      This commit is a followup to the one below. It changes the fragment_num colum (in memory_per_fragment), such that it gives the global frgament id rather than a node-local sequence number. That way, it is possible to see where each fragment (or some replica of it) is located. This is consistent with the output from 'ndb_desc -pn -d <database> <table>.
      Bug 19028487 NPE when scanning rows with blob or text columns
      More fixes for bug#19053226
      Fixes for bug#19053226
      More fixes for bug#19053226
      bug#18410939 - MEMORY LEAK AT EVENT BUFFER ALLOCATING A DUMMY EVENT LIST WHEN INCONSISTENCY
      Bug #17184024         ERROR 4 IN LIBNDBCLIENT.SO.6.0.0 (3-7474573041)
      bug#19122346 fix3.diff FK use full name PP/CC/name + debug
      bug#19122346 fix2.diff fix test error from 7.3 r4203 FK_Bug18069680
      bug#19122346 fix1.diff FK use full name PP/CC/name
      ndb - RSS-DynArr256
      A new ndbapi test case: testNodeRestart -n DeleteRestart.
      Bug #18731008    NDB : AVOID MAPPING EMPTY PAGES DUE TO DELETES DURING NR Bug #18683398    MEMORY LEAK DURING ROLLING RESTART
      Bug #19193927         TC TAKEOVER TAKES TOO LONG CAUSING MANY PROBLEMS
      ndb
      Bug#19193756 MTR GENERATES TOO LONG SOCKET PATHS
      Merge from mysql-cluster-7.2.17-release
      ndb
      use primitive types
      Include stdlib.h for malloc() and free()
      Compiler issues on some Windows platforms
      Add debug to trace bug#18411034 - CRASH IN NDB-SHARE
      Updated the list of tables to be deleted after running ndb clusterj tests Added new test and the model to build specification
      Merge latest nodejs-adapter from 7.3 to 7.4
      Unconditionally disable dtrace for rpm, barfs on Oracle dtrace
      Remove superfluous -master.opt file for the removed test case ndb_mt_recv.
      Unconditionally disable dtrace for rpm-oel, barfs on Oracle dtrace
      correcting copyright headers
      Fix issues with Read/Modify/Update of NDB VO objects containing blobs.
      All NDB read results (including those containing BLOB and TEXT columns) are now ValueObjects.
      Fix bug of using Persistent<T>(x) rather than Persistent<T>::New(x)
      work on support for NdbRecord-backed ValueObjects which contain TEXT or BLOB columns.
      More TEXT tests for NDB
      less debugging output at end of test run
      Fix composition value checking
      Implement bufferForText and textFromBuffer in C++.
      rawNdbDefaultvalue does not require a full-fledged Node Buffer
      let compiler supply default destructors
      Another attempt to fix crashing bug in BlobHandler
      Expose the string encoder statistics in NdbTypeEncoder.cpp to JavaScript.
      Move v8 calls from worker thread to main JS thread
      Support TEXT columns with character set UTF-8 or ASCII. Other charsets (which require recoding) are not yet supported.
      A test file that does not export a test case now causes a warning rather than an error.  This should make it a little easier to develop new tests.
      Column Metadata API provides charsetName rather than charsetNumber
      Fix apparent bug in calculating size requirement of UTF-8 buffer
      Restore compatibility with node-mysql 2.0.0
      Fix crash on stub commit / stub rollback
      update cmake & gyp build lists
      Finish read & write BLOB implementation for NDB adapter
      Implement connection pooling for mysql adapter
      Fix tests that do not close session after running test
      Improve error reporting for connecting to database
      Add suggestion to user to maximize performance of updates
      Improve spi test error reporting
      Succesful insert into BLOB column
      Add BLOB column to stringtypes test suite & confirm that existing tests pass with a mapped (but unused) BLOB field.
      Test that storing a non-BLOB in a BINARY column gives error SQLState 22000
      Use Error SQLState 0F001 "Bad BLOB" (actually a "Locator Exception") if value intended for a BLOB column is not a Buffer.
      Initial implementation work on BLOB support for NDB adapter.
      Refactor connection handling to prepare for connection pooling
      WL#7626 Implement many-to-many relationships for Document Composition
      Don't try immediate startTransaction() unless using async api.
      Keep a single usedOperationSets array rather than one per DBSession. The array is at file scope in NdbTransactionHandler. It does not grow past 4000 elements (a literal constant). Underlying DBOperationSet native objects are freed when the wrapper is placed in the recycler array.
      Disable mysql tests for now
      Attempt to recycle DBOperationSet wrappers
      wrapPointerInObject and unwrapPointer take a v8::Handle<T> rather than a v8::Local<T>
      Improve error reporting for relationships that are null or undefined
      Test a slightly different approach to V8 wrapping
      Minor refactoring in NdbOperation
      Remove the use of "proto" in DBTableHandler
      Refactor DBTableHandler.getFields() into a simple case getFields() and a separate more complex getFieldsWithListener(). Removed the resolveDefaults option which was always set to false.
      Improve error reporting for ProjectionTest
      Improve error reporting for ProjectionTest
      Improve error reporting for test failures
      Compiler error
      Stub out NdbSession.buildReadProjectionOperation in hopes that test suite will run.
      WL#7626 Composition Implement support for one-one, one-many, and many-many relationships. Replace useProjection with implementation for find (projection, key).
      Rather than having a JavaScript wrapper for Record::setNotNull(), implicitly call setNotNull() when writing a data value in encoderWrite().
      Don't use a startTransaction() hint for unique key operations.
      In JsValueConverter for pointer types, if the JavaScript value is Null, represent it as a null pointer.
      Remove what little was left of NdbTransaction_wrapper.cpp
      move ENABLE_WRAPPER_TYPE_CHECKS define into adapter_global.h
      portability fix
      Update source file lists for gyp & CMake
      Add option free-percent
      New design for scans. This removes the previous wrapper for NdbScanOperation and ScanImpl.cpp file and consolidates all scan functions into ScanOperation. Expected: start 416 tests, pass 413, fail 2, skip 1.
      fix wrappers for boolean types
      In test driver allow --stats=query, e.g. --stats=spi/ndb/DBSession
      Add HandleScope to all toJS() template functions just to be safer from enigmatic V8 memory leaks. Provide toJS() and isWrappedPointer() specializations for type bool.
      Refactor NDB execute. This patch renames PendingOperationSet to DBOperationSet, and makes DBOperationSet the "point of contact" for JavaScript calls to begin and execute transactions. All t_basic tests now pass.
      New SPI test   begin transaction; delete (execute NoCommit) ; read deleted row ; commit.
      Minor bug fixes for passing SPI tests
      Major JavaScript logic changes in NDB adapter. NdbTransactionContext, NdbSession, NdbOperation, and NdbConnectionPool are adapted to use the call flow of DBSessionImpl and DBTransactionContext rather than the native call flow of the NDB API.
      This commit includes various small C++ fixes. The next commit includes major JavaScript logic changes. With these together, spi tests pass.
      Add new connection property ndb_sesion_concurrency Refactor initialization of NdbSession and connecting of the new NdbSession to its impl.
      Adapt DBDictionaryImpl to use DBSessionImpl rather than Ndb.
      Revise protocol for registering a transaction open / closed. Use only two calls, registerIntentToOpen() and registerTxClosed(). Always make these calls from JavaScript main thread.
      NdbTransaction is no longer wrapped for JavaScript
      Template class NativeCFunctionCall_4_
      DBSessionImpl
      Adapt AsyncNdbContext to be aware of DBTransactionContext
      executeAsync() on AsyncNdbContext is no longer wrapped for JavaScript; use executeAsync() on DBTransactionContext instead.
      Refactor DBOperationHelper:  it now takes a DBTransactionContext rather than an NdbTransaction.  it now defines operations, but does not prepare them.
      Rename addOperation() to getNextOperation()
      Add two new classes, DBTransactionContext and DBSessionImpl. These will free the JavaScript code from the start/prepare/execute cycle of Ndb and NdbTransaction, eventually allowing operations to be performed with fewer scheduled async calls and therefore less overhead.
      Adapt DBOperationHelper to the KeyOperation / ScanOperation change.
      Bug fix where the do_close flag must be associated with the transaction rather than its parent Ndb object.
      Refactor Operation and DBScanHelper into two classes called KeyOperation and ScanOperation.
      This change alllows Ndb::startTransaction() to run as a sync call in the main JS thread if we suspect that it will not block.  As a proof of concept, this allows you to measure the performance with this change; but it should not be used as-is, because the guess could be wrong, which would cause the main thread to block waiting for network I/O.
      In the common case where an async method call returns int zero, try to optimize away creating a new JavaScript value.
      Slight change to the compatibility strategy for some libuv changes.
      Combine NdbTransaction execute() and close() into a single scheduled call whenever execType is Commit or Rollback.  This saves the scheduling cost of running the close() call by itself.
      Various fixes for lint.
      Remove old stats API.
      Use new stats API in MySQL code.
      Use new stats API in NDB code.
      Revised statistics API. Now each module owns, at file scope, its own stats object. The module registers the stats object with the global statistics, which keeps a reference to it in the stats tree. This should reduce the cost of keeping statistics to practically zero.
      Delay after (rather than before) the first test iteration. This allows V8 to compile all the JavaScript code before dtrace starts running. High dtrace profiling rates caused the first iteration to run very slowly and skewed the profile towards compile times rather than run times.
      Optional delays both before & after jscrund run
      jscrund: add option to delay start of test run
      Add useProjection to Session   this function specifies a projection to be used for find and query operations
      Minor work on DBDictionaryImpl Contain the code for handling NdbDictionary 3-part/slashed/names in DictionaryNameSplitter class. Reformat patch indent width from 4 spaces to 2 spaces. buildDBForeignKey() takes only the fk* and must use its own private name splitter.
      Error 23000 when attempting to set a non-nullable column to null.
      Restore table which should not have been removed from test suite
      Add support for foreign key metadata
      update literal mapping test for schema
      Fix errors in test case & misc. lint errors.
      Check in test case where one operation in a batch has a data type error. This test fails for both NDB and MySQL.
      Expose NdbRecordObject::prepare() to JavaScript. This is a step towards fixing handling of encoder errors for value objects.
      Write a negative value to an unsigned int field of an NDB Value Object. This test causes the test suite to hang forever.
      Run executeAsynch() in JS main thread rather than a UV worker thread. We had seen higher latency using async ndbapi vs. sync ndbapi, but this change eliminates most of that difference.
      unused table in test suite
      Fix for compiler warning in TimestampWriter validity check
      NDB encoding-related changes.  (1) distinguish between 22003 numeric value out of range and HY000 for "value is not numeric"  (2) provide a (hopefully) faster path to encoderWrite and encoderRead by wrapping them as methods of Record
      Refactor error handling
      Attempt to optimize encodeKeyBuffer() for single-column indexes
      Fix reporting of session factory if no mappings
      Remove JsValueAdapter in loader; it is no longer needed.
      This fixes the failing "timestamp 1969" test case for NDB. Test still fails with MySQL.
      Fixes for lint test failures
      Test & fix NDB handling of encoder errors for numeric types
      Tests for numeric types
      This renames the integraltypes suite to numerictypes and adds stub tests for float, double, and decimal columns
      Test for particular expected errors rather than simply for operation failure
      Add decimal support in NdbTypeEncoders Remove JS wrapper for decimal utilities from ndb_util
      Encoders for NDB integer values: if the fast integer conversion fails, try a slow one, then test whether the result is legal.  This should allow writing valid JS string and float values to int columns.
      Improve handling of errors from NDB data type encoders
      Improve handling of data encoder errors in the ndb adapter
      fix sql_mode for mysql adapter
      Implemented test cases
      Stub out new test cases for data type casting
      If MySQLTime.valid is set to false, NdbTypeEncoder will reject the value.
      Allow user to set sql_mode in mysql adapter with a default of STRICT_ALL_TABLES
      Change console.log to udebug.log in issues/2014-03-18Test
      Add shell script to manage regular runs of jscrund
      Adapt loader to use new Batch.getOperationCount() api
      Batch: use getOperationCount()  rather than getSize()
      Add Batch.getSize() method
      Add test case for issue of bad data type for column
      Fix typo
      Add test case for issue where a TableMapping created from a literal mapping could not be used to perform operations (fixed in bzr 686).
      Changes to sample data loader after code review with Craig. This version still has lots of untested features (and combinations of features) but it can load CSV data and random data.
      Bug fix creating TableMapping from object literal
      WL#7578 Replace usage of ndb_schema_share->key with hardcoded text
      WL#7578 Move subscriber bitmaps to NDB binlog component
      WL#7578 Move the g_nodeid_map to Ndb binlog thread
      WL#7578 move clearing of subscribed to binlog thread
      WL#7578 Always expect everyone to ack the schema op
      WL#7578 Refactor schema distribution code
      WL#7578 Refactor schema distribution code
      ndb
      WL#7578 note about nodeid from global cluster connection
      WL#7578 Don't use ndb_schema_share from ack_schema_op
      Initial checkin of JavaScript data loader tool
      Remove windows line endings from ndb_schema_object.cc
      Try to reduce overhead of stats.incr() calls
      Remove the error handling in jscrund_mysqljs backend which duplicates work performed in the jscrund frontend.
      Add conditional guards around udebug log messages.
      Add conditional guards around udebug log statements.
      Improve error reporting while loading mysql node_module
      The node-mysql driver by default constructs an Error object in order to get a stack that includes the user's call to Query. This can be a performance bottleneck.
For keyword delayedInnoDBflush:
For keyword flush:
[33mcommit f63fbd324369fb981e64067cf84584363bc9664e[m
Author: Nuno Carvalho <nuno.carvalho@oracle.com>
Date:   Fri May 18 12:16:51 2018 +0200

    BUG#27652526: REJOIN OLD PRIMARY NODE MAY DUPLICATE KEY WHEN RECOVERY
    
    Group Replication does implement conflict detection on
    multi-primary to avoid write errors on parallel operations.
    The conflict detection is also engaged in single-primary mode on the
    particular case of primary change and the new primary still has a
    backlog to apply. Until the backlog is [1;31mflush[med, conflict detection
    is enabled to prevent write errors between the backlog and incoming
    transactions.
    
    The conflict detection data, which we name certification info, is
    also used to detected dependencies between accepted transactions,
    dependencies which will rule the transactions schedule on the
    parallel applier.
    
    In order to avoid that the certification info grows forever,
    periodically all members exchange their GTID_EXECUTED set, which
    full intersection will provide the set of transactions that are
    applied on all members. Future transactions cannot conflict with
    this set since all members are operating on top of it, so we can
    safely remove all write-sets from the certification info that do
    belong to those transactions.
    More details at WL#6833: Group Replication: Read-set free
    Certification Module (DBSM Snapshot Isolation).
    
    Though a corner case was found on which the garbage collection was
    purging more data than it should.
    The scenario is:
     1) Group with 2 members;
     2) Member1 executes:
          CREATE TABLE t1(a INT, b INT, PRIMARY KEY(a));
          INSERT INTO t1 VALUE(1, 1);
        Both members have a GTID_EXECUTED= UUID:1-4
        Both members certification info has:
           Hash of item in Writeset     snapshot version (Gtid_set)
           #1                           UUID1:1-4
     3) member1 executes TA
          UPDATE t1 SET b=10 WHERE a=1;
        and blocks immediately before send the transaction to the group.
        This transaction has snapshot_version: UUID:1-4
     4) member2 executes TB
          UPDATE t1 SET b=10 WHERE a=1;
        This transaction has snapshot_version: UUID:1-4
        It goes through the complete patch and it is committed.
        This transaction has GTID: UUID:1000002
        Both members have a GTID_EXECUTED= UUID:1-4:1000002
        Both members certification info has:
           Hash of item in Writeset     snapshot version (Gtid_set)
           #1                           UUID1:1-4:1000002
     5) member2 becomes extremely slow in processing transactions, we
        simulate that by holding the transaction queue to the GR
        pipeline.
        Transaction delivery is still working, but the transaction will
        be block before certification.
     6) member1 is able to send its TA transaction, lets recall that
        this transaction has snapshot_version: UUID:1-4.
        On conflict detection on member1, it will conflict with #1,
        since this snapshot_version does not contain the snapshot_version
        of #1, that is TA was executed on a previous version than TB.
        On member2 the transaction will be delivered and will be put on
        hold before conflict detection.
     7) meanwhile the certification info garbage collection kicks in.
        Both members have a GTID_EXECUTED= UUID:1-4:1000002
        Its intersection is UUID:1-4:1000002
        Both members certification info has:
           Hash of item in Writeset     snapshot version (Gtid_set)
           #1                           UUID1:1-4:1000002
        The condition to purge write-sets is:
           snapshot_version.is_subset(intersection)
        We have
           "UUID:1-4:1000002".is_subset("UUID:1-4:1000002)
        which is true, so we remove #1.
        Both members certification info has:
           Hash of item in Writeset     snapshot version (Gtid_set)
           <empty>
     8) member2 gets back to normal, we release transaction TA, lets
        recall that this transaction has snapshot_version: UUID:1-4.
        On conflict detection, since the certification info is empty,
        the transaction will be allowed to proceed, which is incorrect,
        it must rollback (like on member1) since it conflicts with TB.
    
    The problem it is on certification garbage collection, more
    precisely on the condition used to purge data, we cannot leave the
    certification info empty otherwise this situation can happen.
    The condition must be changed to
           snapshot_version.is_subset_not_equals(intersection)
    which will always leave a placeholder to detect delayed conflicting
    transaction.
    
    So a trace of the solution is (starting on step 7):
     7) meanwhile the certification info garbage collection kicks in.
        Both members have a GTID_EXECUTED= UUID:1-4:1000002
        Its intersection is UUID:1-4:1000002
        Both members certification info has:
           Hash of item in Writeset     snapshot version (Gtid_set)
           #1                           UUID1:1-4:1000002
        The condition to purge write-sets is:
           snapshot_version.is_subset_not_equals(intersection)
        We have
           "UUID:1-4:1000002".is_subset_not_equals("UUID:1-4:1000002)
        which is false, so we do not remove #1.
        Both members certification info has:
           Hash of item in Writeset     snapshot version (Gtid_set)
           #1                           UUID1:1-4:1000002
     8) member2 gets back to normal, we release transaction TA, lets
        recall that this transaction has snapshot_version: UUID:1-4.
        On conflict detection on member2, it will conflict with #1,
        since this snapshot_version does not contain the snapshot_version
        of #1, that is TA was executed on a previous version than TB.
    
    This is the same scenario that we see on this bug, though here the
    pipeline is being blocked by the distributed recovery procedure,
    that is, while the joining member is applying the missing data
    through the recovery channel, the incoming data is being queued.
    Meanwhile the certification info garbage collection kicks in and
    purges more data that it should, the result it is that conflicts are
    not being detected.

[33mcommit 1f24c5aa2843fa548aa5c4b29c00f955e03e9f5b[m
Author: Aditya A <aditya.a@oracle.com>
Date:   Fri May 18 12:32:37 2018 +0530

    Bug #27208858   CONCURRENT DDL/DML ON FOREIGN KEYS CRASH IN PAGE_CUR_SEARCH_WITH_MATCH_BYTES
    
    PROBLEM
    -------
    
    1. During truncate when we are trying to [1;31mflush[m out the pages
       of truncated table form the buffer pool we release the dict lock.
    2. At this stage a DDL request  to add a FK constraint from another
       connection,tries to access the stale index memory object of the
       parent table and asserts.
    
    FIX
    ---
    
     Disallow the DDL operation of adding FK when parent table is
     undergoing truncate .
    
     [#rb 19433 Reviewed by Jimmy ]

[33mcommit 3ec74b6c9902ab0ffcbee8b9ece042c1d771fa0d[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Mon May 14 13:31:20 2018 +0200

    Fix for the innodb.log_[1;31mflush[m_order mtr test.
    
    Setup the DEBUG_SYNC point inside InnoDB code in the DBUG_EXECUTE_IF(...)
    just before the proper mini transaction is going to be used (btr0cur.cc).
    
    Use rows with size smaller than 2kB to have consistent behaviour when
    different settings are used for innodb-page-size (e.g. 4kB or 64kB).
    
    Force to assign trx->id at the beginning when we have space in log
    recent closed (because it may trigger [1;31mflush[m of max_trx_id) by doing
    BEGIN, DELETE sequence.

[33mcommit a50fcc118f7bba4d5fe97ab5dac33bfd15e24da4[m
Author: Venkatesh Venugopal <venkatesh.venugopal@oracle.com>
Date:   Mon May 14 11:39:42 2018 +0530

    Bug #27399620: BINLOG AND ENGINE BECOME INCONSISTENT WHEN BINLOG
    CACHE FILE GETS OUT OF SPACE
    
    Problem:
    --------
    If the transaction size is bigger than the binlog_cache_size,
    server uses a file in 'tmpdir' for [1;31mflush[ming the data. If the
    tmpdir partition is full, [1;31mflush[m will fail with 'No Space'
    error.
    
    In such scenarios,
    1. Flush errors were not handled properly in the
       gtid_before_write_cache function.
    
    2. After preparing the transaction, client disconnection
       and rollback were hitting DBUG_ASSSERT(is_binlog_empty())
       in binlog_cache_data::reset() function.
    
    Description:
    ------------
    
    1. In the gtid_before_write_cache function, while [1;31mflush[ming GTID
       to the cache,
    
       a. write position of the cache is set to position 0.
       b. Gtid_log_event is [1;31mflush[med to the cache.
       c. write position is reset to the old position.
    
    In step 'a', reset_write_pos is invoked to set the write position
    to 0. If the cache has swapped to a file, it reinitializes it by
    calling reinit_io_cache() function.
    
    While reinitializing the cache, it tries to [1;31mflush[m the cache to
    the file(file in tmpdir). Since the tmpdir partition is full, [1;31mflush[m
    fails with 'No Space' error and returns from that function.
    
    Since reset_write_pos() or gtid_before_write_cache functions do
    not to check if there was a failure in resetting the position,
    the functions assume that the reset has happened and continues
    without returning immediately and hits an assert
    DBUG_ASSERT(!do_checksum || remains == 0) in
    MYSQL_BIN_LOG::do_write_cache() function.
    
    In release builds, though asserts do not happen, on [1;31mflush[m
    errors, we expected an entry in the error log saying that there
    was an error while writing to binary log. But no such entry was
    there in the error log.
    
    2. On client disconnection/rollback, the server rolls back the
    transaction. While doing so, it calls the
    binlog_cache_data::reset() which in turn calls the truncate()
    function wherein it truncates the binlog cache.
    
    truncate() function tries to reinitialize the cache and
    reinitialization fails(my_b_[1;31mflush[m_io() fails). As a result,
    binlog_cache is not cleared and hits the
    DBUG_ASSERT(is_binlog_empty()).
    
    Fix:
    ----
    1. Flush errors have been handled in the
       gtid_before_write_cache() function.
    
       Now, the server will decide what action to take if this
       situation happens.
    
       If binlog_error_action == ABORT_SERVER, then it will abort the
       server after informing the client with
       'ER_BINLOGGING_IMPOSSIBLE' error.
    
       If binlog_error_action == 'IGNORE_ERROR', then it will ignore
       the error and disable the binlog  further until server is
       restarted again. The same will be mentioned in the error log
       file.
    
    2. Two new functions have been added (set_[1;31mflush[m_error and
       has_[1;31mflush[m_error) to set and check the [1;31mflush[m errors.
       On rollback/client disconnection, the check for
       [1;31mflush[m_error is done and the cache is cleared in case of
       [1;31mflush[m_errors.

[33mcommit 65b61d1494882c75f89ab3536eccc08255392223[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Mon Apr 23 15:25:09 2018 +0200

    BUG#27664539 INNODB: ASSERTION FAILURE: BUF0FLU.CC:457:
                 (BUF_POOL->FLUSH_LIST).START == __NULL
    
    If the page was on disk with higher FIL_PAGE_LSN and it was
    not read from disk, we could potentially decrease the lsn.
    
    Therefore it is much safer, and simpler to rely on the
    log.[1;31mflush[med_to_disk_lsn as the newest_modification for
    no-redo modified dirty pages.

[33mcommit 61c1a2df14c7e8d78263374cafea103e6b145738[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Thu Apr 19 20:34:14 2018 +0200

    BUG#27664539 INNODB: ASSERTION FAILURE: BUF0FLU.CC:457:
                 (BUF_POOL->FLUSH_LIST).START == __NULL
    
    If no-redo mini transaction modifies a given page first time, but the
    page was stored on disk before, it must ensure that the lsn set to the
    newest_modification of the page is not smaller than the page_lsn stored
    on disk (available at frame + FIL_PAGE_LSN).
    
    Added assertion that ensures that the new page_lsn is never smaller than
    the previous one. It is checked whenever page is [1;31mflush[med to disk, when
    the newest_modification is being copied to field at frame + FIL_PAGE_LSN.

[33mcommit 8b5f81ed8fd9fc83c308d66522cfc320f9a227fb[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Thu Apr 19 16:16:09 2018 +0200

    Fixed issues discovered by PB2 after fix for BUG#27664539 was pushed.
    Addressed new comments in RB.
    
    We introduced new system variable - innodb_log_checkpoint_fuzzy_now.
    
    1. Therefore we had to create new mtr test for that variable.
    
    2. Improved doxygen comment for innodb_log_checkpoint_fuzzy_now_set.
    
    3. The test innodb.log_[1;31mflush[m_order was unstable because from time to time,
       max_trx_id needs to be stored to disk, which is solved via mini transaction.
       In such case the prepared trap on DEBUG_SYNC_C point fired in wrong place,
       when trx_sys mutex was held, leading to deadlock and timeouted test.
    
    4. The buf_[1;31mflush[m_wait_[1;31mflush[med() was unused after we removed the only usage
       in the bug fix. Removed the function.
    
    5. Removed the unused include file - log_[1;31mflush[m_order_test_redo_noredo.inc.
    
    6. The forced fuzzy checkpoint should not update the main [1;31mflush[med_lsn.

[33mcommit dd6c48eb25f9903f2d742887c29739f81355e400[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Wed Apr 18 13:11:17 2018 +0200

    BUG#27664539 INNODB: ASSERTION FAILURE: BUF0FLU.CC:457:
                 (BUF_POOL->FLUSH_LIST).START == __NULL
    
    1. Fixed a method to assign LSN to pages dirtied in no-redo mini transaction
       (when MTR_LOG_NO_REDO is set).
    
    2. Introduced new MONITOR counters that provide LSN values:
       - log_lsn_buf_dirty_pages_added,
       - log_lsn_buf_pool_oldest_lwm.
    
    3. Renamed log_buffer_write_completed_before_dirty_pages_added
       to log_wait_for_space_in_log_recent_closed, renamed
       log_buffer_write_completed_and_dirty_pages_added to
       log_buffer_close.
    
    4. Do not wait for [1;31mflush[med pages in log_checkpointer when requesting
       sync [1;31mflush[m.
    
    5. Added assertion that ensures we do not rely on mtr.commit_lsn() of no-redo
       mini transactions.
    
    6. Added mtr test for redo/no-redo mtr commits and relaxed order in [1;31mflush[m lists.
    
    RB: 19252

[33mcommit 850ae3704040439d1678c58297e0a696243c97ca[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Fri Mar 9 14:49:42 2018 +0100

    Bug #27349579 SEVERE PERFORMANCE REGRESSION IN SERVER BOOTSRAP
    
    Post-push fix.
    
    Setting innodb_[1;31mflush[m_log_at_trx_commit=0 is does not work reliably for
    DDL operations. Revert to REPLACE statements in one transaction as a
    quick fix.
    
    Change-Id: I44094afae315038931a28dac5ba2f4a0ff037c35

[33mcommit 708b8bbd3349d29855f06e11c98b95044cc0ecf1[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Fri Mar 9 14:49:42 2018 +0100

    Bug #27349579 SEVERE PERFORMANCE REGRESSION IN SERVER BOOTSRAP
    
    Post-push fix.
    
    Setting innodb_[1;31mflush[m_log_at_trx_commit=0 is does not work reliably for
    DDL operations. Revert to REPLACE statements in one transaction as a
    quick fix.
    
    Change-Id: I44094afae315038931a28dac5ba2f4a0ff037c35

[33mcommit e4c5e123ded028025ae37aff0aa66c50e5b4d7b5[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Fri Feb 23 09:09:09 2018 +0800

    BUG#25834374 - SELF DEADLOCK FOR DICT_PERSIST->LOCK
    
    The lock was introduced by WL#7816, to prevent concurrent dynamic metadata
    redo log writing when there is an ongoing checkpoint, so that no dynamic
    metadata update will be lost.
    
    However, this lock is somehow problematic. Because it will be acquired in
    S mode during INSERT/UPDATE and X mode on checkpoint. The INSERT and UPDATE
    will write redo logs after holding the S mode lock, which may trigger a
    checkpoint, so on the checkpoint, when it tries to get the X mode lock,
    it will fail due to holding previous S mode lock. This design also makes
    log_checkpoint complicated and not easy to understand. So the best is to
    remove this dict_persist->lock completely.
    
    In this patch, this lock is removed. To make sure no concurrent dynamic
    metadata change would be lost, the dict_persist->mutex is now leveraged
    to protect it. The logic is on checkpoint, dict_persist->mutex would be
    got during [1;31mflush[ming all in-memory dynamic metadata to
    mysql.innodb_dynamic_metadata, any concurrent update to in-memory
    dynamic metadata will update the metadata and then check the
    table->dirty_status, if it's already dirty, then just continue, if it's
    not dirty, it has to get the dict_persist->mutex to mark the metadata
    change, at this stage, it has to wait for the checkpoint.
    
    On checkpoint, the checkpoint lsn should also be adjusted a bit.
    Relying only on oldest_lsn is not enough, the dynamic metadata write-back
    will also get a dict_suggest_checkpoint_lsn which is safe for the dynamic
    metadata change so that any dynamic metadata change should be either
    applied to mysql.innodb_dynamic_metadata or in redo logs after this
    dict_suggest_checkpoint_lsn, and the smaller between the oldest_lsn and
    dict_suggest_checkpoint_lsn becomes current checkpoint_lsn. The oldest_lsn
    should not always be far bigger than dict_suggest_checkpoint_lsn, so this
    adjustment should not affect the final checkpoint_lsn too much.
    
    RB: 18555
    Reviewed-by: Pawel Olchawa <pawel.olchawa@oracle.com>

[33mcommit 80976f88f2cd35f28a8320a40fa17da32723cc92[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Feb 15 17:15:36 2018 +0100

    WL#10310 Redo log optimization: dedicated threads and concurrent log buffer.
    
    Post-push fixes for clang warnings:
    
    storage/innobase/buf/buf0flu.cc:437:20: error: unused function
          'buf_[1;31mflush[m_list_order_validate' [-Werror,-Wunused-function]
    static inline bool buf_[1;31mflush[m_list_order_validate(lsn_t earlier_added_lsn,
    
    storage/innobase/os/os0file.cc:314:23:
    error: missing field 'm_file' initializer
          [-Werror,-Wmissing-field-initializers]
      pfs_os_file_t file{0};
    
    storage/innobase/srv/srv0srv.cc:1954:16:
    error: unused function 'timeval_diff_us'
          [-Werror,-Wunused-function]
    
    Change-Id: I2eb1b8347ca7d041ce3c6ac3c0b3a635d5f4805a

[33mcommit 0b1b0b40408d0738ac41f3d1185f5b895730b265[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Feb 15 17:15:36 2018 +0100

    WL#10310 Redo log optimization: dedicated threads and concurrent log buffer.
    
    Post-push fixes for clang warnings:
    
    storage/innobase/buf/buf0flu.cc:437:20: error: unused function
          'buf_[1;31mflush[m_list_order_validate' [-Werror,-Wunused-function]
    static inline bool buf_[1;31mflush[m_list_order_validate(lsn_t earlier_added_lsn,
    
    storage/innobase/os/os0file.cc:314:23:
    error: missing field 'm_file' initializer
          [-Werror,-Wmissing-field-initializers]
      pfs_os_file_t file{0};
    
    storage/innobase/srv/srv0srv.cc:1954:16:
    error: unused function 'timeval_diff_us'
          [-Werror,-Wunused-function]
    
    Change-Id: I2eb1b8347ca7d041ce3c6ac3c0b3a635d5f4805a

[33mcommit 6be2fa0bdbbadc52cc8478b52b69db02b0eaff40[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Wed Feb 14 09:33:42 2018 +0100

    WL#10310 Redo log optimization: dedicated threads and concurrent log buffer.
    
    0. Log buffer became a ring buffer, data inside is no longer shifted.
    
    1. User threads are able to write concurrently to log buffer.
    
    2. Relaxed order of dirty pages in [1;31mflush[m lists - no need to synchronize
       the order in which dirty pages are added to [1;31mflush[m lists.
    
    3. Concurrent MTR commits can interleave on different stages of commits.
    
    4. Introduced dedicated log threads which keep writing log buffer:
        * log_writer: writes log buffer to system buffers,
        * log_[1;31mflush[mer: [1;31mflush[mes system buffers to disk.
       As soon as they finished writing ([1;31mflush[ming) and there is new data to
       write ([1;31mflush[m), they start next write ([1;31mflush[m).
    
    5. User threads no longer write / [1;31mflush[m log buffer to disk, they only
       wait by spinning or on event for notification. They do not have to
       compete for the responsibility of writing / [1;31mflush[ming.
    
    6. Introduced a ring buffer of events (one per log-block) which are used
       by user threads to wait for written/[1;31mflush[med redo log to avoid:
        * contention on single event
        * false wake-ups of all waiting threads whenever some write/[1;31mflush[m
          has finished (we can wake-up only those waiting in related blocks)
    
    7. Introduced dedicated notifier threads not to delay next writes/fsyncs:
        * log_write_notifier: notifies user threads about written redo,
        * log_[1;31mflush[m_notifier: notifies user threads about [1;31mflush[med redo.
    
    8. Master thread no longer has to [1;31mflush[m log buffer.
    
    9. Introduced dedicated log thread which is responsible for writing checkpoints.
       No longer concurrent user threads need to compete for this responsibility.
    
    10. Master thread no longer has to take care of periodical checkpoints.
        Log checkpointer thread writes checkpoint at least once per second
        (before it was once per 7 seconds).
    
    11. The following exposed system variables, can be changed in runtime now:
        * innodb_log_buffer_size,
        * innodb_log_write_ahead_size.
    
    12. Master thread measures average global cpu usage in OS.
    
    13. Introduced new exposed system variables:
        * innodb_log_wait_for_[1;31mflush[m_spin_hwm,
        * innodb_log_spin_cpu_abs_lwm,
        * innodb_log_spin_cpu_pct_hwm.
        They control when we need to use spinning for the best performance,
        to reduce latency which would otherwise come from communication
        between log threads and user threads. The first one is based on
        average [1;31mflush[m time, the two others are based on cpu usage.
    
    14. Introduced new CMake option: ENABLE_EXPERIMENT_SYSVARS=0/1. System variables
        can be marked as hidden unless the experiment mode is turned on.
    
    15. There is a list of hidden new system variables for experiments with redo log.
        We skip listing them here.
    
    16. Created dedicated tester for redo log alone (as gtest).
    
    17. Created doxygen documentation for the new redo log.
    
    18. The dict_persist margin is updated when number of dirty pages is
        changed, instead of calculations on demand.
    
    19. Mechanism used to copy last incomplete block for Clone has been changed,
        because log buffer is concurrent now.
    
    20. Added more useful MONITOR counters for redo, including average lsn rate.
    
    21. Introduced sharded rw-lock to have an option to stop the world in redo,
        because log_mutex is removed.
    
    22. Invented and implemented a concurrent data structure which tracks progress
        of concurrent operations and can answer up to which point they all have been
        finished (when there is some order defined but they are allowed to be executed
        out of the order). This structure is used for concurrent writes to log buffer
        and re-used for concurrent additions to [1;31mflush[m lists.
    
    23. Introduced a universal mechanism to wait on event, which starts with
        provided number of spin delays, then fallbacks to waits on event,
        starting at small timeout, but increasing timeout every few waits.
        This mechanism is used in communication between user and log threads,
        and in communication between different log threads.
    
    24. We slow-down redo log writer when there is no space in redo allowing
        checkpoints to progress and rescue the state of redo.
    
    25. Log buffer can be resize in runtime - the size can also be decreased.
    
    26. Simplified shutdown procedure to avoid a possible returns in logic
        to previous phases.
    
    27. Removed concept of multiple log groups.
    
    28. Relaxed conditions required for checkpoint_lsn. It can now point to
        any data byte within redo (does not need to point to a records group
        beginning).
    
    29. Windows: always use buffered IO for redo log.
    
    30. Mysql test runner received a new feature (thanks to Marcin):
        --exec_in_background.
    
    Review: RB#15134
    
    Reviewers:
        - Marcin Babij <marcin.babij@oracle.com>,
        - Debarun Banerjee <debarun.banerjee@oracle.com>.
    
    Performance tests:
        - Dimitri Kravtchuk <dimitri.kravtchuk@oracle.com>,
        - Daniel Blanchard <daniel.blanchard@oracle.com>,
        - Amrendra Kumar <amrendra.x.kumar@oracle.com>.
    
    QA and MTR tests:
        - Vinay Fisrekar <vinay.fisrekar@oracle.com>.

[33mcommit 1b050394f2a95bdf729c5bef2a287a955f1c3b86[m
Author: Venkatesh Duggirala <venkatesh.duggirala@oracle.com>
Date:   Wed Feb 14 12:27:54 2018 +0530

    Bug#27041759 RESET MASTER WHILE A TRX IN BGC(AFTER FLUSH) LEAVING
    SERVER IN BAD GTID STATE
    
    Problem: When a transaction is in Binlog group commit, ([1;31mflush[m stage is done
             but third stage, commit stage, is not done yet), if some one executes
             RESET MASTER, binlog will not contain the transaction (it will be
             cleared by RESET MASTER), but after the transaction is committed,
             transaction gtid is added to gtid_executed. And this gtid cannot be
             utilized by server again even though the transaction is already
             cleared from the binlog. This leaves the server in bad gtid state.
    
    Analysis: Server adds the transaction's gtid to owned_gtid during the [1;31mflush[m stage.
        And at the time of commit stage, the owned_gtid is added to gtid_executed.
        As the above problem statement states, if there is RESET MASTER in between
        these two stages, the transaction content is getting cleared but we are adding
        the gtid to gtid_executed which leaves the server in bad gtid state.
    
    Fix: RESET MASTER is going to acquire global read lock to make sure
        that no transacation is currently in commit stage while doing it's
        operation. If there are any ongoing commits, RESET MASTER will wait
        until those commits are done. Acquiring global read lock will also
        make sure that no new commits will enter into commit stage. At the
        end of the 'RESET MASTER' operation, it will release the global
        read lock.
    
        Other cases:
           > If the thread is already acquired 'global read lock' by executing
        'FLUSH TABLES WITH READ LOCK' command, then RESET MASTER will not
        try to acquire again.
           > If the thread is holding lock (read/write) on any table, RESET MASTER
             will throw error ER_LOCK_OR_ACTIVE_TRANSACTION.

[33mcommit 228519a0c5d149dd00b0b3b86bb4aa9f47e2f3b3[m
Author: Deepthi ES <deepthi.e.s@oracle.com>
Date:   Wed Dec 6 09:28:05 2017 +0530

    Revert "WL#10475 : Defaults: Enable Parallel Replication Applier"
    
    This reverts commit 573e51cf5c66277695caabebdb38c1c9ada35349
    44fc07918777db863feffa052253357b2b176d59 and
    c01636c07f4f34a1bd7f8f7ab1b5ddf60d2fb2af
    
    Conflicts:
            mysql-test/r/read_only_persisted_plugin_variables.result
            mysql-test/t/[1;31mflush[m2-master.opt
            sql/sys_vars.cc

[33mcommit 541f51122d05b993a9216a0dd46b3fce5a227c3a[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Tue Jan 16 16:19:25 2018 +0100

    Bug #27349579 SEVERE PERFORMANCE REGRESSION IN SERVER BOOTSRAP
    
    Problem: mysqld --initialize is significantly slower on some file
    systems after switching from several INSERT statements in one
    transaction to auto-committing CREATE SPATIAL REFERENCE SYSTEM
    statements to initialize the spatial reference system definition list.
    
    The root cause is that InnoDB transactions are slow on some file
    systems. Since CREATE statements are auto-committing, the change in SQL
    statements during --initialize causes ~5000 new transactions to be
    executed, which is noticable on file systems where transactions are
    slow.
    
    Solution: Set innodb_[1;31mflush[m_log_at_trx_commit=0 before installing spatial
    reference systems during initialization. Since this is done during
    initialization of an empty data directory, no user data is lost if
    mysqld crashes.
    
    Change-Id: I6a23e408a4226b92d437a0181f7fb45f137a63b8

[33mcommit 71b0c585173257ff7a27f0cebe562f69ada2720a[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Fri Jan 12 11:14:55 2018 +0800

    Bug#26848711 - PERFORMANCE REGRESSION IN "CREATE TABLE" SPEED AND SCALABILITY IN 8.0.3
    
    The performance regression is mainly due to that DDL logs are logged and
    [1;31mflush[med after every transaction commit under dict mutex and lock protection.
    So it showed that dict_operation_lock is very hot.
    
    Since it has to [1;31mflush[m redo logs after every transaction commits, so that
    it's true crash-safe DDL, this penalty can't be avoided. However,
    after new DD, dict_operation_lock along with dict_sys mutex are not
    necessary to be held for such a long time during DDL, so we should
    try to deprecate dict_operation_lock and ask for dict_sys mutex
    as less as possible.
    
    Current patch mainly fix this issue in above way for CREATE TABLE and
    the modified code will of course affect ALTER TABLE a bit too.
    Basically, dict_operation_lock is not necessary for CREATE TABLE any more.
    And dict_sys mutex would be acquired only when dict_sys information
    is modified, such as adding new dict_table_t to cache, increase
    dict_sys->size etc. The dict_sys mutex should not be held during
    creating physical data files, etc. Once it's proper time to get rid of
    these dict lock and mutex for all DDLs, it could be possible to clean up
    dict_sys mutex further.
    
    At the meantime, since dict_sys mutex is not held during the whole
    process of CREATE TABLE, once the dict_table_t is added to global cache,
    it has to be kept in cache without eviction before writing metadata of it
    to dd::Table. So this requires some changes for
    innobase_basic_ddl::create_impl().
    
    Furthermore, in this patch, dict_table_close() doesn't have to acquire
    dict_sys mutex any more, instead it has to acquire a per-table mutex
    called dict_table_t::mutex, to prevent the race from ha_innobase::open().
    
    RB: 17608
    Reviewed by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 4c0ae4b42cfc68a3a0752e6e6748c70d30147cbd[m
Author: Pedro Figueiredo <pedro.figueiredo@oracle.com>
Date:   Fri Dec 15 15:18:22 2017 +0000

    Bug#27040070 ERROR 1598 (HY000): BINARY LOGGING NOT POSSIBLE + ABORT
    
    Description
    -----------
    In some cases, while rotating the binary log, the server crashes with an
    expected error but the message being outputed to the error log is not
    consistent with the error. For instance, when the server crashes because
    the binlog numeric suffix reaches maximum allowed value, the message being
    written to the error log states that, either, the disk is full or the
    filesystem is read-only.
    
    How To Repeat
    -------------
    RESET MASTER TO 2147483647;
    FLUSH BINARY LOGS;
    SELECT 1;  # Shows server is gone
    
    Analysis
    --------
    - In sql/binlog.cc, MYSQL_BIN_LOG::new_file_impl function, several function calls
    are subject to error validation, all redirecting to a final tag that outputs
    the same abort message for all of them.
    - In some cases, the error message is erroneous because it doesnot represent
    the actual cause of the abort command.
    - The following test scripts may be affected by changes in this message:
      * mysql-test/suite/binlog_gtid/t/binlog_[1;31mflush[m_logs_error.test
      * mysql-test/suite/binlog/t/binlog_error_action.test
      * mysql-test/suite/i_binlog/t/binlog_disabled_restart_fails.test
    - Either add all the possibles causes to the current message or just forward
    the actual error message to 'exec_binlog_error_action_abort' invocation.
    - Correct the message output in the several tests, if needed.
    
    Fix
    ---
    - Forwarded the actual error as a parameter for 'exec_binlog_error_action_abort',
    outputting to log the actual cause of the abort command.
    - Added a new error message to be forwarded, 'ER_OOM_SAVE_GTIDS_ON_BINLOG_ROTATION'
      for out-of-memory errors while saving GTID's to gtid_executed table on
      binlog rotation.
    - Added new warning suppression following tests:
      * mysql-test/suite/binlog/t/binlog_error_action.test
      * mysql-test/suite/binlog_gtid/t/binlog_[1;31mflush[m_logs_error.test

[33mcommit 684e5e202ea97a2d9066b4bb8218fa2d2db7f7bb[m
Author: Joao Gramacho <joao.gramacho@oracle.com>
Date:   Tue Oct 31 10:41:19 2017 +0000

    WL#9452: Log Position Lock
    
    Step-1: Introduce Master_info::[1;31mflush[med_relay_log_info
    -----------------------------------------------------
    
    Collecting current relay log coordinates directly from its relay_log is
    error prone from the backup/restore point of view.
    
    After writing into the relay log file, the receiver thread will acquire
    the Master_info::data_lock to [1;31mflush[m the new master coordinates into the
    Master_info repository.
    
    When a thread acquires Master_info::data_lock after the relay log write
    and before the receiver thread acquire Master_info::data_lock will make
    the receiver thread to block before [1;31mflush[ming into Master_info
    repository. At this point, the relay_log coordinates are not in sync
    with Master_info repository.
    
    Collecting instance log status at the above mentioned state would lead
    to restoring the relay log to a state other than the one represented at
    slave_master_info table.
    
    This step is introducing a new LOG_INFO variable into Master_info class
    to hold the relay log coordinates (file name and position) representing
    the last master coordinates that were [1;31mflush[med into the Master_info
    repository.
    
    Two new functions will be added to Master_info:
    
      a) Master_info::update_[1;31mflush[med_relay_log_info()
    
         This function will be called by Master_info::[1;31mflush[m_info() at the
         end of a successful [1;31mflush[m of the Master_info content into the
         repository.
    
         It will sync [1;31mflush[med_relay_log_info with current relay_log
         coordinates.
    
      b) void Master_info::get_[1;31mflush[med_relay_log_info(LOG_INFO* linfo)
    
         This function shall be used to collect relay log coordinates that
         the backup should use.
    
    This step is also making Master_info::[1;31mflush[m_info to require data_lock.

[33mcommit 863aac45c8c124d8a80e505e80bd6770d94fe718[m
Author: Sivert Sorumgard <sivert.sorumgaard@oracle.com>
Date:   Mon Aug 28 15:19:00 2017 +0200

    WL#9553: Upgrading the transactional data dictionary tables.
    
    This patch implements support for changing the DD table
    definitions.
    
    Overview.
    ---------
    The main changes are the following:
    
    - SE private data previously hard coded in InnoDB is now
      used only during first time server start. The meta data
      is stored in a DD table. On restart, the meta data is
      fetched from the DD table instead of InnoDB. Thus, we
      may have SE private data that can change.
    
    - During upgrade, we create the required target tables in
      a temporary schema, and migrate the meta data from the
      actual DD tables to the new target tables.
    
    - At the end of upgrade, we modify the persistently stored
      SE private data mentioned in 1) to that of the new target
      tables. We also adjust the schema ID of the target tables
      to simulate altering the schema of the tables. This way,
      we are able to switch from the old to the new DD version
      atomically. The temporary schemas are removed on next
      restart.
    
    In more detail, the patch implements the following:
    
    Performance schema.
    -------------------
    - Change in a performance schema test: Select only the PS_VERSION
      from 'mysql.dd_properties' to avoid reflecting irrelevant meta
      data in the result file, and thus to avoid unnecessary re-recordings
      of the result file.
    
    - Minor changes in the way Plugin_table_impl is used; replaced by
      Object_table_impl for more uniform code.
    
    - Approved by Marc Alff.
    
    Handler and handlerton API and InnoDB.
    --------------------------------------
    - The handler function 'get_se_private_data()' will now be
      called only during '--initialize'. During ordinary restart,
      it will be called once to get the SE private data for the
      'mysql.dd_properties' table, which can never change. This
      is the table that stores the SE private data for the other
      DD tables.
    
    - Modify 'get_se_private_data()' to be in line with what
      'dd_write_table()' does when storing SE private data:
    
      * Store se_private_data for columns. This is now done
        for DD tables in the same way as it is done for
        user tables.
      * Extend se_private_data for indexes to also store
        table_id and space_id. Again, this is done to get
        the same set of meta data for DD tables and user
        tables.
    
      Could dd_write_table() be used to ensure consistency in the
      meta data that is stored?
    
    - At the end of upgrade, we start over DD initialization to
      do the same as for a restart. Thus, we had to provide a new
      parameter to 'get_se_private_data()' to reset the counters
      for this to work with two phases of function calls in the
      case of upgrade.
    
    - We maintain a set in InnoDB of SE private ids of the DD tables.
      This set is used this instead of the hard coded id range used
      previously.
    
    - Replace hard coded ids of tables used in the processing
      of I_S queries by name based lookup.
    
    - Change the order of the DD and DDSE tables in the System_tables
      registry to make sure the table 'innodb_dynamic_metadata' is
      created on a low table id and index id. The motivation is that
      for now, this table must stay at fixed ids because it may be
      opened by InnoDB before the DD is available.
    
    - Approved by Jimmy.
    
    Extensions of 'mysql.dd_properties' and data structures.
    --------------------------------------------------------
    - Valid key/value pairs are explicitly defined:
    
        DD_VERSION                Actual DD version.
        IS_VERSION                Actual I_S version.
        PS_VERSION                Actual P_S version.
        SDI_VERSION               Actual SDI version.
        LCTN                      L_C_T_N setting used during
                                  --initialize.
        MYSQLD_VERSION_LO         Lowest server version which has
                                  been using the data directory.
        MYSQLD_VERSION_HI         Highest server version which has
                                  been using the data directory.
        MYSQLD_VERSION            Current server version.
        MINOR_DOWNGRADE_THRESHOLD The current DD can be used by
                                  previous MRUs, unless their
                                  target DD version is less than
                                  the downgrade threshold.
        SYSTEM_TABLES             List of system tabels with
                                  definitions.
        UPGRADE_TARGET_SCHEMA     Temporary schema used during
                                  upgrade.
        UPGRADE_ACTUAL_SCHEMA     Temporary schema used during
                                  upgrade.
    
    - Simplify Object_table, Object_table_definition,
      Plugin_table_definition, their subclasses and clients.
      Remove unnecessary functions, and rename according to
      usual naming rules. Merge Object_table* and Plugin_table*
      into one class.
    
    - Version number handling does not need to be part of these
      classes, this will be handled elsewhere, so it is removed.
    
    - Object table definitions now may hold definitions of both
      the target and actual tables.
    
    - Introduce explicit enumerations for options, indexes and
      foreign keys for the DD table definitions.
    
    - Explicitly define indexes needed by foreign keys.
    
    - Use the index enumerations when creating instances of
      object keys.
    
    - A new 'DD_bootstrap_ctx' class is introduced as an aid in the
      upgrade process, but also for normal DD bootstrapping. The
      handling of the bootstrap stages is moved into this class.
    
    Changes to the current DD initialization.
    -----------------------------------------
    - Extend the bootstrapper to create target or actual tables
      depending on context.
    
    - Change the way DD objects are [1;31mflush[med (during --initialize) and
      synced (during restart) to avoid problems with overlapping
      ID sequences for the scaffolding and the persisted object IDs.
      This is needed since the DD tables will no more be fixed on low
      IDs.
    
    - Add a new stage before creating tables where the inert table
      'dd_properties' is opened and the version numbers etc. is read.
      Here, the actual DD table definitions are read in case of
      upgrade or minor downgrade.
    
    New handling of upgrade.
    ------------------------
    - Create two temporary schemas with unused schema names, store
      in 'dd_properties'.
    
    - Upon restart, the temporary schemas are dropped.
    
    - First initialize the meta data for the actual DD tables, and
      use this to open the actual tables.
    
    - Then create the target tables, and migrate the meta data from
      the old to the new tables.
    
    - Adjust object ids to simulate altering schema of the new
      and old DD tables at the end of DD upgrade.
    
    - Update properties for all tables, make sure removed
      tables are not reflected in the persisted properties.
    
    Add 'options' columns.
    ----------------------
    - Add a general purpose column to all DD tables that store
      DD entities (i.e.:
    
            catalogs,
            character_sets,
            collations,
            column_statistics,
            events,
            resource_groups,
            routines,
            schemata,
            st_spatial_reference_systems,
           *tables,
           *tablespaces
    
    - Plus a selection of important non-entity tables:
    
           *columns,
           *indexes,
            foreign_keys,
            triggers,
           *parameters
    
    - Tables prefixed by '*' above already have a column named
      'options' which can be used for this purpose.
    
    Miscellaneous.
    --------------
    - Set created/last altered when creating schema.
    
    - Add command line option for disabling automatic DD upgrade.
    
    - Change test for is_dd_table_name() to check for table types in the
      System_tables registry.
    
    - Change dictionary object type names for better conformity.
    
    - Remove *_type classes for the DD object classes.
    
    - Refactor object table usage
    
    Test changes.
    -------------
    - Extend dd_schema_definition_debug_c{i,s} to also record the
      CREATE TABLE statements for the DD tables.
    
    - Record new test results.
    
    - Mask out the DD version number from the SDI which is extracted
      from tablespace files in some tests.

[33mcommit 053a5f91128ac00949e230e98002374b13846a35[m
Author: Christopher Powers <chris.powers@oracle.com>
Date:   Mon Dec 4 16:50:52 2017 -0600

    Bug#25768813 CRASH IN PERSISTED_VARIABLES_CACHE::FLUSH_TO_FILE
    
    Crash caused by race condition in Persisted_variables_cache::[1;31mflush[m_to_file().
    
    Added lock on the persisted variables mutex to block updates to the variable
    cache while it is being written to the file.

[33mcommit 7d6ffdd319a854b39c992d03b3d73862063c0792[m
Author: Christopher Powers <chris.powers@oracle.com>
Date:   Mon Dec 4 15:40:19 2017 -0600

    Bug#25768813 CRASH IN PERSISTED_VARIABLES_CACHE::FLUSH_TO_FILE
    
    Crash caused by race condition in Persisted_variables_cache::[1;31mflush[m_to_file().
    
    Added lock on the persisted variables mutex to block updates to the variable
    cache while it is being written to the file.

[33mcommit 1df8e73e8c7af22c74bef0ab6c0f89bc69b0ee10[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Nov 28 15:51:54 2017 +0100

    Bug#27169809 FIX BUG 17583 FOR ALPINE LINUX
    
    This is an extra addition to the bugfix described below.
    To ensure consistent behaviour also on Alpine, open an extra file descriptor.
    
    Also: when reporting errors in batch mode, [1;31mflush[m stdout before [1;31mflush[ming stderr.
    This makes the output consistent for commands like
    -- exec mysql test>&1 < "<path to input file>"
    
    Similarly for mysqldump: [1;31mflush[m the result file before dumping any error
    reports, to make output deterministic.
    
    Bug#17583: mysql drops connection when stdout is not writable
    
    When the client program had its stdout file descriptor closed by the calling
    shell, after some amount of work (enough to fill a socket buffer) the server
    would complain about a packet error and then disconnect the client.
    
    This is a serious problem.  If stdout is closed before the mysql is
    exec()d, then the first socket() call allocates file number 1 to communicate
    with the server.  Subsequent write()s to that file number (as when printing
    results that come back from the database) go back to the server instead in
    the command channel.  So, one should be able to craft data which, upon being
    selected back from the server to the client, and injected into the command
    stream become valid MySQL protocol to do something nasty when sent /back/ to
    the server.
    
    The solution is to close explicitly the file descriptor that we *printf() to,
    so that the libc layer and the OS layer both agree that the file is closed.
    
    Change-Id: Ic74a2cb752d1a66ff6d7e8e9b8fb98fb85636051

[33mcommit ec22907d9b429d866379e26ff8765f737e2f1c77[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Thu Nov 2 15:44:39 2017 +0530

    WL #8478: UNDO log speedup- parallel LGMAN applying
    
    MTR Test case
    -------------
    
    Steps followed:
    
    1) Create disk tables and do some basic operations on them.
    2) Start LCP so that disk table pages [1;31mflush[med to disk.
    3) Restart one data node in "no-start" mode.
    4) Insert error 7248 to that node for the latest LCP to be
       invalidated, so that the undo log records till the previous LCP
       are applied.
    5) Start node and wait for it to start.
    6) Make sure tables are intact.

[33mcommit 3c3da87c76bb56138561e9b2a90334c2cd74218a[m
Author: Pedro Figueiredo <pedro.figueiredo@oracle.com>
Date:   Thu Nov 16 15:20:18 2017 +0000

    Bug#22994725 RPL.RPL_SEMI_SYNC_FUTURE_LOGPOS FAILSWITH "SEMI-SYNC MASTER FAILED ON NET_FLUSH"
    
    Description
    -----------
    rpl.rpl_semi_sync_future_logpos 'stmt'   w3 [ fail ]  Found warnings/errors
    in server log file!
            Test ended at 2016-03-23 19:35:29
    line
    2016-03-23T18:35:14.607549Z 10 [ERROR] Semi-sync master failed on net_[1;31mflush[m()
    before waiting for slave reply
    ^ Found warnings in /dev/shm/mtr-23122/var-normal/3/log/mysqld.1.err
    ok
    
    Analysis
    --------
    - It is expected for the semi-sync to fail with this error (see also https://bugs.mysql.com/bug.php?id=57764)
    
    Fix
    ---
    - Add message suppression in 'rpl.rpl_semi_sync_future_logpos'

[33mcommit 3df864e8a756a76ac2e63c68d3e8dcce9bfe39f6[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Tue Nov 7 15:50:47 2017 +0300

    Fix for bug#27041536 "TRANS_TABLE || !CHANGED || THD->GET_TRANSACTION()->CANNOT_SAFELY_ROLLBACK...".
    
    CREATE TABLE SELECT which attempted to create non-InnoDB table failed
    due to assertion if there was pre-existing view referencing table to be
    created.
    
    The assertion failure occurred because intermediate commits, which
    happened during update of dependent view metadata in case when table
    in SE not supporting atomic DDL was created, wiped out safe-to-rollback
    flag in transaction context.
    
    This fix removes intermediate commits during dependent view metadata
    updates in CREATE TABLE SELECT. They are not really necessary as even
    for SEs which don't support atomic DDL we can always rollback the
    statement by dropping table created. Such intermediate commits were
    actually causing more trouble than assertion failure above as in RBR
    mode they [1;31mflush[med CREATE TABLE and row events to binary log, thus
    creating discrepancy with potential rollback-by-drop-target-table
    if error occurred after intermediate commit.

[33mcommit c2f61386d4876aa90410829b43964b5f56d98e88[m
Author: Krzysztof Kapuścik <krzysztof.kapuscik@oracle.com>
Date:   Tue Nov 7 12:48:34 2017 +0100

    Bug #27015730 ASSERT IN LOG0LOG.CC: LOG_SYS->FLUSHED_TO_DISK_LSN >= OLDEST_LSN
    
    During the recovery the write_lsn was set to current LSN
    but the [1;31mflush[m positions (current_[1;31mflush[m_lsn and
    [1;31mflush[med_to_disk_lsn) were left unmodified. If nothing was added to
    log before the call to log_checkpoint the assertion was raised.
    
    Because the write_lsn was equal to current lsn the log_write_up_to
    was doing nothing keeping the [1;31mflush[med_to_disk_lsn untouched. But the
    checkpoint code was doing a check that everything up to checkpoint
    lsn was [1;31mflush[med.
    
    The fix sets the [1;31mflush[med position after "recovery" to lsn value
    so last written adn [1;31mflush[med positions are equal.

[33mcommit 2771c9305e7653d4bfbea763ce568ee83266c7af[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Wed Sep 13 13:26:12 2017 +1000

    WL#8619 - Resume IO ops, if [1;31mflush[mes are pending.
    
    Change-Id: I93c84f2e7dfd25f790e264680cd3ef3a163c9185

[33mcommit 52b17d27495c73fea4deedcaf7395e363a1f9252[m
Author: Libing Song <libing.song@oracle.com>
Date:   Fri Sep 1 20:30:49 2017 +0800

    BUG#26666609 SLAVE HANGS - WAITING FOR TABLE METADATA LOCK
    
    ANALYSIS
    ========
    REPAIR/OPTIMIZE/ANALYZE TABLE and
    ALTER TABLE ... REPAIR/OPTIMIZE/ANALYZE PARTITION
    statements maintain the tables one bye one. The metadata lock
    of the table is released immediately after it is maintained. That is
    earlier than the statement is binlogged and committed. That means
    the following statements which updates the same table may be binlogged
    earlier than it. Or they go into the same binlog [1;31mflush[m queue. That
    meant they could be applied on slave parallel. It would cause a
    deadlock if --slave-preserve-commit-order is ON.
    
    For example:
    REPAIR TABLE t1;
    INSERT INTO t1 VALUES(1);
    go into to the same [1;31mflush[m queue. They were binlogged with below information.
    
    REPAIR TABLE t1;
    INSERT INTO t1 VALUES(1);
    
    FIX
    ===
    m_last_blocking_transaction is added to store the sequence_number of the
    transactions which may not safe to parallel with the following transaction.
    The last_committed of the following transactions will be reset to
    m_last_blocking_transaction if their original last_committed is smaller
    than m_last_blocking_transaction.

[33mcommit c8d3b3865c64d91b1c1ec8e10263841ac1a48f39[m
Author: Libing Song <libing.song@oracle.com>
Date:   Fri Sep 1 20:30:49 2017 +0800

    BUG#26666609 SLAVE HANGS - WAITING FOR TABLE METADATA LOCK
    
    ANALYSIS
    ========
    REPAIR/OPTIMIZE/ANALYZE TABLE and
    ALTER TABLE ... REPAIR/OPTIMIZE/ANALYZE PARTITION
    statements maintain the tables one bye one. The metadata lock
    of the table is released immediately after it is maintained. That is
    earlier than the statement is binlogged and committed. That means
    the following statements which updates the same table may be binlogged
    earlier than it. Or they go into the same binlog [1;31mflush[m queue. That
    meant they could be applied on slave parallel. It would cause a
    deadlock if --slave-preserve-commit-order is ON.
    
    For example:
    REPAIR TABLE t1;
    INSERT INTO t1 VALUES(1);
    go into to the same [1;31mflush[m queue. They were binlogged with below information.
    
    REPAIR TABLE t1;
    INSERT INTO t1 VALUES(1);
    
    FIX
    ===
    m_last_blocking_transaction is added to store the sequence_number of the
    transactions which may not safe to parallel with the following transaction.
    The last_committed of the following transactions will be reset to
    m_last_blocking_transaction if their original last_committed is smaller
    than m_last_blocking_transaction.

[33mcommit 8059d529c5f7eeb364d33ca34d8aa1cd6f064cf9[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Fri Sep 1 23:41:41 2017 +1000

    WL#8619 - Need mutex cover when adding to the redo [1;31mflush[m list.

[33mcommit e8c0a6e0569b8721459a1f9577b306ca93918915[m
Author: Mayank Prasad <mayank.prasad@oracle.com>
Date:   Thu Aug 17 18:39:01 2017 +0530

    wl#9193 : Autoscale InnoDB resources based on system resources by default
    
     Details:
            Added a new global bool system variable 'innodb_dedicated_server'
            with default value ON.
            When this variable is set to ON, then innodb_buffer_pool_size and
            innodb_log_file_size are autoscaled based on system memory.
            Also innodb_[1;31mflush[m_method is set to O_DIRECT_NO_FSYNC if supported.
    
            A new component service 'system_variable_source' is also added which
            exposes a method named 'get' which could be used to get the SOURCE of
            a given system variable name.
    
            Reviewed by : thirunarayanan.balathandayuth@oracle.com
                          darshan.m.n@oracle.com
                          venkata.sidagam@oracle.com
            RB : 16832

[33mcommit 671fe624dbf41dfc73ca8f5227659106b2283f83[m
Author: Mayank Prasad <mayank.prasad@oracle.com>
Date:   Thu Jul 27 10:30:33 2017 +0530

    WL#9631 : Change InnoDB IO Defaults - innodb_[1;31mflush[m_neighbors
    
     Changed compiled default value of innodb_[1;31mflush[m_neighbors from
     1 to 0.
    
     Reviewed by : Satya Bodapati <satya.bodapati@oracle.com>
     Reviewed by : Sunny Bains <sunny.bains@oracle.com>
     RB : 16800

[33mcommit 00d33b9f207766bee3cfd0c81fbbd3979fe3b020[m
Author: Jimmy Yang <jimmy.yang@oracle.com>
Date:   Wed Jul 5 11:17:34 2017 +0800

    A follow up fix for [1;31mflush[m log for trx->ddl_operation marked trx

[33mcommit 2e07261cef100a435bd807bc7cf79ff615196e40[m
Author: Jimmy Yang <jimmy.yang@oracle.com>
Date:   Tue Jul 4 14:45:42 2017 +0800

    For DDL LOG operations, we need to set trx->ddl_operation so the log
    is [1;31mflush[med

[33mcommit 8ef232d9fb7b4357c81d22a422a8e06830133fc0[m
Author: Jimmy Yang <jimmy.yang@oracle.com>
Date:   Mon Jul 3 19:40:10 2017 +0800

    Fix Bug#26381301 INNODB: TABLESPACE ID IS .* IN THE DATA DICTIONARY
    BUT IN FILE .* IT IS .*ASSERT
    
    The DDL LOG redo log entry is not [1;31mflush[med due to
    innodb_[1;31mflush[m_log_at_trx_commit set to 0; For DDL operations, we need to
    [1;31mflush[m the log, no matter what the setting is

[33mcommit 68675a0e4d5148e11ad23df1d8aec16a8fadfc04[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Wed Apr 19 14:09:09 2017 +0200

    WL#8069: Delay the sync_lsn by about 2 GCPs, this requires a double write of the LCP control file in many cases where the LSN haven't been [1;31mflush[med to disk while we scanned the fragment. It does have the advantage that we don't waste a lot of UNDO log space for each fragment LCP, this only applies to fragments with disk data columns

[33mcommit cc6b9fa428fd539a39b03adb6e8cb762f2f95dac[m
Author: Darshan M N <darshan.m.n@oracle.com>
Date:   Thu Jun 1 10:49:22 2017 +0530

    Bug#24658707 ASSERT: BUF0BUF.CC:2469:BUF_BLOCK_GET_STATE(BLOCK)
    == BUF_BLOCK_FILE_PAGE
    
    Issue
    =====
    The issue is that during commit_inplace_alter_table we wake up the purge
    thread and we take a btr search latch and try to disable the adaptive hash
    search system and empty the index. The purge operation happening in the
    background, when [1;31mflush[ming the pages, tries to remove possible adaptive hash
    index on the page and it sets the the block state as BUF_BLOCK_REMOVE_HASH
    and waits on the btr search latch taken by the alter command. And in the
    alter command when we're trying to empty the hash index of the same block
    we hit the assertion ut_ad(buf_block_get_state(block) ==
    BUF_BLOCK_FILE_PAGE) as the block state was changed by the purge operation.
    Both the threads would be working on the same block at the time of
    assertion.
    
    Fix
    ===
    The fix has already been pushed to trunk as part of meta-sync branch.
    Readding the assert which was removed earlier to silence the pb2 failures
    which was because of this bug.
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit fa3880ae35bcc593d40e2f30c8d074748162984e[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Tue May 16 12:58:54 2017 +0200

    WL#10441: Add mysqld_safe-functionality to server
    
    - Find the the absolute path of the executable and make argv[0] point to it
    
    - Deduce mysql_home (aka basedir) from the executable path
    
    - Let mysqld::runtime::mysqld_daemonize() return (rather than call
      exit directly) on the parent side, and call
      [1;31mflush[m_error_log_messages() to get all messages from the daemonize
      process properly formatted. Move the call to mysqld_daemonize() to a
      point where paths have been resolved agains CWD so that a daemon
      process treats relative paths in the same way as a regular server.
    
    - Print the name of the chosen error log file before opening and redirecting
      stderr so that users can see where the daemon will try to log messages.
    
    - Fix a bug in open_error_log() which assumed the log file could be used if stat
      showed it to be writable for user (that will be true even if it is not owned
      by the current uid). When calling my_freopen() on such a file the stderr
      FILE pointer becomes invalid, and this causing messages to be lost.
    
    - New mtr test main.basedir.

[33mcommit d49b5240b8f8d9db89f976c308ca14c6084eed3d[m
Author: Dhruthi K V <dhruthi.k.v@oracle.com>
Date:   Mon May 29 18:40:52 2017 +0530

    WL#10478 Defaults: Enable Binary Log Expiration
    
    Rationale
    ----------------
    By default we should place some reasonable limit on the lifespan of binary logs.
    30 days is a fairly safe minimum limit (removal happens at startup and when the
    binary log is [1;31mflush[med). This will help to prevent excessive amounts of disk
    space being wasted on binary logs that are no longer needed for replication or
    recovery purposes.
    
    Server Changes:
    ----------------
    expire_logs_days = 30 : This causes mysqld to periodically purge unused binary
    logs that are older than 30 days

[33mcommit 343ebfda66b8d5bc8c681dced86e47389cee10f8[m
Author: Neha Kumari <neha.n.kumari@oracle.com>
Date:   Sat May 27 15:54:54 2017 +0530

    Bug#25973525:INCORRECT WARNING IS LOGGED ON"FLUSH LOGS"WHEN BINARY-LOG IS IN USE AND ELD!=0
    
    Problem:
    With current behaviour if expire_logs_days/binlog_expire_log_seconds(on mysql-trunk)
    is set, following warning will be logged whenever the user issues
    "FLUSH LOGS"/"PURGE LOGS BEFORE" and binlog file is in use, though the file is
    not old enough to get purged.
    Eg:
    2017-04-27T09:42:10.202909Z 10 [Warning] file ./master-bin.000001 was not purged
    because it was being readby thread number 12
    
    The warning is incorrect since it gives a notion to the user that system tried
    to purge the log-file even when it was not old enough to get purged.
    
    Analysis:
    The root cause is that we check if a log is being used by other thread firstly
    while purging it.
    
    Fix:
    To fix the problem, we check if a log older than the purge time firstly, then
    check if it is being used by other thread while purging it. This will ensure
    that the above warning is gone.
    
    The changes in test rpl_4threads_deadlock was done because it started failing
    after the changes done in binlog.cc. The reason for failure is explained below.
    
    The sync point 'purge_logs_after_lock_index_before_thread_count' is set in the
    method which checks if the log is in use, after the changes done in binlog.cc
    this check(if the log is in use) will be done after purge_time check. The
    purge_time in test was set as 9999-12-12 which was effectively being converted
    to 0(Bug#26147576) and thus the sync point will never be reached.
    To fix this the purge_time is modified to 2038-01-19(highest permissible value).
    
    Additional changes done in rpl_4threads_deadlock
    - We need to have the FLUSH LOGS command inside the while loop so that we have
      binary logs to [1;31mflush[m in second iteration as well, as the PURGE LOGS command
      will purge all but the current binary log file.

[33mcommit 2382d829c1298e3dfa1683e251a3ce5c8d0155e2[m
Author: Deepthi ES <deepthi.e.s@oracle.com>
Date:   Thu May 25 13:26:17 2017 +0530

    Bug#24694453 RPL TESTS FAILING WITH MTS (ANY) AND RELAY_LOG_INFO_REPOSITORY=TABLE
    
    At running rpl.rpl_stm_000001 in MTS with relay-log-info-repository=TABLE the
    test could not sync the slave with the master.
    More specifically after the slave restart :
    
      SET GLOBAL SQL_SLAVE_SKIP_COUNTER=1;
      source include/start_slave.inc;
    
    always resumes the slave with the very error-code query that is intended to
    be skipped. The wrong skip is turned out to be caused by MTS recovery that
    does not see
    
      l.110: drop table t2
    as executed in mysql.slave_worker_info though it must've been applied.
    The missed mysql.slave_worker_info update is found to be caused by
    "lazy" [1;31mflush[m_info() which is called with force == false in MTS
    non-transactional commit branch (Slave_worker::slave_worker_ends_group).
    
    FIXED with turning the force parameter of
    commit_positions(Log_event *evt, Slave_job_group *ptr_g, bool force)
    from false to true.

[33mcommit 77c7d1e43de3ef25e50d18a1b0a6ae52d5fe65d6[m
Author: Deepthi ES <deepthi.e.s@oracle.com>
Date:   Tue May 23 14:39:55 2017 +0530

    Bug#26005418 RPL_SIMULATE_CREATE_CHUNK_FAILURE FAILS IN MTS MODE WITH RLI=TABLE
    
    The synopsis line test failed and its reason turns out to be a persistent error
    at START-SLAVE (l.66: --source include/start_slave.inc).
    The error log actually shows:
    
    [ERROR] Error looking for file after ./slave-relay-bin.000003
    
    The error analysis showed that
    
    SELECT Master_log_name FROM mysql.slave_relay_log_info == ""  => true
    
    The empty Master_log_name obviously can't match to a non-empty data from
    the Worker info table which dooms MTS recovery.
    
    The reason for the empty Master_log_name is that Rotate event applier
    never cared to call Rpl_info_table::[1;31mflush[m_info(force == true). The
    argument value is propagated as false from
    Relay_log_info::inc_group_relay_log_pos().
    Because of that  Rpl_info_table::[1;31mflush[m_info(force == false) returns early
    to put the updated last executed coordinates at risk of getting lost
    which the test demonstrates.
    
    Fixed with making Rpl_info_table::[1;31mflush[m_info(force == true) in the
    Rotate event case.  The parameter value is set to true by
    Rotate_log_event::do_update_pos() and propagated from there through
    Relay_log_info::inc_group_relay_log_pos()'s extended signature with an
    bool argument.

[33mcommit 29761426092215a9be275607828b85560e463007[m
Author: Satya Bodapati <satya.bodapati@oracle.com>
Date:   Tue May 16 11:47:22 2017 +0200

    Bug#25804386 - DUPLICATE VALUE FOR AUTOINC COLUMN
    
    Background:
    ----------
    On checkpoint, the DDTableBuffer in-memory contents are written to the
    physical DDBuffer Table.
    
    During checkpoint, the redo generated by these DDTableBuffer writes
    are written to disk.
    
    Before WL#9499:
    --------------
    The fil_name_parse() which writes MLOG_FIL_NAMEs made sure that the
    redo generated by DDBuffer Table writes are also [1;31mflush[med to disk
    
    So this is not so obvious dependency on fil_names_clear().
    
    After WL#9499:
    --------------
    Since MLOG_FILE_NAME is removed, there is no need to write MLOG_FILE_NAMEs
    as part of checkpoint. So fil_names_clear() is removed.
    
    This exposed the above explained dependency of DDTableBuffer writes
    on fil_names_clear(). Since the redo-writes of DDTableBuffer didn't
    make to disk on checkpoint, after a crash, a duplicate auto-inc value
    is possible and hence this bug.
    
    Fix:
    ----
    1. Change return type of dict_persist_to_dd_table_buffer() to determine if a possible
       write to DDTableBuffer happenned.
    
    2. Flush the redo upto a lsn which includes DDTableBuffer changes.
    
    Reviewed-By: Debarun Banerjee <debarun.banerjee@oracle.com>
    Reviewed-By: Bin Su <bin.x.su@oracle.com>
    RB: 16071

[33mcommit 87d5375b4dc7231352a9dcf10a2bc030c5ffbe08[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Apr 6 08:54:06 2017 +0200

    Bug#25750355 SEND SPJ RESULTS AS 'PACKED' TRANSID_AI WHERE APPLICABLE
    
    Patch enable the usage of 'short' or 'packed short' TRANSID_AI
    signals for sending SPJ results back to the client-API.
    This is a more efficient way to send short TRANSID_AI signals.
    
    It refactors out code for sending TRANSID_AI to the API from
    Dbtup::sendReadAttrinfo() into the new method Dbtup::sendAPI_TRANSID_AI().
    This method is then called from Dbtup::[1;31mflush[m_read_buffer() which is where
    the SPJ results are delivered to the client_API.
    
    Also introduce some cleanup of usage of the magic litterals
    '3' and '22' where 'AttrInfo::HeaderLength' and 'TransIdAI::DataLength'
    should be used instead.
    
    Refactor how the buffering work is divided between
    Dbtup::bufferTRANSID_AI() and the new Dbtup::sendAPI_TRANSID_AI().
    (Related to how the sending of full packed-buffers are handled).

[33mcommit adfc17e3ad68de74f6555c3f43db7f5f9775dece[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Mon Apr 3 11:29:40 2017 +0530

    Bug #24748843 : SYNC PRINTS TO STDOUT CAUSING MAIN THREAD TO SLEEP DURING HIGH IO WAIT
    
    Re-enable asynchronous logging.
    Flush user-space buffered data using f[1;31mflush[m() after every write in the async log thread.

[33mcommit be9ee6d7ac3bb243762cf20e7550d5569e915a94[m
Author: John David Duncan <john.duncan@oracle.com>
Date:   Fri Mar 24 13:37:37 2017 -0700

    wl#9819 bugfix: Use safe_no[1;31mflush[m_sendSignal() from ClusterMgr.
    This adds new safe_sendSignal() methods that take a LinearSectionPtr[].

[33mcommit f4c10f62e6c3362ee95a3fdcd9d4756addedc07d[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Thu Mar 30 16:15:16 2017 +0530

    Bug #24748843: SYNC PRINTS TO STDOUT CAUSING MAIN THREAD TO SLEEP DURING HIGH IO WAIT
    
    Disable async log until the [1;31mflush[ming problems are solved for crashes.

[33mcommit 1183774da0c64e0ea1e83a8a5e984acd6a0676d5[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Mar 28 08:56:30 2017 +0200

    Bug#25792323 MTR TEST BINLOG_CHECK_FLUSH_LOG_ASSERTION GENERATES CORE FILE
    
    mtr test binlog_check_[1;31mflush[m_log_assertion does an abort() which will generate
    core on unix, "would you like to debug" popup on windows.
    
    Fix: Use DBUG_SUICIDE when abort() is expected by the test.

[33mcommit d58a244612ecd404603a93a277ab1e8ba3f53cf4[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Fri Mar 10 14:40:38 2017 +0100

    Bug#25702297 & Bug#22732184
    
    Disable
    
       rpl.rpl_multi_source_filter
       rpl.rpl_filters_check_counter
    
    in UBSAN and
    
       binlog.binlog_check_[1;31mflush[m_log_assertion
    
    in ASAN on PushBuild.
    
    Approved by Jon Olav Hauglid <jon.hauglid@oracle.com> over IM.

[33mcommit 201b2b20d110bc35ddf699754571cb0c064a3f72[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Fri Mar 3 12:40:55 2017 +1100

    Squashed commit of the following:
    
    WL#9499 - InnoDB: Replace MLOG_FILE_NAME with MLOG_FILE_OPEN
    
    Fix the performance issues introduced by WL#7142 and its followup WL#7806.
    
    1. Revert WL#7142 and WL#7806 changes, keep some of the tests to test
       the behaviour that was introduced by the two WLs
    2. Change the tests that rely on the above two WLs behaviour
    3. Use std::unordered_map instead of the homebrew hash table for the recovery
       code and space ID to name mapping
    4. Split the redo log hash table key from <space, page> -> apply records to
       <space> -> apply records
    5. Addition of two new system files (tablespaces.open.1 and tablespaces.open.2)
    
       - Rename MLOG_FILE_NAME to MLOG_FILE_OPEN
       - Remove the two pass recovery code, make it a single pass
       - Track file open, close and rename
       - Write and fsync the tracking state to disk on checkpoint and rename.
       Uses the files in #5 in a round robin fashion
    
    Introduce --innodb-scan-directories="path1;...pathN". Scan the paths for
    .ibd files to open during recovery. This option can be used if the files in #5
    above are corrupt or missing. You should not use this if you move files around.
    While they can be recovered the data dictionary will not be updated and it
    will cause issues during runtimg.
    
    rb#13686 Approved by Satya and Shaohua
    
    commit af3dc1301a768c01b971d14ad07549d6ef470fe6
    Merge: ac37b926e6a 4d81939d63a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Mar 3 11:16:10 2017 +1100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit ac37b926e6ad85b6c4e3d7880b905d082f1674be
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 23:12:24 2017 +1100
    
        WL#9499 - Fix test
    
    commit 2b05df7ffa592da9b19cec7ba31c04795a1cdfc0
    Merge: 3c79f3aee51 71b3bbff153
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 20:34:10 2017 +1100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 3c79f3aee51858b1859f4e8711883a85867c417a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 18:16:35 2017 +1100
    
        WL#9499 - Add an mtr tst
    
    commit 2c7496246c0e95e25c62ceb6fe5c1875f693ffac
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 17:34:50 2017 +1100
    
        WL#9499 Fix bugs
    
        1. Fix a memory leak, call mem_heap_free() instead of mem_heap_empty()
        2. Use a reference instead of copy by value during dblwr traversing
        3. Use absolute path names for tablespace.open.* files
    
    commit fbf87161f3c93979e5abe424fbe0678fdc32159e
    Merge: 517cf3a7bf0 c2b504664ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:39:32 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 517cf3a7bf0490c3168fed020e3096ec500e0a85
    Merge: 4786f93ad8a 5e974fd0ea4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:24:25 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Additional change is to call recv_recovery_from_checkpoint_finish() on abort.
        Instead of recv_sys_free().
    
    commit 4786f93ad8a25506a2a1f6e9d1207256a34b3665
    Merge: 5dc35e05b5f 275245cce32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:43:27 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 5dc35e05b5f2da95c36e191350e9c7087be72194
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:42:40 2017 +0100
    
        WL#9499 Free recv resources on abort
    
    commit bed693070395923ededba736f1c7102b8eb21e95
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 18:34:50 2017 +0100
    
        WL#9499 - Test cannot be run with Valgrind
    
    commit c5d423228ddf58b17866ff8be289dba4a19205d2
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:30:39 2017 +0100
    
        WL#9499 - Remove const
    
    commit ac42498506b4dffb22e74282d0ce037fe3acf977
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:00:30 2017 +0100
    
        WL#9499 - Clean up code
    
    commit bc48077cab9c3ccb1b2797c365fe0940c269a785
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 16:01:09 2017 +0100
    
        WL#9499 - Revert unrelated change
    
    commit 8b2bb0f6d6254b3cfde168d41356400009db12f4
    Merge: eb9b294ba78 153a79ff35d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:43:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit eb9b294ba786800f9e397cd87f01c4f4976edddb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:29:56 2017 +0100
    
        WL#9499 - Remove debug message
    
    commit abae66ad591854ee67a5013f3209be2f82e4d9bf
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 17:04:10 2017 +0100
    
        WL#9499 - Test only works in debug mode.
    
    commit 71ebea70391ef295bed49ee06a8b872f15ecfe97
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:18:08 2017 +0100
    
        WL#9499 - Update to mtr test from Matthias
    
    commit f108a5b92fc476c70c49e4937496b32d9d5d031f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:13:04 2017 +0100
    
        WL#9499 - Increment redo log version number
    
    commit 4439c83a4d3edd6e511706ccf9936770ed29e593
    Merge: fa459186b90 05923bef41d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 09:54:18 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit fa459186b90d7a5ddcba7e3c6c7a9871d0dce793
    Merge: 14ac4f81d84 b401f17e70d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 20:02:40 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 14ac4f81d84bec23a7be210504ca0be93619bf11
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 16:44:57 2017 +0100
    
        WL#9499 - Update from Matthias
    
    commit ed3191a9fc951151fd7d758a527e7ab81530b3f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:16:11 2017 +0100
    
        WL#9499 - Revert change pushed by nmistake
    
    commit 8c0edb998867bf557f6c86410552d6d123892000
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:11:21 2017 +0100
    
        WL#9499 - Don't redo log MLOG_FILE_OPEN until startup is complete
    
    commit 3b503ea1d3f89c0f7e3677d3b56f249c7ebff506
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:37:04 2017 +0100
    
        WL#9499 - Add tests
    
    commit 47af7bd6eec10eac55633d7c4cf54afe607f3649
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:00:30 2017 +0100
    
        WL#9499 - Fix compile problem
    
    commit a8b9a8c6ccb15e2be5ce5db5fa0bce24b86d2c87
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:51:05 2017 +0100
    
        WL#9499 Remove dead code
    
    commit b1dba474486ad10b61029b2ef4e6a91ea67dcea8
    Merge: 3cf9e9eb3e8 a4271026201
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:49:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 3cf9e9eb3e86e4c8f4d44cb79d3f7c456ea7d671
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 18 07:53:43 2017 +0530
    
        WL#9499 - Remove suggestion to use force recovery
    
        --innodb-scan-directories is a safer option for the user. Force recovery should
        be the absolute last resort.
    
    commit 4104c4bfd606270650aac95a9a724e106fe835c5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 09:00:47 2017 +0530
    
        WL#9499 - Fix error message
    
        User can try --innodb-scan-directories="..." if the tablespaces.open.* files
        are corrupt or unreadable.
    
    commit 19ab12e54923b070a0b4ffc76b9fe97ac54ad3cc
    Merge: 50b3a95e446 f0f51c410bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 05:22:57 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Replace readdir_r() with readdir(), compiler complains that readdir_r() is
        deprecated and recommends replacing it with readdir().
    
    commit 50b3a95e446b91853fc35716b63bdc173221d01f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:55:33 2017 +0530
    
        WL#9499 - Fix test
    
    commit 45d202ae0fa35aa3aced55cc1933aeefa33837de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:32:56 2017 +0530
    
        WL#9499 - Remove redundant test
    
    commit 48fe691b97735e5144e9d439a0adbf721b2dc554
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:18:11 2017 +0530
    
        WL#9499 - Add DEBUG sync points
    
    commit d986f4e04a9eb6c2c76d61cd4afe9541d77b34bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:03:50 2017 +0530
    
        WL#9499 - Remove PB2 control file
    
    commit 5af7dca9c305bd366ad2b5c3de26a870e913af4a
    Merge: 74022f50a5f 23a0e71aa3d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 15 09:05:05 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 74022f50a5ff7cb2801c0712601f8a467b409a28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 14 10:31:00 2017 +0530
    
        WL#9499 - Fix test
    
    commit f6188175ee62040ac6a844a5c54787839dff6155
    Merge: 24c867aab14 19ca7c6a5d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 13 12:37:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 24c867aab14556188503aac495f60d89ba3d26ec
    Merge: cb64b8c7f9f a4de6ab549e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 4 06:41:23 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cb64b8c7f9fa9ca05033a9d6f6193cf141746310
    Merge: 17c6c41da0a 88dbc4f4511
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:48:12 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 17c6c41da0afe3fc78843b75fa02578dab29a0ca
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:46:34 2017 +0530
    
        WL#9499 - Add a test for scan directories.
    
        The use case is where the location of the files is not changed but the
        tablespaces.open.* files are missing.
    
    commit 79cc52f1bd82dc65932eacbc9aa14a47e4196572
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 18:01:50 2017 +0530
    
        WL#9499 - If open fails space will be null.
    
    commit 22ea5f31ecc1fa0db8abd57d4a46578e5f891c9a
    Merge: f5b69930f95 853a52cf5a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 12:14:41 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f5b69930f95192ddfdb3ca170024a5c7e3416076
    Merge: 40a4c32f2c4 b18872ed4a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 2 13:54:24 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 40a4c32f2c42b584539a14cbc1ba0d4f0fe7d3c9
    Merge: b1d1923d37c d071c0e7a0b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 1 13:48:33 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit b1d1923d37c3d23a9f701a61b458b7e4cbd3c90c
    Merge: 2fc6c51edab 4ae71705a01
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 31 10:44:59 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2fc6c51edabc3de4537eceb0b82cd62063ada3a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 16:36:46 2017 +0530
    
        WL#9499 - Empty the tablespace.open.* files on normal shutdown.
    
    commit 738acb7d554f97455c8dba512282c7c2e6ba9f3a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:47:21 2017 +0530
    
        WL#9499 - Fix formatting
    
    commit 28f8579a6f729af354e0c50098d16fbfa17cc253
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:25:30 2017 +0530
    
        WL#9499 - Bug fix
    
        The DELETED state was set on a copy of the data structure
    
    commit dd5bf8ea81b7023fa1980c01d89219a690160b04
    Merge: 7eeab0a994d 9c7808e1054
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 21:14:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7eeab0a994db4cf0c2e080f27ff916c778ec65f8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:50:59 2017 +0530
    
        WL#9499 - Add tests.
    
    commit ddfaf047f43587ee807599b0b80b6d01a3579e8c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:48:06 2017 +0530
    
        WL#9499 - Create tablespace bug fix
    
        If there is a checkpoint after the create tablespace is logged and the
        server crashes after writing the page initialization to the redo log. Then
        we neither have the mapping in the redo log nor in the tablespace.open.*
        files. We must update the tablespace mapping before writing the CREATE
        redo log entry so that the state is written out to disk on checkpoint.
    
    commit 29546d3ebea2991e5b86b33edddb551c924bf1db
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 17:55:28 2017 +0530
    
        WL#9499 - Remove dead code from WL#7142
    
    commit eced7a3e4437ee4bb24a12290f561437ddb15611
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 14:51:09 2017 +0530
    
        WL#9499 - Use the tablespace.open.* files in a round robin fashion.
    
    commit d8eff788eea1ad5e6c7786b9d64963524f2b2c81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:56:12 2017 +0530
    
        WL#9499 - Fix duplicate entry
    
    commit 1d04e0cf0308c35ee7498e6919eab9a11c699d52
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:55:30 2017 +0530
    
        WL#9499 - Revert last push
    
    commit 8361d3c39366d6435a895d5b64dd23615d26fc28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Jan 26 09:05:52 2017 +0530
    
        WL#9499 - Write to the tablespace.open.* files in a round robin manner.
    
    commit 3eaba629ee5b5c26a5f4e80852fee2d446f3013f
    Merge: 6642c43d735 bdc49070128
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 25 14:03:15 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6642c43d7353063a455972ab2cbc21220c16be43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 08:34:35 2017 +0530
    
        WL#9499 - Rename fil_ibd_load to fil_ibd_open_for_recovery.
    
    commit fdd1897c79b29c9e0a69c1f81d94927da06d9424
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:28:49 2017 +0530
    
        WL#9499 - Enforce const semantics on Windows for Folder::exists().
    
    commit 9394f4653e10cc5d4ab9b7b0a0b9331fd2666f49
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:08:26 2017 +0530
    
        WL#9499 - Include <array>
    
    commit c1903d28800ae0f7af69552aa669622d552346b4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Jan 21 07:49:28 2017 +0530
    
        WL#9499 - Improve scan directory handling
    
        1. Convert relative paths to absolute paths
        2. Filter out duplicates
        3. Check directories at filtering stage
    
    commit dfea237f4bef914de4067153cbf382240112c4f4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 11:11:05 2017 +0530
    
        WL#9499 - Code clean up
    
    commit c4d51bfdf1c786b1c584c0af1bde080a4f37cc5b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 07:37:06 2017 +0530
    
        WL#9499 - Update the open/rename LSN when a file is opened or renamed.
    
        Minor code cleanup.
        Add diagnostic code for debugging.
    
    commit 5e1d159b571fe6dbfe13c627a245155b82c4bbfa
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 18 10:59:54 2017 +0530
    
        WL#9499 - Filter out '*' from innodb-scan-directories
    
    commit 361f2944f1940f11dfb16dec3589d68335f5e2d8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 21:01:06 2017 +0530
    
        WL#9499 - Code cleanup
    
    commit 288d70b356721887423ca3d2d72b42da331216cd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 13:08:08 2017 +0530
    
        WL#9499 - Sync open file map to disk before checkpoint.
    
    commit 3c602d1b4089cd262200650f4b33986fc9e26531
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:18:46 2017 +0530
    
        WL#9499 - Print expected bytes instead of generic message.
    
    commit f52e0985b8cbef3891385179d35dc8c7f567146a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:07:47 2017 +0530
    
        WL#9499 - Print file size instead of generic message.
    
    commit b27b1b4b4b70e286e2c669f997b0a669f6d6034c
    Merge: bbdd1c46f1e c101ec9b557
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 16 13:19:42 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit bbdd1c46f1ef08d956ea249e1f6f4bc93d3464f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Dec 10 14:41:12 2016 +0530
    
        WL#9499 - Handle the case where the rename has already been done on recovery.
    
    commit 141bdb02b1a402e786db5d8b165b781a5d7370a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 11:59:29 2016 +0530
    
        WL#9499 - Instrumentation for debugging
    
    commit 34815bb24a1c296d9739e7602dc6ccd53c58c44c
    Merge: 41ca3732a6f 13a46b4c5ea
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 09:44:03 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 41ca3732a6ffd8dfa16762a05df6b5c6b4b550c1
    Merge: 7137edb2d2c aba34f1205d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 11:10:08 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7137edb2d2ca60cdec44600ddf3f5cbde424e7a4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 05:56:06 2016 +0530
    
        WL#9499 - Remove unused code. Move id to name mapping sync before log [1;31mflush[m.
    
    commit 2a50067e2da2f7819781de6550e55ca14995c7ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:57:41 2016 +0530
    
        WL#9499 - Initialize the PFS file handle
    
    commit d478d3492cdb40ec02fda9c043bf29b87bae11ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:05:52 2016 +0530
    
        WL#9499 - Fix whitespace
    
    commit 061af748a5e2fde6c1577ccdabfc8a89a9f753de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:02:25 2016 +0530
    
        WL#9499 - Set must [1;31mflush[m on file close/delete.
    
    commit ad76e2b9c7ff757f60c66821e86696d5ab757b18
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 11:43:00 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5a95946d4567dc13cf5a12d6bcdb28b19a02b5bc
    Merge: 1a0f373eb7f da23d6b8e44
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 09:27:45 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1a0f373eb7f03dc22264f91f3f6ed1fd13825de7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 13:01:41 2016 +0530
    
        WL#9499 - Readd test result file back
    
    commit 00afde093183cf850f735940245af111dce82b72
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 12:59:49 2016 +0530
    
        WL#9499 - Don't purge the files based on LWM. It won't work.
    
        We need to also ensure that there aren't any pages in the buffer pool that
        belong to a tablespace that is closed. Redo log records can be written for
        such pages.
    
    commit 3199fe255103daa42f0332b7ff9d565eefff7429
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:41:39 2016 +0530
    
        WL#9499 - Fix typo
    
    commit 351cb6c42709405a79021276f310d7b996aadd1b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:32:02 2016 +0530
    
        WL#9499 - Remove unused function
    
    commit 61cc7f6b06c5280d58217b76d7627013ddcd8338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:22:31 2016 +0530
    
        WL#9499 - Reduce the compression level.
    
    commit 48142e360ff5cfb53d5e416f3d6b92e956237923
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:21:51 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 4de4f8b31ebdff31a2f7a97a1ad211770d20cdd6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 14:07:07 2016 +0530
    
        WL#9499 - Revert ef30f0754ab22e614ac22712c348ec5f53e0f09c
    
    commit c2f77f44c43c209fad86bba568aa521a2dcbf718
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 12:20:37 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 5fccb51769a13cb9a1fc0f29a832d3b0085ad52a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:30:18 2016 +0530
    
        WL#9499 - Print a message when checkpoint is disabled.
    
    commit ef30f0754ab22e614ac22712c348ec5f53e0f09c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:17:27 2016 +0530
    
        WL#9499 - Print progress in 10% units.
    
    commit bc0ded332624fa2c8a08ebfc955a03f1a24e069c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 08:13:54 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 68ce0208cc073452f5f791faf304971dbac7194a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:38:03 2016 +0530
    
        WL#9499 - Scan directories after the mutex code is initialized.
    
    commit 21e07c8fd6b8eddf158fb79980443f6c9f6d238e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:12:23 2016 +0530
    
        WL#9499 - Introduce --innodb-checkpoint-disabled (debug)
    
        Disable checkpointing if the variable is set. This is to force recovery if the
        server is killed during a test.
    
    commit 7033c9bb5ff7641764f70823a73d747b497a0eed
    Merge: 11a6e582417 c6af7f512b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 04:00:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 11a6e582417d45a80a7f19233c2d2191a17936eb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 03:59:05 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 0a38252e65d607b59b1e9f64d0c8003cdecfecfd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 25 05:56:42 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bcf650cc92b8636f3768dcc3deb33b90b2942134
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 08:46:07 2016 +0530
    
        WL#9499 - Change the open files number back to 2.
    
    commit 99960af2825529fb45d021a34ba6c072e8caa0dc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 07:13:58 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bdb91bc0ba03e01661c50c7175d3fd123d2bcd69
    Merge: 61f3e4a5663 a545bdd6e31
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:04:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 61f3e4a5663c375cd44ee766b263281ff7f0601b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:00:20 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 072ab837d0acb4d2ed817110598554acc44ec344
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 12:06:53 2016 +0530
    
        WL#9499 - Set the IMPORT page LSN to the [1;31mflush[med to disk LSN
    
    commit 7f18661432f3645eb9ce76680c62508ced115fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 11:28:47 2016 +0530
    
        WL#9499 - Force a checkpoint before the crash
    
    commit 83671e9c37fa61adfa5546cabe1463a91ff02241
    Merge: cc26d5ae16e d1f811eb6e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 10:52:16 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cc26d5ae16e8d723a2519f38bfbc084c13a766c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 18:40:51 2016 +0530
    
        WL#9499 - Fix latch ordering issue
    
        Cannot hold the log sys mutex when updating the checkpoint LSN for the open
        files in fil0fil.cc.
    
    commit 4474509addfbdf91b9f0ad890a971299c594e738
    Merge: 396755e195c 0856b10cde5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 08:00:05 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 396755e195c1c8d3b2485a58175dcf56ca2cbf3f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:58:05 2016 +0530
    
        WL#9499 - Remove newline added earlier
    
    commit ab5e60ba491e52f1529c22551a936d771b8b5ef9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:57:21 2016 +0530
    
        WL#9499 - Revert a change that was added by mistake.
    
    commit 38688417713e5ef8cbb65032fa0a547ab0c25c15
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 20:44:50 2016 +0530
    
        WL#9499 - Bug fix, using an invalidated iterator.
    
    commit 4082d44f6dc4a5605562e37ccad9ac4db69344c6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 11:30:49 2016 +0530
    
        WL#9499 - Fix doxygen comment
    
    commit d5ca99e14c010a5349aea6c8cc39493b2073b9c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 15:30:12 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a25f3af10ea2893c634dc961d6f2af05efa103ec
    Merge: c8c2a7eba4c aa039b73223
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:52:51 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit c8c2a7eba4cac29ff431588daf2d6def0c0ee5a6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:39:32 2016 +0530
    
        WL#9499 - Fix problem with open files acrosss checkpoints.
    
        The problem is that we write the open file state before writing the checkpoint.
        Before this change the closed files were purged from the open state map and
        the state written to disk. The problem is that the state and mapping of a file
        opened before the last checkpoint but closed just before we write the state
        will not be in the mapping on disk. One solution is to check older files and
        retrieve the mapping from there. The solution chosen is to avoid purging
        files based on open LSN. If the file was opened before the last checkpoint
        and closed within the current checkpoint we note the state as CLOSED but
        write the mapping to disk. It will be purged at the next checkpoint, if it is
        not opened again in the meantime.
    
        Previously an attempt was made to open all files straight after reading the
        mapping from disk. With this change only the state is loaded into memory the
        files are opened on demand. Added a check to verify that the tablespace ID
        from the first page matches the expected value.
    
        Fixed tests to use this new tablespace ID verification.
    
    commit 5dc929e54b1c259f0f8104739ae1f88e9b860f73
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 12:24:40 2016 +0530
    
        WL#9499 - Remove unused code
    
    commit 528b95d70dcc05a69a98ee2a76fdfb8dae1e82fe
    Merge: d9861c40964 75f05cba753
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:14:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d9861c40964ad8fd45ee2cbbd9d94946110e8a9a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 3007ea5af68f40b85bc93098d8385ac96bcbd660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 9592996d2f17c9005262faa75dc1ade9dedbd511
    Merge: da512d5591b ac925fc91f6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Oct 19 10:34:48 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit da512d5591b3379b793d6155089e90791fe94c61
    Merge: f42e2ddd7d5 e635dfe28c0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 30 05:20:10 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f42e2ddd7d50aacae679babe71643af379b5c492
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 15:05:28 2016 +0530
    
        WL#9499 - Fix assertion, the values can be ORred.
    
    commit 94cd08960bc3801acefd4b4ff4ddb4a3e7d7e81a
    Merge: 32a68f91330 59af373321b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 11:05:21 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 32a68f9133011871bfdaba3c742f6239e0a53061
    Merge: 7857f38ebce 15555ae2165
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 21 11:23:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7857f38ebce747135e055bc8a232b649f1aad351
    Merge: 427491f63f1 b43bf88cf80
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 19 11:43:17 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 427491f63f107247c36796e66f6224d20968f104
    Merge: e7fa4c53dcf 23343687722
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 14 22:40:47 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e7fa4c53dcf01ea0e101bd8aa817698492995034
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 19:22:00 2016 +0530
    
        WL#9499 - max_lsn should work with any number of tablespace open files.
    
    commit 09775960da43d36ca64504c1298b9adff3056575
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 17:47:29 2016 +0530
    
        WL#9499 - Fix Names hash bug.
    
    commit 8430c5b34d23cb1774597707fe583dfac93fb3a8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 09:49:47 2016 +0530
    
        WL#9499 - Use std::unordered_map for name to fil_space_t* hash.
    
    commit 5e8275caf9d50dc9ba2f2dadd3b8c0fdeb9c79b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Sep 10 07:55:42 2016 +0530
    
        WL#9499 - Reduce an extra fil_sys_t::mutex call by consolidating [1;31mflush[m request.
    
    commit b29fd1039cf0022cff36a2a2311f464f1f6dbcc5
    Merge: 6235ee4902a a150caebee6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 9 20:44:56 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6235ee4902addd1a041b33469988bb1ea870dc7a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 10:58:00 2016 +0530
    
        WL#9499 - Add debug crash points.
    
    commit bf71fbc72b3570f55c8f01dd1a440e9eff761cb6
    Merge: ce6d2246a94 d25f38e38d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 09:47:37 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit ce6d2246a94801041da0bfece74b5ffdd9e8f796
    Merge: 69adae163de f28c4b9a41e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 7 11:20:50 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 69adae163de295ef0e910752cf5f8c96b1c1114f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:33:29 2016 +0530
    
        WL#9499 - Ensure that the MLOG_FILE_OPEN is always written first to the redo
    
    commit 20d5b1ebe6c899e2a0a1d135ad4303490516ce26
    Merge: 2d7d25c145f 4f1fb936211
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:17:58 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2d7d25c145fae59af744e91fce47fe009c869dad
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 10:06:56 2016 +0530
    
        WL#9499 - Add PFS instrumentation for the tablespace open file.
    
    commit 4e14a53ad129c1adcb0a3330931878a9f24c15cc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:53:57 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a465361e74136662471d2b9c0f307799efbe7269
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:17:43 2016 +0530
    
        WL#9499 - Move the file write code to a separate method.
    
    commit 7a26ba28bf7bf94808c47cfcdb6210c4abde2587
    Merge: f49914e5e61 ed389829067
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 07:55:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f49914e5e61b846c45f7b177308cd891918619e4
    Merge: a4fab040243 16fd507b84a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 31 11:23:42 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit a4fab040243a57fb8ef55f91812604352d8b92c8
    Merge: 93019973329 dfee02dc4f5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 10:42:20 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 9301997332923921b93de4946c4824164723050c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 09:09:05 2016 +0530
    
        WL#9499 - OSX/Solaris compilers don't like the code.
    
    commit 54afa110837a054de24ccda84ddbb4ef2d0b96a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 22:55:19 2016 +0530
    
        WL#9499 - During recovery PFS instrumentation can't be accessed by the user.
    
    commit fa5c11e8cf0fbcd1852535faa74b1a04200df2e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:15:07 2016 +0530
    
        WL#9499 - Fil_Open::purge() can be called during recovery too
    
    commit d8672a978d62db42f1a12ba152693a3c0d244d83
    Merge: d4251d0ed6f 14d2a977ce8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:10:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d4251d0ed6f9df5a3acbf97ce7ba8074f126044c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:07:14 2016 +0530
    
        WL#9499 - Remove a WL#7806 test.
    
        The test doesn't really help. It uses very simplistic checks for matching
        path names. It ignores links (soft and hard) completely. Besides during
        recovery the path names will work with the original path names.
    
    commit fba6656350d0a757b2cc936b017329e7f7ce2d32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:51:53 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b522d665d10dca905420cb9119692dffac5024c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:20:30 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 3a9aca50a2e193398d626b5f75d238b5aa704e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:19:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5923cd73fc3af904220dea20b033ffcbb7892606
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:12:44 2016 +0530
    
        WL#9499 - Use custom allocators.
    
    commit 8c5acab2641cedae9542b9ad9405032abbcb4618
    Merge: 1509c43fcff 3c1319b9901
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:21:28 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1509c43fcffb9a849542ef8f3a62e66fda490fc7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:08:34 2016 +0530
    
        WL#9499 - Fix bug, should be decrement in_use, not increment.
    
    commit 0ad783d5e6e3f99817c8b839fe8521f783577d35
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 07:58:49 2016 +0530
    
        WL#9499 - Change fil_node_t::in_use into a reference counter from bool.
    
    commit 3974f1ed40bfbadcee04fa5fc2e60a50b89f930c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 22:10:24 2016 +0530
    
        WL#9499 - Remove an assertion that is no longer an invariant.
    
    commit d79f12dec7c07698f02ce2e0d0396bcd01bdc683
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 21:52:21 2016 +0530
    
        WL#9499 - Rename fil_node_t::being_extended to in_use. Fix test.
    
    commit 1d3368bcf60e2e339d5917251b51201b94dd63a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:57:38 2016 +0530
    
        WL#9499 - Fix log info messages during recovery/apply.
    
    commit d3811bd67248d3ae014f0e6475b1b49524f5c35b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:40:01 2016 +0530
    
        WL#9499 - Don't print % processed if number of records to apply is small.
    
    commit 55af670ff81170da51fbcae6832c3d6191176602
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:21:31 2016 +0530
    
        WL#9499 - Update test with new log message to check.
    
    commit 60c3d6c074ae230ab594015ed2f99e2eefcf97e0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:09:04 2016 +0530
    
        WL#9499 - Record test, because of new config parameter innodb_scan_directories.
    
    commit bd79ff06406c86758a29a28dbe5e7d494a0aa51f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:05:38 2016 +0530
    
        WL#9499 - Remove WL#7142 artefact.
    
    commit bcb753b72b2a01ba35d952cbab45e420929f2b33
    Merge: e30834ecc60 27d64e974ec
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:26:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e30834ecc60522fca8d7b156a66c0765867dea6e
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Thu Aug 25 05:54:26 2016 +0200
    
        WL#9499 - Destroy the mutex in the Fil_Open destructor.
    
    commit a396d4714bdc46626e07d22b6871be153b627bd3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:17:06 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 282ad76aaeaeb6d91bbf81fcd3315f455d9f572c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:12:33 2016 +0530
    
        WL#9499 - Protect changes to Fil_Open state with a mutex.
    
    commit d338cb9468c126ee7e3eeae3bf37b0fc966bbf53
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 07:37:49 2016 +0530
    
        WL#9499 - Fix division by zero.
    
    commit 845324f19ba0a84538b87c072f6d99514533aa25
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:28:45 2016 +0530
    
        WL#9499 - Check for UNDO tablespace names during directory scan.
    
    commit 30ed1d19389e174605fdfc0b7d55fdf544933712
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:26:08 2016 +0530
    
        WL#9499 - Conform to new naming guidelines.
    
    commit 4cf67b352d4c8131064f832ec884db6166d50e71
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 22:04:43 2016 +0530
    
        WL#9499 - Add test for the configuration variable. Add a version number to the file.
    
    commit ad9c5bca0eba1d7bf8e29cd8ebd7062aae089f90
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 21:01:56 2016 +0530
    
        WL#9499 - Code clean up
    
    commit a9e848158909645ead86759ed7ab64789d18a0cb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 15:26:02 2016 +0530
    
        WL#9499 - Print redo apply progress per tablespace
    
    commit 8cf86cf1567cabc1b03b2e8f2ec1167f3c38ce6c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 13:04:55 2016 +0530
    
        WL#9499 - Print tablespace name and % completed per tablespace
    
    commit 35ccdf32d1d048400012a80422072fb41ceb1bbd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 10:35:26 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit c978fb2e18a4e0b4a93b44fc3c75234bcdb3f1f0
    Merge: 8bde4aeb01c 0832bf660e3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 22:25:57 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 8bde4aeb01c3bcdecfb884e566f0ae28797a5b36
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 13:21:10 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 7f502be746cbe0de1a0c3a992217691b167c2fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 12:12:08 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 247bcfda6744a67cc4e53d61658ca87d206b0660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:57:44 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 04509641b086a1b0b2c591573f95957f8a2f1cd0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:50:55 2016 +0530
    
        WL#9499 - Pass the filename directly to the callback
    
    commit 3efa317825886a3ae5d4a3c771fc0770a2c5a3ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 09:39:18 2016 +0530
    
        WL#9499 - Include tchar.h on Windows
    
    commit 55b814d2c2ebdea7c16a6d87a7251ca3f6e83775
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 07:47:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit e4d203688273b562691c912cb9c7024709757490
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 22:02:02 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 31433b21dcabba0a7705eb8b1879beb1d8c36517
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 21:37:41 2016 +0530
    
        WL#9499 - Move Dir_Walker::walk implementation to os0file.cc
    
    commit 11f9016477274c5420782e365b26762067e7b99b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 18:42:28 2016 +0530
    
        WL#9499 - Fix Windows version of Dir_Walk.
    
    commit f32b88e0b1ef99f220165897db745b1dba12f86b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 13:48:03 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b91ad88d96942f1e05443001b7d1c2f6818ff6d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 14:32:25 2016 +0530
    
        WL#9499 - Initialize active ID to filename set from scanned set.
    
    commit 4a09f677ae7095aac9b07f7beccba8e60c50b065
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 13:09:05 2016 +0530
    
        WL#9499 Scan specified directories to build the ID to name mapping.
    
    commit c13b791497e322e6a5cf64ba85da52ee2cf05d45
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:46:53 2016 +0530
    
        WL#9499 - Fix check for incomplete read.
    
    commit 8a849e0288309cec7228612a62fc2bfd71b595e9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:45:04 2016 +0530
    
        WL#9499 - Fix Windows build errors
    
    commit 4fc24b654da26e8411fc45bc96f73ff70dc73e43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:12:12 2016 +0530
    
        WL#9499 - Need to include string for Windows std::wstring.
    
    commit bcb5c2b23f54776e0faaafba2472bb2555aee561
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:02:59 2016 +0530
    
        WL#9499 - On POSIX fopen() mode should be "w+b".
    
    commit b3c7def1931867633d9b8bb601317e99a06c31a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 21:23:57 2016 +0530
    
        WL#9499 - Open file in binary mode for writing.
    
        Otherwise on Windows newline (0x0A) is translated to CRLF (0x0D0A).
    
    commit 0739399cb8a384c07b4b3540b73ade482d083f4a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 20:27:11 2016 +0530
    
        WL#9499 - More error messages during mapping file read. Add a directory walker.
    
    commit 1322de0af2235bc94630f7cb22e4ead1588775ee
    Merge: f266b100e2f 8fdbb2f5f1a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:47:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f266b100e2f23e775e5e04de8d26301d7f2f1072
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:18:07 2016 +0530
    
        WL#9499 - Flush the tablespace to mapping file buffers before fsync()
    
    commit 7c92536686033c2c70e7df831d569c1cd6f871f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:32:26 2016 +0530
    
        WL#9499 - Remove unused member variable m_lsn.
    
    commit 994c4766ef712e7da668788d0bdd648cbd764982
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:25:05 2016 +0530
    
        WL#9499 - Don't crash on uncompress failure. Try the next file if any.
    
    commit a419a190cdf734e3beca08d339c6c0d307ddff5f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:21:49 2016 +0530
    
        WL#9499 - Print an error code on uncopress failure
    
    commit 77cb39000e098ba4d06873723423521e6889a7d0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:12:11 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit afc632e0ef768542a96d4d15a897cb1780825d2e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 11:34:44 2016 +0530
    
        WL#9499 - Compress the tablespace open state file.
    
    commit 568c9e758084f671007789f7b5d1c996f5df39a0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 09:12:39 2016 +0530
    
        WL#9499 - Free the buffer on return
    
    commit 0f468cf8e50b9605a9e6c4e93c818b0f876c3c29
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 08:42:38 2016 +0530
    
        WL#9499 - Remove protobuf
    
    commit e789eb175d2da90cee2d46e30b91e623546f9e96
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 18 09:59:37 2016 +0530
    
        WL#9499 - Get native HANDLE
    
    commit 6014c5853c09fee75256f9de6a86a5fc0ea18508
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:50:37 2016 +0530
    
        WL#9499 - Use _fileno() on Windows
    
    commit 61e6b4d7c033d48b775b22c4ad6d6b4858cd4cd7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:37:01 2016 +0530
    
        WL#9499 - Use buffered IO for open state file writes
    
    commit 98f40b10c15e49d9a5e14689cdb34758bdf85a05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 12:36:06 2016 +0530
    
        WL#9499 - Don't complain about corrupted encrypted pages during dblwr recovery
    
    commit c674939cbdeaa4a9996960de0fa4e74954ad6f76
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 09:21:06 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for generated sources too.
    
    commit ff68ba26aeaa27070ceeaa8db4472a9ce4daa3c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 08:33:03 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for fil/fil0fil.cc
    
    commit 445985ca11810c528567a4222cad4a7f0ce49e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 19:44:29 2016 +0530
    
        WL#9499 - Read/Write open state files using absolute paths
    
    commit b4d91d3799d94eb2677be6512752ec27dfa5e0f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 14:37:40 2016 +0530
    
        WL#9499 - Fix doxygen errors
    
    commit 8be2de3b3077c0d0f26340c9c80f7ae2247eefbc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 11:20:24 2016 +0530
    
        WL#9499 - Record test, MLOG_FILE_NAME doesn't exist anymore
    
    commit 54e64dc4a97f5bf4b5606cea1841dfc1f04fe536
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 10:41:01 2016 +0530
    
        WL#9499 - Add protobuf library to the embedded library.
    
    commit 83b0fb38283e285e1e963dd2c7c144d70b130338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 21:17:13 2016 +0530
    
        WL#9499 - Improved DBLWR and System table checks and code cleanup
    
        1. Remove dead code
        2. If some pages from the dblwr buffer were not recovered during recovery
           because of a missing tablespace id -> name mapping. Check the tablespace
           ID against the Tablespaces meta-data after recovery.
        3. Track open of the system tablespace. Check if the name of any file
           has changed. We don't rename the system tablespace.
    
    commit 5ebfba1e083f6a1d2b70946b91a02d32733c7e87
    Merge: 7a1b724c04b 0c27bf6fc44
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Mon Aug 15 11:40:07 2016 +0200
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7a1b724c04bf9d2e4aba0e58fb95dc8fc75d55c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 15:07:47 2016 +0530
    
        WL#9499 - Free deferred page memory
    
    commit 4de5d3b03670e4d2e8ebce89e8b3f104968eb3e1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:45:25 2016 +0530
    
        WL#9499 - Remove unrelated changes
    
    commit c9e83914232480501b139c36ef616798a2ac1d05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:28:19 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 6ecdb21d63ef6dd5a6aff997720178ff6510f0d5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 13 14:31:52 2016 +0530
    
        WL#9499 - Don't exit if no open state files found

[33mcommit dbd2ca2f6e14ce0ec19e743eb2f0cfdb20df6573[m
Author: Joao Gramacho <joao.gramacho@oracle.com>
Date:   Tue Nov 1 06:45:39 2016 +0000

    WL#8599: Reduce contention in IO and SQL threads
    
    (Step 1)
    
    This patch introduces the changes for the worklog related to making the
    slave applier to read from the relay log the same way the Binlog_sender
    does from the binary log (using a non-shared IO_CACHE, not relying on
    relay_log->LOCK_log even when reading from the "hot" relay log file).
    
    Made binlog_end_pos atomic
    --------------------------
    
    The MYSQL_BIN_LOG::binlog_end_pos was refactored to be atomic. From the
    Binlog_sender perspective, this would allow reducing the amount of
    acquirements of binary log LOCK_binlog_end_pos. With this change, both
    binary and relay log files readers don't need to acquire the
    LOCK_binlog_end_pos while checking if they reached the end of the "hot"
    log file. They only need to acquire the LOCK_binlog_end_pos if they are
    actually going to wait for updates.
    
    @ sql/binlog.h:
    
    Renamed binlog_end_pos to atomic_binlog_end_pos and made it atomic.
    
      At MYSQL_BIN_LOG::get_binlog_end_pos(), we removed the assertion of
      the ownership of the LOCK_binlog_end_pos, as it is not necessary since
      the binlog_end_pos variable become atomic.
    
    @ sql/rpl_binlog_sender.cc
    
      Refactored Binlog_sender::wait_new_events() to first check if the
      waiting is really needed (if the binary log was not updated before the
      acquirement of LOCK_binlog_end_pos), and then, only if the
      Binlog_sender really need to wait, to enter the
      stage_master_has_sent_all_binlog_to_slave stage and wait for updates
      on the binary log.
    
    Removed the relay_log->LOCK_log usage from next_event()
    -------------------------------------------------------
    
    The slave applier was refactored to not use the relay_log->LOCK_log when
    reading events from the "hot" relay log file.
    
    It was introduced a new PSI mutex key(MYSQL_RELAY_LOG::LOCK_log_end_pos)
    to instrument the LOCK_binlog_end_pos on relay log files.
    
    @ mysql-test/suite/perfschema/r/relaylog.test
    
      The test case had to be recorded again after the addition of the new
      PSI mutex key.
    
    @ sql/mysqld.(cc|.h)
    
    Introduced the new "MYSQL_RELAY_LOG::LOCK_log_end_pos" PSI mutex key.
    
    In order to make the slave applier to not need to acquire
    relay_log->LOCK_log when reading from the "hot" relay log, the slave
    receiver now opens the relay log with the same flags as the binary log
    files are opened: O_WRONLY. This lead to many changes in the slave code.
    
    The rli->ign_master_log_* that relied on relay_log->LOCK_log are now
    being protected by the relay_log->LOCK_binlog_end_pos. This change was
    needed in order to guarantee that the updated generated by events
    ignored by the receiver thread would be properly handled by the applier
    regardless relay_log->LOCK_log.
    
    @ sql/binlog.h
    
      The MYSQL_BIN_LOG::update_binlog_end_pos() function is now also used
      for the relay log. The function was refactored to remove the relay log
      specific code. It also has now a new parameter to tell the function
      that the LOCK_binlog_end_pos was acquired by the caller.
    
      MYSQL_BIN_LOG::after_append_to_relay_log(),
      MYSQL_BIN_LOG::append_event() and MYSQL_BIN_LOG::append_buffer()
      function were renamed to MYSQL_BIN_LOG::after_write_to_relay_log(),
      MYSQL_BIN_LOG::write_event() and MYSQL_BIN_LOG::write_buffer()
      respectively.
    
    @ sql/binlog.cc
    
      At MYSQL_BIN_LOG::open(), there is no distinction about binary or
      relay log with respect to the flags used to open the IO_CACHE.
    
      At MYSQL_BIN_LOG::open_binlog(), replaced a check for the relay log
      that were relying on the io_cache_type to actually check if it is a
      relay log or not.
    
      At MYSQL_BIN_LOG::after_write_to_relay_log(), replaced the function
      used to get the actual file position from my_b_append_tell() to
      my_b_tell(). Also, instead of just signaling the update of the log
      file, this function also cleanup the rli->ign_master_log_name_end.
    
      MYSQL_BIN_LOG::write_event() is now asserting that the log_file.type
      is WRITE_CACHE.
    
      MYSQL_BIN_LOG::write_buffer() is now asserting that the log_file.type
      is WRITE_CACHE. It is also calling my_b_write() to write the buffer
      into the relay log IO_CACHE.
    
      MYSQL_BIN_LOG::wait_for_update_relay_log() was refactored to rely on
      LOCK_binlog_end_pos instead of LOCK_log and was moved to
      sql/rpl_slave.cc as wait_new_relaylog_events().
    
      At MYSQL_BIN_LOG::close, replaced a check for the relay log that were
      relying on the io_cache_type to actually check if it is a relay log or
      not.
    
    @ sql/log_event.cc
    
      Log_event::write_header() now calculates the event
      common_header->log_pos by using my_b_tell() as there is no IO_CACHE
      with SEQ_READ_APPEND type anymore.
    
    @ sql/rpl_rli.h
    
      It was removed the IO_CACHE *cur_log as it is not needed anymore.
    
      It was also removed the cur_log_old_open_count variable.
    
    @ sql/rpl_rli.cc
    
      Relay_log_info::Relay_log_info() now initialize the relay_log using
      the WRITE_CACHE cache type. It was added the initialization of the
      key_RELAYLOG_LOCK_log_end_pos that now is used by the relay log.
    
      It was removed any reference to relay_log->LOCK_log at
      Relay_log_info::init_relay_log_pos() function.
    
    @ sql/rpl_slave.cc
    
      The write_ignored_events_info_to_relay_log() function now relies on
      LOCK_binlog_end_pos instead of LOCK_log.
    
      At queue_event(), there is a rli->relay_log.lock_binlog_end_pos() call
      every time the rli->ign_master_log_* variables are going to be
      handled.
    
      It was created the relay_log_space_verification() static function with
      all the code related to relay log space verification that was inside
      the next_event() function.
    
      The major changes in this step were done at the next_event() static
      function. It doesn't use the relay_log->LOCK_log anymore, and rely on
      relay_log->LOCK_binlog_end_pos when reaching the "hot" relay log file
      boundaries. The function now only reads and event from the relay log
      file if the log is not "hot" or if current reading position is less
      than the binlog_end_pos.
    
      Introduced the wait_new_relaylog_events() function.
    
    @ mysql-test/suite/rpl/t/rpl_relay_log_locking(.test|.result)
    
      It was created a test case that relies on debug instrumentation to
      block the receiver thread while queuing an event and ensure that the
      applier thread is capable of reading from the relay log up to the last
      queued event.
    
    Other references
    ----------------
    
    This patch also fixed:
    
    BUG#25321231: TUNING THE LOG_LOCK CONTENTION FOR IO_THREAD AND
                  SQL_THREAD IN RPL_SLAVE.CC
    
    (Step 2)
    
    This patch made channels retrieved_gtid_sets to use their own
    sid_map/sid_lock and created a class to avoid locking when checking the
    current server GTID_MODE to be used Master_info and Binlog_sender.
    
    Gtid_mode_copy class
    --------------------
    
    Any operation needing to check the current server GTID_MODE would
    acquire the global_sid_lock in order to read the GTID_MODE. This is a
    very fast operation (just to access a server global variable), but while
    done by many concurrent threads it might generate impact, mostly on
    commit operations that acquire the global_sid_lock exclusively.
    
    Also, when the server is committing a group of transactions, as the
    global_sid_lock is acquired for writing, any operation trying to check
    the server GTID_MODE will have to be held.
    
    GTID_MODE is a global variable that should not be changed often, but
    the access to it is protected by any of the four locks described at
    enum_gtid_mode_lock.
    
    Every time a channel receiver thread connects to a master, every time
    a Gtid_log_event or an Anonymous_gtid_log_event is queued by a receiver
    thread, or is going to be sent by the Binlog_sender to a receiver, there
    must be checked if the current GTID_MODE is compatible with the
    operation.
    
    There are some places where the verification is performed while
    already holding one of the above mentioned locks, but there are other
    places that rely on no specific lock and, in this case, will rely on the
    global_sid_lock, blocking any other GTID operation relying on the
    global_sid_map for writing (like a group of transactions being
    committed).
    
    In order to avoid acquiring lock to check a variable that is not
    changed often, we introduced a global (atomic) counter of how many times
    the GTID_MODE was changed since the server startup.
    
    The Gtid_mode_copy class was implemented to hold a copy of the last
    GTID_MODE to be returned without the need of acquiring locks if the
    local GTID mode counter has the same value as the global atomic counter.
    
    @ sql/mysqld.cc
    
      Introduced the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/rpl_gtid_misc.cc
    
      Declared the global atomic _gtid_mode_counter.
    
    @ sql/rpl_gtid.h
    
      Declared the external atomic _gtid_mode_counter.
    
      Defined DEFAULT_GTID_MODE as GTID_MODE_OFF.
    
      Introduced the Gtid_mode_copy class.
    
    @ sql/rpl_binlog_sender.h
    
      Inherited from Gtid_mode_copy to the Binlog_sender class.
    
    @ sql/rpl_binlog_sender.cc
    
      Replaced the calls to get_gtid_mode() by get_gtid_mode_from_copy().
    
    @ sql/rpl_slave.cc
    
      At recover_relay_log(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At init_recovery(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At start_slave_threads(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At get_master_version_and_clock(), replaced the call to
      get_gtid_mode() by get_gtid_mode_from_copy().
    
      At queue_event(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
    @ sql/sys_vars.cc
    
      Incremented the _gtid_mode_counter when GTID_MODE is changed. Also,
      made the GTID_MODE global variable to have DEFAULT_GTID_MODE as its
      default value.
    
    Retrieve_gtid_sets with their own SID maps/SID locks
    ----------------------------------------------------
    
    Any GTID set operation relying on a given SID map (and its respective
    lock) will be blocked by any other operation (in any other GTID set)
    holding the SID lock for writing.
    
    All server GTID state sets (lost_gtids, executed_gtids,
    gtids_only_in_table, previous_gtids_logged and owned_gtids) rely on the
    global SID map (and on the global SID lock). So, when GTIDs are
    committed in the server, the updates on the GTID state lock the SID map
    for writing to prevent other threads to perform updates on the GTID
    state (or read from it while it is being updated). The side effect of
    this way of avoiding other threads to read from or update a GTID set is
    blocking any other GTID activity in other GTID sets relying on the same
    SID map/SID lock. So, before this patch, the replication receiver
    threads had their Retrieved_Gtid_Set relying on the global SID map/lock.
    In this way, when a group commit was updating the GTIDs of the committed
    transactions, any replication receiver trying to queue a Gtid_log_event
    or finishing queuing a Gtid transaction had to wait for the group commit
    to unlock the global SID lock. Also, a group commit trying to lock the
    global SID lock for writing was waiting to all receiver threads queuing
    GTIDs to finish before having being granted with the lock ownership.
    
    The global SID lock on the cases described above is taken for doing
    small operations, and there is no significant impact on server
    performance in a slave server replicating using a single replication
    channel with medium to large transactions and without using MTS. But
    when the slave is scaled to have many replication channels and/or
    replicating many small transactions and using MTS, the impact of the
    concurrency in the global SID lock becomes noticeable.
    
    This patch is making all receiver threads to rely on their own
    (individual) SID maps and locks.
    
    @ sql/binlog.cc
    
      The MYSQL_BIN_LOG::init_gtid_sets() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      The MYSQL_BIN_LOG::open_binlog() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      The MYSQL_BIN_LOG::reset_logs() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      MYSQL_BIN_LOG::after_write_to_relay_log() now uses only the relay log
      sid_lock.
    
    @ sql/log_event.cc
    
      Previous_log_event should assert that the SID map of the GTID set
      passed as parameter is locked (is it not the global_sid_lock for relay
      log events).
    
    @ sql/mysqld.h
    
      Declared the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/mysqld.cc
    
      At gtid_server_init(), initialized the global _gtid_mode_counter.
    
      Introduced the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/rpl_channel_service_interface.cc
    
      The channel_get_last_delivered_gno() function now uses the relay log
      sid_lock.
    
      The channel_wait_until_apply_queue_applied() was refactored to avoid
      blocking both the relay log sid_lock and the global_sid_lock while
      waiting for the condition.
    
    @ sql/rpl_gtid.h
    
      Enabled the declaration of Sid_map::clear() regardless of compiler
      directives.
    
      Declared a new static function Sid_map::get_new_sid_map() to
      retrieve a new empty SID map with its own SID lock.
    
      Declared the Gtid_set::clear_set_and_sid_map() function that takes
      care of cleaning the SID map after cleaning the GTID set.
    
    @ sql/rpl_gtid_set.cc
    
      Introduced the Gtid_set::clear_set_and_sid_map() function that takes
      care of cleaning the SID map after cleaning the GTID set.
    
    @ sql/rpl_gtid_sid_map.cc
    
      Removed the compiler directives preventing the compilation of
      Sid_map::clear().
    
    @ sql/rpl_rli.h
    
      Made the (retrieved) gtid_set a pointer.
    
      Added function to get the GTID set SID map (get_sid_map()) and SID
      lock (get_sid_lock()).
    
      Changed add_logged_gtid() function to use the relay log SID map and
      lock.
    
      Declared a new wait_for_gtid_set() function receiving a char*
      parameter instead of a String*.
    
    @ sql/rpl_rli.cc
    
      Refactored the gtid_set initialization on Relay_log_info constructor
      and cleaned up the GTID set, SID map and lock on destructor.
    
      Introduced the new wait_for_gtid_set() function receiving a char*
      parameter instead of a String* and refactored the wait_for_gtid_set()
      that receives a String* to call the new introduced one.
    
      Added some assertions at Relay_log_info::wait_for_gtid_set() to ensure
      that the GTID set to wait is relying on global_sid_map or has no SID
      map.
    
      Relay_log_info::purge_relay_logs() now uses the relay log SID lock and
      also clears the relay log SID map when cleaning the retrieved GTID
      set.
    
      Relay_log_info::rli_init_info now uses the relay log SID lock.
    
      Relay_log_info::add_gtid_set() now uses the relay log SID lock.
    
    @ sql/rpl_slave.cc
    
      The recover_relay_log() function now uses the relay log SID lock and
      also clears the relay log SID map when cleaning the retrieved GTID
      set.
    
      The show_slave_status() functions were refactored to use the relay log
      SID lock when dealing with the retrieved GTID sets.
    
      The request_dump() function now uses the relay log SID lock when
      dealing with the retrieved GTID set.
    
      The queue_event() function now uses the relay log SID lock when
      dealing with GTIDs of received Gtid_log_events.
    
    @ storage/perfschema/table_replication_connection_status.cc
    
      The table_replication_connection_status::make_row() function was
      refactored to use the relay log SID lock when dealing with the
      retrieved GTID sets.
    
    (Step 3)
    
    This patch moved the call to [1;31mflush[m_master_info() that was done by the
    I/O thread after a successful call to queue_event() to inside the
    queue_event() function, in order to take a ride in the already locked
    mi->data_lock and relay_log->LOCK_log.
    
    This will avoid acquiring the above mentioned locks twice for every
    successful event queued.
    
    It also added a new parameter to [1;31mflush[m_master_info() to opt the [1;31mflush[m of
    the relay log. Previous approach was leading to [1;31mflush[m the relay log
    twice per event.
    
    @ sql/rpl_channel_service_interface.cc
    
      Specified the new queue_event() parameter to not [1;31mflush[m master info
      after queuing the event.
    
    @ sql/rpl_slave.h
    
      Changes [1;31mflush[m_master_info() declaration by adding a new parameter
      telling the function if it needs to acquire the required locks or if
      the locks are already acquired and a new parameter telling the
      function if it needs to [1;31mflush[m the relay log.
    
      Declared QUEUE_EVENT_RESULT enum with the possible results of the
      queue_event() function.
    
      Changes queue_event() declaration to return QUEUE_EVENT_RESULT and
      also to support a new parameter telling the function to also [1;31mflush[m
      master info on after an event be successfully queued.
    
    @ sql/rpl_slave.cc
    
      The [1;31mflush[m_master_info() function was changed to not acquire the
      relay_log->LOCK_log always, but rely on the need_lock parameter to do
      so. It was also changed to only [1;31mflush[m the relay log based on the new
      [1;31mflush[m_relay_log parameter. This will prevent [1;31mflush[ming the relay log
      twice when queuing events.
    
      On handle_slave_io(), refactored the calls to queue_event() and
      [1;31mflush[m_master_info() to use the new implemented parameters.
    
      Refactored queue_event() function to return QUEUE_EVENT_RESULT, and to
      [1;31mflush[m master info without the need of [1;31mflush[ming the relay log in the
      case of a successful event be queued.
    
    Added test cases to improve code coverage:
    
    - rpl_write_ignored_events: ensure the ignored events not yet consumed
      by the slave are taken into account by the SQL thread if the I/O
      thread is stopped before the SQL thread consumed the ignored events
      info.
    
    - rpl_write_ignored_events_fail_writing_rotate: ensure I/O behavior
      when failures happen while writing the ignored events info to the
      relay log.
    
    Also commented an unreachable code to make gcov happy.
    
    Added test cases to verify that receiver threads GTID sets do not rely on
    global SID anymore.
    
    rpl_multi_source_block_receiver: checks that receiver thread receiving GTIDs
    (and adding them to its retrieved GTID set) can apply GTIDs from a server UUID
    that doesn't belong to the global SID map yet.
    
    rpl_line_topology_receiver_block: checks that receiver thread on slave
    receiving GTIDs (and adding them to its retrieved GTID set) can have other
    servers replicating from it.

[33mcommit 0bbe8f73f9ea9cb2966dc7f1fbc0a15281eeb4b9[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Tue Feb 28 10:48:45 2017 +0100

    Squashed commit of the following:
    
    WL#9499 - InnoDB: Replace MLOG_FILE_NAME with MLOG_FILE_OPEN
    
    Fix the performance issues introduced by WL#7142 and its followup WL#7806.
    
    1. Revert WL#7142 and WL#7806 changes, keep some of the tests to test
       the behaviour that was introduced by the two WLs
    2. Change the tests that rely on the above two WLs behaviour
    3. Use std::unordered_map instead of the homebrew hash table for the recovery
       code and space ID to name mapping
    4. Split the redo log hash table key from <space, page> -> apply records to
       <space> -> apply records
    5. Addition of two new system files (tablespaces.open.1 and tablespaces.open.2)
    
     - Rename MLOG_FILE_NAME to MLOG_FILE_OPEN
     - Remove the two pass recovery code, make it a single pass
     - Track file open, close and rename
     - Write and fsync the tracking state to disk on checkpoint and rename.
       Uses the files in #5 in a round robin fashion
    
    Introduce --innodb-scan-directories="path1;...pathN". Scan the paths for
    .ibd files to open during recovery. This option can be used if the files in #5
    above are corrupt or missing. You should not use this if you move files around.
    While they can be recovered the data dictionary will not be updated and it
    will cause issues during runtimg.
    
    rb#13686 Approved by Satya and Shaohua
    
    commit fbf87161f3c93979e5abe424fbe0678fdc32159e
    Merge: 517cf3a7bf0 c2b504664ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:39:32 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 517cf3a7bf0490c3168fed020e3096ec500e0a85
    Merge: 4786f93ad8a 5e974fd0ea4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:24:25 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Additional change is to call recv_recovery_from_checkpoint_finish() on abort.
        Instead of recv_sys_free().
    
    commit 4786f93ad8a25506a2a1f6e9d1207256a34b3665
    Merge: 5dc35e05b5f 275245cce32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:43:27 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 5dc35e05b5f2da95c36e191350e9c7087be72194
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:42:40 2017 +0100
    
        WL#9499 Free recv resources on abort
    
    commit bed693070395923ededba736f1c7102b8eb21e95
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 18:34:50 2017 +0100
    
        WL#9499 - Test cannot be run with Valgrind
    
    commit c5d423228ddf58b17866ff8be289dba4a19205d2
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:30:39 2017 +0100
    
        WL#9499 - Remove const
    
    commit ac42498506b4dffb22e74282d0ce037fe3acf977
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:00:30 2017 +0100
    
        WL#9499 - Clean up code
    
    commit bc48077cab9c3ccb1b2797c365fe0940c269a785
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 16:01:09 2017 +0100
    
        WL#9499 - Revert unrelated change
    
    commit 8b2bb0f6d6254b3cfde168d41356400009db12f4
    Merge: eb9b294ba78 153a79ff35d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:43:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit eb9b294ba786800f9e397cd87f01c4f4976edddb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:29:56 2017 +0100
    
        WL#9499 - Remove debug message
    
    commit abae66ad591854ee67a5013f3209be2f82e4d9bf
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 17:04:10 2017 +0100
    
        WL#9499 - Test only works in debug mode.
    
    commit 71ebea70391ef295bed49ee06a8b872f15ecfe97
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:18:08 2017 +0100
    
        WL#9499 - Update to mtr test from Matthias
    
    commit f108a5b92fc476c70c49e4937496b32d9d5d031f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:13:04 2017 +0100
    
        WL#9499 - Increment redo log version number
    
    commit 4439c83a4d3edd6e511706ccf9936770ed29e593
    Merge: fa459186b90 05923bef41d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 09:54:18 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit fa459186b90d7a5ddcba7e3c6c7a9871d0dce793
    Merge: 14ac4f81d84 b401f17e70d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 20:02:40 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 14ac4f81d84bec23a7be210504ca0be93619bf11
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 16:44:57 2017 +0100
    
        WL#9499 - Update from Matthias
    
    commit ed3191a9fc951151fd7d758a527e7ab81530b3f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:16:11 2017 +0100
    
        WL#9499 - Revert change pushed by nmistake
    
    commit 8c0edb998867bf557f6c86410552d6d123892000
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:11:21 2017 +0100
    
        WL#9499 - Don't redo log MLOG_FILE_OPEN until startup is complete
    
    Date:   Wed Feb 22 09:54:18 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit fa459186b90d7a5ddcba7e3c6c7a9871d0dce793
    Merge: 14ac4f81d84 b401f17e70d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 20:02:40 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 14ac4f81d84bec23a7be210504ca0be93619bf11
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 16:44:57 2017 +0100
    
        WL#9499 - Update from Matthias
    
    commit ed3191a9fc951151fd7d758a527e7ab81530b3f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:16:11 2017 +0100
    
        WL#9499 - Revert change pushed by nmistake
    
    commit 8c0edb998867bf557f6c86410552d6d123892000
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:11:21 2017 +0100
    
        WL#9499 - Don't redo log MLOG_FILE_OPEN until startup is complete
    
    commit 3b503ea1d3f89c0f7e3677d3b56f249c7ebff506
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:37:04 2017 +0100
    
        WL#9499 - Add tests
    
    commit 47af7bd6eec10eac55633d7c4cf54afe607f3649
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:00:30 2017 +0100
    
        WL#9499 - Fix compile problem
    
    commit a8b9a8c6ccb15e2be5ce5db5fa0bce24b86d2c87
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:51:05 2017 +0100
    
        WL#9499 Remove dead code
    
    commit b1dba474486ad10b61029b2ef4e6a91ea67dcea8
    Merge: 3cf9e9eb3e8 a4271026201
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:49:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 3cf9e9eb3e86e4c8f4d44cb79d3f7c456ea7d671
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 18 07:53:43 2017 +0530
    
        WL#9499 - Remove suggestion to use force recovery
    
        --innodb-scan-directories is a safer option for the user. Force recovery should
        be the absolute last resort.
    
    commit 4104c4bfd606270650aac95a9a724e106fe835c5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 09:00:47 2017 +0530
    
        WL#9499 - Fix error message
    
        User can try --innodb-scan-directories="..." if the tablespaces.open.* files
        are corrupt or unreadable.
    
    commit 19ab12e54923b070a0b4ffc76b9fe97ac54ad3cc
    Merge: 50b3a95e446 f0f51c410bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 05:22:57 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Replace readdir_r() with readdir(), compiler complains that readdir_r() is
        deprecated and recommends replacing it with readdir().
    
    commit 50b3a95e446b91853fc35716b63bdc173221d01f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:55:33 2017 +0530
    
        WL#9499 - Fix test
    
    commit 45d202ae0fa35aa3aced55cc1933aeefa33837de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:32:56 2017 +0530
    
        WL#9499 - Remove redundant test
    
    commit 48fe691b97735e5144e9d439a0adbf721b2dc554
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:18:11 2017 +0530
    
        WL#9499 - Add DEBUG sync points
    
    commit d986f4e04a9eb6c2c76d61cd4afe9541d77b34bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:03:50 2017 +0530
    
        WL#9499 - Remove PB2 control file
    
    commit 5af7dca9c305bd366ad2b5c3de26a870e913af4a
    Merge: 74022f50a5f 23a0e71aa3d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 15 09:05:05 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 74022f50a5ff7cb2801c0712601f8a467b409a28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 14 10:31:00 2017 +0530
    
        WL#9499 - Fix test
    
    commit f6188175ee62040ac6a844a5c54787839dff6155
    Merge: 24c867aab14 19ca7c6a5d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 13 12:37:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 24c867aab14556188503aac495f60d89ba3d26ec
    Merge: cb64b8c7f9f a4de6ab549e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 4 06:41:23 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cb64b8c7f9fa9ca05033a9d6f6193cf141746310
    Merge: 17c6c41da0a 88dbc4f4511
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:48:12 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 17c6c41da0afe3fc78843b75fa02578dab29a0ca
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:46:34 2017 +0530
    
        WL#9499 - Add a test for scan directories.
    
        The use case is where the location of the files is not changed but the
        tablespaces.open.* files are missing.
    
    commit 79cc52f1bd82dc65932eacbc9aa14a47e4196572
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 18:01:50 2017 +0530
    
        WL#9499 - If open fails space will be null.
    
    commit 22ea5f31ecc1fa0db8abd57d4a46578e5f891c9a
    Merge: f5b69930f95 853a52cf5a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 12:14:41 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f5b69930f95192ddfdb3ca170024a5c7e3416076
    Merge: 40a4c32f2c4 b18872ed4a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 2 13:54:24 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 40a4c32f2c42b584539a14cbc1ba0d4f0fe7d3c9
    Merge: b1d1923d37c d071c0e7a0b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 1 13:48:33 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit b1d1923d37c3d23a9f701a61b458b7e4cbd3c90c
    Merge: 2fc6c51edab 4ae71705a01
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 31 10:44:59 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2fc6c51edabc3de4537eceb0b82cd62063ada3a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 16:36:46 2017 +0530
    
        WL#9499 - Empty the tablespace.open.* files on normal shutdown.
    
    commit 738acb7d554f97455c8dba512282c7c2e6ba9f3a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:47:21 2017 +0530
    
        WL#9499 - Fix formatting
    
    commit 28f8579a6f729af354e0c50098d16fbfa17cc253
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:25:30 2017 +0530
    
        WL#9499 - Bug fix
    
        The DELETED state was set on a copy of the data structure
    
    commit dd5bf8ea81b7023fa1980c01d89219a690160b04
    Merge: 7eeab0a994d 9c7808e1054
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 21:14:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7eeab0a994db4cf0c2e080f27ff916c778ec65f8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:50:59 2017 +0530
    
        WL#9499 - Add tests.
    
    commit ddfaf047f43587ee807599b0b80b6d01a3579e8c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:48:06 2017 +0530
    
        WL#9499 - Create tablespace bug fix
    
        If there is a checkpoint after the create tablespace is logged and the
        server crashes after writing the page initialization to the redo log. Then
        we neither have the mapping in the redo log nor in the tablespace.open.*
        files. We must update the tablespace mapping before writing the CREATE
        redo log entry so that the state is written out to disk on checkpoint.
    
    commit 29546d3ebea2991e5b86b33edddb551c924bf1db
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 17:55:28 2017 +0530
    
        WL#9499 - Remove dead code from WL#7142
    
    commit eced7a3e4437ee4bb24a12290f561437ddb15611
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 14:51:09 2017 +0530
    
        WL#9499 - Use the tablespace.open.* files in a round robin fashion.
    
    commit d8eff788eea1ad5e6c7786b9d64963524f2b2c81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:56:12 2017 +0530
    
        WL#9499 - Fix duplicate entry
    
    commit 1d04e0cf0308c35ee7498e6919eab9a11c699d52
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:55:30 2017 +0530
    
        WL#9499 - Revert last push
    
    commit 8361d3c39366d6435a895d5b64dd23615d26fc28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Jan 26 09:05:52 2017 +0530
    
        WL#9499 - Write to the tablespace.open.* files in a round robin manner.
    
    commit 3eaba629ee5b5c26a5f4e80852fee2d446f3013f
    Merge: 6642c43d735 bdc49070128
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 25 14:03:15 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6642c43d7353063a455972ab2cbc21220c16be43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 08:34:35 2017 +0530
    
        WL#9499 - Rename fil_ibd_load to fil_ibd_open_for_recovery.
    
    commit fdd1897c79b29c9e0a69c1f81d94927da06d9424
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:28:49 2017 +0530
    
        WL#9499 - Enforce const semantics on Windows for Folder::exists().
    
    commit 9394f4653e10cc5d4ab9b7b0a0b9331fd2666f49
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:08:26 2017 +0530
    
        WL#9499 - Include <array>
    
    commit c1903d28800ae0f7af69552aa669622d552346b4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Jan 21 07:49:28 2017 +0530
    
        WL#9499 - Improve scan directory handling
    
        1. Convert relative paths to absolute paths
        2. Filter out duplicates
        3. Check directories at filtering stage
    
    commit dfea237f4bef914de4067153cbf382240112c4f4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 11:11:05 2017 +0530
    
        WL#9499 - Code clean up
    
    commit c4d51bfdf1c786b1c584c0af1bde080a4f37cc5b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 07:37:06 2017 +0530
    
        WL#9499 - Update the open/rename LSN when a file is opened or renamed.
    
        Minor code cleanup.
        Add diagnostic code for debugging.
    
    commit 5e1d159b571fe6dbfe13c627a245155b82c4bbfa
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 18 10:59:54 2017 +0530
    
        WL#9499 - Filter out '*' from innodb-scan-directories
    
    commit 361f2944f1940f11dfb16dec3589d68335f5e2d8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 21:01:06 2017 +0530
    
        WL#9499 - Code cleanup
    
    commit 288d70b356721887423ca3d2d72b42da331216cd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 13:08:08 2017 +0530
    
        WL#9499 - Sync open file map to disk before checkpoint.
    
    commit 3c602d1b4089cd262200650f4b33986fc9e26531
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:18:46 2017 +0530
    
        WL#9499 - Print expected bytes instead of generic message.
    
    commit f52e0985b8cbef3891385179d35dc8c7f567146a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:07:47 2017 +0530
    
        WL#9499 - Print file size instead of generic message.
    
    commit b27b1b4b4b70e286e2c669f997b0a669f6d6034c
    Merge: bbdd1c46f1e c101ec9b557
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 16 13:19:42 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit bbdd1c46f1ef08d956ea249e1f6f4bc93d3464f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Dec 10 14:41:12 2016 +0530
    
        WL#9499 - Handle the case where the rename has already been done on recovery.
    
    commit 141bdb02b1a402e786db5d8b165b781a5d7370a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 11:59:29 2016 +0530
    
        WL#9499 - Instrumentation for debugging
    
    commit 34815bb24a1c296d9739e7602dc6ccd53c58c44c
    Merge: 41ca3732a6f 13a46b4c5ea
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 09:44:03 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 41ca3732a6ffd8dfa16762a05df6b5c6b4b550c1
    Merge: 7137edb2d2c aba34f1205d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 11:10:08 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7137edb2d2ca60cdec44600ddf3f5cbde424e7a4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 05:56:06 2016 +0530
    
        WL#9499 - Remove unused code. Move id to name mapping sync before log [1;31mflush[m.
    
    commit 2a50067e2da2f7819781de6550e55ca14995c7ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:57:41 2016 +0530
    
        WL#9499 - Initialize the PFS file handle
    
    commit d478d3492cdb40ec02fda9c043bf29b87bae11ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:05:52 2016 +0530
    
        WL#9499 - Fix whitespace
    
    commit 061af748a5e2fde6c1577ccdabfc8a89a9f753de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:02:25 2016 +0530
    
        WL#9499 - Set must [1;31mflush[m on file close/delete.
    
    commit ad76e2b9c7ff757f60c66821e86696d5ab757b18
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 11:43:00 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5a95946d4567dc13cf5a12d6bcdb28b19a02b5bc
    Merge: 1a0f373eb7f da23d6b8e44
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 09:27:45 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1a0f373eb7f03dc22264f91f3f6ed1fd13825de7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 13:01:41 2016 +0530
    
        WL#9499 - Readd test result file back
    
    commit 00afde093183cf850f735940245af111dce82b72
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 12:59:49 2016 +0530
    
        WL#9499 - Don't purge the files based on LWM. It won't work.
    
        We need to also ensure that there aren't any pages in the buffer pool that
        belong to a tablespace that is closed. Redo log records can be written for
        such pages.
    
    commit 3199fe255103daa42f0332b7ff9d565eefff7429
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:41:39 2016 +0530
    
        WL#9499 - Fix typo
    
    commit 351cb6c42709405a79021276f310d7b996aadd1b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:32:02 2016 +0530
    
        WL#9499 - Remove unused function
    
    commit 61cc7f6b06c5280d58217b76d7627013ddcd8338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:22:31 2016 +0530
    
        WL#9499 - Reduce the compression level.
    
    commit 48142e360ff5cfb53d5e416f3d6b92e956237923
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:21:51 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 4de4f8b31ebdff31a2f7a97a1ad211770d20cdd6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 14:07:07 2016 +0530
    
        WL#9499 - Revert ef30f0754ab22e614ac22712c348ec5f53e0f09c
    
    commit c2f77f44c43c209fad86bba568aa521a2dcbf718
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 12:20:37 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 5fccb51769a13cb9a1fc0f29a832d3b0085ad52a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:30:18 2016 +0530
    
        WL#9499 - Print a message when checkpoint is disabled.
    
    commit ef30f0754ab22e614ac22712c348ec5f53e0f09c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:17:27 2016 +0530
    
        WL#9499 - Print progress in 10% units.
    
    commit bc0ded332624fa2c8a08ebfc955a03f1a24e069c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 08:13:54 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 68ce0208cc073452f5f791faf304971dbac7194a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:38:03 2016 +0530
    
        WL#9499 - Scan directories after the mutex code is initialized.
    
    commit 21e07c8fd6b8eddf158fb79980443f6c9f6d238e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:12:23 2016 +0530
    
        WL#9499 - Introduce --innodb-checkpoint-disabled (debug)
    
        Disable checkpointing if the variable is set. This is to force recovery if the
        server is killed during a test.
    
    commit 7033c9bb5ff7641764f70823a73d747b497a0eed
    Merge: 11a6e582417 c6af7f512b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 04:00:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 11a6e582417d45a80a7f19233c2d2191a17936eb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 03:59:05 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 0a38252e65d607b59b1e9f64d0c8003cdecfecfd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 25 05:56:42 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bcf650cc92b8636f3768dcc3deb33b90b2942134
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 08:46:07 2016 +0530
    
        WL#9499 - Change the open files number back to 2.
    
    commit 99960af2825529fb45d021a34ba6c072e8caa0dc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 07:13:58 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bdb91bc0ba03e01661c50c7175d3fd123d2bcd69
    Merge: 61f3e4a5663 a545bdd6e31
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:04:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 61f3e4a5663c375cd44ee766b263281ff7f0601b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:00:20 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 072ab837d0acb4d2ed817110598554acc44ec344
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 12:06:53 2016 +0530
    
        WL#9499 - Set the IMPORT page LSN to the [1;31mflush[med to disk LSN
    
    commit 7f18661432f3645eb9ce76680c62508ced115fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 11:28:47 2016 +0530
    
        WL#9499 - Force a checkpoint before the crash
    
    commit 83671e9c37fa61adfa5546cabe1463a91ff02241
    Merge: cc26d5ae16e d1f811eb6e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 10:52:16 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cc26d5ae16e8d723a2519f38bfbc084c13a766c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 18:40:51 2016 +0530
    
        WL#9499 - Fix latch ordering issue
    
        Cannot hold the log sys mutex when updating the checkpoint LSN for the open
        files in fil0fil.cc.
    
    commit 4474509addfbdf91b9f0ad890a971299c594e738
    Merge: 396755e195c 0856b10cde5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 08:00:05 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 396755e195c1c8d3b2485a58175dcf56ca2cbf3f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:58:05 2016 +0530
    
        WL#9499 - Remove newline added earlier
    
    commit ab5e60ba491e52f1529c22551a936d771b8b5ef9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:57:21 2016 +0530
    
        WL#9499 - Revert a change that was added by mistake.
    
    commit 38688417713e5ef8cbb65032fa0a547ab0c25c15
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 20:44:50 2016 +0530
    
        WL#9499 - Bug fix, using an invalidated iterator.
    
    commit 4082d44f6dc4a5605562e37ccad9ac4db69344c6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 11:30:49 2016 +0530
    
        WL#9499 - Fix doxygen comment
    
    commit d5ca99e14c010a5349aea6c8cc39493b2073b9c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 15:30:12 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a25f3af10ea2893c634dc961d6f2af05efa103ec
    Merge: c8c2a7eba4c aa039b73223
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:52:51 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit c8c2a7eba4cac29ff431588daf2d6def0c0ee5a6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:39:32 2016 +0530
    
        WL#9499 - Fix problem with open files acrosss checkpoints.
    
        The problem is that we write the open file state before writing the checkpoint.
        Before this change the closed files were purged from the open state map and
        the state written to disk. The problem is that the state and mapping of a file
        opened before the last checkpoint but closed just before we write the state
        will not be in the mapping on disk. One solution is to check older files and
        retrieve the mapping from there. The solution chosen is to avoid purging
        files based on open LSN. If the file was opened before the last checkpoint
        and closed within the current checkpoint we note the state as CLOSED but
        write the mapping to disk. It will be purged at the next checkpoint, if it is
        not opened again in the meantime.
    
        Previously an attempt was made to open all files straight after reading the
        mapping from disk. With this change only the state is loaded into memory the
        files are opened on demand. Added a check to verify that the tablespace ID
        from the first page matches the expected value.
    
        Fixed tests to use this new tablespace ID verification.
    
    commit 5dc929e54b1c259f0f8104739ae1f88e9b860f73
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 12:24:40 2016 +0530
    
        WL#9499 - Remove unused code
    
    commit 528b95d70dcc05a69a98ee2a76fdfb8dae1e82fe
    Merge: d9861c40964 75f05cba753
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:14:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d9861c40964ad8fd45ee2cbbd9d94946110e8a9a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 3007ea5af68f40b85bc93098d8385ac96bcbd660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 9592996d2f17c9005262faa75dc1ade9dedbd511
    Merge: da512d5591b ac925fc91f6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Oct 19 10:34:48 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit da512d5591b3379b793d6155089e90791fe94c61
    Merge: f42e2ddd7d5 e635dfe28c0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 30 05:20:10 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f42e2ddd7d50aacae679babe71643af379b5c492
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 15:05:28 2016 +0530
    
        WL#9499 - Fix assertion, the values can be ORred.
    
    commit 94cd08960bc3801acefd4b4ff4ddb4a3e7d7e81a
    Merge: 32a68f91330 59af373321b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 11:05:21 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 32a68f9133011871bfdaba3c742f6239e0a53061
    Merge: 7857f38ebce 15555ae2165
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 21 11:23:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7857f38ebce747135e055bc8a232b649f1aad351
    Merge: 427491f63f1 b43bf88cf80
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 19 11:43:17 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 427491f63f107247c36796e66f6224d20968f104
    Merge: e7fa4c53dcf 23343687722
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 14 22:40:47 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e7fa4c53dcf01ea0e101bd8aa817698492995034
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 19:22:00 2016 +0530
    
        WL#9499 - max_lsn should work with any number of tablespace open files.
    
    commit 09775960da43d36ca64504c1298b9adff3056575
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 17:47:29 2016 +0530
    
        WL#9499 - Fix Names hash bug.
    
    commit 8430c5b34d23cb1774597707fe583dfac93fb3a8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 09:49:47 2016 +0530
    
        WL#9499 - Use std::unordered_map for name to fil_space_t* hash.
    
    commit 5e8275caf9d50dc9ba2f2dadd3b8c0fdeb9c79b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Sep 10 07:55:42 2016 +0530
    
        WL#9499 - Reduce an extra fil_sys_t::mutex call by consolidating [1;31mflush[m request.
    
    commit b29fd1039cf0022cff36a2a2311f464f1f6dbcc5
    Merge: 6235ee4902a a150caebee6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 9 20:44:56 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6235ee4902addd1a041b33469988bb1ea870dc7a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 10:58:00 2016 +0530
    
        WL#9499 - Add debug crash points.
    
    commit bf71fbc72b3570f55c8f01dd1a440e9eff761cb6
    Merge: ce6d2246a94 d25f38e38d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 09:47:37 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit ce6d2246a94801041da0bfece74b5ffdd9e8f796
    Merge: 69adae163de f28c4b9a41e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 7 11:20:50 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 69adae163de295ef0e910752cf5f8c96b1c1114f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:33:29 2016 +0530
    
        WL#9499 - Ensure that the MLOG_FILE_OPEN is always written first to the redo
    
    commit 20d5b1ebe6c899e2a0a1d135ad4303490516ce26
    Merge: 2d7d25c145f 4f1fb936211
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:17:58 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2d7d25c145fae59af744e91fce47fe009c869dad
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 10:06:56 2016 +0530
    
        WL#9499 - Add PFS instrumentation for the tablespace open file.
    
    commit 4e14a53ad129c1adcb0a3330931878a9f24c15cc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:53:57 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a465361e74136662471d2b9c0f307799efbe7269
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:17:43 2016 +0530
    
        WL#9499 - Move the file write code to a separate method.
    
    commit 7a26ba28bf7bf94808c47cfcdb6210c4abde2587
    Merge: f49914e5e61 ed389829067
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 07:55:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f49914e5e61b846c45f7b177308cd891918619e4
    Merge: a4fab040243 16fd507b84a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 31 11:23:42 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit a4fab040243a57fb8ef55f91812604352d8b92c8
    Merge: 93019973329 dfee02dc4f5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 10:42:20 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 9301997332923921b93de4946c4824164723050c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 09:09:05 2016 +0530
    
        WL#9499 - OSX/Solaris compilers don't like the code.
    
    commit 54afa110837a054de24ccda84ddbb4ef2d0b96a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 22:55:19 2016 +0530
    
        WL#9499 - During recovery PFS instrumentation can't be accessed by the user.
    
    commit fa5c11e8cf0fbcd1852535faa74b1a04200df2e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:15:07 2016 +0530
    
        WL#9499 - Fil_Open::purge() can be called during recovery too
    
    commit d8672a978d62db42f1a12ba152693a3c0d244d83
    Merge: d4251d0ed6f 14d2a977ce8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:10:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d4251d0ed6f9df5a3acbf97ce7ba8074f126044c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:07:14 2016 +0530
    
        WL#9499 - Remove a WL#7806 test.
    
        The test doesn't really help. It uses very simplistic checks for matching
        path names. It ignores links (soft and hard) completely. Besides during
        recovery the path names will work with the original path names.
    
    commit fba6656350d0a757b2cc936b017329e7f7ce2d32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:51:53 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b522d665d10dca905420cb9119692dffac5024c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:20:30 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 3a9aca50a2e193398d626b5f75d238b5aa704e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:19:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5923cd73fc3af904220dea20b033ffcbb7892606
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:12:44 2016 +0530
    
        WL#9499 - Use custom allocators.
    
    commit 8c5acab2641cedae9542b9ad9405032abbcb4618
    Merge: 1509c43fcff 3c1319b9901
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:21:28 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1509c43fcffb9a849542ef8f3a62e66fda490fc7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:08:34 2016 +0530
    
        WL#9499 - Fix bug, should be decrement in_use, not increment.
    
    commit 0ad783d5e6e3f99817c8b839fe8521f783577d35
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 07:58:49 2016 +0530
    
        WL#9499 - Change fil_node_t::in_use into a reference counter from bool.
    
    commit 3974f1ed40bfbadcee04fa5fc2e60a50b89f930c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 22:10:24 2016 +0530
    
        WL#9499 - Remove an assertion that is no longer an invariant.
    
    commit d79f12dec7c07698f02ce2e0d0396bcd01bdc683
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 21:52:21 2016 +0530
    
        WL#9499 - Rename fil_node_t::being_extended to in_use. Fix test.
    
    commit 1d3368bcf60e2e339d5917251b51201b94dd63a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:57:38 2016 +0530
    
        WL#9499 - Fix log info messages during recovery/apply.
    
    commit d3811bd67248d3ae014f0e6475b1b49524f5c35b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:40:01 2016 +0530
    
        WL#9499 - Don't print % processed if number of records to apply is small.
    
    commit 55af670ff81170da51fbcae6832c3d6191176602
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:21:31 2016 +0530
    
        WL#9499 - Update test with new log message to check.
    
    commit 60c3d6c074ae230ab594015ed2f99e2eefcf97e0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:09:04 2016 +0530
    
        WL#9499 - Record test, because of new config parameter innodb_scan_directories.
    
    commit bd79ff06406c86758a29a28dbe5e7d494a0aa51f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:05:38 2016 +0530
    
        WL#9499 - Remove WL#7142 artefact.
    
    commit bcb753b72b2a01ba35d952cbab45e420929f2b33
    Merge: e30834ecc60 27d64e974ec
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:26:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e30834ecc60522fca8d7b156a66c0765867dea6e
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Thu Aug 25 05:54:26 2016 +0200
    
        WL#9499 - Destroy the mutex in the Fil_Open destructor.
    
    commit a396d4714bdc46626e07d22b6871be153b627bd3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:17:06 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 282ad76aaeaeb6d91bbf81fcd3315f455d9f572c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:12:33 2016 +0530
    
        WL#9499 - Protect changes to Fil_Open state with a mutex.
    
    commit d338cb9468c126ee7e3eeae3bf37b0fc966bbf53
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 07:37:49 2016 +0530
    
        WL#9499 - Fix division by zero.
    
    commit 845324f19ba0a84538b87c072f6d99514533aa25
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:28:45 2016 +0530
    
        WL#9499 - Check for UNDO tablespace names during directory scan.
    
    commit 30ed1d19389e174605fdfc0b7d55fdf544933712
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:26:08 2016 +0530
    
        WL#9499 - Conform to new naming guidelines.
    
    commit 4cf67b352d4c8131064f832ec884db6166d50e71
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 22:04:43 2016 +0530
    
        WL#9499 - Add test for the configuration variable. Add a version number to the file.
    
    commit ad9c5bca0eba1d7bf8e29cd8ebd7062aae089f90
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 21:01:56 2016 +0530
    
        WL#9499 - Code clean up
    
    commit a9e848158909645ead86759ed7ab64789d18a0cb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 15:26:02 2016 +0530
    
        WL#9499 - Print redo apply progress per tablespace
    
    commit 8cf86cf1567cabc1b03b2e8f2ec1167f3c38ce6c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 13:04:55 2016 +0530
    
        WL#9499 - Print tablespace name and % completed per tablespace
    
    commit 35ccdf32d1d048400012a80422072fb41ceb1bbd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 10:35:26 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit c978fb2e18a4e0b4a93b44fc3c75234bcdb3f1f0
    Merge: 8bde4aeb01c 0832bf660e3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 22:25:57 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 8bde4aeb01c3bcdecfb884e566f0ae28797a5b36
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 13:21:10 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 7f502be746cbe0de1a0c3a992217691b167c2fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 12:12:08 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 247bcfda6744a67cc4e53d61658ca87d206b0660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:57:44 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 04509641b086a1b0b2c591573f95957f8a2f1cd0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:50:55 2016 +0530
    
        WL#9499 - Pass the filename directly to the callback
    
    commit 3efa317825886a3ae5d4a3c771fc0770a2c5a3ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 09:39:18 2016 +0530
    
        WL#9499 - Include tchar.h on Windows
    
    commit 55b814d2c2ebdea7c16a6d87a7251ca3f6e83775
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 07:47:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit e4d203688273b562691c912cb9c7024709757490
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 22:02:02 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 31433b21dcabba0a7705eb8b1879beb1d8c36517
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 21:37:41 2016 +0530
    
        WL#9499 - Move Dir_Walker::walk implementation to os0file.cc
    
    commit 11f9016477274c5420782e365b26762067e7b99b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 18:42:28 2016 +0530
    
        WL#9499 - Fix Windows version of Dir_Walk.
    
    commit f32b88e0b1ef99f220165897db745b1dba12f86b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 13:48:03 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b91ad88d96942f1e05443001b7d1c2f6818ff6d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 14:32:25 2016 +0530
    
        WL#9499 - Initialize active ID to filename set from scanned set.
    
    commit 4a09f677ae7095aac9b07f7beccba8e60c50b065
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 13:09:05 2016 +0530
    
        WL#9499 Scan specified directories to build the ID to name mapping.
    
    commit c13b791497e322e6a5cf64ba85da52ee2cf05d45
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:46:53 2016 +0530
    
        WL#9499 - Fix check for incomplete read.
    
    commit 8a849e0288309cec7228612a62fc2bfd71b595e9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:45:04 2016 +0530
    
        WL#9499 - Fix Windows build errors
    
    commit 4fc24b654da26e8411fc45bc96f73ff70dc73e43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:12:12 2016 +0530
    
        WL#9499 - Need to include string for Windows std::wstring.
    
    commit bcb5c2b23f54776e0faaafba2472bb2555aee561
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:02:59 2016 +0530
    
        WL#9499 - On POSIX fopen() mode should be "w+b".
    
    commit b3c7def1931867633d9b8bb601317e99a06c31a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 21:23:57 2016 +0530
    
        WL#9499 - Open file in binary mode for writing.
    
        Otherwise on Windows newline (0x0A) is translated to CRLF (0x0D0A).
    
    commit 0739399cb8a384c07b4b3540b73ade482d083f4a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 20:27:11 2016 +0530
    
        WL#9499 - More error messages during mapping file read. Add a directory walker.
    
    commit 1322de0af2235bc94630f7cb22e4ead1588775ee
    Merge: f266b100e2f 8fdbb2f5f1a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:47:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f266b100e2f23e775e5e04de8d26301d7f2f1072
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:18:07 2016 +0530
    
        WL#9499 - Flush the tablespace to mapping file buffers before fsync()
    
    commit 7c92536686033c2c70e7df831d569c1cd6f871f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:32:26 2016 +0530
    
        WL#9499 - Remove unused member variable m_lsn.
    
    commit 994c4766ef712e7da668788d0bdd648cbd764982
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:25:05 2016 +0530
    
        WL#9499 - Don't crash on uncompress failure. Try the next file if any.
    
    commit a419a190cdf734e3beca08d339c6c0d307ddff5f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:21:49 2016 +0530
    
        WL#9499 - Print an error code on uncopress failure
    
    commit 77cb39000e098ba4d06873723423521e6889a7d0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:12:11 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit afc632e0ef768542a96d4d15a897cb1780825d2e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 11:34:44 2016 +0530
    
        WL#9499 - Compress the tablespace open state file.
    
    commit 568c9e758084f671007789f7b5d1c996f5df39a0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 09:12:39 2016 +0530
    
        WL#9499 - Free the buffer on return
    
    commit 0f468cf8e50b9605a9e6c4e93c818b0f876c3c29
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 08:42:38 2016 +0530
    
        WL#9499 - Remove protobuf
    
    commit e789eb175d2da90cee2d46e30b91e623546f9e96
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 18 09:59:37 2016 +0530
    
        WL#9499 - Get native HANDLE
    
    commit 6014c5853c09fee75256f9de6a86a5fc0ea18508
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:50:37 2016 +0530
    
        WL#9499 - Use _fileno() on Windows
    
    commit 61e6b4d7c033d48b775b22c4ad6d6b4858cd4cd7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:37:01 2016 +0530
    
        WL#9499 - Use buffered IO for open state file writes
    
    commit 98f40b10c15e49d9a5e14689cdb34758bdf85a05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 12:36:06 2016 +0530
    
        WL#9499 - Don't complain about corrupted encrypted pages during dblwr recovery
    
    commit c674939cbdeaa4a9996960de0fa4e74954ad6f76
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 09:21:06 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for generated sources too.
    
    commit ff68ba26aeaa27070ceeaa8db4472a9ce4daa3c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 08:33:03 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for fil/fil0fil.cc
    
    commit 445985ca11810c528567a4222cad4a7f0ce49e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 19:44:29 2016 +0530
    
        WL#9499 - Read/Write open state files using absolute paths
    
    commit b4d91d3799d94eb2677be6512752ec27dfa5e0f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 14:37:40 2016 +0530
    
        WL#9499 - Fix doxygen errors
    
    commit 8be2de3b3077c0d0f26340c9c80f7ae2247eefbc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 11:20:24 2016 +0530
    
        WL#9499 - Record test, MLOG_FILE_NAME doesn't exist anymore
    
    commit 54e64dc4a97f5bf4b5606cea1841dfc1f04fe536
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 10:41:01 2016 +0530
    
        WL#9499 - Add protobuf library to the embedded library.
    
    commit 83b0fb38283e285e1e963dd2c7c144d70b130338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 21:17:13 2016 +0530
    
        WL#9499 - Improved DBLWR and System table checks and code cleanup
    
        1. Remove dead code
        2. If some pages from the dblwr buffer were not recovered during recovery
           because of a missing tablespace id -> name mapping. Check the tablespace
           ID against the Tablespaces meta-data after recovery.
        3. Track open of the system tablespace. Check if the name of any file
           has changed. We don't rename the system tablespace.
    
    commit 5ebfba1e083f6a1d2b70946b91a02d32733c7e87
    Merge: 7a1b724c04b 0c27bf6fc44
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Mon Aug 15 11:40:07 2016 +0200
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7a1b724c04bf9d2e4aba0e58fb95dc8fc75d55c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 15:07:47 2016 +0530
    
        WL#9499 - Free deferred page memory
    
    commit 4de5d3b03670e4d2e8ebce89e8b3f104968eb3e1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:45:25 2016 +0530
    
        WL#9499 - Remove unrelated changes
    
    commit c9e83914232480501b139c36ef616798a2ac1d05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:28:19 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 6ecdb21d63ef6dd5a6aff997720178ff6510f0d5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 13 14:31:52 2016 +0530
    
        WL#9499 - Don't exit if no open state files found

[33mcommit 245a0966c2d3b4e657509e221da37137f056c9e7[m
Author: Lakshmi Narayanan Sreethar <lakshmi.narayanan.sreethar@oracle.com>
Date:   Fri Feb 3 00:44:06 2017 +0530

    Bug#24666177
    
    PARENT TABLE'S HANDLER NOT UPDATED AFTER ADDING A FK DEPENDENCY
    
    When a foreign key is added or dropped from a table using the alter
    table query, the child's metadata is reloaded in the mysqld handler. But
    the parent table's metadata is not reloaded. Due to this the fk
    information in parent's handler becomes obsolete. When a subsequent
    query comes in that depends on this particular foreign key information,
    it might return bad results. Similar problem happens also after a
    foreign key drop.
    
    This patch fixes that by [1;31mflush[ming out the cached parent table definition
    after a successful foreign key ddl query.

[33mcommit 93f4a9b6fbae1578ed1225af1655c69ca0fee69f[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Jan 19 16:11:23 2017 +0100

    Bug#22705935 NDBAPI : SENDSIGNAL FLUSH OPTIMISATION ISSUES
    
    Follow up patch to fix regression observed in the ATR
    tests:
    
    - testNdbApi -n ApiFailReqBehaviour T1
    - testNdbApi -n CheckDisconnectCommit T1
    - testNdbApi -n CheckDisconnectComplete T1
    - testNdbApi -n FragmentedApiFailure T1
    - ... and possibly more
    
    The original patch removed the ::[1;31mflush[m_send_signal()
    from TransporterFacade::reportConnected / ::reportDisconnected()
    after it had returned from ClusterMgr::reportConnected
    or ::reportDisconnected().
    
    This was done as [1;31mflush[ming is now done by by the poll owner
    when it 'finished poll'. However, that is probably too late
    for the ::reportDisconnected() as we want the receiver to
    take immediate actions on this - Possibly we even reset
    the send buffers as part of disconnecting, such that the
    un[1;31mflush[med signals are lost before they are sent, (Didn't
    really investigate that though)
    
    This patch reintroduce [1;31mflush[ming for ClusterMgr::reportConnected()
    and ::reportDisconnected() by changing their signal sending
    to use the [1;31mflush[ming ::safe_sendSignal() instead of
    ::safe_no[1;31mflush[m_sendSignal(). This reintroduce the
    immediate [1;31mflush[ming of signals sent as part of a
    connect/disconnect.

[33mcommit 767f3877cc70265c0854a84e07f5a215a1239bb2[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jan 6 09:29:05 2017 +0100

    Bug#22705935 NDBAPI : SENDSIGNAL FLUSH OPTIMISATION ISSUES
    
    If signals were sent while the client process received signals
    (typically SUB_GCP_COMPLETE_ACK and TC_COMMIT_ACK), these signals
    were temporary buffered in the send buffers of the clients which
    sent them. If not explicit '[1;31mflush[med', the signal would stay
    in these buffers until the client was woken up again and [1;31mflush[med
    its buffers. However, this could take quite a while, without any
    attempt of guarantying an upper limit of how long the signal
    could remain unsent in the local client buffers. This could
    lead to timeouts and bad behaviour in the components waiting
    for these ACKs. (bug#18753341).
    
    Furthermore, the patch for Bug#23202735
    
    'CLIENT PERFORMANCE REDUCED DUE TO THREADS WOKEN UP TOO EARLY'
    
    Likely worsened the situation by removing some random client
    wakeups where the clients send buffers could have been [1;31mflush[med.
    
    This patch moves the responsibility of [1;31mflush[ming messages
    sent by the receivers from each client, to (only) the
    receiver/poll_owner client. This has the advantage that
    we no longer have to wake up all clients just to have them
    [1;31mflush[m their buffers. Instead we let the (already running)
    poll_owner client do the send buffer [1;31mflush[ming of whatever
    was sent while it deliverd signals to the receipents.
    (in finish_poll())
    
    Note that all such signals should be 'safe-sent'
    (safe_sendSignal()) which implies that the are buffered in
    the poll_owner send buffers. Thus only the poll owner
    send buffers has to be [1;31mflush[med when the poll 'finish'.
    (Added asserts that there are no pending [1;31mflush[m from the other
    'locked-clients')
    
    Explicit '[1;31mflush[m_send_buffers' where we [1;31mflush[med send buffers now
    covered by the above [1;31mflush[m has been removed (reportConnected(),
    reportDisconnected(), complete_poll(), wait_for_input_in_loop().
    The later two were replaced with an assert that there were no
    pending [1;31mflush[mes.
    
    That ^^ uncovered a missing [1;31mflush[m_send_signal() in
    NdbScanOperation::nextResultNdbRecord(), where a
    'prefetch' of more scan results may have been sent, but
    not got [1;31mflush[med to the transporter layer. (Until we eventually
    had to poll-wait for more results)
    
    There has also been some confusion wrt. when to use the
    'safe(_no[1;31mflush[m)_sendSignal()' or not. The method
    TransporterFacade::is_poll_owner_thread() is introduced
    as an utility to be used to 'assert' the correct usage of
    the diferent flavours of the 'sendSignal()' methods.
    See also extensive comments added as part of introducing
    this.
    
    Usage of these asserts uncovered that both
    ClusterMgr::reportConnected() and ::reportDisconnected()
    made usage of raw_sendSignal() instead of its 'safe'
    variant - corrected.

[33mcommit 075acb08ad5ebaf3425ab3c3bcfd2c38252854f3[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Dec 1 11:15:54 2016 +0100

    Bug #24526123 ADAPTIVE SEND ALGORITHM IS BROKEN
    
    The 'adaptive send strategy' was physically removed from the
    code as part of the 'ATC-patches' and 'forceSend' enforce
    independent of which kind of 'send' was specified.
    
    This patch reintroduce an improved version of the adaptive
    send algorithm. Performance test shows that it performs equal
    with the 'force*send' for a lower number ( <= ~20) of client
    threads, and performs increasingly better with higher number
    of threads.
    
    Details from the patch:
    
    part 1:
        Introduce the TransporterFacade member 'NodeBitmask m_active_nodes'
        which is a bitmap of all m_send_buffers[MAX_NODES] having
        '::m_node_active == true'
    
        Replace the loop(s) iterating m_send_biffers[] from
        1..MAX_NODES to instead iterate the set bits in m_active_nodes.
    
    Part2:
        Introduce the TransporterFacade member
        'Uint32 m_poll_waiters'. Keep track of number of trp_clients
        waiting in the receiver poll queue.
    
        Will later be used as a metric to measure the API
        activity level in the adaptive send algorithm.
    
    Part3:
        Fix const correctness in methods related to 'send'
    
    Part4:
        Introduce the trp_client member
        'NodeBitmask m_[1;31mflush[med_nodes_mask' containing the set
        of nodes this trp_client has [1;31mflush[med, but possibly unsent,
        messages to.
    
    Part5:
        Introduce the TransporterFacade::TFSendBuffer member
        'Uint32 m_[1;31mflush[med_cnt'. Will count the number of '[1;31mflush[m' to
        this buffer which has not yet been sent.
    
        Will later be used as a metric to the adaptive [1;31mflush[m
        algorithm to decide whether a message should be sent immediately,
        or if we should wait for possible some more messages to the
        same node to become available.
    
    Part6: refactor:
    
        - Refactor the common 'send to all nodes' loop found in
          both the send thread and in ::do_forceSend() into the
          new method try_send_all().
    
        - Factored out the 'send part' from ::[1;31mflush[m_and_send_buffer()
          into the new method ::try_send_buffer()
    
        - Entirely removed the method [1;31mflush[m_and_send_buffer().
          Replaced with first calling [1;31mflush[m_send_buffer(),
          then try_send_all()
    
        - Introduced the new TransporterFacade member
          'NodeBitmask m_has_data_nodes' which maintain the set
          of datanodes having 'more_data' to be sent. These will
          need attention from the send thread.
    
        - Refactor the send thread to take advantage of new methods
          and members above. Instead of sending to all 'active'
          nodes in each iteration, it will now only send to the
          nodes which 'has_data' - Except every 'sendThreadWaitMillisec'
          where it will also include all 'active' nodes.
    
        - Refactor trp_client::do_forceSend() to take advantage
          of new members above. No functional change (yet)
    
    Part7:
        Introduce NdbCondition_ComputeAbsTime_ns()
    
        The existing NdbCondition_ComputeAbsTime() takes a millisecond
        argument to calculate an 'AbsTime' for the conditional wait
        to wait until. The adaptive send algorithm will need
        an 'AbsTime' caculation with at least micro second resolution.
    
    Part8:
        Introduce the adaptive send
        algorithm. Change trp_client::do_forceSend() to
        use the send type specified instead of always 'forceSend'.
    
        See patch itself for fairly extensive comments about
        how the adaptive send is implemented.

[33mcommit 4bf48e8bf0d572fafc0349a3d7e9376b781a1302[m
Author: Oystein Grovlen <oystein.grovlen@oracle.com>
Date:   Fri Nov 25 13:32:20 2016 +0100

    WL#8737 IO aware defaults for optimizer cost constants
    
    Update default values for optimizer cost constants. New values are:
    
      row_evaluate_cost             0.1
      key_compare_cost              0.05
      memory_temptable_create_cost  1.0
      memory_temptable_row_cost     0.1
      disk_temptable_create_cost    20.0
      disk_temptable_row_cost       0.5
      memory_block_read_cost        0.25
      io_block_read_cost            1.0
    
    Changes to source files:
    
    sql/opt_costconstants.cc
      Changed default values for cost constants.
    sql/sql_select.h
      Change type of JOIN_TAB::read_time from ha_rows to double since cost may now
      be lower than 1.
    sql/sql_optimizer.cc
    sql/sql_select.cc
      Removed casts when assigning to/from JOIN_TAB::read_time
    unittest/gunit/opt_costconstants-t.cc
      Updated unit tests to use new values for cost constants
    
    Changes in tests:
    
    mysql-test/include/join_cache.inc
      Added more data in one table to preserve original query plan.
    mysql-test/include/mix1.inc
      Added more data in in two tables to preserve original query plan.
    mysql-test/r/count_distinct.result
      User variable changed because plans go from BNL to ref access
    mysql-test/t/dd_is_compatibility.test
    mysql-test/r/dd_is_compatibility.result
    mysql-test/r/dd_is_compatibility_ci.result
      Lowered setting of max_join_size to make sure test still get ER_TOO_BIG_SELECT
    mysql-test/r/delete.result
      Changed join order gives more warnings
    mysql-test/r/endspace.result
      Query returned result in different order, re-recorded.
    mysql-test/r/explain.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_rqg_json.result
      Change in two query plans, updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_rqg_trad.result
      Change in one query plan, updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_small_json.result
    mysql-test/r/explain_for_connection_small_trad.result
      One query changes from table scan to ref access, due to magic constants
      added when calculating cost for tables scan. Two queries changes from
      index scan to ref access due to lower cost of doing ref access. Updated cost
      numbers in EXPLAIN JSON.
    mysql-test/r/explain_json_all.result
      Re-recorded new query plan for one query since it no longer tested
      what the original test was for. Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_json_none.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/explain_other.test
    mysql-test/r/explain_other.result
      Added more data to one table in order to preserver original query plan.
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/func_concat.result
      Changed from table scan with BNL to eq_ref access.
      The new plan is identical to the plan when the test case was added.
    mysql-test/r/greedy_optimizer.result
      Several queries got new query plan. All new query plans resulted in a
      lower number of Handler_reads. Updated Last_query_cost numbers.
    mysql-test/r/greedy_search.result
      No changes in query plans but the number of partial plans evaluated
      was changed for several queries.
    mysql-test/r/group_by.result
      Changed from table scan with BNL to ref access
    mysql-test/r/group_min_max.result
      Four queries changes from doing index scan to use range scan due to
      range scan becoming cheaper with all data in memory buffer.
    mysql-test/r/heap_hash.result
      One query changes from using join buffer to use ref access for join.
      This is what the original test used, accepted new plan.
    mysql-test/r/index_merge_innodb.result
      One query changes from ref to range. This is caused by using DS-MRR for the
      range scan. Updated cost numbers in EXPLAIN JSON.
    mysql-test/include/index_merge_intersect_dml.inc
    mysql-test/r/index_merge_intersect_dml.result
      One query changed from doing range scan on primary key to range scan on
      secondary key. Changed query to switch back to use primary key.
    mysql-test/r/index_merge_myisam.result
    mysql-test/r/innodb_explain_json_non_select_all.result
    mysql-test/r/innodb_explain_json_non_select_none.result
    mysql-test/r/internal_tmp_disk_storage_engine.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/join.test
    mysql-test/r/join.result
      Query plan changes for two queries. First fixed by increasing the range
      interval in the query. The second query changes from table scan to
      eq_ref for one table, re-recorded new query plan. Updated Last_query_cost
      numbers.
    mysql-test/r/join_cache_bka.result
      Four queries changes from using BNL to use BKA/ref access.
    mysql-test/r/join_cache_bka_nixbnl.result
      One query changes from table scan to BKA/ref access.
      One query changes join order
    mysql-test/r/join_cache_bkaunique.result
      Four queries changes from using BNL to use BKA-unique/ref access.
    mysql-test/r/join_cache_bnl.result
      Four queries changes from using BNL to use ref access due to ref access
      becoming cheaper with all data in a memory buffer.
    mysql-test/r/join_cache_nojb.result
      Changed join order for one query due to ref access becomming relatively
      less costly compared to table scan when all data is in a memory buffer.
    mysql-test/r/join_outer.result
      Changes in order of results from a few queries, re-recorded. Updated cost
      numbers in EXPLAIN JSON.
    mysql-test/r/join_outer_bka.result
    mysql-test/r/join_outer_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/key.result
      Updated Last_query_cost numbers.
    mysql-test/r/key_diff.result
      One query changes from using join buffering to ref access. The new plan
      has also been accepted as plan for this query before, so just use it.
    mysql-test/r/myisam.result
      One query changes from table scan to range scan, likely due to use of
      magic constants when calculating cost of table scan.
    mysql-test/r/myisam_explain_json_non_select_all.result
    mysql-test/r/myisam_explain_json_non_select_none.result
      Updated cost numbers in EXPLAIN JSON plus two rows estimates in explain.
    mysql-test/r/myisam_icp.result
    mysql-test/r/myisam_icp_all.result
    mysql-test/r/myisam_icp_none.result
      Changes to query plans for two bugs that was reported for InnoDB.
      Accepted changes since the plan is still the same when run with
      InnoDB.
    mysql-test/t/opt_costmodel.test
    mysql-test/r/opt_costmodel.result
    mysql-test/t/opt_costmodel_[1;31mflush[m.test
    mysql-test/r/opt_costmodel_[1;31mflush[m.result
      Updated to use new cost numbers, updated result files.
    mysql-test/r/opt_costmodel_restart.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/opt_hints.result
      Changes from ref access to range access. Does not affect purpose of test
    mysql-test/t/opt_hints_subquery.test
    mysql-test/r/opt_hints_subquery.result
      A lot of changes to explain output:
      -Most of the changes are from using join buffer to ref access (ok)
      -Some changes are in join order (ok)
      -Some changes are in semijoin strategy; adjusted test cases so hints
       are used according to original purpose of tests.
    mysql-test/r/order_by_all.result
    mysql-test/r/order_by_icp_mrr.result
    mysql-test/r/order_by_none.result
      Two queries joining three tables changes join order. The new query plans are
      equal to earlier query plans, so no attempt on reproducing current query
      plans.
    mysql-test/r/partition.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/partition_locking.test
    mysql-test/r/partition_locking.result
      Many queries changed from doing index scan to range scan. Adjusted
      the queries to use index scan. For the last query, the plan change
      is accepted since it is the same as the initial query plan.
    mysql-test/t/partition_pruning.test
    mysql-test/r/partition_pruning.result
      Two queries changed from table scan to range scan. Adjusted queries
      to produce same plan.
    mysql-test/r/range_all.result
    mysql-test/r/range_icp.result
    mysql-test/r/range_icp_mrr.result
    mysql-test/r/range_mrr.result
    mysql-test/r/range_mrr_cost.result
    mysql-test/r/range_none.result
    mysql-test/r/range_with_memory_limit.result
      Change in three query plans. The first is due to range scan becoming cheaper
      than table scan, and join buffering is no longer considered. The two last is
      Change in join order due to differences in cost estimate for ref access
      versus join buffering. The new plan is more similar to initial plan for
      these two queries.
    mysql-test/include/select.inc
    mysql-test/r/select_all.result
    mysql-test/r/select_all_bka.result
    mysql-test/r/select_icp_mrr.result
    mysql-test/r/select_icp_mrr_bka.result
      Two identical queries switches from using join buffering to use ref access.
      Change accepted since ref access was the original join method for these
      queries.
    mysql-test/r/select_none.result
    mysql-test/r/select_none_bka.result
    mysql-test/r/select_none_bka_nixbnl.result
      In addition to the two queries above, a third query changes from table
      scan to range scan due to range access is cheaper with all data in memory.
      Accepted new plan since range scan was the origianal plan when the bug
      was first fixed.
    mysql-test/r/select_all_bka_nixbnl.result
    mysql-test/r/select_icp_mrr_nixbnl.result
      Updated result file after adding sorted_result for two queries in select.inc
    mysql-test/t/select_safe.test
    mysql-test/r/select_safe.result
      Adjusted value for max_join_size to make query fail.
    mysql-test/t/single_delete_update.test
    mysql-test/r/single_delete_update.result
      Two limit queries changed from doing file sort to using index. The
      test assumed that is should use filesort, so increased the limit to
      produce original query plan. Needed to adjust some other parts of
      the test due to this.
    mysql-test/r/status.result
      Updated Last_query_cost numbers.
    mysql-test/r/subquery_all.result
    mysql-test/r/subquery_all_bka.result
      Five queries have changes in query plans:
      -Change from using join buffer to ref access due to ref access is less costly
       with all data in memory buffer.
      -Join order changes due to minor changes in cost estimates, the new
       plan is identical to a former plan for this query.
      -Last three queries change from using join buffering to use ref access
       due to ref access is less costly with data in memory. The query plan for
       these queries has changed several times so no effort on reproducing
       original plan.
    mysql-test/r/subquery_all_bka_nixbnl.result
      Join order changes for one query due to minor changes in cost estimates,
      the new plan is identical to a former plan for this query.
    mysql-test/r/subquery_mat_all.result
      Several queries changes from using DuplicateWeedout to FirstMatch due
      to the cost of FirstMatch reading data is now lower compared to using
      the temporary table. The query plan for these queries have changed
      several times so no attempt on reproducing original query plan.
    mysql-test/r/subquery_nomat_nosj.result
    mysql-test/r/subquery_nomat_nosj_bka.result
    mysql-test/r/subquery_none.result
    mysql-test/r/subquery_none_bka.result
      Join order changes for two queries due to minor changes in cost estimates.
    mysql-test/r/subquery_nomat_nosj_bka_nixbnl.result
    mysql-test/r/subquery_none_bka_nixbnl.result
      Join order change for one query due to minor changes in cost estimates.
    mysql-test/r/subquery_sj_all.result
    mysql-test/r/subquery_sj_all_bka.result
    mysql-test/r/subquery_sj_all_bka_nixbnl.result
    mysql-test/r/subquery_sj_all_bkaunique.result
      About 25 queries has changes in query plans:
      -Materialization to FirstMatch: FirstMatch becomes cheaper due to the
       cost of reading the data when it is in memory is now lower
      -Materialization to DupsWeedOut: Some of the changes are due to
       materialization and dupsweedout having the exact same cost and the change
       is caused by rounding errors. In a few cases, the cost of DupsWeedOut
       is now lower than Materialization.
      -DupsWeedout to FirstMatch: FirstMatch benefits more from having all
       data in a memory buffer
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer
    mysql-test/r/subquery_sj_dupsweed.result
    mysql-test/r/subquery_sj_dupsweed_bka.result
    mysql-test/r/subquery_sj_dupsweed_bka_nixbnl.result
    mysql-test/r/subquery_sj_dupsweed_bkaunique.result
      A few queries have changes in query plan, no changes in semi-join strategy:
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
    mysql-test/r/subquery_sj_firstmatch.result
    mysql-test/r/subquery_sj_firstmatch_bka.result
    mysql-test/r/subquery_sj_firstmatch_bkaunique.result
      A few queries have changes in query plan, no change in semi-join strategy:
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
    mysql-test/r/subquery_sj_firstmatch_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/subquery_sj_loosescan.result
    mysql-test/r/subquery_sj_loosescan_bka.result
    mysql-test/r/subquery_sj_loosescan_bka_nixbnl.result
    mysql-test/r/subquery_sj_loosescan_bkaunique.result
      A few queries have changes in query plan, no change in semi-join strategy:
      -Join order: due to changes in cost estimates, verified that current
       plan is not the same as origianal plan, so just re-recorded.
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
    mysql-test/r/subquery_sj_mat.result
    mysql-test/r/subquery_sj_mat_bka.result
    mysql-test/r/subquery_sj_mat_bka_nixbnl.result
    mysql-test/r/subquery_sj_mat_bkaunique.result
      A few queries have changes in query plan:
      -Join order: due to changes in cost estimates, verified that current
       plan is not the same as origianal plan, so just re-recorded.
      -Join method: Changing from using join buffer to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory buffer.
       This causes changes to join order.
      -One query changes from MaterializeLookup to MaterializeScan.
    mysql-test/r/subquery_sj_mat_nosj.result
      A few queries change from using join buffer to use eq_ref or ref:
      eq_ref and ref get a lower cost when all data is in a memory buffer. This
      causes changes to join order.
    mysql-test/r/subquery_sj_none.result
    mysql-test/r/subquery_sj_none_bka.result
    mysql-test/r/subquery_sj_none_bkaunique.result
      One query changes from using join buffer to use eq_ref or ref:
      eq_ref and ref get a lower cost when all data is in a memory buffer. This
      causes changes to join order.
    mysql-test/r/subquery_sj_none_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/type_blob.result
      Change from ALL to ref_or_null.  Back to plan before switch to InnoDB
    mysql-test/r/type_ranges.result
      Order of warnings changed for an INSERT INTO SELECT statement likely due
      to plan change. Re-recorded result file.
    mysql-test/r/user_var.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/engines/iuds/r/insert_calendar.result
    mysql-test/suite/engines/iuds/t/insert_calendar.test
      Different plans for MyISAM and InnoDB caused different number of warnings.
      Changed start date for range for query to avoid warnings for zero date.
    mysql-test/suite/gcol/inc/gcol_ins_upd.inc
    mysql-test/suite/gcol/r/gcol_ins_upd_innodb.result
    mysql-test/suite/gcol/r/gcol_ins_upd_myisam.result
      Added sorted_result to some queries to handle that the order of the
      result changes. This happened for the MyISAM test, the InnoDB test
      had the same order.
    mysql-test/suite/gcol/r/gcol_keys_innodb.result
    mysql-test/suite/gcol/r/gcol_keys_myisam.result
      Changed plans from table scan to index usage
    mysql-test/suite/gcol/r/gcol_select_myisam.result
      One query changes join order and switches from join buffering to ref
      access.
    mysql-test/suite/gcol/r/gcol_select_innodb.result
      One query changes from using join buffering to do ref access. This is
      caused by table scan becoming relatively more costly compared to ref
      access.
    mysql-test/suite/innodb/t/innodb_mysql.test
    mysql-test/suite/innodb/r/innodb_mysql.result
      Added extra rows to a few tables to preserve original query plan.
    mysql-test/suite/innodb/include/query_workload_itt.inc
    mysql-test/suite/innodb/r/optimizer_temporary_table.result
      Cost estimates of EXPLAIN JSON was unstable since one table was not used
      for a while and sometimes its pages was [1;31mflush[med from buffer pool.
      Added a query that does a table scan to ensure that pages are in buffer pool.
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/innodb_gis/r/create_spatial_index.result
    mysql-test/suite/innodb_gis/r/rtree.result
    mysql-test/suite/innodb_gis/r/rtree_multi_pk.result
      Changes in query plans from full table/index scan to range scan
      Queries will now actually use a spatial index
    mysql-test/suite/innodb/r/temporary_table.result
    mysql-test/suite/innodb/r/temporary_table_optimization.result
    mysql-test/suite/innodb_zip/r/wl6469.result
    mysql-test/suite/innodb_zip/r/wl6560.result
      A few queries changes from table scan to range scan due to use of magic
      constants in the cost model for table scan.
    mysql-test/suite/innodb_fts/r/opt.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/json/r/json_agg.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/opt_trace/r/bugs_no_prot_all.result
    mysql-test/suite/opt_trace/r/bugs_ps_prot_all.result
      Updated cost estimate numbers in optimizer trace output.
      There are a few minor changes in the optimizer trace output
      and a few plan changes.
    mysql-test/suite/opt_trace/r/bugs_no_prot_none.result
    mysql-test/suite/opt_trace/r/bugs_ps_prot_none.result
    mysql-test/suite/opt_trace/r/fulltext.result
    mysql-test/suite/opt_trace/r/general2_no_prot.result
    mysql-test/suite/opt_trace/r/general2_ps_prot.result
    mysql-test/suite/opt_trace/r/general_no_prot_none.result
    mysql-test/suite/opt_trace/r/general_ps_prot_none.result
    mysql-test/suite/opt_trace/r/range_no_prot.result
    mysql-test/suite/opt_trace/r/range_ps_prot.result
      Updated cost estimate numbers in optimizer trace output.
      There are a few tiny minor change in the optimizer trace output.
    mysql-test/suite/opt_trace/r/charset.result
    mysql-test/suite/opt_trace/r/eq_range_statistics.result
    mysql-test/suite/opt_trace/r/filesort_pack.result
    mysql-test/suite/opt_trace/r/filesort_pq.result
    mysql-test/suite/opt_trace/r/general_no_prot_all.result
    mysql-test/suite/opt_trace/r/general_ps_prot_all.result
    mysql-test/suite/opt_trace/r/subquery_no_prot.result
    mysql-test/suite/opt_trace/r/subquery_ps_prot.result
    mysql-test/suite/opt_trace/r/temp_table.result
      Updated cost estimate numbers in optimizer trace output.
    mysql-test/suite/opt_trace/r/security_no_prot.result
    mysql-test/suite/opt_trace/r/security_ps_prot.result
      Updated length numbers for optimizer trace output.
    mysql-test/suite/parts/r/partition_icp.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/sysschema/r/pr_statement_performance_analyzer.result
      Changed query plans give different number for rows_examined
    mysql-test/suite/sys_vars/r/max_join_size_func.result
    mysql-test/suite/sys_vars/r/sql_big_selects_func.result
    mysql-test/suite/sys_vars/t/max_join_size_func.test
    mysql-test/suite/sys_vars/t/sql_big_selects_func.test
      Reduced value for max_join_size to make queries fail with new cost constants.
    mysql-test/suite/test_service_sql_api/r/test_sql_stmt.result
      Changed result order due to different access method
    mysql-test/suite/i_main/r/bug18932813.result
    mysql-test/suite/i_main/r/derived.result
    mysql-test/suite/i_main/r/explain_json.result
    mysql-test/suite/i_main/r/group_by.result
    mysql-test/suite/i_main/r/partition_icp.result
    mysql-test/suite/i_main/r/subquery_mat_cost_based.result
    mysql-test/suite/i_main/r/view.result
      Updated cost numbers in EXPLAIN JSON.
    .../mysql-test/suite/i_main/r/bug22671573.result
      Plan changed from table scan to range scan.
      Verified that test case still reproduce the original bug.
    .../mysql-test/suite/i_main/r/costmodel_planchange.result
      Adjust queries to still identify plan changes
    .../mysql-test/suite/i_main/t/insert.test
    .../mysql-test/suite/i_main/r/insert.result
      Added data to keep same query plan
    .../mysql-test/suite/i_main/t/subquery-bug22262843.test
    .../mysql-test/suite/i_main/r/subquery-bug22262843.result
      Added a row so that subquery materialization is still used.
    .../mysql-test/suite/i_main/t/subquery.test
    .../mysql-test/suite/i_main/r/subquery.result
      Added data to keep on query plan
      Some changes from table scan (with BNL) to ref access
      Some semijoin strategy changes that seems reasonable
    .../mysql-test/suite/i_opt_trace/include/bugs.inc
      Added analyze table to make test stable
    .../mysql-test/suite/i_opt_trace/r/bugs_no_prot.result
    .../mysql-test/suite/i_opt_trace/r/bugs_ps_prot.result
    .../mysql-test/suite/i_opt_trace/r/query_cache_trace.result
      Updated cost numbers in EXPLAIN JSON.
    .../mysql-test/suite/i_opt_trace/r/refaccess_trace.result
      One query plan goes from table scan to eq_ref
      Updated cost numbers in EXPLAIN JSON.
    
    Implemented by Olav Sandstå

[33mcommit 48379ac284466c37af5784cea3b25ec3b88d4e49[m
Author: Catalin Besleaga <catalin.besleaga@oracle.com>
Date:   Tue Sep 27 15:53:21 2016 +0200

    WL#8413: expose COM STMT EXECUTE to plugins
    
    Moved the packet parsing and creation of commands(COM_STMT_EXECUTE,
    COM_STMT_FETCH, COM_STMT_SEND_LONG_DATA, COM_STMT_PREPARE,
    COM_STMT_CLOSE, COM_STMT_RESET) to the Protocol classes as this is
    protocol-dependent, this way enabling PROTOCOL_PLUGINs to execute
    prepared statements.
    
    - added stack-like mechanism for switching between protocols
    - added store_ps_status to the protocol interface for sending the
    statement id and the metadata related to the newly created prepared
    statement
    - added send_parameters to the protocol interface for sending the out
    parameters to the client
    - added the [1;31mflush[m method to the protocol interface to send the current
    stream to the clients (used by the classic protocols).
    - added mysql_stmt_precheck to validate the PS
    - added a send_statement method to sql_prepare

[33mcommit b642224e901a7ea9cf081e56db029a2f0a9fb428[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Wed Nov 9 00:46:26 2016 -0600

    Post-Fix for Bug#24916359 - Test Case table_encrypt_kill.test fails sporadically
    The code must prevent recovery when a different innodb-undo-directory is set.
    Move the fil_[1;31mflush[m, fil_close & fil_free of undo tablespaces that were opened
    during redo discovery to the most appropriate place, fil_space_undo_check_if_opened().

[33mcommit 9146bf9601889bc17270af473481a9d457ae0541[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Mon Oct 31 22:00:32 2016 -0500

    Bug#24916359 - Test Case table_encrypt_kill.test fails sporadically
    
    The failure would occur after a crash, after redo log recovery.
    Redo recovery would open an undo tablespace from the MLOG_FILE_NAME
    log entry.  Later in srv_undo_tablespace_init(), srv_undo_tablespace_open()
    will skip this file since it has already been opened. Instead, it used the
    previous fil_space_t object. But for some reason the node->size would
    sporadically be zero. This zero size causes the reported error during a
    later call to fil_io().
    
    The fil_space_t object created by redo log recovery has other problems.
    It uses the file name as the tablespace name, which includes the path.
    And it does not know that this is an undo tablesapce so it puts the
    object onto the LRU, which it should not be.  There may be other issues
    with this object as well.
    
    The solution is to not only [1;31mflush[m and close that fil_space_t object but
    to also free it. This allows srv_undo_tablespaces_open() to create a new
    one correctly. It is reopened from scratch with a new fil_space_t object
    as if it was not part of redo log recovery, which is already completed by
    this time during startup.
    
    In addition, testing has shown that it is possible for the header page
    of this undo tabelspace to be in the buffer cache when the fil_space_t
    object is freed.  The presence of this page in cache can cause the file
    not to be opened upon the first page read and then an assert in fil_io()
    can be hit when the file is not yet opened.  So fil_undo_tablespace_open()
    will now call fil_space_open() after it has successfully created the
    fil_space_t and fil_node_t objects and incremented srv_undo_tablespaces_open.

[33mcommit 01c194726c75c2ce1ef894e00e3a815ef1e25d9f[m
Author: Darshan M N <darshan.m.n@oracle.com>
Date:   Fri Oct 21 14:52:50 2016 +0530

    Bug#24658707 ASSERT: BUF0BUF.CC:2469:BUF_BLOCK_GET_STATE(BLOCK)
    == BUF_BLOCK_FILE_PAGE
    
    Issue
    =====
    The issue is that during commit_inplace_alter_table we wake up the purge
    thread and we take a btr search latch and try to disable the adaptive hash
    search system and empty the index. The purge operation happening in the
    background, when [1;31mflush[ming the pages, tries to remove possible adaptive hash
    index on the page and it sets the the block state as BUF_BLOCK_REMOVE_HASH
    and waits on the btr search latch taken by the alter command. And in the
    alter command when we're trying to empty the hash index of the same block
    we hit the assertion ut_ad(buf_block_get_state(block) ==
    BUF_BLOCK_FILE_PAGE) as the block state was changed by the purge operation.
    Both the threads would be working on the same block at the time of
    assertion.
    
    Fix
    ===
    The workaround solution for now is to remove the debug assert.
    
    RB: 14344
    Reviewed-by: Jimmy Yang <Jimmy.Yang@oracle.com>

[33mcommit f2bc0f89b7f94cc8fe963d08157413a01d14d994[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Wed Aug 10 17:41:28 2016 +0200

    WL#8688: Support ability to persist SET GLOBAL settings
    
    This WL introduces an option to persist global dynamic configuration variables,
    for example like SET PERSIST innodb_[1;31mflush[m_log_at_timeout= 14;. Configuration
    variables over a connection are lost after server restart. This WL provides
    DBAs a way to store configuration variables in a persistent way and allow
    server to read and apply all those variables which are persisted during a
    restart. A new config file name mysqld-auto.cnf will be created in datadir
    when a variable is persisted. This new config file is in JSON format.
    
    In addition to the persistence we add a performance schema table called
    "variables_info" which will have an entry for all configuration variables.
    This table will also have information about where the current value came
    from and some additional information about the variable. The historical
    configuration files can be used as before.
    
    This WL provides a read only system variable named persisted-globals-load
    which provides an option to enable/disable reading of persistent config file.

[33mcommit 7f9b14de3d63390019fb50f7fdabc1e94eb3852f[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Tue Aug 9 07:37:37 2016 +0200

    WL#8688: Support ability to persist SET GLOBAL settings
    
    This WL introduces an option to persist global dynamic configuration variables,
    for example like SET PERSIST innodb_[1;31mflush[m_log_at_timeout= 14;. Configuration
    variables over a connection are lost after server restart. This WL provides
    DBAs a way to store configuration variables in a persistent way and allow
    server to read and apply all those variables which are persisted during a
    restart. A new config file name mysqld-auto.cnf will be created in datadir
    when a variable is persisted. This new config file is in JSON format.
    
    In addition to the persistence we add a performance schema table called
    "variables_info" which will have an entry for all configuration variables.
    This table will also have information about where the current value came
    from and some additional information about the variable. The historical
    configuration files can be used as before.
    
    This WL provides a read only system variable named persisted-globals-load
    which provides an option to enable/disable reading of persistent config file.

[33mcommit 22bdf56c4216fc542267211d2e00a6d1cf1cfbe7[m
Author: Allen Lai <zheng.lai@oracle.com>
Date:   Wed Aug 3 18:52:42 2016 +0800

    Followup patch for bug#24329079 Crash with InnoDB Encryption, 5.7.13,
    FusionIO & innodb_[1;31mflush[m_method=O_DIRECT
    
    Fixed test case sys_vars.innodb_[1;31mflush[m_method_unix failure by adding.
    suppression

[33mcommit 625fd728a748a43503af84b53d0b8c6cddacac31[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon Aug 1 11:22:53 2016 +0200

    Patch for Bug#20112700 ASSERT(SHOULD_BE_EMPTY) IN \'RESET_SEND_BUFFER\'
    
    Assert in TransporterFacade::reset_send_buffers as send buffers
    were not empty as expected when reconnected to a node after
    a previous disconnect
    
    TransporterFacade::reset_send_buffer() reset the two-level
    send buffers in the TransporterFacade. Whenever a node
    disconnected from the TransporterFacade, its send buffers
    are reset (cleared). In addition to TransporterFacade
    send buffers, each trp_client has its own send buffers
    (Introduced as part of the 'ATC-patches', wl3860). These
    were introduced in order to reduce lock contention as each
    trp_client appends to the send buffers. However, the
    trp_client's send buffers were *not* cleared as part
    of TransporterFacade::reset_send_buffer().
    
    As the trp_client appended its send buffers to the
    TransporterFacade send buffers whenever it found fit,
    we could either:
    
    1) Append the trp_clients send buffer to the TransporterFacade
       after a node had disconnected. When it reconnected
       again, we found the TransporterFacade had a non-empty send buffer
       to the reconnected node which resulted in the assert in
       this bug-subject.
    
    2) (Possibly, but not proved:) The trp_client send buffers could
       be [1;31mflush[med to the TransporterFacade after the node had
       disconnected *and reconnected* again. I am not sure what
       this could cause of strange behavior, but it would certainly not
       be very healthy for the system.
    
    This patch enhance TransporterFacade::reset_send_buffer() to also
    reset the send_buffers of the trp_clients being known to
    the TransporterFacade. In order to provide concurrency protection
    of the TransporterFacade's set of trp_clients, this has to
    be done while holding the poll right: Thus, the call to
    ::reset_send_buffer() had to be moved from TransporterRegistry::do_connect()
    to TransporterRegistry::report_disconnect(). (Note ::report_disconnect()
    and ::report_connect() is only called by the poll owner!).
    
    Furthermore, the odd call to ::reset_send_buffer(..., should_be_empty=true)
    from within ::report_connect() has been removed. That call was mainly
    a safeguard / assert against send buffers not being empty when we
    reconnected again. At this point the send buffers should be empty,
    so an extra reset is redundant. If not empty, it would assert at this
    point. This call to reset_send_buffer was replaced with an assert check
    of the send buffers really being empty (!has_data_to_send()). (Required
    a few non used implementations of the virtual ::has_data_to_send()
    to be fixed), The now non used argument 'should_be_empty' to
    reset_send_buffer() was removed as part of this.
    
    The patch also fix an issue with
    TransporterFacade::m_current_send_buffer_size neither being
    initialized by the C'tor, correctly updated by ::[1;31mflush[m_send_buffer(),
    nor zero'ed by ::reset_send_buffer().

[33mcommit cbdc8784551fe8bf1ce2b7f4d765f8dbc3ed4d3c[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Wed Jun 15 11:30:40 2016 +0530

    WL#9359 - Instrument all background threads. Record test.
    
    page_cleaner_thread_key split into:
     page_[1;31mflush[m_coordinator_thread_key
     page_[1;31mflush[m_thread_key
    
    Move [1;31mflush[m thread creation to [1;31mflush[m init code.

[33mcommit a0df293b90844a2534b4caa90f0fca81ee66097c[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jun 10 13:31:28 2016 +0200

    Fix failing ATR test: 'testSpj -n MixedJoin':
    
    The test utilit function runJoin() had the option to
    set the property 'InsertError' which in case specified
    were used as ERROR_INSERT value. When runJoin() completed
    it *unconditionally* inserted a '0' error in order to clean
    any error prev. inserted.
    
    The testcase MixedJoin ran 6 steps of this testcase in parallel
    *without* any InsertError property being specified. However,
    the last error=0 where nevertheless always set.
    
    The implementation if error insert always send a SYNC_REQ
    signal after an error insert in order to '[1;31mflush[m' it
    to all Ndb blocks. This signal is routed via the block proxy
    which have only 4 slots for outstandig SYNC_REC signal.
    If this limit is exceeded it will crash in LocalProxy.hpp line 217.
    
    As an error insert sets the error globally for all clients connected
    to the datanode, such parall setting of error inserts have never
    been an intended part of what we support. Thus it should be avoided.
    (STEPS == 1 whenever an error is inserted)
    
    This patch makes the 0 error insert conditionally, such that
    the proxy slots for SYNC_REQ are not exhaused.

[33mcommit db7dad4a67c344107f0203581500925065cec676[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Wed May 4 09:58:03 2016 +0800

    Followup: BUG#23102834 INNODB: ZERO FLUSH FROM LRU
    
    Remove buf_lru_[1;31mflush[m_batch.test because it's difficult to have
    predictable result.
    
    Approved by Deb over IM

[33mcommit bd914aebb3ec510784f364e5e71cd35bb8a0cad5[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Thu Apr 28 16:28:07 2016 +0800

    BUG#23102834 INNODB: ZERO FLUSH FROM LRU
    
    It's a regression of wl#8423 InnoDB: Split the buffer pool mutex.
    we wrongly removed the count for lru [1;31mflush[ming in buf_[1;31mflush[m_batch().
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 12509

[33mcommit 65649a16ce9412f7d9286e7e6ad6c2de5769be25[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Thu Apr 21 13:34:00 2016 +0800

    BUG#23067038 ASSERTION FAILURE: BUF0BUF.CC:2861:BUF_PAGE_IN_FILE(BPAGE)
                 LEADS TO CORRUPT DATA
    
    It's a regression of wl#8423 InnoDB: Split the buffer pool mutex,
    in which we removed block mutex protection for buf_fix_count.
    
    The assertion happens when one thread fixed a dirty block but the
    other thread [1;31mflush[med the block and moved the page from LRU list to
    free list, because it saw buf_fix_count is 0, other than 1.
    
    The solution is holding block mutex when buf fix and unfix.
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 12456

[33mcommit fa49f62995e8adaae6844cae9315781c7a432f39[m
Author: Daniel Blanchard <daniel.blanchard@oracle.com>
Date:   Fri Apr 15 11:34:24 2016 +0100

    BUG #22608247 RESULT CONTENT MISMATCH IN BINLOG.BINLOG_MYSQLBINLOG_ROW AND FRIENDS
    
    Problem:
    --------
    This is a known bug in Visual Studio 2015 C Runtime (Connect#1902345)
    https://connect.microsoft.com/VisualStudio/feedback/details/1902345
    
    The bug in _read is as follows:  If...
    
    1.       you are reading from a text mode pipe,
    2.       you call _read to read N bytes,
    3.       _read successfully reads N bytes, and
    4.       the last byte read is a carriage return (CR) character,
    
    then the _read function will complete the read successfully but will
    return N-1 instead of N.  The CR or LF character at the end of the result
    buffer is not counted in the return value.
    
    The bug is fundamentally timing-sensitive because whether _read can
    successfully read N bytes from the pipe depends on how much data has been
    written to the pipe.  Changing the buffer size or changing when the buffer
    is [1;31mflush[med may reduce the likelihood of the problem, but it won't
    necessarily work around the problem in 100% of cases.
    
    Fix:
    ----
    The workaround is to use a binary pipe and do text mode CRLF => LF translation
    manually on the reader side.
    
    Note that this workaround should no longer be necessary when the next
    update to the Universal CRT ships, which is likely to occur around the same
    time as the Windows 10 Anniversary Update this summer (2016).
    
    Reviewed-By: Bjorn Munch <bjorn.munch@oracle.com>
    RB: 12384

[33mcommit 2bcc00d11f21fe43ba3c0e0f81d3d9cec44c44a0[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Tue Mar 29 12:10:56 2016 +0800

    wl#8423 InnoDB: Split the buffer pool mutex
    
    1. Introduce several new list/hash protecting mutexes, and access without any
    mutex to several variables. The new mutexes are:
      - LRU_list_mutex for the LRU_list;
      - zip_free mutex for the zip_free arrays;
      - zip_hash mutex for the zip_hash hash and in_zip_hash flag;
      - free_list_mutex for the free_list and withdraw list;
      - [1;31mflush[m_state_mutex for init_[1;31mflush[m, n_[1;31mflush[m, no_[1;31mflush[m arrays.
    
    2. The variables switched from buffer pool mutex protection to atomic operations
    and/or os_rmb/os_wmb.
      - srv_buf_pool_old_size
      - srv_buf_pool_size
      - srv_buf_pool_curr_size
      - srv_buf_pool_base_size
      - buf_pool->buddy_stat[i].used
      - buf_pool->curr_size, n_chunks_new.
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    Reviewed-by: Allen Lai        <zheng.lai@oracle.com>
    RB: 9797

[33mcommit 707fd3af81b44117f44ba91f1f307506122a4840[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Mar 10 14:29:04 2016 +0800

    Bug#21352937 - REDUCE LOG_SYS->MUTEX CONTENTION BY ALLOWING CONCURRENT
    MTR COMMIT AND LOG WRITE
    
    All mtr commits would have to wait for writing/[1;31mflush[ming redo logs to disk
    in log_write_up_to(). The wait is unnecessary. In this patch, we introduced
    one more log buffer and one mutex.
    
    We always write logs to one log buffer, keeping the other idle. Once we
    need to [1;31mflush[m it, we switch these two buffers, so log_write_up_to() would
    take over the to be [1;31mflush[med buffer and do the [1;31mflush[m job, once the [1;31mflush[ming
    finishes, this buffer becomes the idle one. At the mean time of [1;31mflush[ming,
    all concurrent mtr commits would see the empty new buffer and write logs
    there, even after the [1;31mflush[ming, logs are still writing to this buffer
    before it needs to be [1;31mflush[med.
    
    Let's say we have two adjacent log buffer A and B, at first, all logs are
    written to A, keeping B as empty. Once we want to [1;31mflush[m logs in A, we will
    switch A and B, which is under the protection of current log_sys->mutex.
    Then all logs are now written to B, while A is getting [1;31mflush[med and becomes
    empty and idle. When B is needed to be [1;31mflush[med, we now switch A and B again,
    new commits will come to A, and [1;31mflush[ming of B won't stop the concurrent
    mtr commits. And so on.
    
    The new introduced mutex is mainly used to protect the process of
    log_write_up_to().
    
    The original patch was provided by Weixiang Zhai.
    
    RB: 11142
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>

[33mcommit 157562271416468eb7a52d4fc79236fac6708ac2[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Mon Feb 29 16:06:54 2016 -0600

    Bug 22361764: ASSERT AT NODE->MODIFICATION_COUNTER == NODE->FLUSH_COUNTER
    
    As a result of the following patch alter_kill is failing intermittently:
    
    Commit:      7185d836d074b5ca899c351edbff19d6084e0c40 [7185d83]
    Parents:     e22da5c44e
    Author:      Marko M??kel?? <marko.makela@oracle.com>
    Date:        April 28, 2015 at 3:43:57 AM CDT
    Bug#20961660 RPL TESTS ARE FAILING WITH INNODB:
         UNDO TABLESPACES MUST BE READABLE!
    srv_undo_tablespaces_init(): Close any opened undo tablespace files
    before opening the undo tablespaces.
    fil_space_open(), fil_space_close(): Take a numeric space_id instead of
    tablespace name as a parameter.
    RB:          8735
    Reviewed-by: Kevin Lewis <kevin.lewis@oracle.com>
    Reviewed-by: Mattias Jonsson <mattias.jonsson@oracle.com>
    
    The call stack indicates that the attempt to
    "Close any opened undo tablespace files before opening the
    undo tablespaces" is crashing because there are buffered
    changes to one of the undo tablespaces.
    PB2 indicates that this intermittent crash happens on a variety
    of platforms, not just Windows.
    
    So when srv_start() calls srv_undo_tablespaces_init(), the recovery process
    has already made some new entries into one of the undo tablespaces that
    now needs to be closed by srv_undo_tablespaces_init().
    Note that the patch above added this new call to fil_space_close().
    
    Add     fil_[1;31mflush[m(undo_tablespace_ids[i]);
    just before     fil_space_close(undo_tablespace_ids[i]);
    
    Approved by Marko in rb#11966

[33mcommit dcb8792b371601dc5fc4e9f42fb9c479532fc7c2[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Nov 19 17:11:50 2015 +0800

    WL#6204 - InnoDB persistent max value for autoinc columns
    
    This worklog makes use of the framework introduced by WL#7816 to persist
    the autoinc counters. After this worklog there would be some behaviour
    changes or important points of autoinc counter:
    
    1. Counters of AUTO_INCREMENT should be strictly incremental, as it works
    now, when the server is running.
    
    2. Allocated counters won't be reused after the server restart normally,
    this must be guaranteed.
    
    3. Allocated counters won't be reused after the server restart from a
    crash, this can NOT be guaranteed, since we can't [1;31mflush[m the redo logs
    immediately everytime.
    
    4. Rollback of transaction won't revert the counter.
    
    5. 'ALTER TABLE' would not change the counter to a smaller value than
    current existing max counter in the table.
    
    6. If a counter is updated to some larger value than current next value,
    the larger value should be remembered and next counter should start from
    it.
    
    The persistence during DDL is not supported very well now, since some
    DDL operations are not atomic now. This would be fixed in WL#7743,
    WL#7141, and WL#7016.
    
    RB:9138
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Marko Makela <marko.makela@oracle.com>

[33mcommit 5e2faa44fff9dd5dd464044bcf61d77c879c1eb7[m
Merge: 5ec1eb47c67 43a3d972888
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Aug 20 09:09:54 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      WL#8756  Deprecate binlog_max_[1;31mflush[m_queue_time in 5.7
      Bug#21506237 SIG11 AT QUERY_ARENA::STRMAKE IN SQL/SQL_CLASS.H:216
      Bug#21506237 SIG11 AT QUERY_ARENA::STRMAKE IN SQL/SQL_CLASS.H:216
      Bug#21541481 MEMORY LEAK OF ALLOCATIONS MADE IN VAL_JSON_FUNC_FIELD_SUBSELECT
      Bug#21560934 CHANGE THE NAME OF JSON_APPEND() TO JSON_ARRAY_APPEND()
      Bug#21560934 CHANGE THE NAME OF JSON_APPEND() TO JSON_ARRAY_APPEND()
      Bug #21498544: mysqld --initialize should not complain about lack of ssl certs
      Bug #21498544: mysqld --initialize should not complain about lack of ssl certs
      Small change to default config for Docker-specific rpm package Syncs "official" and our own Docker images
      Bug #20201006 spamming show processlist prevents old connection threads from cleaning up.
      Bug#21451922 - FOUND A MISMATCH PAGE, EXPECT PAGE - ASSERTION
      Doxygen warnings elimination.
      - Bug#21629618: RECOVERY FAILURE: PLUGIN 'INNODB' INIT FUNCTION RETURNED ERROR
      Bug#21616585 ASSERTION FAILED: !(DECIMAL_IS_ZERO(FROM2) && FROM2->SIGN)
      Bug #20625566:   SHOW CREATE USER ALLOWS ACCESS TO OTHER USERS PASSWORD HASH
      Bug# 20625566:   SHOW CREATE USER ALLOWS ACCESS TO OTHER USERS PASSWORD HASH
      - Bug#21629618: RECOVERY FAILURE: PLUGIN 'INNODB' INIT FUNCTION RETURNED ERROR
      Bug#21557723 CAN'T USE OUTPUT OF 'SHOW CREATE TABLE' TO CREATE A NEW TABLE

[33mcommit 206b7bdbc114e7505fb52d8349a4433be22caf48[m
Merge: 8358d59e0ed 7d8937daf6f
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Jul 13 19:17:19 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      BUG#21389101 ST_GEOMFROMGEOJSON: STACK OVERFLOW IN RAPIDJSON::GENERICREADER
      Bug#21383284: ASSERTION IN SELECT_LEX::SETUP_CONDS
      BUG#21303289  Removed sqlbench leftover in deb platform pkg src
      BUG#21434004   UBUNTU 15.04 REPO PACKAGES DO NOT CONTAIN ESSENTIAL SCRIPT LIKE MYSQLD_SAFE list of files being re-installed in server pkg: +usr/bin/mysqlbinlog +usr/bin/mysqld_multi +usr/bin/mysqld_safe
      Remove MCP_GLOBAL_SCHEMA_LOCK patch
      Fix syntax error in ndbinfo_sql.cpp
      Fixed mysql_ssl_rsa_setup test failing on Windows after pushing bug fix for bug#21025377
      BUG#21280816 CONNECTION PERFORMANCE REGRESSION TEST HANGS SYSBENCH
      Keep ndbinfo_sql.ccp in sync with mysql_system_tables.sql
      Remove unintentional change in variables-big.test
      Bug #20168526 YASSL: CORRUPT SSL-KEY CRASHES CLIENT
      Version change in d/changelog for DEB pkg src 5.7.9+ are non-rc releases
      - Bug#21407023: DISABLING AHI SHOULD AVOID TAKING AHI LATCH   Currently if AHI is disabled check for it was protected by AHI latch which   caused latch overhead even though the feature is not adding any value.
      Bug#21429471 - COMMUNITY/COMMERCIAL EL7 UPDATE FAILING WHEN MARIADB-BENCH.X86_64 INSTALLED
      Bug #20728894: MEMORY LEAK IN ADD_DERIVED_KEY()
      Bug #21056907: CONTENTS OF NOT REQUESTED CHAR/VARCHAR                COLUMN ARE REVEALED
      Bug #20777016: DELETE CHECKS PRIVILEGES ON THE WRONG                DATABASE WHEN USING TABLE ALIASES
      Bug #18636874 PASSWORD VALIDATE PLUGIN: DICTIONARY CHECK MISBEHAVES WITH GOOD HEX INPUT
      WL#7254 Audit API extensions
      Bug#21374104 SETUP_TIMERS INITIALIZATION ASSUMES CYCLE TIMER IS ALWAYS AVAILABLE
      Bug #20087571: 5.7 EASILY HITS ERROR 1436 (HY000): THREAD STACK OVERRUN ERRORS ON MANY EXPR'S
      Bug#21383896 DECIMAL FIELD TAKES IN VALUES FROM OTHER FIELDS
      Bug#21153489 VALGRIND ERRORS IN ITEM_BOOL_FUNC2::IS_NULL LEAD TO CRASH LATER
      Fix syntax errors in 16node-tests.txt and upgrade-tests.txt
      Bug#21337139 ATRT SILENTLY STOPS TESTING AT FIRST SYNTAX ERROR IN TEST CASE FILE
      Fix a compilation error after bc098885
      Bug#21338012 MTR MANUAL-GDB OPTION DOES NOT WORK
      Bug #21280801: VERSION TOKEN LOCKING DOES NOT WORK
      BUG#21421471 LICENSE HEADERS MISSING IN FILES
      Bug#21300774 ASSERT `!INIT_FTFUNCS(THD, SELECT_LEX)` IN JOIN::RESET AT SQL/SQL_SELECT.CC:874
      Bug#21300774 ASSERT `!INIT_FTFUNCS(THD, SELECT_LEX)` IN JOIN::RESET AT SQL/SQL_SELECT.CC:874
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      BUG#20074353 HANDLE_FATAL_SIGNAL (SIG=11) IN MY_B_WRITE | MYSYS/MF_IOCACHE.C:1597
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      Addendum 2 to bug #21034322: removed the max test due to it being different for different OSes
      Follow up fix for WL#8149 change, fix create_thd() issue and test mismatches
      Merge WL#8149 related worklogs to mysql-trunk
      Bug#21271736 UNITTEST UT0CRC32-T HANGS ON SOLARIS 10 SPARC
      Bug#21381060 A "CASE WHEN" EXPRESSION WITH NULL AND AN UNSIGNED TYPE GIVES A SIGNED RESULT
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Remove non experimental test.
      Bug#18949282 I_MAIN.MYSQL_CLIENT_TEST FAILED AT LINE 43, COMMAND $I_M_C_T
      Configure smaller redo log for test ndb.ndb_backup_rate.
      Updating the test case ndb_addnode_restart* :  The autotest testSystemRestart had an additional restart loop  in runAddNodesAndRestart function, which is not needed as there  is no change in the configuration of the cluster.  Removed that and updated the name of the funcction and added few  comments to explain the proper setup of the testcase
      Fix for WL#7763
      WL#7763, remove use of inet_ntoa from ndb parts
      Post-push test fix for Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      Bug#17493646 NDB: CALL TO MY_ERROR() LACKS ERROR CODE AND ERROR STRING ARGUMENTS
      Bug#21352763 FLEXASYNC SEGFAULTS IF FAILED TO CREATE TABLES
      BUG#21297407: Fix to ensure sending CONTINUEB with proper variables in dropTable_wait_usage
      Pushing BUG#21297407 revealed an uninited variable in Fragrecord in DBLQH (lcp_frag_ord_state, was set to LCP_QUEUED == 0 in most cases which led to crash if drop table happened before LCP had time to execute
      BUG#20981491: Fix resource issues for NR, LCP andb Backup with regard to scan numbers, BUG#21362758: Crash with holding LocalDLFifoList context over call EXECUTE_DIRECT(NEXT_SCANCONF), BUG#21370839: Ensure also ACC scans are queued in a proper manner, previous push only added test case to autotest
      BUG#20981491: Fix resource issues for NR, LCP andb Backup with regard to scan numbers, BUG#21362758: Crash with holding LocalDLFifoList context over call EXECUTE_DIRECT(NEXT_SCANCONF), BUG#21370839: Ensure also ACC scans are queued in a proper manner
      BUG#20993380: (Also BUG#69994 in community bugs), ensured that node recovery and LCP scans can continue even if user has used up all resources for user level transactions, reserved operation records and segments for necessary things during LCP and NR scans
      Fix test case testRedo -n RedoFull
      Fix testRedo -n RedoFull test case
      BUG#21297407: Speed up drop table
      Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Raise version number after cloning 7.1.36
      Raise version number after cloning 7.3.10
      Raise version number after cloning 7.4.7
      Raise version number after cloning 7.2.21
      Fixed syntax errors in daily-basic-tests.txt
      Implement required methods in clusterj-openjpa
      Bug#20504741 Improve clusterj release of byte buffers by adding a user method session.release
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7570 Remove ifdefs which are not necessary since trunk has it all
      Bug #20592110         CLUSTER CIRCULAR REPLICATION WITH IGNORE_SERVER_IDS() BROKEN BY ANONYMOUS_GTIDS
      revert change to mysql-test-run
      Bug #21326540         NDB_JOIN_PUSHDOWN TESTS UNSTABLE EXECUTE_COUNT
      Remove obsolete ifdef
      Add comment re. valgrind
      WL#6815 Adapt MySQL Cluster to 5.7
      Revert "WL#6815 Adapt MySQL Cluster to 5.7"
      Removed extra blank line in ATRT test scripts preventing tests to start (Due to ATRT bug)
      Bug #17878183       NDB CONTINUOUSLY REBOOTING DUE TO FILE NOT FOUND (DBLQH:
      Bug#17493646 NDB: CALL TO MY_ERROR() LACKS ERROR CODE AND ERROR STRING ARGUMENTS
      Increase timeout for ATRT test
      Increase timeout for ATRT test
      BUG#20904721, WL#8525: Fix of part9, used internal TUP pointer instead of LQH pointer when calling LQH function directly, leads to both wrong handling and sometimes even a crash when index is not a used scan pointer
      Apply pollEvent_v4.patch from Ole John
      restore new scheduler & multiwait fix to bug branch
      If memcached crashes, mysql-test-run should not restart it.
      On misc. errors, print workitem to debug log
      always compile ndb memcache with DEBUG_OUTPUT
      More unified error handling
      New record_ndb_error() function where error logger keeps statistics but caller is resposnsible for writing to log file. Direct error messages to the debug log if enabled.
      The table scan code where NDB Memcache reads it configuration tables was written poorly, and could cause memcached to crash during configuration.
      revise debug messages in new scheduler
      switch default scheduler to Trondheim
      always compile ndb memcache with DEBUG_OUTPUT
      More unified error handling
      New record_ndb_error() function where error logger keeps statistics but caller is resposnsible for writing to log file. Direct error messages to the debug log if enabled.
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#11759461 NDB_CONFIG --XML --CONFIGINFO: VARIOUS UPDATES TO PARAMETERS LISTED
      Bug#11760628 DEPRECATE EXECUTEONCOMPUTER
      Bug #21270509         FAULTY COMMENT DESCRIBING NDB_MGM_NODE_STATE.CONNECT_ADDRESS IN MGMAPI.H
      Bug #21270425         MGMAPI.H SPELLING ERROR
      Bug#20617891: NDB : SUSPICIOUS HANDLING OF SIGNAL-WAIT TIMEOUT IN NDBAPI
      read configuration in a single consistent transaction
      The table scan code where NDB Memcache reads it configuration tables was written poorly, and could cause memcached to crash during configuration.
      Revert "Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000"
      Revert "Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000"
      Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      BUG#20904721: Fix for a number of asserts that assumed interpreted mode for all scans
      BUG#20727343: Fix failing ndb_dd_initial_lg test case, minor initialisation issue
      reapply bugfix in this branch. do not push this change to 7.4
      move another message from debug to detail level
      move another message from debug to detail level
      WL#8525: Part 11, don't use interpreted execution for LCPs and Backups since it is a waste of CPU resources
      BUG#20904721: Part 9: Implementing the adaptive LCP speed using bounded delay concepts and A-level signals
      more safety when Ndb::startTransaction() fails
      more safety when Ndb::startTransaction() fails
      add a more detailed debug output level to ndb memcache
      Anticipate SERVER_ERROR responses in My::Memcache.pm
      Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      Test case for Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      induce memcached to [1;31mflush[m its log file at end of mtr testing
      BUG#20727343: Fix problems in UNDO log applier when changing log files
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Revert of prev push for bug#20957068
      Fix for Bug#20957068:
      Post merge fixes (mysql-5.6.25 via mysql-5.6-cluster-7.3 into mysql-5.6-cluster-7.4)
      Port commit to MySQL Cluster 7.3
      Port of commit to MySQL Cluster 7.3
      Port of commit to MySQL Cluster 7.3
      Port commit to MySQL Cluster 7.3
      some additional debug output re. online reconfiguration
      Test: temporarily revert recent changes
      Bug#20730053: BACKPORT BUG#19770858 TO 5.1
      Test: temporarily revert recent changes
      Bug#20734434 - SPELLING ERROR \"EMDEDDED\" IN RPM SPEC FILES
      Bug#20788853 MUTEX ISSUE IN SQL/SQL_SHOW.CC RESULTING IN SIG6. SOURCE LIKELY
      Bug#18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Bug#21270190 REMOVE UNUSED AND DANGEROUS NDBHOST_GETHOSTNAME()
      Fix compiler warnings due to hidden inherited virtual and release-unused variables.
      Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Backport of Part 2 (of 2) of fix for Bug#18390321 to 7.2 & 7.3
      bug#17638548 Try to address test failures from previous push
      Reenable usage of send threads in MTR tests.
      Part2 (of 2) fix for Bug#18390321
      Temporarily change default MTR test config to use worker thread sending (No send threads) in order to get some regression test coverage of part1 patch for bug 18390321
      Bug #17878183         NDB CONTINUOUSLY REBOOTING DUE TO FILE NOT FOUND (DBLQH: CAUSED BY ERROR 2341)
      Part1 (of 2): Fix for Bug#18390321
      bug#17638548 In NDB Memcache 7.4 use 7.3 Scheduler by default
      bug#17638548 : reset "woken" state after wakeups
      Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Fix failing ATRT testcases:
      Increase timeout value for several failing 'testNodeRestart ... DD' tests.
      Fix failing testcase 'testNodeRestart -n GcpStop T1 --loops=1' :
      Added more printout to testcase 'testBasic -n Bug54986 D2' in order to aid in understanding why / where this test fails.
      Increase timeout for  'testNodeRestart -n Bug27003 T1' from 1800 -> 3600sec.
      Moved unstable 'basic' tests to 'devel'.
      Fix compiler warnings in patch for bug#21185585:
      fix bug in cmakelists from previous push
      Convert test_workqueue into a TAP test
      Fix for bug#21185585
      ndb memcache: recently in CLUB testing of ndb memcache suite, 7.4 consistently passes but 7.3 has many failures.  This commit swaps the default schedulers in 7.3 and 7.4 to see if that leads to any change in the pattern of test results.
      ndb memcache: change default scheduler in 7.3
      bug#21067283 Fix inconsistent space calculations in NdbRecord
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      BUG#18234170 Foreign Constraints are lost from NDB Tables during truncate
      Bug#21184102 PATCH FOR BUG#16890703 MYSQLD STUCK IN OPN TABLES ..., LOST IN 7.3 AND UPWARD Added error check for missing database directory, added testcase
      BUG#18234170 Foreign Constraints are lost from NDB Tables during truncate
      WL#8648 NDB_SHARE lifecycle improvements
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7578 Refactor schema distribution code
      WL#8648 NDB_SHARE lifecycle improvements
      Bug#21141495 NDB_MGMD USES 90% CPU
      Remove global forward declaration of Ndb_fk_data
      BUG#20095208: Fix to make portlib not dependent of ndbgeneral
      Removed compiler warning
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Only use C++ ABI functionality if libstdc++ is being linked. Otherwise resort to protect the allocation/deallocation of the static objects using the existing connection mutex.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      Patch for bug#21109605
      Removed compiler warning
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Only use C++ ABI functionality if libstdc++ is being linked. Otherwise resort to protect the allocation/deallocation of the static objects using the existing connection mutex.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      WL#8525: BUG#20904721: Part6: Improve performance of checksum calculations, remove unnecessary ones and simplify bit toggling ones. Also solves BUG#20980229 that ensures that also header bits are included in checksum calculation.
      BUG#20904721: Fix LCP processing with heavy insert activity, part 2
      Improve multi-thread use of charsetDecoder and charsetEncoder in clusterj Utility   charsetDecoder is used only in Decimal decoding   charsetEncoder is used only in Decimal encoding   charsetDecoder and charsetEncoder are not thread-safe   use charset.decode for decoding   use charset.newEncoder().encode for encoding   avoid synchronization
      bug#20095208 - UNABLE TO STORE FRAGMENT DURING LCP. NDBFS ERROR: 2812 - DBLQH (LINE: 14305)
      bug#20095208 - UNABLE TO STORE FRAGMENT DURING LCP. NDBFS ERROR: 2812 - DBLQH (LINE: 14305)
      Bug#18753887 MYSQLD STOPPED WRITING TO BINARY LOG Modifies pollEvents to return latest_GCI as NDB_FAILURE_GCI (~(Uint64)0) in case a cluster failure has been detected. An internal flag is set in NdbEventBuffer::report_node_failure_completed and the flag is reset when the next SUB_GCP_COMPLETE_REP signal is received. Test case StallingSubscriber is extended to verify that NDB_FAILURE_GCI is returned and that polling of events is resumed after the cluster is connected again and new epochs are received.
      Bug#18753887 MYSQLD STOPPED WRITING TO BINARY LOG     Modifies pollEvents to return latest_GCI as NDB_FAILURE_GCI (~(Uint64)0)     in case a cluster failure has been detected. An internal flag is set     in NdbEventBuffer::report_node_failure_completed and the flag is     reset when the next SUB_GCP_COMPLETE_REP signal is received.     Function Ndb::isExpectingHigherQueuedEpochs is added to be used together     with pollEvents2 that checks if cluster has disconnected due to failure     causing no more events to be received.     Test case StallingSubscriber is extended to verify that NDB_FAILURE_GCI     is returned and that polling of events is resumed after the cluster     is connected again and new epochs are received.
      BUG#20904721: Part 8: Fixing the NDB scheduler to work with Bounded delay signals
      Revert last merge
      Fix multi-thread use of charsetDecoder in clusterj Utility   charsetDecoder is used only in Decimal decoding   charsetDecoder is not thread-safe
      Follow up testcase fix for MCP_BUG20701918
      MCP_BUG20701918  create-old-temporals MySQLD option
      BUG#20904721: Fix of previous push
      Fix regression in debug build caused by fix for bug#20408733.
      WL#8525: BUG#20904721: Part 4, write up description of local LCP protocol and how to handle overload situations, increase to prio level A in some cases. Also standardise naming on END_LCPREQ and END_LCPCONF and remove all usages of END_LCP_REQ and END_LCP_CONF.
      BUG#20904721: WL#8525: Part 3, use prefetch to speed up scan processing for LCP scans and also other full table scans, such as node recovery scans and user level full table scans
      WL#8525: BUG#20904721: Part 7: Ensure it's not so easy to misconfigure LCPs and Backups
      BUG#21049554: Fix OM_SYNC flag to work on all platforms, not only those that support the O_SYNC flag
      WL#8525, BUG#20904721: Part1: Avoid LCP watchdog crash when scanning many pages with LCP_SKIP records
      Fix annoying compiler warnings on Mac OS X
      Fix white space warning in clusterj
      Bug #20504741 Bug #20695155 Improve Clusterj handling of ByteBuffers to reduce direct memory footprint Fix Clusterj incompatibility with Java 7
      Backport My::Memcache.pm improvements from 7.3 This will be null-merged up
      Eliminate some compiler warnings in 3rd party memcached code for NDB Memcache This fix includes both reducing the gcc warning config in CMakeLists.txt and changing two memcached source files. No Oracle copyright is added to the changed 3rd party files.
      Clusterj Trivial bug fix for error displays
      Bug#21055643 REDUCE DEBUG PRINTOUT DURING A GAP AND IMPROVE
      Properly include m_string.h when using my_stpcpy
      Improve comments
      Cache the key_length in NDB_SHARE_KEY
      Provide type safety by using the opaque NDB_SHARE_KEY* type
      Use NDB_SHARE::key_string() instead of direct access to key member
      Move NDB_SHARE::key_length into NDB_SHARE_KEY
      Rewrite the lgive share leak name  to also use NDB_SHARE::create_key
      Move all NDB_SHARE key initialization into NDB_SHARE::creat_key()
      Fix some compiler warnings from memcached sources
      My::Memcache.pm: handle case where the last read before a timeout completed the read buffer. Open a new memcache connection when trying to fetch server error stats.
      Save the prepared key in Ndb_schema_dist_data
      Rename ndbcluster_prepare_rename_share to NDB_SHARE::create_key
      Remove NDB_SHARE::mem_root and instead use my_malloc for dynamic strings
      Change ndcluster_prepare_rename_share to return newly allocated key
      Remove NDB_SHARE::old_names
      Pass the new_key as argument to ndbcluster_rename_share
      Skip ndb_ddl tests with embeddes server
      Change to allocate Ndb_CONFLICT_FN_SHARE bith my_malloc
      Make the NDB_CONFLICT_FN_SHARE an opaque type for users of ndb_share.h
      Remove useless typedefs
      Remove backwards jump into a hoop on fire
      bug#18411034: Remove an unnecessary if-statement
      Print stats for the MEM_ROOT in Ndb_event_data
      Increased the undolog file size from 256MB to 512MB and FragmentLogFileSize from 64MB to 128MB.
      bug#18411034: Assertion gci_ops && (gci == gci_ops->m_gci) failed
      bug#18411034: Assertion gci_ops && (gci == gci_ops->m_gci) failed
      bug#20553313, bug#20707694 - fix index stats query delays
      Bug#20479917 REMOVE MCP_BUG16021021
      Bug#21026199  RANDOM WARNING ORDER NDB_ONE_FRAGMENT
      Addendum to the fix for bug #20681412:
      post push minor test fix for bug:19887143
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug#20234681 HA_NDBCLUSTER USAGE OF FIND_FILES LEAK MEMORY INTO (UNRELEASED) MEM_ROOT
      Move new drop_table test to suite ndbcluster
      Bug#20728189 DROP TABLE SEGFAULTS IF FIRST STATEMENT ON A NEW CONNECTION
      Adding force_restart option to ndb_addnode_restart_setup.inc To force restart servers during retries.
      Bug#20782580: NDB REDO OVERLOAD: ABORT QUEUING REQUESTS IF OUT OF LOG SPACE
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      Added 5 autotest testcases to test node restart with following scenarios. 1. Restarting one node at a time. 2. killing two node of different groups and starting them with and without initial option. 3. Restarting a node which doesn't belongs to node group 0, and checking that it is not associated with node group 0 after restart. 4. killing four node of different groups and starting them with and without initial option. 5. Killing only the master nodes one by one and starting them without initial option.
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      Bug#11762750 TABLE NDBINFO.CONFIG_PARAMS SHOULD BE READ-ONLY (FOR NOW)
      Bug#16731538 MYSQLD CRITICAL FAILURE DURING ORDERED SELECT FROM NDBINFO.CLUSTER_OPERATIONS
      BUG#20075747 RND_INIT() ON AN OPEN SCAN IS USED TO REPOSITION THE CURSOR
      WL#7575 Remove ndbinfo's usage of other engine
      My::Memcache -- longer write timeot
      My::Memcache client, fix bug in read() where desired length is 0
      Remove include/ndb_default_cluster.inc
      WL#8165 Use new records per key interface in NDB
      Fix for Bug#20954804
      Fix for Bug#20954804
      Bug#20782580: NDB REDO OVERLOAD: ABORT QUEUING REQUESTS IF OUT OF LOG SPACE
      Fix a possible crash in AutoTest when an ordered scan encounter error 4008, scan timeout. One such testcase is 'testScan -n ScanRead4880'
      Bug#11760802 SEVERAL MGMAPI FUNCTIONS RETURN 0(SUCCESS) WHEN NO HANDLE OR NOT CONNECTED
      Refactoring of create partitioned table
      Revert unintentional change
      My::Memcache - do not close connection before attempting to fetch server error statistics
      MTR ndb_memcache more tweaks to timeout handling
      Bug#20814396 PB2 IS SECRET ABOUT WHAT UNIT TESTS IT RUN
      Revert "Remove MCP_GLOBAL_SCHEMA_LOCK patch"
      Revert "Remove MCP_GLOBAL_SCHEMA_LOCK patch"
      Fixing the following test failures by synch'ing the error injection and the test checking the error:
      increase timeouts
      Better failure handling in My::Memcache.pm
      Provide more information when an ndb_memcache test fails
      BUG#20887445: Fix so that cpuset is working in ThreadConfig, previously node log proclaimed it was working where it wasn't really working
      Fix ndbapi example programs to work on Mac OS X Yosemite
      BUG#20887445: Fix so that cpuset is working in ThreadConfig, previously node log proclaimed it was working where it wasn't really working
      Fix ndbapi example programs to work on Mac OS X Yosemite
      Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED
      Bug#20729091 - ASSERTION TYPE < NDBDICTIONARY::EVENT::TE_EMPTY FAILED
      Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS
      Bug#20762291 - POLLEVENTS2() WILL RETURN ERROR (-1) IF GIVEN WAITTIME AMILLISECONDS IS NEGATIVE
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Fix testIndex seg fault where index not exists when calling indexReadRecords, added check for NULL return
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      MTR ndb_memcache : still better timeout handling & more verbose reporting during test runs
      Revert to older scheduler as default in 7.4 for testing
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Remove MCP_WIX
      Handle server timouts and disconnects in MTR's My::Memcache client
      Work on My::Memcache to handle server disconnects and timeouts
      Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS Bug#20561446 NDB : NDBEVENTBUFFER NEEDS MORE THREADING PROTECTION
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      fix
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      NDB Memcache external_values fixes: The external_values test had a Perl bug using "==" instead of "eq", causing tests to pass even when the server produced errant responses. This patch fixes the test case and also fixes the revealed errant behavior in memcached.
      Remove MCP_WIX
      Remove MCP_WIX
      Remove MCP_WIX
      Do not change default scheduler in 7.2
      NDB Memcache: use pollEvents2() in reconfiguration waiter thread
      bug#17638548: NDB Memcached uses excessive CPU. This patch works around the underlying issue by defaulting to a new scheduler which does not make use of the NDB MultiWait APIs.
      NDB Memcached: enable "Trondheim" scheduler in 7.2
      one more solaris fix
      Fix for compiler error on Solaris
      Adapt 73 Scheduler to new online configuration manager
      one more solaris fix
      Fix for compiler error on Solaris
      Fixup from previous merge
      NDB Memcache: backport improvements into 7.2
      Backport misc. NDB memcache changes from 7.3 to 7.2
      Raise version number after cloning 7.2.20
      Raise version number after cloning 7.3.9
      Raise version number after cloning 7.4.6
      Raise version number after cloning 7.1.35
      Attempt better "htonll" portability in NDB memcache code
      BUG#20665205, fixed a part where we skipped reading of page 0 which was required to do in last file, also due to file 0, page 0 writes we can trust this page to be correct
      Add ndb specific changes for Bug#20094067: BACKPORT BUG#19683834 TO 5.5 AND 5.6
      Added ndb testcase for bug#19856162.
      Post-push fix for bug#19856162.
      Merge into cluster: WL#8354 BACKPORT DIGEST IMPROVEMENTS TO MYSQL 5.6
      Revert "Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS"
      Revert "Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS"
      Revert "Bug#20729091 - ASSERTION `TYPE < NDBDICTIONARY::EVENT::TE_EMPTY' FAILED."
      Revert "Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED"
      BUG#20665205: Fix REDO log issue
      Added autotest testcases to test addnode and restart.
      Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED
      Bug#20729091 - ASSERTION `TYPE < NDBDICTIONARY::EVENT::TE_EMPTY' FAILED.
      Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS
      Bug 20762291 - POLLEVENTS2() WILL RETURN ERROR (-1) IF GIVEN WAITTIME AMILLISECONDS IS NEGATIVE
      Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS Bug#20561446 NDB : NDBEVENTBUFFER NEEDS MORE THREADING PROTECTION
      Remove MCP_WIX
      Resurrect unintentionally remove disabled.def file

[33mcommit d8da6023b6100bd348160187a9eeedd35f1c3898[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Tue Jun 16 10:45:11 2015 +0300

    Bug#21184265 ASSERT AT ALL || TRX_SYS_GET_N_RW_TRX() > 0
    
    This is a regression from the startup refactoring in WL#7488.
    We aim to create the thread for rolling back incomplete transactions
    only if there are any such transactions to roll back.
    
    The assertion sometimes failed in the recovery steps of the test
    binlog.binlog_group_commit_[1;31mflush[m_crash.
    
    The problem appears to be that the XA PREPARE transaction (internally
    created by the binlog) is accounted for in the trx_sys_get_n_rw_trx(),
    which we were checking. We should only consider those incomplete
    transactions that can be rolled back without involving other layers
    (transactions that are not in XA PREPARE state).
    
    In one observed failure, the error log output suggests that the binlog
    subsystem will have issued XA ROLLBACK for the transaction before the
    InnoDB rollback thread starts executing. The count was 1 before the XA
    ROLLBACK, and 0 after it.
    
    trx_sys_need_rollback(): Renamed from trx_sys_get_n_rw_trx(). Do not
    count transactions that are in XA PREPARE state.
    
    trx_sys_t::n_prepared_recovered_trx: Remove. This field was made redundant
    by the fix of
    Bug#20461632 QUERY CACHE IS DISABLED WHEN RECOVERED XA PREPARE
    TRANSACTIONS EXIST
    
    RB: 9306
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 215f4439e1da855116afda184100d2a6d31a7f23[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Thu May 28 13:58:11 2015 +0300

    WL#7488: InnoDB startup refactoring
    
    Validate the startup parameters before opening files.
    
    srv_start(): Renamed from innobase_start_or_create_for_mysql().
    Move some of the validation to the caller, which is innobase_init().
    
    innodb_log_buffer_size: Renamed from innobase_log_buffer_size,
    using an unsigned type to avoid type casts.
    
    innodb_log_file_size: Renamed from innobase_log_file_size,
    using an unsigned type to avoid type casts.
    
    innobase_read_io_threads, innobase_write_io_threads: Remove.
    Directly map the startup parameters to the variables
    srv_n_read_io_threads, srv_n_write_io_threads.
    
    innodb_change_buffering: Renamed from innobase_change_buffering.
    Use an integer type instead of a string.
    
    innodb_[1;31mflush[m_method: Renamed from innobase_file_[1;31mflush[m_method.
    Use an integer type instead of a string.
    
    innodb_[1;31mflush[m_method_names, innodb_[1;31mflush[m_method_typelib: Valid values of
    innodb_[1;31mflush[m_method.
    
    innodb_change_buffering_names, innodb_change_buffering_typelib:
    Valid values of innodb_change_buffering.
    Replaces innodb_change_buffering_names.
    
    innodb_init(): Renamed from innobase_init().
    innodb_init_abort(): Renamed from innobase_init_abort().
    
    innodb_init(): When startup fails before opening files, do not call
    innodb_init_abort(), but return 1 directly instead.
    
    innodb_buffer_pool_size_init(): New function, to initialize
    and normalize the buffer pool size and related parameters.
    
    innodb_init_params(): New function, to check the startup parameters.
    
    innodb_find_change_buffering_value(), innodb_change_buffering_validate(),
    innodb_change_buffering_update(): Remove. These are made redundant by
    innodb_change_buffering_typelib.
    
    IBUF_USE_COUNT: Remove.
    
    srv_normalize_init_values(): Remove. This will be done in innodb_init().
    
    SysTablespace::normalize_size(): Renamed from SysTablespace::normalize().
    
    RB: 8647
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Mattias Jonsson <mattias.jonsson@oracle.com>

[33mcommit 6e331d3c66e5aafa23df3114096bf44f213ee6cd[m
Author: Daogang.qu <bill.qu@oracle.com>
Date:   Sun May 3 17:56:59 2015 +0800

    Bug #20592961  'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381
    
    If we inject some fault in binary index file using debug options,
    then '[1;31mflush[m logs' command will hit with assertion failure
    '! is_set()' at sql_error.cc:381. The root cause is that the
    '[1;31mflush[m logs' command missed to handle an 'Bad file descriptor'
    error while [1;31mflush[ming io cache.
    
    To fix the problem, handle the 'Bad file descriptor' error
    while [1;31mflush[ming io cache in the case.

[33mcommit 931f119c9e17389dd25e6d2986857b521288d1d8[m
Author: Daogang.qu <bill.qu@oracle.com>
Date:   Sun May 3 17:56:59 2015 +0800

    Bug #20592961 'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381
    
    If we inject some fault in binary index file using debug options,
    then '[1;31mflush[m logs' command will hit with assertion failure
    '! is_set()' at sql_error.cc:381. The root cause is that the
    '[1;31mflush[m logs' command missed to handle an 'Bad file descriptor'
    error while [1;31mflush[ming io cache.
    
    To fix the problem, handle the 'Bad file descriptor' error
    while [1;31mflush[ming io cache in the case.
For keyword binaryLog:
For keyword dsync:
For keyword delayedInnodbWrite:
For keyword binarylog:
For keyword buffer:
[33mcommit 53e0776dc4bb031b46569573069db68ddcc4300e[m
Author: Ivo Roylev <ivo.roylev@oracle.com>
Date:   Mon May 21 23:24:02 2018 +0300

    Bug#27980823: HEAP OVERFLOW VULNERABILITIES IN MYSQL CLIENT LIBRARY
    
    There is an ASSERT on a runtime condition that should be a dynamic check.
    There is also reported a weakness with [1;31mbuffer[m length. Currently cannot simulate an attack service there, but beafing up the code anyway.

[33mcommit 526d2734a783831a66063af016cc3c38b22f3bbe[m
Author: Ivo Roylev <ivo.roylev@oracle.com>
Date:   Mon May 21 22:08:45 2018 +0300

    Bug#27980823: HEAP OVERFLOW VULNERABILITIES IN MYSQL CLIENT LIBRARY
    
    There is an ASSERT on a runtime condition that should be a dynamic check.
    There is also reported a weakness with [1;31mbuffer[m length. Currently cannot simulate an attack service there, but beafing up the code anyway.

[33mcommit a4fa326ddb1884323fe1a9c83f42489f2049675b[m
Author: Ivo Roylev <ivo.roylev@oracle.com>
Date:   Mon May 21 18:35:15 2018 +0300

    Bug#27980823: HEAP OVERFLOW VULNERABILITIES IN MYSQL CLIENT LIBRARY
    
    There is an ASSERT on a runtime condition that should be a dynamic check.
    There is also reported a weakness with [1;31mbuffer[m length. Currently cannot simulate an attack service there, but beafing up the code anyway.

[33mcommit 78d91181539090195ddf97721d4442a0792cffaa[m
Author: Martin Hansson <martin.hansson@oracle.com>
Date:   Fri May 18 15:41:08 2018 +0200

    Bug#27992118: REGEXP_REPLACE ACCUMULATING RESULT
    
    The replacement [1;31mbuffer[m was not cleared when reset with a new
    subject. Fixed by actually clearing it.
    
    Change-Id: Icc24d2d9727d8f540e2e40449f6ea46ce2a07d6b

[33mcommit afd960da05b4c1c5563f999c323665c338253c15[m
Author: Debarun Banerjee <debarun.banerjee@oracle.com>
Date:   Mon May 21 10:46:55 2018 +0530

    BUG#27823064 ERR == DB_SUCCESS || ERR == DB_INVALID_ENCRYPTION_META
    
    Problem :
    ---------
    1. When a tablespace file is extended, we take SX lock on the space
    header page while updating space size. Clone takes S lock during
    page copy and the concurrent modification causes checksum mismatch.
    
    2. When a freed page (on disk) is re allocated and the page is not
    found in [1;31mbuffer[m pool, we create a new page an initialize it. We skip
    reading the old page from disk. During initialization,
      a] New page is added to page hash without latch
      b] Some initial modifications are made on page frame
      c] Page is latched X and fully initialized
    
    When clone tries to get such page with S/SX lock it gets half way
    initialized page during step B] and C]. It results in checksum mismatch
    and other issues during recovery from cloned database.
    
    Solution :
    ----------
    1. Take SX lock during clone page copy rather than S as some
    modifications are made with SX lock.
    
    2. Correct new page creation logic to latch the page early before
    adding the page to page hash.
    
    Reviewed-by: Jimmy Yang <Jimmy.Yang@oracle.com>
    
    RB: 19673

[33mcommit 8d05059fa2ea435260863eaec3388c1e9bd9a3d5[m
Author: Luis Soares <luis.soares@oracle.com>
Date:   Fri May 18 12:49:09 2018 +0100

    Bug #27700486: binlog_log_row - avoid unnecessary malloc and memcpy
    
    Instead of allocating and swapping [1;31mbuffer[m contents,
    use offsets to operate directly on the target [1;31mbuffer[m.
    
    This avoids extra memory management (allocation and
    free) as well as memory copies, at the cost of
    doing some pointer arythmetic instead.

[33mcommit 1f24c5aa2843fa548aa5c4b29c00f955e03e9f5b[m
Author: Aditya A <aditya.a@oracle.com>
Date:   Fri May 18 12:32:37 2018 +0530

    Bug #27208858   CONCURRENT DDL/DML ON FOREIGN KEYS CRASH IN PAGE_CUR_SEARCH_WITH_MATCH_BYTES
    
    PROBLEM
    -------
    
    1. During truncate when we are trying to flush out the pages
       of truncated table form the [1;31mbuffer[m pool we release the dict lock.
    2. At this stage a DDL request  to add a FK constraint from another
       connection,tries to access the stale index memory object of the
       parent table and asserts.
    
    FIX
    ---
    
     Disallow the DDL operation of adding FK when parent table is
     undergoing truncate .
    
     [#rb 19433 Reviewed by Jimmy ]

[33mcommit 32d423289c8c52a959913a615b2110ffb46df815[m
Author: Thayumanavar S <thayumanavar.x.sachithanantha@oracle.com>
Date:   Fri May 4 05:40:19 2018 +0200

    BUG#27699248 - PRPEPARED_STATEMENT::INSERT_PARAMS_FROM_VARS
                   IS INSANELY SLOW.
    
    Executing a prepared statement to insert rows with large number of parameters                                                                                                         takes a long time. To write statement to binlog, the query string is prepared                                                                                                         during the execution. The query string preparation in this scenario involves                                                                                                          many string append calls to expand heap allocated memory and memcpy. Hence the                                                                                                        delay in statement execution is observed.
    
    The fix involves the following changes:
    1. A reasonable size of memory is reserved for the query string. Memory of size
       "original statement string size + 32 times the number of parameters" is
       reserved to avoid reallocations during string appends in common use cases.
    
    2. The String class does not support strings of 4GBytes length. It results in
       an overflow on 64-bit word size platforms. A debug assert is added for 64-bit
       platforms to check overflow condition. It is responsibility of caller to
       ensure the memory [1;31mbuffer[m to hold string doesn't exceed 4G bytes in length.
       An error is reported if the query string size exceeds the string supported
       size during execution of the prepared statements.
    
    3. Unneeded local variable to hold the query string is removed.

[33mcommit 1df5d30dcca350743e4751cddc571bad8b1b8a84[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu May 3 12:44:33 2018 +0200

    Fix compile warning
    
    sql/filesort_utils.h: In member function
    virtual void filesort_[1;31mbuffer[m_unittest::FileSortBufferTest::TearDown():
    sql/filesort_utils.h:251:24: warning: <anonymous>.Filesort_[1;31mbuffer[m::m_sort_length
    is used uninitialized in this function [-Wuninitialized]
    
    Change-Id: If334119a3a336a601187f58bfa2a2ad9d0bef21c

[33mcommit 58086590f58dac7052d2c9458d35f26962b2d76c[m
Author: Rahul Agarkar <rahul.agarkar@oracle.com>
Date:   Thu Mar 15 17:34:52 2018 +0530

    Bug#24734190 KILL-SERVER : LOG PARSING BUFFER OVERFLOW. RECOVERY MAY HAVE FAILED!
    
    Problem
    --------
    While doing a crash recovery, the server failed as it ran out of space on the recovery parsing [1;31mbuffer[m. This was because the server received a log record which was larger than
    the recovery parsing [1;31mbuffer[m which is initialized to 2MB.
    
    Solution
    ---------
    Allocate the recovery parsing [1;31mbuffer[m dynamically and increment it until it reaches the value set by the parameter log_[1;31mbuffer[m_size.
    
    Reviewed by: Debarun Banerjee (debarun.banerjee@oracle.com)
    
    RB: 19211

[33mcommit dd6c48eb25f9903f2d742887c29739f81355e400[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Wed Apr 18 13:11:17 2018 +0200

    BUG#27664539 INNODB: ASSERTION FAILURE: BUF0FLU.CC:457:
                 (BUF_POOL->FLUSH_LIST).START == __NULL
    
    1. Fixed a method to assign LSN to pages dirtied in no-redo mini transaction
       (when MTR_LOG_NO_REDO is set).
    
    2. Introduced new MONITOR counters that provide LSN values:
       - log_lsn_buf_dirty_pages_added,
       - log_lsn_buf_pool_oldest_lwm.
    
    3. Renamed log_[1;31mbuffer[m_write_completed_before_dirty_pages_added
       to log_wait_for_space_in_log_recent_closed, renamed
       log_[1;31mbuffer[m_write_completed_and_dirty_pages_added to
       log_[1;31mbuffer[m_close.
    
    4. Do not wait for flushed pages in log_checkpointer when requesting
       sync flush.
    
    5. Added assertion that ensures we do not rely on mtr.commit_lsn() of no-redo
       mini transactions.
    
    6. Added mtr test for redo/no-redo mtr commits and relaxed order in flush lists.
    
    RB: 19252

[33mcommit 01d39a7295b6914de06c0fd5d8fad2d1d0b31495[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Apr 13 12:32:34 2018 +0200

    Bug #27858762: OUT-OF-BOUNDS ACCESS IN M_RECORD_POINTERS
    
    When we use LIMIT with priority queue, the record pointers are already
    set up before we start reading records, so we should not reset the [1;31mbuffer[m.
    Doing so would cause us to read and write records past the end of the
    vector, which is undefined behavior (but happened to work fine in practice,
    since the memory was not freed).
    
    Change-Id: If4f0a059c403021071ed3d0ff07f6e2d8113204c

[33mcommit 6d783073b941c468f2a720b92d7e90fdc6babdac[m
Author: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>
Date:   Wed Apr 11 12:46:28 2018 +0200

    Bug#27470219 MINOR PERFORMANCE DROP IN MYSQLXCLIENT CAUSED BY RECV BUFFER ALLOCATION
    
    Use preallocated [1;31mbuffer[m on X protocol message receive. If received message
    size do not fit the [1;31mbuffer[m then allocate memory on a heap.
    
    RB: 19043
    Reviewed by: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>
    Reviewed by: Lukasz Kotula <lukasz.kotula@oracle.com>

[33mcommit dee1463201a59d0685792a954ac98da92d8d1ef9[m
Author: Sachin Agarwal <sachin.z.agarwal@oracle.com>
Date:   Tue Apr 10 18:41:13 2018 +0530

    Bug#26100239 - CRASH ON STARTUP, DIVIDE BY ZERO, WITH INAPPROPRIATE
    BUFFER POOL CONFIGURATION
    
    Problem:
    In Windows-x64, when mysql server start with
    "--innodb-[1;31mbuffer[m-pool-size=10G --innodb-[1;31mbuffer[m-pool-instances=64",
    buf_pool_size_align() function raises divide by ZERO exception because
    when it calculate 'm = srv_buf_pool_instances * srv_buf_pool_chunk_unit',
    'm' gets ZERO and 'm' is used to align innodb [1;31mbuffer[m pool size to
    the multiple of 'srv_buf_pool_chunk_unit'.
    'srv_buf_pool_chunk_unit' and 'srv_buf_pool_instances' both are defined
    as ulong, which is 4-byte data-type in Windows-x64. So the multiplication
    of these two variable truncates all the bits beyond 4-bytes.
    
    Fix:
    Modified data-type for 'srv_buf_pool_instances' to ulonglong.
    
    RB: 19194
    Reviewed by : Jimmy.Yang@oracle.com

[33mcommit f5017c9a6fd197372dc5c6ffb86d422d26183121[m
Author: Sreeharsha Ramanavarapu <sreeharsha.ramanavarapu@oracle.com>
Date:   Tue Apr 10 06:03:18 2018 +0530

    Bug #27389294: INCORRECT BEHAVIOR WITH DATETIME COLUMN AND
                   QUERY REQUIRING SORTING
    
    Issue:
    ------
    This problem occurs under the following conditions:
    1) A select query is required to do an "open table"
       (i.e. it follows a FLUSH TABLE or it is the first query
        to access that table).
    2) ORDER BY ... LIMIT's presence mandates sorting.
    3) A DATETIME column is used for ref-access.
    
    Root cause:
    -----------
    1) While optimizing a subquery with ORDER BY:
       a) it is decided that every evaluation of the subquery,
          for every outer row, will use a ref access and a
          filesort.
       b) ref access is set up for WHERE (the referenced value
          is a column of the outer query).
       c) a filesort is set up; this filesort wants to
          implement the ref access too, for this it calls
          get_quick_select_for_ref(); to read the referenced
          value.
    
    2) my_datetime_packed_from_binary() is reached through
       store_key_field::copy_inner() while checking the number
       of rows the ref-access might return.
    
       copy_field.from_field -> (field object of t1_a.c3)
       copy_field.to_field   -> (to object of t1_b.c3)
    
    my_datetime_packed_from_binary() sees a junk value for
    t1_a.c3 is junk as no row of the outer table t1_a has been
    read yet. It is an invalid DATETIME value.
    
    Why does this problem not occur with every other statement?
    For most DML statements empty_record() / restore_record()
    is called at some point and a valid DATETIME value is
    placed in the record [1;31mbuffer[m.
    
    What about SELECT statements?
    SELECT queries call empty_record() / restore_record() only
    in the execution phase, after the plan is created.
    
    Solution:
    ---------
    Calling cp_[1;31mbuffer[m_from_ref() during the optimization phase
    is unsafe because it might access an uninitialized column.
    So remove the call to this function from
    get_quick_select_for_ref(). The actual ref value isn't
    required to create a QUICK_RANGE object anyway.

[33mcommit d982e717aba67227ec40761a21a4211db91aa0e2[m
Author: Arun Kuruvila <arun.kuruvila@oracle.com>
Date:   Mon Apr 9 11:18:12 2018 +0530

    Bug#27510150: MYSQLDUMP FAILS FOR SPECIFIC --WHERE CLAUSES
    
    Description: Mysqldump utility fails for specific clauses
    used with the option, 'where'.
    
    Analysis:- Method, "fix_identifier_with_newline()" that
    prefixes all occurrences of newline char ('\n') in incoming
    [1;31mbuffer[m does not verify the size of the [1;31mbuffer[m. The [1;31mbuffer[m in
    which the incoming [1;31mbuffer[m is copied is limited to 2048 bytes
    and the method does not try to allocate additional memory
    for larger incoming [1;31mbuffer[ms.
    
    Fix:- Method, "fix_identifier_with_newline()" is modified
    to fix this issue.

[33mcommit 26986857917d315cc894da645cb9ddb7f073c41b[m
Author: Ricardo Ferreira E Ferreira <ricardo.e.ferreira@oracle.com>
Date:   Thu Mar 22 16:41:49 2018 +0000

    BUG#27692831: DECODE OF SOME PIT ON PIPELINE_STATS_MEMBER_MESSAGE IS NOT
    ENDIAN SAFE
    
    Some PITs of the stats member message are not being decoded correctly
    w.r.t. endianness. Specifically the PIT_TRANSACTIONS_NEGATIVE_CERTIFIED,
    the PIT_TRANSACTIONS_ROWS_VALIDATING and the PIT_TRANSACTIONS_LOCAL_ROLLBACK.
    
    The fix was to call uint8korr() upon reading from the raw [1;31mbuffer[m.

[33mcommit e57a6e4d9dd03587b8b2ad6c5b11601f4d8120fe[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Tue Mar 13 14:09:29 2018 +0530

    BUG#27591319: MESSAGE FROM LAST --ECHO IS NOT FLUSHED BEFORE TIMING
                  OUT ON SET DEBUG_SYNC
    
    Issue:
    ------
    SET DEBUG_SYNC = 'now WAIT_FOR something' statement in a test cases
    test time out, because something is never triggered, then the most
    recent '--echo' command is not reflected in the log file.
    
    bash> echo sample.test
    --echo one
    --echo two
    --echo three
    SET DEBUG_SYNC = 'now WAIT_FOR ever';
    
    bash> ./mtr main.sample --testcase-timeout=1
    
    This obviously will timeout, since we never trigger signal named
    'ever'. But, the strange thing is that log file contains only:
    
    bash> cat var/log/main.sample/sample.log
    one
    two
    
    The last echo statement output is not written to the log file.
    
    Fix:
    ----
    1. Flush the the contents in output [1;31mbuffer[m to file after writing the
       them.
    
    2. Created 'include/analyze-timeout.test' file.
    
    Change-Id: Id5449a3893958123a1ed555e57ed757643200abd

[33mcommit 7dc0e3841cbea20dd4d32e3dfd8f6b80eb275d6c[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Mar 12 14:51:20 2018 +0100

    WL #11590: More flexible filesort [patch 9/10, optimistic sort key generation]
    
    Enable optimistic sort key generation.
    
    With this change, we no longer end a filesort chunk when it is pessimistically
    out of space (ie., can no longer sustain a worst-case row). Instead, we simply
    start writing the row, and end the chunk only if it actually needed more space
    than the chunk had left (or if it was within a few bytes -- we can't always tell).
    
    This enables us to fit more rows into each chunk (for some cases, quite
    a lot of more rows, although the common case is much more modest), as most rows
    are not worst-case; even more so with the newer Unicode collations. Also,
    it significantly reduces the need for artificially limiting the worst-case
    size of rows through the max_sort_length variable; it is now only used for
    blobs of PAD SPACE collations, where we have to pad the sort lengths to the
    maximum size and the maximum size is by definition large. This means users
    can now ORDER BY things like JSON columns or large VARCHAR fields without
    having to worry that they get wrong results as sort keys are truncated.
    
    Note that this means that you can no longer ORDER BY <json> LIMIT <n>
    (or similarly, on a blob) and get ordering by priority queue, since the
    priority queue still is oriented around worst-case rows. Hopefully, this
    is not a very common use case, and getting actually correct results should
    more than weigh up for it.
    
    In the process, fix so that blobs get variable-length sort keys for
    NO PAD collations. (It would be possible to fix it in a separate commit
    earlier, but not without rewriting tests that would only need to be
    re-rewritten now, so it's easiest to do it in the same commit.)
    
    The unit tests for the filesort [1;31mbuffer[m have been completely rewritten,
    since the working of the [1;31mbuffer[m is so different now.
    
    Change-Id: I4c118dd7820549d47fad95e7bea7686cc7df619d

[33mcommit 9ac683509fa066c80aa7f413f0e2a27846a56061[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Mar 12 14:51:16 2018 +0100

    WL #11590: More flexible filesort [patch 6/10, fix JSON sort keys]
    
    Fix an integer underflow during generation of JSON keys. This is a preexisting
    issue, but is more likely to happen when we start being more aggressive about
    writing sort keys into (too) short [1;31mbuffer[ms.
    
    The included unit test triggers the bug reliably when run with ASan.
    
    Change-Id: I7f5ec60df9cc9eecabe0902d108669e0441ec5ef

[33mcommit 08db920e283ffe70f4ecbea162e11f3f14dee487[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Mar 12 14:51:13 2018 +0100

    WL #11590: More flexible filesort [patch 4/10, optimistic merge]
    
    The merge phase of filesort may need room for as much as 15 rows, since
    we need one row for each chunk and there could be as many chunks.
    However, the current code is too pessimistic, refusing to make a sort if
    there exists a possible scenario where this could fail (ie., 15 rows
    of maximum possible size).
    
    This is too pessimistic; most merges have only seven merge chunks or
    fewer, and most rows are not maximum size. Thus, just assume we're fine,
    and give an error if we actually get into the situation where we don't
    have room for a merged row. This means we could potentially be doing
    wasted work before giving out the error, but it is much friendlier for
    the common case where we actually have enough merge [1;31mbuffer[m.
    
    Change-Id: Idd37075c85f618e6434eb034a5a4a271e170340d

[33mcommit 71464a1edb94d93c0f0c986752b95bcc4d0eb28a[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Mon Mar 12 14:51:11 2018 +0100

    WL #11590: More flexible filesort [patch 3/10, incremental [1;31mbuffer[m]
    
    Instead of allocating one big filesort [1;31mbuffer[m up-front, start with
    a small [1;31mbuffer[m, only increasing it (exponentially) once we actually get more
    data. If we actually need all of the [1;31mbuffer[m, we do somewhat more mallocs
    than in the allocate-once case, but on Linux, the mallocs disappear
    entirely in the rest of the work. (On Windows, we do see a regression
    in heavily concurrent sort benchmarks, but that will be fixed in a future
    worklog.)
    
    For the case where we have a large [1;31mbuffer[m but don't use it (e.g. 256 kB
    of data with 32 MB large [1;31mbuffer[m), we do save a fair amount of CPU time (on the
    order of 7–8%, although of course this will vary with the exact circumstances).
    Also, of course, we save the RAM we don't use.
    
    Note that we never move data between the sort [1;31mbuffer[ms -- once rows are written
    into a [1;31mbuffer[m, they never move. This means we need separate storage for the
    record pointers, which means we also need some care to make sure we don't
    overrun the sort [1;31mbuffer[m budget too much with the hidden cost of storing the
    pointers.
    
    Change-Id: I0599bc10947aec95ae80a3dbbf04e81d2017cfb0

[33mcommit 4a041b99bab1bc20831b9e4ae8219cbd039391c0[m
Author: Tiago Vale <tiago.vale@oracle.com>
Date:   Mon Mar 19 11:21:57 2018 +0000

    Bug#27604471 THERE IS NO LOCAL IP ADDRESS MATCHING THE ONE CONFIGURED FOR THE LOCAL NODE
    
    Note
    ====
    This bug is a duplicate of Bug#27684295 BACKPORT BUG#27376511 TO 5.7.
    
    Problem
    =======
    When using an IP or hostname in the GR configuration parameters, there would
    be no match on Mac OSX. This occurs because the [1;31mbuffer[m isn't large enough
    to store all the interfaces' configurations, and its size does not increase
    because the [1;31mbuffer[m isn't completely filled, since the configurations have
    variable sizes which do not add up exactly to the [1;31mbuffer[m size.
    
    Fix
    ===
    Modified condition to increase the [1;31mbuffer[m when the difference between its
    size and that of the retrieved configurations is smaller than IFNAMSIZ
    added to the size of the sockaddr_storage struct, which is "large enough
    to accommodate all supported protocol-specific address structures", according
    to IETF RFC3493.
    
    Reviewed-by: Sujatha Sivakumar <sujatha.sivakumar@oracle.com>
    Reviewed-by: Filipe Campos <filipe.campos@oracle.com>
    RB: 19146

[33mcommit 1033c68be7c3dc543e1d0cca8658be0ed5ef8f87[m
Author: Lukasz Kotula <lukasz.kotula@oracle.com>
Date:   Mon Feb 26 14:27:05 2018 +0100

    BUG#27435591 - ALIGN MYSQLX_MAX_ALLOWED_PACKET DEFAULT WITH MAX_ALLOWED_PACKET DEFAULT OF 64M
    
    Description
    ===========
    Default configuration of classic protocol allows to handle packets upto 64MB (default of
    max_allowed_packet is set to 64M). X Protocol handles 1MB packets in default, which can
    be a problem when handling similar input as classic.
    
    Fix
    ===
    Default of 'mysqlx_max_allowed_packet' system variable was changed to 64MB. X Plugins
    protobuf decoder was updated to handle large packet without reallocating its internal
    [1;31mbuffer[m (switched from flat [1;31mbuffer[m to ZeroCopyInputStream).
    
    RB: 18941
    Reviewed-by: Tomasz Stepniak <tomasz.s.stepniak@oracle.com>
    Reviewed-by: Grzegorz Szwarc <grzegorz.szwarc@oracle.com>

[33mcommit 8a6dddb97932c898c3983fa997a87ddae59df4d5[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Wed Feb 28 13:44:42 2018 +0100

    Fix for bug in integration between redo log and Clone.
    
    Bug was introduced in the latest merge between 10310 and newer Clone.
    
    Function which was x-locking the log [1;31mbuffer[m and copying last block from
    the log [1;31mbuffer[m to Clone, could return without unlocking the log [1;31mbuffer[m.
    
    This was revealed by assertion failure, when the same thread was trying
    to acquire s-lock for the log [1;31mbuffer[m afterwards (to write data to redo).
    
    Problem was discovered by sporadical PB2 failures of Clone's tests.

[33mcommit 674b75707178e4ebc5be435cba05a2db19a23b77[m
Author: Xing Zhang <xing.z.zhang@oracle.com>
Date:   Sat Feb 24 10:54:03 2018 +0800

    Bug #27507950: CRASH IN GET_CHARSET_NUMBER_INTERNAL WHEN SETTING CHARSET IN
                   MULTIPLE CONNECTION
    
    The crash caused by concurrent get_charset_number_internal() calls is because
    the std::unsorted_map::operator [] is not thread safe. When there are
    multiple threads, one might access the memory already freed by another one.
    
    There is also memory usage continuously increasing observed.  This is
    because the collation name - collation id mapping allocs new [1;31mbuffer[m for new
    added collations, even when the collation doesn't exist at all.
    
    Fix:
    Check the existence of collation when getting its id by the mapping. The
    collation initialization should have been done in init_available_charsets()
    which is thread-safe with std::call_once.
    
    Change-Id: Ie604901a2dce5a1f1a794cdd2196bf5434f9202f

[33mcommit 8f056e82f641164e5a23c12d7b8b0ddd6697bd07[m
Author: Filipe Campos <filipe.campos@oracle.com>
Date:   Tue Feb 20 11:39:46 2018 +0000

    BUG#27376511 - GCS CANNOT FETCH ANY IP ADDRESS BUT 127.0.0.1 IN MAC OS X
    
    Problem
    =======
    When using an IP or hostname in the GR configuration parameters, there would
    be no match on Mac OSX. This occurs because the [1;31mbuffer[m isn't large enough
    to store all the interfaces' configurations, and its size does not increase
    because the [1;31mbuffer[m isn't completely filled, since the configurations have
    variable sizes which do not add up exactly to the [1;31mbuffer[m size.
    
    Fix
    ===
    Modified condition to increase the [1;31mbuffer[m when the difference between its
    size and that of the retrieved configurations is smaller than IFNAMSIZ
    added to the size of the sockaddr_storage struct, which is "large enough
    to accommodate all supported protocol-specific address structures", according
    to IETF RFC3493.
    Also modified the gcs_logging_system unit test, as the log messages that match
    the "\[GCS\] Unable to probe network interface .*" regular expression
    were conveyed as parameter to the version of the log_event method with two
    arguments, instead of the version that has only one. Therefore, the match of
    that method with any inputs needed to be modified.

[33mcommit 3a933215c2edd112ffe5f013a2e7687aa17fad37[m
Author: Xing Zhang <xing.z.zhang@oracle.com>
Date:   Fri Feb 23 10:20:59 2018 +0800

    Bug #27507950: CRASH IN GET_CHARSET_NUMBER_INTERNAL WHEN SETTING CHARSET IN
                   MULTIPLE CONNECTION
    
    We put charset clean up code in my_end(), which is wrong.  Because my_end()
    is called when a thread is to end. So when there are multiple threads, one
    might access the memory already freed by another one.
    There is also memory usage continuously increasing observed.  This is
    because the collation name - collation id mapping allocs new [1;31mbuffer[m for new
    added collations, even when the collation doesn't exist at all.
    
    Fix:
    Move charset clean up code to mysqld's cleanup().
    Check the existence of collation when getting its id by the mapping.
    
    Change-Id: I23ab1628e0caa469dab6f3a3966e629e1654aeee

[33mcommit 2a4b5619ea482e27eb0c2283681175dc19f35c3d[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Feb 21 17:50:49 2018 +0100

    WL#10310 Redo log optimization: dedicated threads and concurrent log [1;31mbuffer[m.
    
    Post-push fix for clang warnings:
    
    storage/innobase/include/sync0sharded_rw.h:61:24: error: lambda capture
          'latch_level' is not used [-Werror,-Wunused-lambda-capture]
        for_each([pfs_key, latch_level](rw_lock_t &lock) {
    
    unittest/gunit/innodb/log0log-t.cc:482:8: error: lambda capture
          'max_dirty_page_age' is not required to be captured for this use [-Werror,-Wunused-lambda-capture]
          [max_dirty_page_age](size_t thread_no) {
    
    Change-Id: I94e89cf47101fd0d2224a1f0b1c41b5b0c0eae3f

[33mcommit 91a3b9b5575d23c168508f9ccda959ff9ea5dd69[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Feb 21 17:50:49 2018 +0100

    WL#10310 Redo log optimization: dedicated threads and concurrent log [1;31mbuffer[m.
    
    Post-push fix for clang warnings:
    
    storage/innobase/include/sync0sharded_rw.h:61:24: error: lambda capture
          'latch_level' is not used [-Werror,-Wunused-lambda-capture]
        for_each([pfs_key, latch_level](rw_lock_t &lock) {
    
    unittest/gunit/innodb/log0log-t.cc:482:8: error: lambda capture
          'max_dirty_page_age' is not required to be captured for this use [-Werror,-Wunused-lambda-capture]
          [max_dirty_page_age](size_t thread_no) {
    
    Change-Id: I94e89cf47101fd0d2224a1f0b1c41b5b0c0eae3f

[33mcommit d26f1640fbecaa40c289e85c5da3b9adafccd1f9[m
Author: Sunny Bains <sunny.bains@oracle.com>
Date:   Sun Feb 18 01:17:26 2018 +1100

    bug#22963374 - Parallelize [1;31mbuffer[m pool creation
    
    Follow up fix.

[33mcommit 7cb7f718b41755d333e5efd601dc58a696da569e[m
Author: Sunny Bains <sunny.bains@oracle.com>
Date:   Sun Feb 18 01:17:26 2018 +1100

    bug#22963374 - Parallelize [1;31mbuffer[m pool creation
    
    Follow up fix.

[33mcommit 8db91f0f958068fe7a98c7745e16880148f619da[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Sat Feb 17 07:46:22 2018 +1100

    bug#22963374 - Parallelize [1;31mbuffer[m pool creation
    
    Follow up fix. Threads array index was out of bounds.

[33mcommit f5b7bc7654c9e2492ef32ab2d2d500fdb834e88c[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Sat Feb 17 07:46:22 2018 +1100

    bug#22963374 - Parallelize [1;31mbuffer[m pool creation
    
    Follow up fix. Threads array index was out of bounds.

[33mcommit 68f3f84ff5af252b1f6540bd17cc7d74a14e4980[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Fri Feb 16 19:44:13 2018 +1100

    bug#22963374 - Parallelize [1;31mbuffer[m pool creation.
    
    RB#18793 - Approved by Jimmy Yang.

[33mcommit 693922038feeb4f918941a7ac660ef5e7fd6ef90[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Fri Feb 16 19:44:13 2018 +1100

    bug#22963374 - Parallelize [1;31mbuffer[m pool creation.
    
    RB#18793 - Approved by Jimmy Yang.

[33mcommit 80976f88f2cd35f28a8320a40fa17da32723cc92[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Feb 15 17:15:36 2018 +0100

    WL#10310 Redo log optimization: dedicated threads and concurrent log [1;31mbuffer[m.
    
    Post-push fixes for clang warnings:
    
    storage/innobase/buf/buf0flu.cc:437:20: error: unused function
          'buf_flush_list_order_validate' [-Werror,-Wunused-function]
    static inline bool buf_flush_list_order_validate(lsn_t earlier_added_lsn,
    
    storage/innobase/os/os0file.cc:314:23:
    error: missing field 'm_file' initializer
          [-Werror,-Wmissing-field-initializers]
      pfs_os_file_t file{0};
    
    storage/innobase/srv/srv0srv.cc:1954:16:
    error: unused function 'timeval_diff_us'
          [-Werror,-Wunused-function]
    
    Change-Id: I2eb1b8347ca7d041ce3c6ac3c0b3a635d5f4805a

[33mcommit 0b1b0b40408d0738ac41f3d1185f5b895730b265[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Feb 15 17:15:36 2018 +0100

    WL#10310 Redo log optimization: dedicated threads and concurrent log [1;31mbuffer[m.
    
    Post-push fixes for clang warnings:
    
    storage/innobase/buf/buf0flu.cc:437:20: error: unused function
          'buf_flush_list_order_validate' [-Werror,-Wunused-function]
    static inline bool buf_flush_list_order_validate(lsn_t earlier_added_lsn,
    
    storage/innobase/os/os0file.cc:314:23:
    error: missing field 'm_file' initializer
          [-Werror,-Wmissing-field-initializers]
      pfs_os_file_t file{0};
    
    storage/innobase/srv/srv0srv.cc:1954:16:
    error: unused function 'timeval_diff_us'
          [-Werror,-Wunused-function]
    
    Change-Id: I2eb1b8347ca7d041ce3c6ac3c0b3a635d5f4805a

[33mcommit 6be2fa0bdbbadc52cc8478b52b69db02b0eaff40[m
Author: Paweł Olchawa <pawel.olchawa@oracle.com>
Date:   Wed Feb 14 09:33:42 2018 +0100

    WL#10310 Redo log optimization: dedicated threads and concurrent log [1;31mbuffer[m.
    
    0. Log [1;31mbuffer[m became a ring [1;31mbuffer[m, data inside is no longer shifted.
    
    1. User threads are able to write concurrently to log [1;31mbuffer[m.
    
    2. Relaxed order of dirty pages in flush lists - no need to synchronize
       the order in which dirty pages are added to flush lists.
    
    3. Concurrent MTR commits can interleave on different stages of commits.
    
    4. Introduced dedicated log threads which keep writing log [1;31mbuffer[m:
        * log_writer: writes log [1;31mbuffer[m to system [1;31mbuffer[ms,
        * log_flusher: flushes system [1;31mbuffer[ms to disk.
       As soon as they finished writing (flushing) and there is new data to
       write (flush), they start next write (flush).
    
    5. User threads no longer write / flush log [1;31mbuffer[m to disk, they only
       wait by spinning or on event for notification. They do not have to
       compete for the responsibility of writing / flushing.
    
    6. Introduced a ring [1;31mbuffer[m of events (one per log-block) which are used
       by user threads to wait for written/flushed redo log to avoid:
        * contention on single event
        * false wake-ups of all waiting threads whenever some write/flush
          has finished (we can wake-up only those waiting in related blocks)
    
    7. Introduced dedicated notifier threads not to delay next writes/fsyncs:
        * log_write_notifier: notifies user threads about written redo,
        * log_flush_notifier: notifies user threads about flushed redo.
    
    8. Master thread no longer has to flush log [1;31mbuffer[m.
    
    9. Introduced dedicated log thread which is responsible for writing checkpoints.
       No longer concurrent user threads need to compete for this responsibility.
    
    10. Master thread no longer has to take care of periodical checkpoints.
        Log checkpointer thread writes checkpoint at least once per second
        (before it was once per 7 seconds).
    
    11. The following exposed system variables, can be changed in runtime now:
        * innodb_log_[1;31mbuffer[m_size,
        * innodb_log_write_ahead_size.
    
    12. Master thread measures average global cpu usage in OS.
    
    13. Introduced new exposed system variables:
        * innodb_log_wait_for_flush_spin_hwm,
        * innodb_log_spin_cpu_abs_lwm,
        * innodb_log_spin_cpu_pct_hwm.
        They control when we need to use spinning for the best performance,
        to reduce latency which would otherwise come from communication
        between log threads and user threads. The first one is based on
        average flush time, the two others are based on cpu usage.
    
    14. Introduced new CMake option: ENABLE_EXPERIMENT_SYSVARS=0/1. System variables
        can be marked as hidden unless the experiment mode is turned on.
    
    15. There is a list of hidden new system variables for experiments with redo log.
        We skip listing them here.
    
    16. Created dedicated tester for redo log alone (as gtest).
    
    17. Created doxygen documentation for the new redo log.
    
    18. The dict_persist margin is updated when number of dirty pages is
        changed, instead of calculations on demand.
    
    19. Mechanism used to copy last incomplete block for Clone has been changed,
        because log [1;31mbuffer[m is concurrent now.
    
    20. Added more useful MONITOR counters for redo, including average lsn rate.
    
    21. Introduced sharded rw-lock to have an option to stop the world in redo,
        because log_mutex is removed.
    
    22. Invented and implemented a concurrent data structure which tracks progress
        of concurrent operations and can answer up to which point they all have been
        finished (when there is some order defined but they are allowed to be executed
        out of the order). This structure is used for concurrent writes to log [1;31mbuffer[m
        and re-used for concurrent additions to flush lists.
    
    23. Introduced a universal mechanism to wait on event, which starts with
        provided number of spin delays, then fallbacks to waits on event,
        starting at small timeout, but increasing timeout every few waits.
        This mechanism is used in communication between user and log threads,
        and in communication between different log threads.
    
    24. We slow-down redo log writer when there is no space in redo allowing
        checkpoints to progress and rescue the state of redo.
    
    25. Log [1;31mbuffer[m can be resize in runtime - the size can also be decreased.
    
    26. Simplified shutdown procedure to avoid a possible returns in logic
        to previous phases.
    
    27. Removed concept of multiple log groups.
    
    28. Relaxed conditions required for checkpoint_lsn. It can now point to
        any data byte within redo (does not need to point to a records group
        beginning).
    
    29. Windows: always use [1;31mbuffer[med IO for redo log.
    
    30. Mysql test runner received a new feature (thanks to Marcin):
        --exec_in_background.
    
    Review: RB#15134
    
    Reviewers:
        - Marcin Babij <marcin.babij@oracle.com>,
        - Debarun Banerjee <debarun.banerjee@oracle.com>.
    
    Performance tests:
        - Dimitri Kravtchuk <dimitri.kravtchuk@oracle.com>,
        - Daniel Blanchard <daniel.blanchard@oracle.com>,
        - Amrendra Kumar <amrendra.x.kumar@oracle.com>.
    
    QA and MTR tests:
        - Vinay Fisrekar <vinay.fisrekar@oracle.com>.

[33mcommit 70e7706a52282cf477c875e4b69130c6d6137743[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Mon Feb 12 12:05:22 2018 +0100

    BUG#27368298: NORMALIZE_DIRNAME() CANNOT PROPERLY HANDLE STRINGS LONGER THAN
    FN_REFLEN
    
    Problem: All mysys path functions assume the destination [1;31mbuffer[m being
    passed to them is FN_REFLEN bytes long. But not all guarded against
    overwriting the [1;31mbuffer[m, and not all ensured that the destination [1;31mbuffer[m
    was '\0'-terminated.
    
    Solution: Ensure destination [1;31mbuffer[m is not overflowed, and makes sure it
    is '\0'-terminated. Add documentation which makes assumptions and
    guarantees explicit.
    
    Change-Id: I25e50f311df42209812b32aa710cea4d74ef9cee
    (cherry picked from commit 40ca13274916524d2f691ea396f59ef619f84a74)

[33mcommit dda3ab903e1bec6b16b170903ad19aee9da13a3d[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Mon Feb 12 12:05:22 2018 +0100

    BUG#27368298: NORMALIZE_DIRNAME() CANNOT PROPERLY HANDLE STRINGS LONGER THAN
    FN_REFLEN
    
    Problem: All mysys path functions assume the destination [1;31mbuffer[m being
    passed to them is FN_REFLEN bytes long. But not all guarded against
    overwriting the [1;31mbuffer[m, and not all ensured that the destination [1;31mbuffer[m
    was '\0'-terminated.
    
    Solution: Ensure destination [1;31mbuffer[m is not overflowed, and makes sure it
    is '\0'-terminated. Add documentation which makes assumptions and
    guarantees explicit.
    
    Change-Id: I25e50f311df42209812b32aa710cea4d74ef9cee

[33mcommit 28eac338d3593de8a4d0a74b2d11014ce9cbed35[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Fri Feb 2 15:01:09 2018 +0100

    Bug#27484133    WINDOW FUNCTIONS COULD READ LESS ROWS FROM TEMPORARY TABLE
    
    A refactoring of the logic of how window functions [1;31mbuffer[m rows and
    re-reads them from the frame [1;31mbuffer[m.
    This reduces the count of calls to handler::rnd_pos() by 25%.
    During this refactoring, other things have been cleaned up:
    - more comments in code
    - if user didn't specify a frame, create a frame of
    RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW (if there is ORDER BY
    in window), or
    BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING (sql_yacc.yy)
    This allows to eliminate quite few tests like "if frame==nullptr".
    - changed signature of create_tmp_table() to make it less
    window-ish: the last parameter (enum TMP_WIN*) is removed,
    because it's possible to infer its value from other information:
    we now give a non-zero Temp_table_param::m_window only if it's
    the OUT table, not the frame [1;31mbuffer[m; so testing m_window is equivalent
    to testing TWP_WIN_CONDITIONAL; not_all_columns is also used, as tmp
    tables which don't care for windowing have it false. Thus,
    enum_tmpfile_windowing_action is removed.
    - when we want to calculate FIRST/LAST/NTH_VALUE without
    modifying the current value of other aggregates, instead of evaluating
    other aggregates but with a "dont_aggregate" flag, we don't evaluate
    them (see CFT_WF_USES_ONLY_ONE_ROW)
    - "dynamic frame upper bound" strategy was for
    RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ;  instead, let it flow
    into the normal range-framing code, but still with a couple of if()s
    here and there to keep optimizations (see range_to_current_row and
    range_from_first_to_current_row)
    - cleaning up of some ref slices was missing (cleanup_item_list)
    - setup_tmp_table_write_func: "phase" can be inferred from
    qep_tab->ref_item_slice
    - saving/restoring special records FBC_FIRST_IN_STATIC_RANGE
    and FBC_LAST_RESULT_OPTIMIZED_RANGE was useless, as WF values
    of previous row are still present in OUT table.
    - sometimes we ask to fetch row N from frame [1;31mbuffer[m, and do the same
    shortly after; added Window::m_row_has_fields_in_out_table
    which keeps track of the last row fetched, so bring_back_frame_row()
    can consult this variable to know it doesn't really have to fetch
    it a second time.
    - m_input_row_clobbered was there to avoid a fetch in case
    the input row hadn't been clobbered; now that we have
    m_row_has_fields_in_out_table we can ask for a fetch unconditionally:
    if row hasn't been clobbered it won't actually be fetched.
    - introduced Window:m_needs_card to avoid recalculation of this info
    for every row (some_wf_needs_frame_card() is thus removed).
    - make "static aggregate" and "row inversion" and "range inversion"
    mutually exclusive
    - setup_windows(): merged prepared-stmt and non-prep-stmt init
    branches as much as possible
    - short-circuiting of last tmp table: made it apply to more cases
    (e.g. if SQL_BUFFER_RESULT and two windows, short-circuit is
    now possible)
    - mgmt of special records moved out of [1;31mbuffer[m_record_somewhere() for
    separation of concerns
    - it was common to call bring_back_frame_row() then copy_fields();
    made the former call the latter.
    - in process_[1;31mbuffer[med_windowing_record: if range frame, set
    upper_limit to INT64_MAX; this is clearer than having
    some_wf_needs_frame_card() return true if range frame (had the same
    effect, but was more hidden).
    - thanks to the caching in bring_back_frame_row(), two_pass_done logic
    is not needed anymore; removed; only one call to
    process_wfs_needing_card() is necessary in code.
    - reestablish_new_partition_row() removed
    - end_write_wf(): moved an if() up so that we have less nested blocks
    - The number of rnd_pos() calls is reduced as announced; but this is
    not tested in MTR, as numbers vary by a few units, depending on if
    test is run alone or not, with prep-stmt or not; so the SHOW STATUS
    are added to window_functions.test but commented out.

[33mcommit 80013ff933f7c9aad1a5da5b29bfd2df0eefc85b[m
Author: Debarun Banerjee <debarun.banerjee@oracle.com>
Date:   Wed Jan 31 10:55:45 2018 +0530

    BUG#27135742 CLONE CREATED IBDATA1 IS OF A DIFFERENT SIZE
    BUG#27245214 LATCHDEBUG::CHECK_ORDER
    
    Problem :
    ---------
    1. When file is extended in page copy stage we are always extending
    the first node/file for the tablespace. For multi-node system tablespace
    this results in extending the first file more than configured length.
    
    2. For persisting dynamic metadata, checkpoint needs to insert data into
    tables. A recent patch caused this regression, where checkpoint is
    called before releasing archiver mutex. This triggers the debug mode
    assert checking mutex order.
    
    3. Issue when clone lsn with block boundary
        - when Trailer chunk is first block in next redo file
        - when trailer chunk ends at file and block boundary
    
    4. Non-linux platforms are not using clone_[1;31mbuffer[m_size
    
    Solution :
    ----------
    1. Evaluate the right size and extend the last file after PAGE COPY
    2. Call checkpoint after releasing archiver mutex
    3. Avoid overwriting trailer if archived log ends at block boundary
    4. Add check if zero-copy is supported and use clone_[1;31mbuffer[m_size
    
    5. Tests for scenarios 1-4
    5A.Test shutdown while clone is in progress
    5B.Test coverage for clone with read/write when not using O_DIRECT
    
    Reviewed-by: Satya Bodapati <satya.bodapati@oracle.com>
    
    RB: 18427

[33mcommit a9d39aedf48f2a4afb2115ea52dcf174dcaf7448[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Tue Jan 30 05:52:32 2018 +0100

    Bug #27322254: WITH PERSIST_ONLY, VARIABLE VALUE EQUALS 18446744073709547520
                   IS STORED AS -4096
    
    Problem: @@max_binlog_cache_size when persisted using PERSIST_ONLY reflects
    wrong value when performance_schema.persisted_variables is queried. This is
    because in Item_func_get_system_var::val_str() unsigned flag for this value
    is ignored, thus ends up converting this value to a longlong.
    
    Fix: Fix is to check for unsigned_flag flag when storing the value in a
    string [1;31mbuffer[m.

[33mcommit e3e2ccc2cf00436a8be026ff421ec5e6facaaa1f[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Jan 25 10:50:14 2018 +0100

    Bug#27418207 MAIN.COMMENT_COLUMN2 FAILS WITH COMPRESSION
    
    Before this fix,
    the following assert fails in sql-common/net_serv.cc,
    in function net_read_packet()
    
        /*
          The right-hand expression
          must match the size of the [1;31mbuffer[m allocated in net_realloc().
        */
        DBUG_ASSERT(net->where_b + NET_HEADER_SIZE + sizeof(uint32) <=
                    net->max_packet + NET_HEADER_SIZE + COMP_HEADER_SIZE);
    
    This is a regression introduced by:
    
    commit 304578be76ba4c4f012c0a591c751ce9fcbb169b
    Author: Tor Didriksen <tor.didriksen@oracle.com>
    Date:   Wed Jan 8 15:12:04 2014 +0100
    
        Bug#17922198 REMOVE OBSOLETE IFDEF HAVE_PURIFY CODE.
    
        Patch #6
        Do not allocate extra byte for uint3korr.
    
    Before this change:
    - uint3korr could read 4 bytes instead of 3
    - an extra byte was allocated as safety
    so that the assert was of the form
    
      DBUG_ASSERT( ... + sizeof(uint32) <= ... + COMP_HEADER_SIZE + 1);
    
    This represents that memory used by the code, in the left hand side,
    is actually within the memory allocated for the data, in the right hand
    side.
    
    The expression "sizeof(uint32)" represented the 4 bytes used by uint3korr.
    
    When the code for uint3korr() was fixed to use really only 3 bytes
    instead of 4, the allocation was shortened by 1 byte (right hand side),
    but the left hand side was forgotten (only 3 bytes are used, not 4),
    causing the regression.
    
    The fix is to implement the correct assert, as in:
    
        DBUG_ASSERT(... + 3 <=
                    ... + COMP_HEADER_SIZE);

[33mcommit 19ca83a71f2d6e7a29feeb6a9082fd50889db788[m
Author: Havard Dybvik <havard.dybvik@oracle.com>
Date:   Thu Jan 11 17:41:31 2018 +0100

    Bug#27312703 ASAN: HEAP-USE-AFTER-FREE: GREATEST/LEAST FUNCTIONS
    
    The underlying [1;31mbuffer[m of a String passed to val_str() was reused in the
    returned String, although the two Strings themselves were different
    objects. Hence, despite being two seemingly independent Strings, freeing
    the allocated space in one of them invalidated the [1;31mbuffer[m of the other.
    Because the String comparison function accesses the underlying [1;31mbuffer[ms
    of both Strings, both [1;31mbuffer[ms need to be non-overlapping and valid at
    time of comparison. Failing to meet this requirement caused
    HEAP-USE-AFTER-FREE.
    
    To ensure use of two distinct String objects with non-overlapping and
    valid [1;31mbuffer[ms, use a boolean variable instead of pointer comparisons to keep
    track of which String object to pass to val_str().
    
    Also changed:
     - Follow the design of other Item classes and reintroduce a String
     member to the Item class for LEAST/GREATEST to avoid copying from a
     temporary [1;31mbuffer[m after comparison.
     - To improve readability in comparison functions for LEAST/GREATEST,
     use a boolean member variable instead of a comparison sign to determine
     whether arguments should be compared as LEAST or GREATEST.
     - Rewrite signed/unsigned integer comparison in LEAST/GREATEST.
    
    Change-Id: Ica42f259fc2176e9cd00513304b636f9bd7dd6dd

[33mcommit f3eae17a7fa5d73419270381dd5c8a31f8403c92[m
Author: Neha Kumari <neha.n.kumari@oracle.com>
Date:   Thu Jan 18 15:09:18 2018 +0530

    Bug#27147095: CONTRIBUTION BY FACEBOOK: ADD RPL_READ_SIZE OPTION
    
    This adds a server variable "rpl_read_size" with a default value of 8kb. It
    must be a multiple of 4kb.
    
    This sets the size for reads done from the relay log and binlog. Making it
    larger might help with IO stalls while reading these files when they are not
    in the OS [1;31mbuffer[m cache.

[33mcommit d11f4c5c8aa63700797eac247818f39361a81356[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Fri Jan 5 13:51:56 2018 +0100

    Bug #27348547: MINOR FILESORT CLEANUPS [temp [1;31mbuffer[m] [noclose]
    
    Since bug #25688673, we always use strnxfrm when sorting items (the special
    code for some old collations that could be transformed in-place was removed).
    Thus, we can remove the code path that doesn't go via a temporary [1;31mbuffer[m.
    
    Change-Id: I68407f9dde858c36aafce67c91987e4a84d9781f

[33mcommit 468b36d6a5d01324226728a8a82771cf5df34316[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Wed Jan 10 16:44:23 2018 +0800

    Bug #24702091   MTR'S CHECK OF RPL_NOGTID.RPL_UPGRADE_SLAVE_MASTER_INFO FAILS
    
    Problem
    =======
    MTR's internal check of some test scripts failed as below.
     block_encryption_mode  aes-128-ecb
     bulk_insert_[1;31mbuffer[m_size        8388608
    -character_sets_dir     /export/home2/pb2/test/sb_3-20434341-1473926827.77/mysql-8
    .0.1-dmr-linux-x86_64-devbld/share/charsets/
    +character_sets_dir     /export/home2/pb2/test/sb_3-20434341-1473926827.77/mysql-8
    .0.1-dmr-linux-x86_64-devbld/share/cha
     character_set_client   latin1
     character_set_connection       latin1
    
    Analysis
    ========
    The mysql_set_character_set_with_default_collation and
    mysql_set_character_set (both defined in client.cc) will temporarily
    change the global variable charsets_dir. This makes them
    non-thread-safe.
    In particular, this can cause access to freed memory in the replication
    receiver thread (aka IO thread) when using multi-source replication. In
    multi-source replication, two such threads are likely to start executing
    at nearly the same time. Then both threads can do the following at about
    the same time:
     1. From connect_to_master:
         1.1. call mysql_options(mysql, MYSQL_SET_CHARSET_DIR, (char *)
    charsets_dir), which will
         1.2. set mysql->options.charset_dir to strdup(charsets_dir).
     2. From connect_to_master:
         2.1. call mysql_reconnect, which will call
         2.2. mysql_set_character_set, which will
         2.3. temporarily change the global charsets_dir to
    mysql->options.charset_dir, then
         2.4. do some work, and finally
         2.5. change back charsets_dir to its previous value
     3. From handle_slave_io, call mysql_close, which calls
    mysql_close_free_options, which frees mysql->options.charset_dir.
    
    Since no locks are protecting the global charsets_dir, the following
    can happen:
     1. T1 executes 1, 2.1, 2.2, 2.3, leaving the global charsets_dir set
    to the T1's mysql->options.charset_dir.
     2. T2 executes 1.1 (thus passing T1's mysql->options.charset_dir as
    the third argument to mysql_set_options), 1.2 (allocate the same space
    pointed by T1's mysql->options.charset_dir) and 2 (store dir into the
    space allocated above).
     3. T1 continues to execute 2.4, 2.5, 3 (restoring the global
    charsets_dir and freeing T1's mysql->options.charset_dir)
     4. T2's mysql->options.charset_dir is freed before it executes 3,
    since it points to the same space with T1's mysql->options.charset_dir.
    
    So the global charsets_dir of a running server is changed unsafely.
    
    Fix
    ===
    After fixing Bug#24465518, we don't change the global charsets_dir
    of a running server, so the problem was fixed. Then we can remove
    force_restart.inc from these test scripts.

[33mcommit 12065270b029821c1dd39dc943c89bbafd92be91[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Wed Dec 13 10:41:29 2017 +0100

    Bug #27273676: SEPARATE UNIQUE AND FILESORT RESULT BUFFERS
    
    When doing unique, e.g. for index merge, it stores its results in filesort's
    [1;31mbuffer[ms. Among others, this means that when having unique + sort together,
    there needs to be copying gymnastics to avoid them stepping on top of each
    others. Separate them out by making a separate result structure that can then
    be duplicated.
    
    Change-Id: Idf272ed5ba16db471e03535cf839242a1f1f6b7d

[33mcommit e3ac8e72aa4ff0df86e61642056edbd4531957ae[m
Author: Daogang Qu <bill.qu@oracle.com>
Date:   Fri Jan 5 16:13:16 2018 +0800

    Bug #24700334   MTR'S CHECK OF RPL.RPL_MULTI_SOURCE_SLAVE_START_STOP FAILS
    
    Problem
    =======
    MTR's internal check of some test scripts failed as below.
     block_encryption_mode  aes-128-ecb
     bulk_insert_[1;31mbuffer[m_size        8388608
    -character_sets_dir     G:/ade/test/sb_1-20445141-1473971193.18/mysql-advanced-8.0.1-dmr-winx64/share/charsets/
    +character_sets_dir
     character_set_client   latin1
     character_set_connection       latin1
    
    Analysis
    ========
    The mysql_set_character_set_with_default_collation and
    mysql_set_character_set (both defined in client.cc) will temporarily
    change the global variable charsets_dir. This makes them
    non-thread-safe.
    In particular, this can cause access to freed memory in the replication
    receiver thread (aka IO thread) when using multi-source replication. In
    multi-source replication, two such threads are likely to start executing
    at nearly the same time. Then both threads can do the following at about
    the same time:
     1. From connect_to_master:
         1.1. call mysql_options(mysql, MYSQL_SET_CHARSET_DIR, (char *)
    charsets_dir), which will
         1.2. set mysql->options.charset_dir to strdup(charsets_dir).
     2. From connect_to_master:
         2.1. call mysql_reconnect, which will call
         2.2. mysql_set_character_set, which will
         2.3. temporarily change the global charsets_dir to
    mysql->options.charset_dir, then
         2.4. do some work, and finally
         2.5. change back charsets_dir to its previous value
     3. From handle_slave_io, call mysql_close, which calls
    mysql_close_free_options, which frees mysql->options.charset_dir.
    
    Since no locks are protecting the global charsets_dir, the following
    can happen:
     1. T1 executes 1, 2.1, 2.2, 2.3, leaving the global charsets_dir set
    to the T1's mysql->options.charset_dir.
     2. T2 executes 1.1 (thus passing T1's mysql->options.charset_dir as
    the third argument to mysql_set_options), 1.2 (allocate the same space
    pointed by T1's mysql->options.charset_dir) and 2 (store dir into the
    space allocated above).
     3. T1 continues to execute 2.4, 2.5, 3 (restoring the global
    charsets_dir and freeing T1's mysql->options.charset_dir)
     4. T2's mysql->options.charset_dir is freed before it executes 3,
    since it points to the same space with T1's mysql->options.charset_dir.
    
    So the global charsets_dir of a running server is changed unsafely.
    
    Fix
    ===
    After fixing Bug#24465518, we don't change the global charsets_dir
    of a running server, so the problem was fixed. Then we can remove
    force_restart.inc from these test scripts.

[33mcommit a01d73860243326334da26a60e21813d175b947d[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Tue Jan 2 18:34:27 2018 +0100

    Bug#27312444: ASAN: MEMCPY-PARAM-OVERLAP WITH JSON_QUOTE FUNCTION
    
    The JSON_QUOTE function could in some situations write the quoted
    string to the same [1;31mbuffer[m that holds the input string, which could
    lead to wrong results.
    
    Make sure that it doesn't write into the same [1;31mbuffer[m as it is reading
    from.
    
    Change-Id: Ic0830346433f79d2e0fc799e03b76c3f6465846f

[33mcommit 2987079abfe37e120433e20e6d0ef8a9fb1a198b[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Dec 20 12:13:06 2017 +0100

    Bug#27294450    VALGRIND: BYTES_SENT() DETECT UNINITIALIZE MEMBER SEND_BUFFER::M_SENDING_SIZE
    
    The member variables m_[1;31mbuffer[med_size and m_sending_size was not initialized in send_[1;31mbuffer[m_init().
    Could possibly cause incorrect 'send [1;31mbuffer[m usage levels' to be calculated, which in
    turn could cause unoptimal send scheduling polizies to be used.
    
    Patch init them.

[33mcommit befab48d9a3cd52e71fbe0989e1380d3924b73b0[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon Dec 18 15:30:27 2017 +0100

    Bug #27218248   MOVE THE 'DEFAULT' SEND_BUFFER HANDLING OUT OF 'CLASS TRANSPORTERREGISTRY'
    
    Pure refactoring patch:
    
    'class TransporterRegistry' is a common component used both internally in the
    data nodes, and as part of the NDB API transporter stack. It 'collects' the
    different aspects of possibly multiple Transporter implementations, and
    different send- and receiver-[1;31mbuffer[m providers and consumers used by either
    multi-threaded or single-threaded ndb, or the NDB API.
    
    Even though this is intended to be a general components, it also has a
    'default' implementation of the send-[1;31mbuffer[ms. This is only used by the
    single-threaded ndb, so this code is really misplaced in class
    TransporterRegistry.
    
    This patch moves the 'default' send_[1;31mbuffer[m implementation out of
    class TransporterRegistry and into class TransporterCallbackKernelNonMT.
    This class already contain other non-mt kernel implementations and seems
    like a natural harbour for this stuff.

[33mcommit 94f5b892bf9c0a8c2a09c5e108004afa0f73e4c7[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Dec 14 15:14:04 2017 +0100

    Bug#24444908  CLUSTER CRASHED DURING RESTART WITH AN ASSERTION `!CALLBACKOBJ->HAS_DATA_TO_SEND
    
    Follow up patch fixing regressions caused by original patch.
    
    There basically were two issues identified:
    
    1) TransporterFacade::enable_send_[1;31mbuffer[m() and ::disable_send_[1;31mbuffer[m() could cause
       a deadlock as they took the TransporterFacade::m_open_close_mutex and
       trp_client::m_mutex in the wrong order. Intention here was to ensure
       that TransporterFacade::m_enabled_nodes_mask and each clients m_enabled
       flag was updated atomically.
    
    2) There were no concurrency protection against different threads starting
       a enable_send_[1;31mbuffer[m() immediately after a disable_send_[1;31mbuffer[m() (Immediately
       trying to reconnect) where the later 'enable could overtake the 'disable',
       resulting in undefined states transitions in the send [1;31mbuffer[ms.
    
    Patch revert (most of) a previous addendum patch attempted to fix these regressions.
    
    Fix for 1) is to reduce the scope of the 'm_open_close_mutex' in the TF enable/disable
    methods, such that it is not held together with the trp_client::m_mutex.
    These overlapping mutexes didn't really serve any purposes anyway as ::open_clnt(),
    which use m_enabled_nodes_mask, has to handle the trp_client enable/disable
    initially not being entirely 'in synch' - Extended comments to cover this.
    
    Fix for 2) is move calls to enable_send_[1;31mbuffer[m() and disable_send_[1;31mbuffer[m()
    into report_connect() and report_disconnect() which is called as poll-owner.
    Thus, enable/disable could only be called from a single thread, providing the
    required serialization of these calls. In addition it also guards against
    a :close() removing the client under the feet of enable/disable as close
    is also guarded by the poll-right.
    
    Note that prior to original patch for this bug, ::reset_send_[1;31mbuffer[ms() used
    to be called from the same report_* methods, before this patch replaced 'reset'
    with enable/disable and placed the calls at the incorrect place.

[33mcommit 2a8959b762a56142dff03a1c971aa5ffe9e343b3[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon Dec 11 13:24:13 2017 +0100

    Bug #27246870   'RESERVED SENDBUFFER' CONCEPT BROKE 'TESTNDBAPI -N MGMDSENDBUFFEREXHAUST'
    
    Change 'send [1;31mbuffer[m free' calculation to not count reserved [1;31mbuffer[m as 'free'
    Also fix ATR test case 'testNdbApi -n MgmdSend[1;31mbuffer[mExhaust' which 'passed'
    even if we could not 'get_status' from mgmd due to lack of send [1;31mbuffer[ms.

[33mcommit cbe26d1e7aa66ba87d6e3da243e03887356c14ca[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon Dec 11 09:19:05 2017 +0100

    bug#24444908  CLUSTER CRASHED DURING RESTART WITH AN ASSERTION `!CALLBACKOBJ->HAS_DATA_TO_SEND.
    
    Move MTR test case added for this bug from ndb_disconnect.test to its own
    ndb_send[1;31mbuffer[m.test.
    
    Test case assumed that code was compiled with debug + ERROR_INSERT which is
    now required in ndb_send[1;31mbuffer[m.test (else it is skipped)

[33mcommit f3552d77d216f4ac147619d3d4ca6ca6fe2cd003[m
Author: Praveenkumar Hulakund <praveenkumar.hulakund@oracle.com>
Date:   Fri Dec 8 02:22:09 2017 +0100

    Bug#25887335 - test case innodb_mysql_sync crash on pb2 run
    
    Issue here is, socket of the killed connection (using KILL
    statement) is not closed. Because of this assert condition
    to check if socket [1;31mbuffer[m is empty, failed.
    
    When thread is in the kill immune mode, kill is not executed
    immediately. kill state is saved and it is applied while exiting
    from the kill immune mode. If the operation is KILL_CONNECTION
    then thread socket connection should be closed but while exiting
    kill immune mode socket was not getting closed. Hence write to
    socket after this step as causing client side assertion.
    
    To fix this issue, code is modified to close socket connection
    for KILL_CONNECTION operation even while exiting from the
    kill immune mode.
    
    Change-Id: I96a9543c9173fd5840ce25e7e6c45e060a680802

[33mcommit f043f0205d50cfdc720271772e29c52b6299ccd6[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Dec 7 14:33:00 2017 +0100

    bug#24444908  CLUSTER CRASHED DURING RESTART WITH AN ASSERTION `!CALLBACKOBJ->HAS_DATA_TO_SEND.
    
    Addendum patch to fix a regression introduce by previous patch set:
    
    Patch for this bug introduced enable/disable semantics for send_[1;31mbuffer[ms. Initially
    all send [1;31mbuffer[ms are disabled, and got enabled as Transporters 'connect', or
    when we 'open' a ned trp_client.
    
    However, if the 'open' of a new client required the m_threads[] array to
    be expanded, it have to send a request signal to its own clusterMgr.
    This happened *before* we had set up which nodes send_bufffers were enabled
    for this client. Thus the send (silently) failed, and 'open' waited
    forever for the m_threads[] array to be expanded.
    
    This patch reordered the 'open' logic, such that the TransporterFacade set
    of already enabled send_[1;31mbuffer[ms are assigned to the to-be-opened-client
    before we possible send the expand request.

[33mcommit 5d7eb6605a1400d90a0434446ea6e3e08437635b[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:38:57 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    and
    
    Bug#25128512 SET RR WITH >1 NG FAILS DUE TO 'WE(1) HAVE BEEN DECLARED DEAD BY 2 (VIA 4)'
    
    Patch fixes race conditions related to asynchronous disconnect / reconnect
    of the transporter while there could be other threads concurrently
    inserting signal data into the send [1;31mbuffer[ms.
    
    A ::reset_send_[1;31mbuffer[m() was performed as part of a disconnect, and
    we required the send [1;31mbuffer[ms to still be empty when we later reconnect.
    When this failed, we could either hit the '!has_data_to_send' assert,
    or we received malicous data which had survived the disconnect.
    
    This patch introduce a number of changes to the Transporter implementations
    in order to fix the insufficent concurrency controll:
    
    1)
     The virtual TransporterCallback method reset_send_[1;31mbuffer[m() is
    replaced with the methods enable_send_[1;31mbuffer[m() / disable_send_[1;31mbuffer[m().
    As part of this an 'enabled' state is also introduced in each implementation
    of the TransporterCallback. This enable us to discard any thread local
    send [1;31mbuffer[ms which are 'late' in being appended to a disabled transporter.
    
    1a)
     Enable and disabling of send [1;31mbuffer[ms has been moved into the
    Transporter::connect* methods instead of having them in the
    TransporterRegistry::report_connect/_disconnect. The *receivers*
    are inited here as their connection state is protected by the
    poll right. However, the poll right gives no such protection
    for the send [1;31mbuffer[ms. (Added a large comment about this)
    
    Thus, it feels more correct to handle
    the send [1;31mbuffer[ms where the transporters are connected.
    
    1b)
     The method has_data_to_send() was removed as part of 1). As any
    'data_to_send' could later be discarded by disabling a node, it
    didn't really make sense to check for 'has_data' is it could
    immediately go away before doSend or whatever. Similar logic has
    instead been added to get_bytes_to_send_iovec(), where we with necessary
    locks held can collect (or discard) send [1;31mbuffer[m to doSend().
    
    2) Added the TransporterSendBufferHandle interface method ::isSendEnabled().
    It replace the usage if Transporter::isConnected() where this method was
    used in a 'send context'. isSendEnabled() provides us with a thread safe
    way of checking if send is enabled for a specific 'send handle'.
    
    2a) Usage of Transporter::isConnected in TransporterRegistry::prepareSend()
    is replaced with ::isSendEnabled().
    
    2b) Defined a 'synchronized' (client threads) or 'optimistic' (data nodes)
    implementation of ::isSendEnabled(). The 'synchronized' implementation
    should be the 'safe' implemetation which Transporter::isConnected() never
    was. This provides us with a thread safe way of checking the connectivity
    to a specific node. (API clients)
    
    2c) Datanodes (both mt- and non-mt) never really cared about a SEND_DISCONNECTED
    error from prepareSend() as it was ignored in the SimulatedBlock::sendSignal()
    methods. (Handled as SEND_OK together with SEND_BLOCKED). So an 'optimistic'
    ::isSendEnabled() is implemented here. (A 'synchronized' implememtation
    with have required taking a mutex, which we probably cant afford)
    Any send [1;31mbuffer[ms allocated data to disabled nodes are discarded by the
    frequent doSend() calling get_bytes_to_send_iovec()

[33mcommit ec54ad242e1326d3424174ce9bd5d953c67a3298[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Nov 9 12:33:59 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    Testcase based on previous dump-2355-patch from Frazer:
    
      ALL DUMP 2355 <nodeId>
    
      On nodeId, it waits a short time (200 millis), then it shuts down.
      On non-nodeId nodes, it starts sending harmless signals to nodeId, but with an
      artificial delay in the signal preparation, so that the shut down of the
      destination may occur 'during' this preparation phase.
      The 'assert that the sendBuffer is empty' code is uncommented.
    
      Effect :
      - NodeId shuts down, then in early restart the other node(s) get an assertion
        failure as their SendBuffers for the node are not empty at connect time.
    
      Why :
      - Sending a signal is not atomic w.r.t. the transporter disconnecting, the
        send [1;31mbuffer[m being cleared, and signal sending being stopped
      - Therefore it is possible for ongoing sends to get into the send [1;31mbuffer[m
        *after* the send [1;31mbuffer[m has been cleared
      - This can cause the assert to fail when communication is opened again :
        Bug #24444908
      - This can cause a previous-incarnation FAIL_REP to be reanimated and kill
        the new node incarnation :
        Bug #25128512
    
    Additionaly two 'fixes' related to these bugs,:
    
      1.  Remove bad error handing code in TransporterRegistry::connect_server
          Once the Transporter itself has connected, it owns the socket, so we must
          not close it from the TransporterRegistry::newSession() thread
    
      2.  Small improvements to FD nulling

[33mcommit e4942b663f3b81e4c4669a729cd9c114dda0b7df[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:38:57 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    and
    
    Bug#25128512 SET RR WITH >1 NG FAILS DUE TO 'WE(1) HAVE BEEN DECLARED DEAD BY 2 (VIA 4)'
    
    Patch fixes race conditions related to asynchronous disconnect / reconnect
    of the transporter while there could be other threads concurrently
    inserting signal data into the send [1;31mbuffer[ms.
    
    A ::reset_send_[1;31mbuffer[m() was performed as part of a disconnect, and
    we required the send [1;31mbuffer[ms to still be empty when we later reconnect.
    When this failed, we could either hit the '!has_data_to_send' assert,
    or we received malicous data which had survived the disconnect.
    
    This patch introduce a number of changes to the Transporter implementations
    in order to fix the insufficent concurrency controll:
    
    1)
     The virtual TransporterCallback method reset_send_[1;31mbuffer[m() is
    replaced with the methods enable_send_[1;31mbuffer[m() / disable_send_[1;31mbuffer[m().
    As part of this an 'enabled' state is also introduced in each implementation
    of the TransporterCallback. This enable us to discard any thread local
    send [1;31mbuffer[ms which are 'late' in being appended to a disabled transporter.
    
    1a)
     Enable and disabling of send [1;31mbuffer[ms has been moved into the
    Transporter::connect* methods instead of having them in the
    TransporterRegistry::report_connect/_disconnect. The *receivers*
    are inited here as their connection state is protected by the
    poll right. However, the poll right gives no such protection
    for the send [1;31mbuffer[ms. (Added a large comment about this)
    
    Thus, it feels more correct to handle
    the send [1;31mbuffer[ms where the transporters are connected.
    
    1b)
     The method has_data_to_send() was removed as part of 1). As any
    'data_to_send' could later be discarded by disabling a node, it
    didn't really make sense to check for 'has_data' is it could
    immediately go away before doSend or whatever. Similar logic has
    instead been added to get_bytes_to_send_iovec(), where we with necessary
    locks held can collect (or discard) send [1;31mbuffer[m to doSend().
    
    2) Added the TransporterSendBufferHandle interface method ::isSendEnabled().
    It replace the usage if Transporter::isConnected() where this method was
    used in a 'send context'. isSendEnabled() provides us with a thread safe
    way of checking if send is enabled for a specific 'send handle'.
    
    2a) Usage of Transporter::isConnected in TransporterRegistry::prepareSend()
    is replaced with ::isSendEnabled().
    
    2b) Defined a 'synchronized' (client threads) or 'optimistic' (data nodes)
    implementation of ::isSendEnabled(). The 'synchronized' implementation
    should be the 'safe' implemetation which Transporter::isConnected() never
    was. This provides us with a thread safe way of checking the connectivity
    to a specific node. (API clients)
    
    2c) Datanodes (both mt- and non-mt) never really cared about a SEND_DISCONNECTED
    error from prepareSend() as it was ignored in the SimulatedBlock::sendSignal()
    methods. (Handled as SEND_OK together with SEND_BLOCKED). So an 'optimistic'
    ::isSendEnabled() is implemented here. (A 'synchronized' implememtation
    with have required taking a mutex, which we probably cant afford)
    Any send [1;31mbuffer[ms allocated data to disabled nodes are discarded by the
    frequent doSend() calling get_bytes_to_send_iovec()

[33mcommit 475a412e3903dac02bf9da3e4e240ae56b3d4685[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Nov 9 12:33:59 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    Testcase based on previous dump-2355-patch from Frazer:
    
      ALL DUMP 2355 <nodeId>
    
      On nodeId, it waits a short time (200 millis), then it shuts down.
      On non-nodeId nodes, it starts sending harmless signals to nodeId, but with an
      artificial delay in the signal preparation, so that the shut down of the
      destination may occur 'during' this preparation phase.
      The 'assert that the sendBuffer is empty' code is uncommented.
    
      Effect :
      - NodeId shuts down, then in early restart the other node(s) get an assertion
        failure as their SendBuffers for the node are not empty at connect time.
    
      Why :
      - Sending a signal is not atomic w.r.t. the transporter disconnecting, the
        send [1;31mbuffer[m being cleared, and signal sending being stopped
      - Therefore it is possible for ongoing sends to get into the send [1;31mbuffer[m
        *after* the send [1;31mbuffer[m has been cleared
      - This can cause the assert to fail when communication is opened again :
        Bug #24444908
      - This can cause a previous-incarnation FAIL_REP to be reanimated and kill
        the new node incarnation :
        Bug #25128512
    
    Additionaly two 'fixes' related to these bugs,:
    
      1.  Remove bad error handing code in TransporterRegistry::connect_server
          Once the Transporter itself has connected, it owns the socket, so we must
          not close it from the TransporterRegistry::newSession() thread
    
      2.  Small improvements to FD nulling

[33mcommit d6bf2b19f240e60c8c86240c61748b75b4019655[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Nov 21 15:38:57 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    and
    
    Bug#25128512 SET RR WITH >1 NG FAILS DUE TO 'WE(1) HAVE BEEN DECLARED DEAD BY 2 (VIA 4)'
    
    Patch fixes race conditions related to asynchronous disconnect / reconnect
    of the transporter while there could be other threads concurrently
    inserting signal data into the send [1;31mbuffer[ms.
    
    A ::reset_send_[1;31mbuffer[m() was performed as part of a disconnect, and
    we required the send [1;31mbuffer[ms to still be empty when we later reconnect.
    When this failed, we could either hit the '!has_data_to_send' assert,
    or we received malicous data which had survived the disconnect.
    
    This patch introduce a number of changes to the Transporter implementations
    in order to fix the insufficent concurrency controll:
    
    1)
     The virtual TransporterCallback method reset_send_[1;31mbuffer[m() is
    replaced with the methods enable_send_[1;31mbuffer[m() / disable_send_[1;31mbuffer[m().
    As part of this an 'enabled' state is also introduced in each implementation
    of the TransporterCallback. This enable us to discard any thread local
    send [1;31mbuffer[ms which are 'late' in being appended to a disabled transporter.
    
    1a)
     Enable and disabling of send [1;31mbuffer[ms has been moved into the
    Transporter::connect* methods instead of having them in the
    TransporterRegistry::report_connect/_disconnect. The *receivers*
    are inited here as their connection state is protected by the
    poll right. However, the poll right gives no such protection
    for the send [1;31mbuffer[ms. (Added a large comment about this)
    
    Thus, it feels more correct to handle
    the send [1;31mbuffer[ms where the transporters are connected.
    
    1b)
     The method has_data_to_send() was removed as part of 1). As any
    'data_to_send' could later be discarded by disabling a node, it
    didn't really make sense to check for 'has_data' is it could
    immediately go away before doSend or whatever. Similar logic has
    instead been added to get_bytes_to_send_iovec(), where we with necessary
    locks held can collect (or discard) send [1;31mbuffer[m to doSend().
    
    2) Added the TransporterSendBufferHandle interface method ::isSendEnabled().
    It replace the usage if Transporter::isConnected() where this method was
    used in a 'send context'. isSendEnabled() provides us with a thread safe
    way of checking if send is enabled for a specific 'send handle'.
    
    2a) Usage of Transporter::isConnected in TransporterRegistry::prepareSend()
    is replaced with ::isSendEnabled().
    
    2b) Defined a 'synchronized' (client threads) or 'optimistic' (data nodes)
    implementation of ::isSendEnabled(). The 'synchronized' implementation
    should be the 'safe' implemetation which Transporter::isConnected() never
    was. This provides us with a thread safe way of checking the connectivity
    to a specific node. (API clients)
    
    2c) Datanodes (both mt- and non-mt) never really cared about a SEND_DISCONNECTED
    error from prepareSend() as it was ignored in the SimulatedBlock::sendSignal()
    methods. (Handled as SEND_OK together with SEND_BLOCKED). So an 'optimistic'
    ::isSendEnabled() is implemented here. (A 'synchronized' implememtation
    with have required taking a mutex, which we probably cant afford)
    Any send [1;31mbuffer[ms allocated data to disabled nodes are discarded by the
    frequent doSend() calling get_bytes_to_send_iovec()

[33mcommit c4734d8ff4473d472ffad456a263a2029aeb66a6[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Nov 9 12:33:59 2017 +0100

    Bug#24444908: CLUSTER CRASHED DURING RESTART WITH AN ASSERTION !CALLBACKOBJ->HAS_DATA_TO_SEND
    
    Testcase based on previous dump-2355-patch from Frazer:
    
      ALL DUMP 2355 <nodeId>
    
      On nodeId, it waits a short time (200 millis), then it shuts down.
      On non-nodeId nodes, it starts sending harmless signals to nodeId, but with an
      artificial delay in the signal preparation, so that the shut down of the
      destination may occur 'during' this preparation phase.
      The 'assert that the sendBuffer is empty' code is uncommented.
    
      Effect :
      - NodeId shuts down, then in early restart the other node(s) get an assertion
        failure as their SendBuffers for the node are not empty at connect time.
    
      Why :
      - Sending a signal is not atomic w.r.t. the transporter disconnecting, the
        send [1;31mbuffer[m being cleared, and signal sending being stopped
      - Therefore it is possible for ongoing sends to get into the send [1;31mbuffer[m
        *after* the send [1;31mbuffer[m has been cleared
      - This can cause the assert to fail when communication is opened again :
        Bug #24444908
      - This can cause a previous-incarnation FAIL_REP to be reanimated and kill
        the new node incarnation :
        Bug #25128512
    
    Additionaly two 'fixes' related to these bugs,:
    
      1.  Remove bad error handing code in TransporterRegistry::connect_server
          Once the Transporter itself has connected, it owns the socket, so we must
          not close it from the TransporterRegistry::newSession() thread
    
      2.  Small improvements to FD nulling

[33mcommit 0a7b26bf13c6e028852fe5d4ea26d6b3c72e38ce[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Wed Dec 6 06:13:50 2017 +0100

    Bug #26100122: SERVER CRASHES WHEN SET PERSIST CALLS WITH A LONG STATEMENT
    
    Problem: During execution of set persist statement variable name and its
    value are copied to a local [1;31mbuffer[m before writing to mysqld-auto.cnf. The
    assumption is that the variable value can no longer be more than 1024 bytes,
    however in this case since the value is more than 1024 bytes, there is a heap
    corruption, causing server to crash.
    
    Fix: Fix is to allocate the needed memory on heap and copy the needed value
    into respective [1;31mbuffer[ms and release the memory.

[33mcommit 6223def1bef68bba4a39ce7d3289bec28ce79750[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Mon Dec 4 10:05:28 2017 +0530

    Bug#27149369: ASSERTION FAILURE IN BOOL
                  READ_FRAME_BUFFER_ROW(INT64, WINDOW*, BOOL)
    
    Problem:
    When handling range frames, if the first row for a range frame is found,
    currently we do not store the position - REA_FIRST_IN_FRAME(as a hint).
    This affects how we retrieve the row from frame [1;31mbuffer[m and fails the assert.
    
    Analysis:
    For these set of values - 392, 1027,1027,1034,1039 and window having
    RANGE BETWEEN 7 PRECEDING and 1 PRECEDING,
    For the fourth row, when calculating the rows that are in range, 1027 from
    row 3 will be marked as first in frame and 1027 from row 4 will be
    marked as last in frame. As a result when we get back to calculating
    "last_value" for row 5 (value 1039)- Since we have first_row < last_row
    in the frame for the previous range frame, we try and retrieve
    FIRST_ROW_IN_FRAME from the frame [1;31mbuffer[m. But we fail to find the row using
    the hints present in [1;31mbuffer[m_positions.
    
    Solution:
    Store the hint REA_FIRST_IN_FRAME when we find the first row in the range
    frame as this will be used for the next range frame calculation.

[33mcommit 1df8e73e8c7af22c74bef0ab6c0f89bc69b0ee10[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Nov 28 15:51:54 2017 +0100

    Bug#27169809 FIX BUG 17583 FOR ALPINE LINUX
    
    This is an extra addition to the bugfix described below.
    To ensure consistent behaviour also on Alpine, open an extra file descriptor.
    
    Also: when reporting errors in batch mode, flush stdout before flushing stderr.
    This makes the output consistent for commands like
    -- exec mysql test>&1 < "<path to input file>"
    
    Similarly for mysqldump: flush the result file before dumping any error
    reports, to make output deterministic.
    
    Bug#17583: mysql drops connection when stdout is not writable
    
    When the client program had its stdout file descriptor closed by the calling
    shell, after some amount of work (enough to fill a socket [1;31mbuffer[m) the server
    would complain about a packet error and then disconnect the client.
    
    This is a serious problem.  If stdout is closed before the mysql is
    exec()d, then the first socket() call allocates file number 1 to communicate
    with the server.  Subsequent write()s to that file number (as when printing
    results that come back from the database) go back to the server instead in
    the command channel.  So, one should be able to craft data which, upon being
    selected back from the server to the client, and injected into the command
    stream become valid MySQL protocol to do something nasty when sent /back/ to
    the server.
    
    The solution is to close explicitly the file descriptor that we *printf() to,
    so that the libc layer and the OS layer both agree that the file is closed.
    
    Change-Id: Ic74a2cb752d1a66ff6d7e8e9b8fb98fb85636051

[33mcommit 16673aba200c812a413b7b408ce81127695716c7[m
Author: Havard Dybvik <havard.dybvik@oracle.com>
Date:   Mon Nov 27 08:56:25 2017 +0100

    Bug#27121663: SIG 11 IN FILL_DD_VIEW_TABLES | SQL/DD/DD_VIEW.CC
    
    The name of a derived table was not saved before the table was
    materialized and assigned the name of the temporary table. When the
    table name was later to be restored to its original value, an invalid
    reference (nullptr) was set. This caused the server to crash because
    'strlen' was called with nullptr as argument.
    
    As a fix, add a call to save_name_temporary() before materialization
    such that the existing call to reset_name_temporary() after
    materialization resets the name correctly.
    
    Also do some cleanup related to internal table names. Previously, "*"
    was used as an internal table name for derived tables, but it was later
    decided to just use the empty string "". Some unnecessary code was still
    leftover after this change. The internal_table_name [1;31mbuffer[m is therefore
    removed, and length of table names for views and derived tables should
    be 0 instead of 1.

[33mcommit 640cf567efb96582de43e2d9fd09bded7a751e76[m
Author: Ivan Švaljek <ivan.svaljek@oracle.com>
Date:   Tue Nov 28 12:10:06 2017 +0100

    Bug #26171967: MYSQLDUMP IN 5.5 SEGFAULTS FOR --WHERE CLAUSES LARGER THAN 2K
    
    Required [1;31mbuffer[m size is calculated and, if neccessary, static [1;31mbuffer[m is
    replaced with a dynamically allocated [1;31mbuffer[m of appropriate size.

[33mcommit 52d3594db2feb8be1309ced2ebdcda53aa6dae63[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Sat Nov 25 20:36:38 2017 +0100

    Bug#27171283: FREQUENT BUFFER REALLOCATIONS WHEN SERIALIZING JSON
    
    When serializing a JSON value to its binary representation,
    String::reserve(size_t) is sometimes called to make sure the
    destination [1;31mbuffer[m has enough room to hold an integer or double value
    of a given size. Unfortunately, if the String needs to allocate more
    memory, this variant of reserve() only reserves the minimum amount of
    memory needed, so it is very likely that a new reallocation is needed
    shortly after. This hurts performance, especially when serializing
    arrays with many numeric values.
    
    This patch makes the serialization use the two-argument variant of
    String::reserve() so that reallocations will increase the [1;31mbuffer[m size
    exponentially and amortize the cost of the reallocations.
    
    Microbenchmarks (64-bit, Intel Core 2 Quad 2.83GHz, GCC 7.2):
    
    BM_JsonBinarySerializeIntArray      17492816 -> 352638 ns/iter [ +4861%]
    BM_JsonBinarySerializeDoubleArray   80549060 -> 321707 ns/iter [+24938%]
    BM_JsonBinarySerializeStringArray     744725 -> 728882 ns/iter [  +2.2%]
    
    Change-Id: Icdb6316c80021043ada5467f4798028b8d44c7e4

[33mcommit 2c22d02a2051b47008c4dca5e10167dcc58a7420[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Tue Nov 21 12:07:05 2017 +0530

    Bug #27129545: WL#8478: NODE CRASHED DURING RESTART WITH ERROR "PGMAN (LINE: 2286) 0X00000002 C
    
    The undo record data is stored in a [1;31mbuffer[m managed by LGMAN.
    In DBTUP(0), a copy of this(through LinearSectionPtr) is sent to the LDM threads.
    However, before this copy is made, there can be a signal sent to PGMAN from DBTUP(0).
    This gives a chance to LGMAN to overwrite the undo record data [1;31mbuffer[m.
    Hence, for cases where a signal is sent to PGMAN in DBTUP(0), save the [1;31mbuffer[m in c_proxy_undo.m_data
    Also improve testability of the assumption that LGMAN assumes DBTUP does not rely on keeping
    the [1;31mbuffer[m pointer valid.

[33mcommit 55f43af9e8608ec1927aaa9d067488b5c47c7dd9[m
Author: Catalin Besleaga <catalin.besleaga@oracle.com>
Date:   Thu Nov 23 13:08:19 2017 +0100

    Bug#26704312 REEXECUTE PREPARED STATEMENT CRASH IN JSON_ARRAY::INSERT_ALIAS
    
    A temporary [1;31mbuffer[m is returned from val_str, which gets deallocated
    before json_array gets it.
    Solution: use the [1;31mbuffer[m provided to the val_str function instead.
    
    Change-Id: I1b112d2ca7973c1dd8fb0cf768f26697e26067db

[33mcommit ca31a5dd647eaf694320e1c3bf2cd17d01b09a83[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Fri Nov 24 10:03:13 2017 +0100

    Bug#25958538 BLOB SIZE INCREASES IN 8.0
    
    - enable ndb_blob_big again, the bug has been closed and also
      binlogging been turned off for --suite=ndb. Thus the [1;31mbuffer[ms
      should not be exhausted randomly.
    
    Change-Id: I7480ecbe5b650f056a3d39be046efc436c41cbcc

[33mcommit 9eb8b4ae4851dcf7ec3beac73d0456abb18610f4[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Tue Nov 21 09:03:59 2017 +0100

    Bug#26990244 REMOVE WERROR WARNINGS FROM NDBCLUSTER [noclose]
    
    - Fix set 'unused-but-set-variable"
    - The sz[] array where used for assert checking only. Fix by moving the
    assert of "buf size > NDB column length" into ndb_pack_varchar() and
    changing ndb_pack_varchar() to automatically deduce size of [1;31mbuffer[m using
    template
    - The col[] array was used mostly for assert checking, remove it
      and get the column when needed instead
    - Change column number defines to static const for improved type
      checking
    - Improve ndb_pack_varchar(), however it still assumes that table
      definition of mysql.ndb_schema is hardcoded
    
    Change-Id: Ifd6d200a53b9cb8bab12ed0d668958b783a75f26

[33mcommit c3e00ba1e6afa1694a6d687a97f158969f8df382[m
Author: Lukasz Kotula <lukasz.kotula@oracle.com>
Date:   Tue Nov 21 19:53:20 2017 +0100

    BUG#27143268 - MYSQLXTEST.EXE : CRASHES MYSQLXTEST.EXE!PROCESS_CLIENT_INPUT(STD::BASIC_ISTREAM
    
    Description
    ===========
    Mysqlxtest crashes because of the large [1;31mbuffer[m allocated on stack.
    
    Fix
    ===
    Change static [1;31mbuffer[m, to dynamic allocated [1;31mbuffer[m (using std::string).
    
    RB: 17993

[33mcommit 69f13665e9d9f748c8f3c7f59fba66f2c7a8daa3[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Wed Nov 22 11:29:58 2017 +0530

    Bug#27135084: WINDOW FUNC: CRASH IN ITEM_FUNC_INT_DIV::VAL_INT
    Bug#27136492: WINDOW FUNC: MAKETIME: CRASH IN MY_DECIMAL2LLDIV_T
    
    Problem:
    While checking for errors in ::compute(), an error is detected which
    is generated earlier. On return from ::compute(), ::val_decimal()
    returns "nullptr". But as null_value is not set, calling functions
    continue to evaluate resulting in server exit.
    
    Solution:
    Return nullptr only when null_value is set. otherwise set the decimal [1;31mbuffer[m
    to 0 and return the decimal [1;31mbuffer[m. Similar to what we do when wf_common_init()
    fails.

[33mcommit 0675bd36b465784a045ff41f12ac1684f50b9613[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Thu Nov 16 22:23:59 2017 +0000

    Bug#25965370 NDB : LQH CAN EXCEED 4 CONCURRENTLY
      OPENED FILES PER PART DURING RESTARTS
    
    During restart, the LQH component in the data node loads redo
    log part metadata for each redo log part it manages, from one
    or more redo log files.
    
    Metadata is stored per megabyte, and each file has a limited
    metadata capacity, so the number of files which must be consulted
    depends on the size of the redo log part.
    
      (NoOfFragmentLogFiles * FragmentLogFileSize)
    
    Files are opened, read and closed sequentially, but the close
    of one file occurs concurrently with the open of the next.
    
    In cases where file close is slow, this can result in more
    than 4 open files per redo log part.
    
    As the files are opened with the OM_WRITE_BUFFER option set,
    this can result in more than 4 chunks of write [1;31mbuffer[m being
    allocated per part.
    
    As the write [1;31mbuffer[m pool is finite, if all redo log parts
    are in a similar state, it may be exhausted, causing node
    shutdown.
    
    The solution chosen is to avoid using the OM_WRITE_BUFFER
    option during metadata reload, so that transiently opening
    more than 4 redo log files per part does not cause node
    failure.
    
    A new ERROR_INSERT is added to slow file closure for metadata
    reload, allowing manual testing of the fix.  No automated
    testcase is added as there is a requirement for large redo
    logs.

[33mcommit e34c6b0dea2d8aa3b8e107762548ea71ad0dd1a3[m
Author: Mayank Prasad <mayank.prasad@oracle.com>
Date:   Wed Nov 15 15:57:00 2017 +0530

    Bug #26588537 : INNODB.INNODB_BUFFER_POOL_RESIZE_DEBUG FAILS WITH SIG 6
    
    Background:
    Buffer pool resize is done in a separate thread. It is done in parallel with
    other thread in which DMLs might be running on server. During resizing a [1;31mbuffer[m
    pool following sequence happens:
    - Disable AHI (if enabled)
    - Resize [1;31mbuffer[m pool
    - Enable AHI (if disabled earlier)
    
    Analysis:
    While disabling AHI, for all blocks in [1;31mbuffer[m pool, we try to reset index and
    n_pointers=0 before we clear the AHI hash table.
    
    BUT, during above processing, it is assumed that, all blocks in [1;31mbuffer[m pool
    would be in BUF_BLOCK_FILE_PAGE state. Which is not true i.e. it is possible
    that a block could be moved to a state BUF_BLOCK_REMOVE_HASH by some other
    thread, while disabling AHI is in progress.
    
    Fix:
    During resizing of [1;31mbuffer[m pool, expect BUF_BLOCK_REMOVE_HASH state as well (with
    BUF_BLOCK_FILE_PAGE) while disabling AHI.
    
    RB: 17864
    Reviewed by : satya.bodapati@oracle.com

[33mcommit 11e7bf5b24c17c982619f95fadf803a1457ccb6f[m
Author: Mayank Prasad <mayank.prasad@oracle.com>
Date:   Wed Nov 15 15:57:00 2017 +0530

    Bug #26588537 : INNODB.INNODB_BUFFER_POOL_RESIZE_DEBUG FAILS WITH SIG 6
    
    Background:
    Buffer pool resize is done in a separate thread. It is done in parallel with
    other thread in which DMLs might be running on server. During resizing a [1;31mbuffer[m
    pool following sequence happens:
    - Disable AHI (if enabled)
    - Resize [1;31mbuffer[m pool
    - Enable AHI (if disabled earlier)
    
    Analysis:
    While disabling AHI, for all blocks in [1;31mbuffer[m pool, we try to reset index and
    n_pointers=0 before we clear the AHI hash table.
    
    BUT, during above processing, it is assumed that, all blocks in [1;31mbuffer[m pool
    would be in BUF_BLOCK_FILE_PAGE state. Which is not true i.e. it is possible
    that a block could be moved to a state BUF_BLOCK_REMOVE_HASH by some other
    thread, while disabling AHI is in progress.
    
    Fix:
    During resizing of [1;31mbuffer[m pool, expect BUF_BLOCK_REMOVE_HASH state as well (with
    BUF_BLOCK_FILE_PAGE) while disabling AHI.
    
    RB: 17864
    Reviewed by : satya.bodapati@oracle.com

[33mcommit 8b0c8ead247a67ad1c60cbc11749c938624192d1[m
Author: Tiago Vale <tiago.vale@oracle.com>
Date:   Fri Nov 10 12:14:56 2017 +0000

    Bug#26961059 M_CONSUMER LOGGING THREAD IS CREATING 1000'S OF ENTRIES IN EVENT_WAITS TABLES
    
    PROBLEM
    Gcs_async_[1;31mbuffer[m maintains a circular [1;31mbuffer[m that stores events on behalf of
    application threads. The [1;31mbuffer[m is consumed by a dedicated thread.
    Even when there are no events to consume, this thread is constantly waking up
    every 500ms.
    
    ANALYSIS
    The Gcs_async_[1;31mbuffer[m::m_consumer thread wakes up every 500ms because it's using
    timed_wait in Gcs_async_[1;31mbuffer[m::sleep_consumer(). In the current state, it's
    incorrect to change timed_wait to wait because it can lead to a deadlock when
    the consumer sees the [1;31mbuffer[m empty and the producer fills it before the
    consumer blocks.
    
    Example interleaving:
    Consumer thread                        Producer thread
    | gcs_logging_system.cc#L240-L243      |
    |                                      | gcs_logging_system.cc#L166-L186
    | gcs_logging_system.cc#L245-L248      |
    
    The core issue in the design that prevents replacing timed_wait with wait is
    that, in the consumer thread, checking if the [1;31mbuffer[m is empty and sleeping is
    not atomic.
    
    FIX
    Make the check-[1;31mbuffer[m-and-sleep action of the consumer thread atomic using the
    existing mutex (m_free_[1;31mbuffer[m_mutex).
    This renders the other mutex (m_wait_for_events_mutex) unnecessary.
    
    Reviewed-by: Alfranio Correia <alfranio.correia@oracle.com>
    Reviewed-by: Andre Negrao <andre.negrao@oracle.com>
    RB: 17905

[33mcommit 742d6d7dab79386e7dc6fdfac9cdb9f6c202a4b8[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Thu Nov 2 11:27:41 2017 +0100

    WL#11158: Part 5:
    Add limit on batch_size_bytes as well, if row size is larger than 2kBytes we will decrease
    parallelism to avoid [1;31mbuffer[m overload problems.

[33mcommit 83bc0137e5ece4101900cbd602c4b1e761d993a9[m
Author: Dag Wanvik <dag.wanvik@oracle.com>
Date:   Thu Nov 9 12:14:56 2017 +0100

    Bug#27061487 WINDOW FUNC, CRASH IN DECIMAL2BIN
    
    Missing initialization of decimal [1;31mbuffer[m leads to error when wf is not
    nullable: maybe_null == false.
    
    Fix: initialize decimal [1;31mbuffer[m after wf_common_init in ::val_decimal
    for wfs. Also return nullptr only when null_value is set after
    common_init.

[33mcommit 7583b629ef1e5c457e5b196cdd12b9fe76ad9b3c[m
Author: Dag Wanvik <dag.wanvik@oracle.com>
Date:   Tue Nov 7 16:38:35 2017 +0100

    Bug#27060420 WINDOW FUNC, VIEW, CRASH IN DO_COPY_MAYBE_NULL
    
    SELECT_LEX::resolve_rollup, if an item is present in GROUP BY clause,
    sets maybe_null to true as ROLLUP will generate NULL's for the column.
    
    In this case the item is an Item_ref_view. The underlying field is
    not, however, set to maybe_null. This later blows up during [1;31mbuffer[med
    windowing when we try to copy a field back from the frame [1;31mbuffer[m.  It
    has a null value due to ROLLUP, but the field doesn't allow it (has no
    to_null_ptr; i.e. since we copy back the original from_null_ptr was
    empty).
    
    Fix:
    
    Set item->real_item()'s maybe_null in addition to item's maybe_null.
    
    Repro test added.

[33mcommit 376861a183e1243bf2c8eb4265ca114a4cb84f3f[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Mon Oct 30 16:28:05 2017 +0100

    Bug#27041288: ASSERTION FAILURE:
                  ROW0SEL.CC:3955:PREBUILT->MYSQL_PREFIX_LEN <= RECORD_BUFFER..
    
    If a table contains a column whose length is zero, the optimizer may
    allocate a record [1;31mbuffer[m that is too small to hold the columns read by
    the query. This leads to an assert failure in debug builds.
    
    The optimizer looks for the last column accessed by the query in order
    to find out how much space it needs for each record. To find the last
    column, it compares the pointers to the beginning of each of the
    columns. When one of the columns has zero length, two columns may have
    the same start position. Since the algorithm doesn't have any
    tie-breaker for this case, it may end up returning the second to last
    column instead of the last column.
    
    The fix is to compare the end of the column instead of the beginning
    of the column, since it is the end that is interesting when
    calculating the minimum space needed for a record.
    
    Change-Id: Iadc3a0782dd3bcc553993eeb4ecc4b42b0fc07fa

[33mcommit 65166288b7ed9718cdfbb14d3f2de6b7e9e6fffc[m
Author: Thayumanavar S <thayumanavar.x.sachithanantha@oracle.com>
Date:   Tue Oct 31 14:37:27 2017 +0100

    BUG#26974113 - CONTRIBUTION BY FACEBOOK; READ COMPRESSED PACKETS OF SIZE
                   0XFFFFFF.
    
    mysqld server when returning a resultset consisting of logical packets
    that are multiples of 0xFFFFFF drops a connection under compress mode.
    When server/client processes a compressed packet that consists of logical
    packets which are multiples of 0xFFFFFF, the last packet in the series is
    terminated by a zero length packet. During read of last zero length packet, we
    save the byte of the header of zero length and skip to the next header of the
    packet. During the next iteration if there are remaining data in [1;31mbuffer[m to be
    processed, the header of the next packet is overwritten with the byte saved
    from the header of the zero length packet. This result in the connection
    being dropped.
    
    The fix is to restore the byte that belongs to the header of the next packet.
    This patch is based on contribution from Facebook Inc.

[33mcommit 556d45deb2d3c8180c5df483f056b0fe53bf82fb[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Tue Oct 24 22:32:59 2017 +0200

    Bug#26188578 Bug#26164633 Bug#26360114 Bug#26781725 Bug#26848089 Regressions with WL#9236
    
    Bug#26188578 WL#9603: HAVING CONDITION IS OPTIMIZED OUT FOR ALIAS ON AGGREGATE W/O GROUP BY
    Bug#26164633 WL#9603: WRONG RESULT WHEN PARTITION EXPR USING AGGREGATES EVALUATES TO NULL
    Bug#26360114 WRONG RESULT WITH AGGREGATE AND HAVING CLAUSE IN VIEW
    Bug#26781725 INCORRECT RESULTS FOR QUERY(MAX FUNC+HAVING CLAUSE) WHEN USED INSIDE VIEW
    Bug#26848089 LEAD/LAG WINDOW FUNCTIONS ON QUOTED JSON STRINGS RETURNS SAME VALUE FOR ALL ROWS
    
    Regressions introduced by changes to Item_ref done in the patch for
    window functions (WL#9236).
    
    Background of existing design before the WL of window functions:
    
    - Item_ref is very old design which was introduced for SQL clause
    HAVING, when HAVING references an item of the SELECT list through an
    alias. It points to an Item ('ref' pointer). When there is a tmp table
    involved in the execution (e.g. GROUP BY before HAVING), we may
    calculate a SELECT list expression (let's say it's an Item_func) and
    store it in the tmp table in the group's row. The
    tmp table's column where it's stored is known as the Item's result_field.
    If HAVING references that expression through an alias, HAVING contains
    Item_ref with a 'ref' pointing to the Item_func. When evaluating
    HAVING, we want to use the already calculated value of Item_func
    (_not_ evaluating the Item_func again, as it may not be deterministic),
    we do that by looking at the value stored in ref->result_field.
    That is why Item_ref::val_int calls ref->val_int_result(), not
    val_int().
    - So the system is relying on the capacity of Item_ref to
    automatically pick the stored value.
    - While that sounds ok for queries with no or only one tmp table, it
    is not enough for more complex queries
    - hence, a second design: "ref item slices": in different phases of
    execution (simply: depending on which table, tmp or non-tmp,
    we're reading now), a same SELECTed expression is represented by
    different Items: it may be SUM initially (Item_sum), then, once
    calculated (with Item_sum::val_int()) and stored in a tmp table with
    one row per group, it becomes Item_field (a column of the tmp
    table). After all groups have been written, if a filesort is used
    to do a final ORDER BY, that sort must call the Item_field's val_int,
    not the Item_sum::val_int which is just the value of the last group.
    - So, depending on which table we're reading now, the SELECTed
    expression is one object or another; for that, we wrap the expression
    in Item_ref, with 'ref' pointing to a place (a cell in the "ref item
    slice"), and at this place we deposit a pointer either to the original
    Item_sum or to the tmp table's Item_field, depending on the phase
    we're in.
    Phases are identified by numbers (grep for the REF_SLICE enum).
    
    With the advent of window functions, more tmp tables are used, and
    form a chain. The fact that Item_ref::val_int always reads ref->result_field
    (i.e. what was saved in the next tmp table) sometimes leads to reading
    not-yet-calculated data from the next tmp table.
    For example, if we have an Item_func I_F, and a tmp table used for windowing,
    and we have an Item_ref I_R to the I_F (HAVING always creates an
    Item_ref), and before the tmp table is written we use I_R::val_int,
    that gets the value of I_F->result_field, reading random data from the
    tmp table. Such I_R::val_int() (or val_int_result(), equivalently)
    could occur in filesort(), for example.
    HAVING is one problem; but the ORDER BY clauses of windowing also use
    Item_ref; and aggregate functions also do (if involved in a more
    complex expression, see Item::split_sum_func2). Aggregate functions
    may be used as arguments to windows, so, depending on the phase,
    Item_ref should pick the aggregate function's value or its saved
    value, which it can't do. The behaviour of Item_ref of "always reading
    the result_field", combined with the increased number of tmp tables,
    made things harder to manage than they used to be.
    
    So things are refactored in this patch:
    - Item_ref::val_(int,etc)() just calls ref->val_(int,etc)(), doesn't
    read ref->result_field anymore
    - when you are reading QEP_TAB Q and want to evaluate an expression
    which depends on values stored in Q and previous tables in the
    execution order, switch to Q->ref_item_slice slice: it will switch to
    Items which point into Q's table.
    - when you are doing a GROUP BY where grouped rows are not
    materialized in a tmp table (because rows are produced in group order
    by the join), a pseudo-tmp table [1;31mbuffer[m is used (no change here); if
    you want to evaluate an expression which depends on values
    stored in this [1;31mbuffer[m, use the REF_SLICE_TMP3 slice.
    - the reads above include: sorting the table, evaluating a condition
    on the table, etc.
    
    Changes:
    
    All val_*result() are removed.
    So Item_ref::val_(int,etc) calls ref->val_(int,etc), not
    val_result. Thus, "ref" needs to be "advanced by one step", as we
    don't look into "its result already stored into the next tmp
    table", anymore. So ref slices are "advanced by one  step" during
    execution.
    Unchanged meaning of "the current ref slice of JOIN":
    it's still the "ref"s (targets) for Item_refs when evaluating Items in
    the current phase of execution.
    Unchanged meaning of QEP_TAB::ref_item_slice: the
    it's still the "ref"s (targets) for Item_refs when evaluating Items
    when reading this QEP_TAB.
    Exception: QEP_TAB::ref_item_slice is not anymore set to
    REF_SLICE_TMP3, as that latter slice is never the one to use to read
    from any QEP_TAB; it's the one to use to read from a pseudo-tmp-table
    of GROUP BY. A consequence is that we cannot use
    QEP_TAB::ref_item_slice to switch to REF_SLICE_TMP3 anymore, so we use
    a new member JOIN::before_ref_item_slice_tmp3 for that.
    Almost all execution functions need to advance to the right slice
    before they read a table.
    
    QEP_TAB::all_fields and QEP_TAB::fields are removed: we can get the
    same information from QEP_TAB::ref_item_slice, using new function
    JOIN::get_current_fields().
    
    class Item:
    all val_x_result() are gone, all calls to them replaced with val_x().
    Item_ref made to behave like Item_direct_ref; thus, Item_direct_ref
    removed and replaced with Item_ref.
    
    Item_field::save_in_field_inner() (item.cc):
        after the changes done to fix_inner_refs() in this patch,
        for the materialization of some IN subquery, we use store_key_item
        to store the left args of the IN subquery,
        while we used to use store_key_field (see comment about fix_inner_refs);
        these left args are indeed outer refs belonging to a grouped query;
        store_key_field() takes its source in Item_field::field;
        store_key_item() rather uses Item_field::save_in_field_inner()
        which takes its source in Item_field::result_field, which assumes
        this field contains the up-to-date value. This logic sounds
        strange and the present patch uses the "field" member as source,
        instead. Perhaps the old logic was necessary when ref slice wasn't
        "advanced one step" as we do now. The modified code is from before
        2000 so we cannot know more about its reason.
    
    item_subselect.cc: ref_by[1] introduced (see explanation there). So we
    now have two "ref_by" pointers; it's then difficult to pass both as
    arguments to split_sum_func2 in sql_resolver.cc so we let
    split_sum_func2 find pointers itself.
    
    sql_join_[1;31mbuffer[m.cc: assert that we needn't switch slice, because we never
    use join [1;31mbuffer[m on a tmp table. Removed useless switch.
    
    JOIN::set_ref_item_slice(): as we use it more now, make it do nothing if
    slice number doesn't change (optimization).
    Switch_ref_item_slice: now it's used in one case where the said slice
    may or not exist, so I make the object a no-op if the slice doesn't
    exist.
    
    JOIN::set_group_rpa: not needed anymore as set_ref_item_slice()
    detects when sliceno doesn't change so we can call it repeatedly;
    removed.
    
    SELECT_LEX::fix_inner_refs(): simplified as Item_direct_ref and
    Item_ref are one now, no need to choose between the two.
    
    sql_select.cc:get_store_key():
    there was an "else if" branch special for DIRECT_REF.
          else if ((*(Item_ref**)(item_ref)->ref)->ref_type()
                   == Item_ref::DIRECT_REF &&
                   item_ref->real_item()->type() == Item::FIELD_ITEM)
                   field_item= static_cast<Item_field*>(item_ref->real_item());
    It was specific of an outer reference belonging to a query with GROUP
    BY. It relied on the two different types of Items created in
    fix_inner_refs(). I remove this because it's not possible anymore to
    distinguish Item_ref from Item_direct_ref (they're one now), and the
    distinction is necessary to make this 'else' work. Likely it makes us
    pick store_key_item() instead of store_key_field(), in this outer-ref
    case, which is acceptable.
    
    sql_select.cc: reset_wf_result_fields(): removed.
      More info about the problem that required this function:
      select from (select WF1 over w1, WF2 over w2) dt;
      where "dt" is materialized. First the "dt" table structure is created with
      create_tmp_table() and that sets WF{1,2}->result_field (pointing into
      columns of "dt"). Then the inner subquery is optimized, that calls
      create_tmp_table() for the two windows. First for w1: WF1 is to be
      calculated in w1 so a column is added for its result in the tmp table; so
      its result_field gets re-set to point there, all fine. Continuing with the
      creation of wf1, WF2 is skipped. Then change_to_use_tmp_fields() sees that
      WF1 and WF2 have a result_field (see test
      'else if ((field= item->get_tmp_table_field()))'), so concludes that the ref
      slice used to read the tmp table of w1 should contain Item_fields for WF1
      and WF2; that's incorrect for WF2, and leads to WF2 never being calculated.
      My fix: in create_tmp_table(), when the destination table is to materialize
      a derived table / UNION (i.e. is not a group-by/windowing table), there's no
      reason to set result_field (results are not saved by this means anyway, but
      by Query_result_union::send_data() which reads the last table of the query
      and writes that to the materialized table), so don't set it.
    
    sql_select.cc: JOIN::make_tmp_tables_info():
          Complement to comment "Exit the TMP3 slice": failing test was
          main.func_group, consider:
          SELECT (SELECT COUNT(DISTINCT t1.b)) FROM t1 GROUP BY t1.a;
          When evaluating COUNT(DISTINCT t1.b): we copy t1.b to tmp table used by
          COUNT(DISTINCT) (i.e. tmp table of Aggregator_distinct):
          for that we must copy t1.b from JOIN's result, not from TMP3 slice:
          indeed TMP3 was filled when we switched to a new group (see
          end_send_group), so it contains the value of t1.b for the first row of
          the group; while COUNT(DISTINCT) wants the value of the current row (or
          it would think all rows of group have same value of t1.b). So the
          copy_field to the COUNT(DISTINCT) tmp table must take its source in
          JOIN, so ref slice must not be TMP3 in setup_sum_funcs.
          Alternatively, I tried to let COUNT(DISTINCT) read from TMP3, so I had
          to update t1.b in TMP3 for every read row but:
          - it broke the undocumented behaviour that "for a non-functionally dependent
          column in group we choose first row"
          - it broke other tests
    
    sql_executor.cc:
    simplified slice switching: switch, when about to read a table, to the
    Items which point to this table; in practice it means:
    - before reading first row (as it may start with a filesort, which may
    have to evaluate some ORDER BY expression on the table); slice switch
    remains in force for next rows too
    - for tmp tables: before evaluating HAVING; even a bit earlier: before
    copy_fields() (see comment in end_send_group())
    - copy_funcs(): no need to calculate functions in two passes, anymore;
    so tmp_table_param::hidden_func_count is removed (was added by the WF
    WL). Proper order is given by sort_copy_func() now.
    - setup_copy_fields(): no need for special case for Item_aggregate_ref,
    said Evgeny; indeed I don't understand why it still would be needed:
    as Item_ref::val_* just evaluates the referenced Item_field (doesn't
    look at result_field), we can just copy the underlying Item_field.
    - complement to comment "As GROUP expressions have changed" at *end* of
    end_send_group():
            Fixes test: main.group_by, query:
            select a, round(rand(100)*10) r2, sum(1) r1 from t1 where a = 1 group  by a
            having r1>1 and r2<=2;
    - complement to comment "We have created a new Item_field" in
    setup_copy_fields():
                The only new thing is below: let 'item->field' allow access to
                REF_SLICE_TMP3. This won't disturb the Copy_field as it has cached
                field->ptr (in copy_field->set()) before the change to
                'item->field' below.
                Why this change: because when we are in slice TMP3 (end_send_group), to
                evaluate HAVING we use Item_ref::val_int() which doesn't anymore use
                ref->val_int_result() but ref->val_int() instead: and
                Item_field::val_int() uses 'field' not 'result_field' so the
                Item_field here must have valid data (i.e. TMP3) in its 'field'.
    - change in QEP_TAB::remove_duplicates(): the function
    used (this-1)->fields. Now that I get rid rid of this member, I found
    a way to do without it: it was used to count hidden fields in 'this';
    I replaced the counting with the existing hidden_field_count.
    - assertions of type:
      this != join()->before_ref_item_slice_tmp3
    are added to make sure that only well-identified functions read from
    REF_SLICE_TMP3.
    
    sql_tmp_table.cc:
    - don't set result_field when it doesn't make sense;
    removes the need to clear it later (i.e. removed
    reset_wf_result_fields()).
    - as we can now create a tmp table by using as source the fields of slice
    REF_SLICE_TMP3, which don't point in a real table::record[0], fixed the
    "move_field" logic in calculation of the field's default value.
    - added sort_copy_func() to evaluate Copy_func-s in proper order (see
    comment there); uses new function Item_ref::contains_alias_of_expr()
    (item.cc); requires to replace Item* pointer in Func_ptr_array with a
    pair of Item* and alias-of-expr property: class Func_ptr.
    - complement to comment "Let each group expression know"
          it is needed to fix Bug#26475312. Indeed, the scenario was (see
          test in window_functions_bugs.test):
          - for group-by write to a tmp table tmp1
          - there is no group aggregate function (so this GROUP BY is there only
          to make distinct groups) so we use end_write() with a duplicate
          elimination in tmp1
          - the concatenation of group expressions is too long to make it a unique
          key so we use a "unique constraint" (hash_field) instead
          - after tmp1 there is tmp2 for windowing.
          - in end_write() we do check_unique_constraint(); after checking
          hash_field it gets a "candidate duplicate"; to check it more thoroughly
          we use group_rec_cmp() to compare the two rows; this function finds the
          value of group expressions in each row; for that it evaluates the
          expressions; but (after the refactoring) the slice we're at is that of
          tmp1 (not of the table before tmp1, anymore); the expression is
          thus a Item_field with 'field' in tmp1; and 'result_field' in tmp2; when
          group_rec_cmp() used get_tmp_table_item() on this Item_field it returned
          result_field i.e. group_rec_cmp() was reading in tmp2, wrongly.
          The fix is the make group_rec_cmp() find the proper 'field'. We record
          it below. Note that it was recorded in the old code too, but not if using
          hash_field (see branch "if (group && !using_unique_constraint)").
          - I also changed unique_hash_group like group_rec_cmp as they looked
          similar.
    - complement to comment "Get the value from default_values":
            Using move_field_offset(diff) below assumes that orig_field->ptr
            points into record[0], which may not be the case. Example:
            - we are creating a tmp table to materialize the query's result, for a
            PS cursor
            - the last table of the query, i.e. input to the cursor's tmp table,
            is the result of GROUP BY, so here 'fields' is items of
            REF_SLICE_TMP3
            - so orig_field is from REF_SLICE_TMP3, it was created by
            setup_copy_fields() from table->field[x] and its ptr points to a
            temporary memory area.
            Conclusion: so we rather use orig_field->table->field[x] which is
            properly in record[0].  By adding 'diff' to ptr we point that field to
            its default value.
            Fixed mysql_client_test.test (precisely the test for bug 11904 there).
    
    table.h: st_order::field renamed to clearer name field_in_tmp_table.
    
    New MTR test bits for better coverage of modified code.
    Tests for the four fixed bugs.
    
    having.test: UPDATEs to the series table are added to make sure a
    failing section doesn't make other following sections fail.
    
    Change-Id: I9775573b821886932b48b08c5ae9ece12e249e71

[33mcommit 1c368c1b32514ae3f21eac7dcb8cc2cdada92542[m
Author: Christopher Powers <chris.powers@oracle.com>
Date:   Thu Oct 19 23:32:41 2017 +0200

    Bug#26980399 STACK BUFFER OVERFLOW OF LOWER_CASE_NAME WHEN SETTING VARIABLES
    
    This bug is a regression from Bug#25680866 "CHARACTER SET SPECS HAVE LOUSY PERFORMANCE..."
    which introduced functions that map character set and collation names to a number.
    These functions copy a null-terminated name string into a fixed-size [1;31mbuffer[m for
    for conversion to lower case. The problem is that incoming strings longer than
    the [1;31mbuffer[m are not re-terminated with null, allowing subsequent reads beyond
    the end of the [1;31mbuffer[m.
    
    The fix ensures that character set names are null-terminated before converting
    to lowercase.

[33mcommit 2649fb29cf77566f68fca55d55c16db8b8d7f456[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Fri Oct 20 11:52:10 2017 +0530

    Bug #26975882: CRASH IN STRING::COPY, USUALLY WITH WKB FUNCTIONS / WINDOW FUNC
    
    An error is generated while evaluating the first argument to Item_func_[1;31mbuffer[m.
    Without checking for errors, we proceed further to evaluate the second argument
    which is a WINDOWING function. And the error is caught here. Windowing
    function returns nullptr. But does not set null_value to true. This results
    in server exit later.
    
    Solution:
    Check the error early in Item_func_[1;31mbuffer[m function.

[33mcommit 06be797507c1bdf6d5602fe394f3bc38fbab30a3[m
Author: Dag Wanvik <dag.wanvik@oracle.com>
Date:   Mon Oct 16 11:15:53 2017 +0200

    Bug#26389508 INT JOIN_READ_KEY(QEP_TAB*): ASSERTION `!TABLE->HAS_NULL_ROW()' FAILED
    
    Analysis:
    
    When a window with [1;31mbuffer[ming follows a equijoin on a unique index
    (JT_EQ_REF) , we can get into trouble because windowing modifies the
    input record, presuming that once the windowing has been handed the
    record, next time control passes back to the join code a (new) record
    will be read to the input record.
    
    However, this does not hold with JT_EQ_REF, cf. the caching done in
    join_read_key:
    
    From its Doxygen:
    
      "Since the eq_ref access method will always return the same row, it
       is not necessary to read the row more than once, regardless of how
       many times it is needed in execution.  This cache element is used
       when a row is needed after it has been read once, unless a key
       conversion error has occurred, or the cache has been disabled."
    
    Fix:
    
    We solve this problem by reinstating the input record before handing
    control back from end_write_wf. We optimize: only do this if the
    window in question follows after such a JOIN, i.e. window #1, and it
    has actually clobbered the input record. This can only happen if
    the last qep_tab has type JT_EQ_REF.
    
    Another, perhaps better approach, is to refactor to never touch the
    input record but keep the copying between the out record and the frame
    table record instead. Left for future refactoring.
    
    Added some missing Window method "const"s, and folded a couple of
    one-liners into window.h (from .cc).
    
    Repro added.
    
    Change-Id: I33bc43cd99ff79303b17d181abc3805ce226fb85

[33mcommit 2f5be15558ae4a93f08ed9f13308ed192b19f2cf[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon Oct 16 09:44:32 2017 +0200

    Bug#25868387 WRONG DATA RETURNED WITH NDB JOIN PUSHDOWN
    
    Fix a regression caused by patch for:
      bug#23130819  (REFACTOR STATE CHANGES FOR THE ROW BUFFER ASSOCIATED WITH THE TABLE CLASS)
    
    The 'Refactor state change' seems to have removed some 'clear all row [1;31mbuffer[ms' logic
    and instead only relied on that all handler calls returned 'HA_ERR_END_OF_FILE' if
    no rows were found.
    
    The ndbcluster handler interface for  ha_ndbcluster::index_read_pushed()
    instead returned 'ok' (0) of no rows were found, which was now interpreted
    as 'another row found'.
    
    Patch fix this by returning 'HA_ERR_END_OF_FILE' as expected by
    the enhanced handler semantics.

[33mcommit 4297dcc522879d67dbf12fe23791fac942a12b6c[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Thu Oct 12 12:30:39 2017 +0300

    Bug #26712418: EMBEDDED SERVER MYSQL_OPTIONS() OPTIONS NOT REMOVED
    WITH REST OF EMBEDDED SERVER
    
     Removed:
     * MYSQL_OPT_GUESS_CONNECTION
     * MYSQL_OPT_USE_EMBEDDED_CONNECTION
     * MYSQL_OPT_USE_REMOTE_CONNECTION
     * MYSQL_SET_CLIENT_IP
     * code in mysql_options() and mysql_get_option() to support these
     * mysql->options.methods_to_use
     * mysql->options.ci.client_ip
     * The whole union at mysql->options.ci
     * unused members of the client structures (safe to do due to the
       major version upgrade)
     * extension and embedded_info from st_mysql_data
     * info_[1;31mbuffer[m from st_mysql

[33mcommit 97dae79ac976bdf70c60670639db3f275ca80b3c[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Oct 12 14:09:31 2017 +0800

    Bug#26950659 - INITIALIZE FAILED:: NODE->N_PENDING == 0 FIL_CLOSE_ALL_FILES
    
    During shutdown, after confirming there is no IO from [1;31mbuffer[m pool,
    there is still some pending IO on DD tablespace found when closing all files.
    The cause is that after checking [1;31mbuffer[m pool, server still tries to
    write back dynamic metadata, which results in new IO for DD tablespace.
    This may happen when fast shutdown.
    
    To fix this, write-back of dynamic metadata should be done first,
    before checking [1;31mbuffer[m pool, if it's a fast shutdown.
    
    RB: 17616
    Reviewed by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 1f53a46deed390d9061d5774134752b64df97051[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Thu Sep 28 15:55:29 2017 +0300

    Bug #26712418: EMBEDDED SERVER MYSQL_OPTIONS() OPTIONS NOT REMOVED
      WITH REST OF EMBEDDED SERVER
    
    Removed:
    * MYSQL_OPT_GUESS_CONNECTION
    * MYSQL_OPT_USE_EMBEDDED_CONNECTION
    * MYSQL_OPT_USE_REMOTE_CONNECTION
    * MYSQL_SET_CLIENT_IP
    * code in mysql_options() and mysql_get_option() to support these
    * mysql->options.methods_to_use
    * mysql->options.ci.client_ip
    * The whole union at mysql->options.ci
    * unused members of the client structures (safe to do due to the
      major version upgrade)
    * extension and embedded_info from st_mysql_data
    * info_[1;31mbuffer[m from st_mysql

[33mcommit 4abbcf09ccfa878d5948bdaf07db89be4f9db146[m
Author: Dag Wanvik <dag.wanvik@oracle.com>
Date:   Thu Oct 5 17:26:31 2017 +0200

    Bug#26802696 DENSE_RANK WRONG WITH BUFFERED PROCESSING
    
    For the first row in a partition when we have [1;31mbuffer[ming, we
    erroneously get values that are one too high. RANK has the same issue,
    but there is accidentally works correctly anyway.
    
    Analysis:
    
    The reason is that the initialization of the cache comparator of the
    ORDER BY happens too early. In streaming mode, we call clear (which
    resets the comparator) in Item_rank::val_int - which works fine because
    the values of the ORDER BY expressions is already available in the
    out[1;31mbuffer[m (copy_fields has been done already).
    
    In [1;31mbuffer[med mode, however, the call to clear happens from
    process_[1;31mbuffer[med_windowing_record *before* copy_fields has been called
    as part of a general reset of window functions' states (when we start
    a partition).
    
    Solution:
    
    Split the state reset and the priming of the comparator, so
    that the latter always happens in Item_rank::val_int.
    
    Repro added.
    
    Change-Id: I8157ed96f2aca7a843ebf0a80364c75d52adef48

[33mcommit cc3d606006517aac71eac550e4272621554edeb6[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Mon Oct 9 12:49:14 2017 +0530

    Bug #26739028: WINDOW FUNC + FROM_UNIXTIME CRASH
    
    Problem:
    "null_value" is not set correctly as Item_lead_lag::compute() does not have a
    way to return any value. Because of which a decimal_[1;31mbuffer[m with no valid
    data is accessed and server exits.
    
    Solution:
    Re-write compute function in Item_lead_lag, Item_first_last_value and
    Item_nth_value to return true if null_value is set or if there is an error.

[33mcommit f603fc4a89586e796f16cefca78b891e9647fd2d[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Fri Aug 18 17:14:35 2017 +0530

    Bug #26026218 : TRANSPORTER ERROR 0X8004, 0X8023; CHECKSUM; UNSUPPORTED BYTE ORDER
    
    Two new manual(recompile) error-injections in mt.cpp :
    
      NDB_BAD_SEND : Causes send [1;31mbuffer[m code to mess with a byte in a send [1;31mbuffer[m
      NDB_LUMPY_SEND : Causes transporters to be given small, oddly aligned and
                       sized IOVECs to send, testing ability of new and existing
                       code to handle this.
    
    These were useful for testing the correctness of the new code, and
    the resulting behaviour / debugging output.

[33mcommit 946996a37677b8ddab302829d237c8a493ce523f[m
Author: Mayank Prasad <mayank.prasad@oracle.com>
Date:   Wed Oct 4 14:23:17 2017 +0530

    Bug#25972975 SERVER CRASH ON RUNNING I_INNODB_ZIP.BUG16067973 WITH --INNODB-SYNC-DEBUG=1
    
    Background:
            innodb_[1;31mbuffer[m_pool_evict='uncompressed' causes all uncompressed pages to
            be evicted from [1;31mbuffer[m pool. innodb_[1;31mbuffer[m_pool_evict_uncompressed() is
            responsible to do above operation.
    
    Issue:
            sequence in which locks are being taken is not correct.
            SYNC_SEARCH_SYS, which is taken when AHI is being searched, shouldn't be
            taken by a thread while its already holding
            SYNC_BUF_BLOCK/SYNC_BUF_PAGE_HASH/SYNC_BUF_LRU_LIST locks. Because of
            this, an assert is seen when innodb_debug_sync=1.
    
    Fix:
            Issue was not present in 5.7 where the sequence of acquiring locks is
            correct. Corrected lock acquiring sequence accordingly.

[33mcommit 85909e0e91c4de3ba716189e7540f3a84226193f[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Wed Oct 4 09:03:41 2017 +0200

    Bug#26907753 COMBINING CTE AND WINDOW FUNCTION GIVES WRONG RESULT
    
    Problem: a query with a CTE or derived table or view which itsef contains a
    window function returned a wrong result.
    
    We're creating a tmp table to serve as frame [1;31mbuffer[m for the window function.
    This table will store the value of Item "i+1" into a column; to access
    this column (Field object) we're reading the Item's result_field,
    assuming the Item is a sub-class of Item_result_field. Most often it is
    (e.g. Item_func_plus is) but here it's not, as "i+1" is actually
    Item_direct_view_ref wrapping Item_func_plus. So it's a wrong C cast
    which causes wrong results (in a debug build it rather causes an
    assertion failure).
    
    Fix: use get_tmp_table_item(), which returns result_field for the
    Item_direct_view_ref, without need for casting.

[33mcommit ffc81c2df6516eaae416bce3c74c8f9427ccb987[m
Author: Pekka Nousiainen <pekka.nousiainen@oracle.com>
Date:   Wed Oct 4 12:41:51 2017 +0300

    wl#7614 options-01.diff
    
    add simpler --page[1;31mbuffer[m option

[33mcommit 286ab1abe33cb129c81261cadfcd94d44e50a606[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Tue Sep 26 12:19:51 2017 +0200

    Bug#26867509: JSON_OBJECT CREATES INVALID JSON CODE
    
    When inserting JSON values from a grouped query into a string column,
    the inserted values could sometimes include the concatenation of all
    the values previously inserted into that column.
    
    The fix is to make Item_copy_json::save_in_field_inner() reset the
    [1;31mbuffer[m before converting the JSON value to text.
    
    Change-Id: I328c88f2fee95ff4406b21d961d9297a3b9fa624

[33mcommit cda8968fc527e54f9bac8d3ed36689e2e03d78e7[m
Author: Debarun Banerjee <debarun.banerjee@oracle.com>
Date:   Thu Sep 21 07:58:43 2017 +0530

    BUG#26555999 XCONNECTION DOESN'T SUPPORT CLONE PLUGIN COMMANDS
    
    BUG#26561706 CLONE COMMANDS SUPER PRIVILEGE IS DEPRECATED
    
    BUG#26617429 CLONE MAY CRASH WHEN DISK FULL
    
    BUG#26787838 WARNING RELATED TO DOUBLEWRTIE BUFFER
    
    BUG#26549840 RECOVERY EXTENDING SMALL FILES TO MULTIPLE OF EXTENT SIZE
    
    Problem :
    ---------
    1. X-Connection is not enabled for clone SQL command
    
    2. Super privilege is deprecated
    
    3. IO error handling in background and state change issue
    
    4. During clone DB start, tablespace file could have missing unallocated
    pages at end. This is adjusted currently after redo recovery, based on
    the size stored in header. The size of the tablespace file may not be
    in exact multiple of extent size before this adjustment. Double write [1;31mbuffer[m
    doesn't find a page based on rounded tablespace size while the page is
    actually there. The warning doesn't have any impact on functionality.
    
    5. For cloned DB start, during redo recovery a tablespace file is extended
    if the page is beyond the current file size. Currently it is extended to
    multiples of extent size which could extend small tablespaces to one
    full extent bloating the overall DB size.
    
    Solution :
    ----------
    1. Add X-Connection flag for clone SQL command
    
    2. Use backup privilege for clone
    
    3. Check for clone state for IO error in archiver background
    
    4. Extend file size after clone page copy stage if required based on
    tablespace header size if required.
    
    5A. Make tablespace extension specific to clone DB start
    
    5B. Extend to multiple of extents only if tablespace size is bigger than
    one extent.
    
    Reviewed-by: Satya Bodapati <satya.bodapati@oracle.com>
    
    RB: 17393

[33mcommit 4fe4bd882c881b3f524b65cefb3c512ba8d7faec[m
Author: Christopher Powers <chris.powers@oracle.com>
Date:   Mon Sep 18 22:46:22 2017 +0200

    Bug#26732229 PERFORMANCE SCHEMA STATEMENT TABLES SHOULD DISPLAY REWRITTEN QUERY TEXT - 8.0+ ASAN FIX
    
    Use rewritten query text when available.
    Save and restore the rewrite [1;31mbuffer[m in prepared statements.

[33mcommit d6cf0927c41bb2bd8ff5e1bba1cec39ae7b75ab0[m
Author: Satya Bodapati <satya.bodapati@oracle.com>
Date:   Fri Sep 15 12:19:02 2017 +0200

    Refix Bug#26389442
    
    - Remove duplicate variable ibuf_use and directly use innodb_change_[1;31mbuffer[ming variable
      innodb_change_[1;31mbuffer[ming is updated whenever uses changes the value

[33mcommit d3f07fe07cf84f9dcbbd666a5311e89bc3282b1c[m
Author: Satya Bodapati <satya.bodapati@oracle.com>
Date:   Thu Sep 14 15:37:34 2017 +0200

    Bug#26389442    INNODB_CHANGE_BUFFERING IS NOT A DYNAMIC VARIABLE
    
    Problem:
    --------
    WL#7488 removed the dynamic property of innodb_change_[1;31mbuffer[ming variable
    
    Fix:
    ----
    Add the update code which handles the dynamic property of innodb_change_bufering
    variable.
    
    Patch written by Sunny Bains <sunny.bains@oracle.com>
    Tested and Reviewed by Satya Bodapati <satya.bodapati@oracle.com> on IM

[33mcommit b8dcd63d07273e9bbb7dca5ae20eb016eb1047dc[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Sep 7 10:14:09 2017 +0200

    Bug#26666274 INFINITE LOOP IN PERFORMANCE SCHEMA BUFFER CONTAINER
    
    Problem 1
    =========
    
    Under load, the performance schema code can execute
    an infinite loop in
      PFS_[1;31mbuffer[m_default_array::allocate()
    
    Root cause 1
    ============
    
    Consider the following loop:
    
      size_t monotonic;
      size_t monotonic_max;
    
      monotonic = m_monotonic.m_u32++;
      monotonic_max = monotonic + m_max; (a)
    
      while (monotonic < monotonic_max)
      {
        ...
        monotonic = m_monotonic.m_u32++; (b)
      }
    
      When the value of monotonic gets close to 2^32,
      the value of monotonic_max gets beyond 2^32 in (a)
      This is ok, as both variables are 64 bits integers.
    
      However, in the loop,
      m_monotonic.m_u32++ is only a 32 bits value (b),
      so that when incrementing to the next value,
      the monotonic counter will never get passed 2^32,
      and therefore will never reach monotonic_max.
    
      The while loop never ends, causing the bug.
    
    Fix 1
    =====
    
      The solution is to change m_monotonic to
      be a PFS_cacheline_atomic_size_t,
      to match the type (size_t) of monotonic and monotonic_max.
    
      With this fix, the loop works properly beyond 2^32.
    
      However, another issue was found by analysis.
    
    Problem 2:
    ==========
    
      When the value of monotonic gets close to 2^64,
      the value of monotonic_max gets beyond 2^64,
      causing an overflow, and wraps to a low integer (a).
    
      In this case, the while loop is never entered,
      because monotonic is near 2^64 and monotonic_max is near 0.
    
      The [1;31mbuffer[m is declared full, without looking at it.
    
      While theoretical (2^64 is a big value, the server needs
      to be up for a long time to get to this state),
      this can potentially lead to extra allocation
      of new container pages, consuming more memory than necessary.
    
    Fix 2
    =====
    
      Add logic that detects the overflow on monotonic_max,
      and reset the monotonic counter to 0.
    
    Misc
    ====
    
      This fix also changes several integer computations
      to use size_t, to clean up the code to avoid other overflows.

[33mcommit faf8497e39518b643d1b2e75c7ccc840153617c5[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Mon Sep 11 13:17:22 2017 +0530

    Bug#26496880: CRASH IN FIELD_BLOB::GET_KEY_IMAGE
    
    Problem:
    read_set for the field is not set because its not part of the query.
    As a result, server exits trying to read the data from the [1;31mbuffer[m.
    
    Analysis:
    For the query in the bugpage, as field "b" is not part of the query, optimizer
    does not set the bit for the field in read_set. This results in innodb
    not fetching the data for field "b". But "b" is part of the primary key. So
    optimizer tries to read the key and fails.
    
    Solution:
    prepare_for_position() called from make_join_read_info() marks the fields
    in read_set, which are part of primary key, if primary key is needed to
    find the row.
    We now call prepare_for_position() if window functions are present.

[33mcommit 79f49360dca75e6495cd104fc651a7db4212e6be[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Thu Aug 10 18:55:39 2017 +0200

    Bug#26614455: MAKE CACHED JSON_PATH OBJECTS IMMUTABLE
    
    The cached Json_path object returned by Json_path_cache::get_path() is
    mutable. If a caller modifies the returned object and doesn't restore
    the original state of the object when it is done, the cache is
    corrupted and could cause wrong results the next time it is used.
    
    JSON_SEARCH is the only caller that does any modification on the
    cached Json_path object. This patch changes it so that it doesn't
    modify the Json_path object. Instead it makes the modifications on a
    String object that represents the path. Since the path needs to be
    converted to a string in the end anyway, this saves some round-trips
    between Json_path representation and String, and gives a small speedup
    as an extra bonus.
    
    Json_path_cache::get_path() is changed to return a pointer to a const
    Json_path object.
    
    Additional changes in the JSON_SEARCH function, while at it:
    
    Remove the String members m_one_or_all_value and m_escape. Since the
    valid values of the one-or-all argument and escape character argument
    of JSON_SEARCH are quite small (3 characters and 1 character), there
    isn't any point in caching these strings in the Item object. Creating
    a small [1;31mbuffer[m on the stack would be enough to avoid heap allocation
    in all the common cases.
    
    Microbenchmarks (64-bit, Intel Core i7-4770 3.4 GHz, GCC 6.3):
    
    BM_JsonSearch              1389 -> 1163 ns/iter [+19.4%]
    BM_JsonSearch_Wildcard     3203 -> 3216 ns/iter [ -0.4%]
    
    Change-Id: I31c5adaafc41403efcbc1edb84ec76b2b7949b57

[33mcommit bd87573bc159c849f34aa8293ec43ac053cbfda0[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Thu Sep 7 10:14:09 2017 +0200

    Bug#26666274 INFINITE LOOP IN PERFORMANCE SCHEMA BUFFER CONTAINER
    
    Problem 1
    =========
    
    Under load, the performance schema code can execute
    an infinite loop in
      PFS_[1;31mbuffer[m_default_array::allocate()
    
    Root cause 1
    ============
    
    Consider the following loop:
    
      size_t monotonic;
      size_t monotonic_max;
    
      monotonic = m_monotonic.m_u32++;
      monotonic_max = monotonic + m_max; (a)
    
      while (monotonic < monotonic_max)
      {
        ...
        monotonic = m_monotonic.m_u32++; (b)
      }
    
      When the value of monotonic gets close to 2^32,
      the value of monotonic_max gets beyond 2^32 in (a)
      This is ok, as both variables are 64 bits integers.
    
      However, in the loop,
      m_monotonic.m_u32++ is only a 32 bits value (b),
      so that when incrementing to the next value,
      the monotonic counter will never get passed 2^32,
      and therefore will never reach monotonic_max.
    
      The while loop never ends, causing the bug.
    
    Fix 1
    =====
    
      The solution is to change m_monotonic to
      be a PFS_cacheline_atomic_size_t,
      to match the type (size_t) of monotonic and monotonic_max.
    
      With this fix, the loop works properly beyond 2^32.
    
      However, another issue was found by analysis.
    
    Problem 2:
    ==========
    
      When the value of monotonic gets close to 2^64,
      the value of monotonic_max gets beyond 2^64,
      causing an overflow, and wraps to a low integer (a).
    
      In this case, the while loop is never entered,
      because monotonic is near 2^64 and monotonic_max is near 0.
    
      The [1;31mbuffer[m is declared full, without looking at it.
    
      While theoretical (2^64 is a big value, the server needs
      to be up for a long time to get to this state),
      this can potentially lead to extra allocation
      of new container pages, consuming more memory than necessary.
    
    Fix 2
    =====
    
      Add logic that detects the overflow on monotonic_max,
      and reset the monotonic counter to 0.
    
    Misc
    ====
    
      This fix also changes several integer computations
      to use size_t, to clean up the code to avoid other overflows.

[33mcommit 5e1a888e9508a4cd902e45d726204b004fe2ea80[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Fri Sep 1 13:49:17 2017 +0200

    Bug #25818451 ASAN HEAP-USE-AFTER-FREE WITH GEOMETRY + STRING
    
    Problem: ST_AsWKT may read freed memory.
    
    Item_func_as_wkt::val_str() first calls args[0]->val_str(swkb_tmp) on
    its first argument (the geometry), providing a temporary String object
    for storage. Most functions will either use that String to store the
    result and return a pointer to it, or return a pointer to a completely
    different String object.
    
    Some items return a completely different String object, but in the
    process write to the String provided by the calling function. Therefore,
    Item_func_as_wkt::val_str() resets its temporary string if the string
    returned by args[0]->val_str() is not swkb_tmp.
    
    However, some items, e.g., Item_func_left and Item_func_right, return a
    different string object that points to the same memory [1;31mbuffer[m as
    swkb_tmp. Since swkb_tmp is different from the returned String object,
    swkb_tmp is reset, thereby freeing the [1;31mbuffer[m that the return value
    points to. Then we try to copy that (freed) [1;31mbuffer[m into swkb_tmp.
    
    Fix: In Item_func_as_wkt::val_str() and Item_func_as_wkb::val_str(),
    instead of resetting swkb_tmp, make a completely new copy of the SRID +
    WKB string of the geometry parameter so that we're guaranteed the string
    owns its own [1;31mbuffer[m and is modifiable.
    
    Change-Id: If9ee8a0843b068a994d6b0c49cef4cad4eabc7c7

[33mcommit c433bd09d09c67563940b28a9f85ef186b56e5ff[m
Author: Norvald H. Ryeng <norvald.ryeng@oracle.com>
Date:   Fri Sep 1 13:49:17 2017 +0200

    Bug #25818451 ASAN HEAP-USE-AFTER-FREE WITH GEOMETRY + STRING
    
    Problem: ST_AsWKT may read freed memory.
    
    Item_func_as_wkt::val_str() first calls args[0]->val_str(swkb_tmp) on
    its first argument (the geometry), providing a temporary String object
    for storage. Most functions will either use that String to store the
    result and return a pointer to it, or return a pointer to a completely
    different String object.
    
    Some items return a completely different String object, but in the
    process write to the String provided by the calling function. Therefore,
    Item_func_as_wkt::val_str() resets its temporary string if the string
    returned by args[0]->val_str() is not swkb_tmp.
    
    However, some items, e.g., Item_func_left and Item_func_right, return a
    different string object that points to the same memory [1;31mbuffer[m as
    swkb_tmp. Since swkb_tmp is different from the returned String object,
    swkb_tmp is reset, thereby freeing the [1;31mbuffer[m that the return value
    points to. Then we try to copy that (freed) [1;31mbuffer[m into swkb_tmp.
    
    Fix: In Item_func_as_wkt::val_str() and Item_func_as_wkb::val_str(),
    instead of resetting swkb_tmp, make a completely new copy of the SRID +
    WKB string of the geometry parameter so that we're guaranteed the string
    owns its own [1;31mbuffer[m and is modifiable.
    
    Change-Id: If9ee8a0843b068a994d6b0c49cef4cad4eabc7c7

[33mcommit 7675a796f31928fc62a9225036c9ef7a84d833a4[m
Author: Kailasnath Nagarkar <kailasnath.nagarkar@oracle.com>
Date:   Mon Aug 28 13:05:20 2017 +0530

    Bug #25737271 : MYSQL SERVER CRASHED WITH SIG 11 ON
                    MERGE_BUFFERSP10SORT_PARAMP11ST_IO_CACHE
    
    ISSUE: The merge_[1;31mbuffer[ms() function had incorrect way
           of handling [1;31mbuffer[ms resulting in server exiting
           abnormally.
    
    SOLUTION:
    Corrected [1;31mbuffer[m handling in merge_[1;31mbuffer[ms()

[33mcommit 84ebe8babdfd3916f8c7e604fad28c40332e6fb8[m
Author: Erik Froseth <erik.froseth@oracle.com>
Date:   Tue Aug 22 12:12:55 2017 +0200

    WL#9223
    
    Post-push fix: The test perfschema.threads_history gave a different
    result in release and debug builds. The root cause for this was that
    the default size for performance_schema_events_waits_history_long_size
    is 10000. The server creates a different number of events_waits markers in
    release and debug, and in debug it exceeds 10000 for the table
    events_waits_history_long. The result is that the performance schema
    table starts to eat up itself, since it is implemented as a ring [1;31mbuffer[m.
    This would give a different result in the test file for release and debug
    builds.
    
    The fix is to increase the size of the variable
    performance_schema_events_waits_history_long_size to ensure that the
    performance schema table doesn't start to eat up itself.
    
    Change-Id: I354bc1ae48630639c947d85a5fdf3e65c4d878ed

[33mcommit 3c7f6b7e8df10d6d3759a3d5fef1ebf40c9d15a0[m
Author: Erik Froseth <erik.froseth@oracle.com>
Date:   Tue Aug 22 12:12:55 2017 +0200

    WL#9223
    
    Post-push fix: The test perfschema.threads_history gave a different
    result in release and debug builds. The root cause for this was that
    the default size for performance_schema_events_waits_history_long_size
    is 10000. The server creates a different number of events_waits markers in
    release and debug, and in debug it exceeds 10000 for the table
    events_waits_history_long. The result is that the performance schema
    table starts to eat up itself, since it is implemented as a ring [1;31mbuffer[m.
    This would give a different result in the test file for release and debug
    builds.
    
    The fix is to increase the size of the variable
    performance_schema_events_waits_history_long_size to ensure that the
    performance schema table doesn't start to eat up itself.
    
    Change-Id: I354bc1ae48630639c947d85a5fdf3e65c4d878ed

[33mcommit 6aee469375a4eafb39d6bfe55027d0721f4c7c2c[m
Author: Sven Sandberg <sven.sandberg@oracle.com>
Date:   Sat May 6 14:33:42 2017 +0200

    WL#2955: RBR replication of partial JSON updates
    
    This worklog enables the replication of small updates of big JSON
    documents more space-efficiently.  More precisely, when using RBR, we
    will write only the modified parts of JSON documents, instead of the
    whole JSON document.
    
    The patch includes the following major components:
    
    - Implement the new option binlog_row_value_options
    
    - Implement logic to generate JSON diffs only when needed
    
      Before, JSON diffs were generated unconditionally by the optimizer.
      We changed so that JSON diffs are only generated when the option is
      enabled (unless inhibited by other options).
    
    - Implement new event type and use it when the option is enabled
    
    - Refactor: make max_row_length a private member of Row_data_memory
    
      This function was only used internally in class Row_data_memory, but
      was defined as a global function in table.cc.  Moved it to a private
      member of Row_data_memory.
    
    - Refactor: simplify pack_row and unpack_row
    
      Made several refactorings in these functions, including:
    
      New utility classes for handling null bits: When reading and writing
      a row in a row event, the logic for iterating over fields was
      interleaved with low-level bit operations to maintain a bitmap of
      null fields.  This made the code error-prone and hard to understand
      and edit.  This refactoring encapsulates the bitmap handling in
      utility classes, and simplifies pack_row / unpack_row accordingly.
    
    - Refactor: add const to integer decoder functions in pack.cc
    
      Functions in mysys/pack.cc that read from a [1;31mbuffer[m did not declare
      the [1;31mbuffer[m as const.  This patch makes net_field_length_size use a
      const parameter and makes other functions use const internally.
      Since these functions are part of the ABI, we also have to update
      include/mysql.h.pp.  (We do not const-ify pointers-to-pointers in
      function declarations, since that breaks compilation on other places
      that call the functions using non-const arguments.)
    
    - Refactor: change Json_diff_vector from a type alias to a class
    
      This was needed because extend Json_diff_vector with more member
      functions.  It also simplifies some forward declarations.
    
    - Refactor: do not overload global identifier TABLE in rpl_tblmap.h
    
      Class table_mapping in rpl_tblmap.h is used both in mysqlbinlog and
      in the server.  In the server, it maps numbers to TABLE objects.  In
      mysqlbinlog, it maps numbers to Table_map_log_event objects.  This
      was implemented by using the type name TABLE, and in mysqlbinlog use
      a typedef that makes TABLE an alias for Table_map_log_event.
    
      This patch changed rpl_tblmap.h so that it does not use the
      identifier TABLE.  Instead, it uses the new typedef Mapped_table
      that maps to TABLE in the server and to Table_map_log_event in
      mysqlbinlog.
    
    - Refactor: remove unused variable Rows_log_event::m_master_reclength
    
      There was a member variable Rows_log_event::m_master_reclength that
      was set to a (strange) value which was never read.  Removed this.
    
    - Refactor: simplify Rows_log_event::read_write_bitmaps_cmp
    
      This member function was implemented only in the base class, but had
      a switch that made it execute differently depending on the
      instance's subclass.  Changed to use a pure virtual function in the
      base class and implement the different logic in each subclass.
    
    - Implement encoder of new event format
    
      Outline of the pipeline:
    
       1. In binlog.cc:Row_data_memory, take a new argument in the
          constructor having two 'data' pointers (this constructor is used
          for Update_rows_log_event and is invoked in
          binlog.cc:THD::binlog_update_row).  This the value of the new
          server option binlog_row_value_options.  Based on this variable,
          determine if Json diffs may be used, estimate how much memory
          will be used (using the new function
          json_diff.cc:Json_diff_vector::binary_length), decide if full
          format or partial format will be used, and adjust the allocated
          memory accordingly.
    
       2. In binlog.cc:THD::binlog_update_row, pass two new arguments to
          pack_row:
    
          - row_image_type, which specifies if this is a
            Write/Update/Delete, and if it is a before-image or
            after-image.
    
          - value_options, which contains the value of
            binlog_row_value_options for update after-images.
    
       3. In rpl_record.cc:pack_row, accept the two new arguments.  If
          this is an update after-image and the bit in value_options is
          set, then determine if any column will use partial format.  If
          any column will use partial format, write the value_options
          field, followed by the partial_bits, to the output.  Otherwise,
          just write value_options=0 to the output and skip the
          value_options.
    
       4. From rpl_record.cc:pack_row, invoke the new function
          rpl_record.cc:pack_field to write a single field.  If the column
          is JSON and this is the after-image of an Update and the bit in
          value_options is set, invoke the new function
          field.cc:Field_json::pack_diff.  Otherwise, or if
          field.cc:Field_json::pack_diff returned NULL, fall back to the
          usual non-diff writer.
    
       5. In Field_json::pack_diff, determine again if this field will be
          smaller in full format or in partial format.  If full format is
          smaller, just return NULL so that rpl_record.cc:pack_field will
          write the full format.  Otherwise, invoke the new function
          json_diff.cc:Json_diff_vector::write_binary.
    
       6. In json_diff.cc:Json_diff_vector::write_binary, write the length
          using 4 bytes, followed by all the diffs.  Write each diff using
          the new function json_diff.c:Json_diff::write_binary.
    
       7. In json_diff.c:Json_diff::write_binary, write a single diff to
          the output.
    
    - Implement decoder of the new format
    
      The pipeline is now:
    
       1. Add a parameter to
          log_event.cc:Rows_log_event::unpack_current_row, which says if
          this is an after-image or not.  Set the parameter from all the
          callers in log_event.cc.
    
       2. Move Rows_log_event::unpack_current_row from log_event.h to
          log_event.cc and make it pass two new arguments to
          rpl_record.cc:unpack_row: row_image_type, which indicates if
          this is Write/Update/Delete and before-image or after-image, and
          has_value_options, which is true for Update events when
          binlog_row_value_options=PARTIAL_JSON.
    
       3. Make rpl_record.cc:unpack_row accept the two new parameters.
    
          First make a few small refactorings in rpl_record.cc:unpack_row:
    
          - Clarify some variable names and improve the comment for the
            function.
    
          - Remove comments about unpack_row being used by backup, having
            rli==NULL.  This may have been an intention at some point in
            time, perhaps in 5.1, but probably never was true.  And rli is
            unconditionally dereferenced in the main loop, so it cannot be
            NULL.  Instead assert that it is not NULL.  Also assert that
            other parameters are not NULL, as well as other preconditions.
    
          - Improve some debug trace printouts.
    
          - Return bool instead of int since the caller does not need to
            distinguish more than two different return statuses.
    
          Then implement the new logic:
    
          - When partial format is enabled, read partial_bits before the
            after-image (from within the main loop, as well as from the
            loop that consumes unused fields), and also read partial_bits
            after the before-image (after the main loop).  For the
            before-image, leave the read-position before the partial_bits.
            Use the new auxiliary function start_partial_bits_reader to
            read the value_options and initialize the Bit_reader
            accordingly, in the two places (after before-image and before
            after-image).
    
          - In order to read the correct number of bits before the
            after-image, start_partial_bits_reader needs to know the
            number of JSON columns on the master.  This is known from the
            table_map_log_event via the table_def class.  For convenience
            (and reuse in the mysqlbinlog patch), we add a member function
            rpl_utility.cc:table_def::json_column_count.  This function
            also caches the computed column count, to speed up successive
            calls (e.g. for many-row updates).
    
          - For the before-image, set the corresponding bit in the table's
            read_set, for any column having a 1 in the partial_bits.  This
            tells the engine to fetch the blob from storage (later, when
            the engine is invoked).  The blob will be needed since we have
            to apply the diff on it.
    
          - Call an auxiliary function rpl_record.cc:unpack_field to read
            each field move some special case handling for blobs into this
            function too.
    
       4. In rpl_record.cc:unpack_field, call
          field.cc:Field_json::unpack_field for partial Json fields.
    
       5. Add new function field.cc:Field_json::unpack_field, which
          invokes the new function
          json_diff.cc:Json_diff_vector::read_binary to read the
          Json_diff_vector, and the pre-existing (since WL#10570) function
          apply_json_diffs to apply the diff.
    
          The Json_diff_vector uses a new MEM_ROOT rather than the one of
          the current_thd, because that allows memory to be freed for each
          value, which saves resources e.g. in case of many-row updates.
    
          Before apply_json_diff can be invoked, we need to call
          table->mark_column_for_partial_update and
          table->setup_partial_update, in order to enable the *slave*
          server to generate JSON diffs in the *slave's* binary log.
    
       6. Add the new function json_diff.cc:Json_diff_vector:read_binary.
          This function reads the length of the field, then iterates over
          the diffs, reads each diff in turn, constructs Json_path and
          Json_wrapper/Json_dom objects, and appends them to the
          Json_diff_vector.
    
          We implement the auxiliary function net_field_length_checked,
          which reads an integer in packed format (see mysys/pack.cc),
          checking for out-of-bounds conditions.
    
    - Implement decoding and pretty-formatting of JSON diffs in mysqlbinlog
    
      mysqlbinlog outputs row events in two forms:
    
      - BINLOG statements that a server can apply.  There is nothing to
        change to make this work for the new event type.
      - "Pseudo-SQL" that humans can read, in case mysqlbinlog is invoked
        with the -v flag.  This is what the present patch implements.
    
      The pipeline in mysqlbinlog is:
    
       1. log_event.cc:Rows_log_event::print_verbose invokes
          log_event.cc:Rows_log_event::print_verbose_one_row with the new
          argument row_image_type, which indicates if this is a
          Write/Update/Delete and whether it is a before-image or
          after-image.
    
       2. In log_event.cc:log_event.cc:Rows_log_event::print_verbose_one_row
          we do two things:
    
          - Refactorings:
    
            - Use a Bit_reader to read the null bits, instead of using bit
              arithmetic.
    
            - Use safer boundary checks.  The code has a pointer to row
              data and a pointer to the end of the row data.  In C/C++, a
              pointer may point to the next byte after an allocated block
              of memory, but incrementing it further has an undefined
              result.  After reading the length of a field, the correct
              way to check that this length is not corrupt is to compare
              it with the end pointer minus the pointer to the read
              position.  (Before, it added the length to the read position
              and compared with the end pointer, but the read position
              plus the length is undefined.)
    
          - Implement the feature:
    
            - Read the value_options, if this is the after-image of a
              PARTIAL_UPDATE_ROWS_EVENT.
    
            - If value_options has the PARTIAL_JSON bit set, read the
              partial_bits.
    
            - Pass the partialness of the column as a parameter to
              log_event.cc:log_event_print_value.
    
       3. In the new function log_event_print_value, accept the new
          parameter, and in case the value is partial, call the new
          function log_event.cc:print_json_diff to parse and print the
          Json diffs.
    
       4. In the new function log_event.cc:print_json_diff, read, parse,
          and print all the diffs.
    
          The output has the form:
            JSON_<func>(
            JSON_<func>(
            ...
            JSON_<func>(@column, path[, value][,
                        path [,value][,
                        ...]]),
            ...
                        path[, value][,
                        path [,value][,
                        ...]]),
                        path[, value][,
                        path [,value][,
                        ...]])
    
          In this output format, the JSON_<func> functions appear in
          *reversed* order, whereas all the (path, value) pairs appear in
          order of appearance.  Therefore, we make two passes over the
          sequence of diffs:
    
           1. Read just the operations and store them in a vector.  Then
              print the operations in reverse order. Operations are
              printed using the new function
              log_event.cc:json_wrapper_to_string.
    
           2. Read the full diffs and output in the order of appearance.
    
       5. Add a new function log_event.cc:json_wrapper_to_string to print
          a Json_wrapper.  This ensures that the Json values are printed
          in the correct type.  JSON_<func> functions will convert SQL
          types to their JSON equivalents: for instance, the JSON function
          JSON_SET('[1, 2]', '$[0]', '[]') will set the 0th element of the
          JSON array to a string containing an open and closing square
          bracket, and not to an empty JSON array.  To account for this,
          different data types need different quoting, and to insert a
          JSON object or JSON array we need to cast the string to JSON
          first.
    
       6. To output JSON values with correct quoting for SQL strings, we use
          the existing my_b_write_quoted, but change it so that:
    
          - it uses a lookup table (computed only once) for simplicity and
            performance;
    
          - it prints common escapes such as \n, \\ in a more
            human-readable way.
    
    - BUG#26018522: MYSQLBINLOG -V PRINTS JSON IN ROW EVENTS WRONG
      mysqlbinlog -v had two problems:
    
      P1. It only read the length of JSON objects from two bytes. But the
          length of JSON data in row events is encoded (in little endian)
          using four bytes.  Therefore, it printed the wrong data for JSON
          objects bigger than 64K.  This also caused subsequent errors.
    
      P2. It only dumped the raw bytes of the [1;31mbuffer[m (quoted).  But row
          events contain a binary format for JSON, so the output was not
          useful.
    
      We fix these two problems as follows:
    
      F1. Read the length from four bytes.
    
      F2. Link mysqlbinlog with the parts of the server that can parse
          binary JSON and format it in human-readable form.  This includes
          three files:
          - json_binary.cc can parse the binary JSON format.
          - json_dom.cc can format human-readable JSON.
          - sql_time.cc is used by json_dom.cc to format time and date.
          All these files contain code that mysqlbinlog does not need and
          which needs to link with more parts of the server (e.g. THD).  To
          avoid link problems we put such code inside #ifdef MYSQL_SERVER.
    
    - Created a new test suite for tests that should not be
      parallelized by MTR because they require many mysqlds.
    
      The new suite contains test cases requiring many (6 or more) mysqlds
      in a replication topology. Running those test cases with
      "--parallel" > 1 may exhaust the test host I/O resources. So, this
      new suite should run only with "--parallel=1".

[33mcommit e8c0a6e0569b8721459a1f9577b306ca93918915[m
Author: Mayank Prasad <mayank.prasad@oracle.com>
Date:   Thu Aug 17 18:39:01 2017 +0530

    wl#9193 : Autoscale InnoDB resources based on system resources by default
    
     Details:
            Added a new global bool system variable 'innodb_dedicated_server'
            with default value ON.
            When this variable is set to ON, then innodb_[1;31mbuffer[m_pool_size and
            innodb_log_file_size are autoscaled based on system memory.
            Also innodb_flush_method is set to O_DIRECT_NO_FSYNC if supported.
    
            A new component service 'system_variable_source' is also added which
            exposes a method named 'get' which could be used to get the SOURCE of
            a given system variable name.
    
            Reviewed by : thirunarayanan.balathandayuth@oracle.com
                          darshan.m.n@oracle.com
                          venkata.sidagam@oracle.com
            RB : 16832

[33mcommit 7674c07d2db9f40a29c36b560011d43a3e898b5f[m
Author: Chaithra Gopalareddy <chaithra.gopalareddy@oracle.com>
Date:   Wed Aug 16 11:48:40 2017 +0530

    Bug #26496645: WINDOW FUNCTIONS: CRASH IN WINDOW::RESTORE_SPECIAL_RECORD
    
    Problem
    When we have a value which is less than argument value for a range frame in
    a windowing function, mysql server exits
    
    Analysis:
    Currently, for a range optimizable window function, the result of the
    window function is stored into a in-memory table in the form of a
    special record, which can be restored later.
    This saves us time from calculating the results again for the next row if
    the value for window function is expected to be the same. But for a case
    when all the values in the frame are less than the specified range value,
    we skip saving this special record. This results in restoring a non-existent
    record and the server exits because of this.
    
    Solution:
    Added saving of the special record to the code flow in
     process_[1;31mbuffer[med_windowing_record.

[33mcommit 10a3fe05784854b9b9c8c6f88d7841257945b23c[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Aug 8 15:29:47 2017 +0200

    Bug#26037206 WL8117: VALGRIND WARNINGS IN DERIVED.TEST
    
    Running 'mtr --valgrind --debug main.derived' gives misc warnings, mostly
    in the handler interface when printing human-readable versions of records.
    
    Fix: don't print records when running with --valgrind, unless the server
    is actually *built* with -DWITH_VALGRIND=1
    
    Also: initialize [1;31mbuffer[m for dbug-printing range optimizer trees.
    Initialize Protocol_classic::input_packet_length in the default CTOR.
    
    Change-Id: I365cde0fe5158d7004228c3c0c873812cb78e437

[33mcommit d7c894eaa06fbb4a83b189f9f50c1b6119e555c9[m
Author: Georgi Kodinov <georgi.kodinov@oracle.com>
Date:   Fri Aug 11 15:31:55 2017 +0300

    WL#6595 addendum 1:
    Fixed a valgrind issue because of sha256 plugin requiring the hash to
    be null-terminated.
    Since the hash in ALTER USER is read from the history table it's not
    guaranteed to be null-terminated.
    Removed the (unsafe) c_ptr() and replaced it with c_ptr_safe() which is:
    a) not causing a valgrind issue on a non-null terminated [1;31mbuffer[m.
    b) ensuring that the returned pointer is null terminated

[33mcommit 02fcd00473da7510c6867c3027e0b3751835ffee[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Fri Aug 11 11:58:57 2017 +0800

    WL#9536: Suppress the 'checksum mismatch' for this one.
    
    It could be possible that the page gets corrupted after crash.
    As long as there is a good page in double write [1;31mbuffer[m, it's fine.

[33mcommit 790e766822b2603f91f8758e534051e721045f16[m
Author: Srikanth B R <srikanth.b.r@oracle.com>
Date:   Thu Aug 10 10:56:14 2017 +0530

    Bug#26187243: FIX AND IMPROVE SEARCH FUNCTIONS IN MTR
    
    Issue:
    ------
    There are bugs/weaknesses in the search functions used in MTR tests:
    - include/search_pattern_in_file.inc: This function reads 50000 bytes
      per chunk and searches for a pattern in the chunk. However, this is
      bound to fail if the pattern crosses the border between two chunks
      and can cause sporadic failures.
    - include/search_pattern.inc: It reads the whole file into a list in
      memory and then processes lines one by one. It would be efficient
      if a single line is read at a time instead of the entire file.
      Also, matching lines which had a pair of single quotes are being
      ignored when the file is sourced multiple times due to improper
      cleanup.
    
    Fix:
    ----
    Search functions have been consolidated into two inc files:
    - include/search_pattern.inc: It should be used for searching patterns
      which occur within a single line. It loads one line from the file at
      a time and searches the specified pattern in it. A [1;31mbuffer[m having the
      specified number of lines prior to the matching line and a file
      lookup for those after it are used to get context lines.
    - include/search_pattern_multiline.inc: It reads the whole file into
      memory and should be used to match patterns which might be spread
      across multiple lines.
    
    Usage of search functions in test scripts was reviewed and they have
    been modified to use search_pattern.inc for all single-line searches.
    
    Reviewed-by: Pavan Naik   <pavan.naik@oracle.com>
                 Deepa Dixit  <deepa.dixit@oracle.com>
    RB: 16811

[33mcommit 3b078313c5afe5c23d1791fd27489979441479f6[m
Author: Guilhem Bichot <guilhem.bichot@oracle.com>
Date:   Mon Aug 7 16:45:13 2017 +0200

    Bug#26556025 ASSERTION `!SELECT_LEX->IS_RECURSIVE() || !TMP_TABLES' FAILED.
    
    With SQL_BUFFER_RESULT = 1 any recursive CTE would cause a server
    exit, with the debug binary.
    Because such setting makes need_tmp_before_win be true which
    forces the creation of a tmp table in JOIN::make_tmp_tables_info(),
    and the recursive query block shouldn't use such table as it introduces
    a layer of [1;31mbuffer[ming which "cuts the recycling of rows".
    Fix: refined the setting of need_tmp_before_win; the CTE already uses
    a tmp table anyway. Also rewrote the conditions to an equivalent but
    hopefully easier block of code.
    Added minimal test for bug in with_recursive_bugs.test.
    Added a few tests in with_recursive.inc (their result is not influenced
    by the code fix; but as they relate to clauses which create tmp tables,
    I wanted to have coverage).

[33mcommit dc5235f21b491e13ac0c5bc08cca5671a9362519[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Fri Jul 28 20:28:45 2017 +0800

    WL#9536: A workaround for Bug#26445422 - WL9536: TOO SMALL BUFFERPOOL NOT REPORTED
    
    Analysis is posted on the bug page, this is a trunk bug.
    
    To make it work smoothly in 9536, an error message is introduced,
    so that users can try to increase innodb_[1;31mbuffer[m_pool_size to
    let the recovery go on.

[33mcommit 793e8e74ff6e34274a093638d5abe0c988f1394c[m
Author: Xing Zhang <xing.z.zhang@oracle.com>
Date:   Tue Jun 20 10:46:18 2017 +0800

    Bug #26286790: PERFORMANCE ISSUE OF EXPLICIT COLLATE CLAUSE
    
    Ordering by a varchar field with explicit collation is much slower than it
    with implicit collation, even if the explicit collation is same as the
    implicit one. A certain sorting with implicit collation needs 0.5 sec, but
    the sorting with explicit collation needs about 1 min.
    
    Cause:
    A item is created for the field with explict collation, and filesort treats
    its weight [1;31mbuffer[m length is fixed. But for the field with implicit
    collation, filesort treats its weight [1;31mbuffer[m length is variable. This
    causes there are much more chunks is created and needed to merge when doing
    filesort for the field with explicit collation. It consumes a lot of time.
    
    Fix:
    All new UCA collations we added don't need padding spaces anymore, so we
    let filesort know that the weight [1;31mbuffer[m length of the item is variable.
    
    Result:
    without this patch, time used to sorting reporter's data needs 0.51 sec and
    58.73 sec.
    With this patch, time used to sorting reporter's data needs 0.54 sec and
    0.76 sec.
    
    Change-Id: I5394faabf6325ff43f71ae6076dedebd3d75c105

[33mcommit 81a76840d1aa7af5f585cfc306bf79387bb832c0[m
Author: Mayank Prasad <mayank.prasad@oracle.com>
Date:   Wed Jul 5 16:06:32 2017 +0530

    Bug #26363837 : SIG=11 TEMPTABLE::ALLOCATOR<UNSIGNED CHAR>::DEALLOCATE
    
    Details :
        In temptable SE, flag Row::m_data_is_in_mysql_memory indicates
        whether [1;31mbuffer[m pointed by Row::m_ptr belongs to this Row
        object (if false) or not (if true). During update, when a Row
        object is being created, Row::copy_to_own_memory() is called
        to have Row::m_ptr allocated (thus it belongs to ROW object) and
        this flag is set to 'false'.
    
    Issue :
        In copy_to_own_memory(), this flag is set to false before successful
        allocation of m_ptr. So in case of failure in allocation, where we
        return from this function, this flag gives wrong information.
    
    Fix :
        In copy_to_own_memory(), setting of this flag should be done
        only after successful allocation of m_ptr.
    
    Reviewed by: Sunny.Bains@oracle.com
    RB : 16692

[33mcommit 5875f45e33bbeff904859e1560d6a930fcf62145[m
Author: Karthik Kamath <karthik.kamath@oracle.com>
Date:   Mon Jul 3 14:13:52 2017 +0530

    BUG#26136674: POSSIBLE UNINTENDED USAGE OF "PRECISION"
                  VARIABLE
    
    ANALYSIS:
    =========
    In the function my_b_vprintf() which is used for logging
    in MySQL, there is an unintended usage of 'precision'
    variable.
    
    my_b_printf() which is wrapper for my_b_vprintf() is a
    simple version of printf().
    Generally in printf() statements, we use an asterisk (*) to
    denote the width specifier/precision instead of hard coding
    it in the format string. The value for '*' is passed as an
    additional integer value argument to printf(), preceding
    the argument that has to be formatted.
    
    To achieve the required formatting, we use two variables
    which are defined below.
    
    - minimum_width (currently implemented for %d and %u):
      The minimum number of characters to be printed. If the
      value to be printed is shorter than this number, the
      result is padded with blank spaces.
    
    - precision (currently implemented for %b, binary [1;31mbuffer[m):
      used to print exactly <precision> bytes from the argument
      without stopping at '\0'.
    
    In the current implementation, 'precision' was used for
    processing '*' which should ideally be used only for
    processing '.*'. This might result in data loss.
    
    FIX:
    ====
    We are now using the variable 'precision' for processing
    of '.*' and 'minimum_width' for processing of '*'.

[33mcommit 30613d6ac81ede01ad2c45ea8d74fd5d43163f48[m
Author: Havard Dybvik <havard.dybvik@oracle.com>
Date:   Fri Jun 23 14:33:29 2017 +0200

    Bug#25738624: ASSERTION `FALSE' FAILED IN SQL/SQL_EXECUTOR.CC
    
    An assertion protecting an unused branch failed if an indexed column in
    a system table was referenced in a MIN/MAX and in a join, and the
    optimizer was unable to optimize away the join in opt_sum_query(). If an
    index was used to extract the MIN/MAX value of the column, the row
    [1;31mbuffer[m of that table would get status 'started' with the content stored
    in the record[0] [1;31mbuffer[m. If the optimizer later tried to access the
    table using read_system(), this status would cause an attempt to restore
    the content from the record[1] [1;31mbuffer[m instead of reading it directly
    from the table. Because only record[0] contains valid data and
    the branch restoring the data from record[1] is declared as unused, the
    assertion fails as it should.
    
    To account for cases where opt_sum_query() is able to determine MIN/MAX
    value from an indexed column in a system table but is not able to
    optimize away subsequent reads to the same table, the row [1;31mbuffer[m status
    is now reset to 'not started' after reading the index. Any subsequent
    read will then fetch data from the table instead of attempting to
    restore it from record[1].

[33mcommit d8deb78e3357b598f60b3e0c1987f7b4b8850f44[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon May 8 13:07:20 2017 +0200

    wl#10234: Enable usage of MultiFrag scan from API -> TC -> SPJ
    
    SPJ API sets the ScanTabReq::setMultiFragFlag() to enable the feature.
    'm_fragsPrWorker' is calculated by the API such that each 'worker'
    handle all fragments located on the same data node.
    
    As a 'batch-[1;31mbuffer[m is set up pr fragment, the batch size available
    for each combined MultiFrag scan is multiplies by m_fragsPrWorker.
    
    Dbspj::execSCAN_FRAGREQ receives the list of fragments to scan
    (set up by TC) in the last longSignal section. Instead of
    scanFrag_build() setting up a single ScanFragHandle for the
    root scan, we now construct one for each of the MultiFragment.
    
    As there is an implementation defined 12-bit limit on
    'maxBatchRows', some additional checks had to be introduced
    to avoid it to overflow. (Due to larger batch sizes now being
    available)

[33mcommit 5659c960020f4832223aaa7f4fd364107fb70624[m
Author: Mikael Ronström <mikael.ronstrom@oracle.com>
Date:   Tue Apr 11 15:01:21 2017 +0200

    BUG#25860002: Fixed problem during online add column where we need to update maxRecordSize regularly in LCP scans to ensure we don't overrun memory [1;31mbuffer[m

[33mcommit 661b7fd8c1471e511c84abc02afef5f07ffe29b0[m
Author: Catalin Besleaga <catalin.besleaga@oracle.com>
Date:   Thu May 11 14:00:59 2017 +0200

    Bug#26042934: Unchecked read after allocated [1;31mbuffer[m
    
    Problem:
    There is no check for packet length before reading the byte that
    specifies if there are new data types provided.
    
    Solution:
    Added checks for the length of the packet_left before reading the byte.
    Also added an assert and a check for the packet length left while
    reading each ps parameter.
    
    Change-Id: I059c7eb31cd5005f4bc8aee3048fdcc2221ff381

[33mcommit 86f92bbd00d28678bedc422a40198a9ec2ac840c[m
Author: Lakshmi Narayanan Sreethar <lakshmi.narayanan.sreethar@oracle.com>
Date:   Fri Jun 2 03:47:31 2017 +0530

    Bug#16371292 : Print FK violation information (PART II : ha_ndbcluster fix)
    
    Part II of the fix.
    This patch updates the get_error_message() method of the ha_ndbcluster to
    fetch the proper details of the FK constraint on an fk constraint violation
    error and print it back to the server's [1;31mbuffer[m. The fk details is got
    either from the last transaction stored in thd_ndb for DML erros or from
    ndb's dictionary for DDL errors.
    
    A new method is also added to the Ndb_fk_util class to generate the FK
    constraint info in required format when an FK object is passed to it.
    
    This patch also updates all the MTR testcases and replaces the `Unknown
    error codes` text with proper FK info.

[33mcommit 29761426092215a9be275607828b85560e463007[m
Author: Satya Bodapati <satya.bodapati@oracle.com>
Date:   Tue May 16 11:47:22 2017 +0200

    Bug#25804386 - DUPLICATE VALUE FOR AUTOINC COLUMN
    
    Background:
    ----------
    On checkpoint, the DDTableBuffer in-memory contents are written to the
    physical DDBuffer Table.
    
    During checkpoint, the redo generated by these DDTableBuffer writes
    are written to disk.
    
    Before WL#9499:
    --------------
    The fil_name_parse() which writes MLOG_FIL_NAMEs made sure that the
    redo generated by DDBuffer Table writes are also flushed to disk
    
    So this is not so obvious dependency on fil_names_clear().
    
    After WL#9499:
    --------------
    Since MLOG_FILE_NAME is removed, there is no need to write MLOG_FILE_NAMEs
    as part of checkpoint. So fil_names_clear() is removed.
    
    This exposed the above explained dependency of DDTableBuffer writes
    on fil_names_clear(). Since the redo-writes of DDTableBuffer didn't
    make to disk on checkpoint, after a crash, a duplicate auto-inc value
    is possible and hence this bug.
    
    Fix:
    ----
    1. Change return type of dict_persist_to_dd_table_[1;31mbuffer[m() to determine if a possible
       write to DDTableBuffer happenned.
    
    2. Flush the redo upto a lsn which includes DDTableBuffer changes.
    
    Reviewed-By: Debarun Banerjee <debarun.banerjee@oracle.com>
    Reviewed-By: Bin Su <bin.x.su@oracle.com>
    RB: 16071

[33mcommit b2bc8c09936bd0a77b9371ddef117316e92cfd19[m
Author: Satya Bodapati <satya.bodapati@oracle.com>
Date:   Tue Apr 11 22:00:40 2017 +0530

    Bug#25775881 INNODB ASSERTION DURING INITIALIZE IF FAILED TO CREATE TABLESPACES.OPEN.1
    
    Problem:
    --------
    1) Initialization problem when mysqld is intialized for mysql user as root (specific paths only)
    2) file creation fopen() takes global umask value which can be changed by server. See Bug#25832856
    3) remove windows specific FILE* to fd conversion to do fsync()
    4) dangling symlink issue when background threads do open() and close() on relative paths.
    
    Fix:
    ----
    1. Change from absolute to relative paths for tablespaces.open.* files
    2. Create/open/close tablespaces.open.* files on startup instead of background thread.
    3. Use InnoDB os_file_*() APIs instead of fopen()/fwrite()/fclose()
    4. Remove windows specific logic for fsync()
    5. Solves the dangling symlink problem because background open()/close()
       is avoided (seen on MTR tests, as it creates symlink)
    6. Introduce OS_BUFFERED_FILE for [1;31mbuffer[med file writes
    
    Reviewed-By: Jimmy Yang <jimmy.yang@oracle.com>
    RB: 16012

[33mcommit cecf4ed4982ce58dd6d31d733d070225e81430b7[m
Author: Joao Gramacho <joao.gramacho@oracle.com>
Date:   Fri Mar 10 15:49:37 2017 +0000

    BUG#25694813 INSTRUMENTATION IS ALWAYS ENABLED FOR REPLICATION P_S
                 STATUS TABLES
    
    Problem
    -------
    
    New fields were added by WL#7374 to following PS replication tables:
    - replication_connection_status;
    - replication_applier_status_by_coordinator;
    - replication_applier_status_by_worker.
    
    The fields are related to GTID monitoring. They have information about
    when a GTID was committed on the original master and on the immediate
    master, when a GTID transaction started being processed by the I/O
    thread (connection_status), by the MTS coordinator and by the worker
    threads. There is also the timing information about the last processed
    transaction of the three replication thread types.
    
    For performance reasons, if this new information is not needed, users
    should be able to disable the instrumentation that populates the new
    table fields. However, in the current implementation, this
    instrumentation is always enabled.
    
    Fix
    ---
    
    The replication monitoring introduced by WL#7374 now depends on
    performance schema being enabled on the server.
    
    When performance schema is not enabled in the server, the replication
    status tables will not collect local timing information. All
    START_*_TIMESTAMP and END_*_TIMESTAMP will be zero for the new queued,
    [1;31mbuffer[med and applied transactions.
    
    We replaced all extra Relay_log_info locking just for ensuring GTID
    information atomicity by a new atomic locking mechanism just for the
    GTID information.
    
    Note: this fix made also some performance schema tables as "perpetual":
    - replication_applier_configuration;
    - replication_applier_status;
    - replication_applier_status_by_coordinator;
    - replication_applier_status_by_worker;
    - replication_connection_configuration;
    - replication_connection_status;
    
    Those tables should be able to present content even when performance
    schema is disabled on server.

[33mcommit 9fd9de49aa4e812c092ce365c7b482f4700c6062[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Thu Feb 16 08:30:00 2017 +0100

    WL#9185 MySQL Cluster support for new DD
    
     - remove temporary [1;31mbuffer[ms for db and table_name since
       drop_all_triggers now takes the expected "const char*"

[33mcommit 7ed9d4b9407bfdcbd19072fb8a50c55cf1e8b23a[m
Author: Jimmy Yang <jimmy.yang@oracle.com>
Date:   Tue May 2 19:10:23 2017 +0800

    temp disable a discard tablespace call in innodb_[1;31mbuffer[m_pool_resize_debug.test
    wait for WL9535

[33mcommit 3519f82183799d6798eb710a7bbd0cec21c635c0[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Apr 27 14:50:00 2017 +0200

    Bug#25972576 ADDRESSSANITIZER: STACK-BUFFER-OVERFLOW HEAP-BUFFER-OVERFLOW FOR MEMCACHED SUITE
    
    AddressSanitizer: stack-[1;31mbuffer[m-overflow
    memcached.memc292_ibd2sdi_system_tablespace
    
    Fix: call buf_page_is_zeroes for the [1;31mbuffer[m we have actually just
    filled: full_page, rather than some other [1;31mbuffer[m.
    
    AddressSanitizer: heap-[1;31mbuffer[m-overflow
    memcached.memc250_container
    
    Fix: use 'val_buf' for printing, 'value' is not null-terminated.
    
    Change-Id: Ia14da2b109fa36def1c5ced5b9a08451bcd05a48

[33mcommit a8ed4057be049c3bab81f97ad55b5f1495b39afa[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Sun Apr 23 14:51:11 2017 +0200

    Bug#25703113 A TOO HIGH 'BATCHBYTESIZE' ARGUMENT SENT IN THE SCANREQ
    
    The max 'BatchByteSize' sent in SCANREQ signals were not always
    set correctly to reflect a limited 'byte' size available in the
    client side result [1;31mbuffer[ms.
    
    This patch refactor parts of the result [1;31mbuffer[m size calculation,
    such that also the 'BatchByteSize' is modified to correctly
    reflect the max batch 'byte' size the data nodes may return

[33mcommit b34a28da7c7efcb5685e82543c9f5df96b2a737f[m
Merge: 577825e5330 be86a27c068
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Thu Apr 20 19:33:23 2017 +0530

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            mysql-test/suite/gis/t/spatial_analysis_functions_[1;31mbuffer[m.test
            mysql-test/t/gis-precise.test

[33mcommit 41ef192112c47a5a06bdb59d5de3cca61f1aa07e[m
Merge: 187324c11fb f8ff8c1399a
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Thu Apr 20 12:11:27 2017 +0530

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            mysql-test/r/gis-precise.result
            mysql-test/r/gis.result
            mysql-test/r/mysqltest.result
            mysql-test/suite/gis/r/spatial_analysis_functions_[1;31mbuffer[m.result
            mysql-test/suite/gis/t/spatial_analysis_functions_[1;31mbuffer[m.test
            mysql-test/t/gis-precise.test
            mysql-test/t/mysqltest.test

[33mcommit dc244e7e4fe5498ca9d872a7c732ed7805e05f42[m
Author: Dmitry Lenev <dmitry.lenev@oracle.com>
Date:   Thu Mar 30 17:39:50 2017 +0300

    Pre-requisite patch for WL#6049 "Meta-data locking for FOREIGN KEY tables".
    
    Also includes fix for bug #25807393 "IMPROPER HANDLING OF DATABASE NAMES WHEN
    LOCKING TABLES FOR TRIGGER EXECUTION".
    
    Changed Query_tables_list::sroutines set/hash to use custom key instead of
    MDL_key. This should allow addition of new entry types for this set without
    adding new artificial namespaces to MDL subsystem.
    
    New custom keys are compatible with MDL_key format, so new initializer for
    MDL_key was introduced, which allows quickly produce MDL_key from 'sroutines'
    keys when needed.
    
    New custom keys should also consume less memory, as unlike MDL_key, they are
    stored in variable-length [1;31mbuffer[m allocated along with entries for 'sroutines'
    set on memory root.
    
    Changed 'sroutines' hash to use binary comparison for the keys. This ensures
    that comparison of database component of the key is done correctly, in
    case-sensitive fashion, on case-sensitive filesystems.
    Since routine and trigger names are case-insensitive, we always lowercase
    their names when generating keys.
    
    This fixes bug #25807393, which occurred because prelocking algorithm was
    not able to differentiate triggers belonging to databases which names only
    differed in case (e.g. 'a' and 'A') and as result ignored tables and
    routines needed by one of 'duplicate' triggers.
    
    Finally, fill_dd_view_routines() code was changed to store only routines
    which were directly used by view. Indirectly used routines should not
    affect view columns/validity status in I_S.

[33mcommit e07873e062c2cfbbf31ce8e87be1aa5dc4dd6db0[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Mar 29 17:42:58 2017 +0200

    Bug#25800933 BROKEN CONCURRENCY CONTROL WHEN UPDATING 'M_NODE_TOTAL_SEND_BUFFER_SIZE'
    
    The node internal scheduler (mt.cpp) collect statistics about its own
    progress and its outstanding work. One such statistics being collected is
    the amount of outstanding 'send-bytes' which is being collected in
    send_[1;31mbuffer[m::m_node_total_send_[1;31mbuffer[m_size. This may later be
    used by the send thread scheduler, which use amount of outstanding sends
    as a metric to self tune its send performance vs latency.
    
    In order to reduce lock contention on the internal send [1;31mbuffer[ms, they
    have been split in two thr_send_[1;31mbuffer[m parts: the 'm_[1;31mbuffer[m' and
    'm_sending' [1;31mbuffer[ms - each of them are protected by their own mutex.
    'm_node_total_send_[1;31mbuffer[m_size' was maintained to reflect the total size
    in these two send [1;31mbuffer[ms.
    
    It turns out that we were not consistent regarding which mutex we
    used in updating 'm_node_total_send_[1;31mbuffer[m_size':
    
     - In link_thread_send_[1;31mbuffer[ms() we locked send_[1;31mbuffer[m::m_[1;31mbuffer[m_lock
     - In bytes_sent() we locked send_[1;31mbuffer[m::m_send_lock
     - In reset_send_[1;31mbuffer[m() we locked both.
    
    Thus there is effectively no concurrency protection of
    'm_node_total_send_[1;31mbuffer[m_size'.
    
    This patch replace m_node_total_send_[1;31mbuffer[m_size with the two
    seperate 'm_[1;31mbuffer[med_size' and 'm_sending_size' which keeps
    track of respective size of the two [1;31mbuffer[ms. These new counters
    are updated under protection of the two different mutexes
    protecting each of the send [1;31mbuffer[ms.
    
    mt_get_send_[1;31mbuffer[m_bytes() will add these together to get the
    total size. This method is already documented as doing an
    unprotected 'get' of the [1;31mbuffer[m seize, which should be OK as
    we can do with a [1;31mbuffer[m size being slightly off. As the
    concurrency controll is now fixed , the updates will be
    correct, and the value will not 'drift' over time.

[33mcommit 87d5375b4dc7231352a9dcf10a2bc030c5ffbe08[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Apr 6 08:54:06 2017 +0200

    Bug#25750355 SEND SPJ RESULTS AS 'PACKED' TRANSID_AI WHERE APPLICABLE
    
    Patch enable the usage of 'short' or 'packed short' TRANSID_AI
    signals for sending SPJ results back to the client-API.
    This is a more efficient way to send short TRANSID_AI signals.
    
    It refactors out code for sending TRANSID_AI to the API from
    Dbtup::sendReadAttrinfo() into the new method Dbtup::sendAPI_TRANSID_AI().
    This method is then called from Dbtup::flush_read_[1;31mbuffer[m() which is where
    the SPJ results are delivered to the client_API.
    
    Also introduce some cleanup of usage of the magic litterals
    '3' and '22' where 'AttrInfo::HeaderLength' and 'TransIdAI::DataLength'
    should be used instead.
    
    Refactor how the [1;31mbuffer[ming work is divided between
    Dbtup::[1;31mbuffer[mTRANSID_AI() and the new Dbtup::sendAPI_TRANSID_AI().
    (Related to how the sending of full packed-[1;31mbuffer[ms are handled).

[33mcommit adfc17e3ad68de74f6555c3f43db7f5f9775dece[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Mon Apr 3 11:29:40 2017 +0530

    Bug #24748843 : SYNC PRINTS TO STDOUT CAUSING MAIN THREAD TO SLEEP DURING HIGH IO WAIT
    
    Re-enable asynchronous logging.
    Flush user-space [1;31mbuffer[med data using fflush() after every write in the async log thread.

[33mcommit f8373b2db4075f7cef78f28d9146acc21ddab9e5[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Thu Mar 30 04:55:17 2017 +0200

    Provide more [1;31mbuffer[m pool for innodb.innodb-copy-alter-debug
    
    Problem: restarting a server in innodb.innodb-copy-alter-debug often
    times out in the 64K page size runs because there is too little room
    in the [1;31mbuffer[m pool.
    
    Solution: increase the size of the [1;31mbuffer[m pool (.opt file).
    
    Approved by Anitha Gopi <anitha.gopi@oracle.com>.

[33mcommit c0b1f54376ef5a95febb28be83abf00ed2ad6196[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon Mar 27 09:08:39 2017 +0200

    Bug#25777337 TC BLOCK DOES NOT HANDLE 'DROPPED' LONG 'TRANSID_AI SIGNALS
    
    Handling of TRANSID_AI signals 'dropped' due to
    'out of long signal message [1;31mbuffer[ms' were not implemented
    in Dbtc::execSIGNAL_DROPPED_REP(). Such signals could (only)
    come from unique index operations.
    
    This patch introduce handling of such dropped TRANSID_AI
    signals by aborting the TcIndexOperation.

[33mcommit 3815ca14e3c4d3e19b1b42f77bb622b2bdbf83d3[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Mar 7 12:11:43 2017 +0100

    WL #10354: Make Unicode 9.0.0 and newer collations NO PAD (fix blob strnxfrm)
    
    Make sorting keys for blobs correctly heed the demand that strnxfrm output
    [1;31mbuffer[ms must be an even number of bytes. (This gets relevant when more complex
    collations than “binary” go through the variable-length path.)
    
    Change-Id: Iac8c27ea1678044c867a604f7cbc084f9284f9a0

[33mcommit 123d102eb6ed97992026bcd060ede52ac52d88eb[m
Author: Maitrayi Sabaratnam <maitrayi.sabaratnam@oracle.com>
Date:   Thu Mar 16 10:08:12 2017 +0100

    Bug#25726723 - REMOVE UNNECESSARY REPORTING OF EVENT BUFFER STATUS
    
    This patch :
    - Corrects the calculation of free percent of event [1;31mbuffer[m to base on the configured event[1;31mbuffer[m_max_alloc size instead of total_alloc size.
    
    - When ndb_event[1;31mbuffer[m_free_percent is configured but not event[1;31mbuffer[m_max_alloc (defaulting to 0 meaning unlimited), Event Buffer Status message in cluster log with report_reason=LOW/ENOUGH_FREE_EVENTBUFFER will NOT be written out.
    
    - When ndb_report_thresh_binlog_epoch_slip is configured,  Event Buffer Status message in cluster log with report_reason=BUFFERED_EPOCHS_OVER_THRESHOLD will be written out every 10 sec instead of 1, when slip > threshold.

[33mcommit 9c1ea6e2e1c66705bc4f5f7d464ebbccd123d4af[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Tue Mar 7 12:11:43 2017 +0100

    WL #10354: Make Unicode 9.0.0 and newer collations NO PAD (fix blob strnxfrm)
    
    Make sorting keys for blobs correctly heed the demand that strnxfrm output
    [1;31mbuffer[ms must be an even number of bytes. (This gets relevant when more complex
    collations than “binary” go through the variable-length path.)
    
    Change-Id: Iac8c27ea1678044c867a604f7cbc084f9284f9a0

[33mcommit 925d458a650c3e7d8d8e873a5eac54cb702b4147[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Wed Mar 8 15:46:52 2017 +0100

    Bug#25688635 ASAN: GLOBAL-BUFFER-OVERFLOW IN MYSQLD WHEN SPECIFYING EMPTY BASEDIR
    
    Push to fix innodb_undo.undo_space_id so it doesn't specify an empty
    basedir and get a [1;31mbuffer[m overflow when run in ASAN.
    
    Approved by Jon Olav Hauglid <jon.hauglid@oracle.com> over IM.

[33mcommit 201b2b20d110bc35ddf699754571cb0c064a3f72[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Fri Mar 3 12:40:55 2017 +1100

    Squashed commit of the following:
    
    WL#9499 - InnoDB: Replace MLOG_FILE_NAME with MLOG_FILE_OPEN
    
    Fix the performance issues introduced by WL#7142 and its followup WL#7806.
    
    1. Revert WL#7142 and WL#7806 changes, keep some of the tests to test
       the behaviour that was introduced by the two WLs
    2. Change the tests that rely on the above two WLs behaviour
    3. Use std::unordered_map instead of the homebrew hash table for the recovery
       code and space ID to name mapping
    4. Split the redo log hash table key from <space, page> -> apply records to
       <space> -> apply records
    5. Addition of two new system files (tablespaces.open.1 and tablespaces.open.2)
    
       - Rename MLOG_FILE_NAME to MLOG_FILE_OPEN
       - Remove the two pass recovery code, make it a single pass
       - Track file open, close and rename
       - Write and fsync the tracking state to disk on checkpoint and rename.
       Uses the files in #5 in a round robin fashion
    
    Introduce --innodb-scan-directories="path1;...pathN". Scan the paths for
    .ibd files to open during recovery. This option can be used if the files in #5
    above are corrupt or missing. You should not use this if you move files around.
    While they can be recovered the data dictionary will not be updated and it
    will cause issues during runtimg.
    
    rb#13686 Approved by Satya and Shaohua
    
    commit af3dc1301a768c01b971d14ad07549d6ef470fe6
    Merge: ac37b926e6a 4d81939d63a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Mar 3 11:16:10 2017 +1100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit ac37b926e6ad85b6c4e3d7880b905d082f1674be
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 23:12:24 2017 +1100
    
        WL#9499 - Fix test
    
    commit 2b05df7ffa592da9b19cec7ba31c04795a1cdfc0
    Merge: 3c79f3aee51 71b3bbff153
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 20:34:10 2017 +1100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 3c79f3aee51858b1859f4e8711883a85867c417a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 18:16:35 2017 +1100
    
        WL#9499 - Add an mtr tst
    
    commit 2c7496246c0e95e25c62ceb6fe5c1875f693ffac
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Mar 2 17:34:50 2017 +1100
    
        WL#9499 Fix bugs
    
        1. Fix a memory leak, call mem_heap_free() instead of mem_heap_empty()
        2. Use a reference instead of copy by value during dblwr traversing
        3. Use absolute path names for tablespace.open.* files
    
    commit fbf87161f3c93979e5abe424fbe0678fdc32159e
    Merge: 517cf3a7bf0 c2b504664ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:39:32 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 517cf3a7bf0490c3168fed020e3096ec500e0a85
    Merge: 4786f93ad8a 5e974fd0ea4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:24:25 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Additional change is to call recv_recovery_from_checkpoint_finish() on abort.
        Instead of recv_sys_free().
    
    commit 4786f93ad8a25506a2a1f6e9d1207256a34b3665
    Merge: 5dc35e05b5f 275245cce32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:43:27 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 5dc35e05b5f2da95c36e191350e9c7087be72194
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:42:40 2017 +0100
    
        WL#9499 Free recv resources on abort
    
    commit bed693070395923ededba736f1c7102b8eb21e95
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 18:34:50 2017 +0100
    
        WL#9499 - Test cannot be run with Valgrind
    
    commit c5d423228ddf58b17866ff8be289dba4a19205d2
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:30:39 2017 +0100
    
        WL#9499 - Remove const
    
    commit ac42498506b4dffb22e74282d0ce037fe3acf977
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:00:30 2017 +0100
    
        WL#9499 - Clean up code
    
    commit bc48077cab9c3ccb1b2797c365fe0940c269a785
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 16:01:09 2017 +0100
    
        WL#9499 - Revert unrelated change
    
    commit 8b2bb0f6d6254b3cfde168d41356400009db12f4
    Merge: eb9b294ba78 153a79ff35d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:43:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit eb9b294ba786800f9e397cd87f01c4f4976edddb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:29:56 2017 +0100
    
        WL#9499 - Remove debug message
    
    commit abae66ad591854ee67a5013f3209be2f82e4d9bf
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 17:04:10 2017 +0100
    
        WL#9499 - Test only works in debug mode.
    
    commit 71ebea70391ef295bed49ee06a8b872f15ecfe97
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:18:08 2017 +0100
    
        WL#9499 - Update to mtr test from Matthias
    
    commit f108a5b92fc476c70c49e4937496b32d9d5d031f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:13:04 2017 +0100
    
        WL#9499 - Increment redo log version number
    
    commit 4439c83a4d3edd6e511706ccf9936770ed29e593
    Merge: fa459186b90 05923bef41d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 09:54:18 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit fa459186b90d7a5ddcba7e3c6c7a9871d0dce793
    Merge: 14ac4f81d84 b401f17e70d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 20:02:40 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 14ac4f81d84bec23a7be210504ca0be93619bf11
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 16:44:57 2017 +0100
    
        WL#9499 - Update from Matthias
    
    commit ed3191a9fc951151fd7d758a527e7ab81530b3f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:16:11 2017 +0100
    
        WL#9499 - Revert change pushed by nmistake
    
    commit 8c0edb998867bf557f6c86410552d6d123892000
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:11:21 2017 +0100
    
        WL#9499 - Don't redo log MLOG_FILE_OPEN until startup is complete
    
    commit 3b503ea1d3f89c0f7e3677d3b56f249c7ebff506
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:37:04 2017 +0100
    
        WL#9499 - Add tests
    
    commit 47af7bd6eec10eac55633d7c4cf54afe607f3649
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:00:30 2017 +0100
    
        WL#9499 - Fix compile problem
    
    commit a8b9a8c6ccb15e2be5ce5db5fa0bce24b86d2c87
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:51:05 2017 +0100
    
        WL#9499 Remove dead code
    
    commit b1dba474486ad10b61029b2ef4e6a91ea67dcea8
    Merge: 3cf9e9eb3e8 a4271026201
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:49:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 3cf9e9eb3e86e4c8f4d44cb79d3f7c456ea7d671
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 18 07:53:43 2017 +0530
    
        WL#9499 - Remove suggestion to use force recovery
    
        --innodb-scan-directories is a safer option for the user. Force recovery should
        be the absolute last resort.
    
    commit 4104c4bfd606270650aac95a9a724e106fe835c5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 09:00:47 2017 +0530
    
        WL#9499 - Fix error message
    
        User can try --innodb-scan-directories="..." if the tablespaces.open.* files
        are corrupt or unreadable.
    
    commit 19ab12e54923b070a0b4ffc76b9fe97ac54ad3cc
    Merge: 50b3a95e446 f0f51c410bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 05:22:57 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Replace readdir_r() with readdir(), compiler complains that readdir_r() is
        deprecated and recommends replacing it with readdir().
    
    commit 50b3a95e446b91853fc35716b63bdc173221d01f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:55:33 2017 +0530
    
        WL#9499 - Fix test
    
    commit 45d202ae0fa35aa3aced55cc1933aeefa33837de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:32:56 2017 +0530
    
        WL#9499 - Remove redundant test
    
    commit 48fe691b97735e5144e9d439a0adbf721b2dc554
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:18:11 2017 +0530
    
        WL#9499 - Add DEBUG sync points
    
    commit d986f4e04a9eb6c2c76d61cd4afe9541d77b34bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:03:50 2017 +0530
    
        WL#9499 - Remove PB2 control file
    
    commit 5af7dca9c305bd366ad2b5c3de26a870e913af4a
    Merge: 74022f50a5f 23a0e71aa3d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 15 09:05:05 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 74022f50a5ff7cb2801c0712601f8a467b409a28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 14 10:31:00 2017 +0530
    
        WL#9499 - Fix test
    
    commit f6188175ee62040ac6a844a5c54787839dff6155
    Merge: 24c867aab14 19ca7c6a5d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 13 12:37:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 24c867aab14556188503aac495f60d89ba3d26ec
    Merge: cb64b8c7f9f a4de6ab549e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 4 06:41:23 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cb64b8c7f9fa9ca05033a9d6f6193cf141746310
    Merge: 17c6c41da0a 88dbc4f4511
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:48:12 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 17c6c41da0afe3fc78843b75fa02578dab29a0ca
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:46:34 2017 +0530
    
        WL#9499 - Add a test for scan directories.
    
        The use case is where the location of the files is not changed but the
        tablespaces.open.* files are missing.
    
    commit 79cc52f1bd82dc65932eacbc9aa14a47e4196572
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 18:01:50 2017 +0530
    
        WL#9499 - If open fails space will be null.
    
    commit 22ea5f31ecc1fa0db8abd57d4a46578e5f891c9a
    Merge: f5b69930f95 853a52cf5a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 12:14:41 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f5b69930f95192ddfdb3ca170024a5c7e3416076
    Merge: 40a4c32f2c4 b18872ed4a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 2 13:54:24 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 40a4c32f2c42b584539a14cbc1ba0d4f0fe7d3c9
    Merge: b1d1923d37c d071c0e7a0b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 1 13:48:33 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit b1d1923d37c3d23a9f701a61b458b7e4cbd3c90c
    Merge: 2fc6c51edab 4ae71705a01
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 31 10:44:59 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2fc6c51edabc3de4537eceb0b82cd62063ada3a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 16:36:46 2017 +0530
    
        WL#9499 - Empty the tablespace.open.* files on normal shutdown.
    
    commit 738acb7d554f97455c8dba512282c7c2e6ba9f3a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:47:21 2017 +0530
    
        WL#9499 - Fix formatting
    
    commit 28f8579a6f729af354e0c50098d16fbfa17cc253
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:25:30 2017 +0530
    
        WL#9499 - Bug fix
    
        The DELETED state was set on a copy of the data structure
    
    commit dd5bf8ea81b7023fa1980c01d89219a690160b04
    Merge: 7eeab0a994d 9c7808e1054
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 21:14:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7eeab0a994db4cf0c2e080f27ff916c778ec65f8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:50:59 2017 +0530
    
        WL#9499 - Add tests.
    
    commit ddfaf047f43587ee807599b0b80b6d01a3579e8c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:48:06 2017 +0530
    
        WL#9499 - Create tablespace bug fix
    
        If there is a checkpoint after the create tablespace is logged and the
        server crashes after writing the page initialization to the redo log. Then
        we neither have the mapping in the redo log nor in the tablespace.open.*
        files. We must update the tablespace mapping before writing the CREATE
        redo log entry so that the state is written out to disk on checkpoint.
    
    commit 29546d3ebea2991e5b86b33edddb551c924bf1db
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 17:55:28 2017 +0530
    
        WL#9499 - Remove dead code from WL#7142
    
    commit eced7a3e4437ee4bb24a12290f561437ddb15611
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 14:51:09 2017 +0530
    
        WL#9499 - Use the tablespace.open.* files in a round robin fashion.
    
    commit d8eff788eea1ad5e6c7786b9d64963524f2b2c81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:56:12 2017 +0530
    
        WL#9499 - Fix duplicate entry
    
    commit 1d04e0cf0308c35ee7498e6919eab9a11c699d52
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:55:30 2017 +0530
    
        WL#9499 - Revert last push
    
    commit 8361d3c39366d6435a895d5b64dd23615d26fc28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Jan 26 09:05:52 2017 +0530
    
        WL#9499 - Write to the tablespace.open.* files in a round robin manner.
    
    commit 3eaba629ee5b5c26a5f4e80852fee2d446f3013f
    Merge: 6642c43d735 bdc49070128
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 25 14:03:15 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6642c43d7353063a455972ab2cbc21220c16be43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 08:34:35 2017 +0530
    
        WL#9499 - Rename fil_ibd_load to fil_ibd_open_for_recovery.
    
    commit fdd1897c79b29c9e0a69c1f81d94927da06d9424
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:28:49 2017 +0530
    
        WL#9499 - Enforce const semantics on Windows for Folder::exists().
    
    commit 9394f4653e10cc5d4ab9b7b0a0b9331fd2666f49
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:08:26 2017 +0530
    
        WL#9499 - Include <array>
    
    commit c1903d28800ae0f7af69552aa669622d552346b4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Jan 21 07:49:28 2017 +0530
    
        WL#9499 - Improve scan directory handling
    
        1. Convert relative paths to absolute paths
        2. Filter out duplicates
        3. Check directories at filtering stage
    
    commit dfea237f4bef914de4067153cbf382240112c4f4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 11:11:05 2017 +0530
    
        WL#9499 - Code clean up
    
    commit c4d51bfdf1c786b1c584c0af1bde080a4f37cc5b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 07:37:06 2017 +0530
    
        WL#9499 - Update the open/rename LSN when a file is opened or renamed.
    
        Minor code cleanup.
        Add diagnostic code for debugging.
    
    commit 5e1d159b571fe6dbfe13c627a245155b82c4bbfa
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 18 10:59:54 2017 +0530
    
        WL#9499 - Filter out '*' from innodb-scan-directories
    
    commit 361f2944f1940f11dfb16dec3589d68335f5e2d8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 21:01:06 2017 +0530
    
        WL#9499 - Code cleanup
    
    commit 288d70b356721887423ca3d2d72b42da331216cd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 13:08:08 2017 +0530
    
        WL#9499 - Sync open file map to disk before checkpoint.
    
    commit 3c602d1b4089cd262200650f4b33986fc9e26531
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:18:46 2017 +0530
    
        WL#9499 - Print expected bytes instead of generic message.
    
    commit f52e0985b8cbef3891385179d35dc8c7f567146a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:07:47 2017 +0530
    
        WL#9499 - Print file size instead of generic message.
    
    commit b27b1b4b4b70e286e2c669f997b0a669f6d6034c
    Merge: bbdd1c46f1e c101ec9b557
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 16 13:19:42 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit bbdd1c46f1ef08d956ea249e1f6f4bc93d3464f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Dec 10 14:41:12 2016 +0530
    
        WL#9499 - Handle the case where the rename has already been done on recovery.
    
    commit 141bdb02b1a402e786db5d8b165b781a5d7370a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 11:59:29 2016 +0530
    
        WL#9499 - Instrumentation for debugging
    
    commit 34815bb24a1c296d9739e7602dc6ccd53c58c44c
    Merge: 41ca3732a6f 13a46b4c5ea
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 09:44:03 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 41ca3732a6ffd8dfa16762a05df6b5c6b4b550c1
    Merge: 7137edb2d2c aba34f1205d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 11:10:08 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7137edb2d2ca60cdec44600ddf3f5cbde424e7a4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 05:56:06 2016 +0530
    
        WL#9499 - Remove unused code. Move id to name mapping sync before log flush.
    
    commit 2a50067e2da2f7819781de6550e55ca14995c7ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:57:41 2016 +0530
    
        WL#9499 - Initialize the PFS file handle
    
    commit d478d3492cdb40ec02fda9c043bf29b87bae11ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:05:52 2016 +0530
    
        WL#9499 - Fix whitespace
    
    commit 061af748a5e2fde6c1577ccdabfc8a89a9f753de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:02:25 2016 +0530
    
        WL#9499 - Set must flush on file close/delete.
    
    commit ad76e2b9c7ff757f60c66821e86696d5ab757b18
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 11:43:00 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5a95946d4567dc13cf5a12d6bcdb28b19a02b5bc
    Merge: 1a0f373eb7f da23d6b8e44
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 09:27:45 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1a0f373eb7f03dc22264f91f3f6ed1fd13825de7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 13:01:41 2016 +0530
    
        WL#9499 - Readd test result file back
    
    commit 00afde093183cf850f735940245af111dce82b72
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 12:59:49 2016 +0530
    
        WL#9499 - Don't purge the files based on LWM. It won't work.
    
        We need to also ensure that there aren't any pages in the [1;31mbuffer[m pool that
        belong to a tablespace that is closed. Redo log records can be written for
        such pages.
    
    commit 3199fe255103daa42f0332b7ff9d565eefff7429
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:41:39 2016 +0530
    
        WL#9499 - Fix typo
    
    commit 351cb6c42709405a79021276f310d7b996aadd1b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:32:02 2016 +0530
    
        WL#9499 - Remove unused function
    
    commit 61cc7f6b06c5280d58217b76d7627013ddcd8338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:22:31 2016 +0530
    
        WL#9499 - Reduce the compression level.
    
    commit 48142e360ff5cfb53d5e416f3d6b92e956237923
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:21:51 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 4de4f8b31ebdff31a2f7a97a1ad211770d20cdd6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 14:07:07 2016 +0530
    
        WL#9499 - Revert ef30f0754ab22e614ac22712c348ec5f53e0f09c
    
    commit c2f77f44c43c209fad86bba568aa521a2dcbf718
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 12:20:37 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 5fccb51769a13cb9a1fc0f29a832d3b0085ad52a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:30:18 2016 +0530
    
        WL#9499 - Print a message when checkpoint is disabled.
    
    commit ef30f0754ab22e614ac22712c348ec5f53e0f09c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:17:27 2016 +0530
    
        WL#9499 - Print progress in 10% units.
    
    commit bc0ded332624fa2c8a08ebfc955a03f1a24e069c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 08:13:54 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 68ce0208cc073452f5f791faf304971dbac7194a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:38:03 2016 +0530
    
        WL#9499 - Scan directories after the mutex code is initialized.
    
    commit 21e07c8fd6b8eddf158fb79980443f6c9f6d238e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:12:23 2016 +0530
    
        WL#9499 - Introduce --innodb-checkpoint-disabled (debug)
    
        Disable checkpointing if the variable is set. This is to force recovery if the
        server is killed during a test.
    
    commit 7033c9bb5ff7641764f70823a73d747b497a0eed
    Merge: 11a6e582417 c6af7f512b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 04:00:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 11a6e582417d45a80a7f19233c2d2191a17936eb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 03:59:05 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 0a38252e65d607b59b1e9f64d0c8003cdecfecfd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 25 05:56:42 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bcf650cc92b8636f3768dcc3deb33b90b2942134
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 08:46:07 2016 +0530
    
        WL#9499 - Change the open files number back to 2.
    
    commit 99960af2825529fb45d021a34ba6c072e8caa0dc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 07:13:58 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bdb91bc0ba03e01661c50c7175d3fd123d2bcd69
    Merge: 61f3e4a5663 a545bdd6e31
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:04:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 61f3e4a5663c375cd44ee766b263281ff7f0601b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:00:20 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 072ab837d0acb4d2ed817110598554acc44ec344
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 12:06:53 2016 +0530
    
        WL#9499 - Set the IMPORT page LSN to the flushed to disk LSN
    
    commit 7f18661432f3645eb9ce76680c62508ced115fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 11:28:47 2016 +0530
    
        WL#9499 - Force a checkpoint before the crash
    
    commit 83671e9c37fa61adfa5546cabe1463a91ff02241
    Merge: cc26d5ae16e d1f811eb6e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 10:52:16 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cc26d5ae16e8d723a2519f38bfbc084c13a766c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 18:40:51 2016 +0530
    
        WL#9499 - Fix latch ordering issue
    
        Cannot hold the log sys mutex when updating the checkpoint LSN for the open
        files in fil0fil.cc.
    
    commit 4474509addfbdf91b9f0ad890a971299c594e738
    Merge: 396755e195c 0856b10cde5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 08:00:05 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 396755e195c1c8d3b2485a58175dcf56ca2cbf3f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:58:05 2016 +0530
    
        WL#9499 - Remove newline added earlier
    
    commit ab5e60ba491e52f1529c22551a936d771b8b5ef9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:57:21 2016 +0530
    
        WL#9499 - Revert a change that was added by mistake.
    
    commit 38688417713e5ef8cbb65032fa0a547ab0c25c15
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 20:44:50 2016 +0530
    
        WL#9499 - Bug fix, using an invalidated iterator.
    
    commit 4082d44f6dc4a5605562e37ccad9ac4db69344c6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 11:30:49 2016 +0530
    
        WL#9499 - Fix doxygen comment
    
    commit d5ca99e14c010a5349aea6c8cc39493b2073b9c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 15:30:12 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a25f3af10ea2893c634dc961d6f2af05efa103ec
    Merge: c8c2a7eba4c aa039b73223
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:52:51 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit c8c2a7eba4cac29ff431588daf2d6def0c0ee5a6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:39:32 2016 +0530
    
        WL#9499 - Fix problem with open files acrosss checkpoints.
    
        The problem is that we write the open file state before writing the checkpoint.
        Before this change the closed files were purged from the open state map and
        the state written to disk. The problem is that the state and mapping of a file
        opened before the last checkpoint but closed just before we write the state
        will not be in the mapping on disk. One solution is to check older files and
        retrieve the mapping from there. The solution chosen is to avoid purging
        files based on open LSN. If the file was opened before the last checkpoint
        and closed within the current checkpoint we note the state as CLOSED but
        write the mapping to disk. It will be purged at the next checkpoint, if it is
        not opened again in the meantime.
    
        Previously an attempt was made to open all files straight after reading the
        mapping from disk. With this change only the state is loaded into memory the
        files are opened on demand. Added a check to verify that the tablespace ID
        from the first page matches the expected value.
    
        Fixed tests to use this new tablespace ID verification.
    
    commit 5dc929e54b1c259f0f8104739ae1f88e9b860f73
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 12:24:40 2016 +0530
    
        WL#9499 - Remove unused code
    
    commit 528b95d70dcc05a69a98ee2a76fdfb8dae1e82fe
    Merge: d9861c40964 75f05cba753
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:14:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d9861c40964ad8fd45ee2cbbd9d94946110e8a9a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 3007ea5af68f40b85bc93098d8385ac96bcbd660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 9592996d2f17c9005262faa75dc1ade9dedbd511
    Merge: da512d5591b ac925fc91f6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Oct 19 10:34:48 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit da512d5591b3379b793d6155089e90791fe94c61
    Merge: f42e2ddd7d5 e635dfe28c0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 30 05:20:10 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f42e2ddd7d50aacae679babe71643af379b5c492
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 15:05:28 2016 +0530
    
        WL#9499 - Fix assertion, the values can be ORred.
    
    commit 94cd08960bc3801acefd4b4ff4ddb4a3e7d7e81a
    Merge: 32a68f91330 59af373321b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 11:05:21 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 32a68f9133011871bfdaba3c742f6239e0a53061
    Merge: 7857f38ebce 15555ae2165
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 21 11:23:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7857f38ebce747135e055bc8a232b649f1aad351
    Merge: 427491f63f1 b43bf88cf80
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 19 11:43:17 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 427491f63f107247c36796e66f6224d20968f104
    Merge: e7fa4c53dcf 23343687722
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 14 22:40:47 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e7fa4c53dcf01ea0e101bd8aa817698492995034
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 19:22:00 2016 +0530
    
        WL#9499 - max_lsn should work with any number of tablespace open files.
    
    commit 09775960da43d36ca64504c1298b9adff3056575
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 17:47:29 2016 +0530
    
        WL#9499 - Fix Names hash bug.
    
    commit 8430c5b34d23cb1774597707fe583dfac93fb3a8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 09:49:47 2016 +0530
    
        WL#9499 - Use std::unordered_map for name to fil_space_t* hash.
    
    commit 5e8275caf9d50dc9ba2f2dadd3b8c0fdeb9c79b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Sep 10 07:55:42 2016 +0530
    
        WL#9499 - Reduce an extra fil_sys_t::mutex call by consolidating flush request.
    
    commit b29fd1039cf0022cff36a2a2311f464f1f6dbcc5
    Merge: 6235ee4902a a150caebee6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 9 20:44:56 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6235ee4902addd1a041b33469988bb1ea870dc7a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 10:58:00 2016 +0530
    
        WL#9499 - Add debug crash points.
    
    commit bf71fbc72b3570f55c8f01dd1a440e9eff761cb6
    Merge: ce6d2246a94 d25f38e38d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 09:47:37 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit ce6d2246a94801041da0bfece74b5ffdd9e8f796
    Merge: 69adae163de f28c4b9a41e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 7 11:20:50 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 69adae163de295ef0e910752cf5f8c96b1c1114f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:33:29 2016 +0530
    
        WL#9499 - Ensure that the MLOG_FILE_OPEN is always written first to the redo
    
    commit 20d5b1ebe6c899e2a0a1d135ad4303490516ce26
    Merge: 2d7d25c145f 4f1fb936211
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:17:58 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2d7d25c145fae59af744e91fce47fe009c869dad
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 10:06:56 2016 +0530
    
        WL#9499 - Add PFS instrumentation for the tablespace open file.
    
    commit 4e14a53ad129c1adcb0a3330931878a9f24c15cc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:53:57 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a465361e74136662471d2b9c0f307799efbe7269
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:17:43 2016 +0530
    
        WL#9499 - Move the file write code to a separate method.
    
    commit 7a26ba28bf7bf94808c47cfcdb6210c4abde2587
    Merge: f49914e5e61 ed389829067
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 07:55:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f49914e5e61b846c45f7b177308cd891918619e4
    Merge: a4fab040243 16fd507b84a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 31 11:23:42 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit a4fab040243a57fb8ef55f91812604352d8b92c8
    Merge: 93019973329 dfee02dc4f5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 10:42:20 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 9301997332923921b93de4946c4824164723050c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 09:09:05 2016 +0530
    
        WL#9499 - OSX/Solaris compilers don't like the code.
    
    commit 54afa110837a054de24ccda84ddbb4ef2d0b96a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 22:55:19 2016 +0530
    
        WL#9499 - During recovery PFS instrumentation can't be accessed by the user.
    
    commit fa5c11e8cf0fbcd1852535faa74b1a04200df2e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:15:07 2016 +0530
    
        WL#9499 - Fil_Open::purge() can be called during recovery too
    
    commit d8672a978d62db42f1a12ba152693a3c0d244d83
    Merge: d4251d0ed6f 14d2a977ce8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:10:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d4251d0ed6f9df5a3acbf97ce7ba8074f126044c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:07:14 2016 +0530
    
        WL#9499 - Remove a WL#7806 test.
    
        The test doesn't really help. It uses very simplistic checks for matching
        path names. It ignores links (soft and hard) completely. Besides during
        recovery the path names will work with the original path names.
    
    commit fba6656350d0a757b2cc936b017329e7f7ce2d32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:51:53 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b522d665d10dca905420cb9119692dffac5024c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:20:30 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 3a9aca50a2e193398d626b5f75d238b5aa704e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:19:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5923cd73fc3af904220dea20b033ffcbb7892606
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:12:44 2016 +0530
    
        WL#9499 - Use custom allocators.
    
    commit 8c5acab2641cedae9542b9ad9405032abbcb4618
    Merge: 1509c43fcff 3c1319b9901
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:21:28 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1509c43fcffb9a849542ef8f3a62e66fda490fc7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:08:34 2016 +0530
    
        WL#9499 - Fix bug, should be decrement in_use, not increment.
    
    commit 0ad783d5e6e3f99817c8b839fe8521f783577d35
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 07:58:49 2016 +0530
    
        WL#9499 - Change fil_node_t::in_use into a reference counter from bool.
    
    commit 3974f1ed40bfbadcee04fa5fc2e60a50b89f930c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 22:10:24 2016 +0530
    
        WL#9499 - Remove an assertion that is no longer an invariant.
    
    commit d79f12dec7c07698f02ce2e0d0396bcd01bdc683
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 21:52:21 2016 +0530
    
        WL#9499 - Rename fil_node_t::being_extended to in_use. Fix test.
    
    commit 1d3368bcf60e2e339d5917251b51201b94dd63a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:57:38 2016 +0530
    
        WL#9499 - Fix log info messages during recovery/apply.
    
    commit d3811bd67248d3ae014f0e6475b1b49524f5c35b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:40:01 2016 +0530
    
        WL#9499 - Don't print % processed if number of records to apply is small.
    
    commit 55af670ff81170da51fbcae6832c3d6191176602
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:21:31 2016 +0530
    
        WL#9499 - Update test with new log message to check.
    
    commit 60c3d6c074ae230ab594015ed2f99e2eefcf97e0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:09:04 2016 +0530
    
        WL#9499 - Record test, because of new config parameter innodb_scan_directories.
    
    commit bd79ff06406c86758a29a28dbe5e7d494a0aa51f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:05:38 2016 +0530
    
        WL#9499 - Remove WL#7142 artefact.
    
    commit bcb753b72b2a01ba35d952cbab45e420929f2b33
    Merge: e30834ecc60 27d64e974ec
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:26:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e30834ecc60522fca8d7b156a66c0765867dea6e
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Thu Aug 25 05:54:26 2016 +0200
    
        WL#9499 - Destroy the mutex in the Fil_Open destructor.
    
    commit a396d4714bdc46626e07d22b6871be153b627bd3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:17:06 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 282ad76aaeaeb6d91bbf81fcd3315f455d9f572c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:12:33 2016 +0530
    
        WL#9499 - Protect changes to Fil_Open state with a mutex.
    
    commit d338cb9468c126ee7e3eeae3bf37b0fc966bbf53
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 07:37:49 2016 +0530
    
        WL#9499 - Fix division by zero.
    
    commit 845324f19ba0a84538b87c072f6d99514533aa25
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:28:45 2016 +0530
    
        WL#9499 - Check for UNDO tablespace names during directory scan.
    
    commit 30ed1d19389e174605fdfc0b7d55fdf544933712
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:26:08 2016 +0530
    
        WL#9499 - Conform to new naming guidelines.
    
    commit 4cf67b352d4c8131064f832ec884db6166d50e71
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 22:04:43 2016 +0530
    
        WL#9499 - Add test for the configuration variable. Add a version number to the file.
    
    commit ad9c5bca0eba1d7bf8e29cd8ebd7062aae089f90
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 21:01:56 2016 +0530
    
        WL#9499 - Code clean up
    
    commit a9e848158909645ead86759ed7ab64789d18a0cb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 15:26:02 2016 +0530
    
        WL#9499 - Print redo apply progress per tablespace
    
    commit 8cf86cf1567cabc1b03b2e8f2ec1167f3c38ce6c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 13:04:55 2016 +0530
    
        WL#9499 - Print tablespace name and % completed per tablespace
    
    commit 35ccdf32d1d048400012a80422072fb41ceb1bbd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 10:35:26 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit c978fb2e18a4e0b4a93b44fc3c75234bcdb3f1f0
    Merge: 8bde4aeb01c 0832bf660e3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 22:25:57 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 8bde4aeb01c3bcdecfb884e566f0ae28797a5b36
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 13:21:10 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 7f502be746cbe0de1a0c3a992217691b167c2fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 12:12:08 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 247bcfda6744a67cc4e53d61658ca87d206b0660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:57:44 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 04509641b086a1b0b2c591573f95957f8a2f1cd0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:50:55 2016 +0530
    
        WL#9499 - Pass the filename directly to the callback
    
    commit 3efa317825886a3ae5d4a3c771fc0770a2c5a3ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 09:39:18 2016 +0530
    
        WL#9499 - Include tchar.h on Windows
    
    commit 55b814d2c2ebdea7c16a6d87a7251ca3f6e83775
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 07:47:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit e4d203688273b562691c912cb9c7024709757490
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 22:02:02 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 31433b21dcabba0a7705eb8b1879beb1d8c36517
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 21:37:41 2016 +0530
    
        WL#9499 - Move Dir_Walker::walk implementation to os0file.cc
    
    commit 11f9016477274c5420782e365b26762067e7b99b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 18:42:28 2016 +0530
    
        WL#9499 - Fix Windows version of Dir_Walk.
    
    commit f32b88e0b1ef99f220165897db745b1dba12f86b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 13:48:03 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b91ad88d96942f1e05443001b7d1c2f6818ff6d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 14:32:25 2016 +0530
    
        WL#9499 - Initialize active ID to filename set from scanned set.
    
    commit 4a09f677ae7095aac9b07f7beccba8e60c50b065
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 13:09:05 2016 +0530
    
        WL#9499 Scan specified directories to build the ID to name mapping.
    
    commit c13b791497e322e6a5cf64ba85da52ee2cf05d45
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:46:53 2016 +0530
    
        WL#9499 - Fix check for incomplete read.
    
    commit 8a849e0288309cec7228612a62fc2bfd71b595e9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:45:04 2016 +0530
    
        WL#9499 - Fix Windows build errors
    
    commit 4fc24b654da26e8411fc45bc96f73ff70dc73e43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:12:12 2016 +0530
    
        WL#9499 - Need to include string for Windows std::wstring.
    
    commit bcb5c2b23f54776e0faaafba2472bb2555aee561
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:02:59 2016 +0530
    
        WL#9499 - On POSIX fopen() mode should be "w+b".
    
    commit b3c7def1931867633d9b8bb601317e99a06c31a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 21:23:57 2016 +0530
    
        WL#9499 - Open file in binary mode for writing.
    
        Otherwise on Windows newline (0x0A) is translated to CRLF (0x0D0A).
    
    commit 0739399cb8a384c07b4b3540b73ade482d083f4a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 20:27:11 2016 +0530
    
        WL#9499 - More error messages during mapping file read. Add a directory walker.
    
    commit 1322de0af2235bc94630f7cb22e4ead1588775ee
    Merge: f266b100e2f 8fdbb2f5f1a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:47:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f266b100e2f23e775e5e04de8d26301d7f2f1072
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:18:07 2016 +0530
    
        WL#9499 - Flush the tablespace to mapping file [1;31mbuffer[ms before fsync()
    
    commit 7c92536686033c2c70e7df831d569c1cd6f871f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:32:26 2016 +0530
    
        WL#9499 - Remove unused member variable m_lsn.
    
    commit 994c4766ef712e7da668788d0bdd648cbd764982
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:25:05 2016 +0530
    
        WL#9499 - Don't crash on uncompress failure. Try the next file if any.
    
    commit a419a190cdf734e3beca08d339c6c0d307ddff5f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:21:49 2016 +0530
    
        WL#9499 - Print an error code on uncopress failure
    
    commit 77cb39000e098ba4d06873723423521e6889a7d0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:12:11 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit afc632e0ef768542a96d4d15a897cb1780825d2e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 11:34:44 2016 +0530
    
        WL#9499 - Compress the tablespace open state file.
    
    commit 568c9e758084f671007789f7b5d1c996f5df39a0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 09:12:39 2016 +0530
    
        WL#9499 - Free the [1;31mbuffer[m on return
    
    commit 0f468cf8e50b9605a9e6c4e93c818b0f876c3c29
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 08:42:38 2016 +0530
    
        WL#9499 - Remove protobuf
    
    commit e789eb175d2da90cee2d46e30b91e623546f9e96
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 18 09:59:37 2016 +0530
    
        WL#9499 - Get native HANDLE
    
    commit 6014c5853c09fee75256f9de6a86a5fc0ea18508
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:50:37 2016 +0530
    
        WL#9499 - Use _fileno() on Windows
    
    commit 61e6b4d7c033d48b775b22c4ad6d6b4858cd4cd7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:37:01 2016 +0530
    
        WL#9499 - Use [1;31mbuffer[med IO for open state file writes
    
    commit 98f40b10c15e49d9a5e14689cdb34758bdf85a05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 12:36:06 2016 +0530
    
        WL#9499 - Don't complain about corrupted encrypted pages during dblwr recovery
    
    commit c674939cbdeaa4a9996960de0fa4e74954ad6f76
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 09:21:06 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for generated sources too.
    
    commit ff68ba26aeaa27070ceeaa8db4472a9ce4daa3c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 08:33:03 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for fil/fil0fil.cc
    
    commit 445985ca11810c528567a4222cad4a7f0ce49e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 19:44:29 2016 +0530
    
        WL#9499 - Read/Write open state files using absolute paths
    
    commit b4d91d3799d94eb2677be6512752ec27dfa5e0f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 14:37:40 2016 +0530
    
        WL#9499 - Fix doxygen errors
    
    commit 8be2de3b3077c0d0f26340c9c80f7ae2247eefbc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 11:20:24 2016 +0530
    
        WL#9499 - Record test, MLOG_FILE_NAME doesn't exist anymore
    
    commit 54e64dc4a97f5bf4b5606cea1841dfc1f04fe536
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 10:41:01 2016 +0530
    
        WL#9499 - Add protobuf library to the embedded library.
    
    commit 83b0fb38283e285e1e963dd2c7c144d70b130338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 21:17:13 2016 +0530
    
        WL#9499 - Improved DBLWR and System table checks and code cleanup
    
        1. Remove dead code
        2. If some pages from the dblwr [1;31mbuffer[m were not recovered during recovery
           because of a missing tablespace id -> name mapping. Check the tablespace
           ID against the Tablespaces meta-data after recovery.
        3. Track open of the system tablespace. Check if the name of any file
           has changed. We don't rename the system tablespace.
    
    commit 5ebfba1e083f6a1d2b70946b91a02d32733c7e87
    Merge: 7a1b724c04b 0c27bf6fc44
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Mon Aug 15 11:40:07 2016 +0200
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7a1b724c04bf9d2e4aba0e58fb95dc8fc75d55c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 15:07:47 2016 +0530
    
        WL#9499 - Free deferred page memory
    
    commit 4de5d3b03670e4d2e8ebce89e8b3f104968eb3e1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:45:25 2016 +0530
    
        WL#9499 - Remove unrelated changes
    
    commit c9e83914232480501b139c36ef616798a2ac1d05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:28:19 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 6ecdb21d63ef6dd5a6aff997720178ff6510f0d5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 13 14:31:52 2016 +0530
    
        WL#9499 - Don't exit if no open state files found

[33mcommit dbd2ca2f6e14ce0ec19e743eb2f0cfdb20df6573[m
Author: Joao Gramacho <joao.gramacho@oracle.com>
Date:   Tue Nov 1 06:45:39 2016 +0000

    WL#8599: Reduce contention in IO and SQL threads
    
    (Step 1)
    
    This patch introduces the changes for the worklog related to making the
    slave applier to read from the relay log the same way the Binlog_sender
    does from the binary log (using a non-shared IO_CACHE, not relying on
    relay_log->LOCK_log even when reading from the "hot" relay log file).
    
    Made binlog_end_pos atomic
    --------------------------
    
    The MYSQL_BIN_LOG::binlog_end_pos was refactored to be atomic. From the
    Binlog_sender perspective, this would allow reducing the amount of
    acquirements of binary log LOCK_binlog_end_pos. With this change, both
    binary and relay log files readers don't need to acquire the
    LOCK_binlog_end_pos while checking if they reached the end of the "hot"
    log file. They only need to acquire the LOCK_binlog_end_pos if they are
    actually going to wait for updates.
    
    @ sql/binlog.h:
    
    Renamed binlog_end_pos to atomic_binlog_end_pos and made it atomic.
    
      At MYSQL_BIN_LOG::get_binlog_end_pos(), we removed the assertion of
      the ownership of the LOCK_binlog_end_pos, as it is not necessary since
      the binlog_end_pos variable become atomic.
    
    @ sql/rpl_binlog_sender.cc
    
      Refactored Binlog_sender::wait_new_events() to first check if the
      waiting is really needed (if the binary log was not updated before the
      acquirement of LOCK_binlog_end_pos), and then, only if the
      Binlog_sender really need to wait, to enter the
      stage_master_has_sent_all_binlog_to_slave stage and wait for updates
      on the binary log.
    
    Removed the relay_log->LOCK_log usage from next_event()
    -------------------------------------------------------
    
    The slave applier was refactored to not use the relay_log->LOCK_log when
    reading events from the "hot" relay log file.
    
    It was introduced a new PSI mutex key(MYSQL_RELAY_LOG::LOCK_log_end_pos)
    to instrument the LOCK_binlog_end_pos on relay log files.
    
    @ mysql-test/suite/perfschema/r/relaylog.test
    
      The test case had to be recorded again after the addition of the new
      PSI mutex key.
    
    @ sql/mysqld.(cc|.h)
    
    Introduced the new "MYSQL_RELAY_LOG::LOCK_log_end_pos" PSI mutex key.
    
    In order to make the slave applier to not need to acquire
    relay_log->LOCK_log when reading from the "hot" relay log, the slave
    receiver now opens the relay log with the same flags as the binary log
    files are opened: O_WRONLY. This lead to many changes in the slave code.
    
    The rli->ign_master_log_* that relied on relay_log->LOCK_log are now
    being protected by the relay_log->LOCK_binlog_end_pos. This change was
    needed in order to guarantee that the updated generated by events
    ignored by the receiver thread would be properly handled by the applier
    regardless relay_log->LOCK_log.
    
    @ sql/binlog.h
    
      The MYSQL_BIN_LOG::update_binlog_end_pos() function is now also used
      for the relay log. The function was refactored to remove the relay log
      specific code. It also has now a new parameter to tell the function
      that the LOCK_binlog_end_pos was acquired by the caller.
    
      MYSQL_BIN_LOG::after_append_to_relay_log(),
      MYSQL_BIN_LOG::append_event() and MYSQL_BIN_LOG::append_[1;31mbuffer[m()
      function were renamed to MYSQL_BIN_LOG::after_write_to_relay_log(),
      MYSQL_BIN_LOG::write_event() and MYSQL_BIN_LOG::write_[1;31mbuffer[m()
      respectively.
    
    @ sql/binlog.cc
    
      At MYSQL_BIN_LOG::open(), there is no distinction about binary or
      relay log with respect to the flags used to open the IO_CACHE.
    
      At MYSQL_BIN_LOG::open_binlog(), replaced a check for the relay log
      that were relying on the io_cache_type to actually check if it is a
      relay log or not.
    
      At MYSQL_BIN_LOG::after_write_to_relay_log(), replaced the function
      used to get the actual file position from my_b_append_tell() to
      my_b_tell(). Also, instead of just signaling the update of the log
      file, this function also cleanup the rli->ign_master_log_name_end.
    
      MYSQL_BIN_LOG::write_event() is now asserting that the log_file.type
      is WRITE_CACHE.
    
      MYSQL_BIN_LOG::write_[1;31mbuffer[m() is now asserting that the log_file.type
      is WRITE_CACHE. It is also calling my_b_write() to write the [1;31mbuffer[m
      into the relay log IO_CACHE.
    
      MYSQL_BIN_LOG::wait_for_update_relay_log() was refactored to rely on
      LOCK_binlog_end_pos instead of LOCK_log and was moved to
      sql/rpl_slave.cc as wait_new_relaylog_events().
    
      At MYSQL_BIN_LOG::close, replaced a check for the relay log that were
      relying on the io_cache_type to actually check if it is a relay log or
      not.
    
    @ sql/log_event.cc
    
      Log_event::write_header() now calculates the event
      common_header->log_pos by using my_b_tell() as there is no IO_CACHE
      with SEQ_READ_APPEND type anymore.
    
    @ sql/rpl_rli.h
    
      It was removed the IO_CACHE *cur_log as it is not needed anymore.
    
      It was also removed the cur_log_old_open_count variable.
    
    @ sql/rpl_rli.cc
    
      Relay_log_info::Relay_log_info() now initialize the relay_log using
      the WRITE_CACHE cache type. It was added the initialization of the
      key_RELAYLOG_LOCK_log_end_pos that now is used by the relay log.
    
      It was removed any reference to relay_log->LOCK_log at
      Relay_log_info::init_relay_log_pos() function.
    
    @ sql/rpl_slave.cc
    
      The write_ignored_events_info_to_relay_log() function now relies on
      LOCK_binlog_end_pos instead of LOCK_log.
    
      At queue_event(), there is a rli->relay_log.lock_binlog_end_pos() call
      every time the rli->ign_master_log_* variables are going to be
      handled.
    
      It was created the relay_log_space_verification() static function with
      all the code related to relay log space verification that was inside
      the next_event() function.
    
      The major changes in this step were done at the next_event() static
      function. It doesn't use the relay_log->LOCK_log anymore, and rely on
      relay_log->LOCK_binlog_end_pos when reaching the "hot" relay log file
      boundaries. The function now only reads and event from the relay log
      file if the log is not "hot" or if current reading position is less
      than the binlog_end_pos.
    
      Introduced the wait_new_relaylog_events() function.
    
    @ mysql-test/suite/rpl/t/rpl_relay_log_locking(.test|.result)
    
      It was created a test case that relies on debug instrumentation to
      block the receiver thread while queuing an event and ensure that the
      applier thread is capable of reading from the relay log up to the last
      queued event.
    
    Other references
    ----------------
    
    This patch also fixed:
    
    BUG#25321231: TUNING THE LOG_LOCK CONTENTION FOR IO_THREAD AND
                  SQL_THREAD IN RPL_SLAVE.CC
    
    (Step 2)
    
    This patch made channels retrieved_gtid_sets to use their own
    sid_map/sid_lock and created a class to avoid locking when checking the
    current server GTID_MODE to be used Master_info and Binlog_sender.
    
    Gtid_mode_copy class
    --------------------
    
    Any operation needing to check the current server GTID_MODE would
    acquire the global_sid_lock in order to read the GTID_MODE. This is a
    very fast operation (just to access a server global variable), but while
    done by many concurrent threads it might generate impact, mostly on
    commit operations that acquire the global_sid_lock exclusively.
    
    Also, when the server is committing a group of transactions, as the
    global_sid_lock is acquired for writing, any operation trying to check
    the server GTID_MODE will have to be held.
    
    GTID_MODE is a global variable that should not be changed often, but
    the access to it is protected by any of the four locks described at
    enum_gtid_mode_lock.
    
    Every time a channel receiver thread connects to a master, every time
    a Gtid_log_event or an Anonymous_gtid_log_event is queued by a receiver
    thread, or is going to be sent by the Binlog_sender to a receiver, there
    must be checked if the current GTID_MODE is compatible with the
    operation.
    
    There are some places where the verification is performed while
    already holding one of the above mentioned locks, but there are other
    places that rely on no specific lock and, in this case, will rely on the
    global_sid_lock, blocking any other GTID operation relying on the
    global_sid_map for writing (like a group of transactions being
    committed).
    
    In order to avoid acquiring lock to check a variable that is not
    changed often, we introduced a global (atomic) counter of how many times
    the GTID_MODE was changed since the server startup.
    
    The Gtid_mode_copy class was implemented to hold a copy of the last
    GTID_MODE to be returned without the need of acquiring locks if the
    local GTID mode counter has the same value as the global atomic counter.
    
    @ sql/mysqld.cc
    
      Introduced the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/rpl_gtid_misc.cc
    
      Declared the global atomic _gtid_mode_counter.
    
    @ sql/rpl_gtid.h
    
      Declared the external atomic _gtid_mode_counter.
    
      Defined DEFAULT_GTID_MODE as GTID_MODE_OFF.
    
      Introduced the Gtid_mode_copy class.
    
    @ sql/rpl_binlog_sender.h
    
      Inherited from Gtid_mode_copy to the Binlog_sender class.
    
    @ sql/rpl_binlog_sender.cc
    
      Replaced the calls to get_gtid_mode() by get_gtid_mode_from_copy().
    
    @ sql/rpl_slave.cc
    
      At recover_relay_log(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At init_recovery(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At start_slave_threads(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
      At get_master_version_and_clock(), replaced the call to
      get_gtid_mode() by get_gtid_mode_from_copy().
    
      At queue_event(), replaced the call to get_gtid_mode() by
      get_gtid_mode_from_copy().
    
    @ sql/sys_vars.cc
    
      Incremented the _gtid_mode_counter when GTID_MODE is changed. Also,
      made the GTID_MODE global variable to have DEFAULT_GTID_MODE as its
      default value.
    
    Retrieve_gtid_sets with their own SID maps/SID locks
    ----------------------------------------------------
    
    Any GTID set operation relying on a given SID map (and its respective
    lock) will be blocked by any other operation (in any other GTID set)
    holding the SID lock for writing.
    
    All server GTID state sets (lost_gtids, executed_gtids,
    gtids_only_in_table, previous_gtids_logged and owned_gtids) rely on the
    global SID map (and on the global SID lock). So, when GTIDs are
    committed in the server, the updates on the GTID state lock the SID map
    for writing to prevent other threads to perform updates on the GTID
    state (or read from it while it is being updated). The side effect of
    this way of avoiding other threads to read from or update a GTID set is
    blocking any other GTID activity in other GTID sets relying on the same
    SID map/SID lock. So, before this patch, the replication receiver
    threads had their Retrieved_Gtid_Set relying on the global SID map/lock.
    In this way, when a group commit was updating the GTIDs of the committed
    transactions, any replication receiver trying to queue a Gtid_log_event
    or finishing queuing a Gtid transaction had to wait for the group commit
    to unlock the global SID lock. Also, a group commit trying to lock the
    global SID lock for writing was waiting to all receiver threads queuing
    GTIDs to finish before having being granted with the lock ownership.
    
    The global SID lock on the cases described above is taken for doing
    small operations, and there is no significant impact on server
    performance in a slave server replicating using a single replication
    channel with medium to large transactions and without using MTS. But
    when the slave is scaled to have many replication channels and/or
    replicating many small transactions and using MTS, the impact of the
    concurrency in the global SID lock becomes noticeable.
    
    This patch is making all receiver threads to rely on their own
    (individual) SID maps and locks.
    
    @ sql/binlog.cc
    
      The MYSQL_BIN_LOG::init_gtid_sets() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      The MYSQL_BIN_LOG::open_binlog() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      The MYSQL_BIN_LOG::reset_logs() function was refactored to use the
      global_sid_lock when dealing with binary log and to use the relay log
      sid_lock when dealing with relay log.
    
      MYSQL_BIN_LOG::after_write_to_relay_log() now uses only the relay log
      sid_lock.
    
    @ sql/log_event.cc
    
      Previous_log_event should assert that the SID map of the GTID set
      passed as parameter is locked (is it not the global_sid_lock for relay
      log events).
    
    @ sql/mysqld.h
    
      Declared the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/mysqld.cc
    
      At gtid_server_init(), initialized the global _gtid_mode_counter.
    
      Introduced the new PSI_rwlock_key key_rwlock_receiver_sid_lock.
    
    @ sql/rpl_channel_service_interface.cc
    
      The channel_get_last_delivered_gno() function now uses the relay log
      sid_lock.
    
      The channel_wait_until_apply_queue_applied() was refactored to avoid
      blocking both the relay log sid_lock and the global_sid_lock while
      waiting for the condition.
    
    @ sql/rpl_gtid.h
    
      Enabled the declaration of Sid_map::clear() regardless of compiler
      directives.
    
      Declared a new static function Sid_map::get_new_sid_map() to
      retrieve a new empty SID map with its own SID lock.
    
      Declared the Gtid_set::clear_set_and_sid_map() function that takes
      care of cleaning the SID map after cleaning the GTID set.
    
    @ sql/rpl_gtid_set.cc
    
      Introduced the Gtid_set::clear_set_and_sid_map() function that takes
      care of cleaning the SID map after cleaning the GTID set.
    
    @ sql/rpl_gtid_sid_map.cc
    
      Removed the compiler directives preventing the compilation of
      Sid_map::clear().
    
    @ sql/rpl_rli.h
    
      Made the (retrieved) gtid_set a pointer.
    
      Added function to get the GTID set SID map (get_sid_map()) and SID
      lock (get_sid_lock()).
    
      Changed add_logged_gtid() function to use the relay log SID map and
      lock.
    
      Declared a new wait_for_gtid_set() function receiving a char*
      parameter instead of a String*.
    
    @ sql/rpl_rli.cc
    
      Refactored the gtid_set initialization on Relay_log_info constructor
      and cleaned up the GTID set, SID map and lock on destructor.
    
      Introduced the new wait_for_gtid_set() function receiving a char*
      parameter instead of a String* and refactored the wait_for_gtid_set()
      that receives a String* to call the new introduced one.
    
      Added some assertions at Relay_log_info::wait_for_gtid_set() to ensure
      that the GTID set to wait is relying on global_sid_map or has no SID
      map.
    
      Relay_log_info::purge_relay_logs() now uses the relay log SID lock and
      also clears the relay log SID map when cleaning the retrieved GTID
      set.
    
      Relay_log_info::rli_init_info now uses the relay log SID lock.
    
      Relay_log_info::add_gtid_set() now uses the relay log SID lock.
    
    @ sql/rpl_slave.cc
    
      The recover_relay_log() function now uses the relay log SID lock and
      also clears the relay log SID map when cleaning the retrieved GTID
      set.
    
      The show_slave_status() functions were refactored to use the relay log
      SID lock when dealing with the retrieved GTID sets.
    
      The request_dump() function now uses the relay log SID lock when
      dealing with the retrieved GTID set.
    
      The queue_event() function now uses the relay log SID lock when
      dealing with GTIDs of received Gtid_log_events.
    
    @ storage/perfschema/table_replication_connection_status.cc
    
      The table_replication_connection_status::make_row() function was
      refactored to use the relay log SID lock when dealing with the
      retrieved GTID sets.
    
    (Step 3)
    
    This patch moved the call to flush_master_info() that was done by the
    I/O thread after a successful call to queue_event() to inside the
    queue_event() function, in order to take a ride in the already locked
    mi->data_lock and relay_log->LOCK_log.
    
    This will avoid acquiring the above mentioned locks twice for every
    successful event queued.
    
    It also added a new parameter to flush_master_info() to opt the flush of
    the relay log. Previous approach was leading to flush the relay log
    twice per event.
    
    @ sql/rpl_channel_service_interface.cc
    
      Specified the new queue_event() parameter to not flush master info
      after queuing the event.
    
    @ sql/rpl_slave.h
    
      Changes flush_master_info() declaration by adding a new parameter
      telling the function if it needs to acquire the required locks or if
      the locks are already acquired and a new parameter telling the
      function if it needs to flush the relay log.
    
      Declared QUEUE_EVENT_RESULT enum with the possible results of the
      queue_event() function.
    
      Changes queue_event() declaration to return QUEUE_EVENT_RESULT and
      also to support a new parameter telling the function to also flush
      master info on after an event be successfully queued.
    
    @ sql/rpl_slave.cc
    
      The flush_master_info() function was changed to not acquire the
      relay_log->LOCK_log always, but rely on the need_lock parameter to do
      so. It was also changed to only flush the relay log based on the new
      flush_relay_log parameter. This will prevent flushing the relay log
      twice when queuing events.
    
      On handle_slave_io(), refactored the calls to queue_event() and
      flush_master_info() to use the new implemented parameters.
    
      Refactored queue_event() function to return QUEUE_EVENT_RESULT, and to
      flush master info without the need of flushing the relay log in the
      case of a successful event be queued.
    
    Added test cases to improve code coverage:
    
    - rpl_write_ignored_events: ensure the ignored events not yet consumed
      by the slave are taken into account by the SQL thread if the I/O
      thread is stopped before the SQL thread consumed the ignored events
      info.
    
    - rpl_write_ignored_events_fail_writing_rotate: ensure I/O behavior
      when failures happen while writing the ignored events info to the
      relay log.
    
    Also commented an unreachable code to make gcov happy.
    
    Added test cases to verify that receiver threads GTID sets do not rely on
    global SID anymore.
    
    rpl_multi_source_block_receiver: checks that receiver thread receiving GTIDs
    (and adding them to its retrieved GTID set) can apply GTIDs from a server UUID
    that doesn't belong to the global SID map yet.
    
    rpl_line_topology_receiver_block: checks that receiver thread on slave
    receiving GTIDs (and adding them to its retrieved GTID set) can have other
    servers replicating from it.

[33mcommit 6ea7d1b70f289bd82172098388494ae57d4669a9[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Thu Mar 2 02:15:26 2017 +1100

    WL#9499 - Follow up fix
    
    1. Call mem_heap_free() instead of mem_heap_empty()
    2. Delete the pages from the dblwr [1;31mbuffer[m that were deferred but not used
    3. Fix a bug in fil_check_missing_tablespaces(), don't do a copy but use
       a reference.

[33mcommit 0bbe8f73f9ea9cb2966dc7f1fbc0a15281eeb4b9[m
Author: Sunny Bains <Sunny.Bains@oracle.com>
Date:   Tue Feb 28 10:48:45 2017 +0100

    Squashed commit of the following:
    
    WL#9499 - InnoDB: Replace MLOG_FILE_NAME with MLOG_FILE_OPEN
    
    Fix the performance issues introduced by WL#7142 and its followup WL#7806.
    
    1. Revert WL#7142 and WL#7806 changes, keep some of the tests to test
       the behaviour that was introduced by the two WLs
    2. Change the tests that rely on the above two WLs behaviour
    3. Use std::unordered_map instead of the homebrew hash table for the recovery
       code and space ID to name mapping
    4. Split the redo log hash table key from <space, page> -> apply records to
       <space> -> apply records
    5. Addition of two new system files (tablespaces.open.1 and tablespaces.open.2)
    
     - Rename MLOG_FILE_NAME to MLOG_FILE_OPEN
     - Remove the two pass recovery code, make it a single pass
     - Track file open, close and rename
     - Write and fsync the tracking state to disk on checkpoint and rename.
       Uses the files in #5 in a round robin fashion
    
    Introduce --innodb-scan-directories="path1;...pathN". Scan the paths for
    .ibd files to open during recovery. This option can be used if the files in #5
    above are corrupt or missing. You should not use this if you move files around.
    While they can be recovered the data dictionary will not be updated and it
    will cause issues during runtimg.
    
    rb#13686 Approved by Satya and Shaohua
    
    commit fbf87161f3c93979e5abe424fbe0678fdc32159e
    Merge: 517cf3a7bf0 c2b504664ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:39:32 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 517cf3a7bf0490c3168fed020e3096ec500e0a85
    Merge: 4786f93ad8a 5e974fd0ea4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 28 10:24:25 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Additional change is to call recv_recovery_from_checkpoint_finish() on abort.
        Instead of recv_sys_free().
    
    commit 4786f93ad8a25506a2a1f6e9d1207256a34b3665
    Merge: 5dc35e05b5f 275245cce32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:43:27 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 5dc35e05b5f2da95c36e191350e9c7087be72194
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 24 10:42:40 2017 +0100
    
        WL#9499 Free recv resources on abort
    
    commit bed693070395923ededba736f1c7102b8eb21e95
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 18:34:50 2017 +0100
    
        WL#9499 - Test cannot be run with Valgrind
    
    commit c5d423228ddf58b17866ff8be289dba4a19205d2
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:30:39 2017 +0100
    
        WL#9499 - Remove const
    
    commit ac42498506b4dffb22e74282d0ce037fe3acf977
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 17:00:30 2017 +0100
    
        WL#9499 - Clean up code
    
    commit bc48077cab9c3ccb1b2797c365fe0940c269a785
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 16:01:09 2017 +0100
    
        WL#9499 - Revert unrelated change
    
    commit 8b2bb0f6d6254b3cfde168d41356400009db12f4
    Merge: eb9b294ba78 153a79ff35d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:43:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit eb9b294ba786800f9e397cd87f01c4f4976edddb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 23 11:29:56 2017 +0100
    
        WL#9499 - Remove debug message
    
    commit abae66ad591854ee67a5013f3209be2f82e4d9bf
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 17:04:10 2017 +0100
    
        WL#9499 - Test only works in debug mode.
    
    commit 71ebea70391ef295bed49ee06a8b872f15ecfe97
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:18:08 2017 +0100
    
        WL#9499 - Update to mtr test from Matthias
    
    commit f108a5b92fc476c70c49e4937496b32d9d5d031f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 12:13:04 2017 +0100
    
        WL#9499 - Increment redo log version number
    
    commit 4439c83a4d3edd6e511706ccf9936770ed29e593
    Merge: fa459186b90 05923bef41d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 22 09:54:18 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit fa459186b90d7a5ddcba7e3c6c7a9871d0dce793
    Merge: 14ac4f81d84 b401f17e70d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 20:02:40 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 14ac4f81d84bec23a7be210504ca0be93619bf11
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 16:44:57 2017 +0100
    
        WL#9499 - Update from Matthias
    
    commit ed3191a9fc951151fd7d758a527e7ab81530b3f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:16:11 2017 +0100
    
        WL#9499 - Revert change pushed by nmistake
    
    commit 8c0edb998867bf557f6c86410552d6d123892000
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:11:21 2017 +0100
    
        WL#9499 - Don't redo log MLOG_FILE_OPEN until startup is complete
    
    Date:   Wed Feb 22 09:54:18 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit fa459186b90d7a5ddcba7e3c6c7a9871d0dce793
    Merge: 14ac4f81d84 b401f17e70d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 20:02:40 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 14ac4f81d84bec23a7be210504ca0be93619bf11
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 16:44:57 2017 +0100
    
        WL#9499 - Update from Matthias
    
    commit ed3191a9fc951151fd7d758a527e7ab81530b3f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:16:11 2017 +0100
    
        WL#9499 - Revert change pushed by nmistake
    
    commit 8c0edb998867bf557f6c86410552d6d123892000
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 15:11:21 2017 +0100
    
        WL#9499 - Don't redo log MLOG_FILE_OPEN until startup is complete
    
    commit 3b503ea1d3f89c0f7e3677d3b56f249c7ebff506
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:37:04 2017 +0100
    
        WL#9499 - Add tests
    
    commit 47af7bd6eec10eac55633d7c4cf54afe607f3649
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 21 11:00:30 2017 +0100
    
        WL#9499 - Fix compile problem
    
    commit a8b9a8c6ccb15e2be5ce5db5fa0bce24b86d2c87
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:51:05 2017 +0100
    
        WL#9499 Remove dead code
    
    commit b1dba474486ad10b61029b2ef4e6a91ea67dcea8
    Merge: 3cf9e9eb3e8 a4271026201
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 20 16:49:38 2017 +0100
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 3cf9e9eb3e86e4c8f4d44cb79d3f7c456ea7d671
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 18 07:53:43 2017 +0530
    
        WL#9499 - Remove suggestion to use force recovery
    
        --innodb-scan-directories is a safer option for the user. Force recovery should
        be the absolute last resort.
    
    commit 4104c4bfd606270650aac95a9a724e106fe835c5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 09:00:47 2017 +0530
    
        WL#9499 - Fix error message
    
        User can try --innodb-scan-directories="..." if the tablespaces.open.* files
        are corrupt or unreadable.
    
    commit 19ab12e54923b070a0b4ffc76b9fe97ac54ad3cc
    Merge: 50b3a95e446 f0f51c410bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 17 05:22:57 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
        Replace readdir_r() with readdir(), compiler complains that readdir_r() is
        deprecated and recommends replacing it with readdir().
    
    commit 50b3a95e446b91853fc35716b63bdc173221d01f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:55:33 2017 +0530
    
        WL#9499 - Fix test
    
    commit 45d202ae0fa35aa3aced55cc1933aeefa33837de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:32:56 2017 +0530
    
        WL#9499 - Remove redundant test
    
    commit 48fe691b97735e5144e9d439a0adbf721b2dc554
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:18:11 2017 +0530
    
        WL#9499 - Add DEBUG sync points
    
    commit d986f4e04a9eb6c2c76d61cd4afe9541d77b34bd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 16 18:03:50 2017 +0530
    
        WL#9499 - Remove PB2 control file
    
    commit 5af7dca9c305bd366ad2b5c3de26a870e913af4a
    Merge: 74022f50a5f 23a0e71aa3d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 15 09:05:05 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 74022f50a5ff7cb2801c0712601f8a467b409a28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Feb 14 10:31:00 2017 +0530
    
        WL#9499 - Fix test
    
    commit f6188175ee62040ac6a844a5c54787839dff6155
    Merge: 24c867aab14 19ca7c6a5d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Feb 13 12:37:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 24c867aab14556188503aac495f60d89ba3d26ec
    Merge: cb64b8c7f9f a4de6ab549e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Feb 4 06:41:23 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cb64b8c7f9fa9ca05033a9d6f6193cf141746310
    Merge: 17c6c41da0a 88dbc4f4511
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:48:12 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 17c6c41da0afe3fc78843b75fa02578dab29a0ca
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 19:46:34 2017 +0530
    
        WL#9499 - Add a test for scan directories.
    
        The use case is where the location of the files is not changed but the
        tablespaces.open.* files are missing.
    
    commit 79cc52f1bd82dc65932eacbc9aa14a47e4196572
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 18:01:50 2017 +0530
    
        WL#9499 - If open fails space will be null.
    
    commit 22ea5f31ecc1fa0db8abd57d4a46578e5f891c9a
    Merge: f5b69930f95 853a52cf5a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Feb 3 12:14:41 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f5b69930f95192ddfdb3ca170024a5c7e3416076
    Merge: 40a4c32f2c4 b18872ed4a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Feb 2 13:54:24 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 40a4c32f2c42b584539a14cbc1ba0d4f0fe7d3c9
    Merge: b1d1923d37c d071c0e7a0b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Feb 1 13:48:33 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit b1d1923d37c3d23a9f701a61b458b7e4cbd3c90c
    Merge: 2fc6c51edab 4ae71705a01
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 31 10:44:59 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2fc6c51edabc3de4537eceb0b82cd62063ada3a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 16:36:46 2017 +0530
    
        WL#9499 - Empty the tablespace.open.* files on normal shutdown.
    
    commit 738acb7d554f97455c8dba512282c7c2e6ba9f3a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:47:21 2017 +0530
    
        WL#9499 - Fix formatting
    
    commit 28f8579a6f729af354e0c50098d16fbfa17cc253
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 30 12:25:30 2017 +0530
    
        WL#9499 - Bug fix
    
        The DELETED state was set on a copy of the data structure
    
    commit dd5bf8ea81b7023fa1980c01d89219a690160b04
    Merge: 7eeab0a994d 9c7808e1054
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 21:14:22 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7eeab0a994db4cf0c2e080f27ff916c778ec65f8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:50:59 2017 +0530
    
        WL#9499 - Add tests.
    
    commit ddfaf047f43587ee807599b0b80b6d01a3579e8c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 20:48:06 2017 +0530
    
        WL#9499 - Create tablespace bug fix
    
        If there is a checkpoint after the create tablespace is logged and the
        server crashes after writing the page initialization to the redo log. Then
        we neither have the mapping in the redo log nor in the tablespace.open.*
        files. We must update the tablespace mapping before writing the CREATE
        redo log entry so that the state is written out to disk on checkpoint.
    
    commit 29546d3ebea2991e5b86b33edddb551c924bf1db
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 17:55:28 2017 +0530
    
        WL#9499 - Remove dead code from WL#7142
    
    commit eced7a3e4437ee4bb24a12290f561437ddb15611
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 14:51:09 2017 +0530
    
        WL#9499 - Use the tablespace.open.* files in a round robin fashion.
    
    commit d8eff788eea1ad5e6c7786b9d64963524f2b2c81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:56:12 2017 +0530
    
        WL#9499 - Fix duplicate entry
    
    commit 1d04e0cf0308c35ee7498e6919eab9a11c699d52
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 27 13:55:30 2017 +0530
    
        WL#9499 - Revert last push
    
    commit 8361d3c39366d6435a895d5b64dd23615d26fc28
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Jan 26 09:05:52 2017 +0530
    
        WL#9499 - Write to the tablespace.open.* files in a round robin manner.
    
    commit 3eaba629ee5b5c26a5f4e80852fee2d446f3013f
    Merge: 6642c43d735 bdc49070128
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 25 14:03:15 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6642c43d7353063a455972ab2cbc21220c16be43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 08:34:35 2017 +0530
    
        WL#9499 - Rename fil_ibd_load to fil_ibd_open_for_recovery.
    
    commit fdd1897c79b29c9e0a69c1f81d94927da06d9424
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:28:49 2017 +0530
    
        WL#9499 - Enforce const semantics on Windows for Folder::exists().
    
    commit 9394f4653e10cc5d4ab9b7b0a0b9331fd2666f49
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 23 06:08:26 2017 +0530
    
        WL#9499 - Include <array>
    
    commit c1903d28800ae0f7af69552aa669622d552346b4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Jan 21 07:49:28 2017 +0530
    
        WL#9499 - Improve scan directory handling
    
        1. Convert relative paths to absolute paths
        2. Filter out duplicates
        3. Check directories at filtering stage
    
    commit dfea237f4bef914de4067153cbf382240112c4f4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 11:11:05 2017 +0530
    
        WL#9499 - Code clean up
    
    commit c4d51bfdf1c786b1c584c0af1bde080a4f37cc5b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Jan 20 07:37:06 2017 +0530
    
        WL#9499 - Update the open/rename LSN when a file is opened or renamed.
    
        Minor code cleanup.
        Add diagnostic code for debugging.
    
    commit 5e1d159b571fe6dbfe13c627a245155b82c4bbfa
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Jan 18 10:59:54 2017 +0530
    
        WL#9499 - Filter out '*' from innodb-scan-directories
    
    commit 361f2944f1940f11dfb16dec3589d68335f5e2d8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 21:01:06 2017 +0530
    
        WL#9499 - Code cleanup
    
    commit 288d70b356721887423ca3d2d72b42da331216cd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 13:08:08 2017 +0530
    
        WL#9499 - Sync open file map to disk before checkpoint.
    
    commit 3c602d1b4089cd262200650f4b33986fc9e26531
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:18:46 2017 +0530
    
        WL#9499 - Print expected bytes instead of generic message.
    
    commit f52e0985b8cbef3891385179d35dc8c7f567146a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Jan 17 09:07:47 2017 +0530
    
        WL#9499 - Print file size instead of generic message.
    
    commit b27b1b4b4b70e286e2c669f997b0a669f6d6034c
    Merge: bbdd1c46f1e c101ec9b557
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Jan 16 13:19:42 2017 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit bbdd1c46f1ef08d956ea249e1f6f4bc93d3464f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Dec 10 14:41:12 2016 +0530
    
        WL#9499 - Handle the case where the rename has already been done on recovery.
    
    commit 141bdb02b1a402e786db5d8b165b781a5d7370a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 11:59:29 2016 +0530
    
        WL#9499 - Instrumentation for debugging
    
    commit 34815bb24a1c296d9739e7602dc6ccd53c58c44c
    Merge: 41ca3732a6f 13a46b4c5ea
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Dec 9 09:44:03 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 41ca3732a6ffd8dfa16762a05df6b5c6b4b550c1
    Merge: 7137edb2d2c aba34f1205d
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 11:10:08 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7137edb2d2ca60cdec44600ddf3f5cbde424e7a4
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Dec 8 05:56:06 2016 +0530
    
        WL#9499 - Remove unused code. Move id to name mapping sync before log flush.
    
    commit 2a50067e2da2f7819781de6550e55ca14995c7ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:57:41 2016 +0530
    
        WL#9499 - Initialize the PFS file handle
    
    commit d478d3492cdb40ec02fda9c043bf29b87bae11ed
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:05:52 2016 +0530
    
        WL#9499 - Fix whitespace
    
    commit 061af748a5e2fde6c1577ccdabfc8a89a9f753de
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 12:02:25 2016 +0530
    
        WL#9499 - Set must flush on file close/delete.
    
    commit ad76e2b9c7ff757f60c66821e86696d5ab757b18
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 11:43:00 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5a95946d4567dc13cf5a12d6bcdb28b19a02b5bc
    Merge: 1a0f373eb7f da23d6b8e44
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Dec 7 09:27:45 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1a0f373eb7f03dc22264f91f3f6ed1fd13825de7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 13:01:41 2016 +0530
    
        WL#9499 - Readd test result file back
    
    commit 00afde093183cf850f735940245af111dce82b72
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Dec 6 12:59:49 2016 +0530
    
        WL#9499 - Don't purge the files based on LWM. It won't work.
    
        We need to also ensure that there aren't any pages in the [1;31mbuffer[m pool that
        belong to a tablespace that is closed. Redo log records can be written for
        such pages.
    
    commit 3199fe255103daa42f0332b7ff9d565eefff7429
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:41:39 2016 +0530
    
        WL#9499 - Fix typo
    
    commit 351cb6c42709405a79021276f310d7b996aadd1b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 06:32:02 2016 +0530
    
        WL#9499 - Remove unused function
    
    commit 61cc7f6b06c5280d58217b76d7627013ddcd8338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:22:31 2016 +0530
    
        WL#9499 - Reduce the compression level.
    
    commit 48142e360ff5cfb53d5e416f3d6b92e956237923
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Nov 29 04:21:51 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 4de4f8b31ebdff31a2f7a97a1ad211770d20cdd6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 14:07:07 2016 +0530
    
        WL#9499 - Revert ef30f0754ab22e614ac22712c348ec5f53e0f09c
    
    commit c2f77f44c43c209fad86bba568aa521a2dcbf718
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 12:20:37 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 5fccb51769a13cb9a1fc0f29a832d3b0085ad52a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:30:18 2016 +0530
    
        WL#9499 - Print a message when checkpoint is disabled.
    
    commit ef30f0754ab22e614ac22712c348ec5f53e0f09c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 10:17:27 2016 +0530
    
        WL#9499 - Print progress in 10% units.
    
    commit bc0ded332624fa2c8a08ebfc955a03f1a24e069c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 08:13:54 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 68ce0208cc073452f5f791faf304971dbac7194a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:38:03 2016 +0530
    
        WL#9499 - Scan directories after the mutex code is initialized.
    
    commit 21e07c8fd6b8eddf158fb79980443f6c9f6d238e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 07:12:23 2016 +0530
    
        WL#9499 - Introduce --innodb-checkpoint-disabled (debug)
    
        Disable checkpointing if the variable is set. This is to force recovery if the
        server is killed during a test.
    
    commit 7033c9bb5ff7641764f70823a73d747b497a0eed
    Merge: 11a6e582417 c6af7f512b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 04:00:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 11a6e582417d45a80a7f19233c2d2191a17936eb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Nov 28 03:59:05 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 0a38252e65d607b59b1e9f64d0c8003cdecfecfd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 25 05:56:42 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bcf650cc92b8636f3768dcc3deb33b90b2942134
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 08:46:07 2016 +0530
    
        WL#9499 - Change the open files number back to 2.
    
    commit 99960af2825529fb45d021a34ba6c072e8caa0dc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 24 07:13:58 2016 +0530
    
        WL#9499 - Code clean up
    
    commit bdb91bc0ba03e01661c50c7175d3fd123d2bcd69
    Merge: 61f3e4a5663 a545bdd6e31
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:04:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 61f3e4a5663c375cd44ee766b263281ff7f0601b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 14:00:20 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 072ab837d0acb4d2ed817110598554acc44ec344
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 12:06:53 2016 +0530
    
        WL#9499 - Set the IMPORT page LSN to the flushed to disk LSN
    
    commit 7f18661432f3645eb9ce76680c62508ced115fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 11:28:47 2016 +0530
    
        WL#9499 - Force a checkpoint before the crash
    
    commit 83671e9c37fa61adfa5546cabe1463a91ff02241
    Merge: cc26d5ae16e d1f811eb6e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 23 10:52:16 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit cc26d5ae16e8d723a2519f38bfbc084c13a766c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 18:40:51 2016 +0530
    
        WL#9499 - Fix latch ordering issue
    
        Cannot hold the log sys mutex when updating the checkpoint LSN for the open
        files in fil0fil.cc.
    
    commit 4474509addfbdf91b9f0ad890a971299c594e738
    Merge: 396755e195c 0856b10cde5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 08:00:05 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 396755e195c1c8d3b2485a58175dcf56ca2cbf3f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:58:05 2016 +0530
    
        WL#9499 - Remove newline added earlier
    
    commit ab5e60ba491e52f1529c22551a936d771b8b5ef9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Nov 4 07:57:21 2016 +0530
    
        WL#9499 - Revert a change that was added by mistake.
    
    commit 38688417713e5ef8cbb65032fa0a547ab0c25c15
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 20:44:50 2016 +0530
    
        WL#9499 - Bug fix, using an invalidated iterator.
    
    commit 4082d44f6dc4a5605562e37ccad9ac4db69344c6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Nov 3 11:30:49 2016 +0530
    
        WL#9499 - Fix doxygen comment
    
    commit d5ca99e14c010a5349aea6c8cc39493b2073b9c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 15:30:12 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a25f3af10ea2893c634dc961d6f2af05efa103ec
    Merge: c8c2a7eba4c aa039b73223
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:52:51 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit c8c2a7eba4cac29ff431588daf2d6def0c0ee5a6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Nov 2 12:39:32 2016 +0530
    
        WL#9499 - Fix problem with open files acrosss checkpoints.
    
        The problem is that we write the open file state before writing the checkpoint.
        Before this change the closed files were purged from the open state map and
        the state written to disk. The problem is that the state and mapping of a file
        opened before the last checkpoint but closed just before we write the state
        will not be in the mapping on disk. One solution is to check older files and
        retrieve the mapping from there. The solution chosen is to avoid purging
        files based on open LSN. If the file was opened before the last checkpoint
        and closed within the current checkpoint we note the state as CLOSED but
        write the mapping to disk. It will be purged at the next checkpoint, if it is
        not opened again in the meantime.
    
        Previously an attempt was made to open all files straight after reading the
        mapping from disk. With this change only the state is loaded into memory the
        files are opened on demand. Added a check to verify that the tablespace ID
        from the first page matches the expected value.
    
        Fixed tests to use this new tablespace ID verification.
    
    commit 5dc929e54b1c259f0f8104739ae1f88e9b860f73
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 12:24:40 2016 +0530
    
        WL#9499 - Remove unused code
    
    commit 528b95d70dcc05a69a98ee2a76fdfb8dae1e82fe
    Merge: d9861c40964 75f05cba753
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:14:40 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d9861c40964ad8fd45ee2cbbd9d94946110e8a9a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 3007ea5af68f40b85bc93098d8385ac96bcbd660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Oct 25 10:04:49 2016 +0530
    
        WL#9499 - Remove last vestiges of MLOG_CHECKPOINT
    
    commit 9592996d2f17c9005262faa75dc1ade9dedbd511
    Merge: da512d5591b ac925fc91f6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Oct 19 10:34:48 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit da512d5591b3379b793d6155089e90791fe94c61
    Merge: f42e2ddd7d5 e635dfe28c0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 30 05:20:10 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f42e2ddd7d50aacae679babe71643af379b5c492
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 15:05:28 2016 +0530
    
        WL#9499 - Fix assertion, the values can be ORred.
    
    commit 94cd08960bc3801acefd4b4ff4ddb4a3e7d7e81a
    Merge: 32a68f91330 59af373321b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 22 11:05:21 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 32a68f9133011871bfdaba3c742f6239e0a53061
    Merge: 7857f38ebce 15555ae2165
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 21 11:23:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7857f38ebce747135e055bc8a232b649f1aad351
    Merge: 427491f63f1 b43bf88cf80
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 19 11:43:17 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 427491f63f107247c36796e66f6224d20968f104
    Merge: e7fa4c53dcf 23343687722
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 14 22:40:47 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e7fa4c53dcf01ea0e101bd8aa817698492995034
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 19:22:00 2016 +0530
    
        WL#9499 - max_lsn should work with any number of tablespace open files.
    
    commit 09775960da43d36ca64504c1298b9adff3056575
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 17:47:29 2016 +0530
    
        WL#9499 - Fix Names hash bug.
    
    commit 8430c5b34d23cb1774597707fe583dfac93fb3a8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Sep 12 09:49:47 2016 +0530
    
        WL#9499 - Use std::unordered_map for name to fil_space_t* hash.
    
    commit 5e8275caf9d50dc9ba2f2dadd3b8c0fdeb9c79b6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Sep 10 07:55:42 2016 +0530
    
        WL#9499 - Reduce an extra fil_sys_t::mutex call by consolidating flush request.
    
    commit b29fd1039cf0022cff36a2a2311f464f1f6dbcc5
    Merge: 6235ee4902a a150caebee6
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Sep 9 20:44:56 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 6235ee4902addd1a041b33469988bb1ea870dc7a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 10:58:00 2016 +0530
    
        WL#9499 - Add debug crash points.
    
    commit bf71fbc72b3570f55c8f01dd1a440e9eff761cb6
    Merge: ce6d2246a94 d25f38e38d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 8 09:47:37 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit ce6d2246a94801041da0bfece74b5ffdd9e8f796
    Merge: 69adae163de f28c4b9a41e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Sep 7 11:20:50 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 69adae163de295ef0e910752cf5f8c96b1c1114f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:33:29 2016 +0530
    
        WL#9499 - Ensure that the MLOG_FILE_OPEN is always written first to the redo
    
    commit 20d5b1ebe6c899e2a0a1d135ad4303490516ce26
    Merge: 2d7d25c145f 4f1fb936211
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 22:17:58 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 2d7d25c145fae59af744e91fce47fe009c869dad
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 10:06:56 2016 +0530
    
        WL#9499 - Add PFS instrumentation for the tablespace open file.
    
    commit 4e14a53ad129c1adcb0a3330931878a9f24c15cc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:53:57 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit a465361e74136662471d2b9c0f307799efbe7269
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 08:17:43 2016 +0530
    
        WL#9499 - Move the file write code to a separate method.
    
    commit 7a26ba28bf7bf94808c47cfcdb6210c4abde2587
    Merge: f49914e5e61 ed389829067
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Sep 1 07:55:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f49914e5e61b846c45f7b177308cd891918619e4
    Merge: a4fab040243 16fd507b84a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 31 11:23:42 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit a4fab040243a57fb8ef55f91812604352d8b92c8
    Merge: 93019973329 dfee02dc4f5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 10:42:20 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 9301997332923921b93de4946c4824164723050c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 30 09:09:05 2016 +0530
    
        WL#9499 - OSX/Solaris compilers don't like the code.
    
    commit 54afa110837a054de24ccda84ddbb4ef2d0b96a1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 22:55:19 2016 +0530
    
        WL#9499 - During recovery PFS instrumentation can't be accessed by the user.
    
    commit fa5c11e8cf0fbcd1852535faa74b1a04200df2e8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:15:07 2016 +0530
    
        WL#9499 - Fil_Open::purge() can be called during recovery too
    
    commit d8672a978d62db42f1a12ba152693a3c0d244d83
    Merge: d4251d0ed6f 14d2a977ce8
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:10:32 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit d4251d0ed6f9df5a3acbf97ce7ba8074f126044c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 29 11:07:14 2016 +0530
    
        WL#9499 - Remove a WL#7806 test.
    
        The test doesn't really help. It uses very simplistic checks for matching
        path names. It ignores links (soft and hard) completely. Besides during
        recovery the path names will work with the original path names.
    
    commit fba6656350d0a757b2cc936b017329e7f7ce2d32
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:51:53 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b522d665d10dca905420cb9119692dffac5024c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:20:30 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 3a9aca50a2e193398d626b5f75d238b5aa704e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:19:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 5923cd73fc3af904220dea20b033ffcbb7892606
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 09:12:44 2016 +0530
    
        WL#9499 - Use custom allocators.
    
    commit 8c5acab2641cedae9542b9ad9405032abbcb4618
    Merge: 1509c43fcff 3c1319b9901
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:21:28 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 1509c43fcffb9a849542ef8f3a62e66fda490fc7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 08:08:34 2016 +0530
    
        WL#9499 - Fix bug, should be decrement in_use, not increment.
    
    commit 0ad783d5e6e3f99817c8b839fe8521f783577d35
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 26 07:58:49 2016 +0530
    
        WL#9499 - Change fil_node_t::in_use into a reference counter from bool.
    
    commit 3974f1ed40bfbadcee04fa5fc2e60a50b89f930c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 22:10:24 2016 +0530
    
        WL#9499 - Remove an assertion that is no longer an invariant.
    
    commit d79f12dec7c07698f02ce2e0d0396bcd01bdc683
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 21:52:21 2016 +0530
    
        WL#9499 - Rename fil_node_t::being_extended to in_use. Fix test.
    
    commit 1d3368bcf60e2e339d5917251b51201b94dd63a3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:57:38 2016 +0530
    
        WL#9499 - Fix log info messages during recovery/apply.
    
    commit d3811bd67248d3ae014f0e6475b1b49524f5c35b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:40:01 2016 +0530
    
        WL#9499 - Don't print % processed if number of records to apply is small.
    
    commit 55af670ff81170da51fbcae6832c3d6191176602
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:21:31 2016 +0530
    
        WL#9499 - Update test with new log message to check.
    
    commit 60c3d6c074ae230ab594015ed2f99e2eefcf97e0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:09:04 2016 +0530
    
        WL#9499 - Record test, because of new config parameter innodb_scan_directories.
    
    commit bd79ff06406c86758a29a28dbe5e7d494a0aa51f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 10:05:38 2016 +0530
    
        WL#9499 - Remove WL#7142 artefact.
    
    commit bcb753b72b2a01ba35d952cbab45e420929f2b33
    Merge: e30834ecc60 27d64e974ec
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:26:25 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit e30834ecc60522fca8d7b156a66c0765867dea6e
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Thu Aug 25 05:54:26 2016 +0200
    
        WL#9499 - Destroy the mutex in the Fil_Open destructor.
    
    commit a396d4714bdc46626e07d22b6871be153b627bd3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:17:06 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 282ad76aaeaeb6d91bbf81fcd3315f455d9f572c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 09:12:33 2016 +0530
    
        WL#9499 - Protect changes to Fil_Open state with a mutex.
    
    commit d338cb9468c126ee7e3eeae3bf37b0fc966bbf53
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 07:37:49 2016 +0530
    
        WL#9499 - Fix division by zero.
    
    commit 845324f19ba0a84538b87c072f6d99514533aa25
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:28:45 2016 +0530
    
        WL#9499 - Check for UNDO tablespace names during directory scan.
    
    commit 30ed1d19389e174605fdfc0b7d55fdf544933712
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 25 00:26:08 2016 +0530
    
        WL#9499 - Conform to new naming guidelines.
    
    commit 4cf67b352d4c8131064f832ec884db6166d50e71
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 22:04:43 2016 +0530
    
        WL#9499 - Add test for the configuration variable. Add a version number to the file.
    
    commit ad9c5bca0eba1d7bf8e29cd8ebd7062aae089f90
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 21:01:56 2016 +0530
    
        WL#9499 - Code clean up
    
    commit a9e848158909645ead86759ed7ab64789d18a0cb
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 15:26:02 2016 +0530
    
        WL#9499 - Print redo apply progress per tablespace
    
    commit 8cf86cf1567cabc1b03b2e8f2ec1167f3c38ce6c
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 13:04:55 2016 +0530
    
        WL#9499 - Print tablespace name and % completed per tablespace
    
    commit 35ccdf32d1d048400012a80422072fb41ceb1bbd
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 24 10:35:26 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit c978fb2e18a4e0b4a93b44fc3c75234bcdb3f1f0
    Merge: 8bde4aeb01c 0832bf660e3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 22:25:57 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 8bde4aeb01c3bcdecfb884e566f0ae28797a5b36
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 13:21:10 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 7f502be746cbe0de1a0c3a992217691b167c2fa9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 12:12:08 2016 +0530
    
        WL#9499 - Fix Windows build issue
    
    commit 247bcfda6744a67cc4e53d61658ca87d206b0660
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:57:44 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 04509641b086a1b0b2c591573f95957f8a2f1cd0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 10:50:55 2016 +0530
    
        WL#9499 - Pass the filename directly to the callback
    
    commit 3efa317825886a3ae5d4a3c771fc0770a2c5a3ff
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 09:39:18 2016 +0530
    
        WL#9499 - Include tchar.h on Windows
    
    commit 55b814d2c2ebdea7c16a6d87a7251ca3f6e83775
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 23 07:47:39 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit e4d203688273b562691c912cb9c7024709757490
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 22:02:02 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit 31433b21dcabba0a7705eb8b1879beb1d8c36517
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 21:37:41 2016 +0530
    
        WL#9499 - Move Dir_Walker::walk implementation to os0file.cc
    
    commit 11f9016477274c5420782e365b26762067e7b99b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 18:42:28 2016 +0530
    
        WL#9499 - Fix Windows version of Dir_Walk.
    
    commit f32b88e0b1ef99f220165897db745b1dba12f86b
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 22 13:48:03 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit b91ad88d96942f1e05443001b7d1c2f6818ff6d3
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 14:32:25 2016 +0530
    
        WL#9499 - Initialize active ID to filename set from scanned set.
    
    commit 4a09f677ae7095aac9b07f7beccba8e60c50b065
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 13:09:05 2016 +0530
    
        WL#9499 Scan specified directories to build the ID to name mapping.
    
    commit c13b791497e322e6a5cf64ba85da52ee2cf05d45
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:46:53 2016 +0530
    
        WL#9499 - Fix check for incomplete read.
    
    commit 8a849e0288309cec7228612a62fc2bfd71b595e9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 10:45:04 2016 +0530
    
        WL#9499 - Fix Windows build errors
    
    commit 4fc24b654da26e8411fc45bc96f73ff70dc73e43
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:12:12 2016 +0530
    
        WL#9499 - Need to include string for Windows std::wstring.
    
    commit bcb5c2b23f54776e0faaafba2472bb2555aee561
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sun Aug 21 09:02:59 2016 +0530
    
        WL#9499 - On POSIX fopen() mode should be "w+b".
    
    commit b3c7def1931867633d9b8bb601317e99a06c31a9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 21:23:57 2016 +0530
    
        WL#9499 - Open file in binary mode for writing.
    
        Otherwise on Windows newline (0x0A) is translated to CRLF (0x0D0A).
    
    commit 0739399cb8a384c07b4b3540b73ade482d083f4a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 20:27:11 2016 +0530
    
        WL#9499 - More error messages during mapping file read. Add a directory walker.
    
    commit 1322de0af2235bc94630f7cb22e4ead1588775ee
    Merge: f266b100e2f 8fdbb2f5f1a
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:47:39 2016 +0530
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit f266b100e2f23e775e5e04de8d26301d7f2f1072
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 20 13:18:07 2016 +0530
    
        WL#9499 - Flush the tablespace to mapping file [1;31mbuffer[ms before fsync()
    
    commit 7c92536686033c2c70e7df831d569c1cd6f871f0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:32:26 2016 +0530
    
        WL#9499 - Remove unused member variable m_lsn.
    
    commit 994c4766ef712e7da668788d0bdd648cbd764982
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:25:05 2016 +0530
    
        WL#9499 - Don't crash on uncompress failure. Try the next file if any.
    
    commit a419a190cdf734e3beca08d339c6c0d307ddff5f
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:21:49 2016 +0530
    
        WL#9499 - Print an error code on uncopress failure
    
    commit 77cb39000e098ba4d06873723423521e6889a7d0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 20:12:11 2016 +0530
    
        WL#9499 - Code cleanup
    
    commit afc632e0ef768542a96d4d15a897cb1780825d2e
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 11:34:44 2016 +0530
    
        WL#9499 - Compress the tablespace open state file.
    
    commit 568c9e758084f671007789f7b5d1c996f5df39a0
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 09:12:39 2016 +0530
    
        WL#9499 - Free the [1;31mbuffer[m on return
    
    commit 0f468cf8e50b9605a9e6c4e93c818b0f876c3c29
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Fri Aug 19 08:42:38 2016 +0530
    
        WL#9499 - Remove protobuf
    
    commit e789eb175d2da90cee2d46e30b91e623546f9e96
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Thu Aug 18 09:59:37 2016 +0530
    
        WL#9499 - Get native HANDLE
    
    commit 6014c5853c09fee75256f9de6a86a5fc0ea18508
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:50:37 2016 +0530
    
        WL#9499 - Use _fileno() on Windows
    
    commit 61e6b4d7c033d48b775b22c4ad6d6b4858cd4cd7
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 14:37:01 2016 +0530
    
        WL#9499 - Use [1;31mbuffer[med IO for open state file writes
    
    commit 98f40b10c15e49d9a5e14689cdb34758bdf85a05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 12:36:06 2016 +0530
    
        WL#9499 - Don't complain about corrupted encrypted pages during dblwr recovery
    
    commit c674939cbdeaa4a9996960de0fa4e74954ad6f76
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 09:21:06 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for generated sources too.
    
    commit ff68ba26aeaa27070ceeaa8db4472a9ce4daa3c9
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Wed Aug 17 08:33:03 2016 +0530
    
        WL#9499 - Protobuf internal code doesn't compile on Solaris/SPARC.
    
        Workaround is to set -Wno-unused-but-set-parameter for fil/fil0fil.cc
    
    commit 445985ca11810c528567a4222cad4a7f0ce49e81
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 19:44:29 2016 +0530
    
        WL#9499 - Read/Write open state files using absolute paths
    
    commit b4d91d3799d94eb2677be6512752ec27dfa5e0f1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 14:37:40 2016 +0530
    
        WL#9499 - Fix doxygen errors
    
    commit 8be2de3b3077c0d0f26340c9c80f7ae2247eefbc
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 11:20:24 2016 +0530
    
        WL#9499 - Record test, MLOG_FILE_NAME doesn't exist anymore
    
    commit 54e64dc4a97f5bf4b5606cea1841dfc1f04fe536
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Tue Aug 16 10:41:01 2016 +0530
    
        WL#9499 - Add protobuf library to the embedded library.
    
    commit 83b0fb38283e285e1e963dd2c7c144d70b130338
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 21:17:13 2016 +0530
    
        WL#9499 - Improved DBLWR and System table checks and code cleanup
    
        1. Remove dead code
        2. If some pages from the dblwr [1;31mbuffer[m were not recovered during recovery
           because of a missing tablespace id -> name mapping. Check the tablespace
           ID against the Tablespaces meta-data after recovery.
        3. Track open of the system tablespace. Check if the name of any file
           has changed. We don't rename the system tablespace.
    
    commit 5ebfba1e083f6a1d2b70946b91a02d32733c7e87
    Merge: 7a1b724c04b 0c27bf6fc44
    Author: Sunny Bains <Sunny.Bains@Oracle.Com>
    Date:   Mon Aug 15 11:40:07 2016 +0200
    
        Merge branch 'mysql-trunk' into mysql-trunk-wl9499
    
    commit 7a1b724c04bf9d2e4aba0e58fb95dc8fc75d55c1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 15:07:47 2016 +0530
    
        WL#9499 - Free deferred page memory
    
    commit 4de5d3b03670e4d2e8ebce89e8b3f104968eb3e1
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:45:25 2016 +0530
    
        WL#9499 - Remove unrelated changes
    
    commit c9e83914232480501b139c36ef616798a2ac1d05
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Mon Aug 15 11:28:19 2016 +0530
    
        WL#9499 - Code clean up
    
    commit 6ecdb21d63ef6dd5a6aff997720178ff6510f0d5
    Author: Sunny Bains <Sunny.Bains@oracle.com>
    Date:   Sat Aug 13 14:31:52 2016 +0530
    
        WL#9499 - Don't exit if no open state files found

[33mcommit 10c5edc6876cf3f0294dbfc2e94a6bd6bd2fe624[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Tue Jan 3 14:55:49 2017 +0530

    Bug #24748843: SYNC PRINTS TO STDOUT CAUSING MAIN THREAD TO SLEEP DURING HIGH IO WAIT
    
    A new OutputStream type- BufferedOutputStream is added in this patch.
    All log messages going to this stream are appended to a log [1;31mbuffer[m.
    Messages from this log [1;31mbuffer[m are read by a log thread which
    appends messages to the data node log file.
    
    The log [1;31mbuffer[m is of type LogBuffer- a class introduced in this
    patch. LogBuffer handles the producer consumer problem.
    Appending logs to the log [1;31mbuffer[m is always non-blocking.
    Hence, the problems arising due to synchronous prints are avoided
    
    The data node's worker process's log messages are made to go into the
    BufferedOutputStream. This makes logging through ndbout << , ndbout_c,
    g_eventLogger in the worker non-blocking.
    
    Logging using [f]printf, [f]write are blocking/synchronous and must be avoided.
    
    CPU locking of the log thread is akin to the other IO threads(Ndbfs).

[33mcommit 3b4ffa6262eb2ade87a2f8d931c2c887df0c85d5[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Wed Feb 1 11:32:49 2017 +0100

    Bug#25461627: VALGRIND WARNING WHEN UPDATING A JSON COLUMN
    
    In some situations, updating a JSON column could cause incorrect
    values to be written into the table. The problem occurs if an UPDATE
    statement updates the same JSON column twice, and the second update
    overwrites the column value with a subset of itself. For example:
    
    UPDATE t SET json_col = JSON_ARRAY(....), json_col = json_col->'$[0]'
    
    The problem is that the second update both reads and writes from the
    output [1;31mbuffer[m, since it needs to read the value that resulted from the
    first update. When reading from and writing to the [1;31mbuffer[m at the same
    time, it may overwrite parts of the [1;31mbuffer[m before it has read them,
    which could result in garbling the value.
    
    This is fixed by writing the new value to a temporary [1;31mbuffer[m first in
    the case where the input is read from the output [1;31mbuffer[m, and only copy
    it to the output [1;31mbuffer[m after all the needed data have been read.

[33mcommit d194220d77cf7c71f13f3b132fee97c4db6a58d6[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Thu Jan 26 11:04:54 2017 +0100

    Bug#23130819: Refactor state changes for the row [1;31mbuffer[m in class TABLE
    
    Followup to fix regression introduced by original bugfix.
    The regression was in the test information_schema-big.
    
    For join operations that produced aggregated, empty results, some
    tables might be left in the "null_row" state after the output row
    had been produced. For the test that failed, this coincided with a later
    ICP evaluation on the table with the erroneous state, which caused a
    wrong false result.
    
    The immediate fix to this problem was to add reset_null_row() calls
    for all tables involved in such operations. This fixed the problem,
    but re-introduced another problem about overwriting of NULL value flags
    for const tables. Const tables actually need the same save and restore
    logic for NULL values as for eq_ref tables. It seemed like a good idea
    to consolidate all NULL value setting and restoring.
    
    Thus, saving and restoring of NULL values is moved from the TABLE_REF
    class to the TABLE class. A null_flags_saved [1;31mbuffer[m is allocated for
    all TABLE objects together with record[0] and record[1]. (It is a very
    small [1;31mbuffer[m, so the overhead is marginal).
    
    The function JOIN::clear() is renamed to JOIN::clear_fields(), it is
    extended with functionality to save NULL values for const tables,
    and it is paired with a new function JOIN::restore_fields() that will
    restore NULL values saved in JOIN::clear_fields().
    
    This also fixed a regression that was introduced when bug#13430588
    was fixed: The offending aggregated query would report a non-NULL value
    when a NULL was expected, see test main.group_by.

[33mcommit 93f4a9b6fbae1578ed1225af1655c69ca0fee69f[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Jan 19 16:11:23 2017 +0100

    Bug#22705935 NDBAPI : SENDSIGNAL FLUSH OPTIMISATION ISSUES
    
    Follow up patch to fix regression observed in the ATR
    tests:
    
    - testNdbApi -n ApiFailReqBehaviour T1
    - testNdbApi -n CheckDisconnectCommit T1
    - testNdbApi -n CheckDisconnectComplete T1
    - testNdbApi -n FragmentedApiFailure T1
    - ... and possibly more
    
    The original patch removed the ::flush_send_signal()
    from TransporterFacade::reportConnected / ::reportDisconnected()
    after it had returned from ClusterMgr::reportConnected
    or ::reportDisconnected().
    
    This was done as flushing is now done by by the poll owner
    when it 'finished poll'. However, that is probably too late
    for the ::reportDisconnected() as we want the receiver to
    take immediate actions on this - Possibly we even reset
    the send [1;31mbuffer[ms as part of disconnecting, such that the
    unflushed signals are lost before they are sent, (Didn't
    really investigate that though)
    
    This patch reintroduce flushing for ClusterMgr::reportConnected()
    and ::reportDisconnected() by changing their signal sending
    to use the flushing ::safe_sendSignal() instead of
    ::safe_noflush_sendSignal(). This reintroduce the
    immediate flushing of signals sent as part of a
    connect/disconnect.

[33mcommit 41a0eac91bb1412d8f72c79dbc8fbce97c5fbc3e[m
Author: Roy Lyseng <roy.lyseng@oracle.com>
Date:   Wed Jan 18 14:25:44 2017 +0100

    Bug#23130819: Refactor state changes for the row [1;31mbuffer[m in class TABLE
    
    This is a more comprehensive fix for bug no 22833364. It reverts the
    changes made in this fix and refactors TABLE status handling.
    
    - Literal values are replaced with setter and getter functions that describe
      the properties of the row [1;31mbuffer[m denoted TABLE::record[0].
    
      set_not_started()
      is_started()
      set_found_row()
      set_no_row()
      set_null_row()
      reset_null_row()
      set_updated_row()
      set_deleted_row()
      has_row()
      has_null_row()
      has_updated_row()
      has_deleted_row()
    
      STATUS_GARBAGE is renamed to STATUS_NOT_STARTED, as it is now only used
      to describe if a table has been accessed yet. The has_row() function
      (which checks the STATUS_NOT_FOUND) is now used both for key lookup
      functions and range scans.
      By using setter functions, we can guarantee that status values are
      maintained consistently.
    
    - TABLE::set_null_row() is called when processing a NULL-complemented row
      in the nested loops join execution, and TABLE::reset_null_row() is called
      when processing is finished.
    
    - The call to restore_record() inside evaluate_null_complemented_join_record()
      was redundant and has been deleted. Thus, a row that has been set to NULL
      can still be used afterwards, except for the NULL bit vector which is
      set to all ones by set_null_row().
    
    - join_read_key() has been refactored to avoid the illogical
      cmp_[1;31mbuffer[m_with_ref() function. Instead, a read_row flag is maintained,
      which controls whether reading a row from storage handler is necessary.
      Notice that it is possible to use a cached row that has been set to NULL,
      since we no longer destroy the row by calling restore_record(), and we
      save the NULL bit vector in a new [1;31mbuffer[m in struct TABLE_REF.
    
    - The has_record field has been removed from struct TABLE_REF since it
      played partially the same role as TABLE::has_row().
    
    - TABLE::status is renamed to m_status and made private.
    
    - All handling of TABLE::m_status is removed from storage engines.
    
    - TABLE::m_status is set in storage engine handler using a new interface:
      TABLE::set_row_status_from_handler(). This is now called from all
      public handler functions, to ensure table status is set consistently.
    
    - A few changes have been done to handler interface to enhance consistency:
      . ha_ft_read() is added as a new public interface.
      . ha_index_read_pushed() and ha_index_next_pushed() are also added.
      . ha_index_next_pushed(), ha_read_range_first() and ha_read_range_next()
        are also added.
    
    - Generally, all public handler functions start with an "ha_" name prefix
      and are non-virtual. Most of these functions call a protected
      handler-specific virtual function with the "ha_" name prefix removed.
      Some deviations to this rule exist when no virtual inner function is
      needed.
    
    - Life cycle description is updated. Since storage engine handler updates
      status after all row operations, it is not needed to set row status
      before calling the handler. However, we must make sure to update status
      when moving rows to record[0] from any other [1;31mbuffer[m.

[33mcommit 2ff30c2291c6b753ef657473bb955bfeda384d7f[m
Author: Priyanka Sangam <priyanka.sangam@oracle.com>
Date:   Wed Jan 18 13:51:39 2017 +0530

    Bug#25302901 NDB_PRINT_BACKUP_FILE SEGMENTATION FAULT WITH A TABLE WITH 500 COL
    
    The ndb_print_backup_file tool reads table descriptors from the
    .ctl file. While reading a table descriptor from the .ctl file
    into the [1;31mbuffer[m, a [1;31mbuffer[m overflow occurs because the table
    descriptor is too large to be accommodated within the [1;31mbuffer[m.
    The [1;31mbuffer[m overflow corrupts the output stream object. The
    corrupted output stream object is then used to print the table
    descriptor, resulting in a segmentation fault.
    
    Fix Description: Increased the [1;31mbuffer[m size so that the largest
    possible table descriptor can be accommodated without overflow.

[33mcommit aaf16b6afc254ca17e63f1ddf16081e84abe1a1d[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Wed Dec 21 16:28:43 2016 +0100

    Bug#25229315: ASSERTION `TABLE->M_RECORD_BUFFER.RECORD_SIZE() ==
                  RECORD_PREFIX_SIZE(TAB)' FAIL
    
    Index merge scans might need to read the primary key columns in
    addition to the columns that are in the read set. When a record [1;31mbuffer[m
    is allocated for an index merge, space is allocated for the columns in
    the read set and also for the primary key columns if needed. For a
    dynamic range scan, however, the extra space for the primary key
    columns is not allocated unless the first range is read using an index
    merge. If the dynamic range scan later uses an index merge to read a
    range, it might not have enough space for the primary key columns in
    the record [1;31mbuffer[m.
    
    This is fixed by allocating space for the primary key columns in the
    record [1;31mbuffer[m also for dynamic range scans.
    
    Change-Id: I365cd9e26f96f64f5dbea30f62cce86d4723ad3c

[33mcommit 97ff1e331a28773953f0118a90951da2b63b439b[m
Author: Elżbieta Babij <elzbieta.babij@oracle.com>
Date:   Mon Jan 2 15:48:47 2017 +0100

    Bug #23573751     ASSERT BLOCK->MAGIC_N == MEM_BLOCK_MAGIC_N IN MEM_BLOCK_VALIDATE AT MEM0MEM.IC:1
    Bug #24603431     [ERROR] INNODB: ASSERTION FAILURE: MEM0MEM.IC:157:BLOCK->MAGIC_N == MEM_BLOCK_MA
    
    This patch does not fix the bugs, but merely tries to deploy a scheme to nail them down easier.
    
    - Changed offending assert to manual check with more verbose fatal error.
    - Introduced 2*16B no man's land in debug version
     * checks on top free or block free that no mans land on boundary is not overwritten, as a way to check some [1;31mbuffer[m under/overflows during writes.
     * on valgrind makes no mans land non-accessible, to efficiently check [1;31mbuffer[m under/overflow on both writes and reads.
    - Improved managing of non-accessible memory checks in valgrind.
    - Increased debug filename storage from 8B to 16B in memory block header.
    - Removed old workaround to problem that is not reproducible anymore (at least on MTR).
    
    RB #14997
    Reviewed by Vasil and Kevin

[33mcommit 767f3877cc70265c0854a84e07f5a215a1239bb2[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Jan 6 09:29:05 2017 +0100

    Bug#22705935 NDBAPI : SENDSIGNAL FLUSH OPTIMISATION ISSUES
    
    If signals were sent while the client process received signals
    (typically SUB_GCP_COMPLETE_ACK and TC_COMMIT_ACK), these signals
    were temporary [1;31mbuffer[med in the send [1;31mbuffer[ms of the clients which
    sent them. If not explicit 'flushed', the signal would stay
    in these [1;31mbuffer[ms until the client was woken up again and flushed
    its [1;31mbuffer[ms. However, this could take quite a while, without any
    attempt of guarantying an upper limit of how long the signal
    could remain unsent in the local client [1;31mbuffer[ms. This could
    lead to timeouts and bad behaviour in the components waiting
    for these ACKs. (bug#18753341).
    
    Furthermore, the patch for Bug#23202735
    
    'CLIENT PERFORMANCE REDUCED DUE TO THREADS WOKEN UP TOO EARLY'
    
    Likely worsened the situation by removing some random client
    wakeups where the clients send [1;31mbuffer[ms could have been flushed.
    
    This patch moves the responsibility of flushing messages
    sent by the receivers from each client, to (only) the
    receiver/poll_owner client. This has the advantage that
    we no longer have to wake up all clients just to have them
    flush their [1;31mbuffer[ms. Instead we let the (already running)
    poll_owner client do the send [1;31mbuffer[m flushing of whatever
    was sent while it deliverd signals to the receipents.
    (in finish_poll())
    
    Note that all such signals should be 'safe-sent'
    (safe_sendSignal()) which implies that the are [1;31mbuffer[med in
    the poll_owner send [1;31mbuffer[ms. Thus only the poll owner
    send [1;31mbuffer[ms has to be flushed when the poll 'finish'.
    (Added asserts that there are no pending flush from the other
    'locked-clients')
    
    Explicit 'flush_send_[1;31mbuffer[ms' where we flushed send [1;31mbuffer[ms now
    covered by the above flush has been removed (reportConnected(),
    reportDisconnected(), complete_poll(), wait_for_input_in_loop().
    The later two were replaced with an assert that there were no
    pending flushes.
    
    That ^^ uncovered a missing flush_send_signal() in
    NdbScanOperation::nextResultNdbRecord(), where a
    'prefetch' of more scan results may have been sent, but
    not got flushed to the transporter layer. (Until we eventually
    had to poll-wait for more results)
    
    There has also been some confusion wrt. when to use the
    'safe(_noflush)_sendSignal()' or not. The method
    TransporterFacade::is_poll_owner_thread() is introduced
    as an utility to be used to 'assert' the correct usage of
    the diferent flavours of the 'sendSignal()' methods.
    See also extensive comments added as part of introducing
    this.
    
    Usage of these asserts uncovered that both
    ClusterMgr::reportConnected() and ::reportDisconnected()
    made usage of raw_sendSignal() instead of its 'safe'
    variant - corrected.

[33mcommit 19bee60cea71a1a4be8491a2190908e567d09a8c[m
Author: Priyanka Sangam <priyanka.sangam@oracle.com>
Date:   Tue Dec 20 11:25:38 2016 +0530

    Bug#25182956 NDB_RESTORE FAILS WITH READMETATABLEDESC READ ERROR
    
    While loading metadata in ndb_restore. table metadata should be
    read from .ctl file into [1;31mbuffer[m and then parsed to generate table
    descriptors. If table descriptor is larger in size than [1;31mbuffer[m
    used for reading from .ctl file, only part of descriptor is
    readable from [1;31mbuffer[m. So [1;31mbuffer[med read always fails and
    ndb_restore errors out.
    
    Increased size of [1;31mbuffer[m used for file reads.

[33mcommit b966242d09f9d1d02122a81b41947a2fa3a073cc[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Fri Jun 24 16:20:33 2016 +0530

    Bug #25260091: BACKPORT BUG 23152979 TO 7.2
    
    DESCRIPTION
    ===========
    Buffer overflow is reported in a lot of code sections spanning
    across ndb code.
    If not handled propoerly, they can cause abnormal behaviour.
    
    ANALYSIS
    ========
    The reported cases are the ones which are likely to cause
    SEGFAULT, MEMORY LEAK etc.
    The function readDataPrivate has a memcpy() that could lead
    to [1;31mbuffer[m overflow.
    Possible [1;31mbuffer[m overflow due to strcat() in get_prefix_buf().
    ndb_end() not called in many places due to which memory leaks
    could happen.
    
    FIX
    ===
    1) Made modifications in code paths leading to readDataPrivate
    to prevent [1;31mbuffer[m overflow:
    
     (i) sql/ha_ndbcluster_binlog.cc: Passed size of buf instead of
     passing UINT_MAX as the "bytes" arg.
     (ii) Added a require() in storage/ndb/tools/ndb_lib_move_data.cpp,
     to make sure "length1" is lesser than or equal to the [1;31mbuffer[m
     size.
    
    2) Added a require() in get_prefix_buf().
    
    3) Added an inline funcion ndb_end_exit() that calls ndb_end() and
    then exits from the program. Substitued return/exit() with ndb_end_exit()
    in places where ndb_end() was missing.
    
    (cherry picked from commit 49400ead2657504457d7b4c0c0b3a3710c6eabfb)
    
    Conflicts:
            storage/ndb/src/common/portlib/NdbConfig.c
            storage/ndb/src/kernel/blocks/dbdih/printFragfile.cpp

[33mcommit 7187b6dc451433ee6274a4738576f7a65ae40d84[m
Author: Oystein Grovlen <oystein.grovlen@oracle.com>
Date:   Tue Dec 6 08:46:09 2016 +0100

    WL#8737 IO aware defaults for optimizer cost constants
    Addendum: Stabilize some long-running tests
    
    Tests that runs long with much data got unstable cost estimates after
    WL#8737 since InnoDB would not necessarily have all of tables/indexes
    in [1;31mbuffer[m pool for the entire test.
    
    mysql-test/include/index_merge_ror.inc
    mysql-test/r/index_merge_innodb.result
    mysql-test/r/index_merge_myisam.result
      Mask entire cost estimates, not just decimals.
    
    mysql-test/r/greedy_search.result
    mysql-test/t/greedy_search.test
      Set memory_block_read_cost equal to io_block_read_cost to make plan
      search independent on how much data is cached in [1;31mbuffer[m pool.

[33mcommit 3b73f56899719eaf397bb85635aecee84702b78d[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Fri Nov 11 10:01:50 2016 +0100

    Bug#24909223: EXCESSIVE MEMORY USAGE BY QUERY
    
    Problem: A block nested loop sometimes allocates a new record [1;31mbuffer[m
    each time it restarts reading of the inner table. Since the record
    [1;31mbuffer[ms are not freed until the executing statement has completed,
    this leads to growing memory usage during the execution of the query.
    
    Fix: When reopening a handler that has already allocated a record
    [1;31mbuffer[m earlier in the same statement, reuse the previously allocated
    [1;31mbuffer[m instead of allocating a new one.

[33mcommit 075acb08ad5ebaf3425ab3c3bcfd2c38252854f3[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Dec 1 11:15:54 2016 +0100

    Bug #24526123 ADAPTIVE SEND ALGORITHM IS BROKEN
    
    The 'adaptive send strategy' was physically removed from the
    code as part of the 'ATC-patches' and 'forceSend' enforce
    independent of which kind of 'send' was specified.
    
    This patch reintroduce an improved version of the adaptive
    send algorithm. Performance test shows that it performs equal
    with the 'force*send' for a lower number ( <= ~20) of client
    threads, and performs increasingly better with higher number
    of threads.
    
    Details from the patch:
    
    part 1:
        Introduce the TransporterFacade member 'NodeBitmask m_active_nodes'
        which is a bitmap of all m_send_[1;31mbuffer[ms[MAX_NODES] having
        '::m_node_active == true'
    
        Replace the loop(s) iterating m_send_biffers[] from
        1..MAX_NODES to instead iterate the set bits in m_active_nodes.
    
    Part2:
        Introduce the TransporterFacade member
        'Uint32 m_poll_waiters'. Keep track of number of trp_clients
        waiting in the receiver poll queue.
    
        Will later be used as a metric to measure the API
        activity level in the adaptive send algorithm.
    
    Part3:
        Fix const correctness in methods related to 'send'
    
    Part4:
        Introduce the trp_client member
        'NodeBitmask m_flushed_nodes_mask' containing the set
        of nodes this trp_client has flushed, but possibly unsent,
        messages to.
    
    Part5:
        Introduce the TransporterFacade::TFSendBuffer member
        'Uint32 m_flushed_cnt'. Will count the number of 'flush' to
        this [1;31mbuffer[m which has not yet been sent.
    
        Will later be used as a metric to the adaptive flush
        algorithm to decide whether a message should be sent immediately,
        or if we should wait for possible some more messages to the
        same node to become available.
    
    Part6: refactor:
    
        - Refactor the common 'send to all nodes' loop found in
          both the send thread and in ::do_forceSend() into the
          new method try_send_all().
    
        - Factored out the 'send part' from ::flush_and_send_[1;31mbuffer[m()
          into the new method ::try_send_[1;31mbuffer[m()
    
        - Entirely removed the method flush_and_send_[1;31mbuffer[m().
          Replaced with first calling flush_send_[1;31mbuffer[m(),
          then try_send_all()
    
        - Introduced the new TransporterFacade member
          'NodeBitmask m_has_data_nodes' which maintain the set
          of datanodes having 'more_data' to be sent. These will
          need attention from the send thread.
    
        - Refactor the send thread to take advantage of new methods
          and members above. Instead of sending to all 'active'
          nodes in each iteration, it will now only send to the
          nodes which 'has_data' - Except every 'sendThreadWaitMillisec'
          where it will also include all 'active' nodes.
    
        - Refactor trp_client::do_forceSend() to take advantage
          of new members above. No functional change (yet)
    
    Part7:
        Introduce NdbCondition_ComputeAbsTime_ns()
    
        The existing NdbCondition_ComputeAbsTime() takes a millisecond
        argument to calculate an 'AbsTime' for the conditional wait
        to wait until. The adaptive send algorithm will need
        an 'AbsTime' caculation with at least micro second resolution.
    
    Part8:
        Introduce the adaptive send
        algorithm. Change trp_client::do_forceSend() to
        use the send type specified instead of always 'forceSend'.
    
        See patch itself for fairly extensive comments about
        how the adaptive send is implemented.

[33mcommit 5fa1980a784b42247a8d0ca377b6eb9f6d6ab8db[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Nov 29 08:28:22 2016 +0100

    Bug#25148549 REVISIT COMPILER FLAGS FOR ORACLE DEVELOPER STUDIO
    
    Post-push fix: Check for CMAKE_BUILD_TYPE = Release or RelWithDebInfo
    when compiling item_geofunc_[1;31mbuffer[m.cc in optimized mode.

[33mcommit 4bf48e8bf0d572fafc0349a3d7e9376b781a1302[m
Author: Oystein Grovlen <oystein.grovlen@oracle.com>
Date:   Fri Nov 25 13:32:20 2016 +0100

    WL#8737 IO aware defaults for optimizer cost constants
    
    Update default values for optimizer cost constants. New values are:
    
      row_evaluate_cost             0.1
      key_compare_cost              0.05
      memory_temptable_create_cost  1.0
      memory_temptable_row_cost     0.1
      disk_temptable_create_cost    20.0
      disk_temptable_row_cost       0.5
      memory_block_read_cost        0.25
      io_block_read_cost            1.0
    
    Changes to source files:
    
    sql/opt_costconstants.cc
      Changed default values for cost constants.
    sql/sql_select.h
      Change type of JOIN_TAB::read_time from ha_rows to double since cost may now
      be lower than 1.
    sql/sql_optimizer.cc
    sql/sql_select.cc
      Removed casts when assigning to/from JOIN_TAB::read_time
    unittest/gunit/opt_costconstants-t.cc
      Updated unit tests to use new values for cost constants
    
    Changes in tests:
    
    mysql-test/include/join_cache.inc
      Added more data in one table to preserve original query plan.
    mysql-test/include/mix1.inc
      Added more data in in two tables to preserve original query plan.
    mysql-test/r/count_distinct.result
      User variable changed because plans go from BNL to ref access
    mysql-test/t/dd_is_compatibility.test
    mysql-test/r/dd_is_compatibility.result
    mysql-test/r/dd_is_compatibility_ci.result
      Lowered setting of max_join_size to make sure test still get ER_TOO_BIG_SELECT
    mysql-test/r/delete.result
      Changed join order gives more warnings
    mysql-test/r/endspace.result
      Query returned result in different order, re-recorded.
    mysql-test/r/explain.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_rqg_json.result
      Change in two query plans, updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_rqg_trad.result
      Change in one query plan, updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_for_connection_small_json.result
    mysql-test/r/explain_for_connection_small_trad.result
      One query changes from table scan to ref access, due to magic constants
      added when calculating cost for tables scan. Two queries changes from
      index scan to ref access due to lower cost of doing ref access. Updated cost
      numbers in EXPLAIN JSON.
    mysql-test/r/explain_json_all.result
      Re-recorded new query plan for one query since it no longer tested
      what the original test was for. Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/explain_json_none.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/explain_other.test
    mysql-test/r/explain_other.result
      Added more data to one table in order to preserver original query plan.
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/func_concat.result
      Changed from table scan with BNL to eq_ref access.
      The new plan is identical to the plan when the test case was added.
    mysql-test/r/greedy_optimizer.result
      Several queries got new query plan. All new query plans resulted in a
      lower number of Handler_reads. Updated Last_query_cost numbers.
    mysql-test/r/greedy_search.result
      No changes in query plans but the number of partial plans evaluated
      was changed for several queries.
    mysql-test/r/group_by.result
      Changed from table scan with BNL to ref access
    mysql-test/r/group_min_max.result
      Four queries changes from doing index scan to use range scan due to
      range scan becoming cheaper with all data in memory [1;31mbuffer[m.
    mysql-test/r/heap_hash.result
      One query changes from using join [1;31mbuffer[m to use ref access for join.
      This is what the original test used, accepted new plan.
    mysql-test/r/index_merge_innodb.result
      One query changes from ref to range. This is caused by using DS-MRR for the
      range scan. Updated cost numbers in EXPLAIN JSON.
    mysql-test/include/index_merge_intersect_dml.inc
    mysql-test/r/index_merge_intersect_dml.result
      One query changed from doing range scan on primary key to range scan on
      secondary key. Changed query to switch back to use primary key.
    mysql-test/r/index_merge_myisam.result
    mysql-test/r/innodb_explain_json_non_select_all.result
    mysql-test/r/innodb_explain_json_non_select_none.result
    mysql-test/r/internal_tmp_disk_storage_engine.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/join.test
    mysql-test/r/join.result
      Query plan changes for two queries. First fixed by increasing the range
      interval in the query. The second query changes from table scan to
      eq_ref for one table, re-recorded new query plan. Updated Last_query_cost
      numbers.
    mysql-test/r/join_cache_bka.result
      Four queries changes from using BNL to use BKA/ref access.
    mysql-test/r/join_cache_bka_nixbnl.result
      One query changes from table scan to BKA/ref access.
      One query changes join order
    mysql-test/r/join_cache_bkaunique.result
      Four queries changes from using BNL to use BKA-unique/ref access.
    mysql-test/r/join_cache_bnl.result
      Four queries changes from using BNL to use ref access due to ref access
      becoming cheaper with all data in a memory [1;31mbuffer[m.
    mysql-test/r/join_cache_nojb.result
      Changed join order for one query due to ref access becomming relatively
      less costly compared to table scan when all data is in a memory [1;31mbuffer[m.
    mysql-test/r/join_outer.result
      Changes in order of results from a few queries, re-recorded. Updated cost
      numbers in EXPLAIN JSON.
    mysql-test/r/join_outer_bka.result
    mysql-test/r/join_outer_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/key.result
      Updated Last_query_cost numbers.
    mysql-test/r/key_diff.result
      One query changes from using join [1;31mbuffer[ming to ref access. The new plan
      has also been accepted as plan for this query before, so just use it.
    mysql-test/r/myisam.result
      One query changes from table scan to range scan, likely due to use of
      magic constants when calculating cost of table scan.
    mysql-test/r/myisam_explain_json_non_select_all.result
    mysql-test/r/myisam_explain_json_non_select_none.result
      Updated cost numbers in EXPLAIN JSON plus two rows estimates in explain.
    mysql-test/r/myisam_icp.result
    mysql-test/r/myisam_icp_all.result
    mysql-test/r/myisam_icp_none.result
      Changes to query plans for two bugs that was reported for InnoDB.
      Accepted changes since the plan is still the same when run with
      InnoDB.
    mysql-test/t/opt_costmodel.test
    mysql-test/r/opt_costmodel.result
    mysql-test/t/opt_costmodel_flush.test
    mysql-test/r/opt_costmodel_flush.result
      Updated to use new cost numbers, updated result files.
    mysql-test/r/opt_costmodel_restart.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/opt_hints.result
      Changes from ref access to range access. Does not affect purpose of test
    mysql-test/t/opt_hints_subquery.test
    mysql-test/r/opt_hints_subquery.result
      A lot of changes to explain output:
      -Most of the changes are from using join [1;31mbuffer[m to ref access (ok)
      -Some changes are in join order (ok)
      -Some changes are in semijoin strategy; adjusted test cases so hints
       are used according to original purpose of tests.
    mysql-test/r/order_by_all.result
    mysql-test/r/order_by_icp_mrr.result
    mysql-test/r/order_by_none.result
      Two queries joining three tables changes join order. The new query plans are
      equal to earlier query plans, so no attempt on reproducing current query
      plans.
    mysql-test/r/partition.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/t/partition_locking.test
    mysql-test/r/partition_locking.result
      Many queries changed from doing index scan to range scan. Adjusted
      the queries to use index scan. For the last query, the plan change
      is accepted since it is the same as the initial query plan.
    mysql-test/t/partition_pruning.test
    mysql-test/r/partition_pruning.result
      Two queries changed from table scan to range scan. Adjusted queries
      to produce same plan.
    mysql-test/r/range_all.result
    mysql-test/r/range_icp.result
    mysql-test/r/range_icp_mrr.result
    mysql-test/r/range_mrr.result
    mysql-test/r/range_mrr_cost.result
    mysql-test/r/range_none.result
    mysql-test/r/range_with_memory_limit.result
      Change in three query plans. The first is due to range scan becoming cheaper
      than table scan, and join [1;31mbuffer[ming is no longer considered. The two last is
      Change in join order due to differences in cost estimate for ref access
      versus join [1;31mbuffer[ming. The new plan is more similar to initial plan for
      these two queries.
    mysql-test/include/select.inc
    mysql-test/r/select_all.result
    mysql-test/r/select_all_bka.result
    mysql-test/r/select_icp_mrr.result
    mysql-test/r/select_icp_mrr_bka.result
      Two identical queries switches from using join [1;31mbuffer[ming to use ref access.
      Change accepted since ref access was the original join method for these
      queries.
    mysql-test/r/select_none.result
    mysql-test/r/select_none_bka.result
    mysql-test/r/select_none_bka_nixbnl.result
      In addition to the two queries above, a third query changes from table
      scan to range scan due to range access is cheaper with all data in memory.
      Accepted new plan since range scan was the origianal plan when the bug
      was first fixed.
    mysql-test/r/select_all_bka_nixbnl.result
    mysql-test/r/select_icp_mrr_nixbnl.result
      Updated result file after adding sorted_result for two queries in select.inc
    mysql-test/t/select_safe.test
    mysql-test/r/select_safe.result
      Adjusted value for max_join_size to make query fail.
    mysql-test/t/single_delete_update.test
    mysql-test/r/single_delete_update.result
      Two limit queries changed from doing file sort to using index. The
      test assumed that is should use filesort, so increased the limit to
      produce original query plan. Needed to adjust some other parts of
      the test due to this.
    mysql-test/r/status.result
      Updated Last_query_cost numbers.
    mysql-test/r/subquery_all.result
    mysql-test/r/subquery_all_bka.result
      Five queries have changes in query plans:
      -Change from using join [1;31mbuffer[m to ref access due to ref access is less costly
       with all data in memory [1;31mbuffer[m.
      -Join order changes due to minor changes in cost estimates, the new
       plan is identical to a former plan for this query.
      -Last three queries change from using join [1;31mbuffer[ming to use ref access
       due to ref access is less costly with data in memory. The query plan for
       these queries has changed several times so no effort on reproducing
       original plan.
    mysql-test/r/subquery_all_bka_nixbnl.result
      Join order changes for one query due to minor changes in cost estimates,
      the new plan is identical to a former plan for this query.
    mysql-test/r/subquery_mat_all.result
      Several queries changes from using DuplicateWeedout to FirstMatch due
      to the cost of FirstMatch reading data is now lower compared to using
      the temporary table. The query plan for these queries have changed
      several times so no attempt on reproducing original query plan.
    mysql-test/r/subquery_nomat_nosj.result
    mysql-test/r/subquery_nomat_nosj_bka.result
    mysql-test/r/subquery_none.result
    mysql-test/r/subquery_none_bka.result
      Join order changes for two queries due to minor changes in cost estimates.
    mysql-test/r/subquery_nomat_nosj_bka_nixbnl.result
    mysql-test/r/subquery_none_bka_nixbnl.result
      Join order change for one query due to minor changes in cost estimates.
    mysql-test/r/subquery_sj_all.result
    mysql-test/r/subquery_sj_all_bka.result
    mysql-test/r/subquery_sj_all_bka_nixbnl.result
    mysql-test/r/subquery_sj_all_bkaunique.result
      About 25 queries has changes in query plans:
      -Materialization to FirstMatch: FirstMatch becomes cheaper due to the
       cost of reading the data when it is in memory is now lower
      -Materialization to DupsWeedOut: Some of the changes are due to
       materialization and dupsweedout having the exact same cost and the change
       is caused by rounding errors. In a few cases, the cost of DupsWeedOut
       is now lower than Materialization.
      -DupsWeedout to FirstMatch: FirstMatch benefits more from having all
       data in a memory [1;31mbuffer[m
      -Join method: Changing from using join [1;31mbuffer[m to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory [1;31mbuffer[m
    mysql-test/r/subquery_sj_dupsweed.result
    mysql-test/r/subquery_sj_dupsweed_bka.result
    mysql-test/r/subquery_sj_dupsweed_bka_nixbnl.result
    mysql-test/r/subquery_sj_dupsweed_bkaunique.result
      A few queries have changes in query plan, no changes in semi-join strategy:
      -Join method: Changing from using join [1;31mbuffer[m to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory [1;31mbuffer[m.
       This causes changes to join order.
    mysql-test/r/subquery_sj_firstmatch.result
    mysql-test/r/subquery_sj_firstmatch_bka.result
    mysql-test/r/subquery_sj_firstmatch_bkaunique.result
      A few queries have changes in query plan, no change in semi-join strategy:
      -Join method: Changing from using join [1;31mbuffer[m to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory [1;31mbuffer[m.
       This causes changes to join order.
    mysql-test/r/subquery_sj_firstmatch_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/subquery_sj_loosescan.result
    mysql-test/r/subquery_sj_loosescan_bka.result
    mysql-test/r/subquery_sj_loosescan_bka_nixbnl.result
    mysql-test/r/subquery_sj_loosescan_bkaunique.result
      A few queries have changes in query plan, no change in semi-join strategy:
      -Join order: due to changes in cost estimates, verified that current
       plan is not the same as origianal plan, so just re-recorded.
      -Join method: Changing from using join [1;31mbuffer[m to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory [1;31mbuffer[m.
       This causes changes to join order.
    mysql-test/r/subquery_sj_mat.result
    mysql-test/r/subquery_sj_mat_bka.result
    mysql-test/r/subquery_sj_mat_bka_nixbnl.result
    mysql-test/r/subquery_sj_mat_bkaunique.result
      A few queries have changes in query plan:
      -Join order: due to changes in cost estimates, verified that current
       plan is not the same as origianal plan, so just re-recorded.
      -Join method: Changing from using join [1;31mbuffer[m to use eq_ref or ref:
       eq_ref and ref get a lower cost when all data is in a memory [1;31mbuffer[m.
       This causes changes to join order.
      -One query changes from MaterializeLookup to MaterializeScan.
    mysql-test/r/subquery_sj_mat_nosj.result
      A few queries change from using join [1;31mbuffer[m to use eq_ref or ref:
      eq_ref and ref get a lower cost when all data is in a memory [1;31mbuffer[m. This
      causes changes to join order.
    mysql-test/r/subquery_sj_none.result
    mysql-test/r/subquery_sj_none_bka.result
    mysql-test/r/subquery_sj_none_bkaunique.result
      One query changes from using join [1;31mbuffer[m to use eq_ref or ref:
      eq_ref and ref get a lower cost when all data is in a memory [1;31mbuffer[m. This
      causes changes to join order.
    mysql-test/r/subquery_sj_none_bka_nixbnl.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/r/type_blob.result
      Change from ALL to ref_or_null.  Back to plan before switch to InnoDB
    mysql-test/r/type_ranges.result
      Order of warnings changed for an INSERT INTO SELECT statement likely due
      to plan change. Re-recorded result file.
    mysql-test/r/user_var.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/engines/iuds/r/insert_calendar.result
    mysql-test/suite/engines/iuds/t/insert_calendar.test
      Different plans for MyISAM and InnoDB caused different number of warnings.
      Changed start date for range for query to avoid warnings for zero date.
    mysql-test/suite/gcol/inc/gcol_ins_upd.inc
    mysql-test/suite/gcol/r/gcol_ins_upd_innodb.result
    mysql-test/suite/gcol/r/gcol_ins_upd_myisam.result
      Added sorted_result to some queries to handle that the order of the
      result changes. This happened for the MyISAM test, the InnoDB test
      had the same order.
    mysql-test/suite/gcol/r/gcol_keys_innodb.result
    mysql-test/suite/gcol/r/gcol_keys_myisam.result
      Changed plans from table scan to index usage
    mysql-test/suite/gcol/r/gcol_select_myisam.result
      One query changes join order and switches from join [1;31mbuffer[ming to ref
      access.
    mysql-test/suite/gcol/r/gcol_select_innodb.result
      One query changes from using join [1;31mbuffer[ming to do ref access. This is
      caused by table scan becoming relatively more costly compared to ref
      access.
    mysql-test/suite/innodb/t/innodb_mysql.test
    mysql-test/suite/innodb/r/innodb_mysql.result
      Added extra rows to a few tables to preserve original query plan.
    mysql-test/suite/innodb/include/query_workload_itt.inc
    mysql-test/suite/innodb/r/optimizer_temporary_table.result
      Cost estimates of EXPLAIN JSON was unstable since one table was not used
      for a while and sometimes its pages was flushed from [1;31mbuffer[m pool.
      Added a query that does a table scan to ensure that pages are in [1;31mbuffer[m pool.
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/innodb_gis/r/create_spatial_index.result
    mysql-test/suite/innodb_gis/r/rtree.result
    mysql-test/suite/innodb_gis/r/rtree_multi_pk.result
      Changes in query plans from full table/index scan to range scan
      Queries will now actually use a spatial index
    mysql-test/suite/innodb/r/temporary_table.result
    mysql-test/suite/innodb/r/temporary_table_optimization.result
    mysql-test/suite/innodb_zip/r/wl6469.result
    mysql-test/suite/innodb_zip/r/wl6560.result
      A few queries changes from table scan to range scan due to use of magic
      constants in the cost model for table scan.
    mysql-test/suite/innodb_fts/r/opt.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/json/r/json_agg.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/opt_trace/r/bugs_no_prot_all.result
    mysql-test/suite/opt_trace/r/bugs_ps_prot_all.result
      Updated cost estimate numbers in optimizer trace output.
      There are a few minor changes in the optimizer trace output
      and a few plan changes.
    mysql-test/suite/opt_trace/r/bugs_no_prot_none.result
    mysql-test/suite/opt_trace/r/bugs_ps_prot_none.result
    mysql-test/suite/opt_trace/r/fulltext.result
    mysql-test/suite/opt_trace/r/general2_no_prot.result
    mysql-test/suite/opt_trace/r/general2_ps_prot.result
    mysql-test/suite/opt_trace/r/general_no_prot_none.result
    mysql-test/suite/opt_trace/r/general_ps_prot_none.result
    mysql-test/suite/opt_trace/r/range_no_prot.result
    mysql-test/suite/opt_trace/r/range_ps_prot.result
      Updated cost estimate numbers in optimizer trace output.
      There are a few tiny minor change in the optimizer trace output.
    mysql-test/suite/opt_trace/r/charset.result
    mysql-test/suite/opt_trace/r/eq_range_statistics.result
    mysql-test/suite/opt_trace/r/filesort_pack.result
    mysql-test/suite/opt_trace/r/filesort_pq.result
    mysql-test/suite/opt_trace/r/general_no_prot_all.result
    mysql-test/suite/opt_trace/r/general_ps_prot_all.result
    mysql-test/suite/opt_trace/r/subquery_no_prot.result
    mysql-test/suite/opt_trace/r/subquery_ps_prot.result
    mysql-test/suite/opt_trace/r/temp_table.result
      Updated cost estimate numbers in optimizer trace output.
    mysql-test/suite/opt_trace/r/security_no_prot.result
    mysql-test/suite/opt_trace/r/security_ps_prot.result
      Updated length numbers for optimizer trace output.
    mysql-test/suite/parts/r/partition_icp.result
      Updated cost numbers in EXPLAIN JSON.
    mysql-test/suite/sysschema/r/pr_statement_performance_analyzer.result
      Changed query plans give different number for rows_examined
    mysql-test/suite/sys_vars/r/max_join_size_func.result
    mysql-test/suite/sys_vars/r/sql_big_selects_func.result
    mysql-test/suite/sys_vars/t/max_join_size_func.test
    mysql-test/suite/sys_vars/t/sql_big_selects_func.test
      Reduced value for max_join_size to make queries fail with new cost constants.
    mysql-test/suite/test_service_sql_api/r/test_sql_stmt.result
      Changed result order due to different access method
    mysql-test/suite/i_main/r/bug18932813.result
    mysql-test/suite/i_main/r/derived.result
    mysql-test/suite/i_main/r/explain_json.result
    mysql-test/suite/i_main/r/group_by.result
    mysql-test/suite/i_main/r/partition_icp.result
    mysql-test/suite/i_main/r/subquery_mat_cost_based.result
    mysql-test/suite/i_main/r/view.result
      Updated cost numbers in EXPLAIN JSON.
    .../mysql-test/suite/i_main/r/bug22671573.result
      Plan changed from table scan to range scan.
      Verified that test case still reproduce the original bug.
    .../mysql-test/suite/i_main/r/costmodel_planchange.result
      Adjust queries to still identify plan changes
    .../mysql-test/suite/i_main/t/insert.test
    .../mysql-test/suite/i_main/r/insert.result
      Added data to keep same query plan
    .../mysql-test/suite/i_main/t/subquery-bug22262843.test
    .../mysql-test/suite/i_main/r/subquery-bug22262843.result
      Added a row so that subquery materialization is still used.
    .../mysql-test/suite/i_main/t/subquery.test
    .../mysql-test/suite/i_main/r/subquery.result
      Added data to keep on query plan
      Some changes from table scan (with BNL) to ref access
      Some semijoin strategy changes that seems reasonable
    .../mysql-test/suite/i_opt_trace/include/bugs.inc
      Added analyze table to make test stable
    .../mysql-test/suite/i_opt_trace/r/bugs_no_prot.result
    .../mysql-test/suite/i_opt_trace/r/bugs_ps_prot.result
    .../mysql-test/suite/i_opt_trace/r/query_cache_trace.result
      Updated cost numbers in EXPLAIN JSON.
    .../mysql-test/suite/i_opt_trace/r/refaccess_trace.result
      One query plan goes from table scan to eq_ref
      Updated cost numbers in EXPLAIN JSON.
    
    Implemented by Olav Sandstå

[33mcommit c8688ce85e99ad038de0a0be78eb47991f3589a1[m
Author: Joao Gramacho <joao.gramacho@oracle.com>
Date:   Wed Oct 5 13:13:29 2016 +0100

    Bug#24710786 STRING OBJECTS SHOULD ALLOW CUSTOM PSI_MEMORY_KEY USAGE
    
    Problem:
    
    It is not possible to monitor Binlog_sender event [1;31mbuffer[m memory
    consumption deterministically because its memory consumption is tied on
    the String memory consumption.
    
    Fix:
    
    Added a String::set_psi_memory_key method.
    
    This patch changed the Binlog_sender to use Binlog_sender::packet as PSI
    memory key for its sender [1;31mbuffer[m and also changed he related test case
    rpl_binlog_sender_packet_shrink.test to use same PSI memory key.

[33mcommit c590a0b61a5f45c17c1546a44620b37e65b141e5[m
Author: Bharathy Satish <bharathy.x.satish@oracle.com>
Date:   Wed Nov 16 12:43:32 2016 +0100

    Bug #24613005: SET PERSIST STORES PREVIOUS VALUE OF INNODB_BUFFER_POOL_SIZE
                   TO MYSQLD-AUTO.CNF
    SET PERSIST innodb_[1;31mbuffer[m_pool_size= <value> writes old value to config file.
    Fixed it by copying the new value into appropriate [1;31mbuffer[m so that correct
    value is reflected in config file.

[33mcommit f717e0567457e8a0d513ac17ff63d62e3dc0670d[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Oct 27 13:56:44 2016 +0200

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    When writing a big-endian 16-bit weight to the [1;31mbuffer[m, do it in one go
    (using htons and memcpy) rather than shifting and masking ourselves;
    seemingly GCC doesn't manage to combine the two writes. (The htons()
    is rewritten to a 16-bit rotate-by-8, which is efficient although it
    is contrary to Intel's recommendation to use XCHG AL, AH.)
    
    Microbenchmark results (Skylake 3.4 GHz, opt, GCC 6.2):
    
      BM_SimpleUTF8MB4          375 ->  309 ns/iter  [+21.4%]
      BM_MixedUTF8MB4           316 ->  307 ns/iter  [ +1.3%]
      BM_MixedUTF8MB4_AS_CS    1041 ->  982 ns/iter  [ +6.1%]
    
    sysbench goes from 10825 -> 11136 tps (+2.9%).
    
    Change-Id: Ifa54a02456dcaec808bef2fc4fb5c6d2158133d7

[33mcommit 16b91a041f32bf701ad7df2b3b03cddf1df624b2[m
Author: Mauritz Sundell <mauritz.sundell@oracle.com>
Date:   Thu Nov 3 18:21:13 2016 +0100

    Add row for Long message [1;31mbuffer[m in view ndbinfo.memoryusage in ndbinfo_sql.
    
    Added earlier in mysql_system_tables.sql

[33mcommit cd1efb89ab105fb369e00a37db0372bfae5ce80e[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Fri Nov 4 15:22:10 2016 +0100

    Bug#24464763 MOST PERFSCHEMA.*_IO TESTS FAIL IF GIS.SRS RUNS BEFORE THEM ON
    THE WORKER
    
    This is a test script fix only, to improve test robustness.
    
    Before this fix, some tests failed with spurious diff related to
      Performance_schema_rwlock_instances_lost
    in the result file.
    
    This is due to the MTR suite default configuration,
    default_mysqld.cnf, which uses a fixed number of instrumented objects:
    for some combinations of tests, the number of items actually instrumented
    during the test payload can exceed artificial limits set in the test cnf.
    
    The fix is to relax limits on the number of instrumented objects,
    and rely on performance schema [1;31mbuffer[ms scaling automatically
    based on the load.
    
    Adjusted the test results accordingly.

[33mcommit 9146bf9601889bc17270af473481a9d457ae0541[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Mon Oct 31 22:00:32 2016 -0500

    Bug#24916359 - Test Case table_encrypt_kill.test fails sporadically
    
    The failure would occur after a crash, after redo log recovery.
    Redo recovery would open an undo tablespace from the MLOG_FILE_NAME
    log entry.  Later in srv_undo_tablespace_init(), srv_undo_tablespace_open()
    will skip this file since it has already been opened. Instead, it used the
    previous fil_space_t object. But for some reason the node->size would
    sporadically be zero. This zero size causes the reported error during a
    later call to fil_io().
    
    The fil_space_t object created by redo log recovery has other problems.
    It uses the file name as the tablespace name, which includes the path.
    And it does not know that this is an undo tablesapce so it puts the
    object onto the LRU, which it should not be.  There may be other issues
    with this object as well.
    
    The solution is to not only flush and close that fil_space_t object but
    to also free it. This allows srv_undo_tablespaces_open() to create a new
    one correctly. It is reopened from scratch with a new fil_space_t object
    as if it was not part of redo log recovery, which is already completed by
    this time during startup.
    
    In addition, testing has shown that it is possible for the header page
    of this undo tabelspace to be in the [1;31mbuffer[m cache when the fil_space_t
    object is freed.  The presence of this page in cache can cause the file
    not to be opened upon the first page read and then an assert in fil_io()
    can be hit when the file is not yet opened.  So fil_undo_tablespace_open()
    will now call fil_space_open() after it has successfully created the
    fil_space_t and fil_node_t objects and incremented srv_undo_tablespaces_open.

[33mcommit e0315768fe7da34b26dc3877dafac1aece0799de[m
Author: Steinar H. Gunderson <steinar.gunderson@oracle.com>
Date:   Thu Oct 27 12:46:06 2016 +0200

    Bug #24823885: PERFORMANCE REGRESSION WHEN CHANGING CHARACTER SET TO UTF8MB4
    
    Increase max_length_for_sort_data from 1024 to 4096.
    
    This parameter controls the threshold for when we stop sorting full rows,
    and instead just sort the sort key plus a row ID, and then go back to the
    table to pick up those rows afterwards.
    
    Since this parameter was introduced and got its current value in 2003,
    several important things have happened:
    
     - Computers have gotten more RAM, so that sort [1;31mbuffer[ms can be larger.
     - We have switched from MyISAM to InnoDB, where picking out a row by ID
       is much more expensive.
     - Unicode collations, for which we grossly overestimate row size in the
       typical case (we assume the string is completely filled with maximum-length
       UTF-8 characters, whereas the typical is more like a 10–20% fill grade
       with ASCII), have become commonplace.
    
    Thus, increase this value; the actual value chosen is a bit arbitrary and would
    benefit from actual benchmarks across a wide variety of real loads, but it's
    obviously a step in the right direction.
    
    sysbench result goes from 7080 -> 9078 tps (+28.2%).
    
    Change-Id: I031ded33e5a18ca903b4549b5692563137672408

[33mcommit c7157dccc1e21d8a13ff4bd900bc30864f39f5f4[m
Author: Dinesh Surya Prakash <dinesh.prakash@oracle.com>
Date:   Thu Oct 13 17:15:20 2016 +0530

    A call to system function malloc is not checked for null in function
    MgmApiSession::list_session.In this function, malloc is used to create a
    temp [1;31mbuffer[m, which we use to create a message and write to the socket in
    single shot.
    
    So, when we encounter malloc failure, instead of writing to socket, now
    we will close the socket as the write also usesmalloc and will eventually
    fails.

[33mcommit d51d9a5f7274be7f5b7124e1af2a5c4e395111ac[m
Author: Dinesh Surya Prakash <dinesh.prakash@oracle.com>
Date:   Thu Oct 13 17:15:20 2016 +0530

    A call to system function malloc is not checked for null in function
    MgmApiSession::list_session.In this function, malloc is used to create a
    temp [1;31mbuffer[m, which we use to create a message and write to the socket in
    single shot.
    
    So, when we encounter malloc failure, instead of writing to socket, now
    we will close the socket as the write also usesmalloc and will eventually
    fails.

[33mcommit 8b3b6d3342233d42e4dfef25af3e4d311a2d68fa[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Oct 12 18:50:47 2016 +0200

    Bug#22313205 PERFORMANCE_SCHEMA STATUS AND VARIABLES TABLES DO NOT HANDLE
    CHARSET PROPERLY
    
    Tables like performance_schema.session_variables can print string values.
    
    Before this fix, string values expressed in a character set different
    than UTf8 would be truncated or incorrect.
    
    This affects for example system variables expressed using
    the file system character set, like character_sets_dir.
    
    With the following options:
    --character-set-filesystem=latin1
    --character-sets-dir=<value in latin1 here>
    the value for character-sets-dir is printed incorrectly,
    because the latin1 value is printed as UTF8.
    
    The root cause is that string values for system variables are
    represented as a binary [1;31mbuffer[m internally, but the associated
    CHARSET_INFO is lost, later assumed to be UTF8.
    
    The fix is to preserve (CHARSET_INFO, string value, string value length)
    together when representing a system variable in the performance schema,
    and use the proper character set when populating the performance_schema
    table.

[33mcommit a2733e0cc41bafc237649f9b3ca6abc7a5d50762[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Tue Oct 4 18:43:30 2016 +0300

    Bug#24796251 ADD DEBUG CHECKS TO JOIN_CACHE
    
    In JOIN_CACHE::rem_space() there is a redundant std::max operation.
    We had better check that there is no overflow. Because code review
    suggests that overflow is not easily possible, we add DBUG_ASSERTs
    to catch any wrongdoing.
    
    Furthermore, assert that after JOIN_CACHE_BKA::init_mrr_buff()
    has been invoked, the join [1;31mbuffer[m is no longer be used by
    JOIN_CACHE::write_record_data() without prior
    JOIN_CACHE::reset_cache(for_writing=true).
    
    JOIN_CACHE_BKA::aux_buff_size: Moved from JOIN_CACHE.
    
    Also improve some comments and add static and const qualifiers.
    
    Reviewed-by: Knut Hatlen <knut.hatlen@oracle.com>

[33mcommit 58cf18730cd42cef542737261d97953f0bc696d8[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue Sep 27 10:58:15 2016 +0200

    Bug#22320066 EVENTS_STATEMENTS_SUMMARY_BY_DIGEST: NO UNIQUE ROWS BY
    DIGEST/SCHEMA_NAME
    
    Fix for trunk (8.0)
    
    Before this fix, table events_statements_summary_by_digest
    exposed many rows for the same statement digest and schema,
    breaking the expected uniqueness of digests.
    
    The root cause is in function find_or_create_digest(),
    which does not handle duplicate inserts in the LF_HASH properly.
    
    When two different sessions execute
    the same statement for the first time,
    each session creates an entry for the statement digest.
    
    In this case, the index is maintained properly with only one entry,
    but the table data itself still contained duplicated rows, orphan.
    
    The fix is to:
    - use a pfs_lock for a statement digest record
    - free the duplicate record when duplication is detected in the unique index
    - loop in the entire [1;31mbuffer[m to find an empty record,
      so that duplicate entries do not create holes and do not cause leaks
    - honor the pfs_lock when exposing the data.
    
    With this fix, the allocation pattern is similar to other instrumentations,
    like the mutex instances for example.
    
    Tested manually with debug code added to expose the race conditions.
    Not testable by MTR scripts.

[33mcommit 608e7c49569827e74ad05d0305ad35e241948ea4[m
Author: Dinesh Surya Prakash <dinesh.prakash@oracle.com>
Date:   Wed Sep 21 21:29:28 2016 +0530

    Bug#21271194 MISSING SANITY CHECK FOR MALLOC() IN SERVICES.CPP
    
    A call to system function malloc is not checked for null in function
    MgmApiSession::list_session. We cannot return error code for this failure
    because as per prototype this function returns void. So, by default the
    caller expects the function to be always success.
    
    In this function, malloc is used to create a temp [1;31mbuffer[m, which we use to
    create a message and write to the socket in single shot. If we
    write the message to the socket directly we can avoid the temp [1;31mbuffer[m.
    
    so, I fixed the bug by removing malloc and adding many write to the socket.

[33mcommit ef4bc923efaca2393671d5565e34248b1659239e[m
Author: Craig L Russell <craig.russell@oracle.com>
Date:   Mon Sep 19 16:48:08 2016 -0700

    Fix clusterj direct memory leaks
      clusterj would leak direct memory in several places:
      setting partition key
      setting bounds for scan
      setting scan filter
    
    SessionImpl.java
      avoid overwriting user-defined partition key
      release direct memory after setting partition key
    
    ValueHandler.java
      add release() method to value handler to allow release of direct memory
    
    ClusterConnectionImpl.java
      when initializing cluster connection, initialize ndbjtie method id cache
    
    DbImpl.java
      reimplement methods to get java wrapper objects for query helper objects
        IndexBound, NdbInterpretedCode, NdbScanFilter, ScanOptions
        optionally synchronize on an external object
        try to obtain helper object and if not successful, retry
        report an error if unsuccessful after 10 tries
    
    DbImplForNdbRecord.java
      add a method to initialize ndbjtie method id cache by
        getting an instance of each of the four types
        when initializing a cluster connection
    
    IndexScanOperationImpl.java
      reimplement setBound methods to borrow a direct [1;31mbuffer[m
        instead of allocating a new direct [1;31mbuffer[m which is leaked
    
    NdbRecordImpl.java
      optionally fill the NdbRecord with default values
      guard calls to logger.debug and logger.detail
    
    NdbRecordInsertOperationImpl.java
      acquire a new value [1;31mbuffer[m in constructor
    
    NdbRecordKeyOperationImpl.java
      acquire a new value [1;31mbuffer[m in constructor
    
    NdbRecordOperationImpl.java
      avoid acquiring a new value [1;31mbuffer[m for all operations
    
    NdbRecordScanOperationImpl.java
      use direct memory [1;31mbuffer[m pool for scan filter
      avoid allocating new value [1;31mbuffer[m if it is not going to be used
    
    NdbRecordScanResultDataImpl.java
      return borrowed value [1;31mbuffer[m if not used in scanOperation.nextResultCopyOut
    
    NdbRecordUniqueKeyOperationImpl.java
      acquire a new value [1;31mbuffer[m in constructor
    
    PartitionKeyImpl.java
      borrow direct [1;31mbuffer[ms for partition key and return them after the operation
    
    ScanFilterImpl.java
      borrow direct [1;31mbuffer[ms for scan filters and return them after the operation
    
    ScanOperationImpl.java
      constructor takes a [1;31mbuffer[m manager
    
    Utility.java
      implement convert functions taking a direct [1;31mbuffer[m as a parameter for
        byte, short, int, long, double, and float
    
    Bundle.properties
      add message for failure to acquire query helper class

[33mcommit ff0f3b1526e21ab87d998c781d827cd20fcb77b3[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Sep 1 15:58:04 2016 +0300

    Yet another attempt to get something useful out of pct_cached_evict.test
    
    Accept the non-deterministic behavior of
    evict_everything_from_[1;31mbuffer[m_pool.inc and if we see no decrease in the
    number of pct_cached_evict's pages then check the actual number of pages
    from information_schema.innodb_[1;31mbuffer[m_page and if it is the same as
    the one reported in information_schema.innodb_cached_indexes, then
    pretend everything is OK - the test was in vain in this case.
    
    Only fail if we see the actual number of pages from
    information_schema.innodb_[1;31mbuffer[m_page smaller than the one reported in
    information_schema.innodb_cached_indexes.

[33mcommit b645850e31d98d877c4764637adaf9732ffae152[m
Author: Dinesh Surya Prakash <dinesh.prakash@oracle.com>
Date:   Thu Jul 14 13:06:03 2016 +0530

    Bug#21286722 MISSING SANITY CHECKS FOR MALLOC() IN RESTORE.CPP, DBUTIL.CPP, SQLCLIENT.CPP
    
    PART 2: DBUTIL.CPPRT 2: DBUTIL.CPP
    
    In DBUTIL.CPP we create [1;31mbuffer[ms using system function malloc but we do not
    check for the failure. As this may lead to crash, have added validation
    to check the pointer for NULL.
    
    In DBUTIL.CPP we create [1;31mbuffer[ms using system function malloc but we do not
    check for the failure. As this may lead to crash, have added validation
    to check the pointer for NULL.

[33mcommit 87a0c874bdb56bf82a9431d8dc5e1d32a24018d4[m
Author: Dinesh Surya Prakash <dinesh.prakash@oracle.com>
Date:   Thu Jul 14 13:06:04 2016 +0530

    Bug#21286722 MISSING SANITY CHECKS FOR MALLOC() IN RESTORE.CPP, DBUTIL.CPP, SQLCLIENT.CPP
    
    PART 3: SQLCLIENT.CPP
    
    In SQLCLIENT.CPP, we create [1;31mbuffer[ms using system function malloc but we do not
    check for the failure. As this may lead to crash, have added validation
    to check the pointer for NULL.

[33mcommit c56bec27a809c291bf6ec135d6a39c2f285d28f9[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Aug 29 10:49:22 2016 +0300

    Attempt to stabilize pct_cached_evict.test
    
    Overflow the [1;31mbuffer[m pool with a table that is 2.0 bigger
    than it, not 1.1. InnoDB persists some old pages in the
    [1;31mbuffer[m pool (innodb_old_blocks_pct) so maybe a bigger table
    will help evict everything else.

[33mcommit a621063909e08294d01c65011717ea780db24a3b[m
Author: Dyre Tjeldvoll <Dyre.Tjeldvoll@oracle.com>
Date:   Wed Aug 10 14:29:27 2016 +0200

    Bug#24481933: STD::BASIC_STRING INSTANTIATION W/ PFS INSTRUMENTATION FOR THE DD
    
    Patch 2: Add a new PFS memory key to track memory used by strings in DD.
    
    The new PFS key key_memory_DD_String, will be used with Stateless_allocator to
    track memory allocated to store strings used in the DD code.
    
    Remove unused PFS keys related to frm files. Rename key_memory_frm to
    key_memory_DD_default_values as it is only used to allocate temporary [1;31mbuffer[ms
    backing Field objects when populating dd::Column objects from Create_field
    objects.

[33mcommit 95ac5a06ca11c1cebfae63729aeaf2766beba69b[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Fri Jun 24 16:20:33 2016 +0530

    Bug #23152979: CLUSTER: POSSIBLE BUFFER OVERFLOW ISSUES
    
    BACKPORTING patch to 7.3
    
    DESCRIPTION
    ===========
    Buffer overflow is reported in a lot of code sections spanning
    across ndb code.
    If not handled propoerly, they can cause abnormal behaviour.
    
    ANALYSIS
    ========
    The reported cases are the ones which are likely to cause
    SEGFAULT, MEMORY LEAK etc.
    The function readDataPrivate has a memcpy() that could lead
    to [1;31mbuffer[m overflow.
    Possible [1;31mbuffer[m overflow due to strcat() in get_prefix_buf().
    ndb_end() not called in many places due to which memory leaks
    could happen.
    
    FIX
    ===
    1) Made modifications in code paths leading to readDataPrivate
    to prevent [1;31mbuffer[m overflow:
    
     (i) sql/ha_ndbcluster_binlog.cc: Passed size of buf instead of
     passing UINT_MAX as the "bytes" arg.
     (ii) Added a require() in storage/ndb/tools/ndb_lib_move_data.cpp,
     to make sure "length1" is lesser than or equal to the [1;31mbuffer[m
     size.
    
    2) Added a require() in get_prefix_buf().
    
    3) Added an inline funcion ndb_end_exit() that calls ndb_end() and
    then exits from the program. Substitued return/exit() with ndb_end_exit()
    in places where ndb_end() was missing.
    
    (cherry picked from commit 49400ead2657504457d7b4c0c0b3a3710c6eabfb)
    
    Conflicts:
            storage/ndb/src/common/portlib/NdbConfig.c
            storage/ndb/src/kernel/blocks/dbdih/printFragfile.cpp

[33mcommit 3e1c876f53c46f4ffc7533b10dde912cb2b766a0[m
Author: Sanjana DS <sanjana.ds@oracle.com>
Date:   Fri Jun 24 16:20:33 2016 +0530

    Bug #23152979: CLUSTER: POSSIBLE BUFFER OVERFLOW ISSUES
    
    DESCRIPTION
    ===========
    Buffer overflow is reported in a lot of code sections spanning
    across ndb code.
    If not handled propoerly, they can cause abnormal behaviour.
    
    ANALYSIS
    ========
    The reported cases are the ones which are likely to cause
    SEGFAULT, MEMORY LEAK etc.
    The function readDataPrivate has a memcpy() that could lead
    to [1;31mbuffer[m overflow.
    Possible [1;31mbuffer[m overflow due to strcat() in get_prefix_buf().
    ndb_end() not called in many places due to which memory leaks
    could happen.
    
    FIX
    ===
    1) Made modifications in code paths leading to readDataPrivate
    to prevent [1;31mbuffer[m overflow:
    
     (i) sql/ha_ndbcluster_binlog.cc: Passed size of buf instead of
     passing UINT_MAX as the "bytes" arg.
     (ii) Added a require() in storage/ndb/tools/ndb_lib_move_data.cpp,
     to make sure "length1" is lesser than or equal to the [1;31mbuffer[m
     size.
    
    2) Added a require() in get_prefix_buf().
    
    3) Added an inline funcion ndb_end_exit() that calls ndb_end() and
    then exits from the program. Substitued return/exit() with ndb_end_exit()
    in places where ndb_end() was missing.

[33mcommit 3b1718b8150ea92166111798c5dc6a11a0e4bfeb[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Thu Aug 11 11:16:28 2016 +0800

    BUG#24287290 BUF POOL MUTEX ORDER VIOLATION IN BUF_POOL_RESIZE
                 WITH MULTIPLE INSTANCES
    
    It's a regression of wl#8423: InnoDB: Split the [1;31mbuffer[m pool mutex.
    
    In buf_pool_resize(), we enter all [1;31mbuffer[m pool mutexes for each
    [1;31mbuffer[m pool instance. we should enter a mutex a time for all
    intances to avoid mutex violation.
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 13614

[33mcommit 21abf7023c2bb21ff8d78c73e24ec637f2ab918a[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Fri Aug 5 12:09:21 2016 +0530

    BUG#23286919 : TEST CONTAINING CALL() STATEMENT FAILS WHEN RUN WITH --PS-PROTOCOL
    
    Post-push fix - Fix heap-[1;31mbuffer[m-overflow issue on ASAN platform.
    
    Reviewed-by: Deepa Dixit <deepa.dixit@oracle.com>

[33mcommit 625fd728a748a43503af84b53d0b8c6cddacac31[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon Aug 1 11:22:53 2016 +0200

    Patch for Bug#20112700 ASSERT(SHOULD_BE_EMPTY) IN \'RESET_SEND_BUFFER\'
    
    Assert in TransporterFacade::reset_send_[1;31mbuffer[ms as send [1;31mbuffer[ms
    were not empty as expected when reconnected to a node after
    a previous disconnect
    
    TransporterFacade::reset_send_[1;31mbuffer[m() reset the two-level
    send [1;31mbuffer[ms in the TransporterFacade. Whenever a node
    disconnected from the TransporterFacade, its send [1;31mbuffer[ms
    are reset (cleared). In addition to TransporterFacade
    send [1;31mbuffer[ms, each trp_client has its own send [1;31mbuffer[ms
    (Introduced as part of the 'ATC-patches', wl3860). These
    were introduced in order to reduce lock contention as each
    trp_client appends to the send [1;31mbuffer[ms. However, the
    trp_client's send [1;31mbuffer[ms were *not* cleared as part
    of TransporterFacade::reset_send_[1;31mbuffer[m().
    
    As the trp_client appended its send [1;31mbuffer[ms to the
    TransporterFacade send [1;31mbuffer[ms whenever it found fit,
    we could either:
    
    1) Append the trp_clients send [1;31mbuffer[m to the TransporterFacade
       after a node had disconnected. When it reconnected
       again, we found the TransporterFacade had a non-empty send [1;31mbuffer[m
       to the reconnected node which resulted in the assert in
       this bug-subject.
    
    2) (Possibly, but not proved:) The trp_client send [1;31mbuffer[ms could
       be flushed to the TransporterFacade after the node had
       disconnected *and reconnected* again. I am not sure what
       this could cause of strange behavior, but it would certainly not
       be very healthy for the system.
    
    This patch enhance TransporterFacade::reset_send_[1;31mbuffer[m() to also
    reset the send_[1;31mbuffer[ms of the trp_clients being known to
    the TransporterFacade. In order to provide concurrency protection
    of the TransporterFacade's set of trp_clients, this has to
    be done while holding the poll right: Thus, the call to
    ::reset_send_[1;31mbuffer[m() had to be moved from TransporterRegistry::do_connect()
    to TransporterRegistry::report_disconnect(). (Note ::report_disconnect()
    and ::report_connect() is only called by the poll owner!).
    
    Furthermore, the odd call to ::reset_send_[1;31mbuffer[m(..., should_be_empty=true)
    from within ::report_connect() has been removed. That call was mainly
    a safeguard / assert against send [1;31mbuffer[ms not being empty when we
    reconnected again. At this point the send [1;31mbuffer[ms should be empty,
    so an extra reset is redundant. If not empty, it would assert at this
    point. This call to reset_send_[1;31mbuffer[m was replaced with an assert check
    of the send [1;31mbuffer[ms really being empty (!has_data_to_send()). (Required
    a few non used implementations of the virtual ::has_data_to_send()
    to be fixed), The now non used argument 'should_be_empty' to
    reset_send_[1;31mbuffer[m() was removed as part of this.
    
    The patch also fix an issue with
    TransporterFacade::m_current_send_[1;31mbuffer[m_size neither being
    initialized by the C'tor, correctly updated by ::flush_send_[1;31mbuffer[m(),
    nor zero'ed by ::reset_send_[1;31mbuffer[m().

[33mcommit 167e00f246f2a30f85171d050bd23de46af970dd[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Tue Jul 19 10:40:32 2016 +0200

    WL#7093: Optimizer provides InnoDB with a bigger [1;31mbuffer[m
    
    This worklog introduces a record [1;31mbuffer[m which is allocated by the
    executor and given to the storage engine for fetching batches of
    records.
    
    InnoDB is changed to use the [1;31mbuffer[m instead of its own prefetch cache
    if a record [1;31mbuffer[m has been provided.

[33mcommit 6415e07df16bed75e737c9dd85d3cd5503703493[m
Author: Erlend Dahl <erlend.dahl@oracle.com>
Date:   Mon Jul 11 22:46:00 2016 +0200

    Bug#20674712 BUFFER POOL LOAD NOT COMPLETED WITHIN EXPECTED TIME
    
    Follow-up fix to cater to another potential output line from the test.
    
    Also, fix a similar issue in innodb.innodb_[1;31mbuffer[m_pool_load
    
    Approved by Shaohua Wang <shaohua.wang@oracle.com> over e-mail.

[33mcommit 8481818b9acd645bce328d7685e607f79bb8d248[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Thu Jun 30 12:22:50 2016 +0800

    Followup: BUG#22885524 RW_LOCK_OWN(HASH_LOCK, RW_LOCK_X)
              || RW_LOCK_OWN(HASH_LOCK, RW_LOCK_S)
    
    BUG#23706343 INNODB ASSERTION FAILURE: SYNC0POLICY.IC:63:!IS_OWNED()
    
    Fix innodb_[1;31mbuffer[m_pool_resize_with_chunks failure on pb2.
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 13009

[33mcommit 6a70aef6c346a7e1c5a394aef3f7e861368cb86b[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Tue Jun 28 16:12:26 2016 +0100

    Bug #23708039 NDB : NDB_MGMD CANNOT PARSE LARGE DUMP CODE VALUES
    
    Increase ndb_mgmd parser [1;31mbuffer[m size.
    
    Discovered in test failures on 32-bit hosts :
      ndbinfo_cluster_locks
      ndbinfo_locks_per_fragment

[33mcommit b960f5f2a043e9cc48934ba6c6b0b6e099435bd3[m
Author: Maitrayi Sabaratnam <maitrayi.sabaratnam@oracle.com>
Date:   Fri Jun 24 16:30:24 2016 +0200

    Bug#22916457 - 'EVENT BUFFER STATUS' REPORTING WHEN CONSUMPTION LAGS BEHIND IS NOICY?
    
    This fix:
    - Re-adds the disabled slip (consumption lag) reporting.
    - Changes the ndb_report_thresh_binlog_epoch_slip default from 3 (probably gci)
      to 10 epochs and the defining text.
    - Counts the number of [1;31mbuffer[med epochs which is used to report the slip.
    The reporting interval of 1 sec is *not* changed in this patch.

[33mcommit 9ac74502201a24a2aba9f7e22e50afdae8be7e66[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Tue Jun 21 10:27:01 2016 +0800

    BUG#22885524 RW_LOCK_OWN(HASH_LOCK, RW_LOCK_X)
                 || RW_LOCK_OWN(HASH_LOCK, RW_LOCK_S)
    
    It's a regression of rb#9797(wl#8423 InnoDB: Split the [1;31mbuffer[m pool mutex).
    
    If we don't hold buf_pool->LRU_list_mutex, etc, page hash can be changed
    by buf_pool_resize(), so we need to use buf_page_hash_lock_s_confirm or
    buf_page_hash_lock_x_confirm to confirm hash lock, otherwise assert fails.
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 13009

[33mcommit eceb6298cb64c1e19414cd309d889ee2f086a4e5[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Tue Jun 14 12:12:25 2016 +0800

    Followup: BUG#23080273 INNODB: ASSERTION FAILURE: SYNC0POLICY.IC:63:!IS_OWNED()
    
    BUG#23549252 ASSERT AT BUF0BUF.IC:272:!MUTEX_OWN(&BUF_POOL->ZIP_FREE_MUTEX)
    
    Fix innodb_[1;31mbuffer[m_pool_resize_with_chunks failure on pb2.

[33mcommit dd6c46bb8f6f9f098e1978f90303d0726e28d0c9[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Fri Jun 10 09:30:22 2016 +0200

    Bug#23540008 SAFE GUARD FOR CHARSET_INFO RETURNED FROM GET_CHARSET
    
    When executing a SELECT from tables:
    - performance_schema.events_statements_current
    - performance_schema.events_statements_history
    - performance_schema.events_statements_history_long
    
    the code reads data that can be concurrently written to.
    
    This race condition is expected (performance schema data [1;31mbuffer[ms are lock
    less), but the code is not robust enought.
    
    In particular, the character set for the sql query text may be invalid.
    
    Before this fix, this condition could cause a crash.
    
    With this fix, reading an invalid character set will truncate the SQL
    TEXT column.

[33mcommit cbc524750c486e9fde8266439979476964917bbb[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Wed Jun 8 10:29:10 2016 +0800

    BUG#23067038 ASSERTION FAILURE: BUF0BUF.CC:2861:BUF_PAGE_IN_FILE(BPAGE)
                 LEADS TO CORRUPT DATA
    
    It's a regression of wl#8423 InnoDB: Split the [1;31mbuffer[m pool mutex.
    
    There is a race: Thread 1, we set buf_fix_count to 0 in buf_page_init().
    Thread 2, we decrease buf_fix_count to 0xffffffff in buf_page_optimistic_get().
    Thread 2, we increase buf_fix_count to 0 in buf_page_get_gen(). Thread 3,
    we evict the page from LRU list. Thread 2, assert fails: buf_page_in_file().
    
    The root cause is missing block mutex protection for buf_page_init().
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 12456

[33mcommit 86da46bfa34e45fd1a7d29b6be8999c99e336f5e[m
Author: John David Duncan <john.duncan@oracle.com>
Date:   Thu May 26 21:42:06 2016 -0700

    wl#9048 NDB Support for MySQL Server access to VIRTUAL GENERATED columns
    
    Squashed commit of the following:
    
    commit f893c00ca96267e0fbd759da33fa534058ab9236
    Merge: 3647279 da63d14
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 25 14:13:02 2016 -0700
    
        Merge ../working/wl9048 into mysql-5.7-cluster-7.5-wl9048
    
    commit da63d14ede4b9746fbac6ffd57828b6f12050c0c
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 25 14:11:31 2016 -0700
    
        Improve comments in Ndb_table_map header
    
    commit 0e43d0ee423b7a2d1f51beeef4d11f7a2e034b93
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 25 13:53:39 2016 -0700
    
        suite/gcol: apply changes based on ReviewBoard #11355 comments for wl#9048
    
    commit 0d28cd9c8f3f4955b09e25876c8b26935e912688
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 25 11:23:21 2016 -0700
    
        wl#9048: Ndb_table_map now wraps a const NdbDictionary::Table *
        (or a null pointer, in the CREATE TABLE use case) and its getColumn()
        method.
    
    commit e65f75b67fe4aa11f71f1797debdd9cfb506ccee
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 24 21:13:40 2016 -0700
    
        suite gcol_ndb cosmetic change
    
    commit 3647279b996e633afd13cec0a9c74b32335bcc72
    Merge: 9819c67 21f36a0
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 24 19:46:51 2016 -0700
    
        Merge ../working/wl9048 into mysql-5.7-cluster-7.5-wl9048
    
    commit 21f36a07b2f2cc7060316bcfefb2c436c62722f7
    Merge: 2c30e80 07cb5b3
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 24 19:46:37 2016 -0700
    
        Merge branch 'mysql-5.7-cluster-7.5' of /Users/jdd/git-work-trees/working/../mysql into mysql-5.7-cluster-7.5-wl9048
    
    commit 9819c6795dab4925c0cf109668c4380eef69faf1
    Merge: 2149fb0 07cb5b3
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 24 19:45:09 2016 -0700
    
        Merge branch 'mysql-5.7-cluster-7.5' into mysql-5.7-cluster-7.5-wl9048
    
    commit 2c30e8003047d777218527320d760433140e273c
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 24 19:43:46 2016 -0700
    
        wl#9048: improve test case in ndb_rpl to test replication for both stored and virtual gcol
    
    commit 2149fb089d31173bf584497bfdf5c13f94a657e3
    Merge: a7a5d8a 5fd29e7
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 24 18:30:44 2016 -0700
    
        Merge ../working/wl9048 into mysql-5.7-cluster-7.5-wl9048
    
    commit 5fd29e784aae1b39a15e2c6e2886b223502b30a0
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 23 21:56:45 2016 -0700
    
        one additional --sorted-result in suite/gcol/inc
    
        merge me
    
    commit a7a5d8a2cae436998302c59939c05ab254ae4c6d
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 23 21:56:45 2016 -0700
    
        one additional --sorted-result in suite/gcol/inc
    
    commit 6143a23090c8e7ee62588b9c4fc8dd799e3f97c0
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 23 14:27:02 2016 -0700
    
        wl#9048 add more test cases for joins
    
    commit cbd012ea92e60286fc11546cb7acf32bb2cddc0d
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 23 14:11:15 2016 -0700
    
        wl#9048: Rather than creating an Ndb_table_map on the stack for each joined table, use the existing m_table_map from each table's handler
    
    commit bfa42ed1625aff9541750042e1afe0e84f8f2c98
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Fri May 20 12:50:28 2016 -0700
    
        wl#9048: fix bitmasks in several more places
    
    commit cf46dc1bf7e1ef9045d901cb9dacf9c788fb845c
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Fri May 20 11:50:03 2016 -0700
    
        wl#9048: Optimize Ndb_table_map constructor in trivial case.
    
    commit 3645679ad6eaf7f123aeb8f7c5f87ce46ecafde6
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Fri May 20 11:48:44 2016 -0700
    
        wl#9048: In create_pushed_join() use a correct Ndb_table_map for each joined table.
    
    commit 1b7679e7dc9f3fa64bebb2fb76090888fbce3f36
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 17 13:52:14 2016 -0700
    
        wl#9048 update result file
    
    commit 7729cf0e40331ded1499be6c88102a9aa71e87c2
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 17 13:45:52 2016 -0700
    
        wl#9048 misc. style revisions
    
    commit 5aa5cff8c520f3c97e270689102b05176c68bf32
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 17 13:44:22 2016 -0700
    
        wl#9048 renaming.
         Rename m_col_id_map to m_table_map
         Rename Ndb_table_map::rewrite_bitmap() to Ndb_table_map::get_column_mask()
    
    commit 44ca4f096131534a0aa4e5391279115c460ac0bc
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 17 13:40:21 2016 -0700
    
        wl#9048: additional SELECT tests
    
    commit 3be4a9f5a8048bc86064d6c50177ba8436089cc2
    Merge: 41de158 7c3e740
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 17 09:29:09 2016 -0700
    
        Merge branch 'mysql-5.7-cluster-7.5' into mysql-5.7-cluster-7.5-wl9048
    
    commit 41de1589c6ed8c8f92dbe4232492effedbe199ce
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 17 09:27:43 2016 -0700
    
        wl#9048: work on gcol_select_ndb test failures
    
    commit d168833d032208b639021b5d35490390da18d201
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 16 11:43:12 2016 -0700
    
        Two more cases in suite/gcol/ where results must be sorted for NDB
    
    commit f425e3a92a64c68058fd41091e1d58f33d270a92
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Fri May 13 13:57:29 2016 -0700
    
        Add mtr collection for testing of this branch
    
    commit dd3f3195594e62cd2fab791945f72064b4c953c3
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Fri May 13 13:52:22 2016 -0700
    
        wl#9048 -- some revisions after code review.
        Not all of this is meant to be kept.
    
    commit b5249c28f3ac9b5b4a3afa5da3380b197112c7bf
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:44 2016 +0200
    
        WL#9048
    
         - add and fix comments
    
    commit dbee585185197bb6787dd1635d573fcbf9785864
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:43 2016 +0200
    
        wl#9048
    
         - data type questions.
    
    commit bce6e2c46f910fe2b2690a5cec9e39f076810a6e
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:42 2016 +0200
    
        wl#9048
    
         - move variables to scope where they are used.
         - would actually prefer if they were only in the for loop scope.
    
    commit 4e7b0672de339b772ca81a5a004b099648f36169
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:41 2016 +0200
    
        wl#9048
    
         - const fixes
    
    commit 70e2411ef4f1948ea1d086c5847d080d04733d8f
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:40 2016 +0200
    
        wl#9048
    
         - remove the almost unused operator[]
         - think it should go since there are two mappings which can be
           performed and without calling a function it's hard to know which
           one.
         - clearer code if we call a function.
    
    commit e35b5042209ccdd4c786ffdb36b7e36f047d973f
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:39 2016 +0200
    
        wl#9048
    
         - add TABLE* which could be used to check functions
           calls programatically.
         - Perhaps only needed for DBUG compile?
         - Perhaps not _all_ properties need to be stored and instead we can
            look them up from m_table. For example m_trivial?
         - we should of course not add it if not used...
    
    commit a6086095a520c5651d13748215383873e6ce9660
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:38 2016 +0200
    
        wl#9048
    
         - initialize member variables early and make them const
    
    commit 501042a8d60379ecd558bf86da0450db6e8acb67
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:37 2016 +0200
    
        wl#9048
    
         - remove Ndb_table_map::init()
    
    commit b3cb28577376aee9e70b3854fd60350841ae933c
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:36 2016 +0200
    
        wl#9048
    
         - remove default constructor for Ndb_table_map, instead create
           the m_col_id_map* from ::open() and close() when it's well known
           which TABLE* to use.
         - should make us detect if the Ndb_table_map is used from
           not open'ed ha_ndbcluster(since m_col_id_mape will be NULL).
         - didn't remember syntax for how to use operator[] from pointer
         - also allows the constructor to be changed to make much more things
        const.
         - think we might even be able to save a pointer to TABLE* to allow
        checking field->stored_in_db etc.
         - starting to see Ndb_table_map more as a wrapper around TABLE
    
    commit 9ca68d82c864a6b8b509a2664a60dde18a5c2569
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:35 2016 +0200
    
        wl#9048
    
         - use stack allocated Ndb_table_map in ha_ndbcluster::create()
         - should try to use ha_ndbcluster member variables only between open()
            and close() and the handler is not open when calling create().
         - trying to make ha_ndcluster::create() a const function at least.
         - yes, I know it already uses m_table and m_tabname etc. but if we
           could get this new code to work without m_col_id_map it would be
           nice.
    
    commit 2a9787158764ef299b37a36366a024d62d6dd41f
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:34 2016 +0200
    
        wl#9048
    
         - remove unused parameter for create_table_set_up_partition_info()
    
    commit 9649b13cedecc88ecd1d27b01ff25763d6e9b884
    Author: Magnus Blåudd <magnus.blaudd@oracle.com>
    Date:   Fri May 13 11:28:33 2016 +0200
    
        wl#9048
    
         - don't use ha_ndbcluster_glue.h which we intend to remove
           as it includes and exposes too much
         - reduce interface of Ndb_table_map, forward declare usage of TABLE
           and onlky include parts which are really used in the implementation
    
    commit 801461babfaa30cbc0303b963131e810d6419317
    Merge: bb268ec a438906
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Fri May 13 12:06:04 2016 -0700
    
        Merge branch 'mysql-5.7-cluster-7.5' of /Users/jdd/git-work-trees/working/../mysql into mysql-5.7-cluster-7.5-wl9048
    
    commit bb268ec306860367aee7dc07e2c1c9b20f610c10
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Thu May 12 13:49:14 2016 -0700
    
        More result sorting in gcol_view test
    
    commit d277c141023e0ead16322e41433975b0ec214c72
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Thu May 12 12:45:11 2016 -0700
    
        wl#9048: Add test case for various NDB column layouts
        including generated, blob, hidden pk, and char(0) columns
    
    commit f1340826d9fc9812c3c8f1e074ca612aca2d775c
    Merge: 1b701d8 45c99c3
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Thu May 12 11:33:21 2016 -0700
    
        Merge branch 'mysql-5.7-cluster-7.5' of /Users/jdd/git-work-trees/working/../mysql into mysql-5.7-cluster-7.5-wl9048
    
    commit 1b701d84265dff9947a3639a10975b6cfac6132f
    Merge: 0a94d97 b708ebf
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 11 10:13:39 2016 -0700
    
        Merge branch 'mysql-5.7-cluster-7.5' of /Users/jdd/git-work-trees/working/../mysql into mysql-5.7-cluster-7.5-wl9048
    
    commit 0a94d975a159f78f2c7701de769f6e7ce130ad15
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 10 16:28:20 2016 -0700
    
        revert bug where table->s->fields was wrongly changed to table->s->stored_fields
    
    commit f8a39d1a422e31b682b7b91d26fb379bbd161fc7
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 10 15:19:59 2016 -0700
    
        wl#9048: In suite/gcol_ndb add tests based on suite/gcol/inc/
    
    commit 804a19d5bcd858109b5ab066da29214a65820ac3
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 10 15:16:50 2016 -0700
    
        wl#9048: Add "ORDER BY" and "--sorted_result" in suite/gcol as needed for tests have repeatable results in NDB.
    
    commit 14e7129ccd3a1e990c2397e2fce839f9e4505362
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 10 15:13:21 2016 -0700
    
        wl#9048 Fix crashing bug in online ALTER TABLE where generated columns are present.
        The binlog injector thread must call lex_start(thd) to initialize lexer so that
        it can parse the SQL expressions for generated columns.
    
    commit 8f818e9abec7d24d47730845097bfbb28ca468a5
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 10 15:11:58 2016 -0700
    
        wl#9048: Move TableMap class from ha_ndbcluster to new ndb_table_map.h|cc files.
    
    commit ab62f7ed23cac892d08e5602cb01b0708bcb72fd
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 9 15:25:22 2016 -0700
    
        wl#9048: in suite/gcol/ add "ORDER BY" needed to make results deterministic for NDB.
    
    commit 1e8f6221cca79e2b5ee0673c305c9ae924d4a735
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 9 14:17:02 2016 -0700
    
        Add dbug output to ndb_set_record_specification
    
    commit abdb3459f09e368b75909f708bae8257bc9a4510
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Mon May 9 14:11:39 2016 -0700
    
        wl#9048: when using a MySQL bitmask with NdbRecord, rewrite it if necessary to compensate for virtual columns
    
    commit 871f30bc39e227aa0d3361fb38587e2ffff2a7b0
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Thu May 5 14:01:20 2016 -0700
    
        wl#9048: add ORDER BY to all table scans in gcol_colum_def_options test
    
    commit e32186e61eda39ad0121c4c931cf3d58c6b6045b
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Thu May 5 13:22:14 2016 -0700
    
        wl#9048: adapt gcol test suite
        Some ALTER TABLE statements return error 1846 from NDB vs. error 1845 from MyISAM
    
    commit 8d94baf585541c7eceb7d8e60d385f3cea6de57f
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Thu May 5 12:00:30 2016 -0700
    
        wl#9048 BLOB handling: more checks for virtual columns
    
    commit 12a0e2982d4f2adcc1d67cc8b5027e40f22f542f
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 4 13:41:52 2016 -0700
    
        wl#9048 reclength vs. stored_rec_length
        stored_rec_length is the length of stored columns only in MySQL's record [1;31mbuffer[m.
        MySQL lays out the [1;31mbuffer[m with all stored columns first, then all virtual columns.
        This patch takes a conservative approach: in the case of copying data from NDB
        to MySQL, we only copy stored_rec_length bytes; but when using the length as
        an allocation size, we assume we need to allocate enough space for both stored
        and virtual columns.
        This also fixes one more case of virtual fields not being computed in MRR results.
    
    commit 5970f5a031c6c91351217b08ae94c4f8775dca3d
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 4 12:16:08 2016 -0700
    
        wl#9048: Support ALTER TABLE
        Note that online ALTER TABLE where the resulting table contains a virtual gcol
        is currently disabled due to crashing bug in NDB binlog injector thread.
    
    commit cc1ab4e2b8f044af6fcb447f5a8caf829e8087c0
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 4 11:59:32 2016 -0700
    
        wl#9048: Check for virtual fields in NDB binlog code
    
    commit 00a34d25c31c3cc01329a03aa60da267ef1abf78
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 4 10:06:30 2016 -0700
    
        wl#9048 update generated columns when reading in MRR and SPJ queries.
        Here we call update_generated_read_fields() from the NDB handler,
        though it is normally called from higher levels in the server, because
        these code paths are not shared with any other storage engines.
    
    commit c634530390abc8f6099169d7da9553b2def45637
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 4 10:00:06 2016 -0700
    
        wl#9048: check whether a query field is a virtual generated column in MRR and SPJ query plans.
    
    commit e0b762b57c47281d870e34a1e3b6d30c1beab831
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 4 09:56:26 2016 -0700
    
        wl#9048: Check for virtual fields and use TableMap to relate field number to column number
    
    commit 9b4faa95263ff34341f9d8d14e06f78013858d7f
    Merge: 3375e48 24d181f
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Wed May 4 09:34:45 2016 -0700
    
        Merge branch 'mysql-5.7-cluster-7.5' of /Users/jdd/git-work-trees/working/../mysql into mysql-5.7-cluster-7.5-wl9048
    
    commit 3375e48c9236982025b2fca9a89647d9b7444161
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 3 14:05:02 2016 -0700
    
        wl#9048: fix calculation of column number for hidden pk
    
    commit 1d7d830685361769c3c58dff5324c524cce01b5b
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 3 14:01:14 2016 -0700
    
        wl#9048: Handle virtual columns in CREATE TABLE
    
    commit db97a0019d4a57670a01004b625172861a634624
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 3 13:44:26 2016 -0700
    
        wl#9048 Create TableMap class.  http://rb.no.oracle.com/rb/r/12582
        Map between NDB column id and MySQL field id.
    
    commit 4c6f56537d11251bf778feda1879dc6d8de658b9
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 3 11:41:30 2016 -0700
    
        wl#9048: Commit gcol_ndb and ndb_rpl tests from original wl#8818 patch
        This creates suite gcol_ndb with some basic tests for stored generated columns
        and adds a simple generated column replication test to suite ndb_rpl.
        This commit does *not* include the ha_ndbcluster.cc implementation of stored
        generated columns from wl#8818, which is quite small and will be included
        in the wl#9048 implementation.
    
    commit 3a2cfc9b2175f6e5064499bddb8dff2a557e8483
    Author: John David Duncan <john.duncan@oracle.com>
    Date:   Tue May 3 11:17:57 2016 -0700
    
        wl#9048 Changes to mysql-test/suite/gcol/ -- http://rb.no.oracle.com/rb/r/11355/
        Update gcol suite for better reuse with NDB

[33mcommit d887a49e84a618e150dfa90d3b977614dc0cb020[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Thu May 19 20:33:06 2016 +0800

    BUG#23136397 ASSERTION FAILURE: BUF0BUF.CC:5410:RW_LOCK_IS_LOCKED
                 (&BLOCK->LOCK, RW_LOCK_X)
    
    It's regression of wl#8423 InnoDB: Split the [1;31mbuffer[m pool mutex.
    
    We should protect buf_page_set_io_fix(&block->page, BUF_IO_READ)
    and rw_lock_x_lock(&block->lock) by buf_pool->LRU_list_mutex.
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 12707

[33mcommit 2869e9961d41f55cddd2d98f7dbdf0dc564de5fb[m
Author: Maitrayi Sabaratnam <maitrayi.sabaratnam@oracle.com>
Date:   Tue May 17 22:56:18 2016 +0200

    Reduce undo [1;31mbuffer[m size to avoid OutOfLogBufferMemory error in some PB machines.

[33mcommit 2eae7d3fca853b2addf6213265cbdb20c44bb92a[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed May 11 12:19:20 2016 +0200

    Bug#23212938 ADD SUPPORT FOR SOLARIS STUDIO 12.5 AKA 5.14
    
    Extra patch for mysql-trunk.
    
    ================
    include/decimal.h
    sql/my_decimal.h
    strings/decimal.cc
    
    query 'connect plug_con,localhost,plug,plug_dest' failed: 2059:
    Authentication plugin 'auth_test_plugin' cannot be loaded:
    ld.so.1: mysqltest: fatal: relocation error: file
    plugin/auth/auth_test_plugin.so: symbol internal_str2dec:
    referenced symbol not found
    
    The problem was this 'extern "C"' function
    static inline int string2decimal(const char *from,
                                     decimal_t *to,
                                     char **end)
    {
      return internal_str2dec(from, to, end, FALSE);
    }
    
    The Solaris Studio C compiler left an unresolved reference to internal_str2dec
    even if the function was un-used.
    
    Fix: either rewrite all plugins to be C++ (remove 'static' which
    enables C++ weak references), or the chosen solution:
    Remove the code from include/decimal.h, it is not used by any C source code.
    
    ================
    include/my_sys.h
    rapid/plugin/x/ngs/src/thread.cc
    
    t@30 (l@30) terminated by signal SEGV (subcode 32767)
    0xffffffff7f3e1f14: _stack_grow+0x0048: ldub     [%o1 - 1], %g0
    Current function is MYSQLparse
    19775   YYSTYPE yylval YY_INITIAL_VALUE(yyval_default);
    current thread: t@30
      [1] _stack_grow(0xffffffff7f54c341, 0xffffffff7f550000, 0x40000, 0xffffffff7f54f801, 0xe860, 0x104480e40), at 0xffffffff7f3e1f14
    =>[2] MYSQLparse(YYTHD = 0xffffffff7f566448), line 19775 in "sql_yacc.cc"
      [3] parse_sql(thd = 0x13edabb08, parser_state = 0xffffffff7f55ed40, creation_ctx = 0x13ee59410), line 7049 in "sql_parse.cc"
    
    The problem was that threads created by/for the X plugin had a much
    smaller actuall stack size than my_thread_stack_size, thus making
    check_stack_overrun() defunct.
    
    Fix: use my_thread_stack_size when creating threads which will execute
    SQL in the server.
    
    ================
    rapid/plugin/x/mysqlxtest_src/mysqlx.cc
    rapid/plugin/x/ngs/src/client.cc
    
    program terminated by signal BUS (invalid address alignment)
    Current function is mysqlx::Connection::send
      663     *buf_ptr = msg.ByteSize() + 1;
    =>[1] mysqlx::Connection::send(this = 0x100de5240, mid = 4, msg = CLASS), line 663 in "mysqlx.cc"
    
    Fix: move byte-[1;31mbuffer[m into anonymous union, to ensure alignment.
    
    ================
    sql/json_dom.cc
    sql/json_dom.h"
    
    Error: Attempt to initialize multiple variant members in
    'Json_wrapper' by initializing 'm_dom_alias'.
    
    Fix: Initialize m_dom_alias in CTOR body rather than CTOR init list.
    
    ================
    storage/innobase/CMakeLists.txt
    
    Linking CXX executable mysqld
    Undefined                    first referenced
     symbol                             in file
    boost::atomics::detail::lockpool::scoped_lock::scoped_lock(volatile const void*)
     ../storage/innobase/libinnobase.a(buf0buf.cc.o)
    
    Problem was that Solaris Studio generates dependencies on
    boost::atomics::detail::lockpool::scoped_lock::scoped_lock
    
    Fix: add libs/atomic/src/lockpool.cpp to list of source files for InnoDB

[33mcommit 48b67d94619aa11b3081accb90fbcb8d2c689826[m
Author: Marc Alff <marc.alff@oracle.com>
Date:   Tue May 3 11:57:06 2016 +0200

    Bug#23104498 MEMORY FOR 'SCALABLE_BUFFER' IS NOT SHOWN IN SHOW ENGINE
    STATUS
    
    Before this fix,
    - SHOW ENGINE PERFORMANCE_SCHEMA STATUS
    - SELECT * FROM performance_schema.memory_summary_global_by_event_name
    would report conflicting data for the total memory used in the performance
    schema.
    
    The root cause is the memory for the scalable [1;31mbuffer[m pages,
    instrumented as memory/performance_schema/scalable_[1;31mbuffer[m.
    This memory is missing from show engine status.
    
    With this fix,
    SHOW ENGINE PERFORMANCE_SCHEMA STATUS
    now includes the mising memory,
    printed as "(pfs_[1;31mbuffer[m_scalable_container).memory"

[33mcommit 5a8497940abafb35bb636ffabec3f9e4ef0c4b67[m
Author: Aakanksha Verma <aakanksha.verma@oracle.com>
Date:   Mon May 2 15:16:52 2016 +0530

    Bug #21512749   REFACTOR SYSVAR INNODB_BUFFER_POOL_SIZE BY
    REMOVING INNOBASE_BUFFER_POOL_SIZE
    
    PROBLEM :
    
    The system variable innodb_[1;31mbuffer[m_pool_size uses two global variables
    innobase_[1;31mbuffer[m_pool_size and srv_buf_pool_curr_size.  It is possible
    to remove the use of innobase_[1;31mbuffer[m_pool_size and tie the variable
    srv_buf_pool_curr_size to the system variable.
    
    FIX :
    
    Implemented innodb_[1;31mbuffer[m_pool_size by making use of
    srv_buf_pool_curr_size directly.
    
    Reviewed by:Annamalai Gurusami<annamalai.gurusami@oracle.com>
    Rb :10943

[33mcommit bd914aebb3ec510784f364e5e71cd35bb8a0cad5[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Thu Apr 28 16:28:07 2016 +0800

    BUG#23102834 INNODB: ZERO FLUSH FROM LRU
    
    It's a regression of wl#8423 InnoDB: Split the [1;31mbuffer[m pool mutex.
    we wrongly removed the count for lru flushing in buf_flush_batch().
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 12509

[33mcommit 298075765de046c00319156e6bd20b9ac3af0b17[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Fri Apr 15 09:23:02 2016 +0200

    Remove unnecessary check of return code
    
     - the function 'bitmap_init' can never fail when
       the "buf" argument is provided.
     - remove the check of return code
     - add wrapper function 'ndb_bitmap_init' which requires [1;31mbuffer[m to
       be provided and adds automatic checking of the [1;31mbuffer[m size and also
       provides type safety
     - starting new file intended to contain wrapper functions for working
       with MY_BITMAP

[33mcommit 65649a16ce9412f7d9286e7e6ad6c2de5769be25[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Thu Apr 21 13:34:00 2016 +0800

    BUG#23067038 ASSERTION FAILURE: BUF0BUF.CC:2861:BUF_PAGE_IN_FILE(BPAGE)
                 LEADS TO CORRUPT DATA
    
    It's a regression of wl#8423 InnoDB: Split the [1;31mbuffer[m pool mutex,
    in which we removed block mutex protection for buf_fix_count.
    
    The assertion happens when one thread fixed a dirty block but the
    other thread flushed the block and moved the page from LRU list to
    free list, because it saw buf_fix_count is 0, other than 1.
    
    The solution is holding block mutex when buf fix and unfix.
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    RB: 12456

[33mcommit 5ff9c4e28ee4f35c597a85de76606a3a4185766a[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Tue Apr 19 07:40:11 2016 +0200

    Bug#23127824 TRANSPORTERFACADE USELESS USAGE OF DYNAMIC MEMORY
    
     - when creating names for TransporterFacadese send [1;31mbuffer[m
       mutexes dynamic memory is used unneccessarily.
     - since length of string is well known, use
       stack allocated [1;31mbuffer[m instead.

[33mcommit 333b61190a4c8a394588f59dda0d884b2342a98d[m
Author: Priyanka Sangam <priyanka.sangam@oracle.com>
Date:   Mon Apr 18 17:04:29 2016 +0530

    Bug #23093656 NDB : LOOPBACK RESERVED SEND BUFFER CALCULATION
    
    Init send[1;31mbuffer[m page size for reserved send[1;31mbuffer[m size calculation.

[33mcommit fa49f62995e8adaae6844cae9315781c7a432f39[m
Author: Daniel Blanchard <daniel.blanchard@oracle.com>
Date:   Fri Apr 15 11:34:24 2016 +0100

    BUG #22608247 RESULT CONTENT MISMATCH IN BINLOG.BINLOG_MYSQLBINLOG_ROW AND FRIENDS
    
    Problem:
    --------
    This is a known bug in Visual Studio 2015 C Runtime (Connect#1902345)
    https://connect.microsoft.com/VisualStudio/feedback/details/1902345
    
    The bug in _read is as follows:  If...
    
    1.       you are reading from a text mode pipe,
    2.       you call _read to read N bytes,
    3.       _read successfully reads N bytes, and
    4.       the last byte read is a carriage return (CR) character,
    
    then the _read function will complete the read successfully but will
    return N-1 instead of N.  The CR or LF character at the end of the result
    [1;31mbuffer[m is not counted in the return value.
    
    The bug is fundamentally timing-sensitive because whether _read can
    successfully read N bytes from the pipe depends on how much data has been
    written to the pipe.  Changing the [1;31mbuffer[m size or changing when the [1;31mbuffer[m
    is flushed may reduce the likelihood of the problem, but it won't
    necessarily work around the problem in 100% of cases.
    
    Fix:
    ----
    The workaround is to use a binary pipe and do text mode CRLF => LF translation
    manually on the reader side.
    
    Note that this workaround should no longer be necessary when the next
    update to the Universal CRT ships, which is likely to occur around the same
    time as the Windows 10 Anniversary Update this summer (2016).
    
    Reviewed-By: Bjorn Munch <bjorn.munch@oracle.com>
    RB: 12384

[33mcommit 8ce2b40c331c2d65e11716c083332f77e3455e47[m
Author: Annamalai Gurusami <annamalai.gurusami@oracle.com>
Date:   Thu Apr 14 13:50:01 2016 +0530

    Bug #21473497 PAGE CLEANER THREAD, ASSERT BLOCK->N_POINTERS == 0
    
    Problem:
    ========
    
    In function buf_LRU_block_free_non_file_page(), the following assert failed:
    
    2113 #if defined UNIV_AHI_DEBUG || defined UNIV_DEBUG
    2114         ut_a(block->n_pointers == 0);
    2115 #endif /* UNIV_AHI_DEBUG || UNIV_DEBUG */
    
    The assert failure call stack was the following (edited for clarity):
    
    ut_dbg_assertion_failed (expr=0x218b883 "block->n_pointers == 0", ...
    -> buf_LRU_block_free_non_file_page (block=0x7ff33216efc8)
     -> buf_LRU_block_free_hashed_page (block=0x7ff33216efc8)
      -> buf_LRU_free_page (bpage=0x7ff33216efc8, zip=false)
       -> buf_LRU_free_from_unzip_LRU_list (buf_pool=0x4089948, scan_all=false)
        -> buf_LRU_scan_and_free_block (buf_pool=0x4089948, scan_all=false)
         -> buf_LRU_get_free_block (buf_pool=0x4089948)
          -> buf_page_init_for_read()
           ...
           -> row_update_for_mysql ()
            -> ha_innobase::update_row ()
             -> handler::ha_update_row ()
              -> mysql_update ()
               ...
    
    Analysis:
    =========
    
    In the function btr_search_drop_page_hash_index(), we have the following check
    in the beginning:
    
    1204         if (!btr_search_enabled) {
    1205                 return;
    1206         }
    
    In the function btr_search_disable(), we have the following code.
    
     351         btr_search_x_lock_all();
     352
     353         if (!btr_search_enabled) {
     354                 if (need_mutex) {
     355                         mutex_exit(&dict_sys->mutex);
     356                 }
     357
     358                 btr_search_x_unlock_all();
     359                 return;
     360         }
     361
     362         btr_search_enabled = false;
    
    Suppose thread 1 (which is the update statement) is invoking
    
    buf_LRU_free_page()
      -> btr_search_drop_page_hash_index()
    
    and is just before the check listed above (line 1204).  If another thread 2
    (which is the [1;31mbuffer[m pool resize thread) invoked btr_search_disable(), and has
    reached line 362.  In such a situation, for thread 1 the function
    btr_search_drop_page_hash_index() will not do anything and return.  So the
    buf_block_t->n_pointers will not be adjusted by thread 1.
    
    Thread 2 will eventually set the buf_block_t->n_pointers to 0.  But before this
    can happen, it is possible for thread 1 to continue further:
    
    buf_LRU_free_page()
      -> btr_search_drop_page_hash_index()
         -> buf_LRU_block_free_hashed_page()
           -> buf_LRU_block_free_non_file_page()
    
    then it will reach the assert:
    
    2046 #if defined UNIV_AHI_DEBUG || defined UNIV_DEBUG
    2047         ut_a(block->n_pointers == 0);
    2048 #endif /* UNIV_AHI_DEBUG || UNIV_DEBUG */
    
    In the core dump, I do see the following stacks (which agrees with my analysis):
    
    Thread 47: (the [1;31mbuffer[m pool resize thread)
    
    buf_block_free (block=0x7ff331e49710)
    -> mem_heap_block_free (heap=0x428a2a8, block=0x7ff331f34000)
     -> mem_heap_free_heap_top ()
      -> mem_heap_empty ()
       -> btr_search_disable ()
        -> buf_pool_resize ()
         -> buf_resize_thread ()
    
    Thread 1: (the update thread)
    
    ut_dbg_assertion_failed (expr=0x218b883 "block->n_pointers == 0", ...
    -> buf_LRU_block_free_non_file_page (block=0x7ff33216efc8)
     -> buf_LRU_block_free_hashed_page (block=0x7ff33216efc8)
      -> buf_LRU_free_page (bpage=0x7ff33216efc8, zip=false)
       -> buf_LRU_free_from_unzip_LRU_list (buf_pool=0x4089948, scan_all=false)
        -> buf_LRU_scan_and_free_block (buf_pool=0x4089948, scan_all=false)
         -> buf_LRU_get_free_block (buf_pool=0x4089948)
          -> buf_page_init_for_read()
           ...
           -> row_update_for_mysql ()
            -> ha_innobase::update_row ()
             -> handler::ha_update_row ()
              -> mysql_update ()
               ...
    
    Solution:
    =========
    
    The assert needs to be adjusted as follows:
    
    2113 #if defined UNIV_AHI_DEBUG || defined UNIV_DEBUG
    2114         ut_a(block->n_pointers == 0 || !btr_search_enabled);
    2115 #endif /* UNIV_AHI_DEBUG || UNIV_DEBUG */
    
    rb#12327 approved by Shaohua.

[33mcommit a59bc548ccbb3871ed0a4a4a43b9ffca3e6899de[m
Author: Aakanksha Verma <aakanksha.verma@oracle.com>
Date:   Wed Apr 13 10:33:53 2016 +0530

    Bug #21512749   REFACTOR SYSVAR INNODB_BUFFER_POOL_SIZE BY
    REMOVING INNOBASE_BUFFER_POOL_SIZE
    
    PROBLEM :
    
    The system variable innodb_[1;31mbuffer[m_pool_size uses two global variables
    innobase_[1;31mbuffer[m_pool_size and srv_buf_pool_curr_size.  It is possible
    to remove the use of innobase_[1;31mbuffer[m_pool_size and tie the variable
    srv_buf_pool_curr_size to the system variable.
    
    FIX :
    
    Implemented innodb_[1;31mbuffer[m_pool_size by making use of
    srv_buf_pool_curr_size directly.
    
    Reviewed by:Annamalai Gurusami<annamalai.gurusami@oracle.com>
    Rb :10943

[33mcommit 45f91dbb2c25996b6b6c382c234f28482b70ed11[m
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Wed Apr 6 12:01:16 2016 +0530

    WL#8795: EVALUATE DEFAULTS SET BY MTR AND CHANGE THEM TO USE SERVER DEFAULTS
             WHERE POSSIBLE
    
    Post-push fix: Fixing test failures after reducing the value of
    innodb-[1;31mbuffer[m-pool-size.
    
    Reviewed-by: Pavan Naik <pavan.naik@oracle.com>

[33mcommit 174ddccd09ff1be04988c147c1bb070a025a485c[m
Author: Deepa Dixit <deepa.dixit@oracle.com>
Date:   Tue Apr 5 18:50:25 2016 +0530

    WL#8795: EVALUATE DEFAULTS SET BY MTR AND CHANGE THEM TO USE SERVER DEFAULTS
             WHERE POSSIBLE
    
    Post-push fix: Decreasing the value of innodb-[1;31mbuffer[m-pool-size
    and innodb-log-file-size in the MTR settings.
    
    Reviewed-by: Pavan Naik <pavan.naik@oracle.com>

[33mcommit 2d3ce356f5693cb047237c2d9bebd0c732a81f51[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Fri Apr 1 17:58:27 2016 +0800

    Fllowup: wl#8423 InnoDB: Split the [1;31mbuffer[m pool mutex
    
    Fix pb2 failures: innodb.innodb_bug14147491 innodb.innochecksum_1

[33mcommit 9fe0b8c87a6aa986c5b95b8b61a56bf4534688e8[m
Author: Olav Sandstaa <olav.sandstaa@oracle.com>
Date:   Tue Mar 29 15:29:04 2016 +0200

    Bug#22973279 IMPROVE ERROR HANDLING FROM CALL TO STORE_KEY::COPY() IN CP_BUFFER_FROM_REF
    
    The function store_key::copy() returns an enum value, but in
    cp_[1;31mbuffer[m_from_ref() this return value is treated as if it is a bit
    vector. If the first bit is set, then this is treated as
    store_key::copy() returns an error.
    
    This patch changes cp_[1;31mbuffer[m_from_ref() to check that
    store_key::copy() returns the enum value store_key::STORE_KEY_OK
    instead treating the return value as a bit vector.

[33mcommit 2bcc00d11f21fe43ba3c0e0f81d3d9cec44c44a0[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Tue Mar 29 12:10:56 2016 +0800

    wl#8423 InnoDB: Split the [1;31mbuffer[m pool mutex
    
    1. Introduce several new list/hash protecting mutexes, and access without any
    mutex to several variables. The new mutexes are:
      - LRU_list_mutex for the LRU_list;
      - zip_free mutex for the zip_free arrays;
      - zip_hash mutex for the zip_hash hash and in_zip_hash flag;
      - free_list_mutex for the free_list and withdraw list;
      - flush_state_mutex for init_flush, n_flush, no_flush arrays.
    
    2. The variables switched from [1;31mbuffer[m pool mutex protection to atomic operations
    and/or os_rmb/os_wmb.
      - srv_buf_pool_old_size
      - srv_buf_pool_size
      - srv_buf_pool_curr_size
      - srv_buf_pool_base_size
      - buf_pool->buddy_stat[i].used
      - buf_pool->curr_size, n_chunks_new.
    
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>
    Reviewed-by: Allen Lai        <zheng.lai@oracle.com>
    RB: 9797

[33mcommit c54d668da782b1cc7d3c6fdb67ef23d60a43e538[m
Author: Benny Wang <benny.wang@oracle.com>
Date:   Tue Mar 22 08:33:22 2016 +0100

    Fixed bug#21982792: TOO MUCH SPAM: 'GOT ERROR 1 WHEN READING TABLE'
    
    When reading one row by reference scan, there are two steps: 1) copy the
    referenced value to the indexed field 2) use the indexed field value to scan
    the index. During step 1, we might meet warnings such as a type conversion
    warnings. In strict mode, these warnings will be treated as errors. However in
    step 1, it misses to check the thd->is_error to see whether there is such kind
    of error. The missing error handling in the server results in the server goes
    forward like no error. At the same time, it will results in some abnormal
    behavior next, such as update_generated_read_fields will throw out an error
    because it checks thd->is_error(). This is unreasonable.
    
    This patch fixes such kind of problems. The thd->is_error() will be detected
    before calling update_generated_read/write fields.  The places where
    the->is_error() is checked are listed as the below:
    1. fill_record() checks after save_in_field()
    2. cp_[1;31mbuffer[m_from_ref() does after copy()
    3. copy_data_between_tables() does after invoke_do_copy()
    4. do_updates() does after invoke_do_copy()
    5. JOIN_CACHE::generate_full_extensions checks after check_match()
    
    This patch causes changes to the test results from i_main.sp. This is caused
    by the new error handling which makes the server return earlier when an error
    has occurred.

[33mcommit 3b61975885f402f87fa0e0e309e3592eb7bd4a39[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Mar 16 13:51:28 2016 +0100

    wl#7677, Yet another followup patch... sigh
    
    This time the usage of MAP_ANONYMOUS caused build break on
    osx and Windows, which seems to not support this. On windows
    as my_mmap() is not natively supported by Windows, and we
    use a my_mmap() function instead. That does not implement
    MAP_ANONYMOUS functionality. (Possibly could be implemented
    later, but that is out of scope for this patch)
    
    On osx it is ,,,, well not supported.
    
    non-ANONYMOUS mapping would have required is to create
    a file to map agains. That does not seem like a favourable
    solution for allocating this kind of [1;31mbuffer[m memory.
    
    Instead this fix let platforms not supporting ANONYMOUS mapping
    use plain malloc instead. Should not really matter much as
    long as Linux (and Solaris) use mmap().
    
    Also fixes a few compiler warnings seen on Windows.

[33mcommit bf958523777a170e8975b9e4b855ed24f640a226[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Tue Mar 15 16:08:42 2016 +0100

    WL#7677: Improve event [1;31mbuffer[m memory allocation
    
    The existing event [1;31mbuffer[m allocation algorith hardly ever
    deallocate any memory, but keep it in its own free-list
    for later reuse.
    
    This result in the total memory usage accumulating to
    the total max ever used.
    
    This WL fix that by allowing the event memory [1;31mbuffer[ms to
    be returned to the operating system when the events has
    been consumed.

[33mcommit 04d563f651f97d54cba0d184b590de91d1eb3209[m
Author: Tatiana Azundris Nuernberg <tatjana.nuernberg@oracle.com>
Date:   Mon Feb 29 09:15:48 2016 +0000

    Bug#16576959: MYSQL_OPTIONS4: POTENTIAL DOS VIA PRINTING TOO MUCH USELESS INFO TO ERROR LOG
    
    The client library can enrich connection data with information about
    the library version, the client's name, the OS the client is running
    on, and in fact pretty much anything it wants.  The designated
    mechanism for this is mysql_options4(), which lets the client put
    arbitrary key/value pairs on the connection info before the connection
    is made.
    
    The server outright refuses a connection when 64+ KB of these data are
    submitted. However, in practice performance schema usually reserve much
    less space (< 1 KB) for each connection's attributes. If the client submits
    more data, the connection will succeed, but a warning will be thrown
    that some attributes were discarded. (The server will provide access
    to all attributes that is has a complete copy of. We do not currently
    show how many attributes were lost on a given connection, nor do we
    show an incomplete attribute with some sort of "cut" marker -- we simply
    don't show a truncated attribute at all. That said, we do expose info
    about the total number of connections with dropped attributes.)
    
    Pre-patch, we simply logged a warning indicating that attributes were
    truncated on a connection, without giving any information beyond the
    timestamp that would allow the administrator to identify the client,
    user, or connection that lost attributes. This made debugging harder
    than it needs to be.
    
    This patch adds additional data to log entry where available, such
    as user/host, connection ID, etc., all in the hope that it will
    make debugging such instances with just the error log much easier,
    and aid cross-referencing in the presence of further logs, such as
    the general query log.
    
    It also adds a new global PFS variable,
    "Performance_schema_session_connect_attrs_longest_seen" that shows the
    size of the longest (valid, i.e. <= 64 KB) [1;31mbuffer[m we were passed, so
    the DBA may adjust the [1;31mbuffer[m, or complain to the application developer.
    
    Finally, when a valid [1;31mbuffer[m in excess of what we accept is passed,
    we will add a new attribute "_truncated" stating how many characters
    were lost (provided the configured [1;31mbuffer[m is large enough to hold
    this information). This should make it easier to identify the exact
    connection that had the questionable attribute set in the PFS,
    without having to resort to the error log.

[33mcommit 707fd3af81b44117f44ba91f1f307506122a4840[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Mar 10 14:29:04 2016 +0800

    Bug#21352937 - REDUCE LOG_SYS->MUTEX CONTENTION BY ALLOWING CONCURRENT
    MTR COMMIT AND LOG WRITE
    
    All mtr commits would have to wait for writing/flushing redo logs to disk
    in log_write_up_to(). The wait is unnecessary. In this patch, we introduced
    one more log [1;31mbuffer[m and one mutex.
    
    We always write logs to one log [1;31mbuffer[m, keeping the other idle. Once we
    need to flush it, we switch these two [1;31mbuffer[ms, so log_write_up_to() would
    take over the to be flushed [1;31mbuffer[m and do the flush job, once the flushing
    finishes, this [1;31mbuffer[m becomes the idle one. At the mean time of flushing,
    all concurrent mtr commits would see the empty new [1;31mbuffer[m and write logs
    there, even after the flushing, logs are still writing to this [1;31mbuffer[m
    before it needs to be flushed.
    
    Let's say we have two adjacent log [1;31mbuffer[m A and B, at first, all logs are
    written to A, keeping B as empty. Once we want to flush logs in A, we will
    switch A and B, which is under the protection of current log_sys->mutex.
    Then all logs are now written to B, while A is getting flushed and becomes
    empty and idle. When B is needed to be flushed, we now switch A and B again,
    new commits will come to A, and flushing of B won't stop the concurrent
    mtr commits. And so on.
    
    The new introduced mutex is mainly used to protect the process of
    log_write_up_to().
    
    The original patch was provided by Weixiang Zhai.
    
    RB: 11142
    Reviewed-by: Debarun Banerjee <debarun.banerjee@oracle.com>

[33mcommit 157562271416468eb7a52d4fc79236fac6708ac2[m
Author: Kevin Lewis <kevin.lewis@oracle.com>
Date:   Mon Feb 29 16:06:54 2016 -0600

    Bug 22361764: ASSERT AT NODE->MODIFICATION_COUNTER == NODE->FLUSH_COUNTER
    
    As a result of the following patch alter_kill is failing intermittently:
    
    Commit:      7185d836d074b5ca899c351edbff19d6084e0c40 [7185d83]
    Parents:     e22da5c44e
    Author:      Marko M??kel?? <marko.makela@oracle.com>
    Date:        April 28, 2015 at 3:43:57 AM CDT
    Bug#20961660 RPL TESTS ARE FAILING WITH INNODB:
         UNDO TABLESPACES MUST BE READABLE!
    srv_undo_tablespaces_init(): Close any opened undo tablespace files
    before opening the undo tablespaces.
    fil_space_open(), fil_space_close(): Take a numeric space_id instead of
    tablespace name as a parameter.
    RB:          8735
    Reviewed-by: Kevin Lewis <kevin.lewis@oracle.com>
    Reviewed-by: Mattias Jonsson <mattias.jonsson@oracle.com>
    
    The call stack indicates that the attempt to
    "Close any opened undo tablespace files before opening the
    undo tablespaces" is crashing because there are [1;31mbuffer[med
    changes to one of the undo tablespaces.
    PB2 indicates that this intermittent crash happens on a variety
    of platforms, not just Windows.
    
    So when srv_start() calls srv_undo_tablespaces_init(), the recovery process
    has already made some new entries into one of the undo tablespaces that
    now needs to be closed by srv_undo_tablespaces_init().
    Note that the patch above added this new call to fil_space_close().
    
    Add     fil_flush(undo_tablespace_ids[i]);
    just before     fil_space_close(undo_tablespace_ids[i]);
    
    Approved by Marko in rb#11966

[33mcommit 55aa9b6865fd28e11e8c2896f1c96ea332d6bcae[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Mon Mar 7 14:39:09 2016 +0100

    Fixed faulty ATR testcase 'test_event -n Apiv2EventBufferOverflow'
    
    wait_to_fill_[1;31mbuffer[m() always waited until 'retries'
    expired before it completed the 'fill'.

[33mcommit 56f7761cd1362de9249029e5309d14aaf49d12fe[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Fri Mar 4 13:38:12 2016 +0100

    Bug#22839888 UNINITIALIZED VALUE WHEN CONVERTING MULTIBYTE STRINGS TO NUMBERS
    
    Problem: valgrind warnings with clang in optimized mode.
    Fix: do not read past the end of the input [1;31mbuffer[m in my_strtod_int()

[33mcommit 25bf5b928a5863eea758af39dab2b80aa8b7fd35[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Thu Mar 3 16:25:44 2016 +0800

    BUG#22329393 - DEADLOCK BETWEEN FILESPACE RW-LOCK AND PERSISTENT COUNTER MUTEX
    
    This deadlock happens when there are one alter table requiring rebuild and
    removing the entry from DDTableBuffer, and the other is pessimistic inserting
    a new row containing autoinc counter. To remove the entry from DDTableBuffer,
    dict_persist::mutex should be held before the pessmistic delete, which
    requests the fielspace rw-lock. At the meantime, to pessimistic insert have
    held the filespace rw-lock to do the split and dict_persist::mutex is
    requested to mark the metadata(autoinc counter) of the table has been changed
    
    The fix would make sure the dict_persist::mutex should be held before the
    filespace rw-lock, thus no deadlock. So during inserting, persisting of the
    counter which requires the dict_persist::mutex should be done at first and
    then inserting operations. This should also be applied to update.
    
    To get the mutex and write the log at first, it would require some changes
    in mtr_t including introducing a new function mlog_open_metadata(),
    so that we can write changes not related to a page to mtr [1;31mbuffer[m first and
    get it committed correctly finally.
    
    RB: 11835
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Marko Makela <marko.makela@oracle.com>

[33mcommit 09c624b187aab895105e1256c69d7381f3a1b71b[m
Author: Shaohua Wang <shaohua.wang@oracle.com>
Date:   Wed Mar 2 09:17:35 2016 +0800

    BUG#22607584 INNODB.ANALYZE_TABLE HAS SOME TIMEOUTS
                 ON WEEKLY PB2 SOLARIS & VALGRIND RUNS
    
    The test is very slow because we insert 1M rows into a table,
    so that the table size is bigger than innodb_[1;31mbuffer[m_pool_size.
    We just disable the test on Solaris, and skip the test when
    log bin is enabled.

[33mcommit 8e973c16f53647a8d6f54b18d6f32ef86263add1[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Wed Feb 24 11:03:57 2016 +0000

    Bug #22749509 NDB : ALLOW SMALLER BACKUPDATABUFFER
    
    Allow smaller backupdata[1;31mbuffer[m sizes as these can help smooth the
    LDM CPU usage of LCP + Backup.
    
    Lowerbound is 512kB as 256kB is too low with default write size
    of 256kB.
    
    Add check to ensure that BackupDataBuffer is big enough to avoid
    producer + consumer deadlock.

[33mcommit 90c68896f594b8259a21c56a424c24daeb86f444[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Fri Feb 19 12:40:23 2016 +0200

    Bug#22742918 ASSERT BUF_PAGE_GET_IO_FIX(BPAGE)==BUF_IO_NONE, BUF_RELOCATE()
    
    buf_page_create_low(): Check if the [1;31mbuffer[m page is I/O-fixed,
    even if it is a compressed-only page.
    
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit eb36f39500de47d3bad6c80b52e09a6bb3b25239[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Thu Feb 18 13:41:06 2016 +0200

    Bug#22755053 REMOVE INNODB_DISABLE_RESIZE_BUFFER_POOL_DEBUG
    
    The debug variable innodb_disable_resize_[1;31mbuffer[m_pool_debug was
    introduced in a workaround in MySQL 5.7.6:
    
    Bug#20461123: SIGNIFICANTLY INCREASED TIME IN VALGRIND TESTS
    
    The root cause was fixed by removing the buf_block_align() calls in
    
    Bug#22709463 LATCHING ORDER VIOLATION IN BUF_BLOCK_ALIGN() DEBUG CALLS
    
    We will remove the variable innodb_disable_resize_[1;31mbuffer[m_pool_debug.
    
    Also, remove the variable buf_chunk_map_ref and simplify
    buf_pool_resize(), now that lookups cannot be performed concurrently
    with [1;31mbuffer[m pool resizing.
    
    RB: 11851
    Reviewed-by: Annamalai Gurusami <annamalai.gurusami@oracle.com>

[33mcommit 83fd9b02d8f8917bdfe6a1cd937a850a9b5955ae[m
Author: Maitrayi Sabaratnam <maitrayi.sabaratnam@oracle.com>
Date:   Thu Feb 18 16:52:42 2016 +0100

    Followup patch for WL#8626 Ndb replication : Improve event [1;31mbuffer[m log messages
    
    Fix compiler warnings on windows and remove a test case which is relevant only for pre-wl versions.

[33mcommit 5fb5593e55880605d88847697d100eb2d9797ae5[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Feb 17 16:23:09 2016 +0100

    Bug#22740246 FIX MORE ERRORS REPORTED BY UBSAN - THREE
    
    extra/yassl/src/[1;31mbuffer[m.cpp:323
    null pointer passed as argument 2, which is declared to never be null
    
    Move testcases for bug 21893562 from gis_bug_crashes to a separate
    file gis_not_ubsan.test
    This bug must be fixed by the boost geometry project
    
    sql/binlog.cc:2331
    sql/rpl_gtid_state.cc:178
    sql/handler.cc:2012
    member call on null pointer of type 'struct Gtid_state'
    
    sql/field.cc:8405
    null pointer passed as argument 2, which is declared to never be null
    
    mysys/mf_iocache.cc:1438
    null pointer passed as argument 2, which is declared to never be null
    Fix: Log_event::wrapper_my_b_safe_write check for size == 0
    
    sql/mysqld.cc
    Add "ubsan" to server name if built with HAVE_UBSAN.
    Add not_ubsan.inc
    This allows mtr tests to do --source include/not_ubsan.inc
    
    sql/partition_info.cc:1572
    signed integer overflow: 0 - -9223372036854775808 cannot be represented in type 'long long int'
    
    storage/innobase/include/ut0mem.ic:39
    null pointer passed as argument 2, which is declared to never be null
    
    keyring unit tests: disable all test cases which use googlemock.

[33mcommit 0fa2cc36835f0de7f5c772bdb96b093c2885813c[m
Author: Maitrayi Sabaratnam <maitrayi.sabaratnam@oracle.com>
Date:   Wed Feb 17 17:58:15 2016 +0100

    WL#8626 Ndb replication : Improve event [1;31mbuffer[m log messages
    
    This wl improves the event [1;31mbuffer[m memory usage reporting by:
    
    a) giving more explanatory, less confusing report fields
    b) adding the ndb object id to show which ndb event [1;31mbuffer[m reports the usage
    c) adding the reason for reporting event [1;31mbuffer[m memory usage status

[33mcommit 4ac11ce994fc7ba223d0df504d3129d36a993978[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Mon Feb 15 14:35:36 2016 +0100

    Bug#22663240 NEVER READ A PAGE IN BUF_PAGE_CREATE()
    
    The function buf_page_create() is invoked when a page is initialized
    so that any previous contents of the page will be ignored.
    
    In certain cases, this function was calling buf_page_get_gen(),
    which could theoretically cause a page to be read from disk, if
    the page got evicted from the [1;31mbuffer[m pool at the right moment.
    
    buf_page_create_low(): Try to assign a page to the [1;31mbuffer[m pool.
    
    buf_page_create(): Take fil_space_t* as a parameter. Callers no
    longer need to invoke buf_page_get().
    
    fsp_page_create(), fsp_alloc_free_page(): Take fil_space_t* as
    a parameter.
    
    RB: 11711
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit 5049737cfcfa5d0450c06d5579ebbd43e0fd4a1b[m
Author: Maitrayi Sabaratnam <maitrayi.sabaratnam@oracle.com>
Date:   Fri Feb 12 00:08:58 2016 +0100

    Bug#18753341 - NDB : SLOW NDBAPI OPERATIONS CAN CAUSE MAXBUFFEREDEPOCHS TO BE EXCEEDED
    
    Optimizing signal sending, by [1;31mbuffer[ming and sending them when the
    [1;31mbuffer[m gets full or periodically, may not suit for
    SUB_GCP_COMPLETE_ACK. Without the ack, Suma [1;31mbuffer[ms may overflow, and
    as a consequence, the API node will be disconnected. The fix sends the
    ack without delay.

[33mcommit ab7e9d22329ce72f6f4e7ad792bc5c4d1a90dcda[m
Author: Thayumanavar S <thayumanavar.x.sachithanantha@oracle.com>
Date:   Wed Feb 10 07:34:29 2016 +0100

    BUG#22142496 - VALGRIND ERRORS IN DD CODE ON FIRST STARTUP,
                   LOADING HELP_CATEGORY.
    
    The record object of the table struct is uninitialized when
    the key [1;31mbuffer[m is constructed. This causes the valgrind to
    report when system tables are registered during boostrap or
    when the key is a mulipart key consisting of varchar type.
    
    The fix is to initialize the table->record[0] from the
    corresponding table share default values [1;31mbuffer[m before the
    key [1;31mbuffer[m is constructed.

[33mcommit f8361d76a277d27bcba159194ab7c4f7b0ecb7c2[m
Author: Allen Lai <zheng.lai@oracle.com>
Date:   Fri Feb 5 21:25:01 2016 +0800

    Fixed bug#21747906 VALGRIND FAILURE: INNODB.INNODB_BUFFER_POOL_LOAD
    
    This test case try to load a not exist page, and it should fail, but the
    page in [1;31mbuffer[m pool is not initialized.
    We can't access the unintialized page.
    
    Reviewed-by: Jimmy Yang<jimmy.yang@oracle.com>
    RB: 11721

[33mcommit 00b9830cd66b1305fdbf1d6de0de782245e944ff[m
Merge: 83a60be5c1e 320b7af8dfc
Author: Robert Golebiowski <robert.golebiowski@oracle.com>
Date:   Wed Jan 27 14:25:17 2016 +0100

    Null merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            plugin/keyring/CMakeLists.txt
            plugin/keyring/[1;31mbuffer[m.h
            plugin/keyring/[1;31mbuffer[med_file_io.cc
            plugin/keyring/[1;31mbuffer[med_file_io.h
            plugin/keyring/i_keyring_io.h
            plugin/keyring/i_keyring_key.h
            plugin/keyring/i_keys_container.h
            plugin/keyring/keyring.cc
            plugin/keyring/keyring.h
            plugin/keyring/keyring_impl.cc
            plugin/keyring/keyring_key.cc
            plugin/keyring/keyring_key.h
            plugin/keyring/keyring_memory.h
            unittest/gunit/keyring/CMakeLists.txt
            unittest/gunit/keyring/keyring-api-t.cc
            unittest/gunit/keyring/keys_container-t.cc

[33mcommit 64971dba09c1c88d3ecc364044923e390631859d[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Jan 19 10:20:09 2016 +0100

    Bug#22561492 FIX MORE ERRORS REPORTED BY UBSAN
    
    Introduce cmakedefine HAVE_UBSAN, and use it to disable some unit
    tests which use gmock. Gmock calls member functions on NULL pointers.
    
    In Binary_log_event CTOR, do not set incident to an illegal value.
    
    Let mtr look for UBSAN memory leaks.
    UBSAN will exit(23) for this case, but the exit status of 'safe_process'
    is ignored by mtr.
    
    Detected by BitMapTest unit test:
    mysys/my_bitmap.cc:340:78:
    signed integer overflow: -2147483648 - 1 cannot be represented in type 'int'
    Fix: make the entire expression unsigned
    
    sql/auth/sql_user.cc
    null pointer passed as argument 1, which is declared to never be null
    
    dictionary_impl.h Failing unit tests:
    member call on null pointer of type 'struct Dictionary_impl'
    Fix: make getters default_catalog_id() and default_catalog_name() static
    member functions.
    
    field.cc
    null pointer passed as argument 1, which is declared to never be null
    
    sql/field.h
    load of value 143, which is not a valid value for type 'bool'
    
    write_str_at_most_255_bytes
    mf_iocache.cc:
    null pointer passed as argument 2, which is declared to never be null
    Fix: do not write zero-length string.
    
    Rows_log_event CTOR
    load of value 1835821430, which is not a valid value for type 'Log_event_type'
    Fix: use input argument to set commoon_header->type_code
    
    Relay_log_info CTOR
    load of value ... which is not a valid value for type bool
    Fix: initialize mts_end_group_sets_max_dbs
    
    table_def::create_conversion_table
    Several uninitialized fields caused by missing CTOR call.
    Fix: use placement new rather than alloc_root.
    
    sql_join_[1;31mbuffer[m.cc
    null pointer passed as argument 2, which is declared to never be null
    Fix: do not copy empty blobs.
    
    sql_thd_internal_api.cc
    null pointer passed as argument 2, which is declared to never be null
    Fix: do not copy empty query string.
    
    table.h
    null pointer passed as argument 1, which is declared to never be null
    Call stack was: JOIN::clear() | mark_as_null_row
    So this is a null row which has no nullable columns.
    Fix: do not memset zero bytes.
    
    sql/xa.h
    null pointer passed as argument 2, which is declared to never be null
    Fix: do not memcpy zero bytes.
    
    ha_innodb.cc
    null pointer passed as argument 2, which is declared to never be null
    Fix: do not memcmp zero bytes.
    
    ibuf0ibuf.cc
    shift exponent 35 is too large for 32-bit type 'int'
    Fix: use unsigned long when shifting
    
    data0data.ic
    null pointer passed as argument 1, which is declared to never be null
    Fix: do not memcmp zero bytes.
    Also in dfield_dup() no point in copying a NULL field->data.
    (mem_heap_dup will allocate non-zero size)
    
    myisam/mi_key.c
    null pointer passed as argument 2, which is declared to never be null
    Fix: do not memcpy zero bytes.
    
    pfs_engine_table.cc
    shift exponent 36 is too large for 32-bit type 'int'
    Fix: use unsigned long when shifting
    
    Suppress UBSAN in Mem_compare_uchar_int::operator()
    
    In multithreaded unit tests, use "threadsafe" death test style.
    
    A couple of suppressions when generating random data in unit tests.

[33mcommit c176426bfc863f3929e501df8d14fa2640bb45c1[m
Merge: 98b066f0376 d80f5822115
Author: Robert Golebiowski <robert.golebiowski@oracle.com>
Date:   Mon Jan 18 11:11:30 2016 +0100

    Null merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            plugin/keyring/[1;31mbuffer[med_file_io.cc
            plugin/keyring/keyring_impl.cc

[33mcommit 76161d5e4b3cdb5793af30a151a5bece4e9345d0[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Fri Dec 18 10:52:38 2015 +0100

    Bug#22284168: REMOVE NOW REDUNDANT SPACE RESERVATION IN JSON_DOM.CC
    
    json_dom.cc has code to make Strings grow exponentially instead of
    linearly. Bug#22239803 made String::append() grow the string [1;31mbuffer[m
    exponentially by default, so this code is redundant now.
    
    This patch removes manual growing of Strings in json_dom.cc. There are
    a couple of exceptions: We still reserve space manually in cases where
    data is added directly into the internal [1;31mbuffer[m without going through
    String::append().

[33mcommit 128632a9657d6dba09c0cbbb0f68f71d932333f6[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Jan 7 14:08:30 2016 +0100

    Bug#22391186 TRUE WHERE CLAUSE DOESN'T RETURN EXPECTED ROW, BUT EMPTY SET
    
    Problem: the function repeat() does not handle input from substr() properly.
    
    Solution: call uses_[1;31mbuffer[m_owned_by() to see if the input to
    repeat is a sub-string of a heap-allocated string.
    If so, copy into a temporary variable before doing the operation.

[33mcommit 9f6a35c017f7fdef7608cdac6aa4022476a86d23[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Dec 22 08:00:28 2015 +0100

    Bug#22321965 MORE HANDLER READ CRASHES IN FIELD_BLOB::GET_KEY_IMAGE
    
    Problem: Valgrind reports 'Conditional jump ...' in Field_blob::get_key_image
    Fix: Similar to the patch for Bug#17846865
        Do not search index if target index value is not stored into row [1;31mbuffer[m
        successfully.

[33mcommit aa89532413d77c5dc618a2fbb5c33765055fe212[m
Author: Maitrayi Sabaratnam <maitrayi.sabaratnam@oracle.com>
Date:   Fri Dec 18 16:20:11 2015 +0100

    Bug#22378288 - CLUSTER LOG: LATEST RESTORABLE GCI IN EVENTBUFFERSTATUS MSG IS FUZZY
    
    The definition of 'latest restorable global checkpoint' value returned in the
    'Event [1;31mbuffer[m status' message in Cluster log can be one of the following :
    the epoch which
     - is currently being consumed
     - will be consumed
     - was already consumed
     - is completely received but that has not reached the event queue yet.
    (though the report does not state which of the above cases was reported).
    
    This fix defines the 'latest restorable global checkpoint' as the one
    that is commpletely consumed by the user and thus is *the* latest
    restorable global checkpoint at *the time the report was created*.

[33mcommit 87235181490ad8faadb96620a3c3bbebf477d436[m
Author: Lakshmi Narayanan Sreethar <lakshmi.narayanan.sreethar@oracle.com>
Date:   Thu Dec 17 16:57:12 2015 +0530

    Follow up to Bug#22104597 and Bug #21777589
    
    Refactored ha_ndbcluster::prepare_inplace_alter_table() and
    ha_ndbcluster::prepare_drop_index()
    
    changes :
    
    ha_ndbcluster::prepare_inplace_alter_table()
     - index_drop_[1;31mbuffer[m is processed in a loop and at each run, and
       prepare_drop_index() is called for each index rather than being called
       at the end
     - This eliminates the need for storing index numbers. So the
       key_numbers is removed.
    
    ha_ndbcluster::prepare_drop_index()
     - Now takes in only one argument - key_num and mark that as
       TO_BE_DROPPED in the m_index array.
     - Removed the other arguments
    
    Also removed the unused implementation of ha_ndbcluster::add_index()

[33mcommit 423f2580964ec660844c805567dff7411fa5ad0a[m
Author: Arnab Ray <arnab.r.ray@oracle.com>
Date:   Thu Dec 10 18:23:25 2015 +0530

    Bug #22333764: FAILURE OF WORKQUEUE UNIT TEST
    
    The workqueue unit test was failing on a number of platforms
    with a "No plan found in TAP output" error.
    
    Fix involves ensuring that the test conforms to the TAP
    specification. Flushing the [1;31mbuffer[m to stdout periodically
    solves the issue.

[33mcommit cd24b332c4d4a258f18afa28cffd78fdb33d7a44[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Tue Dec 15 11:01:47 2015 +0530

    BUG#13535584 : 64BIT TESTS ARE SKIPPED ON A 64-BIT WINDOWS MACHINE
    
    Issue :
    =======
    64-bit tests are getting skipped on 64-bit windows machine. The reason for this
    issue is have_64bit.inc uses sort_[1;31mbuffer[m_size system variable which is of type
    ULONG_MAX. On 64-bit machine, the limit is 2^64, however 64-bit windows still
    defines this as 32-bit, hence making the available value much smaller(limit is 2^32).
    
    Fix :
    =====
    Modified have_62bit.inc to use 'myisam_sort_[1;31mbuffer[m_size' system variable which
    is of type ULONGULONG_MAX.
    
    Reviewed-by: Anitha Gopi <anitha.gopi@oracle.com>
    Reviewed-by: Horst Hunger <horst.hunger@oracle.com>
    RB: 11305

[33mcommit 6de35640d6ac2c6ce6854fb12ceedc6dbaec3693[m
Author: Satya Bodapati <satya.bodapati@oracle.com>
Date:   Mon Nov 30 19:32:27 2015 +0530

    Bug#22157724 - INNODB.MONITOR_RESTART FAILS WITH "UNEXPECTED COUNT"
    
    Problem:
    -------
    Test fails randomly with unexpected count. The unexpected count comes
    from
    
    1. Purge activity from mysql.collations tables (On every startup
       we do DELETE+INSERT into mysql.collations. This causes purge activity
       even after slow shutdown
    
    2. Persisting AUTO-INC values on log_checkpoint by master thread.
       DDL Statement (CREAT TABLE) inserts into DD tables (mysql.columns
       etc). Since these tables have a AUTO-INC column, the checkpoint can
       can also cause searches into B-tree indexes (see
       dict_persist_to_dd_table_[1;31mbuffer[m())
    
    Fix:
    ----
    To solve 1), we will use debug way to stop purge and Bug#22284224 is
    raised to solve the un-necesary DELETE+INSERT on every startup.
    
    For 2), we create table before restart. This makes sure that there
    are no inserts in DD tables.
    
    Also a debug assert is added to find threads which access any other
    table than "t1".
    
    Reviewed-By: Marko Mäkelä <marko.makela@oracle.com>
    RB: 11190

[33mcommit a2fbdc2d1eadc8ab8e27a3da083852f4c40cc65d[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Wed Nov 25 10:48:16 2015 +0100

    Bug#22239803 WITH NO MORE .FRM 64K LIMIT WE CAN CREATE MASSIVE TABLES, BUT TOO SLOW (II)
    
    This is a followup to the patch for:
    Bug#22157531 WITH NO MORE .FRM 64K LIMIT WE CAN CREATE MASSIVE TABLES, BUT TOO SLOWLY..
    
    That patch solved some special cases, but not the general case.
    The general problem is a design flaw in String::mem_realloc():
    the [1;31mbuffer[m grows linearly rather than exponentially.
    This means that 'n * append()' has cost O(n!)
    
    Switching to exponential growth, we get cost O(n) since append has
    (amortized) constant cost.

[33mcommit 2ef0f0470b518e8fe941dac0758d0bb254c56080[m
Author: Pavan Naik <pavan.naik@oracle.com>
Date:   Fri Nov 20 15:49:17 2015 +0530

    BUG#11748572 : ALLOCATING A LARGE QUERY CACHE IS NOT DETERMINISTIC
    
    Issue :
    =======
    Setting query_cache_size to larger values might fail depending on the
    memory pressure being put on the system. This can be seen on pushbuild
    as the test case query_cache_size_basic tries to allocate a +3GB query
    cache, which succeeds in some machines and fails in others.
    
    Both query_cache_size_basic_32.test and query_cache_size_basic_64.test
    are disabled.
    
    Fix :
    =====
    Since query_cache_size value can change depending on the memory pressure
    being put on the machine, remove/comment the test cases with large
    query_cache_size value and enable the tests.
    
    Modified myisam_sort_[1;31mbuffer[m_size_basic.inc to make 32-bit version of the
    test to run on windows 64 bit machine.
    
    Reviewed-by: Horst Hunger <horst.hunger@oracle.com>
    RB: 10986

[33mcommit 4ad473c9a663cb821ef5132ac03c665dbd195280[m
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Fri Nov 20 10:03:08 2015 +0100

    WL#6815 Adapt MySQL Cluster to 5.7
    
     - remove unused versions of isnull() and lex2str()
       which was there for 5.1 "compatibility"
     - remove isnull() since it was only used in one place
     - rewrite remaining lex2str() to automatically deduce
       size of the provided [1;31mbuffer[m
     - this fixes warnings regarding unused functions while
       using certain compilers on OSX.

[33mcommit c5a6240e0c3d771694c182bf6ec7fa036d8914e8[m
Author: Jon Olav Hauglid <jon.hauglid@oracle.com>
Date:   Tue Nov 10 13:45:12 2015 +0100

    Bug#22179518: ASAN: MEMORY LEAK IN INNOCHECKSUM, PART 2
    
    Fix memory leaks in innochecksum. Use Prealloced_array
    rather than raw byte [1;31mbuffer[ms to make sure the arrays are
    deallocated.
    
    The patch also changes MTR so that --valgrind-client applies
    to Innochecksum.

[33mcommit 1a505a93e22d65f645abadd10e043c6ed6d8ad2d[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Wed Nov 11 16:29:20 2015 +0800

    This is a temporary workaround to fix the failure for
    log_file_size_checkpoint, which would fail with:
    --mysqld--innodb_undo_tablespaces=5 --mysqld=--innodb_page_size=64k
    
    We raise the [1;31mbuffer[m pool size in this workaround, but we still want the
    final fixes from these two:
    
    Bug#22179133 - INNODB: TOO SMALL BUFFER POOL FOR INNODB_PAGE_SIZE=64K
    Bug#22186325 - INNODB: CRASH RECOVERY CAN RUN OUT OF BUFFER POOL
    
    Reviewed-by: Marko Makela <marko.makela@oracle.com>

[33mcommit 755a90a881461ba8ad0ed83ff7f9e23e8b21ca8a[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Wed Nov 11 08:47:54 2015 +0200

    Bug#22179745 AVOID ACCESSING THE DATA DICTIONARY BEFORE
    SRV_DICT_RECOVER_ON_RESTART()
    
    WL#7488 refactored the InnoDB startup so that the data dictionary
    would not be accessed before srv_dict_recover_on_restart().
    
    In WL#7816, the call to MetadataRecover::apply() was placed in
    srv_start(), which is too early.
    
    Furthermore, crash recovery with a small [1;31mbuffer[m pool can fail,
    because InnoDB would try to access the [1;31mbuffer[m pool before the
    redo log has ben fully applied. In this case, the [1;31mbuffer[m pool
    could be filled with dirty pages, plus memory allocations from
    the recv_sys subsystem.
    
    dict_load_tablespace(): Remove a workaround.
    
    page_validate(): Add a workaround. We will always have
    trx_sys->max_trx_id==0 during recv_apply_hashed_log_recs(TRUE),
    because the transaction system will be initialized later.
    
    mtr_t::~mtr_t(): Assert that pages will not remain unreleased when
    a mtr_t::commit() is skipped.
    
    recv_recovery_from_checkpoint_finish(): Return MetadataRecover*
    to apply. This will be assigned to a new variable, srv_dict_metadata.
    
    recv_apply_table_dynamic_metadata(): Remove.
    
    srv_fatal_error(): Move from srv0srv.cc to srv0start.cc.
    
    srv_undo_tablespace_open(): Do not call fil_set_max_space_id_if_bigger().
    Instead, let the caller invoke the function when needed.
    
    srv_start(create_new_db=true): Invoke fil_set_max_space_id_if_bigger().
    
    srv_start(create_new_db=false): Call srv_undo_tablespaces_init()
    and trx_sys_init_at_db_start() only
    after recv_recovery_from_checkpoint_finish().
    
    srv_dict_recover_on_restart(): Call srv_dict_metadata->apply().
    
    srv_shutdown_all_bg_threads(): Make the function static.
    Delete srv_dict_metadata.
    
    RB: 11005
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>

[33mcommit e5065ba320f0e3d2d818dc573be68e799dbfc9a1[m
Author: Olav Sandstaa <olav.sandstaa@oracle.com>
Date:   Fri Nov 6 10:04:56 2015 +0100

    Bug#22143189 OPT_COSTMODEL_RESTART FAILS RANDOMLY IN PUSHBUILD
    
    The opt_costmodel_restart tests fails sometimes due to a different
    cost estimate for reading a table than expected. The cause for this
    variation is that after a restart of the server the statistics about
    how much of a table that is in the InnoDB memory [1;31mbuffer[m can vary.
    
    The failing test case was run with different cost constants for
    reading pages from the InnoDB memory [1;31mbuffer[m and from disk. To ensure
    that the same cost estimate is produced in each run, the fix for this
    problem is to adjust the cost constants for reading pages from memory
    [1;31mbuffer[m and disk to have the same value.

[33mcommit 3a0dfd64e70a3db441c6301f593b2b41830590f7[m
Author: Knut Anders Hatlen <knut.hatlen@oracle.com>
Date:   Tue Oct 27 15:12:36 2015 +0100

    Bug#22104357: INCORRECT LENGTH CHECK IN FIELD_JSON::STORE_BINARY()
    
    When checking if a JSON document is larger than the maximum allowed
    document size, it should check the length of the input data and not
    the length of the internal [1;31mbuffer[m.

[33mcommit 0b8d749d85b5c40522663190ba0921ca7eda14a3[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Thu Oct 15 09:35:11 2015 +0200

    Patch for bug#21809959
    
    DROPPED EVENT OPERATIONS REMOVED TOO EARLY AFTER INITIAL RESTART
    
    Several objects in the NdbEventOperationImpl is garbage collected
    based on which GCI has been consumed by the clients. This also
    includes NdbEventOperations which are dropped by dropEventOperation().
    However, as the event_op can still have referrences from [1;31mbuffer[med
    events still not consumed, we cant destruct the event_op immediately.
    First when all events having a GCI <= the 'event_op->stop_gci' has been
    consumed, the event_op can be destructed.
    
    This mechanism relies on a monotonic increasing GCI number - which
    it is not! During initial restart the GCI sequence is reset and
    starts over again from 0/0. Thus leading to both event_op
    being prematurely released, or not released at all (leaked).
    See bug report for further explanation.
    
    This patch introduce a MonotonicEpoch, containing both the GCI
    and a 'gci generation'. The 'generation' is incremented every
    time there is a restart. Comparison operators are provided
    as part of the MonotonicEpoch such that the generation is
    used to provide a monotonic increasing sequence,

[33mcommit b1046230f724d29491ab7e8c685f61191d7e6360[m
Merge: 17390366628 64c88599cf8
Author: Magnus Blåudd <magnus.blaudd@oracle.com>
Date:   Fri Oct 9 15:41:18 2015 +0200

    Merge branch 'mysql-5.6-cluster-7.4' into mysql-5.7-cluster-7.5
    
    Conflicts:
            VERSION
            mysql-test/suite/ndb/r/ndb_join_pushdown_bka.result
            mysql-test/suite/ndb/r/ndb_join_pushdown_default.result
            mysql-test/suite/ndb/r/ndb_join_pushdown_nobnl.result
            mysql-test/suite/ndb/r/ndb_subquery.result
            sql/ndb_conflict.cc
            sql/ndb_conflict.h
            storage/ndb/CMakeLists.txt
            storage/ndb/VERSION
            storage/ndb/src/common/portlib/NdbThread.c
            storage/ndb/src/ndbapi/trp_[1;31mbuffer[m.cpp
            storage/ndb/test/run-test/daily-basic--02-tests.txt
            storage/ndb/tools/listTables.cpp
            storage/ndb/tools/restore/restore_main.cpp

[33mcommit fd3e0fae5894150b8df1493b8c631c50f46b51e7[m
Author: Menelaos Karavelas <menelaos.karavelas@oracle.com>
Date:   Wed Sep 30 16:32:57 2015 +0300

    Bug#21871856 ST_BUFFER() RETURNS AN INVALID POLYGON
    
    Problem: The [1;31mbuffer[m algorithm may compute a polygon with
    an interior ring that touches the exterior ring. This is computed internally
    in Boost.Geometry via a series of union operations, which instead of
    producing a polygon as described above, it produces a polygon with a single
    exterior ring that touches itself. This is what causes the validity failure:
    the self-intersection point of the exterior ring.
    Instead the [1;31mbuffer[m algorithm should have produced a polygon with a hole,
    which is not the case.
    
    Fix: Consider the rings produced during the traversal in the union operations
    mentioned above and split the rings at the appropriate points (points where
    the ring touches itself).

[33mcommit f456145abc4990e32fbd323f66b128cb0a6f4a64[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Thu Sep 24 16:10:59 2015 +0200

    Scale down the lock free hash unit test
    
    Make it suitable for automated PB2 testing where it is not acceptable
    for an unit test to prolong more than a few seconds.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 03e1b740017ec80916bb90876109fe8a50ec150b[m
Merge: 2de63b28ac9 15f1d8f0f67
Author: Marc Alff <marc.alff@oracle.com>
Date:   Wed Sep 23 18:07:53 2015 +0200

    Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            storage/innobase/srv/srv0srv.cc
            storage/perfschema/pfs_[1;31mbuffer[m_container.h

[33mcommit c00d26bcc6f1cd24dd3fdc80f5609b1ecf1d6fec[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Fri Sep 18 10:54:38 2015 +0200

    Patch for bug#21847552
    
    OVERFLOW IN CALCULATION OF 'MEMORY USAGE PERCENT' IN EVENT BUFFER
    
    If total amount of memory allocated for the event [1;31mbuffer[m exceeded
    ~40Mb, the calculation of 'memory usage percent' overflowed
    during calculation.
    
    Patch changed to use Uint64 arithmentics where this could happen.

[33mcommit 65939cb576b42f9da408414d609c6a49473f4dcb[m
Author: Craig L Russell <craig.russell@oracle.com>
Date:   Mon Sep 7 16:04:31 2015 -0700

    Bug#20504741
    Improve clusterj handling of direct [1;31mbuffer[ms
    
    Improve javadoc for new Session.release method

[33mcommit 215fd78ac63df2cf2fcd6db5f86c01a61f29ee5c[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Tue Aug 25 16:26:01 2015 +0100

    Testcase for 3 bugs
    
    21651400 NDB : LOOPBACK TRANSPORTER CAN DISCONNECT
    21664515 NDB : RESERVED SENDBUFFER FOR
    LOOPBACK_TRANSPORTER
    21683144 NDB : CLUSTERMGR DOES NOT CORRECTLY HANDLE
    DISCONNECT DURING CONNECTION SETUP
    
    This patch adds a testcase for these 3 bugs.
    The testcase reduces the Send[1;31mbuffer[m memory
    available in the MGMD node so that even the
    ClusterMgr heartbeast sending (API_REGREQ) causes
    quick SB exhaustion when sending is blocked to some
    node.
    
    When SB is exhausted due to one node being blocked,
    the other nodes experience on their send attempts,
    which causes their transporters to be scheduled for
    disconnection.  This includes the loopback
    transporter-to-self.
    
    With none of the fixes applied, this can result in
    the MGMD hanging as it discards necessary internal
    requests made over the loopback transporter as part
    of API block reference open+close, so some client
    threads get blocked holding shared locks etc.
    
    With bug 21651400 NDB : LOOPBACK TRANSPORTER CAN
    DISCONNECT applied, rather than hanging, the MGMD
    will shutdown.
    With bug 21664515 NDB : RESERVED SENDBUFFER
    FOR LOOPBACK_TRANSPORTER applied, rather than
    shutting down, the MGMD survives as the Loopback
    transporter is protected from general SB pool
    exhaustion. However, other links can still be
    shutdown unfairly.
    
    21683144 NDB : CLUSTERMGR DOES NOT CORRECTLY HANDLE
    DISCONNECT DURING CONNECTION SETUP is covered by
    this testcase as it was exposed by the testcase.
    With the bug fix applied, there are no failures
    due to this bug.

[33mcommit 138a1a45526b1c2c66b2929d871a87cf4223c898[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Wed Sep 2 15:28:38 2015 +0530

    Testcase prep : Add TransporterRegistry blockSend test functionality
    
    The TransporterRegistry already supports blocking
    receive from a particular transporter,
    blocking the reception of signals and e.g.
    socket closures.
    
    This patch adds blocking of send, so that sends
    will be [1;31mbuffer[med by SendBuffers, but not sent over
    the socket.  Note that this blocking does not
    currently affect socket closure handling, or signal
    reception.

[33mcommit 91d368cdfe8514627a8227e31dab67b93ae18eb8[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Aug 26 14:02:48 2015 +0300

    Fix a race between delete and copy-to-next
    
    There is a bug in the lock free hash table used in WL#7170:
    
    During copy to the next array tuples with val = DELETED are skipped and
    not copied as an optimization because such tuples are treated as they do
    not exist, so their existence is not necessary and they only take up
    space.
    
    But there is the following race between copy and concurrent delete:
    
    copy: copy to the next array because val != DELETED (e.g val == 12345)
    (now the next array contains the tuple with val == 12345)
    
    del: change val from 12345 to DELETED
    
    copy: try to CAS val from 12345 to GOTO_NEXT_ARRAY, but it fails because
          val is now DELETED. CAS will return the most recent val and it
          will be DELETED
    
    copy: since CAS failed and we have the most recent value (DELETED), copy
          again to the next array, but val == DELETED and we skip this
          operation as the buggy optimization, nothing is done
    
    copy: try to CAS val from DELETED to GOTO_NEXT_ARRAY, success.
    
    Now the old array contains a tuple with val == DELETED, the next array
    contains a tuple with val == 12345 and the effect of the delete
    operation is lost.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit a0b4d557e2645379f5cc8a94eb9332c4020fa0ba[m
Merge: 43a3d972888 5e2faa44fff
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Aug 20 09:32:29 2015 +0300

    Merge branch 'mysql-trunk-wl7170' into mysql-trunk
    
    * mysql-trunk-wl7170:
      Add a comment about a magic number.
      Comment in os0numa.h why we stick to the Linux API
      Free the memory that was allocated by LocalAlloc()
      Add some comments and a whitespace fixup
      Add a basic mtr test to exercise the new I_S table
      Handle >64 CPUs in Win/os_numa_num_configured_cpus
      Implement os_numa_*() on Windows
      Rename the multi counter to a lock free counter
      Scale down the lock free hash unit test
      Remove a debugging #error
      Add is_ibuf() method to the index_id_t class
      Move the index_id to int conversion to index_id_t
      Non-func: style fixups and code elaborations
      Do not double the size on grow if too many deleted
      Remove temporary debugging printouts
      Silence a compilation warning on Windows
      Non-func: rename some variables
      Fix compilation when libnuma is available
      Simplify the extension of the lock free hash
      Extend the hash grow unit test
      Fix a typo in comment
      Free old arrays' memory in the lock free hash
      Non-func: Rename the hash's sentinel constants
      Prepare for freeing: readers inc/dec a ref counter
      Implement a NUMA-aware counter
      Non-functional style fixup
      Fix a race in parallel grow of the lock free hash
      Fix a UT_DELETE() vs UT_DELETE_ARRAY() mismatch.
      Elaborate a comment.
      At the end, free all arrays in the lock free hash
      Also count the root page of an index
      Adjust mysqlshow.result: a new I_S table was added
      Add an I_S table to peek at the buf stats
      Change buf_stat_per_index_t::get()'s return type
      Add support for testing tbb::concurrent_hash_map
      Plant memory fences to prevent reordering
      Whitespace fixup
      Use a dedicated PFS mem key for the lock free hash
      Don't delete index stats when dropping the index
      Fix compilation failure on 64-bit Windows
      Fix compilation error after mutex API changes
      Copy all tuples to the new array(s) when growing
      Ensure that the number of elements is > 0
      Make m_data atomic because we will be changing it
      Combine a common code from set() and delta()
      Non-func: typedef the type of the nodes
      Go to the next array if the val is flagged as such
      Go to the next array if the val is flagged as such
      Change test lables so that they are aligned
      Remove the commented out atomic inc code
      Add a new unit test: many threads update few keys
      Fix a comment
      Combine inc() and dec() into a single method
      Add more tests of the lock free hash
      Non-func: make it easier to uncomment test macros
      Adjust mutex usage after API change in b80c0b8
      Update outdated comment
      Disable stats collection in the lock free hash
      Relax the memory ordering constraint in set()
      Relax memory ordering constraints in inc()/dec()
      Relax memory ordering constraints wrt array grow
      Temp enforce that boost atomics are lock free
      Clock the timing of the lock free hash unit tests
      Remove unnecessary header include
      Use boost::atomic counters in ut_lock_free_hash_t
      Fix a compilation failure on 32 bit CPUs
      Use boost::atomic instead of os_atomic_t
      Implement a delete operation in the lock free hash
      Non-func: minimize the scope of ibuf_index_id
      Skip too big index ids
      Add a 64 bit CAS() macro on Windows
      Skip ibuf and temp-table pages in stats accounting
      Revert unnecessary whitespace changes
      Use space_id+index_id for identifying an index
      Change the lock free hash value type to signed
      Introduce a mimicry of std::atomic and use it
      Remove the inclusion of an unneeded <map> header
      Revert "Test the mysys's lockfree hash"
      Test the mysys's lockfree hash
      Rename simple_hash_t->std_hash_t in the unit test
      Extend the hash table unit test
      Implement growing of the lock free hash table
      Add gunit test for the lock free hash table
      s/key/m_key/ in ut_lock_free_hash_t::key_val_t
      Add debug asserts to confirm sane key/vals
      Implement a lock free hash table
      Account the creation of new pages
      Ship the estimate of cached pages to the Optimizer
      Account the eviction of leaf pages from the BP
      Account reading of leaf pages into the [1;31mbuffer[m pool
      Add a global key,value store for per-index stats
    
    Reviewed-by: Annamalai Gurusami <annamalai.gurusami@oracle.com>
    Reviewed-by: Kevin Lewis <kevin.lewis@oracle.com>
    RB: 8986

[33mcommit 3e4d729bfd9432db9d54076ba11f2670ad9281db[m
Author: Ole John Aske <ole.john.aske@oracle.com>
Date:   Wed Aug 19 10:56:16 2015 +0200

    Patch for bug#21651536:
    
    POLLEVENTS() RETURNS INCORRECT 'LATESTGCI'
    
    The internal NdbEventBuffer::m_latestGCI was not always updated
    when a completed epoch of event [1;31mbuffer[ms is inserted into the
    event queue. Thus later calls to pollEvents() fails to get and return
    a correct GCI of the events available in the [1;31mbuffer[ms.
    
    Added a testcase and asserts catching if nextEvent() is about
    to return an event with a higher GCI than previously polled,

[33mcommit 5ec1eb47c6712fc1518f9df96a50558abbc98820[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Aug 19 10:04:51 2015 +0300

    Add a comment about a magic number.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 53ee41599414ac798976bf27c5e48fd523386019[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Aug 19 09:47:26 2015 +0300

    Comment in os0numa.h why we stick to the Linux API
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit a2a9cfd974043e6674965e61e6e0163c2585fa08[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Aug 18 22:59:47 2015 +0300

    Free the memory that was allocated by LocalAlloc()
    
    Previously the pointer passed to LocalFree() was not obtained by
    LocalAlloc() but rather a modified such one.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes
    
    Spotted by: Daniel Blanchard <daniel.blanchard@oracle.com>

[33mcommit 734938fb579f0bc6dbe7dea156390fc8ab26485f[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Aug 18 15:13:21 2015 +0300

    Add some comments and a whitespace fixup
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes
    
    Suggested by: Kevin Lewis <kevin.lewis@oracle.com>
    RB: 8986

[33mcommit e6ff4398fbac5f2c052a616c57f636bd626c3b47[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Aug 18 14:31:57 2015 +0300

    Add a basic mtr test to exercise the new I_S table
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 391e4037f28184531e7199ec0d2bbc84fa4aa34d[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Aug 18 11:32:14 2015 +0300

    Handle >64 CPUs in Win/os_numa_num_configured_cpus
    
    Use GetLogicalProcessorInformationEx() to retrieve the number of logical
    CPUs in the system on Windows, instead of GetSystemInfo() because the
    latter will only return the number of processors in the current group if
    there are more than 64 logical CPUs in the system.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit d146bae0e40b8847eb8d9462458e451183203fe1[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Aug 17 13:59:20 2015 +0300

    Implement os_numa_*() on Windows
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 7771a5c1a9f1599da44f5e8b34bb7caf10bb3e56[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri Aug 14 10:23:04 2015 +0300

    Rename the multi counter to a lock free counter
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes
    
    Suggested by:   Annamalai Gurusami <annamalai.gurusami@oracle.com>
    RB: 8986

[33mcommit 97eb36a35881a33c14778f56c69a55bf7ddad294[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Aug 13 10:58:34 2015 +0300

    Scale down the lock free hash unit test
    
    Make it suitable for automated PB2 testing where it is not acceptable
    for an unit test to prolong more than a few seconds.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 888b35a540f4c316465ab43301146cf447f84d4e[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Aug 13 10:39:15 2015 +0300

    Remove a debugging #error
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit a634e03a2b099d3f6c553eee53554c245be26548[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Aug 10 14:25:45 2015 +0300

    Add is_ibuf() method to the index_id_t class
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes
    
    Suggested by: Annamalai Gurusami <annamalai.gurusami@oracle.com>
    RB: 8986

[33mcommit ec93ec773fb44c1ade14bf7d7ccfe682d0889ee4[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Aug 10 13:25:11 2015 +0300

    Move the index_id to int conversion to index_id_t
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes
    
    Suggested by: Annamalai Gurusami <annamalai.gurusami@oracle.com>
    RB: 8986

[33mcommit b752f3e3df74f6421d7a5cb10b11ef063b61c3ac[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri Aug 7 14:03:28 2015 +0300

    Non-func: style fixups and code elaborations
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes
    
    Suggested by: Kevin
    RB: 8986

[33mcommit 189b58af482a0f95a696fbba7003e674ccd78648[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri Aug 7 13:10:02 2015 +0300

    Do not double the size on grow if too many deleted
    
    When growing the hash table do not double the size of the new
    chunk/array if the old one has too many deleted elements. This avoids a
    pathological case where one element is deleted and another one added in
    a loop. Then the array would be filled with deleted elements and
    expanded with a new unnecessary doubled size.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit ad3bf9077b8cdf4f3f028fcba65b77621e88cbbc[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri Aug 7 12:02:23 2015 +0300

    Remove temporary debugging printouts
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit b7c1e09359a930118117eadfab0625cf8c54adbc[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Aug 6 13:33:45 2015 +0300

    Silence a compilation warning on Windows
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit b0d104c281641ba47d9899fae279797c38ab95a7[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Aug 5 19:22:19 2015 +0300

    Non-func: rename some variables
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 7baacbae3add026745b2171649b5c76b55a2f0c2[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Aug 5 18:49:37 2015 +0300

    Fix compilation when libnuma is available
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 54f74c22d54e3d810ee30720c951b59917c44b6a[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Aug 5 15:30:40 2015 +0300

    Simplify the extension of the lock free hash
    
    Serialize the code that copies entries from one array to the next one(s)
    and then frees the unused array. This has a performance impact only on a
    workload that does an aggressive grow (uncommon), but is much simpler
    and thus easier to maintain.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 3951520ee1beee4be905461f405794e294797cbb[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Aug 5 13:35:59 2015 +0300

    Extend the hash grow unit test
    
    Start with a very small hash table of size 1 instead of size 1024. This
    causes much more grow operations in an aggressive manner.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit f5945b9b14909e477da3e8607cbf17e5f7ccef3f[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Aug 4 09:46:10 2015 +0300

    Fix a typo in comment
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit cbb3f6c0c28ac7716e9c3824ae654b9f97fa1884[m
Author: Frazer Clement <frazer.clement@oracle.com>
Date:   Tue Jul 28 12:19:58 2015 +0100

    Bug#20204854       BACKUP FAILING UNDER HEAVY LOAD EXCEPT WHEN SNAPSHOTSTAR
    Bug#21362380       NDB : LOG MAXDISKWRITESPEEDCHANGES FROM ONE LDM INSTANCE
    
    Background
    
    During normal operation, data nodes attempt to maximise
    the disk write speed used for LCP and Backup while remaining
    within the bounds of the configured MinDiskWriteSpeed and
    MaxDiskWriteSpeed.
    
    In 7.4, the implementation of disk write throttling was
    changed to give each LDM thread an equal share of the total
    budget.  This allows parallel LCP to occur without exceeding
    the configured disk IO budget.
    
    However, Backup is executed by only one LDM thread, and so
    it effectively suffered a budget cut.  This results in
    slower time to backup completion, and, if the change
    rate is high enough, can result in failure to backup
    as the Backup log [1;31mbuffer[m fill rate is higher than the
    achievable write rate.
    
    Solution
    
    This patch adds a new cluster configuration parameter :
    
    BackupDiskWriteSpeedPct
    
    This parameter defaults to 50(%) and can be set between
    0(%) and 90(%).
    
    When a Backup starts, the configured percentage of the
    node's maximum write rate budget will be reserved prior
    to sharing out the remainder of the budget amongst LDM
    threads for LCP.
    
    The LDM thread running the backup will receive the whole
    write rate budget for the Backup, plus its (reduced) share
    of the write rate budget for LCP.
    
    This increased budget makes the disk write rate budget
    behave in a similar way to releases < 7.4.
    
    Additionally, a new node log message has been added which
    appears at the end of a Backup and indicates the high-water-mark
    usage of the Backup log [1;31mbuffer[m.  This can be an aid to efficiently
    configuring this parameter.
    
    Notes :
    The LDM thread with increased 'budget' is still free to
    assign the budget to LCP/Backup scan/Backup log on a
    first-come-first-served (FCFS) basis, so the bandwidth
    is not guaranteed.
    
    Reducing the budget available to LCP on the other LDM
    threads will slow the LCP for the duration of the backup.
    This can affect the amount of Redo and Undo log space
    needed.
    
    A separate bug where each LDM thread reported max speed
    changes separately has also been fixed.
    
    Example :
    
    Max write rate = 20MB/s
    Num LDMs = 4
    
    Normal case (no backup):
    
    Each LDM has a Max write rate of 20/4 = 5MB/s
    
    Backup case
    
    Node backup budget = 50% of 20MB = 10MB/s
    Node LCP budget = 20 - 10 = 10MB/s
    Per-LDM LCP budget share = 10/4 = 2.5MB/s
    
    Backup LDM thread budget : 10 + 2.5 = 12.5MB/s
    Other LDM threads budget : 2.5MB/s
    
    Total budget = 12.5 + 2.5 + 2.5 + 2.5 = 20MB/s
    
    Notes :
    
    - 50% default gives similar behavior to previous releases
    - 0% gives current behaviour
    - Increased budget is not guaranteed for Backup log - similar
    to previous releases.

[33mcommit 77dae1a340b2cafc9e298d8954c5be99ae2309ed[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri Jul 24 17:49:52 2015 +0300

    Free old arrays' memory in the lock free hash
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 47158d5fa40e61a31287c1a4c0932cb3ef12b593[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jul 22 10:51:34 2015 +0300

    Non-func: Rename the hash's sentinel constants
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 8b34ae696fc67dbbe8d42351d78a9af66821fce8[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jul 22 10:04:19 2015 +0300

    Prepare for freeing: readers inc/dec a ref counter
    
    Mark the beginning and ending of an access to a given array in the list
    of arrays by incrementing a counter. This will be used when freeing a
    given array that has been garbage collected.
    
    After an array has been added to the garbage bin, then no new readers
    can arrive to it. Then we know that if an array in the garbage bin has
    current number of readers equal to 0, then it is safe to free it.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 919546a78208206ed883fe2ca022457031b8bf1c[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jul 21 13:07:40 2015 +0300

    Implement a NUMA-aware counter
    
    The counter uses a few variables internally, each one dedicated to a
    given CPU and allocated on that CPU's NUMA node.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit deed2e8a101961ebd8525cd415ee01729bac6c9f[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Jul 20 14:06:22 2015 +0300

    Non-functional style fixup
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 9d8500164b0ee3627ba65115b1e8f909dcec2997[m
Author: Craig L Russell <craig.russell@oracle.com>
Date:   Sat Jul 18 17:37:01 2015 -0700

    Bug#20504741
    Improve clusterj handling of direct [1;31mbuffer[ms
    
    With this patch applied, LeakTest runs for thousands of iterations
    with no additional usage of direct memory.
    
    SessionImpl.java
      if find does not find a row in the database, release the key handler
    
    LoadTest.java
      verify that if load doesn’t find a row, the instance is still valid

[33mcommit cc0e14bbf1ea72004951442b1bf07421b1277e76[m
Author: Craig L Russell <craig.russell@oracle.com>
Date:   Sat Jul 18 14:18:30 2015 -0700

    Bug#20504741
    Improve clusterj handling of direct [1;31mbuffer[ms
    
    DbImpl.java
      implement borrow and return partition key byte [1;31mbuffer[ms
    
    PartitionKeyImpl.java
      implement borrow and return partition key byte [1;31mbuffer[ms
    
    Utility.java
      add new methods to use parameter byte [1;31mbuffer[ms instead of allocating
        these methods are used in partition key handling
        convertValue(ByteBuffer [1;31mbuffer[m, Column storeColumn, byte value);
        convertValue(ByteBuffer [1;31mbuffer[m, Column storeColumn, short value);
        convertValue(ByteBuffer [1;31mbuffer[m, Column storeColumn, int value);
        convertValue(ByteBuffer [1;31mbuffer[m, Column storeColumn, long value);
    
    VariableByteBufferPoolImpl.java
      fix bug where the [1;31mbuffer[m used to acquire the Cleaner is not cleaned

[33mcommit c3a3ff1f960a994a299a54a074e6c687bc9a116c[m
Author: Craig L Russell <craig.russell@oracle.com>
Date:   Thu Jul 16 21:11:52 2015 -0700

    Bug#20504741
    Improve clusterj handling of direct [1;31mbuffer[ms
    
    BlobImpl.java
      use [1;31mbuffer[m pool for setValue
    
    ClusterConnectionImpl.java
      implement [1;31mbuffer[m pools for:
        DbImpl error [1;31mbuffer[m,
        DbImpl coordinated transaction id [1;31mbuffer[m,
        DbImpl partition key scratch [1;31mbuffer[m,
        DbImpl string scratch [1;31mbuffer[m
    
    DbImpl.java
      use [1;31mbuffer[m pools for error, transaction id, partition key, string
    
    DbImplForNdbRecord.java
      use [1;31mbuffer[m pool for error
    
    NdbRecordBlobImpl.java
      promote [1;31mbuffer[m handling to BlobImpl.java
    
    Utility.java
      fix bug that used capacity instead of limit for [1;31mbuffer[m handling
    
    VariableByteBufferPoolImpl.java
      fix bug that returned [1;31mbuffer[ms with wrong position

[33mcommit aa2dc24910c7f6eb00757379ad523b35b818f4cf[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jul 15 18:36:31 2015 +0300

    Fix a race in parallel grow of the lock free hash
    
    Synchronize modifications of arr_node_t::m_next from one array to
    another to prevent a scenario where a just appended entry is garbage
    collected and then wrongly re-added in the array when garbage collecting
    the previous one:
    
    A.next is B
    B.next is NULL
    B becomes full
    B.grow()
    bnext = B.next
      (the problem is if bnext is garbage collected here and removed from
      the list by another thread)
    A.next = bnext
    B is now removed from the list
      (now A.next could point to a garbage collected entry)
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 1494423a7097c84871eead8cb1d632a9ffdb2223[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jul 15 18:03:40 2015 +0300

    Fix a UT_DELETE() vs UT_DELETE_ARRAY() mismatch.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 74670bcf961cd8dfdedc14b12847557c026c3826[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jul 14 20:28:56 2015 +0300

    Elaborate a comment.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 10a07a5a27302bd56b0d154e8e425d288b58541a[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jul 14 18:49:57 2015 +0300

    At the end, free all arrays in the lock free hash
    
    When the lock free hash table is destroyed, delete all the arrays in the
    list, not just the first one.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit d833613d47c4093bf55101693feca1e1cd5dad96[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jul 14 09:16:48 2015 +0300

    Also count the root page of an index
    
    btr_page_create() is only used for creating non-root pages, so plant a
    hook for accounting the number of pages per index in btr_create() which
    creates the root page without using btr_page_create().
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit a365d5e5328518b685e1031806a198eab4f934b7[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jul 14 09:14:57 2015 +0300

    Adjust mysqlshow.result: a new I_S table was added
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 206b7bdbc114e7505fb52d8349a4433be22caf48[m
Merge: 8358d59e0ed 7d8937daf6f
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Jul 13 19:17:19 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      BUG#21389101 ST_GEOMFROMGEOJSON: STACK OVERFLOW IN RAPIDJSON::GENERICREADER
      Bug#21383284: ASSERTION IN SELECT_LEX::SETUP_CONDS
      BUG#21303289  Removed sqlbench leftover in deb platform pkg src
      BUG#21434004   UBUNTU 15.04 REPO PACKAGES DO NOT CONTAIN ESSENTIAL SCRIPT LIKE MYSQLD_SAFE list of files being re-installed in server pkg: +usr/bin/mysqlbinlog +usr/bin/mysqld_multi +usr/bin/mysqld_safe
      Remove MCP_GLOBAL_SCHEMA_LOCK patch
      Fix syntax error in ndbinfo_sql.cpp
      Fixed mysql_ssl_rsa_setup test failing on Windows after pushing bug fix for bug#21025377
      BUG#21280816 CONNECTION PERFORMANCE REGRESSION TEST HANGS SYSBENCH
      Keep ndbinfo_sql.ccp in sync with mysql_system_tables.sql
      Remove unintentional change in variables-big.test
      Bug #20168526 YASSL: CORRUPT SSL-KEY CRASHES CLIENT
      Version change in d/changelog for DEB pkg src 5.7.9+ are non-rc releases
      - Bug#21407023: DISABLING AHI SHOULD AVOID TAKING AHI LATCH   Currently if AHI is disabled check for it was protected by AHI latch which   caused latch overhead even though the feature is not adding any value.
      Bug#21429471 - COMMUNITY/COMMERCIAL EL7 UPDATE FAILING WHEN MARIADB-BENCH.X86_64 INSTALLED
      Bug #20728894: MEMORY LEAK IN ADD_DERIVED_KEY()
      Bug #21056907: CONTENTS OF NOT REQUESTED CHAR/VARCHAR                COLUMN ARE REVEALED
      Bug #20777016: DELETE CHECKS PRIVILEGES ON THE WRONG                DATABASE WHEN USING TABLE ALIASES
      Bug #18636874 PASSWORD VALIDATE PLUGIN: DICTIONARY CHECK MISBEHAVES WITH GOOD HEX INPUT
      WL#7254 Audit API extensions
      Bug#21374104 SETUP_TIMERS INITIALIZATION ASSUMES CYCLE TIMER IS ALWAYS AVAILABLE
      Bug #20087571: 5.7 EASILY HITS ERROR 1436 (HY000): THREAD STACK OVERRUN ERRORS ON MANY EXPR'S
      Bug#21383896 DECIMAL FIELD TAKES IN VALUES FROM OTHER FIELDS
      Bug#21153489 VALGRIND ERRORS IN ITEM_BOOL_FUNC2::IS_NULL LEAD TO CRASH LATER
      Fix syntax errors in 16node-tests.txt and upgrade-tests.txt
      Bug#21337139 ATRT SILENTLY STOPS TESTING AT FIRST SYNTAX ERROR IN TEST CASE FILE
      Fix a compilation error after bc098885
      Bug#21338012 MTR MANUAL-GDB OPTION DOES NOT WORK
      Bug #21280801: VERSION TOKEN LOCKING DOES NOT WORK
      BUG#21421471 LICENSE HEADERS MISSING IN FILES
      Bug#21300774 ASSERT `!INIT_FTFUNCS(THD, SELECT_LEX)` IN JOIN::RESET AT SQL/SQL_SELECT.CC:874
      Bug#21300774 ASSERT `!INIT_FTFUNCS(THD, SELECT_LEX)` IN JOIN::RESET AT SQL/SQL_SELECT.CC:874
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      BUG#20074353 HANDLE_FATAL_SIGNAL (SIG=11) IN MY_B_WRITE | MYSYS/MF_IOCACHE.C:1597
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      Addendum 2 to bug #21034322: removed the max test due to it being different for different OSes
      Follow up fix for WL#8149 change, fix create_thd() issue and test mismatches
      Merge WL#8149 related worklogs to mysql-trunk
      Bug#21271736 UNITTEST UT0CRC32-T HANGS ON SOLARIS 10 SPARC
      Bug#21381060 A "CASE WHEN" EXPRESSION WITH NULL AND AN UNSIGNED TYPE GIVES A SIGNED RESULT
      Bug #18871046 SET NUMA MEMPOLICY FOR OPTIMUM MYSQLD PERFORMANCE
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Remove non experimental test.
      Bug#18949282 I_MAIN.MYSQL_CLIENT_TEST FAILED AT LINE 43, COMMAND $I_M_C_T
      Configure smaller redo log for test ndb.ndb_backup_rate.
      Updating the test case ndb_addnode_restart* :  The autotest testSystemRestart had an additional restart loop  in runAddNodesAndRestart function, which is not needed as there  is no change in the configuration of the cluster.  Removed that and updated the name of the funcction and added few  comments to explain the proper setup of the testcase
      Fix for WL#7763
      WL#7763, remove use of inet_ntoa from ndb parts
      Post-push test fix for Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      Bug#17493646 NDB: CALL TO MY_ERROR() LACKS ERROR CODE AND ERROR STRING ARGUMENTS
      Bug#21352763 FLEXASYNC SEGFAULTS IF FAILED TO CREATE TABLES
      BUG#21297407: Fix to ensure sending CONTINUEB with proper variables in dropTable_wait_usage
      Pushing BUG#21297407 revealed an uninited variable in Fragrecord in DBLQH (lcp_frag_ord_state, was set to LCP_QUEUED == 0 in most cases which led to crash if drop table happened before LCP had time to execute
      BUG#20981491: Fix resource issues for NR, LCP andb Backup with regard to scan numbers, BUG#21362758: Crash with holding LocalDLFifoList context over call EXECUTE_DIRECT(NEXT_SCANCONF), BUG#21370839: Ensure also ACC scans are queued in a proper manner, previous push only added test case to autotest
      BUG#20981491: Fix resource issues for NR, LCP andb Backup with regard to scan numbers, BUG#21362758: Crash with holding LocalDLFifoList context over call EXECUTE_DIRECT(NEXT_SCANCONF), BUG#21370839: Ensure also ACC scans are queued in a proper manner
      BUG#20993380: (Also BUG#69994 in community bugs), ensured that node recovery and LCP scans can continue even if user has used up all resources for user level transactions, reserved operation records and segments for necessary things during LCP and NR scans
      Fix test case testRedo -n RedoFull
      Fix testRedo -n RedoFull test case
      BUG#21297407: Speed up drop table
      Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Raise version number after cloning 7.1.36
      Raise version number after cloning 7.3.10
      Raise version number after cloning 7.4.7
      Raise version number after cloning 7.2.21
      Fixed syntax errors in daily-basic-tests.txt
      Implement required methods in clusterj-openjpa
      Bug#20504741 Improve clusterj release of byte [1;31mbuffer[ms by adding a user method session.release
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7570 Remove ifdefs which are not necessary since trunk has it all
      Bug #20592110         CLUSTER CIRCULAR REPLICATION WITH IGNORE_SERVER_IDS() BROKEN BY ANONYMOUS_GTIDS
      revert change to mysql-test-run
      Bug #21326540         NDB_JOIN_PUSHDOWN TESTS UNSTABLE EXECUTE_COUNT
      Remove obsolete ifdef
      Add comment re. valgrind
      WL#6815 Adapt MySQL Cluster to 5.7
      Revert "WL#6815 Adapt MySQL Cluster to 5.7"
      Removed extra blank line in ATRT test scripts preventing tests to start (Due to ATRT bug)
      Bug #17878183       NDB CONTINUOUSLY REBOOTING DUE TO FILE NOT FOUND (DBLQH:
      Bug#17493646 NDB: CALL TO MY_ERROR() LACKS ERROR CODE AND ERROR STRING ARGUMENTS
      Increase timeout for ATRT test
      Increase timeout for ATRT test
      BUG#20904721, WL#8525: Fix of part9, used internal TUP pointer instead of LQH pointer when calling LQH function directly, leads to both wrong handling and sometimes even a crash when index is not a used scan pointer
      Apply pollEvent_v4.patch from Ole John
      restore new scheduler & multiwait fix to bug branch
      If memcached crashes, mysql-test-run should not restart it.
      On misc. errors, print workitem to debug log
      always compile ndb memcache with DEBUG_OUTPUT
      More unified error handling
      New record_ndb_error() function where error logger keeps statistics but caller is resposnsible for writing to log file. Direct error messages to the debug log if enabled.
      The table scan code where NDB Memcache reads it configuration tables was written poorly, and could cause memcached to crash during configuration.
      revise debug messages in new scheduler
      switch default scheduler to Trondheim
      always compile ndb memcache with DEBUG_OUTPUT
      More unified error handling
      New record_ndb_error() function where error logger keeps statistics but caller is resposnsible for writing to log file. Direct error messages to the debug log if enabled.
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Bug#11759461 NDB_CONFIG --XML --CONFIGINFO: VARIOUS UPDATES TO PARAMETERS LISTED
      Bug#11760628 DEPRECATE EXECUTEONCOMPUTER
      Bug #21270509         FAULTY COMMENT DESCRIBING NDB_MGM_NODE_STATE.CONNECT_ADDRESS IN MGMAPI.H
      Bug #21270425         MGMAPI.H SPELLING ERROR
      Bug#20617891: NDB : SUSPICIOUS HANDLING OF SIGNAL-WAIT TIMEOUT IN NDBAPI
      read configuration in a single consistent transaction
      The table scan code where NDB Memcache reads it configuration tables was written poorly, and could cause memcached to crash during configuration.
      Revert "Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000"
      Revert "Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000"
      Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      BUG#20904721: Fix for a number of asserts that assumed interpreted mode for all scans
      BUG#20727343: Fix failing ndb_dd_initial_lg test case, minor initialisation issue
      reapply bugfix in this branch. do not push this change to 7.4
      move another message from debug to detail level
      move another message from debug to detail level
      WL#8525: Part 11, don't use interpreted execution for LCPs and Backups since it is a waste of CPU resources
      BUG#20904721: Part 9: Implementing the adaptive LCP speed using bounded delay concepts and A-level signals
      more safety when Ndb::startTransaction() fails
      more safety when Ndb::startTransaction() fails
      add a more detailed debug output level to ndb memcache
      Anticipate SERVER_ERROR responses in My::Memcache.pm
      Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      Test case for Bug#17312761 MYSQLD WAITS FOR DUMMY NODES (NODEGROUP=65536) TILL NDB-WAIT-CONNECTED PERIOD
      induce memcached to flush its log file at end of mtr testing
      BUG#20727343: Fix problems in UNDO log applier when changing log files
      Bug#21127135 NDB_CONFIG SHOULD SHOW DEPRECATED OPTIONS
      Revert of prev push for bug#20957068
      Fix for Bug#20957068:
      Post merge fixes (mysql-5.6.25 via mysql-5.6-cluster-7.3 into mysql-5.6-cluster-7.4)
      Port commit to MySQL Cluster 7.3
      Port of commit to MySQL Cluster 7.3
      Port of commit to MySQL Cluster 7.3
      Port commit to MySQL Cluster 7.3
      some additional debug output re. online reconfiguration
      Test: temporarily revert recent changes
      Bug#20730053: BACKPORT BUG#19770858 TO 5.1
      Test: temporarily revert recent changes
      Bug#20734434 - SPELLING ERROR \"EMDEDDED\" IN RPM SPEC FILES
      Bug#20788853 MUTEX ISSUE IN SQL/SQL_SHOW.CC RESULTING IN SIG6. SOURCE LIKELY
      Bug#18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Bug#21270190 REMOVE UNUSED AND DANGEROUS NDBHOST_GETHOSTNAME()
      Fix compiler warnings due to hidden inherited virtual and release-unused variables.
      Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Backport of Part 2 (of 2) of fix for Bug#18390321 to 7.2 & 7.3
      bug#17638548 Try to address test failures from previous push
      Reenable usage of send threads in MTR tests.
      Part2 (of 2) fix for Bug#18390321
      Temporarily change default MTR test config to use worker thread sending (No send threads) in order to get some regression test coverage of part1 patch for bug 18390321
      Bug #17878183         NDB CONTINUOUSLY REBOOTING DUE TO FILE NOT FOUND (DBLQH: CAUSED BY ERROR 2341)
      Part1 (of 2): Fix for Bug#18390321
      bug#17638548 In NDB Memcache 7.4 use 7.3 Scheduler by default
      bug#17638548 : reset "woken" state after wakeups
      Debug patch for Bug#17665497 DATANODE CRASH IN DBTUPDISKALLOC.CPP DBTUP (LINE: 848) 0X00000000
      Fix failing ATRT testcases:
      Increase timeout value for several failing 'testNodeRestart ... DD' tests.
      Fix failing testcase 'testNodeRestart -n GcpStop T1 --loops=1' :
      Added more printout to testcase 'testBasic -n Bug54986 D2' in order to aid in understanding why / where this test fails.
      Increase timeout for  'testNodeRestart -n Bug27003 T1' from 1800 -> 3600sec.
      Moved unstable 'basic' tests to 'devel'.
      Fix compiler warnings in patch for bug#21185585:
      fix bug in cmakelists from previous push
      Convert test_workqueue into a TAP test
      Fix for bug#21185585
      ndb memcache: recently in CLUB testing of ndb memcache suite, 7.4 consistently passes but 7.3 has many failures.  This commit swaps the default schedulers in 7.3 and 7.4 to see if that leads to any change in the pattern of test results.
      ndb memcache: change default scheduler in 7.3
      bug#21067283 Fix inconsistent space calculations in NdbRecord
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      BUG#18234170 Foreign Constraints are lost from NDB Tables during truncate
      Bug#21184102 PATCH FOR BUG#16890703 MYSQLD STUCK IN OPN TABLES ..., LOST IN 7.3 AND UPWARD Added error check for missing database directory, added testcase
      BUG#18234170 Foreign Constraints are lost from NDB Tables during truncate
      WL#8648 NDB_SHARE lifecycle improvements
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7578 Refactor schema distribution code
      WL#8648 NDB_SHARE lifecycle improvements
      Bug#21141495 NDB_MGMD USES 90% CPU
      Remove global forward declaration of Ndb_fk_data
      BUG#20095208: Fix to make portlib not dependent of ndbgeneral
      Removed compiler warning
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Only use C++ ABI functionality if libstdc++ is being linked. Otherwise resort to protect the allocation/deallocation of the static objects using the existing connection mutex.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      Patch for bug#21109605
      Removed compiler warning
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Only use C++ ABI functionality if libstdc++ is being linked. Otherwise resort to protect the allocation/deallocation of the static objects using the existing connection mutex.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      Bug#20636124 CRASH AFTER NODES POWER OFF CAUSED A SEGFAULT IN GLOBALDICTCACHE Allocate f_invalid_table and f_altered_table as static local objects and initialize pointers in a thread safe manner using my_pthread_once.
      WL#8525: BUG#20904721: Part6: Improve performance of checksum calculations, remove unnecessary ones and simplify bit toggling ones. Also solves BUG#20980229 that ensures that also header bits are included in checksum calculation.
      BUG#20904721: Fix LCP processing with heavy insert activity, part 2
      Improve multi-thread use of charsetDecoder and charsetEncoder in clusterj Utility   charsetDecoder is used only in Decimal decoding   charsetEncoder is used only in Decimal encoding   charsetDecoder and charsetEncoder are not thread-safe   use charset.decode for decoding   use charset.newEncoder().encode for encoding   avoid synchronization
      bug#20095208 - UNABLE TO STORE FRAGMENT DURING LCP. NDBFS ERROR: 2812 - DBLQH (LINE: 14305)
      bug#20095208 - UNABLE TO STORE FRAGMENT DURING LCP. NDBFS ERROR: 2812 - DBLQH (LINE: 14305)
      Bug#18753887 MYSQLD STOPPED WRITING TO BINARY LOG Modifies pollEvents to return latest_GCI as NDB_FAILURE_GCI (~(Uint64)0) in case a cluster failure has been detected. An internal flag is set in NdbEventBuffer::report_node_failure_completed and the flag is reset when the next SUB_GCP_COMPLETE_REP signal is received. Test case StallingSubscriber is extended to verify that NDB_FAILURE_GCI is returned and that polling of events is resumed after the cluster is connected again and new epochs are received.
      Bug#18753887 MYSQLD STOPPED WRITING TO BINARY LOG     Modifies pollEvents to return latest_GCI as NDB_FAILURE_GCI (~(Uint64)0)     in case a cluster failure has been detected. An internal flag is set     in NdbEventBuffer::report_node_failure_completed and the flag is     reset when the next SUB_GCP_COMPLETE_REP signal is received.     Function Ndb::isExpectingHigherQueuedEpochs is added to be used together     with pollEvents2 that checks if cluster has disconnected due to failure     causing no more events to be received.     Test case StallingSubscriber is extended to verify that NDB_FAILURE_GCI     is returned and that polling of events is resumed after the cluster     is connected again and new epochs are received.
      BUG#20904721: Part 8: Fixing the NDB scheduler to work with Bounded delay signals
      Revert last merge
      Fix multi-thread use of charsetDecoder in clusterj Utility   charsetDecoder is used only in Decimal decoding   charsetDecoder is not thread-safe
      Follow up testcase fix for MCP_BUG20701918
      MCP_BUG20701918  create-old-temporals MySQLD option
      BUG#20904721: Fix of previous push
      Fix regression in debug build caused by fix for bug#20408733.
      WL#8525: BUG#20904721: Part 4, write up description of local LCP protocol and how to handle overload situations, increase to prio level A in some cases. Also standardise naming on END_LCPREQ and END_LCPCONF and remove all usages of END_LCP_REQ and END_LCP_CONF.
      BUG#20904721: WL#8525: Part 3, use prefetch to speed up scan processing for LCP scans and also other full table scans, such as node recovery scans and user level full table scans
      WL#8525: BUG#20904721: Part 7: Ensure it's not so easy to misconfigure LCPs and Backups
      BUG#21049554: Fix OM_SYNC flag to work on all platforms, not only those that support the O_SYNC flag
      WL#8525, BUG#20904721: Part1: Avoid LCP watchdog crash when scanning many pages with LCP_SKIP records
      Fix annoying compiler warnings on Mac OS X
      Fix white space warning in clusterj
      Bug #20504741 Bug #20695155 Improve Clusterj handling of ByteBuffers to reduce direct memory footprint Fix Clusterj incompatibility with Java 7
      Backport My::Memcache.pm improvements from 7.3 This will be null-merged up
      Eliminate some compiler warnings in 3rd party memcached code for NDB Memcache This fix includes both reducing the gcc warning config in CMakeLists.txt and changing two memcached source files. No Oracle copyright is added to the changed 3rd party files.
      Clusterj Trivial bug fix for error displays
      Bug#21055643 REDUCE DEBUG PRINTOUT DURING A GAP AND IMPROVE
      Properly include m_string.h when using my_stpcpy
      Improve comments
      Cache the key_length in NDB_SHARE_KEY
      Provide type safety by using the opaque NDB_SHARE_KEY* type
      Use NDB_SHARE::key_string() instead of direct access to key member
      Move NDB_SHARE::key_length into NDB_SHARE_KEY
      Rewrite the lgive share leak name  to also use NDB_SHARE::create_key
      Move all NDB_SHARE key initialization into NDB_SHARE::creat_key()
      Fix some compiler warnings from memcached sources
      My::Memcache.pm: handle case where the last read before a timeout completed the read [1;31mbuffer[m. Open a new memcache connection when trying to fetch server error stats.
      Save the prepared key in Ndb_schema_dist_data
      Rename ndbcluster_prepare_rename_share to NDB_SHARE::create_key
      Remove NDB_SHARE::mem_root and instead use my_malloc for dynamic strings
      Change ndcluster_prepare_rename_share to return newly allocated key
      Remove NDB_SHARE::old_names
      Pass the new_key as argument to ndbcluster_rename_share
      Skip ndb_ddl tests with embeddes server
      Change to allocate Ndb_CONFLICT_FN_SHARE bith my_malloc
      Make the NDB_CONFLICT_FN_SHARE an opaque type for users of ndb_share.h
      Remove useless typedefs
      Remove backwards jump into a hoop on fire
      bug#18411034: Remove an unnecessary if-statement
      Print stats for the MEM_ROOT in Ndb_event_data
      Increased the undolog file size from 256MB to 512MB and FragmentLogFileSize from 64MB to 128MB.
      bug#18411034: Assertion gci_ops && (gci == gci_ops->m_gci) failed
      bug#18411034: Assertion gci_ops && (gci == gci_ops->m_gci) failed
      bug#20553313, bug#20707694 - fix index stats query delays
      Bug#20479917 REMOVE MCP_BUG16021021
      Bug#21026199  RANDOM WARNING ORDER NDB_ONE_FRAGMENT
      Addendum to the fix for bug #20681412:
      post push minor test fix for bug:19887143
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug#20234681 HA_NDBCLUSTER USAGE OF FIND_FILES LEAK MEMORY INTO (UNRELEASED) MEM_ROOT
      Move new drop_table test to suite ndbcluster
      Bug#20728189 DROP TABLE SEGFAULTS IF FIRST STATEMENT ON A NEW CONNECTION
      Adding force_restart option to ndb_addnode_restart_setup.inc To force restart servers during retries.
      Bug#20782580: NDB REDO OVERLOAD: ABORT QUEUING REQUESTS IF OUT OF LOG SPACE
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      Added 5 autotest testcases to test node restart with following scenarios. 1. Restarting one node at a time. 2. killing two node of different groups and starting them with and without initial option. 3. Restarting a node which doesn't belongs to node group 0, and checking that it is not associated with node group 0 after restart. 4. killing four node of different groups and starting them with and without initial option. 5. Killing only the master nodes one by one and starting them without initial option.
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      WL#7575 Remove ndbinfo's usage of other engine
      Bug#11762750 TABLE NDBINFO.CONFIG_PARAMS SHOULD BE READ-ONLY (FOR NOW)
      Bug#16731538 MYSQLD CRITICAL FAILURE DURING ORDERED SELECT FROM NDBINFO.CLUSTER_OPERATIONS
      BUG#20075747 RND_INIT() ON AN OPEN SCAN IS USED TO REPOSITION THE CURSOR
      WL#7575 Remove ndbinfo's usage of other engine
      My::Memcache -- longer write timeot
      My::Memcache client, fix bug in read() where desired length is 0
      Remove include/ndb_default_cluster.inc
      WL#8165 Use new records per key interface in NDB
      Fix for Bug#20954804
      Fix for Bug#20954804
      Bug#20782580: NDB REDO OVERLOAD: ABORT QUEUING REQUESTS IF OUT OF LOG SPACE
      Fix a possible crash in AutoTest when an ordered scan encounter error 4008, scan timeout. One such testcase is 'testScan -n ScanRead4880'
      Bug#11760802 SEVERAL MGMAPI FUNCTIONS RETURN 0(SUCCESS) WHEN NO HANDLE OR NOT CONNECTED
      Refactoring of create partitioned table
      Revert unintentional change
      My::Memcache - do not close connection before attempting to fetch server error statistics
      MTR ndb_memcache more tweaks to timeout handling
      Bug#20814396 PB2 IS SECRET ABOUT WHAT UNIT TESTS IT RUN
      Revert "Remove MCP_GLOBAL_SCHEMA_LOCK patch"
      Revert "Remove MCP_GLOBAL_SCHEMA_LOCK patch"
      Fixing the following test failures by synch'ing the error injection and the test checking the error:
      increase timeouts
      Better failure handling in My::Memcache.pm
      Provide more information when an ndb_memcache test fails
      BUG#20887445: Fix so that cpuset is working in ThreadConfig, previously node log proclaimed it was working where it wasn't really working
      Fix ndbapi example programs to work on Mac OS X Yosemite
      BUG#20887445: Fix so that cpuset is working in ThreadConfig, previously node log proclaimed it was working where it wasn't really working
      Fix ndbapi example programs to work on Mac OS X Yosemite
      Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED
      Bug#20729091 - ASSERTION TYPE < NDBDICTIONARY::EVENT::TE_EMPTY FAILED
      Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS
      Bug#20762291 - POLLEVENTS2() WILL RETURN ERROR (-1) IF GIVEN WAITTIME AMILLISECONDS IS NEGATIVE
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Attempt to avoid spurious test failures. Increase read timeout in My::Memcache from 4 sec. to 8 sec. Change external_values test to use all non-logging tables.
      Fix testIndex seg fault where index not exists when calling indexReadRecords, added check for NULL return
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      MTR ndb_memcache : still better timeout handling & more verbose reporting during test runs
      Revert to older scheduler as default in 7.4 for testing
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Remove MCP_WIX
      Handle server timouts and disconnects in MTR's My::Memcache client
      Work on My::Memcache to handle server disconnects and timeouts
      Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS Bug#20561446 NDB : NDBEVENTBUFFER NEEDS MORE THREADING PROTECTION
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      fix
      NDB Memcache: mtr failures are caused by faulty locking on linux?
      NDB Memcache external_values fixes: The external_values test had a Perl bug using "==" instead of "eq", causing tests to pass even when the server produced errant responses. This patch fixes the test case and also fixes the revealed errant behavior in memcached.
      Remove MCP_WIX
      Remove MCP_WIX
      Remove MCP_WIX
      Do not change default scheduler in 7.2
      NDB Memcache: use pollEvents2() in reconfiguration waiter thread
      bug#17638548: NDB Memcached uses excessive CPU. This patch works around the underlying issue by defaulting to a new scheduler which does not make use of the NDB MultiWait APIs.
      NDB Memcached: enable "Trondheim" scheduler in 7.2
      one more solaris fix
      Fix for compiler error on Solaris
      Adapt 73 Scheduler to new online configuration manager
      one more solaris fix
      Fix for compiler error on Solaris
      Fixup from previous merge
      NDB Memcache: backport improvements into 7.2
      Backport misc. NDB memcache changes from 7.3 to 7.2
      Raise version number after cloning 7.2.20
      Raise version number after cloning 7.3.9
      Raise version number after cloning 7.4.6
      Raise version number after cloning 7.1.35
      Attempt better "htonll" portability in NDB memcache code
      BUG#20665205, fixed a part where we skipped reading of page 0 which was required to do in last file, also due to file 0, page 0 writes we can trust this page to be correct
      Add ndb specific changes for Bug#20094067: BACKPORT BUG#19683834 TO 5.5 AND 5.6
      Added ndb testcase for bug#19856162.
      Post-push fix for bug#19856162.
      Merge into cluster: WL#8354 BACKPORT DIGEST IMPROVEMENTS TO MYSQL 5.6
      Revert "Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS"
      Revert "Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS"
      Revert "Bug#20729091 - ASSERTION `TYPE < NDBDICTIONARY::EVENT::TE_EMPTY' FAILED."
      Revert "Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED"
      BUG#20665205: Fix REDO log issue
      Added autotest testcases to test addnode and restart.
      Bug#20700220 - GETHIGHESTQUEUEDEPOCH() RETURNS WRONG VALUE THAN INTENDED
      Bug#20729091 - ASSERTION `TYPE < NDBDICTIONARY::EVENT::TE_EMPTY' FAILED.
      Bug#20646496 - ENSURE BACKWARD COMPATIBILITY TO POLLEVENTS, RELATED TO EXCEPTIONAL EPOCHS
      Bug 20762291 - POLLEVENTS2() WILL RETURN ERROR (-1) IF GIVEN WAITTIME AMILLISECONDS IS NEGATIVE
      Bug#20575424 DATA RACE FOR NDBEVENTBUFFER::M_TOTAL_BUCKETS Bug#20561446 NDB : NDBEVENTBUFFER NEEDS MORE THREADING PROTECTION
      Remove MCP_WIX
      Resurrect unintentionally remove disabled.def file

[33mcommit 8358d59e0ed8f0ea634226087de8cb58519757ab[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Jul 13 18:59:49 2015 +0300

    Add an I_S table to peek at the buf stats
    
    Add INFORMATION_SCHEMA.INNODB_CACHED_INDEXES as a tool to view the
    contents of the hash table that stores the number of cached pages per
    index.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 2fad985a08935744348a5db0765509fa6766e5a1[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Jul 13 18:58:14 2015 +0300

    Change buf_stat_per_index_t::get()'s return type
    
    Use uint64_t instead of uintptr_t.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit f921dada0634c65a44968063c4029b63c8b06ba9[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Jul 9 22:06:16 2015 +0300

    Add support for testing tbb::concurrent_hash_map
    
    In the unit test for the lock free hash table, add an option to compile
    and test tbb::concurrent_hash_map instead.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit ea07cbb220e21b895ad5937933fdaf6ecd4b71f9[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jul 7 21:48:53 2015 +0300

    Plant memory fences to prevent reordering
    
    Use memory fences in the lock free hash table to prevent the compiler
    and/or the CPU from reordering some of the code.
    
    The following must happen in a predefined order:
    
    * When copying a tuple to the new/next array, the insertion into the new
      array must precede setting its value in the old array to
      GOTO_NEXT_ARRAY
    
    * When adding a new entry to the garbage bin, the entry construction
      must have completed before any other threads observe the published
      pointer.
    
    * Reading from the next array (when the hash has been expanded) must be
      done after it has been completely created.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 3af217ea6d7c3a8f2a83c199a36c4f990c6040ce[m
Merge: 16fd0c50814 acca848a96b
Author: Jimmy Yang <jimmy.yang@oracle.com>
Date:   Sat Jul 4 01:34:39 2015 +0800

    Null Merge branch 'mysql-5.7' into mysql-trunk
    
    Conflicts:
            mysql-test/suite/innodb/r/innodb-system-table-view.result
            sql/CMakeLists.txt
            sql/field.h
            sql/filesort.cc
            sql/share/errmsg-utf8.txt
            sql/sql_class.cc
            sql/sql_join_[1;31mbuffer[m.h
            sql/sql_table.cc
            storage/innobase/dict/dict0load.cc
            storage/innobase/include/data0data.h
            storage/innobase/include/dict0dict.h
            storage/innobase/include/dict0load.h
            storage/innobase/include/dict0mem.h
            storage/innobase/include/rem0rec.h
            storage/innobase/include/row0log.h
            storage/innobase/include/row0vers.h
            storage/innobase/include/trx0rec.h
            storage/innobase/row/row0ins.cc
            storage/innobase/row/row0sel.cc

[33mcommit a908096555d17ddc3fdad9da5734f9a6028777ee[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Jun 25 15:47:55 2015 +0300

    Whitespace fixup
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 8d024e68c1d5784cb6d30f44c0ed837f608bdd46[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Jun 25 14:26:50 2015 +0300

    Use a dedicated PFS mem key for the lock free hash
    
    Introduce own mem key for accounting via PFS the memory allocations
    inside the lock free hash instead of exploiting the
    buf_stat_per_index_t's key.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 949178f21272f27700d2aa0839d6c36ef7487fe4[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Jun 25 14:12:54 2015 +0300

    Don't delete index stats when dropping the index
    
    This commit reverts parts of 4e4232b.
    
    This is because, in InnoDB, when dropping an index, its pages are left
    in the [1;31mbuffer[m pool and eventually evicted via the LRU mechanism when
    they are not accessed for a long time. This eviction will try to
    decrement the number of pages for a given index and this, if the entry
    in the stats is missing, will lead to negative results. For example:
    
    (index id = 123, n pages in [1;31mbuffer[m pool = 100)
    drop index, delete the (123, 100) tuple
    some of the 100 pages gets evicted and calls dec(123), which results
    in (123, -1)
    
    In the old behavior some entries with negative values will remain
    forever in the hash, unnecessary taking space and CPU cycles during
    search for other entries.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 86e3728c532e508157b72a501396b004ef493931[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Jun 25 13:35:03 2015 +0300

    Fix compilation failure on 64-bit Windows
    
    ...\ut0lock_free_hash-t.cc(502): error C2664: 'void innodb_lock_free_hash_unittest::run_multi_threaded(const char *,size_t,size_t,size_t,size_t,os_thread_func_t)' : cannot convert argument 6 from 'os_thread_ret_t (__cdecl *)(void *)' to 'os_thread_func_t'
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit d148f8d756cd944f11e37c825c5285116ab61b78[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jun 24 22:39:31 2015 +0300

    Fix compilation error after mutex API changes
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit d5a22f3a6e106cfa113a4f05bdd924a4f0560b73[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jun 24 17:51:00 2015 +0300

    Copy all tuples to the new array(s) when growing
    
    For each occupied entry in the old array:
    * copy to the next array
    * mark the entry in the old array as "go to the next array"
    
    For each vacant entry in the old array:
    * mark as "avoid", so that new inserts will consider it occupied
    
    When all elements in the old have either been copied or marked as
    "avoid", then add the array to a list of unused arrays that are to be
    freed when we are sure that no stale readers are still using them.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit f55cdaa347522867ade476360fd9f0328f921b30[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jun 24 17:45:45 2015 +0300

    Ensure that the number of elements is > 0
    
    This is necessary because when extending the list the newly added entry
    has "n_elements * 2" number of elements and "0 * 2" will leads us to
    nowhere.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 9ab2f7b5ed23393532ebea097b3d0836608050bc[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jun 23 14:08:01 2015 +0300

    Make m_data atomic because we will be changing it
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit a437264dfdb201b5327b1cad9a8fc7dd8378909a[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jun 23 13:59:42 2015 +0300

    Combine a common code from set() and delta()
    
    Put the common code in insert_or_update().
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit d67f6877322881469ccb6eadad56ca0bca71a581[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jun 23 11:14:34 2015 +0300

    Non-func: typedef the type of the nodes
    
    Introduce
    typedef ut_lock_free_list_node_t<key_val_t>     arr_node_t;
    to make the code less crowded.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 821b4edc70bfbaa2e46280fae4e9a1f75b67199a[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Jun 22 13:57:10 2015 +0300

    Go to the next array if the val is flagged as such
    
    This patch handles GOTO_NEXT_ARRAY in the read scenarios (get(), del()).
    
    This will be used when copying all the tuples to the next array.
    
    Also, designate a deleted tuple with val == DELETED, instead of
    key == DELETED. There are two reasons for this:
    1. This way it is possible to atomically change a tuple from deleted to
       'go to the next array', by CASing val from DELETED to GOTO_NEXT_ARRAY.
    2. This is more optimal in a scenario where a tuple with a given key is
       being constantly deleted and readded. Now a single cell in the array will
       be reused for this, instead of grabbing a new cell on each readd.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 0d8237a1ac028c304c8278d4d491b788d0e460de[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri Jun 19 14:42:36 2015 +0300

    Go to the next array if the val is flagged as such
    
    In the chain of arrays that constitute the hash table, introduce a magic
    value for m_val GOTO_NEXT_ARRAY which designates to anybody who tries to
    access it (reader or writer) "go to the next array in the chain and do
    your job there".
    
    This patch handles GOTO_NEXT_ARRAY in the write scenarios (set(), inc()
    and dec()).
    
    This will be used when copying all the tuples to the next array.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit e03d302b703b96733f5e3398de6f5eb7bf201322[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri Jun 19 14:33:22 2015 +0300

    Change test lables so that they are aligned
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 0b3adc8c8bbd400187a31b4c0bc7c2f45538590f[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Jun 18 12:14:28 2015 +0300

    Remove the commented out atomic inc code
    
    Atomic increment is only a little bit faster than a busy loop trying to
    CAS x with x+1, even when lots of threads fight to update a few values,
    but the atomic increment does not provide a way to check the value
    before doing the operation.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit a82e9c5570bf57eb3130f9548ff3634c6b53aacf[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Jun 18 12:09:22 2015 +0300

    Add a new unit test: many threads update few keys
    
    Also, put the mostly common code of the bodies of TEST_F() into a
    single function run_multi_threaded() and call it from all TEST_F()s.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 476eaf7659e07e43146ff237281a84e8ed7d2d99[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Jun 18 10:54:25 2015 +0300

    Fix a comment
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit e2755c4ba68190e9dd0e6c0b8233b945ae7503ef[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jun 17 18:23:59 2015 +0300

    Combine inc() and dec() into a single method
    
    The bodies of inc() and dec() were mostly the same, so combine them into
    a common method and call it from inc() and dec().
    
    Also use a busy loop trying to CAS the current value with the current
    value + 1 (for inc() and -1 for dec()) instead of atomic increment (or
    decrement) because that way we can check that we are not atomically
    incrementing some of the magic values that could be used for m_val.
    Currently it is only NOT_FOUND and this is not needed, but
    GOTO_NEXT_ARRAY will be added soon.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 94c2a0db53d439574df25d79f9327a13e3d9681b[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jun 17 17:36:30 2015 +0300

    Add more tests of the lock free hash
    
    The current test was 100% write, now 50% write / 50% read and 100% read
    tests were added.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 9af280e097baae8bde6bfbe66f24cff9b5b788af[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jun 17 17:34:34 2015 +0300

    Non-func: make it easier to uncomment test macros
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit bb809d447446f609f0e8b673a45dde4d84d48ee3[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jun 17 16:54:37 2015 +0300

    Adjust mutex usage after API change in b80c0b8
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit e7c4a27bf8b718080d2c516ee20a09c5c02f731d[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jun 16 20:49:56 2015 +0300

    Update outdated comment
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit e5d074fa5a3c383e0446b96db7851183a02737ef[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jun 16 17:35:17 2015 +0300

    Disable stats collection in the lock free hash
    
    Also enlarge the dataset of the tests because without the debug
    stats collection it now runs significantly faster.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 80b3eab5d9bac582b7e0de4d2ab92576102ca3ee[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jun 16 12:51:41 2015 +0300

    Relax the memory ordering constraint in set()
    
    Any memory operations can be moved before or after the CAS
    which inserts a new (key, value) tuple.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit c96edefd09616530f8f3fb57afc711451f0d31b7[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jun 16 12:24:55 2015 +0300

    Relax memory ordering constraints in inc()/dec()
    
    Any memory operations can be moved before or after the CAS and the
    atomic increment/decrement that constitute the inc() and dec() methods.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit b3382d094053484f15f414845619d0c0ac3363f6[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jun 16 12:07:17 2015 +0300

    Relax memory ordering constraints wrt array grow
    
    Any memory operations can be moved before or after the CAS that
    publishes the newly created array. It is published by appending
    it to the linked list of arrays.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 04d8e6017bc0d80681192b1fad5966bdfdd53df0[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jun 16 11:08:04 2015 +0300

    Temp enforce that boost atomics are lock free
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 7ec8eeb97ba3e0cb8b01aad15ff34ab06ca56feb[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon Jun 15 12:13:05 2015 +0300

    Clock the timing of the lock free hash unit tests
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 57126160beb0a6a016badf6f429f783bd7be4b67[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jun 10 14:41:42 2015 +0300

    Remove unnecessary header include
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 25765c31d19c131d604ff69c9913171468357e5a[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jun 10 13:15:45 2015 +0300

    Use boost::atomic counters in ut_lock_free_hash_t
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 217a4c7d0b4d7b1e6f33bd9f6de1ed2ce66de239[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Jun 10 13:14:58 2015 +0300

    Fix a compilation failure on 32 bit CPUs
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 1e5b0a57b7d058c99295b48b1e9cf7655658fb9e[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Jun 4 18:59:15 2015 +0300

    Use boost::atomic instead of os_atomic_t
    
    And remove the home grown os_atomic_t which was created solely to mimic
    C++11's std::atomic which boost::atomic does better.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 9361a997d1c8348934558b60fa8d3662ffdeaa64[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jun 2 14:43:26 2015 +0300

    Fix a bit of Bug#19628291 QUALITY OF SET GLOBAL INNODB_BUFFER_POOL_FILENAME=... VARIABLE INPUT CHECKING
    
    Fix a bit of Bug#19628291 QUALITY OF SET GLOBAL
    INNODB_BUFFER_POOL_FILENAME=... VARIABLE INPUT CHECKING
    
    Avoid the repetition of the slash in InnoDB [1;31mbuffer[m pool load/dump
    messages like
    
    "2014-10-17 14:17:50 0x80380bc00 InnoDB: Loading [1;31mbuffer[m pool(s) from
    .//ib_[1;31mbuffer[m_pool"
    
    Resolve the [1;31mbuffer[m pool dump file using my_realpath(), so that it is
    always the absolute path and does not contain redundant // or ../
    entries.
    
    Reviewed-by: Marko Makela <marko.makela@oracle.com>
    RB: 9172

[33mcommit 581b3c80d93dbd00ae45d52b5279f5e717990bd1[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Jun 2 11:29:56 2015 +0300

    Implement a delete operation in the lock free hash
    
    And use that to wipe away any stats for an index when it is being
    dropped.
    
    The memory that was occupied by the deleted (key, val) tuple
    is not freed or returned for reuse.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 215f4439e1da855116afda184100d2a6d31a7f23[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Thu May 28 13:58:11 2015 +0300

    WL#7488: InnoDB startup refactoring
    
    Validate the startup parameters before opening files.
    
    srv_start(): Renamed from innobase_start_or_create_for_mysql().
    Move some of the validation to the caller, which is innobase_init().
    
    innodb_log_[1;31mbuffer[m_size: Renamed from innobase_log_[1;31mbuffer[m_size,
    using an unsigned type to avoid type casts.
    
    innodb_log_file_size: Renamed from innobase_log_file_size,
    using an unsigned type to avoid type casts.
    
    innobase_read_io_threads, innobase_write_io_threads: Remove.
    Directly map the startup parameters to the variables
    srv_n_read_io_threads, srv_n_write_io_threads.
    
    innodb_change_[1;31mbuffer[ming: Renamed from innobase_change_[1;31mbuffer[ming.
    Use an integer type instead of a string.
    
    innodb_flush_method: Renamed from innobase_file_flush_method.
    Use an integer type instead of a string.
    
    innodb_flush_method_names, innodb_flush_method_typelib: Valid values of
    innodb_flush_method.
    
    innodb_change_[1;31mbuffer[ming_names, innodb_change_[1;31mbuffer[ming_typelib:
    Valid values of innodb_change_[1;31mbuffer[ming.
    Replaces innodb_change_[1;31mbuffer[ming_names.
    
    innodb_init(): Renamed from innobase_init().
    innodb_init_abort(): Renamed from innobase_init_abort().
    
    innodb_init(): When startup fails before opening files, do not call
    innodb_init_abort(), but return 1 directly instead.
    
    innodb_[1;31mbuffer[m_pool_size_init(): New function, to initialize
    and normalize the [1;31mbuffer[m pool size and related parameters.
    
    innodb_init_params(): New function, to check the startup parameters.
    
    innodb_find_change_[1;31mbuffer[ming_value(), innodb_change_[1;31mbuffer[ming_validate(),
    innodb_change_[1;31mbuffer[ming_update(): Remove. These are made redundant by
    innodb_change_[1;31mbuffer[ming_typelib.
    
    IBUF_USE_COUNT: Remove.
    
    srv_normalize_init_values(): Remove. This will be done in innodb_init().
    
    SysTablespace::normalize_size(): Renamed from SysTablespace::normalize().
    
    RB: 8647
    Reviewed-by: Jimmy Yang <jimmy.yang@oracle.com>
    Reviewed-by: Mattias Jonsson <mattias.jonsson@oracle.com>

[33mcommit 03850ad3962b9c7a023599073048d15c9f961252[m
Merge: 57af7500877 53cd3aada27
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu May 28 11:25:49 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      BUG#20171740 - OVERRIDE DEFAULT SERVICE START/STOP                TIMEOUT USED BY SYSTEMD FOR MYSQL.
      Post-fix of
      Bug#20712775 GEOMETRY OBJECT CONSTRUCTION FUNCTIONS ACCEPT ILLEGAL INPUT
      Revert changes in compress_gtid_table
      Tentative cleanup
      Bug#17473077 EVER INCREASING MEMORY USAGE REPORTED FOR EVENT SCHEDULER
      BUG#20878735 IN IBUF_BITMAP_GET_MAP_PAGE_FUNC, BUF_PAGE_GET_GEN FAILS
      BUG#21086257 INNODB: ONLY ONE DATAFILE PER TABLESPACE IS DISPLAYED
      Revert "Bug#20597981 WRONG RELEVANCE RANKING FOR FULL TEXT SEARCHES"
      Bug#21153166: REMOVE UNUSED VARIABLES AND CONVERT GLOBAL SYMBOLS TO STATIC
      Bug#20914786 : MYSQL_UPGRADE FAILS WITH SHOW_COMPATIBILITY_56 = OFF
      Bug#20914786 : MYSQL_UPGRADE FAILS WITH SHOW_COMPATIBILITY_56 = OFF
      Bug#20914786 : MYSQL_UPGRADE FAILS WITH SHOW_COMPATIBILITY_56 = OFF
      Bug#21073014 SET LIMITNOFILE OPTION IN SYSTEMD SERVICE TO MATCH OPEN_FILES_LIMIT WANTED
      Bug#19771769: --TC-HEURISTIC-RECOVER OPTION VALUES ARE BROKEN
      Final patch with test services plugind for 5.7
      This is a patch for Bug#19771769 - --TC-HEURISTIC-RECOVER OPTION VALUES ARE BROKEN
      BUG#20938915  2PC SUCCEEDS EVEN THOUGH BINLOG FLUSH/SYNC FAILS
      Bug#17479887: test update
      Bug #20602572: EXPIRED-PASSWORD MESSAGE IS OUT OF DATE
      Bug#21087116 : MYSQL_SSL_RSA_SETUP CREATES CLIENT-CERT.PEM WITH INCORRECT CN
      Bug#20597981 WRONG RELEVANCE RANKING FOR FULL TEXT SEARCHES           WHEN FTS_DOC_ID IS PRIMARY KEY.
      Bug#20369401: MTS STOP SLAVE TAKES WAY TOO LONG (WHEN WORKER THREADS ARE SLOW)
      Bug#17479887: test update
      Bug#17479887: followup
      Bug#17479887 Create_tmp_table memory leak
      Bug#21140111: Explain ... match against: Assertion failed: ret ...
      Bug#20571317 TRUNCATE_STRESS TIMES OUT WHEN RUN IN PARALLEL
      BUG#20841874 Fix assertion failure in Boost.Geometry [1;31mbuffer[m().
      Final patch with test services plugind for 5.7

[33mcommit 57af7500877cd3c7a09ca84ce0df5495ccbeecdd[m
Merge: 36787f1a02c 080939bc235
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue May 26 15:07:28 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug#21141390 REMOVE UNUSED FUNCTIONS AND CONVERT GLOBAL SYMBOLS TO STATIC
      Bug21146234 DETECTING MODE IS INCREASING SUSPICIOUS COUNTER FOR RECORDED STATEMENTS
      Bug#18412756 BOGUS ERROR FOR MYISAM SPATIAL INDEX: INCORRECT KEY FILE FOR TABLE
      Follow-up to Bug#21141390 REMOVE UNUSED FUNCTIONS ...
      Bug#21141390 REMOVE UNUSED FUNCTIONS AND CONVERT GLOBAL SYMBOLS TO STATIC
      Bug#20693153 : ACCESS DENIED WITH SSL CONNECTION FROM MYSQL CLIENT
      Bug #20359808 - OUT OF BOUNDS WRITE (OFF BY ONE)
      BUG#20841874 Fix assertion failure in Boost.Geometry [1;31mbuffer[m().

[33mcommit 36787f1a02cdc50b527d5f4889512d85c9e716a1[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon May 25 17:00:12 2015 +0300

    Non-func: minimize the scope of ibuf_index_id
    
    Also, fix a bogus compiler warnings about unused variables.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit abfe6784c58679eef1585b3cb20f04dce13babdd[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Mon May 25 16:45:58 2015 +0300

    Skip too big index ids
    
    The mtr test innodb.file_format_upgrade_16k triggers an assertion due to
    reading a page (space_id=23, page_no=0) with page_type == FIL_PAGE_INDEX
    and having btr_page_get_index_id(frame) == 0xFFFFFFFF0000FFFF (the value
    is a non-deterministic garbage).
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 99c56a3b036e96d3b8df2cdb1a07ef7a22eb8b1f[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed May 20 13:16:05 2015 +0300

    Add a 64 bit CAS() macro on Windows
    
    Use the added macro in os_atomic_t and also use
    os_atomic_increment_uint64() instead of os_atomic_increment_ulint()
    because ulint is 32 bit on 32 bit CPUs.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit c7fa816f53886c3474b65ae4bcf10a80c566c04e[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri May 22 13:06:16 2015 +0300

    Skip ibuf and temp-table pages in stats accounting
    
    Move the check whether a page is an ibuf page or belongs to a temporary
    table to a private method inside buf_stat_per_index_t to avoid
    duplicating that check in all places where inc() or dec() methods are
    called.
    
    Move the buf_stat_per_index_t class into a dedicated header buf0stats.h
    to avoid circular header dependencies. It now needs to include
    ibuf0ibuf.h and fsp0sysspace.h in order to check of a page belongs to
    ibuf or to a temporary table.
    
    Assert that index id can fit into 32 bits. ibuf index id does not fulful
    this because it has the magic constant id of 0xFFFFFFFF00000000.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 90d4c2288b9565f0c82ee235d82a9cbe385d60ae[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed May 20 12:46:33 2015 +0300

    Revert unnecessary whitespace changes
    
    This reduces the diff between mysql-trunk-wl7170 and mysql-trunk.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 35eaca5b53a29e69820ed88092a297c240cf5404[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed May 20 12:38:30 2015 +0300

    Use space_id+index_id for identifying an index
    
    Currently index_id alone is unique in InnoDB, but this may change in the
    future. Thus, embed space_id into the index identifiers that are used to
    track the number of index pages in the [1;31mbuffer[m pool.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 0015a1b7eb81bd9238973a80a19e6db0e573807d[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue May 19 17:19:51 2015 +0300

    Change the lock free hash value type to signed
    
    And allow it to go negative when decrementing. Also, if a decrement
    of a nonexistent key is attempted, instead of doing nothing,
    insert (key, -1).
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit a01484399daf0db2e53521be652b04c4ba23f94e[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue May 19 11:43:40 2015 +0300

    Introduce a mimicry of std::atomic and use it
    
    Instead of directly reading and assigning to some variables on whose
    reads/writes we depend to be atomic, introduce a mimicry of std::atomic
    class and use it instead.
    
    This way it is clear which reads and writes must be atomic. And also it
    will be trivial to switch to C++11's std::atomic once we begin compiling
    in C++11 mode.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 87dbde022c53d393f24d181ff00e52eb5e30922c[m
Merge: 112025a48f8 5eef003ae44
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri May 15 10:46:34 2015 +0300

    Merge remote-tracking branch 'local/mysql-trunk' into mysql-trunk-wl7170
    
    * local/mysql-trunk:
      Fix Bug#20783098 INNODB_CHECKSUM_ALGORITHM=CRC32 IS NOT BYTE ORDER AGNOSTIC
      Bug#20819189: ASSERT IF .FRM EXISTS BUT NO PARTITIONED INNODB TABLE.
      Bug#20561087 : REPLACE_USER_TABLE() DOES NOT CHECK ERROR WHEN READING FROM MYSQL.USER
      Bug#20819189: ASSERT IF .FRM EXISTS BUT NO PARTITIONED INNODB TABLE.
      BUG#19706455: RESET MASTER SHOULD RESET GTID STATE AND NOT ERROR OUT WHEN BINLOG IS OFF
      Test suite cleanup
      Some cosmetic changes which had been suggested in the review of wl#2489 but had to wait for wl#5275 and wl#7870 to be pushed.
      Test cleanup
      Bug#21074643: SERVER SETS OPEN_FILES_LIMIT UNCONDITIONALLY
      Fix for build failure after pushing a767e483e9496e8427d50f59dfa4842d4895e08a
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Bug#20896539 - A QUERY DIGEST SOMETIMES CONTAIN BACKTICKS AND SOMETIMES NOT DEPENDING ON CS
      Post push cleanup
      WL#8216: Deprecate and remove the sync_frm sysvar
      PB2 failures (valgrind and result mismatch) fixes.
      Follow up patch of bug20734998 for fixing Werror failure.
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20762557, Bug#20697533 : Disabled following tests since they fail very often on PB2: main.explain_for_connection_rqg_json main.explain_for_connection_rqg_trad rpl.rpl_perfschema_applier_status
      Test commit
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      WL#8186: Deprecate conversion of pre MySQL 5.1 encoded database names
      Bug#20980885: ENSURE THAT START/STOP GROUP REPLICATION ALWAYS REQUIRE SUPER PRIVILEGE
      Partial backport from mysql-trunk to mysql.5.7 of Bug#21041451: ENABLE AND FIX ADDITONAL WARNINGS REPORTED BY CLANG in order to fix Clang 3.4 warnings in release build. No new warning options are added in the backport.
      Bug#21074358: SOME NEW 5.7 SOURCE FILES ARE D0S FORMATTED
      Bug #17818062       PERFORMANCE SCHEMA, ISSUE WITH UPPERCASE ROUTINES NAMES, PERFSCHEMA.MISC FAILS
      Bug #17818062         PERFORMANCE SCHEMA, ISSUE WITH UPPERCASE ROUTINES NAMES, PERFSCHEMA.MISC FAILS
      Bug#17832047: Crash in calculate_materialization_costs
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      Added openssl multithreading to client.
      Added openssl multithreading to client.
      Bug#20721087 UPGRADE TO BOOST 1.58.0
      Bug#20734998 FAILING ASSERTION: !CURSOR->INDEX->IS_COMMITTED()
      Bug #21047137 REMOVE -GCC FROM NAME OF SOLARIS PACKAGES/TARBALLS
      Bug#19316063: MAKE MTS WORK WITH RELAY_LOG_RECOVERY=1 WHEN GTID IS ENABLED
      Bug#21062842 : Made i_main.costmodel_plan change experimental.
      Bug# 19823076 : READ OF FREED MEMORY IN MY_MB_WC_SJIS WITH                 SOUNDS LIKE OPERATOR IN SUBQUERY
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      BUG#20743468: ASSERTION `OLD_VALUE >= 1' FAILED. | ABORT (SIG=6) IN GTID_STATE::END_ANONYMOUS_ BUG#20748502: ASSERTION `THD->VARIABLES.GTID_NEXT.TYPE== ANONYMOUS_GROUP' FAILED.
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      WL#7589: Updated the README file.
      Bug#21041451: ENABLE AND FIX ADDITONAL WARNINGS REPORTED BY CLANG
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20753620: DBUG: DICT_LOAD_FOREIGN, HA_INNOPART::CHECK, HA_INNOPART::CREATE_NEW_PARTITION
      Silence rpl.rpl_xa_survive_crash_debug in Valgrind
      Bug#21021894 : UNHELPFUL ERROR FOR MYSQL_SSL_RSA_SETUP WHEN DATADIR DOESN'T EXIST
      Bug #18075170 SQL NODE RESTART REQUIRED TO AVOID DEADLOCK AFTER RESTORE
      Bug#21021754 - OPTION FOR MAX_STATEMENT_TIME IS MISSING
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      BUG #21063087 - MTR SHOULD PASS --INNODB_UNDO_TABLESPACES VARIABLE AT BOOTSTRAP
      BUG#20921940 DEBUG ONLY-CODE MAY HAVE SIDE EFFECTS IN HA_INNOBASE::
      - Bug#21046781: WHILE TRUNCATE UNDO-TABLESPACE FILE COULD BE CLOSED IN BACKGROUND
      BUG#21041449 ASSERT IN I_INNODB.INNODB_BUG16244691
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug #20445525 ADD A CONSISTENCY CHECK AGAINST DB_TRX_ID BEING IN THE FUTURE
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug #19138298 RECORD IN INDEX WAS NOT FOUND ON ROLLBACK, TRYING TO INSERT
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20835095 CRASH AT CREATE_REF_FOR_KEY IN SQL/SQL_SELECT.CC
      Bug#20738072 CRASH ON STARTUP WITH MAX-DIGEST-LENGTH OF >=420K
      Bug#20980217 - TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE DOES NOT SHOW CORRECT INDEX NAMES
      Bug#20923066: SSL AND RSA KEY MATERIAL EXPIRATION SHOULD BE EXTENDED
      Corrected validate_password_strength and export_set functions
      Post push fix for BUG#18731252
      Bug#21046582 GEOMETRYCOLLECTION COLUMNS CAN'T STORE SUBTYPES
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      Fix for PB2 test failure.
      Bug#20963082 : AUTO_GENERATE_CERTS PREREQUISITE TESTING NOT CORRECT
      - Bug#21053486: TRUNCATE_RECOVER FAILING IN MYSQL-TRUNK
      Bug#21021894 : UNHELPFUL ERROR FOR MYSQL_SSL_RSA_SETUP WHEN DATADIR DOESN'T EXIST
      Bug#20705648 - max_statement_time leaks memory on windows Bug#20705642 - max_statement_time: assertion failed: pending || thd_timer->thread_id
      Bug#20996273 ALTER USER REWRITE CAUSES DIFFERENCES ON SLAVE
      Fix to remove data dir reference
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Bug#20987568 - INCREASE STOP TIMEOUT OF COMMUNITY RPM SHUTDOWN SCRIPT /ETC/INIT.D/MYSQLD
      - Bug#21046968 : POSSIBLE RACE IN THE TRUNCATE CODE
      WL#7899: Add the tests that were accidentally omitted.
      WL#7899: InnoDB: Map compressed temporary tables to uncompressed
      Bug#20918881 CRASH WITH CENTROID - INVALID FREE
      Bug#20854952 SHOW GLOBAL VARIABLES RETURN WARNING ABOUT SQL_LOG_BIN BEING DEPRECATED
      Bug#21021670 - MISLEADING WARNING WHEN PER-QUERY STATEMENT TIME IS EXCEEDED
      Bug#20854952 SHOW GLOBAL VARIABLES RETURN WARNING ABOUT SQL_LOG_BIN BEING DEPRECATED
      Bug #20692556 : PREPARED STATEMENTS DO NOT TRACK STATUS LIKE STATISTICS
      - Bug#20023425: EMBEDDED SERVER FAILS TO BOOTSTRAP/START UP WITH   INNODB_UNDO_TABLESPACES=2
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Bug #20376498: MAX_ALLOWED_PACKET ERROR DESTROYS ORIGINAL               DATA
      BUG#20753463 HANDLE_FATAL_SIGNAL (SIG=11) IN __STRLEN_SSE2_PMINUB ON              CHANGE MASTER
      Bug#20507804 FAILING ASSERTION: TRX->READ_ONLY && TRX->AUTO_COMMIT && TRX->ISOLATION_LEVEL==1.
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      BUG#18731252 SLAVES WITH SAME SERVER_ID / SERVER_UUID COMPETE FOR              MASTER CONNECTION
      BUG#20768847 ASSERTION 0 IN HA_INNOBASE::COMMIT_INPLACE_ALTER_TABLE
      Post-push fix for BUG#20470724: SET GTID_PURGED SHOULD NOT ROTATE BINLOG
      Fixed Bug#20145024: WRONG RESULT FOR COUNT DISTINCT QUERY IN DERIVED TABLE
      Bug #20592961  'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381 - post fix
      BUG#20977779 CANNOT IMPORT TABLES CONTAINING PREFIX INDEXES
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Fix to avoid build break
      Bug#20814280 SEVERAL PERFORMANCE SCHEMA UNIT TESTS FAIL
      Bug#20814280 SEVERAL PERFORMANCE SCHEMA UNIT TESTS FAIL
      Bug#20379981 ST_CONTAINS(GEOMETRYCOLLECTION(POLY,POLY), LINESTRING) RETURNS WRONG RESULT
      Test cleanup
      Test cleanup
      BUG#20470724: SET GTID_PURGED SHOULD NOT ROTATE BINLOG
      Bug#20748537 INNODB: FAILING ASSERTION: NODE->PCUR->REL_POS == BTR_PCUR_ON
      BUG#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bugi#20593257 FIREWALL PLUGIN LEAK PINS UNDER SPECIAL CIRCUMSTANCES
      BUG#20949314 PARTITION_HELPER::PH_RND_INIT(BOOL): ASSERTION `0' FAILED
      Fix firewall_qc broken test case when the FIREWALL_PLUGIN variable isn't set. This affected 32bit debian
      Fix firewall_qc broken test case when the FIREWALL_PLUGIN variable isn't set. This affected 32bit debian
      Bug#20963147 DECOUPLE DIGEST SIZE FROM SERVER AND PFS
      Bug #20926253 VALGRIND FAILURE IN INNODB.ALTER_MISSING_TABLESPACE
      - Bug#20023425: EMBEDDED SERVER FAILS TO BOOTSTRAP/START UP WITH   INNODB_UNDO_TABLESPACES=2
      Bug#20963147 DECOUPLE DIGEST SIZE FROM SERVER AND PFS
      Raise version number after cloning 5.6.25
      Raise version number after cloning 5.5.44
      BUG#21023683 FAILURE IN EMBEDDED I_INNODB.INNODB-ALTER
      Follow-up to BUG#20913616 - FIREWALL INTEGRATES BADLY WITH QUERY CACHE
      Bug #20914786 : MYSQL_UPGRADE FAILS WITH SHOW_COMPATIBILITY_56 = OFF
      Bug #20753378 ASSERTION `GTID_NEXT->TYPE != AUTOMATIC_GROUP || THD->OWNED_GTID.IS_EMPTY()'
      Bug #20592961  'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381
      Bug #20592961 'FLUSH LOGS' POST FAULT INJECTION HITS ASSERT `! IS_SET()' AT SQL_ERROR.CC:381
      Bug #20753378 ASSERTION `GTID_NEXT->TYPE != AUTOMATIC_GROUP || THD->OWNED_GTID.IS_EMPTY()'
      Fix for missing test recording and test output differences on Windows.
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      Bug#20913616 FIREWALL INTEGRATES BADLY WITH QUERY CACHE
      Bug #20857652 : SERVER CRASHES WITH CREATE/DROP USER                 STATEMENT WITH A PARTICULAR SEQUENCE
      BUG#19897405: CRASH WHILE ACCESSING VIEWS IN STORED ROUTINE               AND TABLES ARE FLUSHED
      Bug#20515155 Views: Assertion failed: is_view_or_derived() && is_merged()
      Bug #20987420 PB2 FAILURE OF TEST CASE INNODB_ZIP.INNODB_16K
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      Bug#20873209 NORMALIZE_STATEMENT() UDF BREAK IN SQL_YACC.YY ON SET PASSWORD=
      BUG#20007583: THE EVENT_SCHEDULER USERNAME IS NOT RESERVERD.               ALLOWS PROCESSLIST VIEW.
      Windows installer in need of fixing to accommodate for WL#7307
      Bug#20768717: DEBUG BUILD FAILS WHEN USING GCC 5 DUE TO COMPILER WARNING
      post push minor test fix for bug:19887143
      BUG#20768847 ASSERTION 0 IN HA_INNOBASE::COMMIT_INPLACE_ALTER_TABLE
      - bug#20938115: innodb_undo_logs max limit should be downgraded from 126 to 94^
      Bug #20563332 : OPEN_FILES_LIMIT BINARY PUT INTO ./BIN DIRECTORY OF A BUILD?
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      Addendum to the fix for bug #20681412:
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug#20979020 - THE TRX IN DDL SHOULD ALWAYS NOT BE ROLLED BACK
      Bug#20709462: GENERATED COLUMNS NOT PRINTED CORRECTLY IN SHOW CREATE TABLE
      Bug#20583321: CRASH ON PS_THREAD_INFO / SYS USAGE
      Bug #18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Fixed failing test
      Bug#20583321: CRASH ON PS_THREAD_INFO / SYS USAGE
      Bug #19077239 mtr tests fixed.
      Bug#19077239 re-enabling disable tests mysql_secure_installation amd mysql_secure_installation_ssl
      Revert "WL#8462: test_services are plugins serving as examples for how plugin services can be tested with mtr."
      Bug #19887143 : THREAD/SQL/MAIN DOESN'T CHANGE STATE/INFO AFTER STARTUP
      WL#7895 - Add systemd support to server.
      Fixed Bug #20683741 UNZIP REQUIRED TO RUN MYSQL-TEST-RUN.PL BUT NOT CHECKED FOR BY CMAKE
      Bug#20865674-VALGRIND FAILURE IN INNODB.CREATE_TABLESPACE
      BUG#19821087 UPDATES TO INDEXED COLUMN MUCH SLOWER IN 5.7.5
      Fixed Bug #20949226: CAN ASSIGN NON-DEFAULT() VALUE TO GENERATED COLUMN
      rb8590 Fixes to sporadically failing on PB2 rpl_xa_survive_crash_debug
      WL#8462: test_services are plugins serving as examples for how plugin services can be tested with mtr.
      Bug #20681412 MYSQLD --INITIALIZE REFERS TO MYSQL_INSTALL_DB AND BOOTSTRAP
      Bug#20937654 CANNOT BUILD WITH "-DDISABLE_SHARED=ON" FOR CMAKE BECAUSE OF REWRITER PLUGIN
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      Fixed failing tests
      WL#6940 Server version token and check
      Bug #20181776 :- ACCESS CONTROL DOESN'T MATCH MOST SPECIFIC                  HOST WHEN IT CONTAINS WILDCARD
      Bug#20961660 RPL TESTS ARE FAILING WITH INNODB: UNDO TABLESPACES MUST BE READABLE!
      WL#4601: Remove fastmutex from the server sources
      Bug #11759858 52203: MTR SPORADIC BUG (COULD NOT EXECUTE 'CHECK-TESTCASE' BEFORE TESTCASE)
      BUG#20955104: ADD UNIT TEST BINARIES AS OPTIONAL TARGETS WHEN MERGE_UNITTESTS=1
      Bug#19865673 DDL LIKE ADD INDEX IS VERY SLOW IN 5.7.5
      Bug #20294225 - INVALID MEMORY ACCESS
      Bug#20275612  MEMCACHED INNODB PLUGIN BREAKS MYSQL ENTERPRISE BACKUP
      Bug#20842030 ST_BUFFER CAN BE CALLED WITH PARAMETERS TO CONSUME INORDINATE AMOUNT OF MEMORY
      Bug #18592390 QUERY TO I_S.TABLES AND I_S.COLUMNS LEADS TO HUGE MEMORY USAGE
      Bug#19822257: WRONG VALUE PASSED TO --INIT-FILE OPTION CAUSES SERVER HANG
      BUG#20748570  BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      Bug#20515155 Views: Assertion failed: is_view_or_derived() && is_merged()
      Improved the way --print-defaults works.
      Bug#20615597 Assertion !thd->is_error() at st_select_lex::prepare()
      BUG#20960406  NO_PROTOCOL.INC SHOULD BE IN MYSQL-TEST/INCLUDE DIRECTORY
      WL#8165 Use new records per key interface in NDB
      Bug #20683237 BACKPORT 19817663 TO 5.1 and 5.5
      Bug #20275612 MEMCACHED INNODB PLUGIN BREAKS MYSQL ENTERPRISE BACKUP
      Bug#20895852 UNDERSIZED TMP_TABLE_SIZE - ASSERTION OR ERROR 2027 (HY000): MALFORMED PACKET
      Bug#20895852 UNDERSIZED TMP_TABLE_SIZE - ASSERTION OR ERROR 2027 (HY000): MALFORMED PACKET
      Revert "Bug#20683741 fixed."
      Revert "Updated file have_util_uz.inc under Bug Bug#20683741"
      Revert "Fixed Bug#20683741"
      WL#6940 Server version token and check
      Bug #20052580 MISSING MUTEX/LOCK IN ACL_AUTHENTICATION()
      Bug#20318154 : NEGATIVE ARRAY INDEX WRITE V2
      Bug#20952953 RPL.RPL_SLAVE_SKIP FAILS IN VALGRIND
      Bug#20952953 RPL.RPL_SLAVE_SKIP FAILS IN VALGRIND
      Fixed Bug#20683741
      Bug#20937173 CLEANUP GIS_DEBUG USELESS CODE
      WL#6940 Server version token and check
      Bug#20922238: REDUCE HEADER FILE DEPENDENCIES IN MY_SYS.H AND M_STRING.H
      BUG#20889900: UNITTESTS SHOULD START THE SERVER WITH APPROPRIATE OPTIONS
      Bug#20810627 ASSERTION: REC_PAGE_NO > 2 IN IBUF_GET_MERGE_PAGE_NOS_FUNC
      Bug#20748570 BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      WL#8017 Infrastructure for Optimizer Hints
      Fixing the query tipping points
      Modified the test to run only on 64 bit machine
      Revert accidental changes to collections/default.push
      Bug#20927239: MY_TIMER-T UNIT TEST DOES NOT WORK WITH MERGE_UNITTESTS=0
      Bug#20922238: REDUCE HEADER FILE DEPENDENCIES IN MY_SYS.H AND M_STRING.H
      Post push fix for BUG#20431860
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Bug#20748570 BOOL HA_TRX_INFO::IS_TRX_READ_WRITE() CONST: ASSERTION `IS_STARTED()' FAILED.
      Bug#20902791 MYSQLDUMP DUMPS SYS_SCHEMA
      Bug#20782142 PAM tests Fixed
      Updated file have_util_uz.inc under Bug Bug#20683741
      BUG#17259750 - STACK CORRUPTION IN VIO_IO_WAIT ON MAC OS X
      BUG# 20798617 - MYSQL CALLS  EXIT(MYSQLD_ABORT_EXIT) WITHOUT                 SHUTTING DOWN INNODB.
      BUG#20597821 INVALID READ OF BLOB MEMORY FREED IN ::CLEAR_BLOB_HEAP_PART
      Bug#20911624 THE SERVER CRASH WHEN TEST ST_INTERSECTS WITH ST_BUFFER
      Bug #20904893         INNODB: FIX RECENT WINDOWS 32 AND 63 BIT COMPILER WARNINGS
      Bug#20921370: NEW CLANG 3.6 WARNINGS - MUST ENABLE -WNO-UNUSED-LOCAL-TYPEDEF
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Clean up mysql-test/collections
      Enable run of default suites on daily valgrind
      Bug#19593342 CREATE SPATIAL INDEX FAILS TO FLAG AN ERROR FOR INVALID GEOMETRY DATA
      Bug#20903701 FIX VALGRIND WARNINGS IN UNIT TESTS
      WL#8161: Locking service for read/write named locks
      Bug#20789078 innodb: assertion: index->id == btr_page_get_index_id(page)
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug#18486509 ASSERTION FAILED: TABLE->KEY_READ == 0 IN CLOSE_THREAD_TABLE
      WL#8161: Locking service for read/write named locks
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Bug #16861371 SSL_OP_NO_COMPRESSION NOT DEFINED
      Fix Bug#20618309 ASSERT SLOT1->PAGE_LEVEL == SLOT2->PAGE_LEVEL, BTR_ESTIMATE_N_ROWS_IN_RANGE()
      Bug #20476395 DICT_LOAD_FOREIGNS() FAILED IN COMMIT_INPLACE_ALTER_TABLE
      Bug#20573701 DROP DATABASE ASSERT ON DEBUG WHEN OTHER FILES PRESENT IN DB FOLDER.
      Bug#20573701 DROP DATABASE ASSERT ON DEBUG WHEN OTHER FILES PRESENT IN DB FOLDER.
      Bug#20902600: REDUCE HEADER FILE DEPENDENCIES IN SP* AND EVENT* FILES
      Bug #20883256         INNODB: WARNINGS: NONNULL PARAMETER WILL EVALUATE TO 'TRUE' ON FIRST ENCOUNTER
      Bug#20888417: REMOVE FUNCTION DECLARATIONS WITHOUT DEFINITIONS
      Bug#20814396 PB2 IS SECRET ABOUT WHAT UNIT TESTS IT RUN
      WL#8161: Locking service for read/write named locks
      BUG #20414588 - REMOVE HARD-CODED AIO DISABLE FROM MTR
      Bug#20882432 INCORRECT MERGE_THRESHOLD LENGTH IN SYS_INDEXES AFTER UPGRADE, TRUNCATE, RESTART
      Clarify comment in my_global.h about where and why this header should be included.
      Dummy commit to keep the push hook happy.
      Bug#20856729: QUERY REWRITE: WRONG IFDEF SYMBOL IN SERVICE_PARSER.H
      Bug#20364862 : MYSQLADMIN PASSWORD AFFECTS EXTERNAL AUTH ACCOUNTS
      Bug#20364862 : MYSQLADMIN PASSWORD AFFECTS EXTERNAL AUTH ACCOUNTS
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Bug #19953365 MY_PRINT_DEFAULTS DOES NOT MASK PASSWORDS
      Bug#20752436: INNODB: FAILING ASSERTION: 0 IN FILE HANDLER0ALTER.CC LINE 6647
      BUG#17650326 MYSQLBINLOG PRINTS INVALID SQL FROM RELAY LOGS WHEN GTID IS ENABLED
      Bug#20350989: MYSQLBINLOG CAN'T DECODE EVENTS > ~1.6GB
      Bug#20609063 - STDOUT AND STDERR REDIRECTION ISSUES
      Bug#20752436: INNODB: FAILING ASSERTION: 0 IN FILE HANDLER0ALTER.CC LINE 6647
      Bug#20886222 MOVE THE DECLARATION OF FIL_NODE_T TO A HEADER FILE,              AND CLEAN UP COMMENTS Move the definition of the data structure fil_node_t from fil0fil.cc to fil0fil.h so that diagnostics code outside that module can access information about the files belonging to a tablespace. Also do other cleanup and formatting changes.
      Bug#20888417: REMOVE FUNCTION DECLARATIONS WITHOUT DEFINITIONS
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Bug#20849157 FIREWALL PLUGIN LEAKS MEMORY IN REPORT_ACCESS_DENIED Bug#20848331 WOULD LIKE ABILITY TO THROTTLE FIREWALL ACCESS DENIED MESSAGES
      Test cleanup
      Convert a func comments to new the InnoDB style.
      Non-functional style fixups
      Bug#20872436 MAKE DIST BY MISTAKE COPIES FILES WITH VARIABLE EXPANSION
      Bug#20882345: MOVE CODE OUT OF HANDLER.H
      Post-merge fix for WL#7806: Remove bogus files.
      Bug #17055185 : WRONG RESULTS WHEN RUNNING A SELECT THAT INCLUDES A HAVING BASED ON A FUNCTION.
      Bug#20615023 SIGNAL 11 IN ITEM_FIELD::RESULT_TYPE DURING 1ST EXECUTION OF PREPARED STMT
      Bug#20872436 MAKE DIST BY MISTAKE COPIES FILES WITH VARIABLE EXPANSION
      BUG 20459905 - DEADLOCK OF THREADS DETECTED! 5.7.5, 1 THREAD SQL TESTCASE, SPORADIC, IN IB_LOGF
      Bug#20863042 Stop filling mtr logs with InnoDB page dumps
      Remove a test from the experimental collection.
      Bug#20865407: DBUG_ASSERT(1) MAKES NO SENSE
      BUG#20857756: BUILD NT_SERVC.CC ONCE FOR ALL UNITTESTS ON WIN32
      Clean up the post-commit fix for Bug#20872655 debug instrumentation.
      Bug#20874411 INNODB SHUTDOWN HANGS IF INNODB_FORCE_RECOVERY>=3 SKIPPED ANY ROLLBACK
      Followup fix for BUG#20518099
      Post-commit fix or work-around for Bug#20872655 debug instrumentation.
      Post-merge fix for Bug#20872655 XA ROLLBACK IS NOT CRASH-SAFE
      Bug#20518099 - CLEANUP UNIV_INNOCHECKSUM in innodb code base
      Bug#19363615 : innodb.log_file fails very frequently on windows and solaris. Moved test from experimental to disabled state
      Raised version after tagging 5.1.74 (some commits skipped)
      Bug#20872655 XA ROLLBACK IS NOT CRASH-SAFE
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Bug#20788811 MAX_STATEMENT_TIME: ASSERTION `EXPLAIN_OTHER || UNIT->IS_OPTIMIZED()' FAILED.
      Bug#20771331 : BE MORE EXPLICIT WHEN ABORTING DUE TO MISSING DIR SET BY SECURE-FILE-PRIV OPTION
      Test cleanup
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES            OF INNODB_CHECKSUM_ALGORITHM
      Bug#20104307 GTID_EXECUTED TABLE COMPRESSION THREAD MAY NOT WAKE UP
      sys_vars.innodb_compress_debug_basic requires P_S to run
      Bug#20859285: REDUCE HEADER FILE DEPENDENCIES OF SQL_CLASS.H AND TABLE.H
      Add daily and weekly collections of tests that shun --parallel.
      Bug#20578834 - INNODB READ ONLY MODE AND NON EXISTENT TMP DIR CRASHES SERVER
      Bug #20809045    BUFFER OVERFLOW IN MYSQL
      Silence rpl_xa_survive_crash_debug in Valgrind.
      Bug# 19573096: LOADING CORRUPTED GEOMETRY DATA INTO A                MYISAM TABLE CAUSES THE SERVER TO CRASH
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES                    OF INNODB_CHECKSUM_ALGORITHM
      Bug#20857979 REMOVE DEPENDENCY ON HANDLER.H FROM PFS_ENGINE_TABLE.H
      Bug#20768820 MAIN.BIGINT TEST FAILS WHEN BUILT WITH GCC 5 IN RELEASE BUILD
      Bug#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bug#20858778 VALGRIND FAILURE AFTER THE PUSH OF WL#8244
      Bug#20855853 MDL SUBSYSTEM ENCAPSULATION BROKEN
      Bug#20816223 test fix.
      Remove MCP_WIX
      Remove MCP_WIX
      WL#7806: Add a test case from Viswanatham Gudipati with some cleanup by me.
      Test cleanup
      WL#7806: Relax a test that started to fail due to WL#6205.
      WL#7795 PERFORMANCE SCHEMA, HISTORY PER THREAD
      WL#7795 PERFORMANCE SCHEMA, HISTORY PER THREAD
      Clean up a test case. Use slow shutdown in order to avoid generating redo log after restart, for processing old undo logs or change [1;31mbuffer[m records.
      WL#7806: Re-enable a test and work around a problem in WL#6965.
      WL#7806: Add a temporary workaround until WL#7691.
      WL#7806: Temporarily remove the fil_sys_lookup[] for user tablespaces in order to ensure that we are not masking Bug#18645050.
      WL#7806: Add a flat fil_sys_lookup[] array so that fil_spaces_lookup() can avoid acquiring fil_system->mutex when looking up the system tablespace or the undo tablespaces. This is addressing a performance regression.
      WL#7806: Correct some comments.
      Test that no redo log gets generated unexpectedly.
      Rename some tests to comply with new policy:
      Try to get a test to work on Windows.

[33mcommit 112025a48f84ec4f0140a9af1f14e4ec76da3668[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri May 15 10:14:09 2015 +0300

    Remove the inclusion of an unneeded <map> header
    
    std::map is not used anymore in buf_stat_per_index_t
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit a3424a3a57b6ce552f1ea725ebd9a313ad4edfac[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Thu May 7 11:58:48 2015 +0300

    WL#7899: InnoDB: Map compressed temporary tables to uncompressed
    
    Temporary tables are supposed to be short-lived, ideally never written
    back to files, unless the [1;31mbuffer[m pool space is tight. It does not seem
    to make sense to try to reduce the file I/O by increasing the memory
    and CPU usage.
    
    With this change, all temporary tables will be created in the shared
    temporary tablespace "ibtmp1" introduced in WL#6560.
    
    Two columns will be dropped from the INFORMATION_SCHEMA table
    introduced in WL#6469, because they will be always FALSE:
    
    INNODB_TEMP_TABLE_INFO.PER_TABLE_TABLESPACE
    INNODB_TEMP_TABLE_INFO.IS_COMPRESSED
    
    After a long discussion, we come to the agreement:
    1) innodb_strict_mode would be default ON (WL#7703)
    2) When innodb_strict_mode is ON, we should reject compressed
    temporary tables by throwing an explicit error, telling users
    to try other row formats
    3) if innodb_strict_mode is OFF, we should try to accept all
    current SQL statement which is currently handled.
    So compression-related options would be ignored and
    some warnings would be thrown.
    
    If innodb_strict_mode=OFF, ROW_FORMAT=COMPRESSED or KEY_BLOCK_SIZE
    will be interpreted as ROW_FORMAT=DYNAMIC, since DYNAMIC row format is
    closer to COMPRESSED in that it supports better support for large
    BLOBs. Warnings will be issued about this.
    
    If innodb_strict_mode=ON (the default), we will throw a new error code:
    ER_UNSUPPORT_COMPRESSED_TEMPORARY_TABLE.
    
    dict_tf_to_fsp_flags(): Remove the parameter is_temp.  We no longer
    create implicit tablespaces for temporary tables. (This is the main
    motivation of WL#7899.)
    
    row_mysql_drop_temp_tables(): Remove. Temporary tables will reside
    only in the shared temporary tablespace which will be emptied on
    startup, so there is nothing to drop. Also, no entries will be written
    to the persistent data dictionary about temporary tables.
    
    This work was originally done by Bin Su for MySQL 5.7 about a year ago,
    but it was not accepted for MySQL 5.7.

[33mcommit ca6ecd8229c53b0a139304bf6641cef6e529e61a[m
Merge: b840f9e9e35 2e91bec76f5
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Apr 8 12:35:31 2015 +0300

    Merge remote-tracking branch 'myrepo/mysql-trunk' into mysql-trunk-wl7170
    
    * myrepo/mysql-trunk:
      Bug #20590548 UNABLE TO LOGIN WITH USER WHOSE PWD CHANGED FROM 5.6.23 MYSQLADMIN IN 5.7.6
      Bug#20726413 : MYSQL_SSL_RSA_SETUP DOES NOT HAVE USER OPTION
      Fix Bug#20568464 MITIGATE THE STRICTNESS OF STRICT_* MODES                    OF INNODB_CHECKSUM_ALGORITHM
      WL#8244 Hints for subquery strategies. Part#2: Add support for SEMIJOIN/_SEMIJOIN and SUBQUERY hints
      WL#8244 Hints for subquery strategies. Part#1: Add optimizer_switch for DuplicateWeedout strategy.
      WL#7696 follow up fix, check return values.
      Fixed bug#20745142: GENERATED COLUMNS: ASSERTION FAILED: THD->CHANGE_LIST.IS_EMPTY()
      Fixed bug#20797941: WL8149:ASSERTION `!TABLE || (!TABLE->READ_SET ||                     BITMAP_IS_SET(TABLE->READ_SET
      BUG#20593808 - CRASH WITH PARTITIONED TABLES + MULTITABLE DELETE
      WL#7696 follow up fix.
      Bug#20788853 MUTEX ISSUE IN SQL/SQL_SHOW.CC RESULTING IN SIG6. SOURCE LIKELY FILL_VARIABLES
      WL#7696 followup - remove unused file
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, check return value of file read.
      WL#7696 followup fix, rerecord the test
      WL#7696 follow up fix, add INNODB_COMPRESS_DEBUG to the test.
      Bug#20840377 UNITILAISED BYTES REPORTED AT MY_WRITE.C:63
      Fixed failing tests after commit 335a53004313ab5a971cf17dea36f1dc4490db9f MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20755430 COST CONSTANT CACHE MUTEX NOT INSTRUMENTED BY PERFORMANCE SCHEMA
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      MANAGE HANDLE_GRANT_STRUCT DURING DROP USER
      WL#7696 follow up fix.
      WL#7696 follow up fix - add INNODB_COMPRESS_DEBUG to the list
      Addendum to bug #20810928: fixed the test to reflect that COM_SHUTDOWN can be a zero-length RPC
      BUG#20422712 - CANNOT INITIALIZE OR USE RAW DEVICE AS INNODB FILE
      Bug#20678411 BROKEN MAKEFILE DEPENDENCY: SQL_YACC.YY AND LEX_TOKEN.H
      Bug #17299181    CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      BUG#20093172 LOG_STATE DECLARED VOLATILE, MISSING MEMORY BARRIERS
      BUG#20042205 RPL_GTID CHECKABLE_RWLOCK DEBUG CODE DOESN'T NEED VOLATILE              LOCK_STATE
      BUG#20042109 MYSQL_BIN_LOG::M_PREP_XIDS DOESN'T NEED TO BE VOLATILE
      BUG#20754369: BACKPORT BUG#20007583 TO 5.1
      Bug #17299181  CREATE_TIME AND UPDATE_TIME ARE WRONG FOR PARTITIONED TABLES
      Bug#20411374:CAN NOT EXECUTE CHANGE MASTER AFTER ERROR OCCURED IN MTS MODE
      Bug#20683741 fixed.
      Bug #20814051 CREATE USER BINLOG EVENTS INCLUDE NEW ACCOUNT KEYWORD
      BUG#20510811 - RQG_ALTER_ONLINE_PART RUN INTO ASSERTION: NODE->ENTRY
      Bug#20279241 - ALTER TABLE XXX CHARACTER SET UTF8, CONVERT TO CHARACTER SET LATIN1 SHOULD FAIL
      Adapt new sql/ha_ndbcluster.cc code to use the new ER_THD() macro
      Remove MCP_GLOBAL_SCHEMA_LOCK patch
      Bug #20810928: CANNOT SHUTDOWN MYSQL USING JDBC DRIVER
      Fixed Bug #20683741.
      Test cleanup
      Bump version to 7.5.0
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20811494 SHOW_COMPATIBILITY_56 = OFF INCOMPATIBLE WITH CONNECTORS
      Bug#20531812: MEMORY CONSUMED QUICKLY WHILE EXECUTING LOOP IN PROCEDURE
      Bug#20683959 LOAD DATA INFILE IGNORES A SPECIFIC ROW SILENTLY UNDER DB CHARSET IS UTF8
      Remove MCP_BUG16021021
      Remove MCP_WIX
      Bug#20313067 CHECK TABLE REPORTS WRONG COUNT FOR SPATIAL INDEX AND OTHER GIS PROBLEMS
      Bug#20124342 MYSQL 5.6 SLAVE OUT OF MEMORY ERROR ? Problem: I/O thread on Slave with master_info_repository=TABLE settings, is leaking memory that leads to Out of memory (OOM) after some time.
      Fix merge error in mysql_system_tables_fix.sql
      Remove MCP tags for BUG16226274
      BUG#20811125 INNODB FTS: FTS_PRINT_DOC_ID PRINTS TOO MANY DEBUG INFORMATION
      Bug#20762059 - innodb_thread_concurrency=1 and queries using intrinsic temp tables, causes hang
      Create an .inc file which does slow shutdown before restarting innodb in read-only mode.
      Bug#19811953 ENVELOPE() FUNCTION RETURNS INVALID POLYGON Bug#20196720 ENVELOPE(P) RETURNS NULL FOR A NON NULL POLYGON P
      Bug #20544581         ASSERTION: REC_PAGE_NO > (ULINT) 4 - (REC_SPACE_ID != 0)
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      Bug#19770943 THD::LOCK_QUERY_PLAN HAS AN UNREASONABLY HIGH CONTRIBUTION TO WAIT TIME
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 - Fix a merge issue.
      WL#7696 - Fix a merge issue
      WL#7696 - Fix the column ordinatlity. Messed up in a previous merge.
      WL#7696 - Fix a compilation error
      move some compression tests elsewhere until using Win32::API module is approved. Improve error detection, if there is no module, the tests will succeed, not fail as before, but the testing power will be somewhat limited.
      Bumped rpm version for oel due to respin
      Bug#20756770 MYSQL SERVER DOESN'T COMPILE AGAINST OPENSSL 1.0.1M
      Patch for Bug#17162055: SSL.CMAKE SILENTLY CHOOSES BUNDLED YASSL INSTEAD OF ERRORING FOR OLD OPENSSL VER
      Bug#20755346 EXAMPLE SCRIPT IN FIREWALL MISSES WHERE CLAUSE
      Bug#20764521 REGRESSION: FIREWALL USE GENERAL_HOST TO RESOLVE HOST
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#8326 Make NO_AUTO_CREATE_USER sql_mode behavior the default in 5.7
      Resurrect unintentionally remove disabled.def file
      Resurrect unintentionally remove disabled.def file
      Bug#20651661 NDBEVENTBUFFER LEAKS GCI_OP
      Remove three files which did not properly remain
      WL#7696 - Make LZ4 decompress safe during recovery
      Remove hack to allow large number of failing tests in mtr.pl
      WL#7696 - Reset the contents of the page to NUL.
      WL#7696 - Use the double write [1;31mbuffer[m pages for compressed pages.
      WL#7696 - Fix syntax error on Windows.
      WL#7696 - Fix debug assertion.
      mysql-test/include/innodb-compress-utils.inc:   add OSD support to get allocated file size for Windows
      add the result file missing in the previous commit
      Test update:   mysql-test/suite/innodb/t/table_compress.test:     fix one failing case for 32k   mysql-test/suite/innodb/r/table_compress_2.result: make use of new     include files   mysql-test/suite/innodb/t/table_compress_3.test: new test to cover     what was not covered yet, shared tablespaces in particular   mysql-test/include/innodb-compress-verify.inc: common sequence     for compression verification   mysql-test/include/innodb-compress-utils.inc: perl compression     related utilities.     Note: OSD Windows file allocated size is not implemented yet.     The test is still expected to pass on Windows because the allocated     size is forced to the expected value.
      Bug #20536590: BACKPORT BUG #12368204 AND BUG #16953758 TO MYSQL-5.6
      WL#7696 - Code clean up. Ignore table COMPRESSION setting if set to NONE.
      WL#7696 - Minor code cleanup
      WL#7696 - Fix the punch hole size calculation.
      Bug#20712432 AUTOTEST: TESTFK FAIL IN CLEARTABLE WITH 256 REFERENCED ROW EXISTS
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#18408653 AUTOTEST FAIL: TESTNDBAPI -N FRAGMENTEDAPIFAILURE T1
      Bug#17775772 POTENTIALLY UNINITIALIZED BUFFER IN NDBOUT::PRINT* PRINTOUT   - print nothing or just empty newline instead of uninitialized [1;31mbuffer[m   - catch error with an assert in debug compile
      Bug#17775607 POTENTIALLY UNINITIALIZED BUFFER IN VNDBOUT_C PRINTOUT  - print empty newline instead of uninitialized [1;31mbuffer[m  - catch error with an assert in debug compile  - Mark vndbout_c as static and thus local to implementation Conflicts in copyright:        storage/ndb/include/util/NdbOut.hpp     storage/ndb/src/common/util/NdbOut.cpp
      Remove unused parameter ndbcluster_drop_event()
      Bug#20032381 KILLED_STATE SAVE IN NDBCLUSTER_BINLOG RETRY AT SHUTDOWN DOESN'T NEED TO BE VOLA
      Bug#20014045 MONOTONIC SPELT INCORRECTLY IN NDB CODE
      Bug#20092754:  MYSQLD CRASH (FOUND UNCOMITTED AUTOCOMMIT+RBWR TRANSACTION, COMMIT STATUS 3)
      mysql-test/suite/innodb/t/table_compress_2.test:
      Raise version number after cloning 7.4.5
      Correct MTR command for 64k run. Adiing missing "k".
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      Tetss that use innodb_compress_debug should run against debug server
      Added runs with differnt combination and page size setting for Innodb suites
      mysql-test/suite/innodb/t/table_compress.test:   Fix failure when hole punching is not available.   Now the test will be skipped instead
      Revert accidental bump of server version back to 5.6.23
      Fix a compilation warning in non-debug mode
      BUG#18949230: Removed unneeded ndbassert and fixed printout, also recorded number of real periods
      Added some extra output to ndbapi tests utilities as an aid to hunt down the AutoTest failure 'testBasic -n Bug54986 D2'
      Added log printout about invalidation of REDO log and where log head was found
      WL#6815 Adapt MySQL Cluster to 5.7
      Added autotest files for Mikaels environment, added comments about how to get file system as part of results in autotest, added comment about how to handle older git versions with autotest
      BUG#20546157: Fix problems in START_PERMREQ and START_INFOREQ that hangs node restarts when invalidation of nodes is still ongoing at node restart
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20480035 REMOVE MCP_BUG44529
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disable ndb_rpl_circular_2ch* waiting for Bug20592110
      Disable ndb_addnode_witbinlog waiting for Bug17400320
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75720: Fix platform issues with ndb_dd_dump test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7696 Add support for 'bundled' or 'system' lz4 library
      WL#7696 - Don't print a warning on Windows if SPARSE FILE attribute can't be set
      BUG#20631645: Ensure that SYSFILE->latestLCP_ID is properly up-to-date in the pause LCP protocol
      Fix regression caused by wl#7674 in testBasic -n RefreshTuple T6 D1
      Fix regression caused by wl#7674 in testDict -n Bug13416603 I2.
      Fix for Bug#20408733:
      WL#7696 - Punch hole message is Linux specific.
      WL#7696 - Backport code from mysql-trunk to mysql-5.7
      Followup fix for "Bug20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK"
      WL#6815 Adapt MySQL Cluster to 5.7
      Another follow up fix for "BUG11748566 - MYSQL SHOWS WRONG DEFAULT VALUE FOR PK IF  NOT NULL NOT SPECIFIED"
      BUG#20568586: Fix ndb_cpcd to avoid reading a closed file
      BUG#20567730: Ensure that late arriving LCP_FRAG_ORD with lastFragmentFlag set from new master are handled correctly, correct is to ignore them if such a signal arrives in idle LCP state
      Fix for bug#20538179
      BUG#20546899: Faulty ndbrequire fixed
      BUG#20553247: Fix memcpy overlapping copy issue
      BUG#20553247: Use memmove for overlapping memory copy
      Commit this fix on behalf of Pekka N:
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      BUG#19811871 VERSION NUMBR NOT SHOWN IN LOG WHEN [RE]STARTING 5.6.21 SERVICE WITH SLES11 REPO
      BUG#20477758 CONFLICTS WHILE INSTALLING COMMUNITY PACKAGES WHEN MARIADB, LIB FILES INSTALLED
      Updated copyright information
      Bug#20228839: MISSING DATABASE '-D' OPTIONS FOR FEW OF THE HUGO TOOLS
      Re-enable clusterj tests disabled during 7.4.4 release.
      Bug#20593065 MULTI UPDATE RETURNS DIFFERENT DATA WITH ENGINE NDB
      This commit is a followup to the fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_time calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop timeout to be configured).
      Add support for SLES12
      Merge 7.3->7.4
      Merge 7.2->7.3
      Overriding release() function from the DynamicObject class in its subclasses.
      This commit is a fix for bugs 20069617 (consider noofreplicas in dynamic max_failure_time calculation) and 20069624 (allow the 120s constant part of the gcp_save gcp_stop timeout to be configured).
      Reverse order of libraries used when linking the ndbapi examples
      Add small MCP for problem with Partition_handler::get_default_num_partitions
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM: fix test regression
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#7549: Fix test case for removed EMPTY_LCP protocol
      BUG#20444078: Removed unneeded log printout
      BUG#20444078: Fix master takeover of COPY_GCIREQ protocol
      WL#6815 Adapt MySQL Cluster to 5.7
      Revert accidental version number change
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20528878 : P_S UNIT TEST IS FAILING
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20539452 POSSIBLE MEMORY LEAK IN NDBEVENTBUFFER::ALLOC_MEM
      Temporarily hack mtr.pl to allow a large number of failing tests
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Disabling ndb.clusterj and ndb.clusterj_jpa tests for 7.4.4 release.
      WL#6815 Adapt MySQL Cluster to 5.7
      bump version to 7.4.5
      Bump version to 7.4.5
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20281479: Entered eternal loop when starting node in MGM server due to buggy bug fix
      Fix unintentional increase in testsize by a factor of 100 of 'testBasic -n Bug54986'
      BUG#20513571: Introduce MaxSendDelay for large clusters
      Fix failing AutoTest 'testIndex -n NFNR3*'
      BUG#20512063: Moved verbose logging to only be used in verbose mode
      Add missing failure detection for 'testBasic -n Bug54986'.
      BUG#20281479: Ensure that START_ORD is properly sent from management server
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#20504971: Fixed restart_info table to provide its output
      WL#6815 Adapt MySQL Cluster to 5.7
      Proper error printouts after reaching NDBT_FAILED in test cases
      Backport fix for BUG#20276462
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Bug#20412236 NDB : TRPMAN RECEIVES DUPLICATE DUMP_STATE_ORD SIGNALS
      Updated to newest version of flexAsynch
      Patch related to bug#18401543
      BUG20308276: Don't use same list for master and participant part of takeover processing
      Fix issue in AutoTest where test are being killed by WatchDog during memory allog in startphase 0.
      BUG20276462: Fixed spelling error in error code
      BUG#20276462: Error code ZNODE_FAILURE_ERROR has no treatment in NDB API, use NODE_SHUTDOWN_ERROR instead
      WL#8148 NDB: Add git support to Autotest
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      WL#6815 Adapt MySQL Cluster to 5.7  - remove MCP tags for MCP_WL1735 which was forgotten when    rewriting clean_away_stray_files() to use find_files() directly.  - Now there should be no trace left of MCP_WL1735
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT
      Bug#20234994 JOINS ARE NOT PUSHED AFTER WL6042
      Revert "Adapt pushed joins to WL#6042"
      Fix for Bug#19053226 AUTOTEST FAIL: TESTSRBANK -N MIX -L 300 -R 15 T1
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) PART III
      Bug#20410087 GCOV COVERAGE DATA FOR NDB KERNEL IS MISSING
      WL#8294 NDB: turn on signal checksum as default
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Bug#20423960 REMOVE TESTING OF NO LONGER USED EMPTY_LCP_REQ/CONF.
      Disabling mtr tests on 7.1 which fail because SSL certificates have expired.
      Re-recording mtr test result after ssl certificate update
      Bug#18366947 : VALID DATE RANGE OF DUMMY SSL CERTS IS WAY TOO SHORT Generated new certificates with validity upto 2029.
      Fix test client failure for AutoTest 'testNodeRestart -n ClusterSplitLatency'
      Bug#19785977:  CRASH IN NDBINDEXSCANOPERATION::SCANINDEXIMPL
      Bug#20423898 BAD TEST TESTNODERESTART -N LCPTAKEOVER CAN NOT FAIL.
      Improve ndb_rpl_circular_2ch_rep_status reliability.
      Test was random failing due to matching random binlog junk. Make false matches less likely.
      A little brute force to understand the issues with ndb_rpl_circular_2ch_rep_status
      Bug#17579998 INVALID SUB_GCP_COMPLETE_REP DUE TO SUMA RESEND DATA FOR ALREADY COMPLETE EPOCH
      Experimental experiment with experimental status.
      A more standard variant of !valgrind.
      BUG#19667566 : PARTITION BY WITH COMMENT LEADS TO MYSQL SERVER REBOOT IN MYSQL CLUSTER
      Sacrifice Valgrind run to improve ndb_rpl_slave_binlog_index reliability.
      Backport of fix for bug#16209645
      Bug#17579998 TEST 'TESTNODERESTART -N GCP -L 1 T1' FAILS DUE TO MYSQLD ABORTED
      ndb_rpl_slave_binlog_index.test
      ndb_types.test contained binary raw data from 'bit' and 'binary' columns.
      Bug #20372169         NDB : INCORRECT STATUS VARIABLES NDB_LAST_COMMIT_EPOCH_[SERVER|SESSION]
      Fix of uncorrect merge (7.2 -> 7.3) of regression fix for bug#19524096
      Fix regression introduced by fix for bug#19524096.
      Fix regression introduced by fix for bug#19524096.
      Fix regression introduced by fix for bug#bug#19524096.
      Improve ndb_rpl_slave_binlog_index.test behaviour under Valgrind.
      Bug#20364309 MODIFY SHOW CREATE TABLE OUTPUT FOR BETTER OPENSTACK INTEGRATION
      Add some improved debugging to help understand non locally reproducable problems with ndb_binlog_last_commit_epoch testcase.
      This commit is a fix for Bug#19880969 (CLUB FOR 7.1, LINUX-RELEASE, 345 WARNINGS IN BUILD). The fix suppresses these warnings, so that the corresponding square in club becomes green rather than red.
      Bug #19306793         CORE IN NDBAPI WHEN EXTENDED EXTENSION TABLE IS CREATED IN MYSQL 7.4
      Quick fix of corrupted special comment characters. No code change.
      Updated the copyright year in README and welcome message
      Improve garbage collection of clusterj artifacts
      Updating copyright year
      Some copyright fixes to files changed in 2014
      Fixing user visible copyright years
      Fix for 7.4.3 build failures
      Fix for copy right year
      Corrected copyright year by sreedhar
      Updated README and banners to 2015
      bump version to 7.1.35
      pgmanpe pe-dump.diff pgman: dump max page entries bug#18484117 bug#19915761 bug#19958804
      pgmanpe pe-config.diff pgman: configure max page entries bug#18484117 bug#19915761 bug#19958804
      BUG#19480197, BUG#73667, BUG#74945: Ensure Local object has transferred back object to real object before calling recursive function
      Cherrypick fix which removes MCP_WL1735 from 7.4
      Cherrypick fix for bug20009152 from 7.4
      Adapt pushed joins to WL#6042
      Follow up fix for bug#20112981
      Fix for bug#20112981
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - rewrite clean_away_stray_files() to use find_files() direct rather than going via make_db_list(). - The only difference between make_db_list() and find_files() is that the information_schema database is not   return in the list of databases. But it's currently not possible  to create a NDB table in information_schema   and thus there can not be any "stray" tables there either.  - testcase added to ndb_reconnect which shows access denied when trying to create table    in information_schema  - This avoids patching the MySQL Server to make the static make_db_list() function available    to use in ha_ndbcluster_binlog and thus the MCP for make_db_list() and LOOKUP_FIELD_VALUES   can be removed. - Also remove the NDB_WITHOUT_MAKE_DB_LIST which was used for compiling ndbcluster in MySQL Server
      Remove unused TNTO_NO_REMOVE_STRAY_FILES Thd_ndb option
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#19898269, BUG#74594: Fixed wrong order of sending bitmap of LCP participants to ensure that starting node can correctly calculate the lcpOngoing flag for each fragment
      Another addendum patch for bug#20112981, adressing comment from Mikael R.
      Incremental addendum patch for bug#20112981
      Fix for bug#20112981
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      Bug#20032861 DROP DATABASE PERFORMANCE_SCHEMA DROPS IT ON ALL SQL NODES
      BUG#75220: Added option to use 10 and 20 LDM threads (same for NoOfLogParts)
      BUG#20215395: Bug in cluster join protocol
      Added jams to place where data nodes freezes in startup
      BUG#19590336: Preparatory patch adding lots of jam:s to DD code, also a few more more comments added
      Additions to wl#7674
      Bug#18715165, BUG#17069285
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Bug#19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Bug#20193236 SOME COMPILER WARNINGS BECAME ERRORS AFTER MERGE OF MYSQL SERVER 5.5.41
      Cherrypick from 5.6 : Bug#20009154 - FIX REGRESSION AFTER HA_FLUSH_LOGS() HOOK FOR NDB IS REMOVED.
      Bug 19895502 -  BINARY LOG GROUP COMMIT CAUSES REGRESSION FOR NDB REPLICATION.
      This commit is a followup to WL#8145 (NdbInfo : Per-fragment operations info). That WL introduced an error causing 'testScan -n Bug54945 T1' to fail: short-signal scans crashes because the attrinfo section is not available at the point where the code tries to read it to find the size of the interpreted progam. This commit fixes that by not trying to count program size for short-signal scans and lookups. Since these only happen during online upgrade, they are not important for per-fragment statistics.
      Bug #19992856 MYSQL CLUSTER TRIGGER ON DELETE FALSE POSITIVE
      This commit is a followup to the fix for bug#19976428 ("reports failing with 'out of longmessage[1;31mbuffer[m' error"). This commit updates a regression test (testIndex/FireTrigOverload) so that it will expect the right error code (293 "Inconsistent trigger state in TC block" instead of 218 "Out of LongMessageBuffer").
      autotest auto1.diff testBasic -n Bug16834333 : fix dict cache crash
      Bug #19858151         MAKING DATA NODE SELF-EXCLUDE MECHANISM MORE ROBUST
      Bug #19550973: CREATE/DROP DATABASE STATEMENT SEGFAULTS IF IDENTIFIER LENGTH IS >=64
      Updated fix for bug#20113145:
      Follow up to fix for bug#bug#20166585:
      Follow up to fix for bug#bug#20166585:
      This commit fixes bug #19976428 ("reports failing with 'out of longmessage[1;31mbuffer[m' error"), and a set of other issues related to the pool of "Fired Trigger" records.
      Bug#17069285 : SEGMENTATION FAULT IN NDB_PRINT_FILE
      Update to recent fix where we failed to close scan cursors at the end of their lifetime.
      WL#7514: Fitted into infoEvent max size and decreased some too wordy log printouts
      Update 'v3' fix for bug#20166585:
      WL#7514: Fixed an incorrect assert
      Fix for various AutoTest 'testIndex ...' crashing due to excessive memory usage.
      Bug#18715165, BUG#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for: - Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT - BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      Bug#17069285 Rewriting the mysql-test/mysql-test-run.pl hack for "BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE"
      The AutoTest testcase 'testScan -n Bug54945 T1' crashed as it failed to create a transaction object which was later referred without first checking that it was created.
      Fix for crashing AutoTest: 'testNdbApi -n RecordSpecificationBackwardCompatibility'
      WL#6815  Adapt MySQL Cluster to 5.7
      Fix flexAsynch also in 7.3, backport from 7.4
      WL#7508: Parallelize synchronization of starting nodes with live nodes
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7  - Test fails since the two new default sql_modes  ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES   are displayed by "show create procedure"  - Update .result file to include the two new default sql_modes(as has been done in similar   places)
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      Experimental fix for several AutoTest which crash with an unreadable stack dump very early in their lifecycle, like:
      Fixed crashing AutoTest testBitfield.
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Cherrypick fix for ndb_memcache out of source from 7.4
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20136739 NEW WARNINGS AFTER MERGE FROM SERVER 5.5.41 AND 5.6.22 INTO MYSQL CLUSTER
      Bug#20135403 NDB_MEMCACHE TEST DOES NOT WORK IN OUT OF SOURCE BUILD
      Fixed crashing AutoTest: './testLimits -n ExhaustSegmentedSectionPk WIDE_2COL'
      Bug#18715165 : NDB_INDEX_STAT FAILS WHEN UNIQUE KEY EXISTS; SEGMENTATION_FAULT
      BUG#74594: Fixed a hang in PAUSE LCP protocol when LCP was completed between PAUSE and UNPAUSE
      Removed lots of jam noise from QMGR preventing one from seeing the bugs
      WL#6815  Adapt MySQL Cluster to 5.7
      Revert some junk lines from pfs_upfgrade*.result files
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815  Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherry-picked from mysql-5.6.22-release
      Cherry-pick from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.6.22-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-picked from mysql-5.5.41-release
      Cherry-pick from mysql-5.5.41-release
      Added tag mysql-5.6.22
      Added tag mysql-5.5.41
      BUG#74594: Fix missing state update that causes PAUSE LCP protocol to hang
      BUG#74594: Added some more DUMP printouts for PAUSE LCP protocol
      WL#7650: Make atrt work on Mac OS X
      Removed assert / require from NDBT_ResultRow c'tor and rewrote it such that it could be constructed even if the the object is not in 'Retrieved' state.
      BUG#75007: Ensure we wait until master takeover is completed before handle LCP_COMPLETE_REP from LQH and DIH participants in the LCP protocol
      Bug#20029843 7.4.2 REGRESSION: UPGRADE_TRAFFIC FAILURES FOR 7.4 -> 7.3: Fixed incorrect conditional expressions
      Cherrypick fix for ndb_dist_priv.sql from 7.4
      WL#6815  Adapt MySQL Cluster to 5.7
      Cherrypick fix for mysql_system_tables_fix.sql from 7.4
      WL#6815 Adapt MySQL Cluster to 5.7
      Encourage MySQL to treat numeric variables as numbers so that ndb_rpl_conflict_epoch2_extra does not return incorrect results from inequality tests.
      BUG#75007: More work on ensuring that we drop the right signals of the LCP_COMPLETE_REP and LCP_FRAG_REP, a bit tricky to decide, wrote up an analysis in a comment and a fairly simple code based on this analysis
      Cherrypick fixes for ndb_alter_table_online from 7.4
      Remove usage of DEFAULT 0 for TIMESTAMP
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fixed for ndb_update_no_read from 7.4
      Turn "info" off after each section in test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      Cherrypick fix for ndb_dd_disk2memory from 7.4
      Add missing enable_query_log comman in ndb_dd_disk2memory.test
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#75007: Fixed interaction with early master takeover initialisation and handling of failed node in LCP, code in new master
      BUG#75007: Handle side effect of bug fix, there are signals generated by node failure handling that must be allowed to pass through the code as they are required for node fail handling to be done properly
      Apply patch for MCP_BUG19704825to 5.7.5
      Bug#20031425 NDBINFO NAMESPACE FREE CHECK FAILURE
      WL#6815 Adapt MySQL Cluster to 5.7
      WL#6815 Adapt MySQL Cluster to 5.7
      BUG#74594: Fix of variable length in message to management server to avoid printing garbage
      BUG#75007: Ensure that we drop LCP_FRAG_REP and LCP_COMPLETE_REP that originates from a dead node. The LCP could potentially be done before this arrives due to node failure handling, these signals are sometimes delayed and thus we need to take care that we can still receive them.
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Assumption that all alive nodes have participated in LCP at close down time caused havoc since we can now be alive and still not have participated in the LCP. So had to move the send of the last LCP_COMPLETE_REP backwards a bit to be able to reuse the m_participatingDIH bitmap to send to.
      remove last NDB_WITHOUT_COLUMN_FORMAT ifdef  - since all versions of MySQL Server which ndbcluster   compiles against now supports "field->column_format" and "field->storage_type" - one NDB_WITHOUT_COLUMN_FORMAT left behind(or reappeared)
      BUG#19795152: Missed essential ptrCheckGuard in upgrade/downgrade situations
      WL#7514: More printouts to log for system restart case
      BUG#18610698: New test case
      BUG19795152: Fix Software upgrade issue
      Add missing delete of Ndb instance created by testcase
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Minor tweak of jamming and of a loop
      BUG#19795217: Checked the LCP state a bit too early
      BUG#74594: Added one more cluster log event
      BUG#74594: Wrong check if LCP is idle when sending UnPause message
      bug#20045455 Improve error reporting for clusterj
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Fixed a compiler warning in new tool
      BUG#74594: Wrote an analysis tool for reading DIH Fraglist files to enable easier analysis of system restart bugs
      BUG#74594: Queued LCP_COMPLETE_REP comes from LQH, not from DIH
      BUG#74594: Fixed a typo bug in an important condition
      Bug#20067036 AUTOTEST RELATES TEST CLIENTS COREDUMPING TO INCORRECT TESTS
      BUG#74594: Added a new ndbrequire to find problem
      WL#7514: Added a bit more logging of the actual start order signal
      flexBench created its worker threads, flexBenchThread, with a stack of insufficent size. This later caused the threads to crash.
      WL#7509: Add undocumented interface to change Disk Write Speed in LCPs, change isn't persistent over restarts, useful to handle SRs where restarts are too slow
      WL#7509: Tweaked the adaptive LCP speed parameters to be a bit slower in changing
      BUG#74594: Add DUMP_STATE_ORD variant to print pause state to cluster log
      BUG#19795108: Proper fix of node restart status using the new Node Recovery Status module
      BUG#19795152: Handle Partial System restarts
      BUG#74594: Used wrong variable in non-master to decide on pauseAction
      Attempt better "htonll" portability in NDB memcache code
      Fix for bug#19390895
      BUG#74594: Ensure that we drop PAUSE_LCP_REQ signals from master if it concerns a node that already has died
      BUG#74594: Node failure in inopportune time caused crash
      BUG#74594: Decrease amount of useless jam:ing to make bugs more visible
      Bug#19642978: NDB_RESTORE CORES ON BUILT-IN PRIMARY KEY + STAGING BLOB CONVERSIONS ON SPARC
      Fix for bug#20031313  AUTOTEST CASE 'TESTDICT -N GETTABINFOREF' NEVER WORKED FOR >= 4 DATA NODES
      BUG#74594: Turned ndbrequire condition the wrong way, caused obvious crash, added a few more ndbrequires while at it
      BUG#19795152: Also NODE_FAILURE_COMPLETED and ALLOCATED_NODE_ID can be states from where a node fails from DISCONNECT_REP although the node hasn't really started its start yet.
      BUG#74594: Removed buggy ndbrequire, not correct though to possibility of delaying arrival of LCP_FRAG_REP when copying table to disk
      BUG#19795152: NdbTick_Elapsed parameters in wrong order
      BUG#19795152: Added one more acceptable state transition, ALLOCATED_NODE_ID -> ALLOCATED_NODE_ID
      BUG#74594: Missed setting lcp id in COPY_TABREQ, added ints of LCP variables on replica and fragment records, removed init of lcpStatus in INCL_NODEREQ which depended on old fact that we included when LCP was idle, now this is no longer necessary, missed init of m_lcp_start_time in including node in LCP, added a number of log prints
      WL#6815 Adapt MySQL Cluster to 5.7
      Bug#19676350 NDB_RPL_CONFLICT_EPOCH SHOWS SCHEMA DIST TIME FAST FORWARD DUE TO EINVAL
      BUG#74594: missed init of c_queued_lcp_complete_rep
      BUG#74594: Handle fromTimeQueue issues with LCP_FRAG_REP
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed more on asserts
      BUG#74594: Fixed stopping of pause properly in master and in non-master
      BUG#74594: Wrong assumption in START_LCP_REQ removed, fix of ndbrequire of COPY_TABREQ counter improved
      BUG#74594: Added new parameters to allocStoredReplica
      BUG#74594: Missed init of fragId and tableId in replica record, wrong assumption about m_participatingDIH in START_LCP_REQ
      BUG#74594: Missed clear of own node in NodeReceiverGroup in sending FLUSH_LCP_REP_REQ
      BUG#74594: Fixed typo
      BUG#74594: Missing inserts into signal table
      BUG#74594: Fixes for wrong assert, missing state update and wrong condition
      BUG#74594, fix for sanity check
      BUG#19795152: Fix a placement new that overwrote the node recovery timers in debug mode, added a bit more debug code and arranged the parameters in some common functions a bit more logically
      BUG#74594: Added missing file CopyTab.hpp
      BUG#74594: Remove need for long wait for LCP to copy meta data to make restart times more predictable and faster
      BUG#74639: Preparatory patch to handle overload bugs that is likely to be caused by higher pressure on LCPs and restarts
      BUG#19795152: Added missing file: NodeRecoveryStatusRep.hpp
      BUG#19795152: Wait for LCP start at node restart, add node recovery status table as well
      BUG#19795217: Remove EMPTY_LCP protocol from master takeover
      BUG#74594: Part 2: Fix a potential LCP stoppage
      BUG#74594: Part 1: Remove a faulty ndbrequire
      BUG#19795029: Improve logging of restarts developed in WL#7514
      BUG#19795108: Fix of node restart status for adapting speed of LCP disk write speed
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug #19822069 TESTUPGRADE -N UPGRADE_API_BEFORE_NR1 T2 FAILS DUE TO CONCURRENT CREATEDROPEVENT
      Bug#20007248 NDB NOT FUNCTIONAL ON POWER
      Bug#20007216 FLEXASYNC USES 32BIT MATH, LEADING TO INCORRECT SUMMARY ON POWER8
      Fix regression in AutoTest -n DropWithTakeover T1 introduced by fix for bug#19874809:
      Add missing newline before end of file in AsyncNdbContext.cpp
      Fix build failure in MCP patch for BUG19553099
      bug#20017292 Clusterj logging levels too verbose
      Bug#20009152 FIELD NAME NOT INCLUDED IN WARNING WHEN CONVERTING TO FIXED
      WL#7640  Ndb Active Active Delete-Delete handling
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Fix Club test regressions after backport of bug#19524096:
      WL#7640  Ndb Active Active Delete-Delete handling
      Provide easy way to store documents with no mapping and no schema defined   define new method on session factory: db(database_name) returns db object   db object has properties corresponding to table names     if table does not exist, create the table       if user has not mapped the table, create default table mapping and table       if user has mapped the table, use table mapping to create the table   Operations on session using non-existing table name     will now create the table if it does not exist and user has mapped the table
      Fix bad #ifdef
      Bug#19903481 - INTERNAL ERROR DURING ONLINE REORG, TRIX (LINE: 782) 0X00000002
      Bug #19817817 TFBUFFER::VALIDATE() CONST: ASSERTION `(P->M_BYTES & 3) == 0\' FAILED
      Backport of fix for bug#19524096
      Bug#19999242 DELETEING NDB_CLUSTER_CONNECTION WITH NDB INSTANCES
      bug#19913569
      Avoid segv when closing session factory with sessions still active
      Bug #17592990: DATA MISMATCH BETWEEN C NDB API AND MYSQL CLI.
      Backport of fix for Bug#19724313
      Fix for bug#19880747:
      Fix for bug#19875663
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Bug#14571512 : --PRINT_DATA TRUNCATING THE LAST 16 BYTES OF BLOB FIELD
      Fix for bug#19881025:
      This commit is an update of WL#7375 (Ndbinfo: Per-fragment memory usage reporting). Column fixed_elem_free_rows in view ndbinfo.memory_per_fragment is renamed to fixed_elem_free_count to get a more consisten naming.
      Fix for bug#19874809 :
      Added sles11 repo packages
      This commit implements WL#8145 (NdbInfo : Per-fragment operations info).
      Follow up fix for bug#18352514 fixing a build failure.
      Addendum fix for bug#18352514:
      bump version to 7.4.3
      Bug #19875710         NDB : COMMIT ACK MARKERS LEAK @ LQH IN 7.4
      BUG#19815044: Part 4, remove usage of global block variable m_pgman_ptr, it is used for parameter passing, but can in some weird situation in DBTUP it can be reassigned to a value that can cause an inconsistent database.
      BUG#19815044: Part 3, fix such that an aborted insert after a committed delete doesn't lead to that triggers for delete isn't executed by ensuring that delete_insert_flag is properly maintained
      BUG#19815044: Part 1: Improve jamming support to make it easier to read what's going on bug situations
      BUG#19815044: Add test case for it used in autotest
      BUG#19815041: Crash on abort of delete after successful delete on a disk data table
      Add global.fail_connect to test utilities
      Fix ProjectionErrorTest
      Improve error reporting for multidb tests
      big lint-fixing patch
      Fix unified_debug issue with per-file levels for C++ files Remove workaround for this in executable programs
      Converter use in DBTableHandler (fixes freeform tests for ndb)
      Big deglobalization patch. Removes many global variables (but not all).
      Move SQL.create and SQL.drop from test harness into adapters. NDB depends on MySQL for this.
      Enhance closeAllOpenSessionFactories() so it takes a callback & returns a promise
      Fix for bug#19712569
      When using node --harmony and strict mode, DBIndexHandler cannot be forward declared   and still use the function DBIndexHandler(parent, dbIndex) syntax.
      jscrund: add support for B tests with varying size varchar. (Only supported by jscrund_mysqljs crund backend).
      lint globals cleanup
      Fixes restart race causing test timeout in AutoTest 'testDict -n schemaTrans'
      Return an error if writing non-Buffer data to binary columns
      Allow flexible mapping for node.js domain classes
      Fix for bug#18352514
      Fix for bug#19661543
      Remove warning introduced with patch for BUG#19236945
      Bug #19236945 ADDRESSSANITIZER BUG SHOW UP IN NDBRECATTR::RECEIVE_DATA CALLED FROM RESTORE.CPP
      bug#19793475 - NO WAIT FOR EPOCHS THAT HAVE NO DB CHANGES MADE BY THIS NDB THD TO BE IN BINLOG
      Removing the extra blank line from daily-basic-autotest-conf
      Fixed compilation error due to changed file name
      Bug#19267720:  NDB REPLICATION : DO NOT SETUP CONFLICT RESOLUTION FOR EXCEPTIONS TABLES
      formatting
      Docs work
      BUG#19795072: Fix problems related to ndbinfo tables for disk write speed
      BUG#19643174: Fix races in relation to sending TC_COMMIT_ACK and handling of complete of a transaction
      Removed compiler warnings
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000): GOT ERROR 4547 PART II
      Cherrypick from 7.4 (revno 4354): Implement status variables exposing last commit epochs for the server   and each session.
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      bug#18411034 - CRASH IN NDB-SHARE: some debug to trace the problem
      BUG#19724313: Handle multiple threads crashing at the same time properly
      Added missing include for previous patch Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Restore computeChecksum to computeXorChecksum that was reverted in patch for Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Merge of Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      Refactoring of Packer::unpack in preparation of merging Bug#19582925
      Bug #19582925 ENHANCED DETECTION AND DUMP OF CORRUPT OR UNSUPPORTED MESSAGES
      wl#7674-5 fixing errors
      wl#7674-5 fixing errors and compiler warnings
      wl#7674 Backward compatibility/new event api methods
      wl#7675 Introduce state machine for event [1;31mbuffer[ming
      BUG#14798022 : "CHAR (0)" DATATYPE CAUSING ERROR 1296 (HY000) : GOT ERROR 4547 : 'RecordSpecification has overlapping offsets'
      Applying the patch for regression bug#19582807 for 7.1.33 cluster release
      Improve Query documentation
      Cherrypicked
      Cherrypicked
      Bug #19582807 MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Wl#7639 Ndb Active Active Manageability improvements
      Removed compiler warnings
      WL#7642 Ndb Active Active Binlog Read Tracking: Removed uninitialized data to remove valgrind warnings
      Work on new README
      Bug #17257842     EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug #19766167         NDB : VALGRIND REACHABLE MEMORY IN NDB_RPL_CONFLICT_EPOCH_TRANS
      Fix new log printouts - Use log functions of component in favour of sql_print_information - Break long lines
      In-Progress Packaging / Documentation improvements
      Iterate array rather than for/in
      Add mynode.closeAllOpenSessionFactories()
      Windows testcase fix attempt
      Follow up patch for WL#7953 Transporter handshake retry
      WL#7642 Ndb Active Active Binlog Read Tracking: Updated result for ndb_rpl_conflict_read_tracking test case to reflect new conflict counters
      WL#7640  Ndb Active Active Delete-Delete handling
      bump version to 7.3.8
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      The patch series for WL#7642 Ndb Active Active Binlog Read Tracking
      bump version to 7.2.19
      bump version to 7.1.34
      Bug#19692387 PORT FIX FOR BUG 18770469 TO MYSQL CLUSTER 7.3
      Added ndb_print_file man pages
      Bug #17257842 EXCESSIVE RETRY FREQUENCY FOR API NODES RECONNECT CAUSES HIGH CPU ON MGM NODES.
      Bug#18487960: SIG 11 on delete with index merge
      Follow up patch for WL#7953 Transporter handshake retry
      Follow up patch for WL#7953 Transporter handshake retry
      Patch 2 for WL#7953 Transporter handshake retry
      Patch 1 for WL#7953 Transporter handshake retry
      Patch 3 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 2 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      Patch 1 of 3 for WL#7654: "Reduce lock contention in NDB mt-scheduler"
      adding checksum to the cnf file
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19667663 : NDB_SHOW_TABLE TEST CASES FAILING ON SPARC
      Bug #19600834  late code review comment
      Bug #19600834 DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH)
      Bug #19600834         DOWNGRADE FROM 7.4 TO 7.3 IS FAILING (CRASH) ...
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3
      Bug #19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Bug#19364731 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.3  - revert the reverted
      Bug#19365180 PORT FIX FOR BUG 17283409 TO MYSQL CLUSTER 7.2
      Change from mysql-5.6 to build Oracle Linux 7 RPMs
      WL#7640  Ndb Active Active Delete-Delete handling
      WL7640 Add delete-delete conflict count
      Adding ndb_print_file to spec file
      Repush of WL#7544 after 7.4.1 clone tag.
      bump version to 7.4.2
      Set version 7.4.1
      Revert WL#7544, not to be included in DMR 7.4.1
      Reorder member initializer list for thr_data to follow initialization order. This removes compiler warning introduced in fix of Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      WL#7544: Optimisations of the NDB API receiver thread in various manners. 1) Optimising method to unpack field data from TRANSID_AI signal, 2) optimised handling of trp_client locking check, 3) reorganised code in NDB API receiver thread for better performance and more readability, 4) Optimisation signal receive handler
      BUG#19451060: One more step on the way to understanding commit ack markers
      Bug #19582807    MAKE SIGNAL DUMP IN TRACE FILES ALWAYS START FROM LATEST SIGNAL
      Fix for bug#19559313, call getPerformStateString() with a nodeId arg instead of a state argument
      Fix for Bug#19552283 :
      Update documentation to remove useProjection       Update Session.js to remove useProjection
      BUG#19552349: Avoid stack overrun by removing endless recursive call
      BUG#19451060: Further refinements of bug fix, previous ndbrequire revealed a race that could cause multiple REMOVE_MARKER_ORDs to appear for the same transaction, added long comment about this specific race variant. Left a part of the ndbrequire still to ensure that this only happens when receiving REMOVE_MARKER_ORD sent by API through TC_COMMIT_ACK and not through API failure handling
      Bug #18703922  DUMP-CODE ACTIVATED DEBUGGING ON WATCHDOG OVERLOAD ISSUES
      Bug #17730825  NDB API: POSSIBLE LEAK OF CONNECTION OBJECTS
      BUG#19524096: Converted many 4009 errors to temporary error 4035, ensured APIs can use new data nodes sooner, fixed some wrong error categories, removed no longer used errors, fixed some anomaly in communication towards the API, small improvement of restart printouts, should give autotest a much better chance to get rid of redness
      Bug #17893872         ER_DUP_ENTRY WHEN INSERTING TO AUTO-INC COLUMN ON SPARC MULTI-MASTER SETUP
      BUG#19451060: Added more descriptive information at crashes related to commit ack markers, changed name of noFired to numFired for clarity, added possibility to put last in free list to aid crash printouts
      Fix for spelling error in Win32 code
      WL#7509: Introduced more configurability of disk write speeds and added a number of new ndbinfo tables to track this new more adaptive behaviour
      WL7845: More and safer ways to print records in DBTC
      BUG#19451049: Missing call to prepareTUPKEYREQ from handle_lcp_keep, added comment about handle_lcp_keep
      bug#19124970 - PB WITH POLLEVENTS , NDBEVENTS
      Backport from 7.2
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      BUG#17069285 SEGMENTATION FAULT IN NDB_PRINT_FILE
      The Bug was due to m_out object used in NdbOut operator was not initialized/set to the output stream. Added an ndb_init() call to initialize it to output stream. Added an environmental variable $NDB_PRINT_FILE to give path to its binary in  mysql-test/mysql-test-run.pl file. Added a unit test and its result file.
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      bug#19031389 bugfix.diff bug fix
      bug#19031389 bugtest.diff bug test
      BUG#19513967: Fixed missing init of longer bitmask
      Bug#19202654  NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      BUG#17703874
      Bug#19202654: NDB_RESTORE NOT ABLE TO RESTORE META WITH 17K OBJECTS
      Bug #18354165         16723708 CHANGED EVENT CATEGORY VALUES
      Clusterj windows CMakeList error
      Clusterj support for autoincrement columns http://wl.no.oracle.com/worklog/NDB-RawIdeaBin/index.pl?tid=8027
      Added missing logging.properties
      Clusterj improve maven handling for out-of-source builds
      Bug#18875137: NDB_RESTORE STILL MISSING SOME TYPE CONVERSIONS
      Fix for Bug#19414511:
      Bug #19236785  ADDRESSSANITIZER BUG IN ~NDB_MOVE_DATA Bug #73311      AddressSanitizer bug in ~Ndb_move_data
      Bug #19235428  ADDRESSSANITIZER BUG IN DATABUFFER2<SZ,POOL>::IMPORT (DBDICT::ALTERTABLE_PARSE) Bug #73310     AddressSanitizer bug in DataBuffer2<sz,Pool>::import (Dbdict::alterTable_parse)
      Bug #19235170  ADDRESSSANITIZER BUG IN DBUTIL::GET_SYSTAB_TABLEID Bug #73308  AddressSanitizer bug in DbUtil::get_systab_tableid
      Bug#11764704 : Exclude missing tables when restoring a backup  - added an option "--exclude-missing-tables" to ndb_restore tool  - when enabled, the missing tables will be added to the    exclude tables list before starting to restore.  - updated test cases accordingly.
      Revert fix merged in from 5.5.39 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert fix merged in from 5.6.20 that does not work as is in MySQL Cluster Bug#17283409  4-WAY DEADLOCK: ZOMBIES, PURGING BINLOGS, SHOW PROCESSLIST, SHOW BINLOGS
      Revert quick fix for dtrace problems in release tree. New fix in CMake files will be merged in from 5.6.20.
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      The confusion in the bug#16374870 is caused by the poor usage message which fails to add *args* table [index].
      This commit is a followup to the one below. It changes the fragment_num colum (in memory_per_fragment), such that it gives the global frgament id rather than a node-local sequence number. That way, it is possible to see where each fragment (or some replica of it) is located. This is consistent with the output from 'ndb_desc -pn -d <database> <table>.
      Bug 19028487 NPE when scanning rows with blob or text columns
      More fixes for bug#19053226
      Fixes for bug#19053226
      More fixes for bug#19053226
      bug#18410939 - MEMORY LEAK AT EVENT BUFFER ALLOCATING A DUMMY EVENT LIST WHEN INCONSISTENCY
      Bug #17184024         ERROR 4 IN LIBNDBCLIENT.SO.6.0.0 (3-7474573041)
      bug#19122346 fix3.diff FK use full name PP/CC/name + debug
      bug#19122346 fix2.diff fix test error from 7.3 r4203 FK_Bug18069680
      bug#19122346 fix1.diff FK use full name PP/CC/name
      ndb - RSS-DynArr256
      A new ndbapi test case: testNodeRestart -n DeleteRestart.
      Bug #18731008    NDB : AVOID MAPPING EMPTY PAGES DUE TO DELETES DURING NR Bug #18683398    MEMORY LEAK DURING ROLLING RESTART
      Bug #19193927         TC TAKEOVER TAKES TOO LONG CAUSING MANY PROBLEMS
      ndb
      Bug#19193756 MTR GENERATES TOO LONG SOCKET PATHS
      Merge from mysql-cluster-7.2.17-release
      ndb
      use primitive types
      Include stdlib.h for malloc() and free()
      Compiler issues on some Windows platforms
      Add debug to trace bug#18411034 - CRASH IN NDB-SHARE
      Updated the list of tables to be deleted after running ndb clusterj tests Added new test and the model to build specification
      Merge latest nodejs-adapter from 7.3 to 7.4
      Unconditionally disable dtrace for rpm, barfs on Oracle dtrace
      Remove superfluous -master.opt file for the removed test case ndb_mt_recv.
      Unconditionally disable dtrace for rpm-oel, barfs on Oracle dtrace
      correcting copyright headers
      Fix issues with Read/Modify/Update of NDB VO objects containing blobs.
      All NDB read results (including those containing BLOB and TEXT columns) are now ValueObjects.
      Fix bug of using Persistent<T>(x) rather than Persistent<T>::New(x)
      work on support for NdbRecord-backed ValueObjects which contain TEXT or BLOB columns.
      More TEXT tests for NDB
      less debugging output at end of test run
      Fix composition value checking
      Implement [1;31mbuffer[mForText and textFromBuffer in C++.
      rawNdbDefaultvalue does not require a full-fledged Node Buffer
      let compiler supply default destructors
      Another attempt to fix crashing bug in BlobHandler
      Expose the string encoder statistics in NdbTypeEncoder.cpp to JavaScript.
      Move v8 calls from worker thread to main JS thread
      Support TEXT columns with character set UTF-8 or ASCII. Other charsets (which require recoding) are not yet supported.
      A test file that does not export a test case now causes a warning rather than an error.  This should make it a little easier to develop new tests.
      Column Metadata API provides charsetName rather than charsetNumber
      Fix apparent bug in calculating size requirement of UTF-8 [1;31mbuffer[m
      Restore compatibility with node-mysql 2.0.0
      Fix crash on stub commit / stub rollback
      update cmake & gyp build lists
      Finish read & write BLOB implementation for NDB adapter
      Implement connection pooling for mysql adapter
      Fix tests that do not close session after running test
      Improve error reporting for connecting to database
      Add suggestion to user to maximize performance of updates
      Improve spi test error reporting
      Succesful insert into BLOB column
      Add BLOB column to stringtypes test suite & confirm that existing tests pass with a mapped (but unused) BLOB field.
      Test that storing a non-BLOB in a BINARY column gives error SQLState 22000
      Use Error SQLState 0F001 "Bad BLOB" (actually a "Locator Exception") if value intended for a BLOB column is not a Buffer.
      Initial implementation work on BLOB support for NDB adapter.
      Refactor connection handling to prepare for connection pooling
      WL#7626 Implement many-to-many relationships for Document Composition
      Don't try immediate startTransaction() unless using async api.
      Keep a single usedOperationSets array rather than one per DBSession. The array is at file scope in NdbTransactionHandler. It does not grow past 4000 elements (a literal constant). Underlying DBOperationSet native objects are freed when the wrapper is placed in the recycler array.
      Disable mysql tests for now
      Attempt to recycle DBOperationSet wrappers
      wrapPointerInObject and unwrapPointer take a v8::Handle<T> rather than a v8::Local<T>
      Improve error reporting for relationships that are null or undefined
      Test a slightly different approach to V8 wrapping
      Minor refactoring in NdbOperation
      Remove the use of "proto" in DBTableHandler
      Refactor DBTableHandler.getFields() into a simple case getFields() and a separate more complex getFieldsWithListener(). Removed the resolveDefaults option which was always set to false.
      Improve error reporting for ProjectionTest
      Improve error reporting for ProjectionTest
      Improve error reporting for test failures
      Compiler error
      Stub out NdbSession.buildReadProjectionOperation in hopes that test suite will run.
      WL#7626 Composition Implement support for one-one, one-many, and many-many relationships. Replace useProjection with implementation for find (projection, key).
      Rather than having a JavaScript wrapper for Record::setNotNull(), implicitly call setNotNull() when writing a data value in encoderWrite().
      Don't use a startTransaction() hint for unique key operations.
      In JsValueConverter for pointer types, if the JavaScript value is Null, represent it as a null pointer.
      Remove what little was left of NdbTransaction_wrapper.cpp
      move ENABLE_WRAPPER_TYPE_CHECKS define into adapter_global.h
      portability fix
      Update source file lists for gyp & CMake
      Add option free-percent
      New design for scans. This removes the previous wrapper for NdbScanOperation and ScanImpl.cpp file and consolidates all scan functions into ScanOperation. Expected: start 416 tests, pass 413, fail 2, skip 1.
      fix wrappers for boolean types
      In test driver allow --stats=query, e.g. --stats=spi/ndb/DBSession
      Add HandleScope to all toJS() template functions just to be safer from enigmatic V8 memory leaks. Provide toJS() and isWrappedPointer() specializations for type bool.
      Refactor NDB execute. This patch renames PendingOperationSet to DBOperationSet, and makes DBOperationSet the "point of contact" for JavaScript calls to begin and execute transactions. All t_basic tests now pass.
      New SPI test   begin transaction; delete (execute NoCommit) ; read deleted row ; commit.
      Minor bug fixes for passing SPI tests
      Major JavaScript logic changes in NDB adapter. NdbTransactionContext, NdbSession, NdbOperation, and NdbConnectionPool are adapted to use the call flow of DBSessionImpl and DBTransactionContext rather than the native call flow of the NDB API.
      This commit includes various small C++ fixes. The next commit includes major JavaScript logic changes. With these together, spi tests pass.
      Add new connection property ndb_sesion_concurrency Refactor initialization of NdbSession and connecting of the new NdbSession to its impl.
      Adapt DBDictionaryImpl to use DBSessionImpl rather than Ndb.
      Revise protocol for registering a transaction open / closed. Use only two calls, registerIntentToOpen() and registerTxClosed(). Always make these calls from JavaScript main thread.
      NdbTransaction is no longer wrapped for JavaScript
      Template class NativeCFunctionCall_4_
      DBSessionImpl
      Adapt AsyncNdbContext to be aware of DBTransactionContext
      executeAsync() on AsyncNdbContext is no longer wrapped for JavaScript; use executeAsync() on DBTransactionContext instead.
      Refactor DBOperationHelper:  it now takes a DBTransactionContext rather than an NdbTransaction.  it now defines operations, but does not prepare them.
      Rename addOperation() to getNextOperation()
      Add two new classes, DBTransactionContext and DBSessionImpl. These will free the JavaScript code from the start/prepare/execute cycle of Ndb and NdbTransaction, eventually allowing operations to be performed with fewer scheduled async calls and therefore less overhead.
      Adapt DBOperationHelper to the KeyOperation / ScanOperation change.
      Bug fix where the do_close flag must be associated with the transaction rather than its parent Ndb object.
      Refactor Operation and DBScanHelper into two classes called KeyOperation and ScanOperation.
      This change alllows Ndb::startTransaction() to run as a sync call in the main JS thread if we suspect that it will not block.  As a proof of concept, this allows you to measure the performance with this change; but it should not be used as-is, because the guess could be wrong, which would cause the main thread to block waiting for network I/O.
      In the common case where an async method call returns int zero, try to optimize away creating a new JavaScript value.
      Slight change to the compatibility strategy for some libuv changes.
      Combine NdbTransaction execute() and close() into a single scheduled call whenever execType is Commit or Rollback.  This saves the scheduling cost of running the close() call by itself.
      Various fixes for lint.
      Remove old stats API.
      Use new stats API in MySQL code.
      Use new stats API in NDB code.
      Revised statistics API. Now each module owns, at file scope, its own stats object. The module registers the stats object with the global statistics, which keeps a reference to it in the stats tree. This should reduce the cost of keeping statistics to practically zero.
      Delay after (rather than before) the first test iteration. This allows V8 to compile all the JavaScript code before dtrace starts running. High dtrace profiling rates caused the first iteration to run very slowly and skewed the profile towards compile times rather than run times.
      Optional delays both before & after jscrund run
      jscrund: add option to delay start of test run
      Add useProjection to Session   this function specifies a projection to be used for find and query operations
      Minor work on DBDictionaryImpl Contain the code for handling NdbDictionary 3-part/slashed/names in DictionaryNameSplitter class. Reformat patch indent width from 4 spaces to 2 spaces. buildDBForeignKey() takes only the fk* and must use its own private name splitter.
      Error 23000 when attempting to set a non-nullable column to null.
      Restore table which should not have been removed from test suite
      Add support for foreign key metadata
      update literal mapping test for schema
      Fix errors in test case & misc. lint errors.
      Check in test case where one operation in a batch has a data type error. This test fails for both NDB and MySQL.
      Expose NdbRecordObject::prepare() to JavaScript. This is a step towards fixing handling of encoder errors for value objects.
      Write a negative value to an unsigned int field of an NDB Value Object. This test causes the test suite to hang forever.
      Run executeAsynch() in JS main thread rather than a UV worker thread. We had seen higher latency using async ndbapi vs. sync ndbapi, but this change eliminates most of that difference.
      unused table in test suite
      Fix for compiler warning in TimestampWriter validity check
      NDB encoding-related changes.  (1) distinguish between 22003 numeric value out of range and HY000 for "value is not numeric"  (2) provide a (hopefully) faster path to encoderWrite and encoderRead by wrapping them as methods of Record
      Refactor error handling
      Attempt to optimize encodeKeyBuffer() for single-column indexes
      Fix reporting of session factory if no mappings
      Remove JsValueAdapter in loader; it is no longer needed.
      This fixes the failing "timestamp 1969" test case for NDB. Test still fails with MySQL.
      Fixes for lint test failures
      Test & fix NDB handling of encoder errors for numeric types
      Tests for numeric types
      This renames the integraltypes suite to numerictypes and adds stub tests for float, double, and decimal columns
      Test for particular expected errors rather than simply for operation failure
      Add decimal support in NdbTypeEncoders Remove JS wrapper for decimal utilities from ndb_util
      Encoders for NDB integer values: if the fast integer conversion fails, try a slow one, then test whether the result is legal.  This should allow writing valid JS string and float values to int columns.
      Improve handling of errors from NDB data type encoders
      Improve handling of data encoder errors in the ndb adapter
      fix sql_mode for mysql adapter
      Implemented test cases
      Stub out new test cases for data type casting
      If MySQLTime.valid is set to false, NdbTypeEncoder will reject the value.
      Allow user to set sql_mode in mysql adapter with a default of STRICT_ALL_TABLES
      Change console.log to udebug.log in issues/2014-03-18Test
      Add shell script to manage regular runs of jscrund
      Adapt loader to use new Batch.getOperationCount() api
      Batch: use getOperationCount()  rather than getSize()
      Add Batch.getSize() method
      Add test case for issue of bad data type for column
      Fix typo
      Add test case for issue where a TableMapping created from a literal mapping could not be used to perform operations (fixed in bzr 686).
      Changes to sample data loader after code review with Craig. This version still has lots of untested features (and combinations of features) but it can load CSV data and random data.
      Bug fix creating TableMapping from object literal
      WL#7578 Replace usage of ndb_schema_share->key with hardcoded text
      WL#7578 Move subscriber bitmaps to NDB binlog component
      WL#7578 Move the g_nodeid_map to Ndb binlog thread
      WL#7578 move clearing of subscribed to binlog thread
      WL#7578 Always expect everyone to ack the schema op
      WL#7578 Refactor schema distribution code
      WL#7578 Refactor schema distribution code
      ndb
      WL#7578 note about nodeid from global cluster connection
      WL#7578 Don't use ndb_schema_share from ack_schema_op
      Initial checkin of JavaScript data loader tool
      Remove windows line endings from ndb_schema_object.cc
      Try to reduce overhead of stats.incr() calls
      Remove the error handling in jscrund_mysqljs backend which duplicates work performed in the jscrund frontend.
      Add conditional guards around udebug log messages.
      Add conditional guards around udebug log statements.
      Improve error reporting while loading mysql node_module
      The node-mysql driver by default constructs an Error object in order to get a stack that includes the user's call to Query. This can be a performance bottleneck.

[33mcommit 018ee48617052b3806f4dd22d93242c2aa16ae3b[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Apr 8 11:52:14 2015 +0300

    Test the mysys's lockfree hash
    
    It is impossible to implement the ut_hash_interface_t using the mysys's
    lockfree hash because it requires the called to maintain a "pins" object
    on his own, in addition to the hash table itself. Thus, messup the neat
    implementation in the unit test.
    
    This commit is for historical reference and is going to be reverted.
    
    The mysys's lockfree is about 10 times slower than the implementation in
    ut0lock_free_hash.h for the workload in the ut0lock_free_hash-t unit
    test.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 6a8e942977dd798050cd1c86acc05fd9966b975f[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Mar 31 16:36:11 2015 +0300

    Rename simple_hash_t->std_hash_t in the unit test
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit b73ee71b072c49f7acf2a27f8dc1cbf553ee2e3a[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Mar 31 15:50:40 2015 +0300

    Extend the hash table unit test
    
    Extend the test to also (conditionally, configured at compilation time)
    test the performance of std::map and std::unordered_map.
    
    For this introduce an interface class ut_hash_interface_t which is
    implemented by ut_lock_free_hash_t and also by a simple class inside the
    unit test which uses std::map (or std::unordered_map) + a mutex.
    
    Also make the number of initially pre-allocated elements configurable as
    a parameter to the ut_lock_free_hash_t constructor.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 56731d709527a77ac473decda153a192e2049abf[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Mar 26 13:35:09 2015 +0200

    Implement growing of the lock free hash table
    
    With this change when the hash is filled up and needs to be extended, a
    new array is appended and the hash consists of two or more arrays.
    Search and insert operations are performed on each array separately.
    
    When a new array is appended the data in the old one is not transferred
    to the new one. It is to be determined if this is necessary from
    performance point of view (searching in more than one array is
    sub optimal).
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 321bf0c14c5ecf0a4936a8defb0f1a6bcdf3394e[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Wed Mar 25 11:15:20 2015 +0200

    Add gunit test for the lock free hash table
    
    The test has a multi threaded part that hammers a global hash with
    changes to shared (key, value) tuples as well as private to the thread
    ones.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 9196a02696c64fe46e4d5883f0acb9fbc76b3d1d[m
Author: Marko Mäkelä <marko.makela@oracle.com>
Date:   Thu Mar 26 14:57:08 2015 +0200

    Bug#20737524 post-push fix: Compare the full index_id_t in InnoDB monitor.
    
    buf_page_monitor(): When checking if the page belongs to the InnoDB
    change [1;31mbuffer[m, also compare the space_id.
    
    Reviewed-by: Vasil Dimov <vasil.dimov@oracle.com>

[33mcommit 8d5a70624d0358cd01c746706a632f8cd964c61a[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Sun Mar 22 09:40:25 2015 +0200

    s/key/m_key/ in ut_lock_free_hash_t::key_val_t
    
    To obey the InnoDB coding style.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit d2bc43d1737186f30eff6cf7fd28883861faf1ff[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri Mar 20 16:06:30 2015 +0200

    Add debug asserts to confirm sane key/vals
    
    Make sure that the to-be-set key or val does not collide with the
    internally reserved values in the hash table.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 4129e497b95e0151464cc5a3ca831bad256561f7[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Tue Mar 17 15:26:55 2015 +0200

    Implement a lock free hash table
    
    The hash table stores (key, value) pairs where both the key and the
    value are of type uintptr_t (word size) and has two big limitations:
    1. Cannot be resized
    2. Cannot delete elements
    
    Use this hash table inside buf_stat_per_index_t - no mutex protection is
    needed now for this global variable.
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 743385a257da78bb0f98605773db5b16381b266d[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Fri Mar 13 18:16:59 2015 +0200

    Account the creation of new pages
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit e89bb126466299e453f7007d445aafa883ce6316[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Mar 12 20:52:59 2015 +0200

    Ship the estimate of cached pages to the Optimizer
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes
    
    Ship the percentage of cached pages for each index in
    ha_innobase::info() regardless of the flag (HA_STATUS_*). Thus
    reorganize the code from:
    
      if (HA_STATUS_CONST) {
        check that the number of indexes in mysql and innodb are the same
        lock
        for each index {
          ship records per key esitmates
        }
        unlock
      }
    
    to:
    
      check that the number of indexes in mysql and innodb are the same
      lock
      for each index {
        NEW CODE: ship % of pages cached
        if (HA_STATUS_CONST) {
          ship records per key esitmates
        }
      }
      unlock

[33mcommit 66787248cfd3426b6f7554628f249c9ea95e3ecc[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Mar 12 20:33:54 2015 +0200

    Account the eviction of leaf pages from the BP
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit a51d26957dd48c78d7f2c6df50fb181634e57b3f[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Mar 12 20:19:50 2015 +0200

    Account reading of leaf pages into the [1;31mbuffer[m pool
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit 88e21cdea735bf6f7b419427080b57de1d74e209[m
Author: Vasil Dimov <vasil.dimov@oracle.com>
Date:   Thu Mar 12 19:12:34 2015 +0200

    Add a global key,value store for per-index stats
    
    WL#7170 InnoDB [1;31mbuffer[m estimates for tables and indexes

[33mcommit dec109fa0b90b6831dd8b8f85c9ede46fe41b08d[m
Author: Tor Didriksen <tor.didriksen@oracle.com>
Date:   Tue Feb 24 16:22:51 2015 +0100

    Bug#20565160 ASSERTION `SORT_FIELD->LENGTH >= LENGTH' FAILED
    
    If the functions 'least' or 'greatest' are used to compare
    datetime(n) data and string literals, we need to re-calculate 'max_length'.
    Otherwise we may allocate too small [1;31mbuffer[m for sorting the result.

[33mcommit 1b50cb72bc75e76f7f1238188f5950473b0dd68c[m
Author: Krunal Bauskar <krunal.bauskar@oracle.com>
Date:   Wed Feb 11 14:37:48 2015 +0530

    - Bug#20512578 WRONG LENGTH IN INFORMATION_SCHEMA.INNODB_TEMP_TABLE_INFO.NAME
      - Missed updating the [1;31mbuffer[m length reserved for holding the data.
    
      Reviewed by: Marko Makela (marko.makela@@oracle.com>
      over IM

[33mcommit a5da78d1822dd5d9001d27f61536469fd10e54c1[m
Author: Krunal Bauskar <krunal.bauskar@oracle.com>
Date:   Wed Feb 11 13:22:55 2015 +0530

    - Bug#20512578  WRONG LENGTH IN INFORMATION_SCHEMA.INNODB_TEMP_TABLE_INFO.NAME
    
      - Field named "field_length" in definition of I_S table is suppose to
        represent character length for the column and not the [1;31mbuffer[m length.
    
      - Buffer length is then calculated based on charset used.
    
      - Fixed the issue for innodb_temp_table_info to use length as column size.
    
      Reviewed by: Marko Makela (marko.makela@@oracle.com>
      over IM

[33mcommit 26c1d1e7d99cbe9c8feea856f805babf2f48167a[m
Author: Bin Su <bin.x.su@oracle.com>
Date:   Tue Feb 10 10:09:25 2015 +0800

    BUG#20474542 - BUFFER POOL LOAD ASSERTS ON ATTEMPTING TO READ
    NON EXISTING PAGE
    
    According to the report, there was a TRUNCATE TABLE before we try to
    load the dumpped pages into [1;31mbuffer[m pool. In this case, we indeed can
    meet these out of bound pages. We should simply skip these pages,
    since they're truncated and nothing to load.
    
    RB: 7935
    Reviewed-by: Vasil <vasil.dimov@oracle.com>

[33mcommit d64a0f110f1c7aeb181d823e2c6c4529c7a093fd[m
Author: Marko Makela <marko.makela@oracle.com>
Date:   Mon Nov 10 15:04:59 2014 +0200

    Clean up a test case.
    Use slow shutdown in order to avoid generating redo log after restart,
    for processing old undo logs or change [1;31mbuffer[m records.
    
    Use common header files for killing the server.
For keyword bufferpoolsize:
